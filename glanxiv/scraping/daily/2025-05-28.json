[
  {
    "id": "http://arxiv.org/abs/2505.22946v1",
    "title": "NegVQA: Can Vision Language Models Understand Negation?",
    "authors": [
      "Yuhui Zhang",
      "Yuchang Su",
      "Yiming Liu",
      "Serena Yeung-Levy"
    ],
    "abstract": "Negation is a fundamental linguistic phenomenon that can entirely reverse the\nmeaning of a sentence. As vision language models (VLMs) continue to advance and\nare deployed in high-stakes applications, assessing their ability to comprehend\nnegation becomes essential. To address this, we introduce NegVQA, a visual\nquestion answering (VQA) benchmark consisting of 7,379 two-choice questions\ncovering diverse negation scenarios and image-question distributions. We\nconstruct NegVQA by leveraging large language models to generate negated\nversions of questions from existing VQA datasets. Evaluating 20\nstate-of-the-art VLMs across seven model families, we find that these models\nstruggle significantly with negation, exhibiting a substantial performance drop\ncompared to their responses to the original questions. Furthermore, we uncover\na U-shaped scaling trend, where increasing model size initially degrades\nperformance on NegVQA before leading to improvements. Our benchmark reveals\ncritical gaps in VLMs' negation understanding and offers insights into future\nVLM development. Project page available at\nhttps://yuhui-zh15.github.io/NegVQA/.",
    "pdf_url": "http://arxiv.org/pdf/2505.22946v1",
    "published": "2025-05-28T23:58:37+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV",
      "cs.CY",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.22945v1",
    "title": "OWL: Probing Cross-Lingual Recall of Memorized Texts via World Literature",
    "authors": [
      "Alisha Srivastava",
      "Emir Korukluoglu",
      "Minh Nhat Le",
      "Duyen Tran",
      "Chau Minh Pham",
      "Marzena Karpinska",
      "Mohit Iyyer"
    ],
    "abstract": "Large language models (LLMs) are known to memorize and recall English text\nfrom their pretraining data. However, the extent to which this ability\ngeneralizes to non-English languages or transfers across languages remains\nunclear. This paper investigates multilingual and cross-lingual memorization in\nLLMs, probing if memorized content in one language (e.g., English) can be\nrecalled when presented in translation. To do so, we introduce OWL, a dataset\nof 31.5K aligned excerpts from 20 books in ten languages, including English\noriginals, official translations (Vietnamese, Spanish, Turkish), and new\ntranslations in six low-resource languages (Sesotho, Yoruba, Maithili,\nMalagasy, Setswana, Tahitian). We evaluate memorization across model families\nand sizes through three tasks: (1) direct probing, which asks the model to\nidentify a book's title and author; (2) name cloze, which requires predicting\nmasked character names; and (3) prefix probing, which involves generating\ncontinuations. We find that LLMs consistently recall content across languages,\neven for texts without direct translation in pretraining data. GPT-4o, for\nexample, identifies authors and titles 69% of the time and masked entities 6%\nof the time in newly translated excerpts. Perturbations (e.g., masking\ncharacters, shuffling words) modestly reduce direct probing accuracy (7% drop\nfor shuffled official translations). Our results highlight the extent of\ncross-lingual memorization and provide insights on the differences between the\nmodels.",
    "pdf_url": "http://arxiv.org/pdf/2505.22945v1",
    "published": "2025-05-28T23:57:03+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.22944v3",
    "title": "ATI: Any Trajectory Instruction for Controllable Video Generation",
    "authors": [
      "Angtian Wang",
      "Haibin Huang",
      "Jacob Zhiyuan Fang",
      "Yiding Yang",
      "Chongyang Ma"
    ],
    "abstract": "We propose a unified framework for motion control in video generation that\nseamlessly integrates camera movement, object-level translation, and\nfine-grained local motion using trajectory-based inputs. In contrast to prior\nmethods that address these motion types through separate modules or\ntask-specific designs, our approach offers a cohesive solution by projecting\nuser-defined trajectories into the latent space of pre-trained image-to-video\ngeneration models via a lightweight motion injector. Users can specify\nkeypoints and their motion paths to control localized deformations, entire\nobject motion, virtual camera dynamics, or combinations of these. The injected\ntrajectory signals guide the generative process to produce temporally\nconsistent and semantically aligned motion sequences. Our framework\ndemonstrates superior performance across multiple video motion control tasks,\nincluding stylized motion effects (e.g., motion brushes), dynamic viewpoint\nchanges, and precise local motion manipulation. Experiments show that our\nmethod provides significantly better controllability and visual quality\ncompared to prior approaches and commercial solutions, while remaining broadly\ncompatible with various state-of-the-art video generation backbones. Project\npage: https://anytraj.github.io/.",
    "pdf_url": "http://arxiv.org/pdf/2505.22944v3",
    "published": "2025-05-28T23:49:18+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.22943v1",
    "title": "Can LLMs Deceive CLIP? Benchmarking Adversarial Compositionality of Pre-trained Multimodal Representation via Text Updates",
    "authors": [
      "Jaewoo Ahn",
      "Heeseung Yun",
      "Dayoon Ko",
      "Gunhee Kim"
    ],
    "abstract": "While pre-trained multimodal representations (e.g., CLIP) have shown\nimpressive capabilities, they exhibit significant compositional vulnerabilities\nleading to counterintuitive judgments. We introduce Multimodal Adversarial\nCompositionality (MAC), a benchmark that leverages large language models (LLMs)\nto generate deceptive text samples to exploit these vulnerabilities across\ndifferent modalities and evaluates them through both sample-wise attack success\nrate and group-wise entropy-based diversity. To improve zero-shot methods, we\npropose a self-training approach that leverages rejection-sampling fine-tuning\nwith diversity-promoting filtering, which enhances both attack success rate and\nsample diversity. Using smaller language models like Llama-3.1-8B, our approach\ndemonstrates superior performance in revealing compositional vulnerabilities\nacross various multimodal representations, including images, videos, and\naudios.",
    "pdf_url": "http://arxiv.org/pdf/2505.22943v1",
    "published": "2025-05-28T23:45:55+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV",
      "cs.LG",
      "cs.SD"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.22942v2",
    "title": "WorkForceAgent-R1: Incentivizing Reasoning Capability in LLM-based Web Agents via Reinforcement Learning",
    "authors": [
      "Yuchen Zhuang",
      "Di Jin",
      "Jiaao Chen",
      "Wenqi Shi",
      "Hanrui Wang",
      "Chao Zhang"
    ],
    "abstract": "Large language models (LLMs)-empowered web agents enables automating complex,\nreal-time web navigation tasks in enterprise environments. However, existing\nweb agents relying on supervised fine-tuning (SFT) often struggle with\ngeneralization and robustness due to insufficient reasoning capabilities when\nhandling the inherently dynamic nature of web interactions. In this study, we\nintroduce WorkForceAgent-R1, an LLM-based web agent trained using a rule-based\nR1-style reinforcement learning framework designed explicitly to enhance\nsingle-step reasoning and planning for business-oriented web navigation tasks.\nWe employ a structured reward function that evaluates both adherence to output\nformats and correctness of actions, enabling WorkForceAgent-R1 to implicitly\nlearn robust intermediate reasoning without explicit annotations or extensive\nexpert demonstrations. Extensive experiments on the WorkArena benchmark\ndemonstrate that WorkForceAgent-R1 substantially outperforms SFT baselines by\n10.26-16.59%, achieving competitive performance relative to proprietary\nLLM-based agents (gpt-4o) in workplace-oriented web navigation tasks.",
    "pdf_url": "http://arxiv.org/pdf/2505.22942v2",
    "published": "2025-05-28T23:45:28+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.22941v2",
    "title": "The only Class 0 Flower snark is the smallest",
    "authors": [
      "Guilherme Adamatti Bridi",
      "Andr√© Luis Alves Martins",
      "Franklin de Lima Marquezino",
      "Celina Miraglia Herrera de Figueiredo"
    ],
    "abstract": "Graph pebbling is a game played on graphs with pebbles on their vertices. A\npebbling move removes two pebbles from one vertex and places one pebble on an\nadjacent vertex. The pebbling number is the smallest $t$ so that from any\ninitial configuration of $t$ pebbles it is possible, after a sequence of\npebbling moves, to place a pebble on any given target vertex. Graphs whose\npebbling number is equal to the number of vertices are called Class~$0$ and\nprovide a challenging set of graphs that resist being characterized. In this\nnote, we answer a question recently proposed by the pioneering study on the\npebbling number of snark graphs: we prove that the smallest Flower snark $J_3$\nis Class~$0$, establishing that $J_3$ is in fact the only Class~$0$ Flower\nsnark.",
    "pdf_url": "http://arxiv.org/pdf/2505.22941v2",
    "published": "2025-05-28T23:45:27+00:00",
    "categories": [
      "math.CO",
      "cs.DM"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.22940v1",
    "title": "A Smart-Contract to Resolve Multiple Equilibrium in Intermediated Trade",
    "authors": [
      "Daniel Aronoff",
      "Robert M. Townsend"
    ],
    "abstract": "We present a model of a market that is intermediated by broker-dealers where\nthere is multiple equilibrium. We then design a smart-contract that receives\nmessages and algorithmically sends trading instructions. The smart-contract\nresolves the multiple equilibrium by implementing broker-dealer joint profit\nmaximization as a Nash equilibrium. This outcome relies upon several factors:\nAgent commitments to follow the smart contract protocol; selective privacy of\ninformation; a structured timing of trade offers and acceptances and,\ncrucially, trust that the smart-contract will execute the correct algorithm.\nCommitment is achieved by a legal contract or contingent deposit that\nincentivizes agents to comply with the protocol. Privacy is maintained by using\nfully homomorphic encryption. Multiple equilibrium is resolved by imposing a\nsequential ordering of trade offers and acceptances, and trust in the\nsmart-contract is achieved by appending the smart-contract to a public\nblockchain, thereby enabling verification of its computations. This model\nserves as an example of how a smart-contract implemented with cryptography and\nblockchain can improve market outcomes.",
    "pdf_url": "http://arxiv.org/pdf/2505.22940v1",
    "published": "2025-05-28T23:44:01+00:00",
    "categories": [
      "econ.TH",
      "cs.GT",
      "91-08, 91-10",
      "J.4"
    ],
    "primary_category": "econ.TH"
  },
  {
    "id": "http://arxiv.org/abs/2505.22939v1",
    "title": "Generative Social Choice: The Next Generation",
    "authors": [
      "Niclas Boehmer",
      "Sara Fish",
      "Ariel D. Procaccia"
    ],
    "abstract": "A key task in certain democratic processes is to produce a concise slate of\nstatements that proportionally represents the full spectrum of user opinions.\nThis task is similar to committee elections, but unlike traditional settings,\nthe candidate set comprises all possible statements of varying lengths, and so\nit can only be accessed through specific queries. Combining social choice and\nlarge language models, prior work has approached this challenge through a\nframework of generative social choice. We extend the framework in two\nfundamental ways, providing theoretical guarantees even in the face of\napproximately optimal queries and a budget limit on the overall length of the\nslate. Using GPT-4o to implement queries, we showcase our approach on datasets\nrelated to city improvement measures and drug reviews, demonstrating its\neffectiveness in generating representative slates from unstructured user\nopinions.",
    "pdf_url": "http://arxiv.org/pdf/2505.22939v1",
    "published": "2025-05-28T23:40:24+00:00",
    "categories": [
      "cs.GT",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.GT"
  },
  {
    "id": "http://arxiv.org/abs/2505.22938v1",
    "title": "Fast Isotropic Median Filtering",
    "authors": [
      "Ben Weiss"
    ],
    "abstract": "Median filtering is a cornerstone of computational image processing. It\nprovides an effective means of image smoothing, with minimal blurring or\nsoftening of edges, invariance to monotonic transformations such as gamma\nadjustment, and robustness to noise and outliers. However, known algorithms\nhave all suffered from practical limitations: the bit depth of the image data,\nthe size of the filter kernel, or the kernel shape itself. Square-kernel\nimplementations tend to produce streaky cross-hatching artifacts, and nearly\nall known efficient algorithms are in practice limited to square kernels. We\npresent for the first time a method that overcomes all of these limitations.\nOur method operates efficiently on arbitrary bit-depth data, arbitrary kernel\nsizes, and arbitrary convex kernel shapes, including circular shapes.",
    "pdf_url": "http://arxiv.org/pdf/2505.22938v1",
    "published": "2025-05-28T23:38:21+00:00",
    "categories": [
      "cs.CV",
      "cs.DS"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.22937v1",
    "title": "Improving QA Efficiency with DistilBERT: Fine-Tuning and Inference on mobile Intel CPUs",
    "authors": [
      "Ngeyen Yinkfu"
    ],
    "abstract": "This study presents an efficient transformer-based question-answering (QA)\nmodel optimized for deployment on a 13th Gen Intel i7-1355U CPU, using the\nStanford Question Answering Dataset (SQuAD) v1.1. Leveraging exploratory data\nanalysis, data augmentation, and fine-tuning of a DistilBERT architecture, the\nmodel achieves a validation F1 score of 0.6536 with an average inference time\nof 0.1208 seconds per question. Compared to a rule-based baseline (F1: 0.3124)\nand full BERT-based models, our approach offers a favorable trade-off between\naccuracy and computational efficiency. This makes it well-suited for real-time\napplications on resource-constrained systems. The study includes systematic\nevaluation of data augmentation strategies and hyperparameter configurations,\nproviding practical insights into optimizing transformer models for CPU-based\ninference.",
    "pdf_url": "http://arxiv.org/pdf/2505.22937v1",
    "published": "2025-05-28T23:38:11+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.22936v1",
    "title": "Mean-Field Games with two-sided singular controls for L√©vy processes",
    "authors": [
      "Facundo Oli√∫"
    ],
    "abstract": "In a probabilistic mean field game driven by a L\\'evy process an individual\nplayer aims to minimize a long run discounted/ergodic cost by controlling the\nprocess through a pair of increasing and decreasing c\\`adl\\`ag processes, while\nhe is interacting with an aggregate of players through the expectation of a\ncontrolled process by another pair of c\\`adl\\`ag processes. With the Brouwer\nfixed point theorem, we provide easy to check conditions for the existence of\nmean field game equilibrium controls for both the discounted and ergodic\ncontrol problem, characterize them as the solution of an integro-differential\nequation and show with a counterexample that uniqueness does not always holds.\nFurthermore, we study the convergence of equilibrium controls in the abelian\nsense. Finally, we treat the convergence of a finite-player game to this\nproblem to justify our approach.",
    "pdf_url": "http://arxiv.org/pdf/2505.22936v1",
    "published": "2025-05-28T23:34:14+00:00",
    "categories": [
      "math.OC",
      "math.PR",
      "60G40, 60G51, 49N80, 93E20"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2505.22935v2",
    "title": "Is Noise Conditioning Necessary? A Unified Theory of Unconditional Graph Diffusion Models",
    "authors": [
      "Jipeng Li",
      "Yanning Shen"
    ],
    "abstract": "Explicit noise-level conditioning is widely regarded as essential for the\neffective operation of Graph Diffusion Models (GDMs). In this work, we\nchallenge this assumption by investigating whether denoisers can implicitly\ninfer noise levels directly from corrupted graph structures, potentially\neliminating the need for explicit noise conditioning. To this end, we develop a\ntheoretical framework centered on Bernoulli edge-flip corruptions and extend it\nto encompass more complex scenarios involving coupled structure-attribute\nnoise. Extensive empirical evaluations on both synthetic and real-world graph\ndatasets, using models such as GDSS and DiGress, provide strong support for our\ntheoretical findings. Notably, unconditional GDMs achieve performance\ncomparable or superior to their conditioned counterparts, while also offering\nreductions in parameters (4-6%) and computation time (8-10%). Our results\nsuggest that the high-dimensional nature of graph data itself often encodes\nsufficient information for the denoising process, opening avenues for simpler,\nmore efficient GDM architectures.",
    "pdf_url": "http://arxiv.org/pdf/2505.22935v2",
    "published": "2025-05-28T23:31:07+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.22934v1",
    "title": "Unraveling LoRA Interference: Orthogonal Subspaces for Robust Model Merging",
    "authors": [
      "Haobo Zhang",
      "Jiayu Zhou"
    ],
    "abstract": "Fine-tuning large language models (LMs) for individual tasks yields strong\nperformance but is expensive for deployment and storage. Recent works explore\nmodel merging to combine multiple task-specific models into a single multi-task\nmodel without additional training. However, existing merging methods often fail\nfor models fine-tuned with low-rank adaptation (LoRA), due to significant\nperformance degradation. In this paper, we show that this issue arises from a\npreviously overlooked interplay between model parameters and data\ndistributions. We propose Orthogonal Subspaces for Robust model Merging (OSRM)\nto constrain the LoRA subspace *prior* to fine-tuning, ensuring that updates\nrelevant to one task do not adversely shift outputs for others. Our approach\ncan seamlessly integrate with most existing merging algorithms, reducing the\nunintended interference among tasks. Extensive experiments on eight datasets,\ntested with three widely used LMs and two large LMs, demonstrate that our\nmethod not only boosts merging performance but also preserves single-task\naccuracy. Furthermore, our approach exhibits greater robustness to the\nhyperparameters of merging. These results highlight the importance of\ndata-parameter interaction in model merging and offer a plug-and-play solution\nfor merging LoRA models.",
    "pdf_url": "http://arxiv.org/pdf/2505.22934v1",
    "published": "2025-05-28T23:28:12+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.22933v1",
    "title": "Emergent universal long-range structure in random-organizing systems",
    "authors": [
      "Satyam Anand",
      "Guanming Zhang",
      "Stefano Martiniani"
    ],
    "abstract": "Self-organization through noisy interactions is ubiquitous across physics,\nmathematics, and machine learning, yet how long-range structure emerges from\nlocal noisy dynamics remains poorly understood. Here, we investigate three\nparadigmatic random-organizing particle systems drawn from distinct domains:\nmodels from soft matter physics (random organization, biased random\norganization) and machine learning (stochastic gradient descent), each\ncharacterized by distinct sources of noise. We discover universal long-range\nbehavior across all systems, namely the suppression of long-range density\nfluctuations, governed solely by the noise correlation between particles.\nFurthermore, we establish a connection between the emergence of long-range\norder and the tendency of stochastic gradient descent to favor flat minima -- a\nphenomenon widely observed in machine learning. To rationalize these findings,\nwe develop a fluctuating hydrodynamic theory that quantitatively captures all\nobservations. Our study resolves long-standing questions about the microscopic\norigin of noise-induced hyperuniformity, uncovers striking parallels between\nstochastic gradient descent dynamics on particle system energy landscapes and\nneural network loss landscapes, and should have wide-ranging applications --\nfrom the self-assembly of hyperuniform materials to ecological population\ndynamics and the design of generalizable learning algorithms.",
    "pdf_url": "http://arxiv.org/pdf/2505.22933v1",
    "published": "2025-05-28T23:24:14+00:00",
    "categories": [
      "cond-mat.soft",
      "cond-mat.dis-nn",
      "cond-mat.stat-mech"
    ],
    "primary_category": "cond-mat.soft"
  },
  {
    "id": "http://arxiv.org/abs/2506.05371v2",
    "title": "Hyperelastic characterization via deep indentation",
    "authors": [
      "Mohammad Shojaeifard",
      "Mattia Bacca"
    ],
    "abstract": "Hyperelastic material characterization is crucial for understanding the\nbehavior of soft materials -- such as tissues, rubbers, hydrogels, and polymers\n-- under quasi-static loading before failure. Traditional methods typically\nrely on uniaxial tensile tests, which require the cumbersome preparation of\ndumbbell-shaped samples for clamping in a uniaxial testing machine. In\ncontrast, indentation-based methods, which can be conducted \\textit{in-situ}\nwithout sample preparation, have been underexplored. To characterize the\nhyperelastic behavior of soft materials, deep indentation is required, where\nthe material response extends beyond linear elasticity. In this study, we\nperform finite element analysis to link the force ($F$) versus indentation\ndepth ($D$) curve with the hyperelastic behavior of a soft incompressible\nmaterial, using a one-term Ogden model for simplicity. We identify three\nindentation regimes based on the ratio between indentation depth and the radius\n($R$) of the spherical-tipped cylindrical indenter: the Hertzian regime ($D <\n0.1R$), where $F = \\frac{16}{9} E R^{0.5} D^{1.5}$; the parabolic regime ($D >\n10R$), where $F = E D^2 \\beta$ and the indenter radius becomes irrelevant; and\nan intermediate regime ($0.1R < D < 10R$) bridging the two extremes. We find\nthat the Ogden strain-stiffening coefficient ($\\alpha$) increases the parabolic\nindentation coefficient ($\\beta$), allowing for the estimation of $\\alpha$ from\n$\\beta$. Furthermore, we observe that Coulomb friction increases $\\beta$,\npotentially masking the effect of strain-stiffening for small $\\alpha$.\nHowever, for $\\alpha > 3$, friction has a negligible effect. Finally, our\nresults show good agreement with experimental data, demonstrating that deep\nindentation can be an effective method for extracting hyperelastic properties\nfrom soft materials through \\textit{in-situ} testing.",
    "pdf_url": "http://arxiv.org/pdf/2506.05371v2",
    "published": "2025-05-28T23:24:03+00:00",
    "categories": [
      "cond-mat.soft",
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.soft"
  },
  {
    "id": "http://arxiv.org/abs/2506.02023v1",
    "title": "DistMLIP: A Distributed Inference Platform for Machine Learning Interatomic Potentials",
    "authors": [
      "Kevin Han",
      "Bowen Deng",
      "Amir Barati Farimani",
      "Gerbrand Ceder"
    ],
    "abstract": "Large-scale atomistic simulations are essential to bridge computational\nmaterials and chemistry to realistic materials and drug discovery applications.\nIn the past few years, rapid developments of machine learning interatomic\npotentials (MLIPs) have offered a solution to scale up quantum mechanical\ncalculations. Parallelizing these interatomic potentials across multiple\ndevices poses a challenging, but promising approach to further extending\nsimulation scales to real-world applications. In this work, we present\nDistMLIP, an efficient distributed inference platform for MLIPs based on\nzero-redundancy, graph-level parallelization. In contrast to conventional\nspace-partitioning parallelization, DistMLIP enables efficient MLIP\nparallelization through graph partitioning, allowing multi-device inference on\nflexible MLIP model architectures like multi-layer graph neural networks.\nDistMLIP presents an easy-to-use, flexible, plug-in interface that enables\ndistributed inference of pre-existing MLIPs. We demonstrate DistMLIP on four\nwidely used and state-of-the-art MLIPs: CHGNet, MACE, TensorNet, and eSEN. We\nshow that existing foundational potentials can perform near-million-atom\ncalculations at the scale of a few seconds on 8 GPUs with DistMLIP.",
    "pdf_url": "http://arxiv.org/pdf/2506.02023v1",
    "published": "2025-05-28T23:23:36+00:00",
    "categories": [
      "cs.DC",
      "cond-mat.mtrl-sci",
      "cs.LG",
      "cs.PF"
    ],
    "primary_category": "cs.DC"
  },
  {
    "id": "http://arxiv.org/abs/2505.22932v3",
    "title": "Variational Quantum Simulations of a Two-Dimensional Frustrated Transverse-Field Ising Model on a Trapped-Ion Quantum Computer",
    "authors": [
      "Ammar Kirmani",
      "Elijah Pelofske",
      "Andreas B√§rtschi",
      "Stephan Eidenbenz",
      "Jian-Xin Zhu"
    ],
    "abstract": "Quantum computers are an ideal platform to study the ground state properties\nof strongly correlated systems due to the limitation of classical computing\ntechniques particularly for systems exhibiting quantum phase transitions. While\nthe error rates of Noisy Intermediate-Scale Quantum (NISQ) computers are still\nhigh, simulating strongly correlated systems on such devices and extracting\ninformation of possible phases may be within reach. The frustrated\ntransverse-field Ising model (TFIM) is such a system with multiple ordered\nmagnetic phases. In this study, we simulate a two-dimensional frustrated TFIM\nwith next-nearest-neighbor spin-exchange interactions at zero temperature. The\ncompetition between the nearest-neighbor ferromagnetic and\nnext-nearest-neighbor antiferromagnetic coupling gives rise to frustration in\nthe system. Moreover, the presence of quantum fluctuations makes the\nground-state phase profile even richer. We use the Variational Quantum\nEigensolver (VQE) to compute the phases on a square lattice with periodic\nboundary conditions for a system of 16 sites (qubits). The trained VQE circuits\nare compared to exact diagonalization, allowing us to extract error measures of\nVQE. We focus on the ground-state phase transitions of this model, where VQE\nsucceeds in finding the dominant magnetic phases. The optimized VQE circuits\nare then executed on the Quantinuum H1-1 trapped-ion quantum computer without\nusing any error mitigation techniques. Our experiments show near perfect\nrecovery of the magnetic phases of the frustrated model through ground-state\nenergy, the energy derivative, and the spin correlation functions. Thus, we\nshow that the trapped-ion quantum processor is able to achieve reliable\nsimulations of a strongly correlated system within the limitations of the VQE\napproach.",
    "pdf_url": "http://arxiv.org/pdf/2505.22932v3",
    "published": "2025-05-28T23:20:20+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.22931v1",
    "title": "Recursive Difference Categories and Topos-Theoretic Universality",
    "authors": [
      "Andreu Ballus Santacana"
    ],
    "abstract": "We introduce a radically minimal categorical foundation for logic, semantics,\nand computation, built from a single generative axiom of recursive difference.\nFrom the null mnema M0 and iterated labeled extensions by D, we form the free\ncategory M and its sheaf topos Sh(M). We prove:\n  Modal completeness: Lawvere-Tierney topologies on Sh(M) classify all standard\nmodal logics (K, T, S4, S5) purely via submonoids of the free monoid D*.\n  Fixed-point expressivity: The internal mu-calculus over infinite branching\nrealizes the full Janin-Walukiewicz theorem.\n  ZFC and Set-modeling: Sh(M) embeds Set via constant sheaves and internalizes\na model of ZFC by recursive descent.\n  Turing encodability: Finite-automaton and Turing-machine sheaves arise\nsyntactically, yielding a fully mechanizable internal semantics.\n  Internal meta-theorems: Godel completeness and Lowenheim-Skolem hold\ninternally via total descent and vanishing first cohomology H1.\n  We further construct faithful geometric embeddings:\n  Set -> Sh(M) -> Eff, and Sh(M) -> sSet,\n  connecting to realizability and simplicial frameworks. Unlike HoTT and\nclassical site-theoretic models, Sh(M) exhibits total cohomological triviality,\nno torsors, and fully conservative gluing of all local data. Thus, we realize\nLawvere's vision of deriving semantics-modal, set-theoretic, computational, and\nmeta-logical-entirely from one syntactic axiom, unifying logic, semantics, and\ncomputation under a single recursive principle.",
    "pdf_url": "http://arxiv.org/pdf/2505.22931v1",
    "published": "2025-05-28T23:18:04+00:00",
    "categories": [
      "math.CT",
      "cs.LO",
      "18F20, 18C10, 03G30, 03B45, 03G12",
      "F.4.1; F.3.2; F.1.1"
    ],
    "primary_category": "math.CT"
  },
  {
    "id": "http://arxiv.org/abs/2505.23851v1",
    "title": "ASyMOB: Algebraic Symbolic Mathematical Operations Benchmark",
    "authors": [
      "Michael Shalyt",
      "Rotem Elimelech",
      "Ido Kaminer"
    ],
    "abstract": "Large language models (LLMs) are rapidly approaching the level of proficiency\nin university-level symbolic mathematics required for applications in advanced\nscience and technology. However, existing benchmarks fall short in assessing\nthe core skills of LLMs in symbolic mathematics-such as integration,\ndifferential equations, and algebraic simplification. To address this gap, we\nintroduce ASyMOB, a novel assessment framework focused exclusively on symbolic\nmanipulation, featuring 17,092 unique math challenges, organized by similarity\nand complexity. ASyMOB enables analysis of LLM generalization capabilities by\ncomparing performance in problems that differ by simple numerical or symbolic\n`perturbations'. Evaluated LLMs exhibit substantial degradation in performance\nfor all perturbation types (up to -70.3%), suggesting reliance on memorized\npatterns rather than deeper understanding of symbolic math, even among models\nachieving high baseline accuracy. Comparing LLM performance to computer algebra\nsystems, we identify examples where they fail while LLMs succeed, as well as\nproblems solved only by combining both approaches. Models capable of integrated\ncode execution yielded higher accuracy compared to their performance without\ncode, particularly stabilizing weaker models (up to +33.1% for certain\nperturbation types). Notably, the most advanced models (o4-mini, Gemini 2.5\nFlash) demonstrate not only high symbolic math proficiency (scoring 96.8% and\n97.6% on the unperturbed set), but also remarkable robustness against\nperturbations, (-21.7% and -21.2% vs. average -50.4% for the other models).\nThis may indicate a recent \"phase transition\" in the generalization\ncapabilities of frontier LLMs. It remains to be seen whether the path forward\nlies in deeper integration with sophisticated external tools, or in developing\nmodels so capable that symbolic math systems like CAS become unnecessary.",
    "pdf_url": "http://arxiv.org/pdf/2505.23851v1",
    "published": "2025-05-28T23:11:14+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.SC"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.22930v1",
    "title": "The Wave Equation in the Context of Reduced Groups $C^*$-Algebras",
    "authors": [
      "Fan Huang"
    ],
    "abstract": "Motivated by the identification $C(\\mathbb{T})\\cong C_r^*(\\mathbb{Z})$ and\nthe wave equation on the circle, we explore the wave equation in the context of\nreduced group $C^*$-algebras $C_r^*(G)$ for countably infinite, possibly\nnon-abelian groups $G$. Using a one-parameter group of $*$-automorphisms whose\ninfinitesimal generator paves the way to an analogue of the Laplacian, we\nestablish the existence and uniqueness of solutions to the wave equation within\nthis framework.",
    "pdf_url": "http://arxiv.org/pdf/2505.22930v1",
    "published": "2025-05-28T23:10:50+00:00",
    "categories": [
      "math.OA"
    ],
    "primary_category": "math.OA"
  },
  {
    "id": "http://arxiv.org/abs/2505.22929v1",
    "title": "Categorification of quasi-split iquantum groups",
    "authors": [
      "Jonathan Brundan",
      "Weiqiang Wang",
      "Ben Webster"
    ],
    "abstract": "We introduce a new family of graded 2-categories generalizing the 2-quantum\ngroups introduced by Khovanov, Lauda and Rouquier. We use them to categorify\nquasi-split iquantum groups in all symmetric types.",
    "pdf_url": "http://arxiv.org/pdf/2505.22929v1",
    "published": "2025-05-28T23:10:03+00:00",
    "categories": [
      "math.QA",
      "math.RT",
      "17B37, 18M05, 18M30"
    ],
    "primary_category": "math.QA"
  },
  {
    "id": "http://arxiv.org/abs/2505.22928v1",
    "title": "Enhancing Study-Level Inference from Clinical Trial Papers via RL-based Numeric Reasoning",
    "authors": [
      "Massimiliano Pronesti",
      "Michela Lorandi",
      "Paul Flanagan",
      "Oisin Redmon",
      "Anya Belz",
      "Yufang Hou"
    ],
    "abstract": "Systematic reviews in medicine play a critical role in evidence-based\ndecision-making by aggregating findings from multiple studies. A central\nbottleneck in automating this process is extracting numeric evidence and\ndetermining study-level conclusions for specific outcomes and comparisons.\nPrior work has framed this problem as a textual inference task by retrieving\nrelevant content fragments and inferring conclusions from them. However, such\napproaches often rely on shallow textual cues and fail to capture the\nunderlying numeric reasoning behind expert assessments.\n  In this work, we conceptualise the problem as one of quantitative reasoning.\nRather than inferring conclusions from surface text, we extract structured\nnumerical evidence (e.g., event counts or standard deviations) and apply domain\nknowledge informed logic to derive outcome-specific conclusions. We develop a\nnumeric reasoning system composed of a numeric data extraction model and an\neffect estimate component, enabling more accurate and interpretable inference\naligned with the domain expert principles. We train the numeric data extraction\nmodel using different strategies, including supervised fine-tuning (SFT) and\nreinforcement learning (RL) with a new value reward model.\n  When evaluated on the CochraneForest benchmark, our best-performing approach\n-- using RL to train a small-scale number extraction model -- yields up to a\n21% absolute improvement in F1 score over retrieval-based systems and\noutperforms general-purpose LLMs of over 400B parameters by up to 9%. Our\nresults demonstrate the promise of reasoning-driven approaches for automating\nsystematic evidence synthesis.",
    "pdf_url": "http://arxiv.org/pdf/2505.22928v1",
    "published": "2025-05-28T22:59:45+00:00",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.22927v1",
    "title": "Wideband Glide-Symmetric Slow-Wave Structure for Millimeter-Wave Sheet Beam TWTs",
    "authors": [
      "Robert Marosi",
      "Muhammed Zuboraj",
      "Filippo Capolino"
    ],
    "abstract": "We introduce a slow-wave structure (SWS) for a millimeter-wave sheet-beam\ntraveling-wave tube (TWT) with wide bandwidth. The wideband and stable\noperation is enabled through the topological properties associated with\nglide-symmetry that close the bandgap at the $3\\pi$-point and also make the\non-axis interaction impedance negligible for the backward wave. This space\nharmonic structure is designed to operate in the $V$-band over 55-68 GHz with\nsynchronism to a 5.2 kV, 11 mA sheet electron beam that will be produced by a\ndiamond field-emitter array.",
    "pdf_url": "http://arxiv.org/pdf/2505.22927v1",
    "published": "2025-05-28T22:59:24+00:00",
    "categories": [
      "physics.plasm-ph"
    ],
    "primary_category": "physics.plasm-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.22926v1",
    "title": "Leveraging Diffusion Models for Synthetic Data Augmentation in Protein Subcellular Localization Classification",
    "authors": [
      "Sylvey Lin",
      "Zhi-Yi Cao"
    ],
    "abstract": "We investigate whether synthetic images generated by diffusion models can\nenhance multi-label classification of protein subcellular localization.\nSpecifically, we implement a simplified class-conditional denoising diffusion\nprobabilistic model (DDPM) to produce label-consistent samples and explore\ntheir integration with real data via two hybrid training strategies: Mix Loss\nand Mix Representation. While these approaches yield promising validation\nperformance, our proposed MixModel exhibits poor generalization to unseen test\ndata, underscoring the challenges of leveraging synthetic data effectively. In\ncontrast, baseline classifiers built on ResNet backbones with conventional loss\nfunctions demonstrate greater stability and test-time performance. Our findings\nhighlight the importance of realistic data generation and robust supervision\nwhen incorporating generative augmentation into biomedical image\nclassification.",
    "pdf_url": "http://arxiv.org/pdf/2505.22926v1",
    "published": "2025-05-28T22:58:50+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.22925v1",
    "title": "Superoscillations and Physical Applications",
    "authors": [
      "Andrew N. Jordan",
      "John C. Howell",
      "Nicholas Vamivakas",
      "Ebrahim Karimi"
    ],
    "abstract": "This book chapter gives a selective review of physical implementations and\napplications of superoscillations and associated phenomena. We introduce the\nfield by reviewing simple examples of superoscillations and showing how their\nexistence naturally follows from the real part of the quantum mechanical weak\nvalue, which the parallel phenomena of supergrowth naturally follows from the\nimaginary part. Focusing on electromagnetic applications, we review the topics\nof superoscillation and supergrowth in speckle, creating superoscillating hot\nspots with patterned filters, superspectroscopic discrimination of two\nmolecules, noise mitigation and the engineering of super behavior in point\nspread functions for the purpose of optical superresolution. We also cover a\nvariety of different methods for creating superoscillatory and supergrowing\nfunctions, reviewing both mathematical and physical ways to create this class\nof functions, and beyond. Promising directions for future research, including\nsuperoscillations in other wave phenomena, super radar, and generalized\nsuper-phenomena in quantum physics, are outlined.",
    "pdf_url": "http://arxiv.org/pdf/2505.22925v1",
    "published": "2025-05-28T22:57:06+00:00",
    "categories": [
      "quant-ph",
      "physics.optics"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.00054v1",
    "title": "Retrieval-Augmented Generation: A Comprehensive Survey of Architectures, Enhancements, and Robustness Frontiers",
    "authors": [
      "Chaitanya Sharma"
    ],
    "abstract": "Retrieval-Augmented Generation (RAG) has emerged as a powerful paradigm to\nenhance large language models (LLMs) by conditioning generation on external\nevidence retrieved at inference time. While RAG addresses critical limitations\nof parametric knowledge storage-such as factual inconsistency and domain\ninflexibility-it introduces new challenges in retrieval quality, grounding\nfidelity, pipeline efficiency, and robustness against noisy or adversarial\ninputs. This survey provides a comprehensive synthesis of recent advances in\nRAG systems, offering a taxonomy that categorizes architectures into\nretriever-centric, generator-centric, hybrid, and robustness-oriented designs.\nWe systematically analyze enhancements across retrieval optimization, context\nfiltering, decoding control, and efficiency improvements, supported by\ncomparative performance analyses on short-form and multi-hop question answering\ntasks. Furthermore, we review state-of-the-art evaluation frameworks and\nbenchmarks, highlighting trends in retrieval-aware evaluation, robustness\ntesting, and federated retrieval settings. Our analysis reveals recurring\ntrade-offs between retrieval precision and generation flexibility, efficiency\nand faithfulness, and modularity and coordination. We conclude by identifying\nopen challenges and future research directions, including adaptive retrieval\narchitectures, real-time retrieval integration, structured reasoning over\nmulti-hop evidence, and privacy-preserving retrieval mechanisms. This survey\naims to consolidate current knowledge in RAG research and serve as a foundation\nfor the next generation of retrieval-augmented language modeling systems.",
    "pdf_url": "http://arxiv.org/pdf/2506.00054v1",
    "published": "2025-05-28T22:57:04+00:00",
    "categories": [
      "cs.IR",
      "cs.CL"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2505.22924v2",
    "title": "Optimizing QUBO on a quantum computer by mimicking imaginary time evolution",
    "authors": [
      "Yahui Chai",
      "Alice Di Tucci"
    ],
    "abstract": "We propose a hybrid quantum-classical algorithm for solving QUBO problems\nusing an Imaginary Time Evolution-Mimicking Circuit (ITEMC). The circuit\nparameters are optimized to closely mimic imaginary time evolution, using only\nsingle- and two-qubit expectation values. This significantly reduces the\nmeasurement overhead by avoiding full energy evaluation. By updating the\ninitial state based on results from last step iteratively, the algorithm\nquickly converges to the low-energy solutions. With a pre-sorting step that\noptimizes quantum gate ordering based on QUBO coefficients, the convergence is\nfurther improved. Our classical simulations achieve approximation ratios above\n0.99 up to 150 qubits. Furthermore, the linear scaling of entanglement entropy\nwith system size suggests that the circuit is challenging to simulate\nclassically using tensor networks. We also demonstrate hardware runs on IBM's\ndevice for 40, 60, and 80 qubits, and obtain solutions compatible with that\nfrom simulated annealing.",
    "pdf_url": "http://arxiv.org/pdf/2505.22924v2",
    "published": "2025-05-28T22:56:57+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.22923v1",
    "title": "Plug-and-Play Posterior Sampling for Blind Inverse Problems",
    "authors": [
      "Anqi Li",
      "Weijie Gan",
      "Ulugbek S. Kamilov"
    ],
    "abstract": "We introduce Blind Plug-and-Play Diffusion Models (Blind-PnPDM) as a novel\nframework for solving blind inverse problems where both the target image and\nthe measurement operator are unknown. Unlike conventional methods that rely on\nexplicit priors or separate parameter estimation, our approach performs\nposterior sampling by recasting the problem into an alternating Gaussian\ndenoising scheme. We leverage two diffusion models as learned priors: one to\ncapture the distribution of the target image and another to characterize the\nparameters of the measurement operator. This PnP integration of diffusion\nmodels ensures flexibility and ease of adaptation. Our experiments on blind\nimage deblurring show that Blind-PnPDM outperforms state-of-the-art methods in\nterms of both quantitative metrics and visual fidelity. Our results highlight\nthe effectiveness of treating blind inverse problems as a sequence of denoising\nsubproblems while harnessing the expressive power of diffusion-based priors.",
    "pdf_url": "http://arxiv.org/pdf/2505.22923v1",
    "published": "2025-05-28T22:53:07+00:00",
    "categories": [
      "eess.IV",
      "cs.CV"
    ],
    "primary_category": "eess.IV"
  },
  {
    "id": "http://arxiv.org/abs/2505.22922v1",
    "title": "Scalable Parameter and Memory Efficient Pretraining for LLM: Recent Algorithmic Advances and Benchmarking",
    "authors": [
      "Athanasios Glentis",
      "Jiaxiang Li",
      "Qiulin Shang",
      "Andi Han",
      "Ioannis Tsaknakis",
      "Quan Wei",
      "Mingyi Hong"
    ],
    "abstract": "Fueled by their remarkable ability to tackle diverse tasks across multiple\ndomains, large language models (LLMs) have grown at an unprecedented rate, with\nsome recent models containing trillions of parameters. This growth is\naccompanied by substantial computational challenges, particularly regarding the\nmemory and compute resources required for training and fine-tuning. Numerous\napproaches have been explored to address these issues, such as LoRA. While\nthese methods are effective for fine-tuning, their application to pre-training\nis significantly more challenging due to the need to learn vast datasets.\nMotivated by this issue, we aim to address the following questions: Can\nparameter- or memory-efficient methods enhance pre-training efficiency while\nachieving performance comparable to full-model training? How can the\nperformance gap be narrowed? To this end, the contributions of this work are\nthe following. (1) We begin by conducting a comprehensive survey that\nsummarizes state-of-the-art methods for efficient pre-training. (2) We perform\na benchmark evaluation of several representative memory efficient pre-training\napproaches to comprehensively evaluate their performance across model sizes. We\nobserve that with a proper choice of optimizer and hyperparameters, full-rank\ntraining delivers the best performance, as expected. We also notice that\nincorporating high-rank updates in low-rank approaches is the key to improving\ntheir performance. (3) Finally, we propose two practical techniques, namely\nweight refactorization and momentum reset, to enhance the performance of\nefficient pre-training methods. We observe that applying these techniques to\nthe low-rank method (on a 1B model) can achieve a lower perplexity than popular\nmemory efficient algorithms such as GaLore and Fira, while simultaneously using\nabout 25% less memory.",
    "pdf_url": "http://arxiv.org/pdf/2505.22922v1",
    "published": "2025-05-28T22:51:43+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.23850v2",
    "title": "Bubble-Burst Synthesis of Ammonia, Amino Acids, and Urea Under Ambient, Catalyst-Free Conditions",
    "authors": [
      "Jerome J. Cuomo",
      "Ian Goodall",
      "C. Richard Guarnieri",
      "Gennaro",
      "Cuomo",
      "Stephen Hudak"
    ],
    "abstract": "This study introduces a catalyst-free, ambient-temperature method for\nsynthesizing nitrogen-based compounds critical to fertilizer production,\nincluding ammonia, urea, ammonium salts, and amino acids. The process relies on\nbubble-burst-induced microenvironments, where gas bubbles undergo rapid growth\nand collapse, releasing intense localized energy sufficient to dissociate\nnitrogen and water molecules. These high-energy zones produce reactive species,\nincluding atomic hydrogen (H*) that facilitate nitrogen fixation and drive\nsubsequent chemical transformations without needing catalysts or elevated\nconditions. Experimental validation using colorimetric assays, Raman\nspectroscopy, and microscopy confirms the in situ formation of ammonia and its\ndownstream conversion into structurally relevant compounds, including\npeptide-like assemblies. The system supports reaction tuning through dissolved\ncarbon dioxide (CO2) or organic acids and can be enhanced by low-energy inputs\nsuch as UV or ultrasound. Its simplicity, modularity, and ability to operate\nwithout external infrastructure offer a practical and scalable platform for\ndecentralized fertilizer generation and sustainable biochemical production.",
    "pdf_url": "http://arxiv.org/pdf/2505.23850v2",
    "published": "2025-05-28T22:49:44+00:00",
    "categories": [
      "physics.chem-ph",
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "physics.chem-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.22921v1",
    "title": "Structured Memory Mechanisms for Stable Context Representation in Large Language Models",
    "authors": [
      "Yue Xing",
      "Tao Yang",
      "Yijiashun Qi",
      "Minggu Wei",
      "Yu Cheng",
      "Honghui Xin"
    ],
    "abstract": "This paper addresses the limitations of large language models in\nunderstanding long-term context. It proposes a model architecture equipped with\na long-term memory mechanism to improve the retention and retrieval of semantic\ninformation across paragraphs and dialogue turns. The model integrates explicit\nmemory units, gated writing mechanisms, and attention-based reading modules. A\nforgetting function is introduced to enable dynamic updates of memory content,\nenhancing the model's ability to manage historical information. To further\nimprove the effectiveness of memory operations, the study designs a joint\ntraining objective. This combines the main task loss with constraints on memory\nwriting and forgetting. It guides the model to learn better memory strategies\nduring task execution. Systematic evaluation across multiple subtasks shows\nthat the model achieves clear advantages in text generation consistency,\nstability in multi-turn question answering, and accuracy in cross-context\nreasoning. In particular, the model demonstrates strong semantic retention and\ncontextual coherence in long-text tasks and complex question answering\nscenarios. It effectively mitigates the context loss and semantic drift\nproblems commonly faced by traditional language models when handling long-term\ndependencies. The experiments also include analysis of different memory\nstructures, capacity sizes, and control strategies. These results further\nconfirm the critical role of memory mechanisms in language understanding. They\ndemonstrate the feasibility and effectiveness of the proposed approach in both\narchitectural design and performance outcomes.",
    "pdf_url": "http://arxiv.org/pdf/2505.22921v1",
    "published": "2025-05-28T22:49:04+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.22920v1",
    "title": "Monolithic framework to simulate fluid-structure interaction problems using geometric volume-of-fluid method",
    "authors": [
      "Soham Prajapati",
      "Ali Fakhreddine",
      "Krishnan Mahesh"
    ],
    "abstract": "We develop a three-dimensional Eulerian framework to simulate fluid-structure\ninteraction (FSI) problems on a fixed Cartesian grid using the geometric\nvolume-of-fluid (VOF) method. The coupled problem involves incompressible flow\nand viscous hyperelastic solids. A VOF-based one-continuum formulation is used\nto describe the unified momentum conservation equations with incompressibility\nconstraints that are solved using the finite volume method (FVM). In the\ngeometric VOF interface-capturing (IC) approach, the PLIC method is used to\nreconstruct the interface, and the Lagrangian Explicit (LE) method is used in\nthe directionally split advection procedure. To model the hyperelastic behavior\nof the solid, we consider Mooney-Rivlin material models, where we use the left\nCauchy-Green deformation tensor (B) to account for the solid deformation on an\nEulerian grid and the fifth-order WENO-Z reconstruction method is utilized to\ntreat the advection terms involved in the transport equation of B. Multiple\nbenchmark problems are considered to verify the accuracy of the approach.\nFurthermore, to demonstrate the capability of the solver to handle turbulent\ninteractions, we perform direct numerical simulation (DNS) of turbulent channel\nflow with a deformable compliant bottom wall and a rigid top wall; our\nobservations align well with previous experimental and numerical works. The\ndetailed numerical experiments show that: (i) Despite the discontinuity of the\ninterface across the cell boundaries and stress discontinuity across the\ninterface, a VOF/PLIC-based FSI framework can provide stable and accurate\nsolutions that significantly minimizes numerical artifacts (e.g., flotsam and\nspurious currents) while maintaining a sharp interface. (ii) The accuracy of a\nVOF/PLIC-based FSI approach on coarse grids is comparable to the accuracy of a\ndiffusive IC method-based FSI approach on much finer grids.",
    "pdf_url": "http://arxiv.org/pdf/2505.22920v1",
    "published": "2025-05-28T22:47:33+00:00",
    "categories": [
      "physics.flu-dyn",
      "physics.comp-ph"
    ],
    "primary_category": "physics.flu-dyn"
  },
  {
    "id": "http://arxiv.org/abs/2505.22919v2",
    "title": "ER-REASON: A Benchmark Dataset for LLM-Based Clinical Reasoning in the Emergency Room",
    "authors": [
      "Nikita Mehandru",
      "Niloufar Golchini",
      "David Bamman",
      "Travis Zack",
      "Melanie F. Molina",
      "Ahmed Alaa"
    ],
    "abstract": "Large language models (LLMs) have been extensively evaluated on medical\nquestion answering tasks based on licensing exams. However, real-world\nevaluations often depend on costly human annotators, and existing benchmarks\ntend to focus on isolated tasks that rarely capture the clinical reasoning or\nfull workflow underlying medical decisions. In this paper, we introduce\nER-Reason, a benchmark designed to evaluate LLM-based clinical reasoning and\ndecision-making in the emergency room (ER)--a high-stakes setting where\nclinicians make rapid, consequential decisions across diverse patient\npresentations and medical specialties under time pressure. ER-Reason includes\ndata from 3,984 patients, encompassing 25,174 de-identified longitudinal\nclinical notes spanning discharge summaries, progress notes, history and\nphysical exams, consults, echocardiography reports, imaging notes, and ER\nprovider documentation. The benchmark includes evaluation tasks that span key\nstages of the ER workflow: triage intake, initial assessment, treatment\nselection, disposition planning, and final diagnosis--each structured to\nreflect core clinical reasoning processes such as differential diagnosis via\nrule-out reasoning. We also collected 72 full physician-authored rationales\nexplaining reasoning processes that mimic the teaching process used in\nresidency training, and are typically absent from ER documentation. Evaluations\nof state-of-the-art LLMs on ER-Reason reveal a gap between LLM-generated and\nclinician-authored clinical reasoning for ER decisions, highlighting the need\nfor future research to bridge this divide.",
    "pdf_url": "http://arxiv.org/pdf/2505.22919v2",
    "published": "2025-05-28T22:43:44+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.22918v2",
    "title": "Re-ttention: Ultra Sparse Visual Generation via Attention Statistical Reshape",
    "authors": [
      "Ruichen Chen"
    ],
    "abstract": "Diffusion Transformers (DiT) have become the de-facto model for generating\nhigh-quality visual content like videos and images. A huge bottleneck is the\nattention mechanism where complexity scales quadratically with resolution and\nvideo length. One logical way to lessen this burden is sparse attention, where\nonly a subset of tokens or patches are included in the calculation. However,\nexisting techniques fail to preserve visual quality at extremely high sparsity\nlevels and might even incur non-negligible compute overheads. % To address this\nconcern, we propose Re-ttention, which implements very high sparse attention\nfor visual generation models by leveraging the temporal redundancy of Diffusion\nModels to overcome the probabilistic normalization shift within the attention\nmechanism. Specifically, Re-ttention reshapes attention scores based on the\nprior softmax distribution history in order to preserve the visual quality of\nthe full quadratic attention at very high sparsity levels. % Experimental\nresults on T2V/T2I models such as CogVideoX and the PixArt DiTs demonstrate\nthat Re-ttention requires as few as 3.1\\% of the tokens during inference,\noutperforming contemporary methods like FastDiTAttn, Sparse VideoGen and\nMInference. Further, we measure latency to show that our method can attain over\n45\\% end-to-end % and over 92\\% self-attention latency reduction on an H100 GPU\nat negligible overhead cost.\n  Code available online here:\n\\href{https://github.com/cccrrrccc/Re-ttention}{https://github.com/cccrrrccc/Re-ttention}",
    "pdf_url": "http://arxiv.org/pdf/2505.22918v2",
    "published": "2025-05-28T22:39:12+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.22916v1",
    "title": "On the Resolution of Stochastic MPECs over Networks: Distributed Implicit Zeroth-Order Gradient Tracking Methods",
    "authors": [
      "Mohammadjavad Ebrahimi",
      "Uday V. Shanbhag",
      "Farzad Yousefian"
    ],
    "abstract": "The mathematical program with equilibrium constraints (MPEC) is a powerful\nyet challenging class of constrained optimization problems, where the\nconstraints are characterized by a parametrized variational inequality (VI)\nproblem. While efficient algorithms for addressing MPECs and their stochastic\nvariants (SMPECs) have been recently presented, distributed SMPECs over\nnetworks pose significant challenges. This work aims to develop fully iterative\nmethods with complexity guarantees for resolving distributed SMPECs in two\nproblem settings: (1) distributed single-stage SMPECs and (2) distributed\ntwo-stage SMPECs. In both cases, the global objective function is distributed\namong a network of agents that communicate cooperatively. Under the assumption\nthat the parametrized VI is uniquely solvable, the resulting implicit problem\nin upper-level decisions is generally neither convex nor smooth. Under some\nstandard assumptions, including the uniqueness of the solution to the VI\nproblems and the Lipschitz continuity of the implicit global objective\nfunction, we propose single-stage and two-stage zeroth-order distributed\ngradient tracking optimization methods where the gradient of a smoothed\nimplicit objective function is approximated using two (possibly inexact)\nevaluations of the lower-level VI solutions. In the exact setting of both the\nsingle-stage and two-stage problems, we achieve the best-known complexity bound\nfor centralized nonsmooth nonconvex stochastic optimization. This complexity\nbound is also achieved (for the first time) for our method in addressing the\ninexact setting of the distributed two-stage SMPEC. In addressing the inexact\nsetting of the single-stage problem, we derive an overall complexity bound,\nimproving the dependence on the dimension compared to the existing results for\nthe centralized SMPECs.",
    "pdf_url": "http://arxiv.org/pdf/2505.22916v1",
    "published": "2025-05-28T22:37:27+00:00",
    "categories": [
      "math.OC"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2505.22915v1",
    "title": "Spontaneous vortex lattice due to orbital magnetization in valley polarized superconductors",
    "authors": [
      "Ammar Jahin",
      "Shi-Zeng Lin"
    ],
    "abstract": "In this work, we study the spontaneous formation of a vortex lattice in\ntwo-dimensional valley polarized superconductors due to orbital magnetization.\nThe screening of magnetic field is weak for two-dimension superconductors,\nallowing for the magnetic flux associated with vortices to penetrate deep into\nthe superconducting region. The Zeeman coupling between orbital magnetization\nand magnetic fields associated with vortices leads to the formation of a vortex\nlattice, once the vortex self-energy is lower than the Zeeman energy. We study\nthe phase diagram and the vortex lattice configuration, and discuss the\nconsequences of the vortex lattice formation in various experimental setups.",
    "pdf_url": "http://arxiv.org/pdf/2505.22915v1",
    "published": "2025-05-28T22:37:21+00:00",
    "categories": [
      "cond-mat.supr-con"
    ],
    "primary_category": "cond-mat.supr-con"
  },
  {
    "id": "http://arxiv.org/abs/2506.00053v1",
    "title": "Improving statistical learning methods via features selection without replacement sampling and random projection",
    "authors": [
      "Sulaiman khan",
      "Muhammad Ahmad",
      "Fida Ullah",
      "Carlos Aguilar Iba√±ez",
      "Jos√© Eduardo Valdez Rodriguez"
    ],
    "abstract": "Cancer is fundamentally a genetic disease characterized by genetic and\nepigenetic alterations that disrupt normal gene expression, leading to\nuncontrolled cell growth and metastasis. High-dimensional microarray datasets\npose challenges for classification models due to the \"small n, large p\"\nproblem, resulting in overfitting. This study makes three different key\ncontributions: 1) we propose a machine learning-based approach integrating the\nFeature Selection Without Re-placement (FSWOR) technique and a projection\nmethod to improve classification accuracy. 2) We apply the Kendall statistical\ntest to identify the most significant genes from the brain cancer mi-croarray\ndataset (GSE50161), reducing the feature space from 54,675 to 20,890 genes.3)\nwe apply machine learning models using k-fold cross validation techniques in\nwhich our model incorpo-rates ensemble classifiers with LDA projection and\nNa\\\"ive Bayes, achieving a test score of 96%, outperforming existing methods by\n9.09%. The results demonstrate the effectiveness of our ap-proach in\nhigh-dimensional gene expression analysis, improving classification accuracy\nwhile mitigating overfitting. This study contributes to cancer biomarker\ndiscovery, offering a robust computational method for analyzing microarray\ndata.",
    "pdf_url": "http://arxiv.org/pdf/2506.00053v1",
    "published": "2025-05-28T22:36:46+00:00",
    "categories": [
      "q-bio.QM",
      "cs.AI",
      "cs.LG",
      "stat.AP",
      "stat.ML"
    ],
    "primary_category": "q-bio.QM"
  },
  {
    "id": "http://arxiv.org/abs/2505.22914v1",
    "title": "cadrille: Multi-modal CAD Reconstruction with Online Reinforcement Learning",
    "authors": [
      "Maksim Kolodiazhnyi",
      "Denis Tarasov",
      "Dmitrii Zhemchuzhnikov",
      "Alexander Nikulin",
      "Ilya Zisman",
      "Anna Vorontsova",
      "Anton Konushin",
      "Vladislav Kurenkov",
      "Danila Rukhovich"
    ],
    "abstract": "Computer-Aided Design (CAD) plays a central role in engineering and\nmanufacturing, making it possible to create precise and editable 3D models.\nUsing a variety of sensor or user-provided data as inputs for CAD\nreconstruction can democratize access to design applications. However, existing\nmethods typically focus on a single input modality, such as point clouds,\nimages, or text, which limits their generalizability and robustness. Leveraging\nrecent advances in vision-language models (VLM), we propose a multi-modal CAD\nreconstruction model that simultaneously processes all three input modalities.\nInspired by large language model (LLM) training paradigms, we adopt a two-stage\npipeline: supervised fine-tuning (SFT) on large-scale procedurally generated\ndata, followed by reinforcement learning (RL) fine-tuning using online\nfeedback, obtained programatically. Furthermore, we are the first to explore RL\nfine-tuning of LLMs for CAD tasks demonstrating that online RL algorithms such\nas Group Relative Preference Optimization (GRPO) outperform offline\nalternatives. In the DeepCAD benchmark, our SFT model outperforms existing\nsingle-modal approaches in all three input modalities simultaneously. More\nimportantly, after RL fine-tuning, cadrille sets new state-of-the-art on three\nchallenging datasets, including a real-world one.",
    "pdf_url": "http://arxiv.org/pdf/2505.22914v1",
    "published": "2025-05-28T22:32:31+00:00",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.22913v1",
    "title": "Mustafar: Promoting Unstructured Sparsity for KV Cache Pruning in LLM Inference",
    "authors": [
      "Donghyeon Joo",
      "Helya Hosseini",
      "Ramyad Hadidi",
      "Bahar Asgari"
    ],
    "abstract": "We demonstrate that unstructured sparsity significantly improves KV cache\ncompression for LLMs, enabling sparsity levels up to 70% without compromising\naccuracy or requiring fine-tuning. We conduct a systematic exploration of\npruning strategies and find per-token magnitude-based pruning as highly\neffective for both Key and Value caches under unstructured sparsity, surpassing\nprior structured pruning schemes. The Key cache benefits from prominent outlier\nelements, while the Value cache surprisingly benefits from a simple\nmagnitude-based pruning despite its uniform distribution. KV cache size is the\nmajor bottleneck in decode performance due to high memory overhead for large\ncontext lengths. To address this, we use a bitmap-based sparse format and a\ncustom attention kernel capable of compressing and directly computing over\ncompressed caches pruned to arbitrary sparsity patterns, significantly\naccelerating memory-bound operations in decode computations and thereby\ncompensating for the overhead of runtime pruning and compression. Our custom\nattention kernel coupled with the bitmap-based format delivers substantial\ncompression of KV cache upto 45% of dense inference and thereby enables longer\ncontext length and increased tokens/sec throughput of upto 2.23x compared to\ndense inference. Our pruning mechanism and sparse attention kernel is available\nat https://github.com/dhjoo98/mustafar.",
    "pdf_url": "http://arxiv.org/pdf/2505.22913v1",
    "published": "2025-05-28T22:32:15+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.04243v1",
    "title": "Triple Attention Transformer Architecture for Time-Dependent Concrete Creep Prediction",
    "authors": [
      "Warayut Dokduea",
      "Weerachart Tangchirapat",
      "Sompote Youwai"
    ],
    "abstract": "This paper presents a novel Triple Attention Transformer Architecture for\npredicting time-dependent concrete creep, addressing fundamental limitations in\ncurrent approaches that treat time as merely an input parameter rather than\nmodeling the sequential nature of deformation development. By transforming\nconcrete creep prediction into an autoregressive sequence modeling task similar\nto language processing, our architecture leverages the transformer's\nself-attention mechanisms to capture long-range dependencies in historical\ncreep patterns. The model implements a triple-stream attention framework\nincorporating temporal attention for sequential progression, feature attention\nfor material property interactions, and batch attention for inter-sample\nrelationships. Evaluated on experimental datasets with standardized daily\nmeasurements spanning 160 days, the architecture achieves exceptional\nperformance with mean absolute percentage error of 1.63% and R2 values of 0.999\nacross all datasets, substantially outperforming traditional empirical models\nand existing machine learning approaches. Ablation studies confirm the critical\nrole of attention mechanisms, with attention pooling contributing most\nsignificantly to model performance. SHAP analysis reveals Young's modulus as\nthe primary predictive feature, followed by density and compressive strength,\nproviding interpretability essential for engineering applications. A deployed\nweb-based interface facilitates practical implementation, enabling real-time\npredictions using standard laboratory parameters. This work establishes the\nviability of applying transformer architectures to materials science problems,\ndemonstrating the potential for data-driven approaches to revolutionize\nstructural behavior prediction and engineering design practices.",
    "pdf_url": "http://arxiv.org/pdf/2506.04243v1",
    "published": "2025-05-28T22:30:35+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.15700v1",
    "title": "Contraction Actor-Critic: Contraction Metric-Guided Reinforcement Learning for Robust Path Tracking",
    "authors": [
      "Minjae Cho",
      "Hiroyasu Tsukamoto",
      "Huy Trong Tran"
    ],
    "abstract": "Control contraction metrics (CCMs) provide a framework to co-synthesize a\ncontroller and a corresponding contraction metric -- a positive-definite\nRiemannian metric under which a closed-loop system is guaranteed to be\nincrementally exponentially stable. However, the synthesized controller only\nensures that all the trajectories of the system converge to one single\ntrajectory and, as such, does not impose any notion of optimality across an\nentire trajectory. Furthermore, constructing CCMs requires a known dynamics\nmodel and non-trivial effort in solving an infinite-dimensional convex\nfeasibility problem, which limits its scalability to complex systems featuring\nhigh dimensionality with uncertainty. To address these issues, we propose to\nintegrate CCMs into reinforcement learning (RL), where CCMs provide\ndynamics-informed feedback for learning control policies that minimize\ncumulative tracking error under unknown dynamics. We show that our algorithm,\ncalled contraction actor-critic (CAC), formally enhances the capability of CCMs\nto provide a set of contracting policies with the long-term optimality of RL in\na fully automated setting. Given a pre-trained dynamics model, CAC\nsimultaneously learns a contraction metric generator (CMG) -- which generates a\ncontraction metric -- and uses an actor-critic algorithm to learn an optimal\ntracking policy guided by that metric. We demonstrate the effectiveness of our\nalgorithm relative to established baselines through extensive empirical\nstudies, including simulated and real-world robot experiments, and provide a\ntheoretical rationale for incorporating contraction theory into RL.",
    "pdf_url": "http://arxiv.org/pdf/2506.15700v1",
    "published": "2025-05-28T22:26:23+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.22912v1",
    "title": "The spectral energy distribution of extreme population A quasars",
    "authors": [
      "Karla Garnica",
      "Deborah Dultzin",
      "Paola Marziani",
      "Swayamtrupta Panda"
    ],
    "abstract": "Knowledge of the broad-band active galactic nuclei (AGN) spectral energy\ndistribution (SED) that ionizes the gas-rich broad emission line region is key\nto understanding the various radiative processes at play and their importance\nthat eventually leads to the emission line formation. We modeled a spectral\nenergy distribution for highly accreting quasars, also known as extreme\npopulation A sources, based mainly on observational data available in\nastronomical databases, and on accretion disk models for the unobservable\nfar-UV domain. Our selection criterion is the RFeII parameter - the ratio of\nthe optical FeII emission between 4434 A and 4684 A to the H-beta 4861 A\nintensity, RFeII > 1. This criterion is satisfied by highly-accreting, possibly\nsuper-Eddington, black holes. We analyzed 155 sources up to a redshift of\napproximately 1, previously reported in the literature, to construct a median\nradio-quiet SED spanning from radio to X-ray wavelengths. We find that the SED\nof quasars exhibits distinct features compared to lower accreting AGN,\nincluding a pronounced big blue bump and strong optical/UV emission along with\na steep X-ray continuum. We classify the sources into radio-quiet,\nradio-intermediate, and radio-loud categories, observing that\nradio-intermediate and a subsample of radio-quiet AGN show a significant far-IR\nexcess over the radio-quiet SED and the far-IR excess appears to be related to\nthe prominence of Feii emission. There is an overall consistency between the\nnew SED and the one obtained for high Eddington ratio quasars in previous work.\nWe provide the SEDs in digital format for eventual applications.",
    "pdf_url": "http://arxiv.org/pdf/2505.22912v1",
    "published": "2025-05-28T22:20:56+00:00",
    "categories": [
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2505.22911v2",
    "title": "Hierarchical Material Recognition from Local Appearance",
    "authors": [
      "Matthew Beveridge",
      "Shree K. Nayar"
    ],
    "abstract": "We introduce a taxonomy of materials for hierarchical recognition from local\nappearance. Our taxonomy is motivated by vision applications and is arranged\naccording to the physical traits of materials. We contribute a diverse,\nin-the-wild dataset with images and depth maps of the taxonomy classes.\nUtilizing the taxonomy and dataset, we present a method for hierarchical\nmaterial recognition based on graph attention networks. Our model leverages the\ntaxonomic proximity between classes and achieves state-of-the-art performance.\nWe demonstrate the model's potential to generalize to adverse, real-world\nimaging conditions, and that novel views rendered using the depth maps can\nenhance this capability. Finally, we show the model's capacity to rapidly learn\nnew materials in a few-shot learning setting.",
    "pdf_url": "http://arxiv.org/pdf/2505.22911v2",
    "published": "2025-05-28T22:20:50+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.22910v1",
    "title": "Talent or Luck? Evaluating Attribution Bias in Large Language Models",
    "authors": [
      "Chahat Raj",
      "Mahika Banerjee",
      "Aylin Caliskan",
      "Antonios Anastasopoulos",
      "Ziwei Zhu"
    ],
    "abstract": "When a student fails an exam, do we tend to blame their effort or the test's\ndifficulty? Attribution, defined as how reasons are assigned to event outcomes,\nshapes perceptions, reinforces stereotypes, and influences decisions.\nAttribution Theory in social psychology explains how humans assign\nresponsibility for events using implicit cognition, attributing causes to\ninternal (e.g., effort, ability) or external (e.g., task difficulty, luck)\nfactors. LLMs' attribution of event outcomes based on demographics carries\nimportant fairness implications. Most works exploring social biases in LLMs\nfocus on surface-level associations or isolated stereotypes. This work proposes\na cognitively grounded bias evaluation framework to identify how models'\nreasoning disparities channelize biases toward demographic groups.",
    "pdf_url": "http://arxiv.org/pdf/2505.22910v1",
    "published": "2025-05-28T22:18:46+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.22909v1",
    "title": "Learning to Charge More: A Theoretical Study of Collusion by Q-Learning Agents",
    "authors": [
      "Cristian Chica",
      "Yinglong Guo",
      "Gilad Lerman"
    ],
    "abstract": "There is growing experimental evidence that $Q$-learning agents may learn to\ncharge supracompetitive prices. We provide the first theoretical explanation\nfor this behavior in infinite repeated games. Firms update their pricing\npolicies based solely on observed profits, without computing equilibrium\nstrategies. We show that when the game admits both a one-stage Nash equilibrium\nprice and a collusive-enabling price, and when the $Q$-function satisfies\ncertain inequalities at the end of experimentation, firms learn to consistently\ncharge supracompetitive prices. We introduce a new class of one-memory subgame\nperfect equilibria (SPEs) and provide conditions under which learned behavior\nis supported by naive collusion, grim trigger policies, or increasing\nstrategies. Naive collusion does not constitute an SPE unless the\ncollusive-enabling price is a one-stage Nash equilibrium, whereas grim trigger\npolicies can.",
    "pdf_url": "http://arxiv.org/pdf/2505.22909v1",
    "published": "2025-05-28T22:18:35+00:00",
    "categories": [
      "econ.GN",
      "cs.AI",
      "cs.GT",
      "q-fin.EC"
    ],
    "primary_category": "econ.GN"
  },
  {
    "id": "http://arxiv.org/abs/2505.22908v1",
    "title": "3DGS Compression with Sparsity-guided Hierarchical Transform Coding",
    "authors": [
      "Hao Xu",
      "Xiaolin Wu",
      "Xi Zhang"
    ],
    "abstract": "3D Gaussian Splatting (3DGS) has gained popularity for its fast and\nhigh-quality rendering, but it has a very large memory footprint incurring high\ntransmission and storage overhead. Recently, some neural compression methods,\nsuch as Scaffold-GS, were proposed for 3DGS but they did not adopt the approach\nof end-to-end optimized analysis-synthesis transforms which has been proven\nhighly effective in neural signal compression. Without an appropriate analysis\ntransform, signal correlations cannot be removed by sparse representation.\nWithout such transforms the only way to remove signal redundancies is through\nentropy coding driven by a complex and expensive context modeling, which\nresults in slower speed and suboptimal rate-distortion (R-D) performance. To\novercome this weakness, we propose Sparsity-guided Hierarchical Transform\nCoding (SHTC), the first end-to-end optimized transform coding framework for\n3DGS compression. SHTC jointly optimizes the 3DGS, transforms and a lightweight\ncontext model. This joint optimization enables the transform to produce\nrepresentations that approach the best R-D performance possible. The SHTC\nframework consists of a base layer using KLT for data decorrelation, and a\nsparsity-coded enhancement layer that compresses the KLT residuals to refine\nthe representation. The enhancement encoder learns a linear transform to\nproject high-dimensional inputs into a low-dimensional space, while the decoder\nunfolds the Iterative Shrinkage-Thresholding Algorithm (ISTA) to reconstruct\nthe residuals. All components are designed to be interpretable, allowing the\nincorporation of signal priors and fewer parameters than black-box transforms.\nThis novel design significantly improves R-D performance with minimal\nadditional parameters and computational overhead.",
    "pdf_url": "http://arxiv.org/pdf/2505.22908v1",
    "published": "2025-05-28T22:17:24+00:00",
    "categories": [
      "cs.CV",
      "eess.IV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.22907v1",
    "title": "Conversational Alignment with Artificial Intelligence in Context",
    "authors": [
      "Rachel Katharine Sterken",
      "James Ravi Kirkpatrick"
    ],
    "abstract": "The development of sophisticated artificial intelligence (AI) conversational\nagents based on large language models raises important questions about the\nrelationship between human norms, values, and practices and AI design and\nperformance. This article explores what it means for AI agents to be\nconversationally aligned to human communicative norms and practices for\nhandling context and common ground and proposes a new framework for evaluating\ndevelopers' design choices. We begin by drawing on the philosophical and\nlinguistic literature on conversational pragmatics to motivate a set of\ndesiderata, which we call the CONTEXT-ALIGN framework, for conversational\nalignment with human communicative practices. We then suggest that current\nlarge language model (LLM) architectures, constraints, and affordances may\nimpose fundamental limitations on achieving full conversational alignment.",
    "pdf_url": "http://arxiv.org/pdf/2505.22907v1",
    "published": "2025-05-28T22:14:34+00:00",
    "categories": [
      "cs.CY",
      "cs.CL"
    ],
    "primary_category": "cs.CY"
  },
  {
    "id": "http://arxiv.org/abs/2505.22906v2",
    "title": "HiLDe: Intentional Code Generation via Human-in-the-Loop Decoding",
    "authors": [
      "Emmanuel Anaya Gonz√°lez",
      "Raven Rothkopf",
      "Sorin Lerner",
      "Nadia Polikarpova"
    ],
    "abstract": "While AI programming tools hold the promise of increasing programmers'\ncapabilities and productivity to a remarkable degree, they often exclude users\nfrom essential decision-making processes, causing many to effectively \"turn off\ntheir brains\" and over-rely on solutions provided by these systems. These\nbehaviors can have severe consequences in critical domains, like software\nsecurity. We propose Human-in-the-loop Decoding, a novel interaction technique\nthat allows users to observe and directly influence LLM decisions during code\ngeneration, in order to align the model's output with their personal\nrequirements. We implement this technique in HiLDe, a code completion assistant\nthat highlights critical decisions made by the LLM and provides local\nalternatives for the user to explore. In a within-subjects study (N=18) on\nsecurity-related tasks, we found that HiLDe led participants to generate\nsignificantly fewer vulnerabilities and better align code generation with their\ngoals compared to a traditional code completion assistant.",
    "pdf_url": "http://arxiv.org/pdf/2505.22906v2",
    "published": "2025-05-28T22:11:17+00:00",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.PL"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2505.22905v1",
    "title": "Profiling and optimization of multi-card GPU machine learning jobs",
    "authors": [
      "Marcin Lawenda",
      "Kyrylo Khloponin",
      "Krzesimir Samborski",
      "≈Åukasz Szustak"
    ],
    "abstract": "The effectiveness and efficiency of machine learning methodologies are\ncrucial, especially with respect to the quality of results and computational\ncost. This paper discusses different model optimization techniques, providing a\ncomprehensive analysis of key performance indicators. Several parallelization\nstrategies for image recognition, adapted to different hardware and software\nconfigurations, including distributed data parallelism and distributed hardware\nprocessing, are analyzed. Selected optimization strategies are studied in\ndetail, highlighting the related challenges and advantages of their\nimplementation. Furthermore, the impact of different performance improvement\ntechniques (DPO, LoRA, QLoRA, and QAT) on the tuning process of large language\nmodels is investigated. Experimental results illustrate how the nature of the\ntask affects the iteration time in a multiprocessor environment, VRAM\nutilization, and overall memory transfers. Test scenarios are evaluated on the\nmodern NVIDIA H100 GPU architecture.",
    "pdf_url": "http://arxiv.org/pdf/2505.22905v1",
    "published": "2025-05-28T22:11:05+00:00",
    "categories": [
      "cs.DC",
      "cs.PF"
    ],
    "primary_category": "cs.DC"
  },
  {
    "id": "http://arxiv.org/abs/2505.22904v2",
    "title": "Defining Foundation Models for Computational Science: A Call for Clarity and Rigor",
    "authors": [
      "Youngsoo Choi",
      "Siu Wun Cheung",
      "Youngkyu Kim",
      "Ping-Hsuan Tsai",
      "Alejandro N. Diaz",
      "Ivan Zanardi",
      "Seung Whan Chung",
      "Dylan Matthew Copeland",
      "Coleman Kendrick",
      "William Anderson",
      "Traian Iliescu",
      "Matthias Heinkenschloss"
    ],
    "abstract": "The widespread success of foundation models in natural language processing\nand computer vision has inspired researchers to extend the concept to\nscientific machine learning and computational science. However, this position\npaper argues that as the term \"foundation model\" is an evolving concept, its\napplication in computational science is increasingly used without a universally\naccepted definition, potentially creating confusion and diluting its precise\nscientific meaning. In this paper, we address this gap by proposing a formal\ndefinition of foundation models in computational science, grounded in the core\nvalues of generality, reusability, and scalability. We articulate a set of\nessential and desirable characteristics that such models must exhibit, drawing\nparallels with traditional foundational methods, like the finite element and\nfinite volume methods. Furthermore, we introduce the Data-Driven Finite Element\nMethod (DD-FEM), a framework that fuses the modular structure of classical FEM\nwith the representational power of data-driven learning. We demonstrate how\nDD-FEM addresses many of the key challenges in realizing foundation models for\ncomputational science, including scalability, adaptability, and physics\nconsistency. By bridging traditional numerical methods with modern AI\nparadigms, this work provides a rigorous foundation for evaluating and\ndeveloping novel approaches toward future foundation models in computational\nscience.",
    "pdf_url": "http://arxiv.org/pdf/2505.22904v2",
    "published": "2025-05-28T22:10:16+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NA",
      "math.NA"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.22903v2",
    "title": "Non-uniqueness of stationary measures for stochastic systems with almost surely invariant manifolds",
    "authors": [
      "Jacob Bedrossian",
      "Alex Blumenthal",
      "Sam Punshon-Smith"
    ],
    "abstract": "We develop a general framework for establishing non-uniqueness of stationary\nmeasures for stochastically forced dynamical systems possessing an almost\nsurely invariant submanifold. Our main abstract result provides sufficient\nconditions for the existence of multiple stationary measures on compact\nmanifolds, though the underlying methodology extends to non-compact settings.\nThe key insight is to construct additional stationary measures by exploiting\nthe linear instability of the invariant submanifold, as quantified by a\npositive transverse Lyapunov exponent.\n  To demonstrate the practical applicability of our framework, we apply it to\nthe Lorenz 96 model with degenerate stochastic forcing, which serves as an\nexample of both non-compact and high-dimensional dynamics. We prove that as the\ndamping parameter becomes sufficiently small, the unique stationary measure\nbifurcates, giving rise to exactly two distinct stationary measures. The proof\ncombines our general theory with computer-assisted verification of certain Lie\nalgebra generation properties that ensure the required hypoellipticity and\nirreducibility conditions.",
    "pdf_url": "http://arxiv.org/pdf/2505.22903v2",
    "published": "2025-05-28T22:09:54+00:00",
    "categories": [
      "math.DS",
      "math.PR",
      "37H15, 60H10 (Primary) 37D25, 35R60, 37A50 (Secondary)"
    ],
    "primary_category": "math.DS"
  },
  {
    "id": "http://arxiv.org/abs/2506.15699v1",
    "title": "BLUR: A Benchmark for LLM Unlearning Robust to Forget-Retain Overlap",
    "authors": [
      "Shengyuan Hu",
      "Neil Kale",
      "Pratiksha Thaker",
      "Yiwei Fu",
      "Steven Wu",
      "Virginia Smith"
    ],
    "abstract": "Machine unlearning has the potential to improve the safety of large language\nmodels (LLMs) by removing sensitive or harmful information post hoc. A key\nchallenge in unlearning involves balancing between forget quality (effectively\nunlearning undesirable information) and retain quality (maintaining good\nperformance on other, general tasks). Unfortunately, as we show, current LLM\nunlearning benchmarks contain highly disparate forget and retain sets --\npainting a false picture of the effectiveness of LLM unlearning methods. This\ncan be particularly problematic because it opens the door for benign\nperturbations, such as relearning attacks, to easily reveal supposedly\nunlearned knowledge once models are deployed. To address this, we present\n$\\texttt{BLUR}$: a benchmark for LLM unlearning that provides more realistic\nscenarios of forget-retain overlap. $\\texttt{BLUR}$ significantly expands on\nexisting unlearning benchmarks by providing extended evaluation tasks, combined\nforget/retain queries, and relearning datasets of varying degrees of\ndifficulty. Despite the benign nature of the queries considered, we find that\nthe performance of existing methods drops significantly when evaluated on\n$\\texttt{BLUR}$, with simple approaches performing better on average than more\nrecent methods. These results highlight the importance of robust evaluation and\nsuggest several important directions of future study. Our benchmark is publicly\navailable at: https://huggingface.co/datasets/forgelab/BLUR",
    "pdf_url": "http://arxiv.org/pdf/2506.15699v1",
    "published": "2025-05-28T22:09:04+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.22902v1",
    "title": "Markovian heat engine boosted by quantum coherence",
    "authors": [
      "Freddier Cuenca-Montenegro",
      "Marcela Herrera",
      "John H. Reina"
    ],
    "abstract": "We evaluate the role of quantum coherence as a thermodynamic resource in a\nnoisy, Markovian one-qubit heat engine. We demonstrate that, when operating\naccording to a quantum Otto cycle, can surpass the classical efficiency limit\nby consuming the coherence of noisy quantum states. Computed Leggett-Garg\ntemporal correlations imply the engine's non-classical nature. Amplitude\ndamping significantly reduces efficiency and extractable work. In contrast,\nphase damping has no significant impact on the extractable work. We implement\nthe entire Otto cycle in a quantum circuit, simulating realistic amplitude and\nphase damping channels, as well as gate-level noise. We introduce an\noperational measure of the circuit's thermodynamic cost, establishing a direct\nlink between energy consumption and information processing in quantum heat\nengines.",
    "pdf_url": "http://arxiv.org/pdf/2505.22902v1",
    "published": "2025-05-28T22:07:56+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.22901v2",
    "title": "1-D Schr√∂dinger operator on a star graph with nondefinite weight function",
    "authors": [
      "Edison Leguizam√≥n",
      "Carsten Trunk",
      "Mitsuru Wilson",
      "Monika Winklmeier"
    ],
    "abstract": "On a star graph $G$ with $n = n_+ + n_-$ edges of unit length, we study the\noperator $-\\frac{\\mathrm{d}^2}{\\mathrm{d} x^2}$ on $n_+$ and\n$\\frac{\\mathrm{d}^2}{\\mathrm{d} x^2}$ on $n_-$ edges equipped with Dirichlet\nboundary conditions at the outer vertices and a Kirchhoff condition at the\ncentral vertex. We study the spectral properties of the corresponding\nindefinite Kirchhoff Laplacian on $G$ and we show that it is similar to a\nselfadjoint operator in the Hilbert space $L^2(G)$ and that its eigenfunctions\nform a Riesz basis. Furthermore, we give a complete description of the point\nspectrum.",
    "pdf_url": "http://arxiv.org/pdf/2505.22901v2",
    "published": "2025-05-28T22:05:00+00:00",
    "categories": [
      "math.SP",
      "47A10, 47A75, 34B45"
    ],
    "primary_category": "math.SP"
  },
  {
    "id": "http://arxiv.org/abs/2505.22900v1",
    "title": "A Closer Look at Chapoton's q-Ehrhart Polynomials",
    "authors": [
      "Matthias Beck",
      "Thomas Kunze"
    ],
    "abstract": "If $\\mathcal{P}$ is a lattice polytope (i.e., $\\mathcal{P}$ is the convex\nhull of finitely many integer points in $\\mathbb{R}^d$), Ehrhart's famous\ntheorem (1962) asserts that the integer-point counting function $|t \\mathcal{P}\n\\cap \\mathbb{Z}^d|$ is a polynomial in the integer variable $t$. Chapoton\n(2016) proved that, given a fixed integral form $\\lambda: \\mathbb{Z}^d \\to\n\\mathbb{Z}$, there exists a polynomial $\\text{cha}_\\mathcal{P}^\\lambda(q,x) \\in\n\\mathbb{Q}(q)[x]$ such that the refined enumeration function $\\sum_{ \\mathbf{m}\n\\in t \\mathcal{P} } q^{ \\lambda(\\mathbf{m}) }$ equals the evaluation\n$\\text{cha}_\\mathcal{P}^\\lambda (q, [t]_q)$ where, as usual, $[t]_q := \\frac{\nq^t - 1 }{ q-1 }$; naturally, for $q=1$ we recover the Ehrhart polynomial. Our\nmotivating goal is to view Chapoton's work through the lens of Brion's Theorem\n(1988), which expresses the integer-point structure of a given polytope via\nthat of its vertex cones. It turns out that this viewpoint naturally yields\nvarious refinements and extensions of Chapoton's results, including explicit\nformulas for $\\text{cha}_\\mathcal{P}^\\lambda(q,x)$, its leading coefficient,\nand its behavior as $t \\to \\infty$. We also prove an analogue of Chapoton's\nstructural and reciprocity theorems for rational polytopes (i.e., with vertices\nin $\\mathbb{Q}^d$).",
    "pdf_url": "http://arxiv.org/pdf/2505.22900v1",
    "published": "2025-05-28T22:04:32+00:00",
    "categories": [
      "math.CO",
      "52B20 (Primary) 05A15 (Secondary)"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.22899v1",
    "title": "On the Dynamic Regret of Following the Regularized Leader: Optimism with History Pruning",
    "authors": [
      "Naram Mhaisen",
      "George Iosifidis"
    ],
    "abstract": "We revisit the Follow the Regularized Leader (FTRL) framework for Online\nConvex Optimization (OCO) over compact sets, focusing on achieving dynamic\nregret guarantees. Prior work has highlighted the framework's limitations in\ndynamic environments due to its tendency to produce \"lazy\" iterates. However,\nbuilding on insights showing FTRL's ability to produce \"agile\" iterates, we\nshow that it can indeed recover known dynamic regret bounds through optimistic\ncomposition of future costs and careful linearization of past costs, which can\nlead to pruning some of them. This new analysis of FTRL against dynamic\ncomparators yields a principled way to interpolate between greedy and agile\nupdates and offers several benefits, including refined control over regret\nterms, optimism without cyclic dependence, and the application of minimal\nrecursive regularization akin to AdaFTRL. More broadly, we show that it is not\nthe lazy projection style of FTRL that hinders (optimistic) dynamic regret, but\nthe decoupling of the algorithm's state (linearized history) from its iterates,\nallowing the state to grow arbitrarily. Instead, pruning synchronizes these two\nwhen necessary.",
    "pdf_url": "http://arxiv.org/pdf/2505.22899v1",
    "published": "2025-05-28T22:03:15+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.22898v1",
    "title": "Spring-Brake! Handed Shearing Auxetics Improve Efficiency of Hopping and Standing",
    "authors": [
      "Joseph Sullivan",
      "Ian Good",
      "Samuel A. Burden",
      "Jeffrey Ian Lipton"
    ],
    "abstract": "Energy efficiency is critical to the success of legged robotics. Efficiency\nis lost through wasted energy during locomotion and standing. Including elastic\nelements has been shown to reduce movement costs, while including breaks can\nreduce standing costs. However, adding separate elements for each increases the\nmass and complexity of a leg, reducing overall system performance. Here we\npresent a novel compliant mechanism using a Handed Shearing Auxetic (HSA) that\nacts as a spring and break in a monopod hopping robot. The HSA acts as a\nparallel elastic actuator, reducing electrical power for dynamic hopping and\nmatching the efficiency of state-of-the-art compliant hoppers. The HSA\\u2019s\nauxetic behavior enables dual functionality. During static tasks, it locks\nunder large forces with minimal input power by blocking deformation, creating\nhigh friction similar to a capstan mechanism. This allows the leg to support\nheavy loads without motor torque, addressing thermal inefficiency. The\nmulti-functional design enhances both dynamic and static performance, offering\na versatile solution for robotic applications.",
    "pdf_url": "http://arxiv.org/pdf/2505.22898v1",
    "published": "2025-05-28T22:01:45+00:00",
    "categories": [
      "cs.RO",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.22897v1",
    "title": "VIGNETTE: Socially Grounded Bias Evaluation for Vision-Language Models",
    "authors": [
      "Chahat Raj",
      "Bowen Wei",
      "Aylin Caliskan",
      "Antonios Anastasopoulos",
      "Ziwei Zhu"
    ],
    "abstract": "While bias in large language models (LLMs) is well-studied, similar concerns\nin vision-language models (VLMs) have received comparatively less attention.\nExisting VLM bias studies often focus on portrait-style images and\ngender-occupation associations, overlooking broader and more complex social\nstereotypes and their implied harm. This work introduces VIGNETTE, a\nlarge-scale VQA benchmark with 30M+ images for evaluating bias in VLMs through\na question-answering framework spanning four directions: factuality,\nperception, stereotyping, and decision making. Beyond narrowly-centered\nstudies, we assess how VLMs interpret identities in contextualized settings,\nrevealing how models make trait and capability assumptions and exhibit patterns\nof discrimination. Drawing from social psychology, we examine how VLMs connect\nvisual identity cues to trait and role-based inferences, encoding social\nhierarchies, through biased selections. Our findings uncover subtle,\nmultifaceted, and surprising stereotypical patterns, offering insights into how\nVLMs construct social meaning from inputs.",
    "pdf_url": "http://arxiv.org/pdf/2505.22897v1",
    "published": "2025-05-28T22:00:30+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.22896v1",
    "title": "Exploring Integration by Differentiation",
    "authors": [
      "R. D. George",
      "C. Vignat"
    ],
    "abstract": "This work validates and extends the method of integration by differentiation,\ninitially introduced by A. Kempf et al., and demonstrates its compatibility\nwith classical rules of integration. It provides applications to classical\nintegrals, including one by Ramanujan, and extends the method to the\nmultivariate setting. Volumes of simplexes are computed by acting with\nindicator functions on elementary kernels, and a rotationally invariant\nformulation is derived. Finally, the method is extended to Jackson's\nq-integral.",
    "pdf_url": "http://arxiv.org/pdf/2505.22896v1",
    "published": "2025-05-28T22:00:11+00:00",
    "categories": [
      "math.CA",
      "26A42, 33F10, 33B15, 44A10, 26B15"
    ],
    "primary_category": "math.CA"
  },
  {
    "id": "http://arxiv.org/abs/2505.22895v2",
    "title": "Electronic structure calculation for superheavy elements Livermorium (Lv, Z=116) and Tennessine (Ts, Z=117) and their lighter analogs Te, I, Po, and At",
    "authors": [
      "V. A. Dzuba",
      "V. V. Flambaum",
      "G. K. Vong"
    ],
    "abstract": "Advanced theoretical techniques that combine the linearized coupled-cluster\nmethod, configuration interaction method, and perturbation theory are used to\ncalculate energy levels, ionization potentials, electron affinities, field\nisotope shift, and static dipole polarizabilities of the superheavy elements Lv\nand Ts, along with their lighter analogs Te, I, Po, and At. Calculations for\nthe heavy elements, Po, At, Lv, and Ts are used to address the gaps in the\nexperimental data. Calculations for the lighter elements, Te and I (and partly\nPo and At) are used to demonstrate the accuracy of the calculations.",
    "pdf_url": "http://arxiv.org/pdf/2505.22895v2",
    "published": "2025-05-28T21:56:55+00:00",
    "categories": [
      "physics.atom-ph"
    ],
    "primary_category": "physics.atom-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.22894v1",
    "title": "Monotone Bounded-Depth Complexity of Homomorphism Polynomials",
    "authors": [
      "C. S. Bhargav",
      "Shiteng Chen",
      "Radu Curticapean",
      "Prateek Dwivedi"
    ],
    "abstract": "For every fixed graph $H$, it is known that homomorphism counts from $H$ and\ncolorful $H$-subgraph counts can be determined in $O(n^{t+1})$ time on\n$n$-vertex input graphs $G$, where $t$ is the treewidth of $H$. On the other\nhand, a running time of $n^{o(t / \\log t)}$ would refute the exponential-time\nhypothesis. Komarath, Pandey and Rahul (Algorithmica, 2023) studied algebraic\nvariants of these counting problems, i.e., homomorphism and subgraph\n$\\textit{polynomials}$ for fixed graphs $H$. These polynomials are weighted\nsums over the objects counted above, where each object is weighted by the\nproduct of variables corresponding to edges contained in the object. As shown\nby Komarath et al., the $\\textit{monotone}$ circuit complexity of the\nhomomorphism polynomial for $H$ is $\\Theta(n^{\\mathrm{tw}(H)+1})$.\n  In this paper, we characterize the power of monotone $\\textit{bounded-depth}$\ncircuits for homomorphism and colorful subgraph polynomials. This leads us to\ndiscover a natural hierarchy of graph parameters $\\mathrm{tw}_\\Delta(H)$, for\nfixed $\\Delta \\in \\mathbb N$, which capture the width of tree-decompositions\nfor $H$ when the underlying tree is required to have depth at most $\\Delta$. We\nprove that monotone circuits of product-depth $\\Delta$ computing the\nhomomorphism polynomial for $H$ require size\n$\\Theta(n^{\\mathrm{tw}_\\Delta(H^{\\dagger})+1})$, where $H^{\\dagger}$ is the\ngraph obtained from $H$ by removing all degree-$1$ vertices. This allows us to\nderive an optimal depth hierarchy theorem for monotone bounded-depth circuits\nthrough graph-theoretic arguments.",
    "pdf_url": "http://arxiv.org/pdf/2505.22894v1",
    "published": "2025-05-28T21:56:54+00:00",
    "categories": [
      "cs.CC",
      "cs.DM"
    ],
    "primary_category": "cs.CC"
  },
  {
    "id": "http://arxiv.org/abs/2505.22893v2",
    "title": "The global communication pathways of the human brain transcend the cortical-subcortical-cerebellar division",
    "authors": [
      "Julian Schulte",
      "Mario Senden",
      "Gustavo Deco",
      "Xenia Kobeleva",
      "Gorka Zamora-L√≥pez"
    ],
    "abstract": "Understanding how cortex, subcortex and cerebellum integrate is a major\nchallenge for neuroscience, however, studies of the brain's structural\nconnectivity have mostly focused on cortico-cortical links. Here, we used\ndiffusion imaging to construct the structural connectome of the entire human\nbrain including 360 cortical, 233 subcortical, and 125 cerebellar regions of\ninterest (ROIs). We found that the brain forms a modular and hierarchical\nnetwork architecture, organized into modules of mixed cortical, subcortical\nand/or cerebellar regions, and whose cross-modular pathways are centralized\nthrough highly connected hub ROIs (a `rich-club'). This global rich-club is\nsubcortically dominated and, surprisingly, composed of hub ROIs from all\nsubcortical structures rather than one region like the thalamus, centralizing\nthe communication pathways. This study improves our understanding of the human\nbrain's organization. It provides structural evidence to question the prevalent\ncortico-centric notion by revealing a connectome centered at the subcortex but\nmade of transversal pathways.",
    "pdf_url": "http://arxiv.org/pdf/2505.22893v2",
    "published": "2025-05-28T21:52:05+00:00",
    "categories": [
      "q-bio.NC"
    ],
    "primary_category": "q-bio.NC"
  },
  {
    "id": "http://arxiv.org/abs/2505.22892v1",
    "title": "Signatures of Correlation of Spacetime Fluctuations in Laser Interferometers",
    "authors": [
      "B. Sharmila",
      "Sander M. Vermeulen",
      "Animesh Datta"
    ],
    "abstract": "Spacetime fluctuations (SFs), a common feature of different proposed gravity\nmodels, could be detected using laser interferometers. In the search for SFs, a\ncorrespondence between the expected output signals and different gravity models\nis needed, both for guiding the design of future interferometers, and for\nidentifying the signal in experimental data. In this work, we provide such a\ncorrespondence for some classes of SFs and geometries of the interferometers.\nWe consider three different classes of SFs, characterised by the decay\nbehaviours and symmetries of their two-point correlation functions. Our\napproach applies to Michelson laser interferometers with Fabry-P\\'erot arm\ncavities such as the km-long LIGO detectors and those without arm cavities such\nas the laboratory-scale setups QUEST and GQuEST. Analysing the expected\ninterferometer output signals, we identify three characteristic signatures for\neach class of SF. The designed broadband sensitivity of the laboratory-scale\ninstruments would allow all characteristic signatures of the different classes\nof SFs to be observed, and such observations could provide more information on\nthe nature of the SFs than those from LIGO. On the other hand, we find that\nLIGO is better suited for detecting the bare presence or absence of SFs.",
    "pdf_url": "http://arxiv.org/pdf/2505.22892v1",
    "published": "2025-05-28T21:52:02+00:00",
    "categories": [
      "gr-qc",
      "physics.ins-det",
      "physics.optics",
      "quant-ph"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2505.22891v1",
    "title": "Electron-positron pair annihilation in kinetic plasma",
    "authors": [
      "Haidar Al-Naseri"
    ],
    "abstract": "The process of electron positron pair annihilation, driven by strong fields\n(Inverse Schwinger mechanism) and high-frequency waves, is studied using the\nDirac Heisenberg Wigner formalism. In an electron positron plasma, the presence\nof a strong field leads to both pair creation and annihilation. Depending on\nplasma properties such as non-degeneracy and the momentum distribution, pair\nannihilation can dominate over pair creation. The energy released from\nannihilated pairs can lead to an enhancement of the field energy, provided that\nthe plasma effectively blocks the creation of new pairs. Additionally, pair\nannihilation induced by high-frequency waves is shown to occur when the photon\nenergy matches the energy of the pairs in the plasma.",
    "pdf_url": "http://arxiv.org/pdf/2505.22891v1",
    "published": "2025-05-28T21:48:32+00:00",
    "categories": [
      "physics.plasm-ph",
      "hep-ph",
      "hep-th"
    ],
    "primary_category": "physics.plasm-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.22890v1",
    "title": "Physics-Infused Reduced-Order Modeling for Analysis of Multi-Layered Hypersonic Thermal Protection Systems",
    "authors": [
      "Carlos A. Vargas Venegas",
      "Daning Huang",
      "Patrick Blonigan",
      "JohnTencer"
    ],
    "abstract": "This work presents a physics-infused reduced-order modeling (PIROM) framework\nfor efficient and accurate prediction of transient thermal behavior in\nmulti-layered hypersonic thermal protection systems (TPS). The PIROM\narchitecture integrates a reduced-physics backbone, based on the\nlumped-capacitance model (LCM), with data-driven correction dynamics formulated\nvia a coarse-graining approach rooted in the Mori-Zwanzig formalism. While the\nLCM captures the dominant heat transfer mechanisms, the correction terms\ncompensate for residual dynamics arising from higher-order non-linear\ninteractions and heterogeneities across material layers. The proposed PIROM is\nbenchmarked against two non-intrusive reduced-order models (ROMs): Operator\nInference (OpInf) and Neural Ordinary Differential Equations (NODE). The PIROM\nconsistently achieves errors below 1% for a wide range of extrapolative\nsettings involving time- and space-dependent boundary conditions and\ntemperature-varying material property perturbations. In contrast, OpInf\nexhibits moderate degradation, and NODE suffers substantial loss in accuracy\ndue to its lack of embedded physics. Despite higher training costs, PIROM\ndelivers online evaluations of two orders of magnitude faster than the\nfull-order model. These results demonstrate that PIROM effectively reconciles\nthe trade-offs between accuracy, generalizability, and efficiency, providing a\nrobust framework for thermal modeling of TPS under diverse operating\nconditions.",
    "pdf_url": "http://arxiv.org/pdf/2505.22890v1",
    "published": "2025-05-28T21:46:19+00:00",
    "categories": [
      "physics.comp-ph",
      "cs.NA",
      "math.NA"
    ],
    "primary_category": "physics.comp-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.22889v1",
    "title": "Local Stability and Region of Attraction Analysis for Neural Network Feedback Systems under Positivity Constraints",
    "authors": [
      "Hamidreza Montazeri Hedesh",
      "Moh Kamalul Wafi",
      "Milad Siami"
    ],
    "abstract": "We study the local stability of nonlinear systems in the Lur'e form with\nstatic nonlinear feedback realized by feedforward neural networks (FFNNs). By\nleveraging positivity system constraints, we employ a localized variant of the\nAizerman conjecture, which provides sufficient conditions for exponential\nstability of trajectories confined to a compact set. Using this foundation, we\ndevelop two distinct methods for estimating the Region of Attraction (ROA): (i)\na less conservative Lyapunov-based approach that constructs invariant sublevel\nsets of a quadratic function satisfying a linear matrix inequality (LMI), and\n(ii) a novel technique for computing tight local sector bounds for FFNNs via\nlayer-wise propagation of linear relaxations. These bounds are integrated into\nthe localized Aizerman framework to certify local exponential stability.\nNumerical results demonstrate substantial improvements over existing integral\nquadratic constraint-based approaches in both ROA size and scalability.",
    "pdf_url": "http://arxiv.org/pdf/2505.22889v1",
    "published": "2025-05-28T21:45:49+00:00",
    "categories": [
      "eess.SY",
      "cs.AI",
      "cs.SY",
      "93D09, 93D20, 93C10, 68T07",
      "B.1.3; G.1; I.2; I.2.3; I.2.8; I.2.1; J.2"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2505.22888v1",
    "title": "When Models Reason in Your Language: Controlling Thinking Trace Language Comes at the Cost of Accuracy",
    "authors": [
      "Jirui Qi",
      "Shan Chen",
      "Zidi Xiong",
      "Raquel Fern√°ndez",
      "Danielle S. Bitterman",
      "Arianna Bisazza"
    ],
    "abstract": "Recent Large Reasoning Models (LRMs) with thinking traces have shown strong\nperformance on English reasoning tasks. However, their ability to think in\nother languages is less studied. This capability is as important as answer\naccuracy for real world applications because users may find the reasoning trace\nuseful for oversight only when it is expressed in their own language. We\ncomprehensively evaluate two leading families of LRMs on our XReasoning\nbenchmark and find that even the most advanced models often revert to English\nor produce fragmented reasoning in other languages, revealing a substantial gap\nin multilingual reasoning. Prompt based interventions that force models to\nreason in the users language improve readability and oversight but reduce\nanswer accuracy, exposing an important trade off. We further show that targeted\npost training on just 100 examples mitigates this mismatch, though some\naccuracy loss remains. Our results highlight the limited multilingual reasoning\ncapabilities of current LRMs and outline directions for future work. Code and\ndata are available at https://github.com/Betswish/mCoT-XReasoning.",
    "pdf_url": "http://arxiv.org/pdf/2505.22888v1",
    "published": "2025-05-28T21:44:12+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.22887v1",
    "title": "Understanding and Embracing Imperfection in Physical Learning Networks",
    "authors": [
      "Sam Dillavou",
      "Marcelo Guzman",
      "Andrea J. Liu",
      "Douglas J. Durian"
    ],
    "abstract": "Performing machine learning (ML) with analog instead of digital signals\noffers advantages in speed and energy efficiency, but component and measurement\nimperfections can make nonlinear analog networks difficult to train. As a\nresult, most schemes involve a precise digital model, either to train alone or\nin tandem with experiments. Here we take a different perspective: working in\nthe analog domain, we characterize the consequences of the inherent\nimperfection of a physical learning system and, ultimately, overcome them. We\ntrain an analog network of self-adjusting resistors -- a contrastive local\nlearning network (CLLN) -- for multiple tasks, and observe limit cycles and\ncharacteristic scaling behaviors absent in `perfect' systems. We develop an\nanalytical model that captures these phenomena by incorporating an uncontrolled\nbut deterministic bias into the learning process. Our results suggest that\nimperfections limit precision and erase memory of previous tasks by\ncontinuously modifying the underlying representation of all learned tasks, akin\nto representational drift in the brain. Finally, we introduce and demonstrate a\nsystem-agnostic training method that greatly suppresses these effects. Our work\npoints to a new, scalable approach in analog learning, one that eschews precise\nmodeling and instead thrives in the mess of real systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.22887v1",
    "published": "2025-05-28T21:42:17+00:00",
    "categories": [
      "cond-mat.dis-nn",
      "cond-mat.soft"
    ],
    "primary_category": "cond-mat.dis-nn"
  },
  {
    "id": "http://arxiv.org/abs/2505.22886v1",
    "title": "Telecom quantum dots on GaAs substrates as integration-ready high performance single-photon sources",
    "authors": [
      "Beatrice Costa",
      "Bianca Scaparra",
      "Xiao Wei",
      "Hubert Riedl",
      "Gregor Koblm√ºller",
      "Eugenio Zallo",
      "Jonathan Finley",
      "Lukas Hanschke",
      "Kai M√ºller"
    ],
    "abstract": "The development of deterministic single photon sources emitting in the\ntelecommunication bands is a key challenge for quantum communication and\nphotonic quantum computing. Here, we investigate the optical properties and\nsingle-photon emission of molecular beam epitaxy grown semiconductor quantum\ndots emitting in the telecom O- and C- bands. The quantum dots are embedded in\na InGaAs matrix with fixed indium content grown on top of a compositionally\ngraded InGaAs buffer. This structure allows for the future implementation of\nelectrically contacted nanocavities to enable high-quality and bright QD\nemission. In detailed optical characterizations we observe linewidths as low as\n$ 50 \\mu$eV, close to the spectrometer resolution limit, low fine structure\nsplittings close to $ 10 \\mu$eV, and $g^{(2)} (0)$ values as low as $0.08$.\nThese results advance the current performance metrics for MBE-grown quantum\ndots on GaAs substrates emitting in the telecom bands and showcase the\npotential of the presented heterostructures for further integration into\nphotonic devices.",
    "pdf_url": "http://arxiv.org/pdf/2505.22886v1",
    "published": "2025-05-28T21:41:56+00:00",
    "categories": [
      "cond-mat.mes-hall",
      "physics.app-ph",
      "quant-ph"
    ],
    "primary_category": "cond-mat.mes-hall"
  },
  {
    "id": "http://arxiv.org/abs/2505.22885v1",
    "title": "Extensions of homogeneous distributions on deformations to the normal cone",
    "authors": [
      "Moudrik Chamoux"
    ],
    "abstract": "On a deformation to the normal cone $\\operatorname{DNC}(M,V)$ we show that\ngiven a distribution $u\\in\\mathcal{D}'(\\operatorname{DNC}(M,V)\\setminus\nV\\times\\mathbb{R})$ if $u$ is homogeneous of order $a$ for the zoom action,\nthen it admits an $a$-homogeneous extension\n$\\widetilde{u}\\in\\mathcal{D}'(\\operatorname{DNC}(M,V))$. We describe all such\nextensions and discuss briefly about how it translates to the work of Van Erp\nand Yuncken in arXiv:2303.15787 . The technique used come from the results on\nthe extension of weakly homogeneous distributions provided by Yves Meyer in the\n90s.",
    "pdf_url": "http://arxiv.org/pdf/2505.22885v1",
    "published": "2025-05-28T21:36:59+00:00",
    "categories": [
      "math.DG",
      "math.FA"
    ],
    "primary_category": "math.DG"
  },
  {
    "id": "http://arxiv.org/abs/2505.22884v1",
    "title": "Evolution analysis of software quality metrics in an open-source java project: A case study on TestNG",
    "authors": [
      "Venkata Sai Sravya Sambaturu"
    ],
    "abstract": "Software quality is critical in modern software engineering, especially in\nlarge and evolving codebases. This study analyzes the evolution of software\nquality metrics in five successive versions of the open-source Java testing\nframework TestNG. Using the static analysis tool Understand, eleven key\nobject-oriented metrics, including cyclomatic complexity, class coupling, and\nlines of code, were extracted for each version. Statistical and visual analyses\nreveal structural trends over time. The results indicate that TestNG has\nmatured into a more stable and maintainable framework, reflecting ongoing\ndevelopment, refactoring, and architectural improvements. This study provides\ninsights into design evolution and offers recommendations for maintaining code\nquality in similar projects.",
    "pdf_url": "http://arxiv.org/pdf/2505.22884v1",
    "published": "2025-05-28T21:34:27+00:00",
    "categories": [
      "cs.SE",
      "cs.CE"
    ],
    "primary_category": "cs.SE"
  },
  {
    "id": "http://arxiv.org/abs/2505.22883v1",
    "title": "Spectrally Resolved Higher Order Photon Statistics of Spontaneous Parametric Down Conversion",
    "authors": [
      "Jeffrey Carvalho",
      "Chiran Wijesundara",
      "Tim Thomay"
    ],
    "abstract": "The photon statistics of Spontaneous Parametric Down Conversion (SPDC)\nexhibit dependencies on wavelength, pump power, and coincidence time. Notably,\nthe average photon numbers were found to asymmetrically increase with\nincreasing pump power around the degenerate wavelength of emission. By the\ncoupling of the detection scheme to a spectrometer, studying different\nbandwidths within the emission revealed that shorter wavelengths increased\nnonlinearly with pump power, while longer wavelengths showed more linear\nbehavior, indicating a wavelength dependent efficiency in the generation of the\nSPDC. We employ the use of a four detector Hanbury Brown and Twiss\nInterferometer to study the photon statistics of the signal beam, where the\nidler serves as the herald. The measured statistics were found to be best\ndescribed by a Negative Binomial Distribution, which is a characteristic of\nthermal light sources. The detection and characterization of complex light\nsources has wide ranging applications in the fields of quantum metrology,\nquantum communications, and quantum computing, more specifically, a system that\nis sensitive to wavelength and photon number distribution.",
    "pdf_url": "http://arxiv.org/pdf/2505.22883v1",
    "published": "2025-05-28T21:33:32+00:00",
    "categories": [
      "quant-ph",
      "physics.optics"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.22882v1",
    "title": "TwinTrack: Bridging Vision and Contact Physics for Real-Time Tracking of Unknown Dynamic Objects",
    "authors": [
      "Wen Yang",
      "Zhixian Xie",
      "Xuechao Zhang",
      "Heni Ben Amor",
      "Shan Lin",
      "Wanxin Jin"
    ],
    "abstract": "Real-time tracking of previously unseen, highly dynamic objects in\ncontact-rich environments -- such as during dexterous in-hand manipulation --\nremains a significant challenge. Purely vision-based tracking often suffers\nfrom heavy occlusions due to the frequent contact interactions and motion blur\ncaused by abrupt motion during contact impacts. We propose TwinTrack, a\nphysics-aware visual tracking framework that enables robust and real-time 6-DoF\npose tracking of unknown dynamic objects in a contact-rich scene by leveraging\nthe contact physics of the observed scene. At the core of TwinTrack is an\nintegration of Real2Sim and Sim2Real. In Real2Sim, we combine the complementary\nstrengths of vision and contact physics to estimate object's collision geometry\nand physical properties: object's geometry is first reconstructed from vision,\nthen updated along with other physical parameters from contact dynamics for\nphysical accuracy. In Sim2Real, robust pose estimation of the object is\nachieved by adaptive fusion between visual tracking and prediction of the\nlearned contact physics. TwinTrack is built on a GPU-accelerated, deeply\ncustomized physics engine to ensure real-time performance. We evaluate our\nmethod on two contact-rich scenarios: object falling with rich contact impacts\nagainst the environment, and contact-rich in-hand manipulation. Experimental\nresults demonstrate that, compared to baseline methods, TwinTrack achieves\nsignificantly more robust, accurate, and real-time 6-DoF tracking in these\nchallenging scenarios, with tracking speed exceeding 20 Hz. Project page:\nhttps://irislab.tech/TwinTrack-webpage/",
    "pdf_url": "http://arxiv.org/pdf/2505.22882v1",
    "published": "2025-05-28T21:32:12+00:00",
    "categories": [
      "cs.RO"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.22881v1",
    "title": "Smart Surrogate Losses for Contextual Stochastic Linear Optimization with Robust Constraints",
    "authors": [
      "Hyungki Im",
      "Wyame Benslimane",
      "Paul Grigas"
    ],
    "abstract": "We study an extension of contextual stochastic linear optimization (CSLO)\nthat, in contrast to most of the existing literature, involves inequality\nconstraints that depend on uncertain parameters predicted by a machine learning\nmodel. To handle the constraint uncertainty, we use contextual uncertainty sets\nconstructed via methods like conformal prediction. Given a contextual\nuncertainty set method, we introduce the \"Smart Predict-then-Optimize with\nRobust Constraints\" (SPO-RC) loss, a feasibility-sensitive adaptation of the\nSPO loss that measures decision error of predicted objective parameters. We\nalso introduce a convex surrogate, SPO-RC+, and prove Fisher consistency with\nSPO-RC. To enhance performance, we train on truncated datasets where true\nconstraint parameters lie within the uncertainty sets, and we correct the\ninduced sample selection bias using importance reweighting techniques. Through\nexperiments on fractional knapsack and alloy production problem instances, we\ndemonstrate that SPO-RC+ effectively handles uncertainty in constraints and\nthat combining truncation with importance reweighting can further improve\nperformance.",
    "pdf_url": "http://arxiv.org/pdf/2505.22881v1",
    "published": "2025-05-28T21:29:40+00:00",
    "categories": [
      "cs.LG",
      "math.OC",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.22880v1",
    "title": "Semantic Exploration and Dense Mapping of Complex Environments using Ground Robots Equipped with LiDAR and Panoramic Camera",
    "authors": [
      "Xiaoyang Zhan",
      "Shixin Zhou",
      "Qianqian Yang",
      "Yixuan Zhao",
      "Hao Liu",
      "Srinivas Chowdary Ramineni",
      "Kenji Shimada"
    ],
    "abstract": "This paper presents a system for autonomous semantic exploration and dense\nsemantic target mapping of a complex unknown environment using a ground robot\nequipped with a LiDAR-panoramic camera suite. Existing approaches often\nstruggle to balance collecting high-quality observations from multiple view\nangles and avoiding unnecessary repetitive traversal. To fill this gap, we\npropose a complete system combining mapping and planning. We first redefine the\ntask as completing both geometric coverage and semantic viewpoint observation.\nWe then manage semantic and geometric viewpoints separately and propose a novel\nPriority-driven Decoupled Local Sampler to generate local viewpoint sets. This\nenables explicit multi-view semantic inspection and voxel coverage without\nunnecessary repetition. Building on this, we develop a hierarchical planner to\nensure efficient global coverage. In addition, we propose a Safe Aggressive\nExploration State Machine, which allows aggressive exploration behavior while\nensuring the robot's safety. Our system includes a plug-and-play semantic\ntarget mapping module that integrates seamlessly with state-of-the-art SLAM\nalgorithms for pointcloud-level dense semantic target mapping. We validate our\napproach through extensive experiments in both realistic simulations and\ncomplex real-world environments. Simulation results show that our planner\nachieves faster exploration and shorter travel distances while guaranteeing a\nspecified number of multi-view inspections. Real-world experiments further\nconfirm the system's effectiveness in achieving accurate dense semantic object\nmapping of unstructured environments.",
    "pdf_url": "http://arxiv.org/pdf/2505.22880v1",
    "published": "2025-05-28T21:27:32+00:00",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.22879v1",
    "title": "Visualizing Cloud-native Applications with KubeDiagrams",
    "authors": [
      "Philippe Merle",
      "Fabio Petrillo"
    ],
    "abstract": "Modern distributed applications increasingly rely on cloud-native platforms\nto abstract the complexity of deployment and scalability. As the de facto\norchestration standard, Kubernetes enables this abstraction, but its\ndeclarative configuration model makes the architectural understanding\ndifficult. Developers, operators, and architects struggle to form accurate\nmental models from raw manifests, Helm charts, or cluster state descriptions.\nWe introduce KubeDiagrams, an open-source tool that transforms Kubernetes\nmanifests into architecture diagrams. By grounding our design in a\nuser-centered study of real-world visualization practices, we identify the\nspecific challenges Kubernetes users face and map these to concrete design\nrequirements. KubeDiagrams integrates seamlessly with standard Kubernetes\nartifacts, preserves semantic fidelity to core concepts, and supports\nextensibility and automation. We detail the tool's architecture, visual\nencoding strategies, and extensibility mechanisms. Three case studies\nillustrate how KubeDiagrams enhances system comprehension and supports\narchitectural reasoning in distributed cloud-native systems. KubeDiagrams\naddresses concrete pain points in Kubernetes-based DevOps practices and is\nvalued for its automation, clarity, and low-friction integration into\nreal-world tooling environments.",
    "pdf_url": "http://arxiv.org/pdf/2505.22879v1",
    "published": "2025-05-28T21:27:25+00:00",
    "categories": [
      "cs.SE",
      "cs.DC"
    ],
    "primary_category": "cs.SE"
  },
  {
    "id": "http://arxiv.org/abs/2505.22878v1",
    "title": "BugWhisperer: Fine-Tuning LLMs for SoC Hardware Vulnerability Detection",
    "authors": [
      "Shams Tarek",
      "Dipayan Saha",
      "Sujan Kumar Saha",
      "Farimah Farahmandi"
    ],
    "abstract": "The current landscape of system-on-chips (SoCs) security verification faces\nchallenges due to manual, labor-intensive, and inflexible methodologies. These\nissues limit the scalability and effectiveness of security protocols, making\nbug detection at the Register-Transfer Level (RTL) difficult. This paper\nproposes a new framework named BugWhisperer that utilizes a specialized,\nfine-tuned Large Language Model (LLM) to address these challenges. By enhancing\nthe LLM's hardware security knowledge and leveraging its capabilities for text\ninference and knowledge transfer, this approach automates and improves the\nadaptability and reusability of the verification process. We introduce an\nopen-source, fine-tuned LLM specifically designed for detecting security\nvulnerabilities in SoC designs. Our findings demonstrate that this tailored LLM\neffectively enhances the efficiency and flexibility of the security\nverification process. Additionally, we introduce a comprehensive hardware\nvulnerability database that supports this work and will further assist the\nresearch community in enhancing the security verification process.",
    "pdf_url": "http://arxiv.org/pdf/2505.22878v1",
    "published": "2025-05-28T21:25:06+00:00",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.23849v2",
    "title": "CADRE: Customizable Assurance of Data Readiness in Privacy-Preserving Federated Learning",
    "authors": [
      "Kaveen Hiniduma",
      "Zilinghan Li",
      "Aditya Sinha",
      "Ravi Madduri",
      "Suren Byna"
    ],
    "abstract": "Privacy-Preserving Federated Learning (PPFL) is a decentralized machine\nlearning approach where multiple clients train a model collaboratively. PPFL\npreserves the privacy and security of a client's data without exchanging it.\nHowever, ensuring that data at each client is of high quality and ready for\nfederated learning (FL) is a challenge due to restricted data access. In this\npaper, we introduce CADRE (Customizable Assurance of Data Readiness) for\nfederated learning (FL), a novel framework that allows users to define custom\ndata readiness (DR) metrics, rules, and remedies tailored to specific FL tasks.\nCADRE generates comprehensive DR reports based on the user-defined metrics,\nrules, and remedies to ensure datasets are prepared for FL while preserving\nprivacy. We demonstrate a practical application of CADRE by integrating it into\nan existing PPFL framework. We conducted experiments across six datasets and\naddressed seven different DR issues. The results illustrate the versatility and\neffectiveness of CADRE in ensuring DR across various dimensions, including data\nquality, privacy, and fairness. This approach enhances the performance and\nreliability of FL models as well as utilizes valuable resources.",
    "pdf_url": "http://arxiv.org/pdf/2505.23849v2",
    "published": "2025-05-28T21:24:46+00:00",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.22877v1",
    "title": "Probing the existence of a minimal length through compact binary inspiral",
    "authors": [
      "N. V. Krishnendu",
      "Aldo Perri",
      "Sumanta Chakraborty",
      "Alessandro Pesci"
    ],
    "abstract": "Existence of a minimal length in spacetime geometries avoids several singular\nsituations involving quantum theory and gravity. In this work, we show that the\nexistence of such a minimal length also affects the gravitational wave (GW)\nwaveform of any inspiraling binary black hole (BH) system by introducing a\nminimum frequency, below which the BHs behave as perfectly reflecting compact\nobjects, while above they are identical to classical BHs. This leads to a\nsignificant imprint on the tidal heating term, appearing in the GW waveform at\n2.5 post Newtonian order. Based on these modifications to the inspiraling\nwaveform, it turns out that the detection of highly spinning and highly\nabsorbing, almost classical BH like compact objects, inspiraling around each\nother, would be in tension with the quantum properties of BH geometries. The\nsame would also be true if the zero point length exceeds the Planck length by a\nsignificant amount, suggesting that the zero point length, if it exists, must\nbe of the same order as the Planck length, or smaller, purely from GW\nobservations.",
    "pdf_url": "http://arxiv.org/pdf/2505.22877v1",
    "published": "2025-05-28T21:22:38+00:00",
    "categories": [
      "gr-qc"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2506.03172v1",
    "title": "Large Neighborhood and Hybrid Genetic Search for Inventory Routing Problems",
    "authors": [
      "Jingyi Zhao",
      "Claudia Archetti",
      "Tuan Anh Pham",
      "Thibaut Vidal"
    ],
    "abstract": "The inventory routing problem (IRP) focuses on jointly optimizing inventory\nand distribution operations from a supplier to retailers over multiple days.\nCompared to other problems from the vehicle routing family, the interrelations\nbetween inventory and routing decisions render IRP optimization more\nchallenging and call for advanced solution techniques. A few studies have\nfocused on developing large neighborhood search approaches for this class of\nproblems, but this remains a research area with vast possibilities due to the\nchallenges related to the integration of inventory and routing decisions. In\nthis study, we advance this research area by developing a new large\nneighborhood search operator tailored for the IRP. Specifically, the operator\noptimally removes and reinserts all visits to a specific retailer while\nminimizing routing and inventory costs. We propose an efficient tailored\ndynamic programming algorithm that exploits preprocessing and acceleration\nstrategies. The operator is used to build an effective local search routine,\nand included in a state-of-the-art routing algorithm, i.e., Hybrid Genetic\nSearch (HGS). Through extensive computational experiments, we demonstrate that\nthe resulting heuristic algorithm leads to solutions of unmatched quality up to\nthis date, especially on large-scale benchmark instances.",
    "pdf_url": "http://arxiv.org/pdf/2506.03172v1",
    "published": "2025-05-28T21:18:08+00:00",
    "categories": [
      "cs.NE",
      "stat.ME"
    ],
    "primary_category": "cs.NE"
  },
  {
    "id": "http://arxiv.org/abs/2505.22876v1",
    "title": "Next Generation LLRF Control and Monitoring System for S-Band Linear Accelerators",
    "authors": [
      "Chao Liu",
      "Ankur Dhar",
      "Emma Snively",
      "Mohamed Othman",
      "Ryan Herbst",
      "Emilio A. Nanni"
    ],
    "abstract": "The low-level RF (LLRF) systems for S-band linear accelerating structures are\ntypically implemented with heterodyne base architectures. We have developed and\ncharacterized the next generation LLRF (NG-LLRF) based on the RF system-on-chip\n(RFSoC) for C-band accelerating structures, and the platform delivered the\npulse-to-pulse fluctuation levels considerably better than the requirement of\nthe targeted applications. The NG-LLRF system uses the direct RF sampling\ntechnique of the RFSoC, which significantly simplified the architecture\ncompared to the conventional LLRF. We have extended the frequency range of the\nNG-LLRF to S-band and experimented with different RFSoC devices and system\ndesigns to meet the more stringent requirements for S-band LLRF applications.\nIn this paper, the characterization results of the platform with different\nsystem architectures will be summarized and the high-power test results of the\nNG-LLRF with the S-band accelerating structure in the Next Linear Collider Test\nAccelerator (NLCTA) test facility at the SLAC National Accelerator Laboratory\nwill be presented and analyzed.",
    "pdf_url": "http://arxiv.org/pdf/2505.22876v1",
    "published": "2025-05-28T21:17:39+00:00",
    "categories": [
      "physics.acc-ph",
      "astro-ph.IM"
    ],
    "primary_category": "physics.acc-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.22875v1",
    "title": "Monotonicity and decompositions of random regular graphs",
    "authors": [
      "Lawrence Hollom",
      "Lyuben Lichev",
      "Adva Mond",
      "Julien Portier",
      "Yiting Wang"
    ],
    "abstract": "In this work we establish several monotonicity and decomposition results in\nthe framework of random regular graphs. Among other results, we show that, for\na wide range of parameters $d_1 \\leq d_2$, there exists a coupling of\n$G(n,d_1)$ and $G(n,d_2)$ satisfying that $G(n,d_1) \\subseteq G(n,d_2)$ with\nhigh probability, confirming a conjecture of Gao, Isaev and McKay in a new\nregime. Our contributions include new tools for analysing contiguity and total\nvariation distance between random regular graph models, a novel procedure for\ngenerating unions of random edge-disjoint perfect matchings, and refined\nestimates of Gao's bounds on the number of perfect matchings in random regular\ngraphs. In addition, we make progress towards another conjecture of Isaev,\nMcKay, Southwell and Zhukovskii.",
    "pdf_url": "http://arxiv.org/pdf/2505.22875v1",
    "published": "2025-05-28T21:17:03+00:00",
    "categories": [
      "math.CO",
      "math.PR",
      "05C80"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.22874v4",
    "title": "Spectrum Selective Interfaces and Materials towards Non-photothermal Saltwater Evaporation: Demonstration with a White Ceramic Wick",
    "authors": [
      "Navindra D. Singh",
      "James Leung",
      "Ji Feng",
      "Alma K. Gonz√°lez-Alcalde",
      "Arial Tolentino",
      "David Tuft",
      "Juchen Guo",
      "Luat T. Vuong"
    ],
    "abstract": "Most solar desalination efforts are photothermal: they evaporate water with\n``black'' materials that absorb as much sunlight as possible. Such\n``brine-boiling'' methods are limited by the high thermal mass of water, i.e.,\nits capacity to store and release heat. Here, we study the light-enhanced\nevaporation by a hard, white, aluminum nitride wick, and propose a route to\nselectively target salt-water bonds instead of bulk heating via deep-UV\ninteractions. Through experiments and analyses that isolate the effects of\nlight absorption and heating in aluminum nitride, we provide experimental\nevidence of a light-driven, spectrum-selective path to non-photothermal\nsaltwater evaporation. Leverage of these light-matter interactions in white\nceramic wicks may achieve low-cost, low-energy desalination, reduce the heat\nisland effects of traditional solar technologies, and contribute to new cooling\ntechnologies where drought is also a concern.",
    "pdf_url": "http://arxiv.org/pdf/2505.22874v4",
    "published": "2025-05-28T21:16:44+00:00",
    "categories": [
      "cond-mat.mtrl-sci",
      "physics.optics"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2505.22873v1",
    "title": "Forecasting Residential Heating and Electricity Demand with Scalable, High-Resolution, Open-Source Models",
    "authors": [
      "Stephen J. Lee",
      "Cailinn Drouin"
    ],
    "abstract": "We present a novel framework for high-resolution forecasting of residential\nheating and electricity demand using probabilistic deep learning models. We\nfocus specifically on providing hourly building-level electricity and heating\ndemand forecasts for the residential sector. Leveraging multimodal\nbuilding-level information -- including data on building footprint areas,\nheights, nearby building density, nearby building size, land use patterns, and\nhigh-resolution weather data -- and probabilistic modeling, our methods provide\ngranular insights into demand heterogeneity. Validation at the building level\nunderscores a step change improvement in performance relative to NREL's\nResStock model, which has emerged as a research community standard for\nresidential heating and electricity demand characterization. In building-level\nheating and electricity estimation backtests, our probabilistic models\nrespectively achieve RMSE scores 18.3\\% and 35.1\\% lower than those based on\nResStock. By offering an open-source, scalable, high-resolution platform for\ndemand estimation and forecasting, this research advances the tools available\nfor policymakers and grid planners, contributing to the broader effort to\ndecarbonize the U.S. building stock and meeting climate objectives.",
    "pdf_url": "http://arxiv.org/pdf/2505.22873v1",
    "published": "2025-05-28T21:16:27+00:00",
    "categories": [
      "econ.GN",
      "q-fin.EC",
      "stat.ML"
    ],
    "primary_category": "econ.GN"
  },
  {
    "id": "http://arxiv.org/abs/2506.00052v1",
    "title": "Using LLMs to Advance the Cognitive Science of Collectives",
    "authors": [
      "Ilia Sucholutsky",
      "Katherine M. Collins",
      "Nori Jacoby",
      "Bill D. Thompson",
      "Robert D. Hawkins"
    ],
    "abstract": "LLMs are already transforming the study of individual cognition, but their\napplication to studying collective cognition has been underexplored. We lay out\nhow LLMs may be able to address the complexity that has hindered the study of\ncollectives and raise possible risks that warrant new methods.",
    "pdf_url": "http://arxiv.org/pdf/2506.00052v1",
    "published": "2025-05-28T21:15:46+00:00",
    "categories": [
      "q-bio.NC",
      "cs.AI",
      "cs.HC",
      "cs.MA",
      "cs.SI"
    ],
    "primary_category": "q-bio.NC"
  },
  {
    "id": "http://arxiv.org/abs/2505.22872v1",
    "title": "High Precision RF Pulse Shaping with Direct RF Sampling for Future Linear Accelerators",
    "authors": [
      "Chao Liu",
      "Ankur Dhar",
      "Ryan Herbst",
      "Emilio A. Nanni"
    ],
    "abstract": "In various of particle accelerator designs, amplitude and phase modulation\nmethods are commonly applied to shape the RF pulses for implementing pulse\ncompressors or compensating for the fluctuations introduced by the high-power\nRF components and beam loading effects. Phase modulations are typically\nimplemented with additional phase shifters that require drive or control\nelectronics. With our recent next-generation LLRF (NG-LLRF) platform developed\nbased on direct RF sampling technology of RF system-on-chip (RFSoC) devices, RF\npulse shaping can be realized without the analogue phase shifters, which can\nsignificantly simplify the system architecture. We performed a range of\nhigh-power experiments in the C-band to evaluate the RF pulse-shaping\ncapabilities of the NG-LLRF system at different stages of the RF circuits. In\nthis paper, the high-power characterization results with the Cool Copper\nCollider (C3) structure driven by RF pulses with different modulation schemes\nwill be described. With the pulse modulation and demodulation completely\nimplemented in the digital domain, the RF pulse shaping schemes can be rapidly\nadapted for X-band structures simply by adding analogue mixers.",
    "pdf_url": "http://arxiv.org/pdf/2505.22872v1",
    "published": "2025-05-28T21:13:35+00:00",
    "categories": [
      "physics.acc-ph",
      "astro-ph.IM"
    ],
    "primary_category": "physics.acc-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.22871v1",
    "title": "The WHY in Business Processes: Unification of Causal Process Models",
    "authors": [
      "Yuval David",
      "Fabiana Fournier",
      "Lior Limonad",
      "Inna Skarbovsky"
    ],
    "abstract": "Causal reasoning is essential for business process interventions and\nimprovement, requiring a clear understanding of causal relationships among\nactivity execution times in an event log. Recent work introduced a method for\ndiscovering causal process models but lacked the ability to capture alternating\ncausal conditions across multiple variants. This raises the challenges of\nhandling missing values and expressing the alternating conditions among log\nsplits when blending traces with varying activities.\n  We propose a novel method to unify multiple causal process variants into a\nconsistent model that preserves the correctness of the original causal models,\nwhile explicitly representing their causal-flow alternations. The method is\nformally defined, proved, evaluated on three open and two proprietary datasets,\nand released as an open-source implementation.",
    "pdf_url": "http://arxiv.org/pdf/2505.22871v1",
    "published": "2025-05-28T21:12:30+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.22870v1",
    "title": "Emergence of Transverse Dielectric Response in Ferroelectric Dielectric Heterostructures",
    "authors": [
      "Fernando G√≥mez-Ortiz",
      "Ramamoorthy Ramesh",
      "Javier Junquera"
    ],
    "abstract": "We report the emergence of a transverse dielectric response in\nPbTiO$_{3}$/SrTiO$_{3}$ superlattices hosting polar vortex structures. Using\nsecond-principles simulations, we find that an electric field applied along one\ndirection induces significant local polarization responses along orthogonal\ndirections, with magnitudes approaching half that of the diagonal\nsusceptibility components. These off-diagonal responses are strongly dependent\non the topology of the vortex structure and can be deterministically tuned or\neven reversed via homogeneous electric fields or epitaxial strain. Notably, the\ntransverse susceptibilities become comparable to the diagonal components during\na field- or strain-induced transition to a polarization wave state. This\ndiscovery opens avenues for engineering reconfigurable nanoscale dielectric\nresponses in topologically textured ferroelectric systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.22870v1",
    "published": "2025-05-28T21:07:17+00:00",
    "categories": [
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2505.22869v1",
    "title": "CFP-Gen: Combinatorial Functional Protein Generation via Diffusion Language Models",
    "authors": [
      "Junbo Yin",
      "Chao Zha",
      "Wenjia He",
      "Chencheng Xu",
      "Xin Gao"
    ],
    "abstract": "Existing PLMs generate protein sequences based on a single-condition\nconstraint from a specific modality, struggling to simultaneously satisfy\nmultiple constraints across different modalities. In this work, we introduce\nCFP-Gen, a novel diffusion language model for Combinatorial Functional Protein\nGENeration. CFP-Gen facilitates the de novo protein design by integrating\nmultimodal conditions with functional, sequence, and structural constraints.\nSpecifically, an Annotation-Guided Feature Modulation (AGFM) module is\nintroduced to dynamically adjust the protein feature distribution based on\ncomposable functional annotations, e.g., GO terms, IPR domains and EC numbers.\nMeanwhile, the Residue-Controlled Functional Encoding (RCFE) module captures\nresidue-wise interaction to ensure more precise control. Additionally,\noff-the-shelf 3D structure encoders can be seamlessly integrated to impose\ngeometric constraints. We demonstrate that CFP-Gen enables high-throughput\ngeneration of novel proteins with functionality comparable to natural proteins,\nwhile achieving a high success rate in designing multifunctional proteins. Code\nand data available at https://github.com/yinjunbo/cfpgen.",
    "pdf_url": "http://arxiv.org/pdf/2505.22869v1",
    "published": "2025-05-28T21:05:46+00:00",
    "categories": [
      "cs.CV",
      "cs.LG",
      "q-bio.BM"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.22868v1",
    "title": "CrossNAS: A Cross-Layer Neural Architecture Search Framework for PIM Systems",
    "authors": [
      "Md Hasibul Amin",
      "Mohammadreza Mohammadi",
      "Jason D. Bakos",
      "Ramtin Zand"
    ],
    "abstract": "In this paper, we propose the CrossNAS framework, an automated approach for\nexploring a vast, multidimensional search space that spans various design\nabstraction layers-circuits, architecture, and systems-to optimize the\ndeployment of machine learning workloads on analog processing-in-memory (PIM)\nsystems. CrossNAS leverages the single-path one-shot weight-sharing strategy\ncombined with the evolutionary search for the first time in the context of PIM\nsystem mapping and optimization. CrossNAS sets a new benchmark for PIM neural\narchitecture search (NAS), outperforming previous methods in both accuracy and\nenergy efficiency while maintaining comparable or shorter search times.",
    "pdf_url": "http://arxiv.org/pdf/2505.22868v1",
    "published": "2025-05-28T21:00:49+00:00",
    "categories": [
      "cs.ET",
      "cs.AR",
      "cs.LG"
    ],
    "primary_category": "cs.ET"
  },
  {
    "id": "http://arxiv.org/abs/2505.22867v1",
    "title": "GateNLP at SemEval-2025 Task 10: Hierarchical Three-Step Prompting for Multilingual Narrative Classification",
    "authors": [
      "Iknoor Singh",
      "Carolina Scarton",
      "Kalina Bontcheva"
    ],
    "abstract": "The proliferation of online news and the increasing spread of misinformation\nnecessitate robust methods for automatic data analysis. Narrative\nclassification is emerging as a important task, since identifying what is being\nsaid online is critical for fact-checkers, policy markers and other\nprofessionals working on information studies. This paper presents our approach\nto SemEval 2025 Task 10 Subtask 2, which aims to classify news articles into a\npre-defined two-level taxonomy of main narratives and sub-narratives across\nmultiple languages.\n  We propose Hierarchical Three-Step Prompting (H3Prompt) for multilingual\nnarrative classification. Our methodology follows a three-step Large Language\nModel (LLM) prompting strategy, where the model first categorises an article\ninto one of two domains (Ukraine-Russia War or Climate Change), then identifies\nthe most relevant main narratives, and finally assigns sub-narratives. Our\napproach secured the top position on the English test set among 28 competing\nteams worldwide. The code is available at https://github.com/GateNLP/H3Prompt.",
    "pdf_url": "http://arxiv.org/pdf/2505.22867v1",
    "published": "2025-05-28T20:59:28+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.22866v1",
    "title": "Scaling Offline RL via Efficient and Expressive Shortcut Models",
    "authors": [
      "Nicolas Espinosa-Dice",
      "Yiyi Zhang",
      "Yiding Chen",
      "Bradley Guo",
      "Owen Oertell",
      "Gokul Swamy",
      "Kiante Brantley",
      "Wen Sun"
    ],
    "abstract": "Diffusion and flow models have emerged as powerful generative approaches\ncapable of modeling diverse and multimodal behavior. However, applying these\nmodels to offline reinforcement learning (RL) remains challenging due to the\niterative nature of their noise sampling processes, making policy optimization\ndifficult. In this paper, we introduce Scalable Offline Reinforcement Learning\n(SORL), a new offline RL algorithm that leverages shortcut models - a novel\nclass of generative models - to scale both training and inference. SORL's\npolicy can capture complex data distributions and can be trained simply and\nefficiently in a one-stage training procedure. At test time, SORL introduces\nboth sequential and parallel inference scaling by using the learned Q-function\nas a verifier. We demonstrate that SORL achieves strong performance across a\nrange of offline RL tasks and exhibits positive scaling behavior with increased\ntest-time compute. We release the code at\nnico-espinosadice.github.io/projects/sorl.",
    "pdf_url": "http://arxiv.org/pdf/2505.22866v1",
    "published": "2025-05-28T20:59:22+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "I.2.6"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.22865v1",
    "title": "BinauralFlow: A Causal and Streamable Approach for High-Quality Binaural Speech Synthesis with Flow Matching Models",
    "authors": [
      "Susan Liang",
      "Dejan Markovic",
      "Israel D. Gebru",
      "Steven Krenn",
      "Todd Keebler",
      "Jacob Sandakly",
      "Frank Yu",
      "Samuel Hassel",
      "Chenliang Xu",
      "Alexander Richard"
    ],
    "abstract": "Binaural rendering aims to synthesize binaural audio that mimics natural\nhearing based on a mono audio and the locations of the speaker and listener.\nAlthough many methods have been proposed to solve this problem, they struggle\nwith rendering quality and streamable inference. Synthesizing high-quality\nbinaural audio that is indistinguishable from real-world recordings requires\nprecise modeling of binaural cues, room reverb, and ambient sounds.\nAdditionally, real-world applications demand streaming inference. To address\nthese challenges, we propose a flow matching based streaming binaural speech\nsynthesis framework called BinauralFlow. We consider binaural rendering to be a\ngeneration problem rather than a regression problem and design a conditional\nflow matching model to render high-quality audio. Moreover, we design a causal\nU-Net architecture that estimates the current audio frame solely based on past\ninformation to tailor generative models for streaming inference. Finally, we\nintroduce a continuous inference pipeline incorporating streaming STFT/ISTFT\noperations, a buffer bank, a midpoint solver, and an early skip schedule to\nimprove rendering continuity and speed. Quantitative and qualitative\nevaluations demonstrate the superiority of our method over SOTA approaches. A\nperceptual study further reveals that our model is nearly indistinguishable\nfrom real-world recordings, with a $42\\%$ confusion rate.",
    "pdf_url": "http://arxiv.org/pdf/2505.22865v1",
    "published": "2025-05-28T20:59:15+00:00",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD"
  },
  {
    "id": "http://arxiv.org/abs/2505.22864v1",
    "title": "The National Research Platform: Stretched, Multi-Tenant, Scientific Kubernetes Cluster",
    "authors": [
      "Derek Weitzel",
      "Ashton Graves",
      "Sam Albin",
      "Huijun Zhu",
      "Frank W√ºrthwein",
      "Mahidhar Tatineni",
      "Dmitry Mishin",
      "John Graham",
      "Elham E Khoda",
      "Mohammad Firas Sada",
      "Larry Smarr",
      "Thomas DeFanti"
    ],
    "abstract": "The National Research Platform (NRP) represents a distributed, multi-tenant\nKubernetes-based cyberinfrastructure designed to facilitate collaborative\nscientific computing. Spanning over 75 locations in the U.S. and\ninternationally, the NRP uniquely integrates varied computational resources,\nranging from single nodes to extensive GPU and CPU clusters, to support diverse\nresearch workloads including advanced AI and machine learning tasks. It\nemphasizes flexibility through user-friendly interfaces such as JupyterHub and\nlow level control of resources through direct Kubernetes interaction. Critical\noperational insights are discussed, including security enhancements using\nKubernetes-integrated threat detection, extensive monitoring, and comprehensive\naccounting systems. This paper highlights the NRP's growing importance and\nscalability in addressing the increasing demands for distributed scientific\ncomputational resources.",
    "pdf_url": "http://arxiv.org/pdf/2505.22864v1",
    "published": "2025-05-28T20:58:58+00:00",
    "categories": [
      "cs.DC"
    ],
    "primary_category": "cs.DC"
  },
  {
    "id": "http://arxiv.org/abs/2505.22863v1",
    "title": "Large Language Models for Depression Recognition in Spoken Language Integrating Psychological Knowledge",
    "authors": [
      "Yupei Li",
      "Shuaijie Shao",
      "Manuel Milling",
      "Bj√∂rn W. Schuller"
    ],
    "abstract": "Depression is a growing concern gaining attention in both public discourse\nand AI research. While deep neural networks (DNNs) have been used for\nrecognition, they still lack real-world effectiveness. Large language models\n(LLMs) show strong potential but require domain-specific fine-tuning and\nstruggle with non-textual cues. Since depression is often expressed through\nvocal tone and behaviour rather than explicit text, relying on language alone\nis insufficient. Diagnostic accuracy also suffers without incorporating\npsychological expertise. To address these limitations, we present, to the best\nof our knowledge, the first application of LLMs to multimodal depression\ndetection using the DAIC-WOZ dataset. We extract the audio features using the\npre-trained model Wav2Vec, and mapped it to text-based LLMs for further\nprocessing. We also propose a novel strategy for incorporating psychological\nknowledge into LLMs to enhance diagnostic performance, specifically using a\nquestion and answer set to grant authorised knowledge to LLMs. Our approach\nyields a notable improvement in both Mean Absolute Error (MAE) and Root Mean\nSquare Error (RMSE) compared to a base score proposed by the related original\npaper. The codes are available at\nhttps://github.com/myxp-lyp/Depression-detection.git",
    "pdf_url": "http://arxiv.org/pdf/2505.22863v1",
    "published": "2025-05-28T20:53:05+00:00",
    "categories": [
      "cs.HC",
      "cs.CL"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2505.22861v2",
    "title": "Causal-PIK: Causality-based Physical Reasoning with a Physics-Informed Kernel",
    "authors": [
      "Carlota Par√©s-Morlans",
      "Michelle Yi",
      "Claire Chen",
      "Sarah A. Wu",
      "Rika Antonova",
      "Tobias Gerstenberg",
      "Jeannette Bohg"
    ],
    "abstract": "Tasks that involve complex interactions between objects with unknown dynamics\nmake planning before execution difficult. These tasks require agents to\niteratively improve their actions after actively exploring causes and effects\nin the environment. For these type of tasks, we propose Causal-PIK, a method\nthat leverages Bayesian optimization to reason about causal interactions via a\nPhysics-Informed Kernel to help guide efficient search for the best next\naction. Experimental results on Virtual Tools and PHYRE physical reasoning\nbenchmarks show that Causal-PIK outperforms state-of-the-art results, requiring\nfewer actions to reach the goal. We also compare Causal-PIK to human studies,\nincluding results from a new user study we conducted on the PHYRE benchmark. We\nfind that Causal-PIK remains competitive on tasks that are very challenging,\neven for human problem-solvers.",
    "pdf_url": "http://arxiv.org/pdf/2505.22861v2",
    "published": "2025-05-28T20:51:12+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.22862v2",
    "title": "Optimal Auction Design for Dynamic Stochastic Environments: Myerson Meets Naor",
    "authors": [
      "Yeon-Koo Che",
      "Andrew B. Choi"
    ],
    "abstract": "Allocation of goods and services often involves both stochastic supply and\nstochastic demand. Motivated by applications such as cloud computing, gig\nplatforms, and blockchain auctions, we study the design of optimal selling\nmechanisms in an environment where buyers with private valuations arrive\nstochastically and are assigned goods that also arrive stochastically, and\neither buyers or goods can be held in a queue at costs until allocation. The\noptimal mechanism dynamically leverages competitive pressure across time by\nmanaging the queue of buyers and inventory of goods, using reserve prices that\nincrease with the number of buyers in the queue and decrease with the number of\nitems in inventory, and an auction to allocate the goods.",
    "pdf_url": "http://arxiv.org/pdf/2505.22862v2",
    "published": "2025-05-28T20:51:12+00:00",
    "categories": [
      "econ.TH"
    ],
    "primary_category": "econ.TH"
  },
  {
    "id": "http://arxiv.org/abs/2505.22860v1",
    "title": "Permissioned LLMs: Enforcing Access Control in Large Language Models",
    "authors": [
      "Bargav Jayaraman",
      "Virendra J. Marathe",
      "Hamid Mozaffari",
      "William F. Shen",
      "Krishnaram Kenthapadi"
    ],
    "abstract": "In enterprise settings, organizational data is segregated, siloed and\ncarefully protected by elaborate access control frameworks. These access\ncontrol structures can completely break down if an LLM fine-tuned on the siloed\ndata serves requests, for downstream tasks, from individuals with disparate\naccess privileges. We propose Permissioned LLMs (PermLLM), a new class of LLMs\nthat superimpose the organizational data access control structures on query\nresponses they generate. We formalize abstractions underpinning the means to\ndetermine whether access control enforcement happens correctly over LLM query\nresponses. Our formalism introduces the notion of a relevant response that can\nbe used to prove whether a PermLLM mechanism has been implemented correctly. We\nalso introduce a novel metric, called access advantage, to empirically evaluate\nthe efficacy of a PermLLM mechanism. We introduce three novel PermLLM\nmechanisms that build on Parameter Efficient Fine-Tuning to achieve the desired\naccess control. We furthermore present two instantiations of access\nadvantage--(i) Domain Distinguishability Index (DDI) based on Membership\nInference Attacks, and (ii) Utility Gap Index (UGI) based on LLM utility\nevaluation. We demonstrate the efficacy of our PermLLM mechanisms through\nextensive experiments on four public datasets (GPQA, RCV1, SimpleQA, and WMDP),\nin addition to evaluating the validity of DDI and UGI metrics themselves for\nquantifying access control in LLMs.",
    "pdf_url": "http://arxiv.org/pdf/2505.22860v1",
    "published": "2025-05-28T20:47:02+00:00",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.22859v1",
    "title": "4DTAM: Non-Rigid Tracking and Mapping via Dynamic Surface Gaussians",
    "authors": [
      "Hidenobu Matsuki",
      "Gwangbin Bae",
      "Andrew J. Davison"
    ],
    "abstract": "We propose the first 4D tracking and mapping method that jointly performs\ncamera localization and non-rigid surface reconstruction via differentiable\nrendering. Our approach captures 4D scenes from an online stream of color\nimages with depth measurements or predictions by jointly optimizing scene\ngeometry, appearance, dynamics, and camera ego-motion. Although natural\nenvironments exhibit complex non-rigid motions, 4D-SLAM remains relatively\nunderexplored due to its inherent challenges; even with 2.5D signals, the\nproblem is ill-posed because of the high dimensionality of the optimization\nspace. To overcome these challenges, we first introduce a SLAM method based on\nGaussian surface primitives that leverages depth signals more effectively than\n3D Gaussians, thereby achieving accurate surface reconstruction. To further\nmodel non-rigid deformations, we employ a warp-field represented by a\nmulti-layer perceptron (MLP) and introduce a novel camera pose estimation\ntechnique along with surface regularization terms that facilitate\nspatio-temporal reconstruction. In addition to these algorithmic challenges, a\nsignificant hurdle in 4D SLAM research is the lack of reliable ground truth and\nevaluation protocols, primarily due to the difficulty of 4D capture using\ncommodity sensors. To address this, we present a novel open synthetic dataset\nof everyday objects with diverse motions, leveraging large-scale object models\nand animation modeling. In summary, we open up the modern 4D-SLAM research by\nintroducing a novel method and evaluation protocols grounded in modern vision\nand rendering techniques.",
    "pdf_url": "http://arxiv.org/pdf/2505.22859v1",
    "published": "2025-05-28T20:45:10+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.22858v1",
    "title": "A Probabilistic Jump-Diffusion Framework for Open-World Egocentric Activity Recognition",
    "authors": [
      "Sanjoy Kundu",
      "Shanmukha Vellamcheti",
      "Sathyanarayanan N. Aakur"
    ],
    "abstract": "Open-world egocentric activity recognition poses a fundamental challenge due\nto its unconstrained nature, requiring models to infer unseen activities from\nan expansive, partially observed search space. We introduce ProbRes, a\nProbabilistic Residual search framework based on jump-diffusion that\nefficiently navigates this space by balancing prior-guided exploration with\nlikelihood-driven exploitation. Our approach integrates structured commonsense\npriors to construct a semantically coherent search space, adaptively refines\npredictions using Vision-Language Models (VLMs) and employs a stochastic search\nmechanism to locate high-likelihood activity labels while minimizing exhaustive\nenumeration efficiently. We systematically evaluate ProbRes across multiple\nopenness levels (L0--L3), demonstrating its adaptability to increasing search\nspace complexity. In addition to achieving state-of-the-art performance on\nbenchmark datasets (GTEA Gaze, GTEA Gaze+, EPIC-Kitchens, and Charades-Ego), we\nestablish a clear taxonomy for open-world recognition, delineating the\nchallenges and methodological advancements necessary for egocentric activity\nunderstanding.",
    "pdf_url": "http://arxiv.org/pdf/2505.22858v1",
    "published": "2025-05-28T20:44:14+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.22857v1",
    "title": "NGPU-LM: GPU-Accelerated N-Gram Language Model for Context-Biasing in Greedy ASR Decoding",
    "authors": [
      "Vladimir Bataev",
      "Andrei Andrusenko",
      "Lilit Grigoryan",
      "Aleksandr Laptev",
      "Vitaly Lavrukhin",
      "Boris Ginsburg"
    ],
    "abstract": "Statistical n-gram language models are widely used for context-biasing tasks\nin Automatic Speech Recognition (ASR). However, existing implementations lack\ncomputational efficiency due to poor parallelization, making context-biasing\nless appealing for industrial use. This work rethinks data structures for\nstatistical n-gram language models to enable fast and parallel operations for\nGPU-optimized inference. Our approach, named NGPU-LM, introduces customizable\ngreedy decoding for all major ASR model types - including transducers,\nattention encoder-decoder models, and CTC - with less than 7% computational\noverhead. The proposed approach can eliminate more than 50% of the accuracy gap\nbetween greedy and beam search for out-of-domain scenarios while avoiding\nsignificant slowdown caused by beam search. The implementation of the proposed\nNGPU-LM is open-sourced.",
    "pdf_url": "http://arxiv.org/pdf/2505.22857v1",
    "published": "2025-05-28T20:43:10+00:00",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "cs.SD"
    ],
    "primary_category": "eess.AS"
  },
  {
    "id": "http://arxiv.org/abs/2505.22856v1",
    "title": "Nanoscale quantum imaging of field-free deterministic switching of a chiral antiferromagnet",
    "authors": [
      "Jingcheng Zhou",
      "Senlei Li",
      "Chuangtang Wang",
      "Hanshang Jin",
      "Stelo Xu",
      "Zelong Xiong",
      "Carson Jacobsen",
      "Kenji Watanabe",
      "Takashi Taniguchi",
      "Valentin Taufour",
      "Liuyan Zhao",
      "Hua Chen",
      "Chunhui Rita Du",
      "Hailong Wang"
    ],
    "abstract": "Recently, unconventional spin-orbit torques (SOTs) with tunable spin\ngeneration open new pathways for designing novel magnetization control for\ncutting-edge spintronics innovations. A leading research thrust is to develop\nfield-free deterministic magnetization switching for implementing scalable and\nenergy favorable magnetic recording and storage applications, which have been\ndemonstrated in conventional ferromagnetic and antiferromagnetic material\nsystems. Here we extend this advanced magnetization control strategy to chiral\nantiferromagnet Mn3Sn using spin currents with out-of-plane canted polarization\ngenerated from low-symmetry van der Waals (vdW) material WTe2. Numerical\ncalculations suggest that damping-like SOT of spins injected perpendicular to\nthe kagome plane of Mn3Sn serves as a driving force to rotate the chiral\nmagnetic order, while the field-like SOT of spin currents with polarization\nparallel to the kagome plane provides the bipolar deterministicity to the\nmagnetic switching. We further introduce scanning quantum microscopy to\nvisualize nanoscale evolutions of Mn3Sn magnetic domains during the field-free\nswitching process, corroborating the exceptionally large magnetic switching\nratio up to 90%. Our results highlight the opportunities provided by hybrid SOT\nmaterial platforms consisting of noncollinear antiferromagnets and low-symmetry\nvdW spin source materials for developing next-generation, transformative\nspintronic logic devices.",
    "pdf_url": "http://arxiv.org/pdf/2505.22856v1",
    "published": "2025-05-28T20:42:34+00:00",
    "categories": [
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2505.22855v1",
    "title": "IRS: Incremental Relationship-guided Segmentation for Digital Pathology",
    "authors": [
      "Ruining Deng",
      "Junchao Zhu",
      "Juming Xiong",
      "Can Cui",
      "Tianyuan Yao",
      "Junlin Guo",
      "Siqi Lu",
      "Marilyn Lionts",
      "Mengmeng Yin",
      "Yu Wang",
      "Shilin Zhao",
      "Yucheng Tang",
      "Yihe Yang",
      "Paul Dennis Simonson",
      "Mert R. Sabuncu",
      "Haichun Yang",
      "Yuankai Huo"
    ],
    "abstract": "Continual learning is rapidly emerging as a key focus in computer vision,\naiming to develop AI systems capable of continuous improvement, thereby\nenhancing their value and practicality in diverse real-world applications. In\nhealthcare, continual learning holds great promise for continuously acquired\ndigital pathology data, which is collected in hospitals on a daily basis.\nHowever, panoramic segmentation on digital whole slide images (WSIs) presents\nsignificant challenges, as it is often infeasible to obtain comprehensive\nannotations for all potential objects, spanning from coarse structures (e.g.,\nregions and unit objects) to fine structures (e.g., cells). This results in\ntemporally and partially annotated data, posing a major challenge in developing\na holistic segmentation framework. Moreover, an ideal segmentation model should\nincorporate new phenotypes, unseen diseases, and diverse populations, making\nthis task even more complex. In this paper, we introduce a novel and unified\nIncremental Relationship-guided Segmentation (IRS) learning scheme to address\ntemporally acquired, partially annotated data while maintaining\nout-of-distribution (OOD) continual learning capacity in digital pathology. The\nkey innovation of IRS lies in its ability to realize a new spatial-temporal OOD\ncontinual learning paradigm by mathematically modeling anatomical relationships\nbetween existing and newly introduced classes through a simple incremental\nuniversal proposition matrix. Experimental results demonstrate that the IRS\nmethod effectively handles the multi-scale nature of pathological segmentation,\nenabling precise kidney segmentation across various structures (regions, units,\nand cells) as well as OOD disease lesions at multiple magnifications. This\ncapability significantly enhances domain generalization, making IRS a robust\napproach for real-world digital pathology applications.",
    "pdf_url": "http://arxiv.org/pdf/2505.22855v1",
    "published": "2025-05-28T20:41:56+00:00",
    "categories": [
      "eess.IV",
      "cs.CV"
    ],
    "primary_category": "eess.IV"
  },
  {
    "id": "http://arxiv.org/abs/2505.22854v1",
    "title": "CLIPGaussian: Universal and Multimodal Style Transfer Based on Gaussian Splatting",
    "authors": [
      "Kornel Howil",
      "Joanna Waczy≈Ñska",
      "Piotr Borycki",
      "Tadeusz Dziarmaga",
      "Marcin Mazur",
      "Przemys≈Çaw Spurek"
    ],
    "abstract": "Gaussian Splatting (GS) has recently emerged as an efficient representation\nfor rendering 3D scenes from 2D images and has been extended to images, videos,\nand dynamic 4D content. However, applying style transfer to GS-based\nrepresentations, especially beyond simple color changes, remains challenging.\nIn this work, we introduce CLIPGaussians, the first unified style transfer\nframework that supports text- and image-guided stylization across multiple\nmodalities: 2D images, videos, 3D objects, and 4D scenes. Our method operates\ndirectly on Gaussian primitives and integrates into existing GS pipelines as a\nplug-in module, without requiring large generative models or retraining from\nscratch. CLIPGaussians approach enables joint optimization of color and\ngeometry in 3D and 4D settings, and achieves temporal coherence in videos,\nwhile preserving a model size. We demonstrate superior style fidelity and\nconsistency across all tasks, validating CLIPGaussians as a universal and\nefficient solution for multimodal style transfer.",
    "pdf_url": "http://arxiv.org/pdf/2505.22854v1",
    "published": "2025-05-28T20:41:24+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.22853v3",
    "title": "A unified quaternion-complex framework for Navier-Stokes equations: new insights and implications",
    "authors": [
      "Farrukh A. Chishtie"
    ],
    "abstract": "We present a novel, unified quaternion-complex framework for formulating the\nincompressible Navier-Stokes equations that reveals the geometric structure\nunderlying viscous fluid motion and resolves the Clay Institute's Millennium\nPrize problem. By introducing complex coordinates $z = x + iy$ and expressing\nthe velocity field as $F = u + iv$, we demonstrate that the nonlinear\nconvection terms decompose as $(u \\cdot \\nabla)F = F \\cdot \\frac{\\partial\nF}{\\partial z} + F^* \\cdot \\frac{\\partial F}{\\partial \\bar{z}}$, separating\ninviscid convection from viscous coupling effects. We extend this framework to\nthree dimensions using quaternions and prove global regularity through\ngeometric constraints inherent in quaternion algebra. The incompressibility\nconstraint naturally emerges as a requirement that $\\frac{\\partial F}{\\partial\nz}$ be purely imaginary, linking fluid mechanics to complex analysis\nfundamentally. Our main result establishes that quaternion orthogonality\nrelations prevent finite-time singularities by ensuring turbulent energy\ncascade remains naturally bounded. The quaternion-complex formulation\ndemonstrates that turbulence represents breakdown of quaternion-analyticity\nwhile maintaining geometric stability, providing rigorous mathematical\nfoundation for understanding why real fluids exhibit finite turbulent behavior\nrather than mathematical singularities. We prove that for any smooth initial\ndata, there exists a unique global smooth solution to the three-dimensional\nincompressible Navier-Stokes equations, directly resolving the Clay Institute\nchallenge. Applications to atmospheric boundary layer physics demonstrate\nimmediate practical relevance for environmental modeling, weather prediction,\nand climate modeling.",
    "pdf_url": "http://arxiv.org/pdf/2505.22853v3",
    "published": "2025-05-28T20:37:33+00:00",
    "categories": [
      "physics.flu-dyn",
      "math.CV"
    ],
    "primary_category": "physics.flu-dyn"
  },
  {
    "id": "http://arxiv.org/abs/2505.22852v1",
    "title": "Operationalizing CaMeL: Strengthening LLM Defenses for Enterprise Deployment",
    "authors": [
      "Krti Tallam",
      "Emma Miller"
    ],
    "abstract": "CaMeL (Capabilities for Machine Learning) introduces a capability-based\nsandbox to mitigate prompt injection attacks in large language model (LLM)\nagents. While effective, CaMeL assumes a trusted user prompt, omits\nside-channel concerns, and incurs performance tradeoffs due to its dual-LLM\ndesign. This response identifies these issues and proposes engineering\nimprovements to expand CaMeL's threat coverage and operational usability. We\nintroduce: (1) prompt screening for initial inputs, (2) output auditing to\ndetect instruction leakage, (3) a tiered-risk access model to balance usability\nand control, and (4) a verified intermediate language for formal guarantees.\nTogether, these upgrades align CaMeL with best practices in enterprise security\nand support scalable deployment.",
    "pdf_url": "http://arxiv.org/pdf/2505.22852v1",
    "published": "2025-05-28T20:35:24+00:00",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.22851v1",
    "title": "Separating dots with circles",
    "authors": [
      "James Beyer",
      "Jaewon Min",
      "Greg Muller"
    ],
    "abstract": "Given a finite set of points in general position in the plane or sphere, we\ncount the number of ways to separate those points using two types of circles:\ncircles through three of the points, and circles through none of the points (up\nto an equivalence). In each case, we show the number of circles which separate\nthe points into subsets of size k and l is independent of the configuration of\npoints, and we provide an explicit formula in each case. We also consider how\nthe circles change as the configuration of dots varies continuously. We show\nthat an associated higher order Voronoi decomposition of the sphere changes by\na sequence of local `moves'. As a consequence, an associated cluster algebra is\nindependent of the configuration of dots, and only depends on the number of\ndots and the order of the Voronoi decomposition.",
    "pdf_url": "http://arxiv.org/pdf/2505.22851v1",
    "published": "2025-05-28T20:34:56+00:00",
    "categories": [
      "math.CO",
      "math.MG",
      "Primary 52B05, Secondary 68U05, 05E15, 13F60"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.22850v1",
    "title": "Improving Contrastive Learning for Referring Expression Counting",
    "authors": [
      "Kostas Triaridis",
      "Panagiotis Kaliosis",
      "E-Ro Nguyen",
      "Jingyi Xu",
      "Hieu Le",
      "Dimitris Samaras"
    ],
    "abstract": "Object counting has progressed from class-specific models, which count only\nknown categories, to class-agnostic models that generalize to unseen\ncategories. The next challenge is Referring Expression Counting (REC), where\nthe goal is to count objects based on fine-grained attributes and contextual\ndifferences. Existing methods struggle with distinguishing visually similar\nobjects that belong to the same category but correspond to different referring\nexpressions. To address this, we propose C-REX, a novel contrastive learning\nframework, based on supervised contrastive learning, designed to enhance\ndiscriminative representation learning. Unlike prior works, C-REX operates\nentirely within the image space, avoiding the misalignment issues of image-text\ncontrastive learning, thus providing a more stable contrastive signal. It also\nguarantees a significantly larger pool of negative samples, leading to improved\nrobustness in the learned representations. Moreover, we showcase that our\nframework is versatile and generic enough to be applied to other similar tasks\nlike class-agnostic counting. To support our approach, we analyze the key\ncomponents of sota detection-based models and identify that detecting object\ncentroids instead of bounding boxes is the key common factor behind their\nsuccess in counting tasks. We use this insight to design a simple yet effective\ndetection-based baseline to build upon. Our experiments show that C-REX\nachieves state-of-the-art results in REC, outperforming previous methods by\nmore than 22\\% in MAE and more than 10\\% in RMSE, while also demonstrating\nstrong performance in class-agnostic counting. Code is available at\nhttps://github.com/cvlab-stonybrook/c-rex.",
    "pdf_url": "http://arxiv.org/pdf/2505.22850v1",
    "published": "2025-05-28T20:33:42+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.22849v1",
    "title": "Flexure-FET-Based Receiver with Competitive Binding for Interference Mitigation in Molecular Communication",
    "authors": [
      "Dilara Aktas",
      "Ozgur B. Akan"
    ],
    "abstract": "Molecular communication (MC), a biologically inspired technology, enables\napplications in nanonetworks and the Internet of Everything (IoE), with great\npotential for intra-body systems such as drug delivery, health monitoring, and\ndisease detection. This paper extends our prior work on the Flexure-FET MC\nreceiver by integrating a competitive binding model to enhance performance in\nhigh-interference environments, where multiple molecular species coexist in the\nreception space. Previous studies have largely focused on ligand concentration\nestimation and detection, without fully addressing the effects of inter-species\ncompetition for receptor binding. Our proposed framework captures this\ncompetition, offering a more biologically accurate model for multitarget\nenvironments. By incorporating competition dynamics, the model improves\nunderstanding of MC behavior under interference. This approach enables\nfine-tuning of receptor responses by adjusting ligand concentrations and\nreceptor affinities, thereby optimizing the performance of the Flexure-FET MC\nreceiver. Comprehensive analysis shows that accounting for competitive binding\nis crucial for improving reliability and accuracy in complex MC systems.\nFactors such as signal-to-noise ratio (SNR), symbol error probability (SEP),\ninterferer concentration, and receptor dynamics are shown to significantly\naffect performance. The proposed framework highlights the need to manage these\nfactors effectively. Results demonstrate that modeling interference through\ncompetitive binding offers a realistic system perspective and allows tuning of\nreceiver response, enabling robust detection in environments with multiple\ncoexisting species.",
    "pdf_url": "http://arxiv.org/pdf/2505.22849v1",
    "published": "2025-05-28T20:33:31+00:00",
    "categories": [
      "eess.SP",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2505.22848v2",
    "title": "LiTEx: A Linguistic Taxonomy of Explanations for Understanding Within-Label Variation in Natural Language Inference",
    "authors": [
      "Pingjun Hong",
      "Beiduo Chen",
      "Siyao Peng",
      "Marie-Catherine de Marneffe",
      "Barbara Plank"
    ],
    "abstract": "There is increasing evidence of Human Label Variation (HLV) in Natural\nLanguage Inference (NLI), where annotators assign different labels to the same\npremise-hypothesis pair. However, within-label variation--cases where\nannotators agree on the same label but provide divergent reasoning--poses an\nadditional and mostly overlooked challenge. Several NLI datasets contain\nhighlighted words in the NLI item as explanations, but the same spans on the\nNLI item can be highlighted for different reasons, as evidenced by free-text\nexplanations, which offer a window into annotators' reasoning. To\nsystematically understand this problem and gain insight into the rationales\nbehind NLI labels, we introduce LITEX, a linguistically-informed taxonomy for\ncategorizing free-text explanations. Using this taxonomy, we annotate a subset\nof the e-SNLI dataset, validate the taxonomy's reliability, and analyze how it\naligns with NLI labels, highlights, and explanations. We further assess the\ntaxonomy's usefulness in explanation generation, demonstrating that\nconditioning generation on LITEX yields explanations that are linguistically\ncloser to human explanations than those generated using only labels or\nhighlights. Our approach thus not only captures within-label variation but also\nshows how taxonomy-guided generation for reasoning can bridge the gap between\nhuman and model explanations more effectively than existing strategies.",
    "pdf_url": "http://arxiv.org/pdf/2505.22848v2",
    "published": "2025-05-28T20:32:48+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.22847v1",
    "title": "Sampling Finite Unit Norm Tight Frames Using Symplectic Geometry",
    "authors": [
      "Mason Faldet",
      "Clayton Shonkwiler"
    ],
    "abstract": "Unit-norm tight frames in finite-dimensional Hilbert spaces (FUNTFs) are\nfundamental in signal processing, offering optimal robustness to noise and\nmeasurement loss. In this paper we introduce the Eigenlift algorithm for\nsampling random FUNTFs. Our approach exploits the symplectic geometry of the\nFUNTF space, which we characterize as a symplectic reduction of frame space by\na symmetry group. We then define a Hamiltonian torus action on this reduced\nspace whose momentum map induces a fiber bundle structure. The algorithm\nproceeds by sampling a point from the base space, which is a convex polytope,\nlifting it deterministically to a point on the corresponding fiber, then acting\non this point by a random element of the torus to obtain a random FUNTF. We\nimplement the method in Python and validate it in low-dimensional settings\nwhere it is computationally feasible to sample the base polytope via rejection\nsampling.",
    "pdf_url": "http://arxiv.org/pdf/2505.22847v1",
    "published": "2025-05-28T20:29:03+00:00",
    "categories": [
      "math.FA",
      "math.SG"
    ],
    "primary_category": "math.FA"
  },
  {
    "id": "http://arxiv.org/abs/2505.22846v1",
    "title": "RocqStar: Leveraging Similarity-driven Retrieval and Agentic Systems for Rocq generation",
    "authors": [
      "Nikita Khramov",
      "Andrei Kozyrev",
      "Gleb Solovev",
      "Anton Podkopaev"
    ],
    "abstract": "Interactive Theorem Proving was repeatedly shown to be fruitful combined with\nGenerative Artificial Intelligence. This paper assesses multiple approaches to\nRocq generation and illuminates potential avenues for improvement. We highlight\nthe importance of thorough premise selection for generating Rocq proofs and\npropose a novel approach, leveraging retrieval via a self-attentive embedder\nmodel. The evaluation of the designed approach shows up to 28% relative\nincrease of the generator's performance. We tackle the problem of writing Rocq\nproofs using a multi-stage agentic system, tailored for formal verification,\nand demonstrate its high effectiveness. We conduct an ablation study and show\nthe use of multi-agent debate on the planning stage of proof synthesis.",
    "pdf_url": "http://arxiv.org/pdf/2505.22846v1",
    "published": "2025-05-28T20:26:11+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.LO",
      "cs.SE"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.23848v1",
    "title": "Derailing Non-Answers via Logit Suppression at Output Subspace Boundaries in RLHF-Aligned Language Models",
    "authors": [
      "Harvey Dam",
      "Jonas Knochelmann",
      "Vinu Joseph",
      "Ganesh Gopalakrishnan"
    ],
    "abstract": "We introduce a method to reduce refusal rates of large language models (LLMs)\non sensitive content without modifying model weights or prompts. Motivated by\nthe observation that refusals in certain models were often preceded by the\nspecific token sequence of a token marking the beginning of the\nchain-of-thought (CoT) block (<think>) followed by a double newline token\n(\\n\\n), we investigate the impact of two simple formatting adjustments during\ngeneration: suppressing \\n\\n after <think> and suppressing the end-of-sequence\ntoken after the end of the CoT block (</think>). Our method requires no\ndatasets, parameter changes, or training, relying solely on modifying token\nprobabilities during generation. In our experiments with official DeepSeek-R1\ndistillations, these interventions increased the proportion of substantive\nanswers to sensitive prompts without affecting performance on standard\nbenchmarks. Our findings suggest that refusal behaviors can be circumvented by\nblocking refusal subspaces at specific points in the generation process.",
    "pdf_url": "http://arxiv.org/pdf/2505.23848v1",
    "published": "2025-05-28T20:25:24+00:00",
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.22845v1",
    "title": "Security Benefits and Side Effects of Labeling AI-Generated Images",
    "authors": [
      "Sandra H√∂ltervennhoff",
      "Jonas Ricker",
      "Maike M. Raphael",
      "Charlotte Schwedes",
      "Rebecca Weil",
      "Asja Fischer",
      "Thorsten Holz",
      "Lea Sch√∂nherr",
      "Sascha Fahl"
    ],
    "abstract": "Generative artificial intelligence is developing rapidly, impacting humans'\ninteraction with information and digital media. It is increasingly used to\ncreate deceptively realistic misinformation, so lawmakers have imposed\nregulations requiring the disclosure of AI-generated content. However, only\nlittle is known about whether these labels reduce the risks of AI-generated\nmisinformation.\n  Our work addresses this research gap. Focusing on AI-generated images, we\nstudy the implications of labels, including the possibility of mislabeling.\nAssuming that simplicity, transparency, and trust are likely to impact the\nsuccessful adoption of such labels, we first qualitatively explore users'\nopinions and expectations of AI labeling using five focus groups. Second, we\nconduct a pre-registered online survey with over 1300 U.S. and EU participants\nto quantitatively assess the effect of AI labels on users' ability to recognize\nmisinformation containing either human-made or AI-generated images. Our focus\ngroups illustrate that, while participants have concerns about the practical\nimplementation of labeling, they consider it helpful in identifying\nAI-generated images and avoiding deception. However, considering security\nbenefits, our survey revealed an ambiguous picture, suggesting that users might\nover-rely on labels. While inaccurate claims supported by labeled AI-generated\nimages were rated less credible than those with unlabeled AI-images, the belief\nin accurate claims also decreased when accompanied by a labeled AI-generated\nimage. Moreover, we find the undesired side effect that human-made images\nconveying inaccurate claims were perceived as more credible in the presence of\nlabels.",
    "pdf_url": "http://arxiv.org/pdf/2505.22845v1",
    "published": "2025-05-28T20:24:45+00:00",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CY",
      "cs.SI"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.22844v1",
    "title": "Observation of dispersion anomalies by design",
    "authors": [
      "Mahmoud M. Samak",
      "Osama R. Bilal"
    ],
    "abstract": "Band structures encode electronic, optical, and acoustic properties of matter\nand can serve as an essential tool in material discovery and design. Dispersion\nanomalies -- sharp, non-standard features in the frequency-wavenumber relation\n-- have been historically correlated with phonon-electron coupling or\nlong-range interaction. Through a combination of experimental, numerical, and\nanalytical methods, we show how magnetic couplings can induce negative\nstiffness and sculpt dispersion relations to support zero-frequency phonon\nanomalies at arbitrary, non-zero wavenumbers. Our approach enables the\nrealization of complete wavenumber band gaps without time-modulation,\nelectron-phonon coupling, or long-range interactions. We identify the\nconditions under which non-differentiable zero-frequency phonons exist away\nfrom the high-symmetry points. Our framework generalizes across monoatomic and\ndiatomic lattices, locally resonant metamaterials, non-local systems, as well\nas higher dimensional crystals. In addition, we report the first passive- or\nactive- experimental observation of wavenumber band gaps in higher dimensions.\nOur work establishes a new paradigm in dispersion engineering and provides\nmeans for understanding wave-matter interaction in both the frequency and\nwavenumber domains.",
    "pdf_url": "http://arxiv.org/pdf/2505.22844v1",
    "published": "2025-05-28T20:22:54+00:00",
    "categories": [
      "physics.app-ph"
    ],
    "primary_category": "physics.app-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.22843v2",
    "title": "Aurora: Are Android Malware Classifiers Reliable and Stable under Distribution Shift?",
    "authors": [
      "Alexander Herzog",
      "Aliai Eusebi",
      "Lorenzo Cavallaro"
    ],
    "abstract": "The performance figures of modern drift-adaptive malware classifiers appear\npromising, but does this translate to genuine operational reliability? The\nstandard evaluation paradigm primarily focuses on baseline performance metrics,\nneglecting confidence-error alignment and operational stability. While\nTESSERACT established the importance of temporal evaluation, we take a\ncomplementary direction by investigating whether malware classifiers maintain\nreliable and stable confidence estimates under distribution shifts and\nexploring the tensions between scientific advancement and practical impacts\nwhen they do not. We propose AURORA, a framework to evaluate malware\nclassifiers based on their confidence quality and operational resilience.\nAURORA subjects the confidence profile of a given model to verification to\nassess the reliability of its estimates. Unreliable confidence estimates erode\noperational trust, waste valuable annotation budget on non-informative samples\nfor active learning, and leave error-prone instances undetected in selective\nclassification. AURORA is complemented by a set of metrics designed to go\nbeyond point-in-time performance, striving towards a more holistic assessment\nof operational stability throughout temporal evaluation periods. The fragility\nin SOTA frameworks across datasets of varying drift suggests the need for a\nreturn to the whiteboard.",
    "pdf_url": "http://arxiv.org/pdf/2505.22843v2",
    "published": "2025-05-28T20:22:43+00:00",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.22842v1",
    "title": "Bayesian Attention Mechanism: A Probabilistic Framework for Positional Encoding and Context Length Extrapolation",
    "authors": [
      "Arthur S. Bianchessi",
      "Rodrigo C. Barros",
      "Lucas S. Kupssinsk√º"
    ],
    "abstract": "Transformer-based language models rely on positional encoding (PE) to handle\ntoken order and support context length extrapolation. However, existing PE\nmethods lack theoretical clarity and rely on limited evaluation metrics to\nsubstantiate their extrapolation claims. We propose the Bayesian Attention\nMechanism (BAM), a theoretical framework that formulates positional encoding as\na prior within a probabilistic model. BAM unifies existing methods (e.g., NoPE\nand ALiBi) and motivates a new Generalized Gaussian positional prior that\nsubstantially improves long-context generalization. Empirically, BAM enables\naccurate information retrieval at $500\\times$ the training context length,\noutperforming previous state-of-the-art context length generalization in long\ncontext retrieval accuracy while maintaining comparable perplexity and\nintroducing minimal additional parameters.",
    "pdf_url": "http://arxiv.org/pdf/2505.22842v1",
    "published": "2025-05-28T20:22:23+00:00",
    "categories": [
      "cs.CL",
      "cs.LG",
      "I.2.6; I.2.7"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.22841v1",
    "title": "Kernel-Smoothed Scores for Denoising Diffusion: A Bias-Variance Study",
    "authors": [
      "Franck Gabriel",
      "Fran√ßois Ged",
      "Maria Han Veiga",
      "Emmanuel Schertzer"
    ],
    "abstract": "Diffusion models now set the benchmark in high-fidelity generative sampling,\nyet they can, in principle, be prone to memorization. In this case, their\nlearned score overfits the finite dataset so that the reverse-time SDE samples\nare mostly training points. In this paper, we interpret the empirical score as\na noisy version of the true score and show that its covariance matrix is\nasymptotically a re-weighted data PCA. In large dimension, the small time limit\nmakes the noise variance blow up while simultaneously reducing spatial\ncorrelation. To reduce this variance, we introduce a kernel-smoothed empirical\nscore and analyze its bias-variance trade-off. We derive asymptotic bounds on\nthe Kullback-Leibler divergence between the true distribution and the one\ngenerated by the modified reverse SDE. Regularization on the score has the same\neffect as increasing the size of the training dataset, and thus helps prevent\nmemorization. A spectral decomposition of the forward diffusion suggests better\nvariance control under some regularity conditions of the true data\ndistribution. Reverse diffusion with kernel-smoothed empirical score can be\nreformulated as a gradient descent drifted toward a Log-Exponential\nDouble-Kernel Density Estimator (LED-KDE). This perspective highlights two\nregularization mechanisms taking place in denoising diffusions: an initial\nGaussian kernel first diffuses mass isotropically in the ambient space, while a\nsecond kernel applied in score space concentrates and spreads that mass along\nthe data manifold. Hence, even a straightforward regularization-without any\nlearning-already mitigates memorization and enhances generalization.\nNumerically, we illustrate our results with several experiments on synthetic\nand MNIST datasets.",
    "pdf_url": "http://arxiv.org/pdf/2505.22841v1",
    "published": "2025-05-28T20:22:18+00:00",
    "categories": [
      "cs.LG",
      "math.PR",
      "stat.ML",
      "G.3; I.2.6"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.22840v1",
    "title": "Development and Validation of SXI++ LNM Algorithm for Sepsis Prediction",
    "authors": [
      "Dharambir Mahto",
      "Prashant Yadav",
      "Mahesh Banavar",
      "Jim Keany",
      "Alan T Joseph",
      "Srinivas Kilambi"
    ],
    "abstract": "Sepsis is a life-threatening condition affecting over 48.9 million people\nglobally and causing 11 million deaths annually. Despite medical advancements,\npredicting sepsis remains a challenge due to non-specific symptoms and complex\npathophysiology. The SXI++ LNM is a machine learning scoring system that\nrefines sepsis prediction by leveraging multiple algorithms and deep neural\nnetworks. This study aims to improve robustness in clinical applications and\nevaluates the predictive performance of the SXI++ LNM for sepsis prediction.\nThe model, utilizing a deep neural network, was trained and tested using\nmultiple scenarios with different dataset distributions. The model's\nperformance was assessed against unseen test data, and accuracy, precision, and\narea under the curve (AUC) were calculated. THE SXI++ LNM outperformed the\nstate of the art in three use cases, achieving an AUC of 0.99 (95% CI:\n0.98-1.00). The model demonstrated a precision of 99.9% (95% CI: 99.8-100.0)\nand an accuracy of 99.99% (95% CI: 99.98-100.0), maintaining high reliability.",
    "pdf_url": "http://arxiv.org/pdf/2505.22840v1",
    "published": "2025-05-28T20:20:35+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.22839v1",
    "title": "How Do Diffusion Models Improve Adversarial Robustness?",
    "authors": [
      "Liu Yuezhang",
      "Xue-Xin Wei"
    ],
    "abstract": "Recent findings suggest that diffusion models significantly enhance empirical\nadversarial robustness. While some intuitive explanations have been proposed,\nthe precise mechanisms underlying these improvements remain unclear. In this\nwork, we systematically investigate how and how well diffusion models improve\nadversarial robustness. First, we observe that diffusion models intriguingly\nincrease, rather than decrease, the $\\ell_p$ distance to clean\nsamples--challenging the intuition that purification denoises inputs closer to\nthe original data. Second, we find that the purified images are heavily\ninfluenced by the internal randomness of diffusion models, where a compression\neffect arises within each randomness configuration. Motivated by this\nobservation, we evaluate robustness under fixed randomness and find that the\nimprovement drops to approximately 24% on CIFAR-10--substantially lower than\nprior reports approaching 70%. Importantly, we show that this remaining\nrobustness gain strongly correlates with the model's ability to compress the\ninput space, revealing the compression rate as a reliable robustness indicator\nwithout requiring gradient-based analysis. Our findings provide novel insights\ninto the mechanisms underlying diffusion-based purification, and offer guidance\nfor developing more effective and principled adversarial purification systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.22839v1",
    "published": "2025-05-28T20:19:21+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.22838v1",
    "title": "A Unified Treatment of Some Classic Combinatorial Inequalities Using the Variance Method",
    "authors": [
      "Douglas R. Stinson"
    ],
    "abstract": "The \"variance method\" has been used to prove many classical inequalities in\ndesign theory and coding theory. The purpose of this expository note is to\nreview and present some of these inequalities in a unified setting. I will also\ndiscuss some examples from my own research where I have employed these\ntechniques.",
    "pdf_url": "http://arxiv.org/pdf/2505.22838v1",
    "published": "2025-05-28T20:17:09+00:00",
    "categories": [
      "math.CO",
      "05B05"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.22837v1",
    "title": "Quantum Reservoir Computing for Corrosion Prediction in Aerospace: A Hybrid Approach for Enhanced Material Degradation Forecasting",
    "authors": [
      "Akshat Tandon",
      "James Brown",
      "Kenny Heitritter",
      "Tarini Hardikar",
      "Kanav Setia",
      "Rene Boettcher",
      "Klaus Schertler",
      "Jasper Simon Krauser"
    ],
    "abstract": "The prediction of material degradation is an important problem to solve in\nmany industries. Environmental conditions, such as humidity and temperature,\nare important drivers of degradation processes, with corrosion being one of the\nmost prominent ones. Quantum machine learning is a promising research field but\nsuffers from well known deficits such as barren plateaus and measurement\noverheads. To address this problem, recent research has examined quantum\nreservoir computing to address time-series prediction tasks. Although a\npromising idea, developing circuits that are expressive enough while respecting\nthe limited depths available on current devices is challenging. In classical\nreservoir computing, the onion echo state network model (ESN)\n[https://doi.org/10.1007/978-3-031-72359-9_9] was introduced to increase the\ninterpretability of the representation structure of the embeddings. This onion\nESN model utilizes a concatenation of smaller reservoirs that describe\ndifferent time scales by covering different regions of the eigenvalue spectrum.\nHere, we use the same idea in the realm of quantum reservoir computing by\nsimultaneously evolving smaller quantum reservoirs to better capture all the\nrelevant time-scales while keeping the circuit depth small. We do this by\nmodifying the rotation angles which we show alters the eigenvalues of the\nquantum evolution, but also note that modifying the number of mid-circuit\nmeasurements accomplishes the same goals of changing the long-term or\nshort-term memory. This onion QRC outperforms a simple model and a single\nclassical reservoir for predicting the degradation of aluminum alloys in\ndifferent environmental conditions. By combining the onion QRC with an\nadditional classical reservoir layer, the prediction accuracy is further\nimproved.",
    "pdf_url": "http://arxiv.org/pdf/2505.22837v1",
    "published": "2025-05-28T20:16:20+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.22836v1",
    "title": "Model-Free Deep Hedging with Transaction Costs and Light Data Requirements",
    "authors": [
      "Pierre Brugi√®re",
      "Gabriel Turinici"
    ],
    "abstract": "Option pricing theory, such as the Black and Scholes (1973) model, provides\nan explicit solution to construct a strategy that perfectly hedges an option in\na continuous-time setting. In practice, however, trading occurs in discrete\ntime and often involves transaction costs, making the direct application of\ncontinuous-time solutions potentially suboptimal. Previous studies, such as\nthose by Buehler et al. (2018), Buehler et al. (2019) and Cao et al. (2019),\nhave shown that deep learning or reinforcement learning can be used to derive\nbetter hedging strategies than those based on continuous-time models. However,\nthese approaches typically rely on a large number of trajectories (of the order\nof $10^5$ or $10^6$) to train the model. In this work, we show that using as\nfew as 256 trajectories is sufficient to train a neural network that\nsignificantly outperforms, in the Geometric Brownian Motion framework, both the\nclassical Black & Scholes formula and the Leland model, which is arguably one\nof the most effective explicit alternatives for incorporating transaction\ncosts. The ability to train neural networks with such a small number of\ntrajectories suggests the potential for more practical and simple\nimplementation on real-time financial series.",
    "pdf_url": "http://arxiv.org/pdf/2505.22836v1",
    "published": "2025-05-28T20:16:07+00:00",
    "categories": [
      "q-fin.MF",
      "q-fin.ST"
    ],
    "primary_category": "q-fin.MF"
  },
  {
    "id": "http://arxiv.org/abs/2505.22835v1",
    "title": "Computing higher direct images in Macaulay2",
    "authors": [
      "Sasha Zotine"
    ],
    "abstract": "This article highlights the ToricHigherDirectImages package in Macaulay2. The\ncentral feature is a method for computing (higher) direct images of line\nbundles under surjective toric morphisms.",
    "pdf_url": "http://arxiv.org/pdf/2505.22835v1",
    "published": "2025-05-28T20:15:22+00:00",
    "categories": [
      "math.AG",
      "13-04 (Primary), 14Q15, 14F08, 14M25 (Secondary)"
    ],
    "primary_category": "math.AG"
  },
  {
    "id": "http://arxiv.org/abs/2505.22834v1",
    "title": "Counterfactuals in Macroscopic Quantum Physics: Irreversibility, Measurement and Locality",
    "authors": [
      "Maria Violaris"
    ],
    "abstract": "Can quantum theory be applied on all scales? While there are many arguments\nfor the universality of quantum theory, this question remains a subject of\ndebate. It is unknown how far the existence of macroscopic irreversibility can\nbe derived from or reconciled with time-reversal symmetric quantum dynamics.\nFurthermore, reasoning about quantum measurements can appear to produce\nsurprising and even paradoxical outcomes. The classical outcomes of quantum\nmeasurements are in some contexts deemed to violate the fundamental principle\nof locality, in particular when considering entanglement and Bell non-locality.\nTherefore measurement, irreversibility and locality can all appear to challenge\nthe universality of quantum theory. In this thesis we approach these problems\nusing counterfactuals -- statements about the possibility and impossibility of\ntransformations. Using the principles of constructor theory and quantum\ninformation theory, we find novel features of quantum thermodynamics relating\nto irreversibility, information erasure and coherence. We also develop tools to\nquantify the full implications of non-commutativity of quantum operators in\nsettings where quantum theory is applied universally to measurement devices.\nThis reveals new ways of characterising the quantum information stored in\nentanglement and quantum branching structure. Our results reinforce the ability\nof universal quantum theory to consistently describe both microscopic and\nmacroscopic observers and thermodynamic systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.22834v1",
    "published": "2025-05-28T20:14:17+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.22833v1",
    "title": "Enhanced Excited State Population and Coherence via Adiabatic Tunneling Ionization and Excitation",
    "authors": [
      "Chi-Hong Yuen"
    ],
    "abstract": "Tunneling ionization followed by strong-field excitation leads to important\nultrafast phenomena such as charge migration and lasing. Recent theoretical\ndevelopments suggest that the population of the ionic excited state can be\ngreatly enhanced due to the complex interplay between tunneling and excitation.\nIn this Letter, using an adiabatic approach for both tunneling and excitation,\nsemi-analytical solutions are derived for the population and coherence of a\ntwo-level ionic system. This approach removes the strong-field dressing,\nrevealing novel sub-half-cycle processes for excited state population and\ncoherence buildup. It predicts that the excited state population is enhanced by\nan order of magnitude, independent of the laser wavelength, while coherence\namplitude can be boosted by over four orders of magnitude for a multi-cycle\npulse. For a single-cycle pulse, it suggests that coherence amplitude decreases\nrapidly as the wavelength increases. This work introduces a novel framework for\ngenerating and controlling the electronic excited state and coherence using\nintense laser pulses, with applications in strong-field control of chemistry\nand lasing.",
    "pdf_url": "http://arxiv.org/pdf/2505.22833v1",
    "published": "2025-05-28T20:13:56+00:00",
    "categories": [
      "quant-ph",
      "physics.atom-ph",
      "physics.chem-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.22832v1",
    "title": "2-Segal sets and pseudomonoids in the bicategory of spans",
    "authors": [
      "Sophia E Marx",
      "Rajan Amit Mehta"
    ],
    "abstract": "In this survey article, we give an introduction to the notion of a 2-Segal\nset and prove that 2-Segal sets are equivalent to pseudomonoids in the\nbicategory of spans. The proof utilizes graphical techniques for 2-Segal sets\nand spans that should be useful in more general settings.\n  There are procedures for obtaining an associative algebra from a 2-Segal set\n(satisfying finiteness conditions). We describe these procedures and give\nseveral examples of algebras arising from 2-Segal sets.\n  Wherever possible, we avoid higher category theory so as to make the paper\naccessible to a wide audience.",
    "pdf_url": "http://arxiv.org/pdf/2505.22832v1",
    "published": "2025-05-28T20:13:44+00:00",
    "categories": [
      "math.CT",
      "math.AT",
      "18B10, 18B40, 18C40, 18N50"
    ],
    "primary_category": "math.CT"
  },
  {
    "id": "http://arxiv.org/abs/2505.22831v1",
    "title": "Orca: Browsing at Scale Through User-Driven and AI-Facilitated Orchestration Across Malleable Webpages",
    "authors": [
      "Peiling Jiang",
      "Haijun Xia"
    ],
    "abstract": "Web-based activities are fundamentally distributed across webpages. However,\nconventional browsers with stacks of tabs fail to support operating and\nsynthesizing large volumes of information across pages. While recent AI systems\nenable fully automated web browsing and information synthesis, they often\ndiminish user agency and hinder contextual understanding. Therefore, we explore\nhow AI could instead augment users' interactions with content across webpages\nand mitigate cognitive and manual efforts. Through literature on information\ntasks and web browsing challenges, and an iterative design process, we present\na rich set of novel interactions with our prototype web browser, Orca.\nLeveraging AI, Orca supports user-driven exploration, operation, organization,\nand synthesis of web content at scale. To enable browsing at scale, webpages\nare treated as malleable materials that humans and AI can collaboratively\nmanipulate and compose into a malleable, dynamic, and browser-level workspace.\nOur evaluation revealed an increased \"appetite\" for information foraging,\nenhanced user control, and more flexibility in sensemaking across a broader\ninformation landscape on the web.",
    "pdf_url": "http://arxiv.org/pdf/2505.22831v1",
    "published": "2025-05-28T20:13:39+00:00",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2505.22830v2",
    "title": "What Has Been Lost with Synthetic Evaluation?",
    "authors": [
      "Alexander Gill",
      "Abhilasha Ravichander",
      "Ana Marasoviƒá"
    ],
    "abstract": "Large language models (LLMs) are increasingly used for data generation.\nHowever, creating evaluation benchmarks raises the bar for this emerging\nparadigm. Benchmarks must target specific phenomena, penalize exploiting\nshortcuts, and be challenging. Through two case studies, we investigate whether\nLLMs can meet these demands by generating reasoning over-text benchmarks and\ncomparing them to those created through careful crowdsourcing. Specifically, we\nevaluate both the validity and difficulty of LLM-generated versions of two\nhigh-quality reading comprehension datasets: CondaQA, which evaluates reasoning\nabout negation, and DROP, which targets reasoning about quantities. We find\nthat prompting LLMs can produce variants of these datasets that are often valid\naccording to the annotation guidelines, at a fraction of the cost of the\noriginal crowdsourcing effort. However, we show that they are less challenging\nfor LLMs than their human-authored counterparts. This finding sheds light on\nwhat may have been lost by generating evaluation data with LLMs, and calls for\ncritically reassessing the immediate use of this increasingly prevalent\napproach to benchmark creation.",
    "pdf_url": "http://arxiv.org/pdf/2505.22830v2",
    "published": "2025-05-28T20:12:32+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.22829v1",
    "title": "Bridging Distribution Shift and AI Safety: Conceptual and Methodological Synergies",
    "authors": [
      "Chenruo Liu",
      "Kenan Tang",
      "Yao Qin",
      "Qi Lei"
    ],
    "abstract": "This paper bridges distribution shift and AI safety through a comprehensive\nanalysis of their conceptual and methodological synergies. While prior\ndiscussions often focus on narrow cases or informal analogies, we establish two\ntypes connections between specific causes of distribution shift and\nfine-grained AI safety issues: (1) methods addressing a specific shift type can\nhelp achieve corresponding safety goals, or (2) certain shifts and safety\nissues can be formally reduced to each other, enabling mutual adaptation of\ntheir methods. Our findings provide a unified perspective that encourages\nfundamental integration between distribution shift and AI safety research.",
    "pdf_url": "http://arxiv.org/pdf/2505.22829v1",
    "published": "2025-05-28T20:11:30+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.22828v1",
    "title": "The range of the des statistic for conjugacy classes in $S_n$",
    "authors": [
      "Yisca Kares"
    ],
    "abstract": "We determine the range of the des statistic on every conjugacy class in the\nsymmetric group $S_n$, prove that the minimum is $1$ (except for the identity\nclass), and show that every intermediate value from $1$ to the maximum value is\nattained. We also demonstrate a constructive method to achieve every value in\nthe range and discuss its combinatorial implications.",
    "pdf_url": "http://arxiv.org/pdf/2505.22828v1",
    "published": "2025-05-28T20:11:03+00:00",
    "categories": [
      "math.CO"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2506.04242v1",
    "title": "Linear instability of plane Couette and Poiseuille flows",
    "authors": [
      "Sergey G. Chefranov",
      "Alexander G. Chefranov"
    ],
    "abstract": "It is shown that linear instability of plane Couette flow can take place even\nat finite Reynolds numbers which meets with known experimental data. This new\nresult of the linear theory of hydrodynamic stability is obtained only due by\nabandoning traditional assumption of the longitudinal periodicity of\ndisturbances in the flow direction.",
    "pdf_url": "http://arxiv.org/pdf/2506.04242v1",
    "published": "2025-05-28T20:10:39+00:00",
    "categories": [
      "physics.flu-dyn"
    ],
    "primary_category": "physics.flu-dyn"
  },
  {
    "id": "http://arxiv.org/abs/2505.22827v1",
    "title": "Learning-Based Robust Fixed-Time Terminal Sliding Mode Control",
    "authors": [
      "Chaimae El Mortajinea",
      "Moussa Labbadib",
      "Adnane Saoudc",
      "Mostafa Bouzia"
    ],
    "abstract": "In this paper, we develop and analyze an integral fixed-time sliding mode\ncontrol method for a scenario in which the system model is only partially\nknown, utilizing Gaussian processes. We present two theorems on fixed-time\nconvergence. The first theorem addresses the fully known system model, while\nthe second considers situations where the system's drift is approximated\nutilizing Gaussian processes (GP) for approximating unknown dynamics. Both\ntheorems establish the global fixed-time stability of the closed-loop system.\nThe stability analysis is based on a straightforward quadratic Lyapunov\nfunction. Our proposed method outperforms an established adaptive fixed-time\nsliding mode control approach, especially when ample training data is\navailable.",
    "pdf_url": "http://arxiv.org/pdf/2505.22827v1",
    "published": "2025-05-28T20:10:23+00:00",
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2505.22826v1",
    "title": "Assembly in Directed Hypergraphs",
    "authors": [
      "Christoph Flamm",
      "Daniel Merkle",
      "Peter F. Stadler"
    ],
    "abstract": "Assembly theory has received considerable attention in the recent past. Here\nwe analyze the formal framework of this model and show that assembly pathways\ncoincide with certain minimal hyperpaths in B-hypergraphs. This makes it\npossible to generalize the notion of assembly to general chemical reaction\nsystems and to make explicit the connection to rule based models of chemistry,\nin particular DPO graph rewriting. We observe, furthermore, that assembly\ntheory is closely related to retrosynthetic analysis in chemistry. The assembly\nindex fits seamlessly into a large family of cost measures for directed\nhyperpath problems that also encompasses cost functions used in computational\nsynthesis planning. This allows to devise a generic approach to compute\ncomplexity measures derived from minimal hyperpaths in rule-derived directed\nhypergraphs using integer linear programming.",
    "pdf_url": "http://arxiv.org/pdf/2505.22826v1",
    "published": "2025-05-28T20:10:22+00:00",
    "categories": [
      "cs.DM"
    ],
    "primary_category": "cs.DM"
  },
  {
    "id": "http://arxiv.org/abs/2505.22825v1",
    "title": "PGLearn -- An Open-Source Learning Toolkit for Optimal Power Flow",
    "authors": [
      "Michael Klamkin",
      "Mathieu Tanneau",
      "Pascal Van Hentenryck"
    ],
    "abstract": "Machine Learning (ML) techniques for Optimal Power Flow (OPF) problems have\nrecently garnered significant attention, reflecting a broader trend of\nleveraging ML to approximate and/or accelerate the resolution of complex\noptimization problems. These developments are necessitated by the increased\nvolatility and scale in energy production for modern and future grids. However,\nprogress in ML for OPF is hindered by the lack of standardized datasets and\nevaluation metrics, from generating and solving OPF instances, to training and\nbenchmarking machine learning models. To address this challenge, this paper\nintroduces PGLearn, a comprehensive suite of standardized datasets and\nevaluation tools for ML and OPF. PGLearn provides datasets that are\nrepresentative of real-life operating conditions, by explicitly capturing both\nglobal and local variability in the data generation, and by, for the first\ntime, including time series data for several large-scale systems. In addition,\nit supports multiple OPF formulations, including AC, DC, and second-order cone\nformulations. Standardized datasets are made publicly available to democratize\naccess to this field, reduce the burden of data generation, and enable the fair\ncomparison of various methodologies. PGLearn also includes a robust toolkit for\ntraining, evaluating, and benchmarking machine learning models for OPF, with\nthe goal of standardizing performance evaluation across the field. By promoting\nopen, standardized datasets and evaluation metrics, PGLearn aims at\ndemocratizing and accelerating research and innovation in machine learning\napplications for optimal power flow problems. Datasets are available for\ndownload at https://www.huggingface.co/PGLearn.",
    "pdf_url": "http://arxiv.org/pdf/2505.22825v1",
    "published": "2025-05-28T20:10:04+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SY",
      "eess.SY",
      "math.OC"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.22824v1",
    "title": "Constrained Hamiltonian Systems on Observation-Induced Fiber Bundles: Theory of Symmetry and Integrability",
    "authors": [
      "Dongzhe Zheng"
    ],
    "abstract": "Classical constrained Hamiltonian theory assumes complete observability of\nsystem states, but in reality only partial state information is often\navailable. This paper establishes a complete geometric theoretical framework\nfor handling such incompletely observed systems. By introducing the concept of\nobservation-induced fiber bundles, we naturally extend Dirac constraint theory\nto the fiber bundle setting, unifying the treatment of state constraints and\nobservation constraints. Main results include: (1) Classification of existence\nconditions for observation fiber bundles based on characteristic class theory;\n(2) Complete characterization of Poisson structures on fiber bundles and\ncorresponding symplectic reduction theory; (3) Geometric necessary and\nsufficient conditions for integrability and Lax pair construction; (4)\nExtension of Noether's theorem under symmetry group actions. The theoretical\nframework naturally encompasses a wide range of applications from classical\nmechanics to modern safety-critical control systems, providing a rigorous\nmathematical foundation for dynamical analysis under incomplete information.",
    "pdf_url": "http://arxiv.org/pdf/2505.22824v1",
    "published": "2025-05-28T20:09:45+00:00",
    "categories": [
      "math.GM",
      "53D05, 37J15, 37J35, 53C05, 70H45, 58A30"
    ],
    "primary_category": "math.GM"
  },
  {
    "id": "http://arxiv.org/abs/2505.22823v2",
    "title": "Self-Critique and Refinement for Faithful Natural Language Explanations",
    "authors": [
      "Yingming Wang",
      "Pepa Atanasova"
    ],
    "abstract": "With the rapid development of Large Language Models (LLMs), Natural Language\nExplanations (NLEs) have become increasingly important for understanding model\npredictions. However, these explanations often fail to faithfully represent the\nmodel's actual reasoning process. While existing work has demonstrated that\nLLMs can self-critique and refine their initial outputs for various tasks, this\ncapability remains unexplored for improving explanation faithfulness. To\naddress this gap, we introduce Self-critique and Refinement for Natural\nLanguage Explanations (SR-NLE), a framework that enables models to improve the\nfaithfulness of their own explanations -- specifically, post-hoc NLEs --\nthrough an iterative critique and refinement process without external\nsupervision. Our framework leverages different feedback mechanisms to guide the\nrefinement process, including natural language self-feedback and, notably, a\nnovel feedback approach based on feature attribution that highlights important\ninput words. Our experiments across three datasets and four state-of-the-art\nLLMs demonstrate that SR-NLE significantly reduces unfaithfulness rates, with\nour best method achieving an average unfaithfulness rate of 36.02%, compared to\n54.81% for baseline -- an absolute reduction of 18.79%. These findings reveal\nthat the investigated LLMs can indeed refine their explanations to better\nreflect their actual reasoning process, requiring only appropriate guidance\nthrough feedback without additional training or fine-tuning.",
    "pdf_url": "http://arxiv.org/pdf/2505.22823v2",
    "published": "2025-05-28T20:08:42+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.22822v1",
    "title": "traccc: GPU track reconstruction library for HEP experiments",
    "authors": [
      "Paul Gessinger",
      "Heather M. Gray",
      "Attila Krasznahorkay",
      "Charles Leggett",
      "Joana Niermann",
      "Andreas Salzburger",
      "Stephen Nicholas Swatman",
      "Beomki Yeo"
    ],
    "abstract": "We present the current development status and progress of traccc, a GPU track\nreconstruction library developed in the context of the A Common Tracking\nSoftware (ACTS) project. traccc implements tracking algorithms used in high\nenergy physics (HEP) experiments, including the Kalman filter based track\nfinding and fitting. We benchmark the software with data simulated by Geant4 to\nmeasure the physics and computing performance. We show that the physics\nperformance for GPU and CPU are very close. We also show that the GPUs can\nachieve higher computational performance than the CPU for sufficiently large\nevents.",
    "pdf_url": "http://arxiv.org/pdf/2505.22822v1",
    "published": "2025-05-28T20:00:51+00:00",
    "categories": [
      "hep-ex"
    ],
    "primary_category": "hep-ex"
  },
  {
    "id": "http://arxiv.org/abs/2505.22821v1",
    "title": "Simple Classes of Automatic Structures",
    "authors": [
      "Achim Blumensath"
    ],
    "abstract": "We study two subclasses of the class of automatic structures: automatic\nstructures of polynomial growth and Presburger structures. We present algebraic\ncharacterisations of the groups and the equivalence structures in these two\nclasses.",
    "pdf_url": "http://arxiv.org/pdf/2505.22821v1",
    "published": "2025-05-28T19:59:53+00:00",
    "categories": [
      "cs.LO",
      "math.LO"
    ],
    "primary_category": "cs.LO"
  },
  {
    "id": "http://arxiv.org/abs/2505.22820v1",
    "title": "Preference Learning with Response Time",
    "authors": [
      "Ayush Sawarni",
      "Sahasrajit Sarmasarkar",
      "Vasilis Syrgkanis"
    ],
    "abstract": "This paper investigates the integration of response time data into human\npreference learning frameworks for more effective reward model elicitation.\nWhile binary preference data has become fundamental in fine-tuning foundation\nmodels, generative AI systems, and other large-scale models, the valuable\ntemporal information inherent in user decision-making remains largely\nunexploited. We propose novel methodologies to incorporate response time\ninformation alongside binary choice data, leveraging the Evidence Accumulation\nDrift Diffusion (EZ) model, under which response time is informative of the\npreference strength. We develop Neyman-orthogonal loss functions that achieve\noracle convergence rates for reward model learning, matching the theoretical\noptimal rates that would be attained if the expected response times for each\nquery were known a priori. Our theoretical analysis demonstrates that for\nlinear reward functions, conventional preference learning suffers from error\nrates that scale exponentially with reward magnitude. In contrast, our response\ntime-augmented approach reduces this to polynomial scaling, representing a\nsignificant improvement in sample efficiency. We extend these guarantees to\nnon-parametric reward function spaces, establishing convergence properties for\nmore complex, realistic reward models. Our extensive experiments validate our\ntheoretical findings in the context of preference learning over images.",
    "pdf_url": "http://arxiv.org/pdf/2505.22820v1",
    "published": "2025-05-28T19:55:54+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.22819v4",
    "title": "Three New Identities Linking Bernoulli Numbers, Bessel Numbers, and Stirling Numbers",
    "authors": [
      "Abdelhay Benmoussa"
    ],
    "abstract": "We give three new identities which connects Bernoulli numbers, Bessel\nnumbers, and Stirling numbers. The proof proceeds via an operational identity\nfor $(x^{-1}D)^n$, an expansion of a quadratic-step product in the falling\nfactorial basis, and coefficient extraction using Faulhaber's formula and\nStirling numbers of the first kind.",
    "pdf_url": "http://arxiv.org/pdf/2505.22819v4",
    "published": "2025-05-28T19:55:05+00:00",
    "categories": [
      "math.GM",
      "11B68, 05A18, 11B73, 33C10"
    ],
    "primary_category": "math.GM"
  },
  {
    "id": "http://arxiv.org/abs/2505.22818v1",
    "title": "A Tool for Generating Exceptional Behavior Tests With Large Language Models",
    "authors": [
      "Linghan Zhong",
      "Samuel Yuan",
      "Jiyang Zhang",
      "Yu Liu",
      "Pengyu Nie",
      "Junyi Jessy Li",
      "Milos Gligoric"
    ],
    "abstract": "Exceptional behavior tests (EBTs) are crucial in software development for\nverifying that code correctly handles unwanted events and throws appropriate\nexceptions. However, prior research has shown that developers often prioritize\ntesting \"happy paths\", e.g., paths without unwanted events over exceptional\nscenarios. We present exLong, a framework that automatically generates EBTs to\naddress this gap. exLong leverages a large language model (LLM) fine-tuned from\nCodeLlama and incorporates reasoning about exception-throwing traces,\nconditional expressions that guard throw statements, and non-exceptional\nbehavior tests that execute similar traces. Our demonstration video illustrates\nhow exLong can effectively assist developers in creating comprehensive EBTs for\ntheir project (available at https://youtu.be/Jro8kMgplZk).",
    "pdf_url": "http://arxiv.org/pdf/2505.22818v1",
    "published": "2025-05-28T19:53:20+00:00",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE"
  },
  {
    "id": "http://arxiv.org/abs/2505.22817v1",
    "title": "Enhanced Stability and Linearly Polarized Emission from CsPbI$_3$ Perovskite Nanoplatelets through A-site Cation Engineering",
    "authors": [
      "Woo Hyeon Jeong",
      "Junzhi Ye",
      "Jongbeom Kim",
      "Rui Xu",
      "Xinyu Shen",
      "Chia-Yu Chang",
      "Eilidh L. Quinn",
      "Myoung Hoon Song",
      "Peter Nellist",
      "Henry J. Snaith",
      "Yunwei Zhang",
      "Bo Ram Lee",
      "Robert L. Z. Hoye"
    ],
    "abstract": "The anisotropy of perovskite nanoplatelets (PeNPLs) opens up many\nopportunities in optoelectronics, including enabling the emission of linearly\npolarized light. But the limited stability of PeNPLs is a pressing challenge,\nespecially for red-emitting CsPbI$_3$. Herein, we address this limitation by\nalloying FA into the perovskite cuboctahedral site. Unlike Cs/FA alloying in\nbulk thin films or nonconfined nanocubes, FA incorporation in nanoplatelets\nrequires meticulous control over the reaction conditions, given that\nnanoplatelets are obtained in kinetically-driven growth regimes instead of\nthermodynamically-driven conditions. Through in-situ photoluminescence (PL)\nmeasurements, we find that excess FA leads to uncontrolled growth, where\nphase-impurities and nanoplatelets of multiple thicknesses co-exist.\nRestricting the FA content to up to 25% Cs substitution enables monodisperse\nPeNPLs, and increases the PL quantum yield (from 53% to 61%), exciton lifetime\n(from 18 ns to 27 ns), and stability in ambient air (from ~2 days to >7 days)\ncompared to CsPbI$_3$. This arises due to hydrogen bonding between FA and the\noleate and oleylammonium ligands, anchoring them to the surface to improve\noptoelectronic properties and stability. The reduction in non-radiative\nrecombination, improvement in the nanoplatelet aspect ratio, and higher ligand\ndensity lead to FA-containing PeNPLs more effectively forming edge-up\nsuperlattices, enhancing the PL degree of linear polarization from 5.1%\n(CsPbI$_3$) to 9.4% (Cs$_{0.75}$FA$_{0.25}$PbI$_3$). These fundamental insights\nshow how the stability limitations of PeNPLs could be addressed, and these\nmaterials grown more precisely to improve their performance as polarized light\nemitters, critical for utilizing them in next-generation display, bioimaging\nand communications applications.",
    "pdf_url": "http://arxiv.org/pdf/2505.22817v1",
    "published": "2025-05-28T19:52:20+00:00",
    "categories": [
      "cond-mat.mtrl-sci",
      "physics.app-ph"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2505.22816v1",
    "title": "Provably Efficient Quantum Thermal State Preparation via Local Driving",
    "authors": [
      "Dominik Hahn",
      "S. A. Parameswaran",
      "Benedikt Placke"
    ],
    "abstract": "Preparing the thermal density matrix $\\rho_{\\beta}\\propto e^{-\\beta H}$\ncorresponding to a given Hamiltonian $H$ is a task of central interest across\nquantum many-body physics, and is particularly salient when attempting to study\nit with quantum computers. Although solved {in principle} by recent\nconstructions of efficiently simulable Lindblad master equations -- that\nprovably have $\\rho_{\\beta}$ as a steady state [C.-F. Chen {\\it et al},\narXiv:2311.09207] -- their implementation requires large-scale quantum\ncomputational resources and is hence challenging {in practice} on current or\neven near-term quantum devices. Here, we propose a scheme for approximately\npreparing quantum thermal states that only requires the [repeated]\nimplementation of three readily available ingredients: (a) analog simulation of\n$H$; (b) strictly local but time-dependent couplings to ancilla qubits; and (c)\nreset of the ancillas. We give rigorous performance guarantees independent of\ndetailed physical knowledge of $H$ beyond its locality.",
    "pdf_url": "http://arxiv.org/pdf/2505.22816v1",
    "published": "2025-05-28T19:48:07+00:00",
    "categories": [
      "quant-ph",
      "cond-mat.other",
      "cond-mat.stat-mech",
      "math-ph",
      "math.MP"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.06321v1",
    "title": "On the Interplay of Privacy, Persuasion and Quantization",
    "authors": [
      "Anju Anand",
      "Emrah Akyol"
    ],
    "abstract": "We develop a communication-theoretic framework for privacy-aware and\nresilient decision making in cyber-physical systems under misaligned objectives\nbetween the encoder and the decoder. The encoder observes two correlated\nsignals ($X$,$\\theta$) and transmits a finite-rate message $Z$ to aid a\nlegitimate controller (the decoder) in estimating $X+\\theta$, while an\neavesdropper intercepts $Z$ to infer the private parameter $\\theta$. Unlike\nconventional setups where encoder and decoder share a common MSE objective,\nhere the encoder minimizes a Lagrangian that balances legitimate control\nfidelity and the privacy leakage about $\\theta$. In contrast, the decoder's\ngoal is purely to minimize its own estimation error without regard for privacy.\nWe analyze fully, partially, and non-revealing strategies that arise from this\nconflict, and characterize optimal linear encoders when the rate constraints\nare lifted. For finite-rate channels, we employ gradient-based methods to\ncompute the optimal controllers. Numerical experiments illustrate how tuning\nthe privacy parameter shapes the trade-off between control performance and\nresilience against unauthorized inferences.",
    "pdf_url": "http://arxiv.org/pdf/2506.06321v1",
    "published": "2025-05-28T19:44:31+00:00",
    "categories": [
      "eess.SP",
      "cs.GT",
      "cs.IT",
      "cs.SY",
      "eess.SY",
      "math.IT"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2505.22815v2",
    "title": "IMTS is Worth Time $\\times$ Channel Patches: Visual Masked Autoencoders for Irregular Multivariate Time Series Prediction",
    "authors": [
      "Zhangyi Hu",
      "Jiemin Wu",
      "Hua Xu",
      "Mingqian Liao",
      "Ninghui Feng",
      "Bo Gao",
      "Songning Lai",
      "Yutao Yue"
    ],
    "abstract": "Irregular Multivariate Time Series (IMTS) forecasting is challenging due to\nthe unaligned nature of multi-channel signals and the prevalence of extensive\nmissing data. Existing methods struggle to capture reliable temporal patterns\nfrom such data due to significant missing values. While pre-trained foundation\nmodels show potential for addressing these challenges, they are typically\ndesigned for Regularly Sampled Time Series (RTS). Motivated by the visual Mask\nAutoEncoder's (MAE) powerful capability for modeling sparse multi-channel\ninformation and its success in RTS forecasting, we propose VIMTS, a framework\nadapting Visual MAE for IMTS forecasting. To mitigate the effect of missing\nvalues, VIMTS first processes IMTS along the timeline into feature patches at\nequal intervals. These patches are then complemented using learned\ncross-channel dependencies. Then it leverages visual MAE's capability in\nhandling sparse multichannel data for patch reconstruction, followed by a\ncoarse-to-fine technique to generate precise predictions from focused contexts.\nIn addition, we integrate self-supervised learning for improved IMTS modeling\nby adapting the visual MAE to IMTS data. Extensive experiments demonstrate\nVIMTS's superior performance and few-shot capability, advancing the application\nof visual foundation models in more general time series tasks. Our code is\navailable at https://github.com/WHU-HZY/VIMTS.",
    "pdf_url": "http://arxiv.org/pdf/2505.22815v2",
    "published": "2025-05-28T19:44:03+00:00",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.22814v2",
    "title": "A Large Language Model-Enabled Control Architecture for Dynamic Resource Capability Exploration in Multi-Agent Manufacturing Systems",
    "authors": [
      "Jonghan Lim",
      "Ilya Kovalenko"
    ],
    "abstract": "Manufacturing environments are becoming more complex and unpredictable due to\nfactors such as demand variations and shorter product lifespans. This\ncomplexity requires real-time decision-making and adaptation to disruptions.\nTraditional control approaches highlight the need for advanced control\nstrategies capable of overcoming unforeseen challenges, as they demonstrate\nlimitations in responsiveness within dynamic industrial settings. Multi-agent\nsystems address these challenges through decentralization of decision-making,\nenabling systems to respond dynamically to operational changes. However,\ncurrent multi-agent systems encounter challenges related to real-time\nadaptation, context-aware decision-making, and the dynamic exploration of\nresource capabilities. Large language models provide the possibility to\novercome these limitations through context-aware decision-making capabilities.\nThis paper introduces a large language model-enabled control architecture for\nmulti-agent manufacturing systems to dynamically explore resource capabilities\nin response to real-time disruptions. A simulation-based case study\ndemonstrates that the proposed architecture improves system resilience and\nflexibility. The case study findings show improved throughput and efficient\nresource utilization compared to existing approaches.",
    "pdf_url": "http://arxiv.org/pdf/2505.22814v2",
    "published": "2025-05-28T19:43:12+00:00",
    "categories": [
      "cs.MA",
      "cs.AI"
    ],
    "primary_category": "cs.MA"
  },
  {
    "id": "http://arxiv.org/abs/2505.22813v2",
    "title": "X-Factor: Quality Is a Dataset-Intrinsic Property",
    "authors": [
      "Josiah Couch",
      "Miao Li",
      "Rima Arnaout",
      "Ramy Arnaout"
    ],
    "abstract": "In the universal quest to optimize machine-learning classifiers, three\nfactors -- model architecture, dataset size, and class balance -- have been\nshown to influence test-time performance but do not fully account for it.\nPreviously, evidence was presented for an additional factor that can be\nreferred to as dataset quality, but it was unclear whether this was actually a\njoint property of the dataset and the model architecture, or an intrinsic\nproperty of the dataset itself. If quality is truly dataset-intrinsic and\nindependent of model architecture, dataset size, and class balance, then the\nsame datasets should perform better (or worse) regardless of these other\nfactors. To test this hypothesis, here we create thousands of datasets, each\ncontrolled for size and class balance, and use them to train classifiers with a\nwide range of architectures, from random forests and support-vector machines to\ndeep networks. We find that classifier performance correlates strongly by\nsubset across architectures ($R^2=0.79$), supporting quality as an intrinsic\nproperty of datasets independent of dataset size and class balance and of model\narchitecture. Digging deeper, we find that dataset quality appears to be an\nemergent property of something more fundamental: the quality of datasets'\nconstituent classes. Thus, quality joins size, class balance, and model\narchitecture as an independent correlate of performance and a separate target\nfor optimizing machine-learning-based classification.",
    "pdf_url": "http://arxiv.org/pdf/2505.22813v2",
    "published": "2025-05-28T19:41:37+00:00",
    "categories": [
      "cs.LG",
      "68T07",
      "I.2.6"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.22812v1",
    "title": "Moduli spaces for $Œò$-strata and non-reductive quotients",
    "authors": [
      "Ludvig Modin"
    ],
    "abstract": "We give a new proof of the $\\hat{U}$-theorem of B\\'erczi, Doran, Hawes and\nKirwan on the existence of geometric quotients for actions of graded unipotent\ngroups in terms of stacks of filtrations and gradings introduced by\nHalpern-Leistner. Our proof works over any affine Noetherian base, in\nparticular it simultaneously generalizes the previous results to arbitrary\ncharacteristic, actions in families and to general $\\Theta$-strata.",
    "pdf_url": "http://arxiv.org/pdf/2505.22812v1",
    "published": "2025-05-28T19:40:48+00:00",
    "categories": [
      "math.AG",
      "14D23, 14D22"
    ],
    "primary_category": "math.AG"
  },
  {
    "id": "http://arxiv.org/abs/2505.22811v1",
    "title": "Highly Efficient and Effective LLMs with Multi-Boolean Architectures",
    "authors": [
      "Ba-Hien Tran",
      "Van Minh Nguyen"
    ],
    "abstract": "Weight binarization has emerged as a promising strategy to drastically reduce\nthe complexity of large language models (LLMs). It is mainly classified into\ntwo approaches: post-training binarization and finetuning with training-aware\nbinarization methods. The first approach, while having low complexity, leads to\nsignificant loss of information from the original LLMs, resulting in poor\nperformance. The second approach, on the other hand, relies heavily on\nfull-precision latent weights for gradient approximation of binary weights,\nwhich not only remains suboptimal but also introduces substantial complexity.\nIn this paper, we introduce a novel framework that effectively transforms LLMs\ninto multi-kernel Boolean parameters, for the first time, finetunes them\ndirectly in the Boolean domain, eliminating the need for expensive latent\nweights. This significantly reduces complexity during both finetuning and\ninference. Through extensive and insightful experiments across a wide range of\nLLMs, we demonstrate that our method outperforms recent ultra low-bit\nquantization and binarization methods.",
    "pdf_url": "http://arxiv.org/pdf/2505.22811v1",
    "published": "2025-05-28T19:40:34+00:00",
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2505.22810v1",
    "title": "VidText: Towards Comprehensive Evaluation for Video Text Understanding",
    "authors": [
      "Zhoufaran Yang",
      "Yan Shu",
      "Zhifei Yang",
      "Yan Zhang",
      "Yu Li",
      "Keyang Lu",
      "Gangyan Zeng",
      "Shaohui Liu",
      "Yu Zhou",
      "Nicu Sebe"
    ],
    "abstract": "Visual texts embedded in videos carry rich semantic information, which is\ncrucial for both holistic video understanding and fine-grained reasoning about\nlocal human actions. However, existing video understanding benchmarks largely\noverlook textual information, while OCR-specific benchmarks are constrained to\nstatic images, limiting their ability to capture the interaction between text\nand dynamic visual contexts. To address this gap, we propose VidText, a new\nbenchmark designed for comprehensive and in-depth evaluation of video text\nunderstanding. VidText offers the following key features: 1) It covers a wide\nrange of real-world scenarios and supports multilingual content, encompassing\ndiverse settings where video text naturally appears. 2) It introduces a\nhierarchical evaluation framework with video-level, clip-level, and\ninstance-level tasks, enabling assessment of both global summarization and\nlocal retrieval capabilities. 3) The benchmark also introduces a set of paired\nperception reasoning tasks, ranging from visual text perception to cross-modal\nreasoning between textual and visual information. Extensive experiments on 18\nstate-of-the-art Large Multimodal Models (LMMs) reveal that current models\nstruggle across most tasks, with significant room for improvement. Further\nanalysis highlights the impact of both model-intrinsic factors, such as input\nresolution and OCR capability, and external factors, including the use of\nauxiliary information and Chain-of-Thought reasoning strategies. We hope\nVidText will fill the current gap in video understanding benchmarks and serve\nas a foundation for future research on multimodal reasoning with video text in\ndynamic environments.",
    "pdf_url": "http://arxiv.org/pdf/2505.22810v1",
    "published": "2025-05-28T19:39:35+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.22809v2",
    "title": "First Steps Towards Overhearing LLM Agents: A Case Study With Dungeons & Dragons Gameplay",
    "authors": [
      "Andrew Zhu",
      "Evan Osgood",
      "Chris Callison-Burch"
    ],
    "abstract": "Much work has been done on conversational LLM agents which directly assist\nhuman users with tasks. We present an alternative paradigm for interacting with\nLLM agents, which we call \"overhearing agents\". These overhearing agents do not\nactively participate in conversation -- instead, they \"listen in\" on\nhuman-to-human conversations and perform background tasks or provide\nsuggestions to assist the user. In this work, we explore the overhearing agents\nparadigm through the lens of Dungeons & Dragons gameplay. We present an\nin-depth study using large multimodal audio-language models as overhearing\nagents to assist a Dungeon Master. We perform a human evaluation to examine the\nhelpfulness of such agents and find that some large audio-language models have\nthe emergent ability to perform overhearing agent tasks using implicit audio\ncues. Finally, we release Python libraries and our project code to support\nfurther research into the overhearing agents paradigm at\nhttps://github.com/zhudotexe/overhearing_agents.",
    "pdf_url": "http://arxiv.org/pdf/2505.22809v2",
    "published": "2025-05-28T19:34:36+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.22808v1",
    "title": "A Terminology and Quantitative Framework for Assessing the Habitability of Solar System and Extraterrestrial Worlds",
    "authors": [
      "Daniel Apai",
      "Rory Barnes",
      "Matthew M. Murphy",
      "Tim Lichtenberg",
      "Noah Tuchow",
      "Regis Ferriere",
      "Kevin Wagner",
      "Antonin Affholder",
      "Renu Malhotra",
      "Baptiste Journaux",
      "Allona Vazan",
      "Ramses Ramirez",
      "Abel Mendez",
      "Stephen R. Kane",
      "Veronica H. Klawender",
      "NExSS Quantitative Habitability Science Working Group"
    ],
    "abstract": "The search for extraterrestrial life in the Solar System and beyond is a key\nscience driver in astrobiology, planetary science, and astrophysics. A critical\nstep is the identification and characterization of potential habitats, both to\nguide the search and to interpret its results. However, a well-accepted,\nself-consistent, flexible, and quantitative terminology and method of\nassessment of habitability are lacking. Our paper fills this gap based on a\nthree year-long study by the NExSS Quantitative Habitability Science Working\nGroup. We reviewed past studies of habitability, but find that the lack of a\nuniversally valid definition of life prohibits a universally applicable\ndefinition of habitability. A more nuanced approach is needed. We introduce a\nquantitative habitability assessment framework (QHF) that enables\nself-consistent, probabilistic assessment of the compatibility of two models:\nFirst, a habitat model, which describes the probability distributions of key\nconditions in the habitat. Second, a viability model, which describes the\nprobability that a metabolism is viable given a set of environmental\nconditions. We provide an open-source implementation of this framework and four\nexamples as a proof of concept: (a) Comparison of two exoplanets for\nobservational target prioritization; (b) Interpretation of atmospheric O2\ndetection in two exoplanets; (c) Subsurface habitability of Mars; and (d) Ocean\nhabitability in Europa. These examples demonstrate that our framework can\nself-consistently inform astrobiology research over a broad range of questions.\nThe proposed framework is modular so that future work can expand the range and\ncomplexity of models available, both for habitats and for metabolisms.",
    "pdf_url": "http://arxiv.org/pdf/2505.22808v1",
    "published": "2025-05-28T19:33:51+00:00",
    "categories": [
      "astro-ph.EP"
    ],
    "primary_category": "astro-ph.EP"
  },
  {
    "id": "http://arxiv.org/abs/2505.22807v4",
    "title": "Distribution free M-estimation",
    "authors": [
      "Felipe Areces",
      "John C. Duchi"
    ],
    "abstract": "The basic question of delineating those statistical problems that are\nsolvable without making any assumptions on the underlying data distribution has\nlong animated statistics and learning theory. This paper characterizes when a\nconvex M-estimation or stochastic optimization problem is solvable in such an\nassumption-free setting, providing a precise dividing line between solvable and\nunsolvable problems. The conditions we identify show, perhaps surprisingly,\nthat Lipschitz continuity of the loss being minimized is not necessary for\ndistribution free minimization, and they are also distinct from classical\ncharacterizations of learnability in machine learning.",
    "pdf_url": "http://arxiv.org/pdf/2505.22807v4",
    "published": "2025-05-28T19:33:12+00:00",
    "categories": [
      "math.ST",
      "cs.IT",
      "cs.LG",
      "math.IT",
      "stat.TH"
    ],
    "primary_category": "math.ST"
  },
  {
    "id": "http://arxiv.org/abs/2506.00051v1",
    "title": "Beyond Monoliths: Expert Orchestration for More Capable, Democratic, and Safe Large Language Models",
    "authors": [
      "Philip Quirke",
      "Narmeen Oozeer",
      "Chaithanya Bandi",
      "Amir Abdullah",
      "Jason Hoelscher-Obermaier",
      "Jeff M. Phillips",
      "Joshua Greaves",
      "Clement Neo",
      "Fazl Barez",
      "Shriyash Upadhyay"
    ],
    "abstract": "This position paper argues that the prevailing trajectory toward ever larger,\nmore expensive generalist foundation models controlled by a handful of big\ncompanies limits innovation and constrains progress. We challenge this approach\nby advocating for an \"Expert Orchestration\" framework as a superior alternative\nthat democratizes LLM advancement. Our proposed framework intelligently selects\nfrom thousands of existing models based on query requirements and\ndecomposition, focusing on identifying what models do well rather than how they\nwork internally. Independent \"judge\" models assess various models' capabilities\nacross dimensions that matter to users, while \"router\" systems direct queries\nto the most appropriate specialists within an approved set. This approach\ndelivers superior performance by leveraging targeted expertise rather than\nforcing costly generalist models to address all user requirements. The expert\norchestration paradigm represents a significant advancement in LLM capability\nby enhancing transparency, control, alignment, and safety through model\nselection while fostering a more democratic ecosystem.",
    "pdf_url": "http://arxiv.org/pdf/2506.00051v1",
    "published": "2025-05-28T19:32:10+00:00",
    "categories": [
      "cs.CY"
    ],
    "primary_category": "cs.CY"
  },
  {
    "id": "http://arxiv.org/abs/2505.22806v1",
    "title": "Origin of compact exoplanetary systems during disk infall",
    "authors": [
      "Raluca Rufu",
      "Robin M. Canup"
    ],
    "abstract": "Exoplanetary systems that contain multiple planets on short-period orbits\nappear to be prevalent in the current observed exoplanetary population, yet the\nprocesses that give rise to such configurations remain poorly understood. A\ncommon prior assumption is that planetary accretion commences after the infall\nof gas and solids to the circumstellar disk ended. However, observational\nevidence indicates that accretion may begin earlier. We propose that compact\nsystems are surviving remnants of planet accretion that occurred during the\nfinal phases of infall. In regions of the disk experiencing ongoing infall, the\nplanetary mass is set by the balance between accretion of infalling solids and\nthe increasingly rapid inward migration driven by the surrounding gas as the\nplanet grows. This balance selects for similarly-sized planets whose mass is a\nfunction of infall and disk conditions. We show that infall-produced planets\ncan survive until the gas disk disperses and migration ends, and that across a\nbroad range of conditions, the mass of surviving systems is regulated to a few\n10^{-5} to 10^{-4} times the host star's mass. This provides an explanation for\nthe similar mass ratios of known compact systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.22806v1",
    "published": "2025-05-28T19:27:30+00:00",
    "categories": [
      "astro-ph.EP",
      "physics.space-ph"
    ],
    "primary_category": "astro-ph.EP"
  },
  {
    "id": "http://arxiv.org/abs/2505.22805v1",
    "title": "Anomalies by Synthesis: Anomaly Detection using Generative Diffusion Models for Off-Road Navigation",
    "authors": [
      "Siddharth Ancha",
      "Sunshine Jiang",
      "Travis Manderson",
      "Laura Brandt",
      "Yilun Du",
      "Philip R. Osteen",
      "Nicholas Roy"
    ],
    "abstract": "In order to navigate safely and reliably in off-road and unstructured\nenvironments, robots must detect anomalies that are out-of-distribution (OOD)\nwith respect to the training data. We present an analysis-by-synthesis approach\nfor pixel-wise anomaly detection without making any assumptions about the\nnature of OOD data. Given an input image, we use a generative diffusion model\nto synthesize an edited image that removes anomalies while keeping the\nremaining image unchanged. Then, we formulate anomaly detection as analyzing\nwhich image segments were modified by the diffusion model. We propose a novel\ninference approach for guided diffusion by analyzing the ideal guidance\ngradient and deriving a principled approximation that bootstraps the diffusion\nmodel to predict guidance gradients. Our editing technique is purely test-time\nthat can be integrated into existing workflows without the need for retraining\nor fine-tuning. Finally, we use a combination of vision-language foundation\nmodels to compare pixels in a learned feature space and detect semantically\nmeaningful edits, enabling accurate anomaly detection for off-road navigation.\nProject website: https://siddancha.github.io/anomalies-by-diffusion-synthesis/",
    "pdf_url": "http://arxiv.org/pdf/2505.22805v1",
    "published": "2025-05-28T19:26:48+00:00",
    "categories": [
      "cs.RO",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.22804v1",
    "title": "Dynamic Task Adaptation for Multi-Robot Manufacturing Systems with Large Language Models",
    "authors": [
      "Jonghan Lim",
      "Ilya Kovalenko"
    ],
    "abstract": "Recent manufacturing systems are increasingly adopting multi-robot\ncollaboration to handle complex and dynamic environments. While multi-agent\narchitectures support decentralized coordination among robot agents, they often\nface challenges in enabling real-time adaptability for unexpected disruptions\nwithout predefined rules. Recent advances in large language models offer new\nopportunities for context-aware decision-making to enable adaptive responses to\nunexpected changes. This paper presents an initial exploratory implementation\nof a large language model-enabled control framework for dynamic task\nreassignment in multi-robot manufacturing systems. A central controller agent\nleverages the large language model's ability to interpret structured robot\nconfiguration data and generate valid reassignments in response to robot\nfailures. Experiments in a real-world setup demonstrate high task success rates\nin recovering from failures, highlighting the potential of this approach to\nimprove adaptability in multi-robot manufacturing systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.22804v1",
    "published": "2025-05-28T19:26:07+00:00",
    "categories": [
      "cs.RO",
      "cs.MA"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.22803v1",
    "title": "CLUE: Neural Networks Calibration via Learning Uncertainty-Error alignment",
    "authors": [
      "Pedro Mendes",
      "Paolo Romano",
      "David Garlan"
    ],
    "abstract": "Reliable uncertainty estimation is critical for deploying neural networks\n(NNs) in real-world applications. While existing calibration techniques often\nrely on post-hoc adjustments or coarse-grained binning methods, they remain\nlimited in scalability, differentiability, and generalization across domains.\nIn this work, we introduce CLUE (Calibration via Learning Uncertainty-Error\nAlignment), a novel approach that explicitly aligns predicted uncertainty with\nobserved error during training, grounded in the principle that well-calibrated\nmodels should produce uncertainty estimates that match their empirical loss.\nCLUE adopts a novel loss function that jointly optimizes predictive performance\nand calibration, using summary statistics of uncertainty and loss as proxies.\nThe proposed method is fully differentiable, domain-agnostic, and compatible\nwith standard training pipelines. Through extensive experiments on vision,\nregression, and language modeling tasks, including out-of-distribution and\ndomain-shift scenarios, we demonstrate that CLUE achieves superior calibration\nquality and competitive predictive performance with respect to state-of-the-art\napproaches without imposing significant computational overhead.",
    "pdf_url": "http://arxiv.org/pdf/2505.22803v1",
    "published": "2025-05-28T19:23:47+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.22802v2",
    "title": "From Signed Networks to Group Graphs",
    "authors": [
      "Tim S. Evans"
    ],
    "abstract": "I define a \"group graph\" which encodes the symmetry in a dynamical process on\na network. Group graphs extend signed networks, where links are labelled with\nplus or minus one, by allowing link labels from any group and generalising the\nstandard notion of balance. I show that for processes on a balanced group graph\nthe time evolution is completely determined by the network topology, not by the\ngroup structure. This unifies and extends recent findings on signed networks\n(Tian \\& Lambiotte, 2024a) and complex networks (Tian \\& Lambiotte, 2024b). I\nwill also relate the results discussed here to related work such as the \"group\ngraph\" of Harary (1982), a \"voltage graph\" (Gross, 1974) and a \"gain graph\"\n(Zaslavsky 1989). Finally, I will review some promising applications for\nnetwork dynamics and symmetry-driven modelling including status, edges with a\nzero label, weak balance, unbalanced group graphs and using monoids.",
    "pdf_url": "http://arxiv.org/pdf/2505.22802v2",
    "published": "2025-05-28T19:23:41+00:00",
    "categories": [
      "physics.soc-ph",
      "cs.DM",
      "cs.SI"
    ],
    "primary_category": "physics.soc-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.22801v1",
    "title": "Towards a More Generalized Approach in Open Relation Extraction",
    "authors": [
      "Qing Wang",
      "Yuepei Li",
      "Qiao Qiao",
      "Kang Zhou",
      "Qi Li"
    ],
    "abstract": "Open Relation Extraction (OpenRE) seeks to identify and extract novel\nrelational facts between named entities from unlabeled data without pre-defined\nrelation schemas. Traditional OpenRE methods typically assume that the\nunlabeled data consists solely of novel relations or is pre-divided into known\nand novel instances. However, in real-world scenarios, novel relations are\narbitrarily distributed. In this paper, we propose a generalized OpenRE setting\nthat considers unlabeled data as a mixture of both known and novel instances.\nTo address this, we propose MixORE, a two-phase framework that integrates\nrelation classification and clustering to jointly learn known and novel\nrelations. Experiments on three benchmark datasets demonstrate that MixORE\nconsistently outperforms competitive baselines in known relation classification\nand novel relation clustering. Our findings contribute to the advancement of\ngeneralized OpenRE research and real-world applications.",
    "pdf_url": "http://arxiv.org/pdf/2505.22801v1",
    "published": "2025-05-28T19:21:54+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.22800v1",
    "title": "Selenization of V2O5/WO3 Bilayers for Tuned Optoelectronic Response of WSe2 Films",
    "authors": [
      "Abhishek Bajgain",
      "Santu Prasad Jana",
      "Alexander Samokhvalov",
      "Thomas Parker",
      "John Derek Demaree",
      "Ramesh C. Budhani"
    ],
    "abstract": "Scalable and controlled doping of two-dimensional transition metal\ndichalcogenides is essential for tuning their electronic and optoelectronic\nproperties. In this work, we demonstrate a robust approach for substitution of\nvanadium in tungsten diselenide (WSe$_2$) via the selenization of pre-deposited\nV$_2$O$_5$/WO$_3$ thin films. By adjusting the thickness of the vanadium oxide\nlayer, the V concentration in W$_{1-x}$V$_x$Se$_2$ is systematically varied.\nElectrical measurements on field-effect transistors reveal a substantial\nenhancement in hole conduction, with drain current increasing by nearly three\norders of magnitude compared to undoped WSe$_2$. Temperature-dependent\nelectrical resistivity indicates a clear insulator-to-metal transition with\nincreasing V content, likely due to band structure modifications. Concurrently,\nthe photoconductive gain decreases, suggesting enhanced recombination and\ncharge screening effects. These results establish vanadium doping via\nselenization of V$_2$O$_5$/WO$_3$ films as a scalable strategy for modulating\nthe transport and photoresponse of WSe$_2$, offering promising implications for\nwafer-scale optoelectronic device integration.",
    "pdf_url": "http://arxiv.org/pdf/2505.22800v1",
    "published": "2025-05-28T19:15:17+00:00",
    "categories": [
      "cond-mat.mes-hall",
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mes-hall"
  },
  {
    "id": "http://arxiv.org/abs/2505.22799v1",
    "title": "Theory and simulation of elastoinertial rectification of oscillatory flows in two-dimensional deformable rectangular channels",
    "authors": [
      "Uday M. Rade",
      "Shrihari D. Pande",
      "Ivan C. Christov"
    ],
    "abstract": "A slender two-dimensional (2D) channel bounded by a rigid bottom surface and\na slender elastic layer above deforms when a fluid flows through it.\nHydrodynamic forces cause deformation at the fluid-solid interface, which in\nturn changes the cross-sectional area of the fluidic channel. The nonlinear\ncoupling between flow and deformation, along with the attendant asymmetry in\ngeometry caused by flow-induced deformation, produces a streaming effect (a\nnon-zero cycle-average despite time-periodic forcing). Surprisingly, fluid\ninertia provides another nonlinear coupling, tightly connected to deformation,\nthat enhances streaming, termed ``elastoinertial rectification'' by Zhang and\nRallabandi [J. Fluid Mech. 996, A16 (2024)]. We adapt the latter theory of how\ntwo-way coupled fluid--structure interaction (FSI) produces streaming to a 2D\nrectangular configuration, specifically taking care to capture the deformations\nof the nearly incompressible slender elastic layer via the combined foundation\nmodel of Chandler and Vella [Proc. R. Soc. A 476, 20200551 (2020)]. We\nsupplement the elastoinertial rectification theory with direct numerical\nsimulations performed using a conforming arbitrary Lagrangian-Eulerian (ALE)\nFSI formulation with streamline upwind Petrov-Galerkin stabilization,\nimplemented via the open-source computing platform FEniCS. We examine the axial\nvariation of the cycle-averaged pressure as a function of key dimensionless\ngroups of the problem: the Womersley number, the elastoviscous number, and the\ncompliance number. Assuming a small compliance number, we find excellent\nagreement between theory and simulations for the leading-order pressure and\ndeformation across a range of conditions. At the next order, the cycle-averaged\npressures agree well; however, the cycle-averaged deformation is found to\nexhibit significant axial and vertical displacements, unlike the combined\nfoundation model.",
    "pdf_url": "http://arxiv.org/pdf/2505.22799v1",
    "published": "2025-05-28T19:14:26+00:00",
    "categories": [
      "physics.flu-dyn"
    ],
    "primary_category": "physics.flu-dyn"
  },
  {
    "id": "http://arxiv.org/abs/2505.22798v1",
    "title": "Efficient Preimage Approximation for Neural Network Certification",
    "authors": [
      "Anton Bj√∂rklund",
      "Mykola Zaitsev",
      "Marta Kwiatkowska"
    ],
    "abstract": "The growing reliance on artificial intelligence in safety- and\nsecurity-critical applications demands effective neural network certification.\nA challenging real-world use case is certification against ``patch attacks'',\nwhere adversarial patches or lighting conditions obscure parts of images, for\nexample traffic signs. One approach to certification, which also gives\nquantitative coverage estimates, utilizes preimages of neural networks, i.e.,\nthe set of inputs that lead to a specified output. However, these preimage\napproximation methods, including the state-of-the-art PREMAP algorithm,\nstruggle with scalability. This paper presents novel algorithmic improvements\nto PREMAP involving tighter bounds, adaptive Monte Carlo sampling, and improved\nbranching heuristics. We demonstrate efficiency improvements of at least an\norder of magnitude on reinforcement learning control benchmarks, and show that\nour method scales to convolutional neural networks that were previously\ninfeasible. Our results demonstrate the potential of preimage approximation\nmethodology for reliability and robustness certification.",
    "pdf_url": "http://arxiv.org/pdf/2505.22798v1",
    "published": "2025-05-28T19:13:56+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR",
      "68T07"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.22797v1",
    "title": "Fast Trajectory-Independent Model-Based Reconstruction Algorithm for Multi-Dimensional Magnetic Particle Imaging",
    "authors": [
      "Vladyslav Gapyak",
      "Thomas M√§rz",
      "Andreas Weinmann"
    ],
    "abstract": "Magnetic Particle Imaging (MPI) is a promising tomographic technique for\nvisualizing the spatio-temporal distribution of superparamagnetic\nnanoparticles, with applications ranging from cancer detection to real-time\ncardiovascular monitoring. Traditional MPI reconstruction relies on either\ntime-consuming calibration (measured system matrix) or model-based simulation\nof the forward operator. Recent developments have shown the applicability of\nChebyshev polynomials to multi-dimensional Lissajous Field-Free Point (FFP)\nscans. This method is bound to the particular choice of sinusoidal scanning\ntrajectories. In this paper, we present the first reconstruction on real 2D MPI\ndata with a trajectory-independent model-based MPI reconstruction algorithm. We\nfurther develop the zero-shot Plug-and-Play (PnP) algorithm of the authors --\nwith automatic noise level estimation -- to address the present deconvolution\nproblem, leveraging a state-of-the-art denoiser trained on natural images\nwithout retraining on MPI-specific data. We evaluate our method on the publicly\navailable 2D FFP MPI dataset ``MPIdata: Equilibrium Model with Anisotropy\",\nfeaturing scans of six phantoms acquired using a Bruker preclinical scanner.\nMoreover, we show reconstruction performed on custom data on a 2D scanner with\nadditional high-frequency excitation field and partial data. Our results\ndemonstrate strong reconstruction capabilities across different scanning\nscenarios -- setting a precedent for general-purpose, flexible model-based MPI\nreconstruction.",
    "pdf_url": "http://arxiv.org/pdf/2505.22797v1",
    "published": "2025-05-28T19:13:46+00:00",
    "categories": [
      "cs.CV",
      "cs.NA",
      "math.NA",
      "physics.med-ph"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.22796v1",
    "title": "Symmetry tuning topological states of an axion insulator with noncollinear magnetic order",
    "authors": [
      "S. X. M. Riberolles",
      "A. M. Nediƒá",
      "B. Kuthanazhi",
      "F. Ye",
      "S. L. Bud'ko",
      "P. C. Canfield",
      "R. J. McQueeney",
      "Junyeong Ahn",
      "V. L. Quito",
      "T. V. Trevisan",
      "L. L. Wang",
      "P. P. Orth",
      "B. G. Ueland"
    ],
    "abstract": "Topological properties of quantum materials are intimately related to\nsymmetry. Here, we tune the magnetic order of the axion insulator candidate\nEuIn$_2$As$_2$ from its broken-helix ground state to the field-polarized phase\nby applying an in-plane magnetic field. Using results from neutron diffraction\nand magnetization measurements with ab inito theory and symmetry analysis, we\ndetermine how the field tunes the magnetic symmetry within individual magnetic\ndomains and examine the resulting changes to the topological surface states and\nhinge states existing on edges shared by certain surfaces hosting gapped Dirac\nstates. We predict field-tunable complex and domain-specific hinge-state\npatterns, with some crystal surfaces undergoing a field-induced topological\nphase transition. We further find that domain walls have pinned hinge states\nwhen intersecting certain crystal surfaces, providing another channel for\ntuning the chiral-charge-transport pathways.",
    "pdf_url": "http://arxiv.org/pdf/2505.22796v1",
    "published": "2025-05-28T19:12:18+00:00",
    "categories": [
      "cond-mat.mtrl-sci",
      "cond-mat.str-el"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2505.22795v1",
    "title": "Window observables for benchmarking parton distribution functions",
    "authors": [
      "Joe Karpie",
      "Christopher J. Monahan",
      "Kostas Orginos",
      "Savvas Zafeiropoulos"
    ],
    "abstract": "Global analysis of collider and fixed-target experimental data and\ncalculations from lattice quantum chromodynamics (QCD) are used to gain\ncomplementary information on the structure of hadrons. We propose novel\n``window observables'' that allow for higher precision cross-validation between\nthe different approaches, a critical step for studies that wish to combine the\ndatasets. Global analyses are limited by the kinematic regions accessible to\nexperiment, particularly in a range of Bjorken-$x$, and lattice QCD\ncalculations also have limitations requiring extrapolations to obtain the\nparton distributions. We provide two different ``window observables'' that can\nbe defined within a region of $x$ where extrapolations and interpolations in\nglobal analyses remain reliable and where lattice QCD results retain\nsensitivity and precision.",
    "pdf_url": "http://arxiv.org/pdf/2505.22795v1",
    "published": "2025-05-28T19:11:27+00:00",
    "categories": [
      "hep-lat",
      "hep-ph"
    ],
    "primary_category": "hep-lat"
  },
  {
    "id": "http://arxiv.org/abs/2505.22794v1",
    "title": "Timelike Quantum Energy Teleportation in the Nambu-Jona-Lasinio Model",
    "authors": [
      "Fidele J. Twagirayezu"
    ],
    "abstract": "We propose a novel timelike quantum energy teleportation (QET) protocol\nwithin the 1+1 dimensional Nambu-Jona-Lasinio (NJL) model, an interacting\nfermionic field theory exhibiting spontaneous chiral symmetry breaking. By\ncoupling localized Unruh-DeWitt detectors to the fermionic field, we\ndemonstrate how an initial observer's measurement enables a second observer to\nextract energy at a later time using only classical information transfer. This\nprotocol leverages the NJL vacuum's rich entanglement structure, driven by the\nchiral condensate, to facilitate energy transfer without physical particle\ntransport. We derive the energy flows and explore the roles of measurement and\ntime evolution and validate the protocol through quantum circuit simulations on\na lattice-regularized NJL model. Our findings highlight the NJL model's\npotential as a platform for exploring QET in interacting quantum field theories\nand pave the way for experimental realizations on quantum hardware.",
    "pdf_url": "http://arxiv.org/pdf/2505.22794v1",
    "published": "2025-05-28T19:05:44+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.22793v2",
    "title": "Evaluation of Cultural Competence of Vision-Language Models",
    "authors": [
      "Srishti Yadav",
      "Lauren Tilton",
      "Maria Antoniak",
      "Taylor Arnold",
      "Jiaang Li",
      "Siddhesh Milind Pawar",
      "Antonia Karamolegkou",
      "Stella Frank",
      "Zhaochong An",
      "Negar Rostamzadeh",
      "Daniel Hershcovich",
      "Serge Belongie",
      "Ekaterina Shutova"
    ],
    "abstract": "Modern vision-language models (VLMs) often fail at cultural competency\nevaluations and benchmarks. Given the diversity of applications built upon\nVLMs, there is renewed interest in understanding how they encode cultural\nnuances. While individual aspects of this problem have been studied, we still\nlack a comprehensive framework for systematically identifying and annotating\nthe nuanced cultural dimensions present in images for VLMs. This position paper\nargues that foundational methodologies from visual culture studies (cultural\nstudies, semiotics, and visual studies) are necessary for cultural analysis of\nimages. Building upon this review, we propose a set of five frameworks,\ncorresponding to cultural dimensions, that must be considered for a more\ncomplete analysis of the cultural competencies of VLMs.",
    "pdf_url": "http://arxiv.org/pdf/2505.22793v2",
    "published": "2025-05-28T19:04:04+00:00",
    "categories": [
      "cs.CV",
      "cs.CL"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.22792v2",
    "title": "Rhetorical Text-to-Image Generation via Two-layer Diffusion Policy Optimization",
    "authors": [
      "Yuxi Zhang",
      "Yueting Li",
      "Xinyu Du",
      "Sibo Wang"
    ],
    "abstract": "Generating images from rhetorical languages remains a critical challenge for\ntext-to-image models. Even state-of-the-art (SOTA) multimodal large language\nmodels (MLLM) fail to generate images based on the hidden meaning inherent in\nrhetorical language--despite such content being readily mappable to visual\nrepresentations by humans. A key limitation is that current models emphasize\nobject-level word embedding alignment, causing metaphorical expressions to\nsteer image generation towards their literal visuals and overlook the intended\nsemantic meaning. To address this, we propose Rhet2Pix, a framework that\nformulates rhetorical text-to-image generation as a multi-step policy\noptimization problem, incorporating a two-layer MDP diffusion module. In the\nouter layer, Rhet2Pix converts the input prompt into incrementally elaborated\nsub-sentences and executes corresponding image-generation actions, constructing\nsemantically richer visuals. In the inner layer, Rhet2Pix mitigates reward\nsparsity during image generation by discounting the final reward and optimizing\nevery adjacent action pair along the diffusion denoising trajectory. Extensive\nexperiments demonstrate the effectiveness of Rhet2Pix in rhetorical\ntext-to-image generation. Our model outperforms SOTA MLLMs such as GPT-4o,\nGrok-3 and leading academic baselines across both qualitative and quantitative\nevaluations. The code and dataset used in this work are publicly available.",
    "pdf_url": "http://arxiv.org/pdf/2505.22792v2",
    "published": "2025-05-28T19:03:37+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.22791v1",
    "title": "Quantum cooling below absolute zero",
    "authors": [
      "Francesco Libbi",
      "Lorenzo Monacelli",
      "Boris Kozinsky"
    ],
    "abstract": "Similar to other perovskites in its family, SrTiO$_3$ exhibits a significant\nsoftening of the ferroelectric mode with decreasing temperature, a behavior\nthat typically heralds the onset of a ferroelectric transition. However, this\nmaterial remains paraelectric down to 0K due to the Heisenberg quantum\nuncertainty principle that prevents atoms from localizing in the ferroelectric\nminima, a fundamental limit that appears impossible to overcome. This work\nshows that in the strong out-of-equilibrium regime induced by resonant mid-IR\npulses, quantum fluctuations can be suppressed, effectively cooling the\nmaterial below the 0K ground state and inducing a ferroelectric transition in\nSrTiO$_3$ that is otherwise impossible. The appearance of a metastable state,\nthat is distinct from the conventional ground state, is the first demonstration\nof how it is possible to leverage and control quantum fluctuations with pulsed\nlight to qualitatively alter the free energy landscape of a quantum system. We\npredict the conditions and system parameter under which induced non-equilibrium\nstate can be long-lived and even permanent. In providing a quantitative\ndescription, based on first principles machine learned potential energy\nsurface, we explain recent experimental observations of light-induced\nferroelectric transition in this material.",
    "pdf_url": "http://arxiv.org/pdf/2505.22791v1",
    "published": "2025-05-28T19:03:30+00:00",
    "categories": [
      "quant-ph",
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.22790v1",
    "title": "Odderon Exchange in Elastic Proton-Proton and Proton-Antiproton Scattering at TeV Energies",
    "authors": [
      "Istv√°n Szanyi"
    ],
    "abstract": "The odderon, a leading crossing-odd $t$-channel exchange, was first proposed\nby L. Lukaszuk and B. Nicolescu in 1973, but its existence remained elusive for\n48 years. Elastic proton-proton scattering measurements at CERN's Large Hadron\nCollider (LHC) and elastic proton-antiproton scattering measurements at FNAL's\nTevatron, performed at TeV-scale center-of-mass energies ($\\sqrt{s}$) and over\nwide ranges of squared four-momentum transfer ($t$), opened new opportunities\nto study the physics of elastic hadronic processes which ultimately led to the\ndiscovery of odderon exchange in the nonperturbative domain of strong\ninteractions, as detailed in this dissertation. In quantum chromodynamics\n(QCD), the fundamental theory of strong interactions, the odderon is described\nin the perturbative regime as a $t$-channel exchange of an odd number of\ninteracting gluons.",
    "pdf_url": "http://arxiv.org/pdf/2505.22790v1",
    "published": "2025-05-28T19:02:40+00:00",
    "categories": [
      "hep-ph"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.22789v1",
    "title": "PdNeuRAM: Forming-Free, Multi-Bit Pd/HfO2 ReRAM for Energy-Efficient Computing",
    "authors": [
      "Erbing Hua",
      "Theofilos Spyrou",
      "Majid Ahmadi",
      "Abdul Momin Syed",
      "Hanzhi Xun",
      "Laurentiu Braic",
      "Ewout van der Veer",
      "Nazek Elatab",
      "Anteneh Gebregiorgis",
      "Georgi Gaydadjiev",
      "Beatriz Noheda",
      "Said Hamdioui",
      "Ryoichi Ishihara",
      "Heba Abunahla"
    ],
    "abstract": "Memristor technology shows great promise for energy-efficient computing, yet\nit grapples with challenges like resistance drift and inherent variability. For\nfilamentary Resistive RAM (ReRAM), one of the most investigated types of\nmemristive devices, the expensive electroforming step required to create\nconductive pathways results in increased power and area overheads and reduced\nendurance. In this study, we present novel HfO2-based forming-free ReRAM\ndevices, PdNeuRAM, that operate at low voltages, support multi-bit\nfunctionality, and display reduced variability. Through a deep understanding\nand comprehensive material characterization, we discover the key process that\nallows this unique behavior: a Pd-O-Hf configuration that capitalizes on Pd\ninnate affinity for integrating into HfO2. This structure actively facilitates\ncharge redistribution at room temperature, effectively eliminating the need for\nelectroforming. Moreover, the fabricated ReRAM device provides tunable\nresistance states for dense memory and reduces programming and reading energy\nby 43% and 73%, respectively, using spiking neural networks (SNN). This study\nreveals novel mechanistic insights and delineates a strategic roadmap for the\nrealization of power-efficient and cost-effective ReRAM devices.",
    "pdf_url": "http://arxiv.org/pdf/2505.22789v1",
    "published": "2025-05-28T19:02:24+00:00",
    "categories": [
      "cond-mat.mtrl-sci",
      "eess.IV"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2505.22788v1",
    "title": "Effects of thrust, tip-speed ratio, and time variations on wind-turbine wakes at high Reynolds numbers",
    "authors": [
      "Nathaniel J. Wei",
      "Adina Y. Fleisher",
      "John W. Kurelek",
      "Marcus N. Hultmark"
    ],
    "abstract": "The evolution of rotor wakes is an important problem for a wide range of\nwind-energy and aerodynamic applications, and is of particular relevance to\ndynamic wake control strategies for wind farms. This study aims to clarify the\ninfluence of turbine thrust and tip-speed ratio on tip-vortex breakdown and the\nevolution of the near wake. Scaling arguments show that these parameters\ncontribute to the wake dynamics in distinct ways, and that neither thrust nor\ntip-speed ratio are alone sufficient to describe near and intermediate wake\ndevelopment. These considerations are especially critical for time-varying\nflows. To demonstrate these principles, a wind turbine at a near utility-scale\nReynolds number ($Re_D=4\\times10^6$) is forced in periodic rotation-rate\noscillations at low Strouhal numbers ($St=0.04$). The slow time-varying forcing\nprotocol decouples thrust and tip-speed ratio effects without introducing\nnonlinear dynamics into the wake that would appear at higher forcing\nfrequencies. Flow measurements in the wake of the turbine show disturbances\npropagate through the wake as traveling waves, with thrust and tip-speed ratio\nvariations displaying synergistic or competing effects on wake dynamics\ndepending on the relative phase and amplitude of such disturbances. The results\nprovide key insights into the dynamics of time-varying wakes, limitations in\nexisting models of rotor wake dynamics, and to future novel wake-control\nschemes.",
    "pdf_url": "http://arxiv.org/pdf/2505.22788v1",
    "published": "2025-05-28T19:01:13+00:00",
    "categories": [
      "physics.flu-dyn"
    ],
    "primary_category": "physics.flu-dyn"
  },
  {
    "id": "http://arxiv.org/abs/2506.03171v1",
    "title": "EdgeVidSum: Real-Time Personalized Video Summarization at the Edge",
    "authors": [
      "Ghulam Mujtaba",
      "Eun-Seok Ryu"
    ],
    "abstract": "EdgeVidSum is a lightweight method that generates personalized, fast-forward\nsummaries of long-form videos directly on edge devices. The proposed approach\nenables real-time video summarization while safeguarding user privacy through\nlocal data processing using innovative thumbnail-based techniques and efficient\nneural architectures. Unlike conventional methods that process entire videos\nframe by frame, the proposed method uses thumbnail containers to significantly\nreduce computational complexity without sacrificing semantic relevance. The\nframework employs a hierarchical analysis approach, where a lightweight 2D CNN\nmodel identifies user-preferred content from thumbnails and generates\ntimestamps to create fast-forward summaries. Our interactive demo highlights\nthe system's ability to create tailored video summaries for long-form videos,\nsuch as movies, sports events, and TV shows, based on individual user\npreferences. The entire computation occurs seamlessly on resource-constrained\ndevices like Jetson Nano, demonstrating how EdgeVidSum addresses the critical\nchallenges of computational efficiency, personalization, and privacy in modern\nvideo consumption environments.",
    "pdf_url": "http://arxiv.org/pdf/2506.03171v1",
    "published": "2025-05-28T18:59:41+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.05370v1",
    "title": "Contextual Memory Intelligence -- A Foundational Paradigm for Human-AI Collaboration and Reflective Generative AI Systems",
    "authors": [
      "Kristy Wedel"
    ],
    "abstract": "A critical challenge remains unresolved as generative AI systems are quickly\nimplemented in various organizational settings. Despite significant advances in\nmemory components such as RAG, vector stores, and LLM agents, these systems\nstill have substantial memory limitations. Gen AI workflows rarely store or\nreflect on the full context in which decisions are made. This leads to repeated\nerrors and a general lack of clarity. This paper introduces Contextual Memory\nIntelligence (CMI) as a new foundational paradigm for building intelligent\nsystems. It repositions memory as an adaptive infrastructure necessary for\nlongitudinal coherence, explainability, and responsible decision-making rather\nthan passive data. Drawing on cognitive science, organizational theory,\nhuman-computer interaction, and AI governance, CMI formalizes the structured\ncapture, inference, and regeneration of context as a fundamental system\ncapability. The Insight Layer is presented in this paper to operationalize this\nvision. This modular architecture uses human-in-the-loop reflection, drift\ndetection, and rationale preservation to incorporate contextual memory into\nsystems. The paper argues that CMI allows systems to reason with data, history,\njudgment, and changing context, thereby addressing a foundational blind spot in\ncurrent AI architectures and governance efforts. A framework for creating\nintelligent systems that are effective, reflective, auditable, and socially\nresponsible is presented through CMI. This enhances human-AI collaboration,\ngenerative AI design, and the resilience of the institutions.",
    "pdf_url": "http://arxiv.org/pdf/2506.05370v1",
    "published": "2025-05-28T18:59:16+00:00",
    "categories": [
      "cs.AI",
      "cs.ET"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.22787v1",
    "title": "Can Large Language Models Match the Conclusions of Systematic Reviews?",
    "authors": [
      "Christopher Polzak",
      "Alejandro Lozano",
      "Min Woo Sun",
      "James Burgess",
      "Yuhui Zhang",
      "Kevin Wu",
      "Serena Yeung-Levy"
    ],
    "abstract": "Systematic reviews (SR), in which experts summarize and analyze evidence\nacross individual studies to provide insights on a specialized topic, are a\ncornerstone for evidence-based clinical decision-making, research, and policy.\nGiven the exponential growth of scientific articles, there is growing interest\nin using large language models (LLMs) to automate SR generation. However, the\nability of LLMs to critically assess evidence and reason across multiple\ndocuments to provide recommendations at the same proficiency as domain experts\nremains poorly characterized. We therefore ask: Can LLMs match the conclusions\nof systematic reviews written by clinical experts when given access to the same\nstudies? To explore this question, we present MedEvidence, a benchmark pairing\nfindings from 100 SRs with the studies they are based on. We benchmark 24 LLMs\non MedEvidence, including reasoning, non-reasoning, medical specialist, and\nmodels across varying sizes (from 7B-700B). Through our systematic evaluation,\nwe find that reasoning does not necessarily improve performance, larger models\ndo not consistently yield greater gains, and knowledge-based fine-tuning\ndegrades accuracy on MedEvidence. Instead, most models exhibit similar\nbehavior: performance tends to degrade as token length increases, their\nresponses show overconfidence, and, contrary to human experts, all models show\na lack of scientific skepticism toward low-quality findings. These results\nsuggest that more work is still required before LLMs can reliably match the\nobservations from expert-conducted SRs, even though these systems are already\ndeployed and being used by clinicians. We release our codebase and benchmark to\nthe broader research community to further investigate LLM-based SR systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.22787v1",
    "published": "2025-05-28T18:58:09+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.22786v1",
    "title": "Topological Machine Learning for Protein-Nucleic Acid Binding Affinity Changes Upon Mutation",
    "authors": [
      "Xiang Liu",
      "Junjie Wee",
      "Guo-Wei Wei"
    ],
    "abstract": "Understanding how protein mutations affect protein-nucleic acid binding is\ncritical for unraveling disease mechanisms and advancing therapies. Current\nexperimental approaches are laborious, and computational methods remain limited\nin accuracy. To address this challenge, we propose a novel topological machine\nlearning model (TopoML) combining persistent Laplacian (from topological data\nanalysis) with multi-perspective features: physicochemical properties,\ntopological structures, and protein Transformer-derived sequence embeddings.\nThis integrative framework captures robust representations of protein-nucleic\nacid binding interactions. To validate the proposed method, we employ two\ndatasets, a protein-DNA dataset with 596 single-point amino acid mutations, and\na protein-RNA dataset with 710 single-point amino acid mutations. We show that\nthe proposed TopoML model outperforms state-of-the-art methods in predicting\nmutation-induced binding affinity changes for protein-DNA and protein-RNA\ncomplexes.",
    "pdf_url": "http://arxiv.org/pdf/2505.22786v1",
    "published": "2025-05-28T18:57:51+00:00",
    "categories": [
      "q-bio.QM"
    ],
    "primary_category": "q-bio.QM"
  },
  {
    "id": "http://arxiv.org/abs/2505.22785v2",
    "title": "Navigating the Latent Space Dynamics of Neural Models",
    "authors": [
      "Marco Fumero",
      "Luca Moschella",
      "Emanuele Rodol√†",
      "Francesco Locatello"
    ],
    "abstract": "Neural networks transform high-dimensional data into compact, structured\nrepresentations, often modeled as elements of a lower dimensional latent space.\nIn this paper, we present an alternative interpretation of neural models as\ndynamical systems acting on the latent manifold. Specifically, we show that\nautoencoder models implicitly define a latent vector field on the manifold,\nderived by iteratively applying the encoding-decoding map, without any\nadditional training. We observe that standard training procedures introduce\ninductive biases that lead to the emergence of attractor points within this\nvector field. Drawing on this insight, we propose to leverage the vector field\nas a representation for the network, providing a novel tool to analyze the\nproperties of the model and the data. This representation enables to: (i)\nanalyze the generalization and memorization regimes of neural models, even\nthroughout training; (ii) extract prior knowledge encoded in the network's\nparameters from the attractors, without requiring any input data; (iii)\nidentify out-of-distribution samples from their trajectories in the vector\nfield. We further validate our approach on vision foundation models, showcasing\nthe applicability and effectiveness of our method in real-world scenarios.",
    "pdf_url": "http://arxiv.org/pdf/2505.22785v2",
    "published": "2025-05-28T18:57:41+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.22784v3",
    "title": "Split the Yield, Share the Risk: Pricing, Hedging and Fixed rates in DeFi",
    "authors": [
      "Viraj Nadkarni",
      "Pramod Viswanath"
    ],
    "abstract": "We present the first formal treatment of \\emph{yield tokenization}, a\nmechanism that decomposes yield-bearing assets into principal and yield\ncomponents to facilitate risk transfer and price discovery in decentralized\nfinance (DeFi). We propose a model that characterizes yield token dynamics\nusing stochastic differential equations. We derive a no-arbitrage pricing\nframework for yield tokens, enabling their use in hedging future yield\nvolatility and managing interest rate risk in decentralized lending pools.\nTaking DeFi lending as our focus, we show how both borrowers and lenders can\nuse yield tokens to achieve optimal hedging outcomes and mitigate exposure to\nadversarial interest rate manipulation. Furthermore, we design automated market\nmakers (AMMs) that incorporate a menu of bonding curves to aggregate liquidity\nfrom participants with heterogeneous risk preferences. This leads to an\nefficient and incentive-compatible mechanism for trading yield tokens and yield\nfutures. Building on these foundations, we propose a modular\n\\textit{fixed-rate} lending protocol that synthesizes on-chain yield token\nmarkets and lending pools, enabling robust interest rate discovery and\nenhancing capital efficiency. Our work provides the theoretical underpinnings\nfor risk management and fixed-income infrastructure in DeFi, offering practical\nmechanisms for stable and sustainable yield markets.",
    "pdf_url": "http://arxiv.org/pdf/2505.22784v3",
    "published": "2025-05-28T18:57:28+00:00",
    "categories": [
      "econ.TH",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "econ.TH"
  },
  {
    "id": "http://arxiv.org/abs/2506.03170v2",
    "title": "PALADIN : Robust Neural Fingerprinting for Text-to-Image Diffusion Models",
    "authors": [
      "Murthy L",
      "Subarna Tripathi"
    ],
    "abstract": "The risk of misusing text-to-image generative models for malicious uses,\nespecially due to the open-source development of such models, has become a\nserious concern. As a risk mitigation strategy, attributing generative models\nwith neural fingerprinting is emerging as a popular technique. There has been a\nplethora of recent work that aim for addressing neural fingerprinting. A\ntrade-off between the attribution accuracy and generation quality of such\nmodels has been studied extensively. None of the existing methods yet achieved\n100% attribution accuracy. However, any model with less than cent percent\naccuracy is practically non-deployable. In this work, we propose an accurate\nmethod to incorporate neural fingerprinting for text-to-image diffusion models\nleveraging the concepts of cyclic error correcting codes from the literature of\ncoding theory.",
    "pdf_url": "http://arxiv.org/pdf/2506.03170v2",
    "published": "2025-05-28T18:52:40+00:00",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.22783v1",
    "title": "Temporal Convolutional Autoencoder for Interference Mitigation in FMCW Radar Altimeters",
    "authors": [
      "Charles E. Thornton",
      "Jamie Sloop",
      "Samuel Brown",
      "Aaron Orndorff",
      "William C. Headley",
      "Stephen Young"
    ],
    "abstract": "We investigate the end-to-end altitude estimation performance of a\nconvolutional autoencoder-based interference mitigation approach for\nfrequency-modulated continuous-wave (FMCW) radar altimeters. Specifically, we\nshow that a Temporal Convolutional Network (TCN) autoencoder effectively\nexploits temporal correlations in the received signal, providing superior\ninterference suppression compared to a Least Mean Squares (LMS) adaptive\nfilter. Unlike existing approaches, the present method operates directly on the\nreceived FMCW signal. Additionally, we identify key challenges in applying deep\nlearning to wideband FMCW interference mitigation and outline directions for\nfuture research to enhance real-time feasibility and generalization to\narbitrary interference conditions.",
    "pdf_url": "http://arxiv.org/pdf/2505.22783v1",
    "published": "2025-05-28T18:52:10+00:00",
    "categories": [
      "eess.SP",
      "cs.LG"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2505.22782v1",
    "title": "Molecular anyons in fractional quantum Hall effect",
    "authors": [
      "Mytraya Gattu",
      "J. K. Jain"
    ],
    "abstract": "One of the profound consequences of the fractional quantum Hall (FQH) effect\nis the notion of fractionally charged anyons. In spite of extensive\nexperimental study, puzzles remain, however. For example, both shot-noise and\nAharonov-Bohm interference measurements sometimes report a charge that is a\nmultiple of the elementary charge. We report here high-precision microscopic\ncalculations that reveal the surprising result that the FQH anyons often bind\ntogether into stable clusters, which we term molecular anyons. This is\ncounterintuitive, given that the elementary anyons carry the same charge and\nare therefore expected to repel one another. The number of anyons in a cluster,\nits binding energy and its size depend sensitively on the parent FQH state and\nthe interaction between electrons (which is experimentally tunable, e.g., by\nvarying the quantum well width). Our calculations further suggest that the\ncharge-$1/4$ non-Abelian anyons of the $5/2$ FQH state may also bind to form\ncharge-$1/2$ Abelian clusters. The existence of molecular anyons not only can\nprovide a natural explanation for the observed charges, but also leads to a\nhost of new predictions for future experiments and invites a re-analysis of\nmany past ones.",
    "pdf_url": "http://arxiv.org/pdf/2505.22782v1",
    "published": "2025-05-28T18:51:30+00:00",
    "categories": [
      "cond-mat.str-el",
      "cond-mat.mes-hall"
    ],
    "primary_category": "cond-mat.str-el"
  },
  {
    "id": "http://arxiv.org/abs/2505.22781v1",
    "title": "Finite-Sample Convergence Bounds for Trust Region Policy Optimization in Mean-Field Games",
    "authors": [
      "Antonio Ocello",
      "Daniil Tiapkin",
      "Lorenzo Mancini",
      "Mathieu Lauri√®re",
      "Eric Moulines"
    ],
    "abstract": "We introduce Mean-Field Trust Region Policy Optimization (MF-TRPO), a novel\nalgorithm designed to compute approximate Nash equilibria for ergodic\nMean-Field Games (MFG) in finite state-action spaces. Building on the\nwell-established performance of TRPO in the reinforcement learning (RL)\nsetting, we extend its methodology to the MFG framework, leveraging its\nstability and robustness in policy optimization. Under standard assumptions in\nthe MFG literature, we provide a rigorous analysis of MF-TRPO, establishing\ntheoretical guarantees on its convergence. Our results cover both the exact\nformulation of the algorithm and its sample-based counterpart, where we derive\nhigh-probability guarantees and finite sample complexity. This work advances\nMFG optimization by bridging RL techniques with mean-field decision-making,\noffering a theoretically grounded approach to solving complex multi-agent\nproblems.",
    "pdf_url": "http://arxiv.org/pdf/2505.22781v1",
    "published": "2025-05-28T18:50:25+00:00",
    "categories": [
      "stat.ML",
      "cs.LG",
      "math.ST",
      "stat.TH"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2505.22780v1",
    "title": "Depth to magnetic source estimation using TDX contour",
    "authors": [
      "Hammed Oyekan"
    ],
    "abstract": "Accurate depth estimation of magnetic sources plays a crucial role in various\ngeophysical applications, including mineral exploration, resource assessments,\nregional hydrocarbon exploration, and geological mapping. Thus, this abstract\npresents a fast and simple method of estimating the depth of a magnetic body\nusing the TDX derivative of the total magnetic field. TDX is a first-order\nderivative of the magnetic field that, in addition to edge detection, is less\naffected by noise, allowing for better depth resolution. The reduced\nsensitivity to noise enables a clearer estimation of depth and enhances the\naccuracy of the depth determination process. The TDX, as a variant of the phase\nderivative, is independent of magnetization and can be used to identify the\nedge of a magnetic body. In addition to excelling at edge detection, they can\nalso estimate the depth of the magnetic source producing the anomalies. In this\nstudy, we explore the utilization of contour of the TDX derivative for\nestimating depth, assuming a vertical contact source. We demonstrate the\neffectiveness of the method using a two-prism block model and a simple bishop\nmodel with a uniform susceptibility of 0.001 cgs. The results agree with the\nknown depth, providing evidence of the reliability of the method despite the\nrestrictive nature of the assumption, especially for the Bishop model, where\nthere are numerous fault structures.",
    "pdf_url": "http://arxiv.org/pdf/2505.22780v1",
    "published": "2025-05-28T18:47:56+00:00",
    "categories": [
      "physics.geo-ph"
    ],
    "primary_category": "physics.geo-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.22779v1",
    "title": "Predicting Human Depression with Hybrid Data Acquisition utilizing Physical Activity Sensing and Social Media Feeds",
    "authors": [
      "Mohammad Helal Uddin",
      "Sabur Baidya"
    ],
    "abstract": "Mental disorders including depression, anxiety, and other neurological\ndisorders pose a significant global challenge, particularly among individuals\nexhibiting social avoidance tendencies. This study proposes a hybrid approach\nby leveraging smartphone sensor data measuring daily physical activities and\nanalyzing their social media (Twitter) interactions for evaluating an\nindividual's depression level. Using CNN-based deep learning models and Naive\nBayes classification, we identify human physical activities accurately and also\nclassify the user sentiments. A total of 33 participants were recruited for\ndata acquisition, and nine relevant features were extracted from the physical\nactivities and analyzed with their weekly depression scores, evaluated using\nthe Geriatric Depression Scale (GDS) questionnaire. Of the nine features, six\nare derived from physical activities, achieving an activity recognition\naccuracy of 95%, while three features stem from sentiment analysis of Twitter\nactivities, yielding a sentiment analysis accuracy of 95.6%. Notably, several\nphysical activity features exhibited significant correlations with the severity\nof depression symptoms. For classifying the depression severity, a support\nvector machine (SVM)-based algorithm is employed that demonstrated a very high\naccuracy of 94%, outperforming alternative models, e.g., the multilayer\nperceptron (MLP) and k-nearest neighbor. It is a simple approach yet highly\neffective in the long run for monitoring depression without breaching personal\nprivacy.",
    "pdf_url": "http://arxiv.org/pdf/2505.22779v1",
    "published": "2025-05-28T18:47:34+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.22778v1",
    "title": "Machine Learning Models Have a Supply Chain Problem",
    "authors": [
      "Sarah Meiklejohn",
      "Hayden Blauzvern",
      "Mihai Maruseac",
      "Spencer Schrock",
      "Laurent Simon",
      "Ilia Shumailov"
    ],
    "abstract": "Powerful machine learning (ML) models are now readily available online, which\ncreates exciting possibilities for users who lack the deep technical expertise\nor substantial computing resources needed to develop them. On the other hand,\nthis type of open ecosystem comes with many risks. In this paper, we argue that\nthe current ecosystem for open ML models contains significant supply-chain\nrisks, some of which have been exploited already in real attacks. These include\nan attacker replacing a model with something malicious (e.g., malware), or a\nmodel being trained using a vulnerable version of a framework or on restricted\nor poisoned data. We then explore how Sigstore, a solution designed to bring\ntransparency to open-source software supply chains, can be used to bring\ntransparency to open ML models, in terms of enabling model publishers to sign\ntheir models and prove properties about the datasets they use.",
    "pdf_url": "http://arxiv.org/pdf/2505.22778v1",
    "published": "2025-05-28T18:47:14+00:00",
    "categories": [
      "cs.LG",
      "cs.CR"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.22777v2",
    "title": "MEDAL: A Framework for Benchmarking LLMs as Multilingual Open-Domain Chatbots and Dialogue Evaluators",
    "authors": [
      "John Mendon√ßa",
      "Alon Lavie",
      "Isabel Trancoso"
    ],
    "abstract": "As the capabilities of chatbots and their underlying LLMs continue to\ndramatically improve, evaluating their performance has increasingly become a\nmajor blocker to their further development. A major challenge is the available\nbenchmarking datasets, which are largely static, outdated, and lacking in\nmultilingual coverage, limiting their ability to capture subtle linguistic and\ncultural variations. This paper introduces MEDAL, an automated multi-agent\nframework for generating, evaluating, and curating more representative and\ndiverse open-domain dialogue evaluation benchmarks. Our approach leverages\nseveral state-of-the-art LLMs to generate user-chatbot multilingual dialogues,\nconditioned on varied seed contexts. A strong LLM (GPT-4.1) is then used for a\nmultidimensional analysis of the performance of the chatbots, uncovering\nnoticeable cross-lingual performance differences. Guided by this large-scale\nevaluation, we curate a new meta-evaluation multilingual benchmark and\nhuman-annotate samples with nuanced quality judgments. This benchmark is then\nused to assess the ability of several reasoning and non-reasoning LLMs to act\nas evaluators of open-domain dialogues. We find that current LLMs struggle to\ndetect nuanced issues, particularly those involving empathy and reasoning.",
    "pdf_url": "http://arxiv.org/pdf/2505.22777v2",
    "published": "2025-05-28T18:45:42+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.22776v1",
    "title": "A Contingency Model Predictive Control Framework for Safe Learning",
    "authors": [
      "Merlijne Geurts",
      "Tren Baltussen",
      "Alexander Katriniok",
      "Maurice Heemels"
    ],
    "abstract": "This research introduces a multi-horizon contingency model predictive control\n(CMPC) framework in which classes of robust MPC (RMPC) algorithms are combined\nwith classes of learning-based MPC (LB-MPC) algorithms to enable safe learning.\nWe prove that the CMPC framework inherits the robust recursive feasibility\nproperties of the underlying RMPC scheme, thereby ensuring safety of the CMPC\nin the sense of constraint satisfaction. The CMPC leverages the LB-MPC to\nsafely learn the unmodeled dynamics to reduce conservatism and improve\nperformance compared to standalone RMPC schemes, which are conservative in\nnature. In addition, we present an implementation of the CMPC framework that\ncombines a particular RMPC and a Gaussian Process MPC scheme. A simulation\nstudy on automated lane merging demonstrates the advantages of our general CMPC\nframework.",
    "pdf_url": "http://arxiv.org/pdf/2505.22776v1",
    "published": "2025-05-28T18:45:23+00:00",
    "categories": [
      "math.OC"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2505.22775v1",
    "title": "Forecasting Constraints on Non-Thermal Light Massive Relics from Future CMB Experiments",
    "authors": [
      "Arka Banerjee",
      "Abhik Bhattacharjee",
      "Subinoy Das",
      "Anshuman Maharana",
      "Ravi Kumar Sharma"
    ],
    "abstract": "In this work, we present Fisher forecasts on non-thermal LiMR models for the\nupcoming CMB Stage IV experiment -- particularly focusing on a model of\ninflaton/moduli decay giving rise to non-thermally distributed dark sector\nparticles, and also comparing our results with those for sterile particles\nfollowing the Dodelson-Widrow distribution. Two independent parameters, the\neffective number of extra relativistic species $\\Delta N_\\mathrm{eff}$ and the\neffective mass $M_\\mathrm{sp}^\\mathrm{eff}$ of the relic, influence linear\ncosmological observables. We find $\\Delta N_\\mathrm{eff}$ to be more tightly\nconstrained with $\\sigma(\\Delta N_\\mathrm{eff})\\sim10^{-3}$, for a less\nabundant, heavier LiMR which becomes fully non-relativistic around\nmatter-radiation equality than a more abundant, lighter LiMR which becomes\nfully non-relativistic just after recombination, for which $\\sigma(\\Delta\nN_\\mathrm{eff})\\sim10^{-2}$. The uncertainties on $M_\\mathrm{sp}^\\mathrm{eff}$\ndiffer by a factor of $\\sim3$ between the two cases. Our analysis also reveals\ndistinct parameter correlations: the phenomenological parameters $\\{\\Delta\nN_\\mathrm{eff}, M_\\mathrm{sp}^\\mathrm{eff}\\}$ are found to be negatively\ncorrelated for the former case and positively correlated for the latter. We\nobtain similar constraints on the cosmological parameters (in either case) for\nboth the inflaton/moduli decay and the Dodelson-Widrow models when the first\ntwo moments of the LiMR distribution function, related to the phenomenological\nparameters, are matched. Finally, by constructing a modified distribution that\nmatches the first two moments of the Dodelson-Widrow but deviates maximally in\nthe third moment, we demonstrate that CMB Stage IV data is not expected to be\nsensitive to higher moments of the distribution.",
    "pdf_url": "http://arxiv.org/pdf/2505.22775v1",
    "published": "2025-05-28T18:45:11+00:00",
    "categories": [
      "astro-ph.CO",
      "hep-ph"
    ],
    "primary_category": "astro-ph.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.22774v1",
    "title": "Counting trees: A treebank-driven exploration of syntactic variation in speech and writing across languages",
    "authors": [
      "Kaja Dobrovoljc"
    ],
    "abstract": "This paper presents a novel treebank-driven approach to comparing syntactic\nstructures in speech and writing using dependency-parsed corpora. Adopting a\nfully inductive, bottom-up method, we define syntactic structures as\ndelexicalized dependency (sub)trees and extract them from spoken and written\nUniversal Dependencies (UD) treebanks in two syntactically distinct languages,\nEnglish and Slovenian. For each corpus, we analyze the size, diversity, and\ndistribution of syntactic inventories, their overlap across modalities, and the\nstructures most characteristic of speech. Results show that, across both\nlanguages, spoken corpora contain fewer and less diverse syntactic structures\nthan their written counterparts, with consistent cross-linguistic preferences\nfor certain structural types across modalities. Strikingly, the overlap between\nspoken and written syntactic inventories is very limited: most structures\nattested in speech do not occur in writing, pointing to modality-specific\npreferences in syntactic organization that reflect the distinct demands of\nreal-time interaction and elaborated writing. This contrast is further\nsupported by a keyness analysis of the most frequent speech-specific\nstructures, which highlights patterns associated with interactivity,\ncontext-grounding, and economy of expression. We argue that this scalable,\nlanguage-independent framework offers a useful general method for\nsystematically studying syntactic variation across corpora, laying the\ngroundwork for more comprehensive data-driven theories of grammar in use.",
    "pdf_url": "http://arxiv.org/pdf/2505.22774v1",
    "published": "2025-05-28T18:43:26+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.22773v1",
    "title": "Ultra-long-living magnons in the quantum limit",
    "authors": [
      "Rostyslav O. Serha",
      "Kaitlin H. McAllister",
      "Fabian Majcen",
      "Sebastian Knauer",
      "Timmy Reimann",
      "Carsten Dubs",
      "Gennadii A. Melkov",
      "Alexander A. Serga",
      "Vasyl S. Tyberkevych",
      "Andrii V. Chumak",
      "Dmytro A. Bozhko"
    ],
    "abstract": "Coherence time is the property of a quantum system that determines how long a\nstate can hold quantum information. This parameter is directly bound to their\nlifetime in solid-state systems, where quantum information could be stored in\nquasiparticles. For decades, quasiparticles associated with magnetization order\ndisturbance - magnons, had reported lifetimes below one microsecond at\ngigahertz frequencies, restricting their use as a quantum information carrier.\nHere, we report on the observation of short-wavelength magnons with lifetimes\nexceeding 18{\\mu}s at millikelvin temperatures. The experiment has been\nperformed in an ultra-pure single-crystal Yttrium Iron Garnet sphere in a wide\nrange of temperatures from ambient down to 30 mK. Our results open doors for\nusing magnons as data carriers in modern solid-state quantum computing\nplatforms.",
    "pdf_url": "http://arxiv.org/pdf/2505.22773v1",
    "published": "2025-05-28T18:43:02+00:00",
    "categories": [
      "cond-mat.mtrl-sci",
      "quant-ph"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2505.22772v2",
    "title": "Calibrated Value-Aware Model Learning with Probabilistic Environment Models",
    "authors": [
      "Claas Voelcker",
      "Anastasiia Pedan",
      "Arash Ahmadian",
      "Romina Abachi",
      "Igor Gilitschenski",
      "Amir-massoud Farahmand"
    ],
    "abstract": "The idea of value-aware model learning, that models should produce accurate\nvalue estimates, has gained prominence in model-based reinforcement learning.\nThe MuZero loss, which penalizes a model's value function prediction compared\nto the ground-truth value function, has been utilized in several prominent\nempirical works in the literature. However, theoretical investigation into its\nstrengths and weaknesses is limited. In this paper, we analyze the family of\nvalue-aware model learning losses, which includes the popular MuZero loss. We\nshow that these losses, as normally used, are uncalibrated surrogate losses,\nwhich means that they do not always recover the correct model and value\nfunction. Building on this insight, we propose corrections to solve this issue.\nFurthermore, we investigate the interplay between the loss calibration, latent\nmodel architectures, and auxiliary losses that are commonly employed when\ntraining MuZero-style agents. We show that while deterministic models can be\nsufficient to predict accurate values, learning calibrated stochastic models is\nstill advantageous.",
    "pdf_url": "http://arxiv.org/pdf/2505.22772v2",
    "published": "2025-05-28T18:40:49+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.12051v2",
    "title": "GUST: Quantifying Free-Form Geometric Uncertainty of Metamaterials Using Small Data",
    "authors": [
      "Jiahui Zheng",
      "Cole Jahnke",
      "Wei \"Wayne\" Chen"
    ],
    "abstract": "This paper introduces GUST (Generative Uncertainty learning via\nSelf-supervised pretraining and Transfer learning), a framework for quantifying\nfree-form geometric uncertainties inherent in the manufacturing of\nmetamaterials. GUST leverages the representational power of deep generative\nmodels to learn a high-dimensional conditional distribution of as-fabricated\nunit cell geometries given nominal designs, thereby enabling uncertainty\nquantification. To address the scarcity of real-world manufacturing data, GUST\nemploys a two-stage learning process. First, it leverages self-supervised\npretraining on a large-scale synthetic dataset to capture the structure\nvariability inherent in metamaterial geometries and an approximated\ndistribution of as-fabricated geometries given nominal designs. Subsequently,\nGUST employs transfer learning by fine-tuning the pretrained model on limited\nreal-world manufacturing data, allowing it to adapt to specific manufacturing\nprocesses and nominal designs. With only 960 unit cells additively manufactured\nin only two passes, GUST can capture the variability in geometry and effective\nmaterial properties. In contrast, directly training a generative model on the\nsame amount of real-world data proves insufficient, as demonstrated through\nboth qualitative and quantitative comparisons. This scalable and cost-effective\napproach significantly reduces data requirements while maintaining the\neffectiveness in learning complex, real-world geometric uncertainties, offering\nan affordable method for free-form geometric uncertainty quantification in the\nmanufacturing of metamaterials. The capabilities of GUST hold significant\npromise for high-precision industries such as aerospace and biomedical\nengineering, where understanding and mitigating manufacturing uncertainties are\ncritical.",
    "pdf_url": "http://arxiv.org/pdf/2506.12051v2",
    "published": "2025-05-28T18:40:15+00:00",
    "categories": [
      "cs.LG",
      "cs.CE"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.00050v1",
    "title": "Distinguishing Fact from Fiction: Student Traits, Attitudes, and AI Hallucination Detection in Business School Assessment",
    "authors": [
      "Canh Thien Dang",
      "An Nguyen"
    ],
    "abstract": "As artificial intelligence (AI) becomes integral to the society, the ability\nto critically evaluate AI-generated content is increasingly vital. On the\ncontext of management education, we examine how academic skills, cognitive\ntraits, and AI scepticism influence students' ability to detect factually\nincorrect AI-generated responses (hallucinations) in a high-stakes assessment\nat a UK business school (n=211, Year 2 economics and management students). We\nfind that only 20% successfully identified the hallucination, with strong\nacademic performance, interpretive skills thinking, writing proficiency, and AI\nscepticism emerging as key predictors. In contrast, rote knowledge application\nproved less effective, and gender differences in detection ability were\nobserved. Beyond identifying predictors of AI hallucination detection, we tie\nthe theories of epistemic cognition, cognitive bias, and transfer of learning\nwith new empirical evidence by demonstrating how AI literacy could enhance\nlong-term analytical performance in high-stakes settings. We advocate for an\ninnovative and practical framework for AI-integrated assessments, showing that\nstructured feedback mitigates initial disparities in detection ability. These\nfindings provide actionable insights for educators designing AI-aware curricula\nthat foster critical reasoning, epistemic vigilance, and responsible AI\nengagement in management education. Our study contributes to the broader\ndiscussion on the evolution of knowledge evaluation in AI-enhanced learning\nenvironments.",
    "pdf_url": "http://arxiv.org/pdf/2506.00050v1",
    "published": "2025-05-28T18:39:57+00:00",
    "categories": [
      "cs.CY"
    ],
    "primary_category": "cs.CY"
  },
  {
    "id": "http://arxiv.org/abs/2505.22771v2",
    "title": "Automated Essay Scoring Incorporating Annotations from Automated Feedback Systems",
    "authors": [
      "Christopher Ormerod"
    ],
    "abstract": "This study illustrates how incorporating feedback-oriented annotations into\nthe scoring pipeline can enhance the accuracy of automated essay scoring (AES).\nThis approach is demonstrated with the Persuasive Essays for Rating, Selecting,\nand Understanding Argumentative and Discourse Elements (PERSUADE) corpus. We\nintegrate two types of feedback-driven annotations: those that identify\nspelling and grammatical errors, and those that highlight argumentative\ncomponents. To illustrate how this method could be applied in real-world\nscenarios, we employ two LLMs to generate annotations -- a generative language\nmodel used for spell correction and an encoder-based token-classifier trained\nto identify and mark argumentative elements. By incorporating annotations into\nthe scoring process, we demonstrate improvements in performance using\nencoder-based large language models fine-tuned as classifiers.",
    "pdf_url": "http://arxiv.org/pdf/2505.22771v2",
    "published": "2025-05-28T18:39:56+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.00049v1",
    "title": "Rethinking Hybrid Retrieval: When Small Embeddings and LLM Re-ranking Beat Bigger Models",
    "authors": [
      "Arjun Rao",
      "Hanieh Alipour",
      "Nick Pendar"
    ],
    "abstract": "This paper presents a comparison of embedding models in tri-modal hybrid\nretrieval for Retrieval-Augmented Generation (RAG) systems. We investigate the\nfusion of dense semantic, sparse lexical, and graph-based embeddings, focusing\non the performance of the MiniLM-v6 and BGE-Large architectures. Contrary to\nconventional assumptions, our results show that the compact MiniLM-v6\noutperforms the larger BGE-Large when integrated with LLM-based re-ranking\nwithin our tri-modal hybrid framework. Experiments conducted on the SciFact,\nFIQA, and NFCorpus datasets demonstrate significant improvements in retrieval\nquality with the MiniLM-v6 configuration. The performance difference is\nparticularly pronounced in agentic re-ranking scenarios, indicating better\nalignment between MiniLM-v6's embedding space and LLM reasoning. Our findings\nsuggest that embedding model selection for RAG systems should prioritize\ncompatibility with multi-signal fusion and LLM alignment, rather than relying\nsolely on larger models. This approach may reduce computational requirements\nwhile improving retrieval accuracy and efficiency.",
    "pdf_url": "http://arxiv.org/pdf/2506.00049v1",
    "published": "2025-05-28T18:39:40+00:00",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2505.22770v2",
    "title": "Mutation of $œÑ$-exceptional sequences for acyclic quivers over local algebras",
    "authors": [
      "Iacopo Nonis"
    ],
    "abstract": "Let $k$ be an algebraically closed field. Let $R$ be a local commutative\nfinite dimensional $k$-algebra and let $Q$ be a quiver with no loops or\noriented cycles. We show that mutation of $\\tau$-exceptional sequences over\n$\\Lambda = R\\otimes_k kQ \\cong RQ$ in the sense of Buan, Hanson, and Marsh\ncoincides with the classical mutation of exceptional sequences defined by\nCrawley-Boevey and Ringel. In particular, the braid group acts transitively on\nthe set of complete $\\tau$-exceptional sequences in $\\text{mod }{\\Lambda}$.",
    "pdf_url": "http://arxiv.org/pdf/2505.22770v2",
    "published": "2025-05-28T18:38:49+00:00",
    "categories": [
      "math.RT",
      "16D90, 16G10, 16G20, 16S90"
    ],
    "primary_category": "math.RT"
  },
  {
    "id": "http://arxiv.org/abs/2505.22769v3",
    "title": "MAC-Gaze: Motion-Aware Continual Calibration for Mobile Gaze Tracking",
    "authors": [
      "Yaxiong Lei",
      "Mingyue Zhao",
      "Yuheng Wang",
      "Shijing He",
      "Yusuke Sugano",
      "Mohamed Khamis",
      "Juan Ye"
    ],
    "abstract": "Mobile gaze tracking faces a fundamental challenge: maintaining accuracy as\nusers naturally change their postures and device orientations. Traditional\ncalibration approaches, like one-off, fail to adapt to these dynamic\nconditions, leading to degraded performance over time. We present MAC-Gaze, a\nMotion-Aware continual Calibration approach that leverages smartphone Inertial\nmeasurement unit (IMU) sensors and continual learning techniques to\nautomatically detect changes in user motion states and update the gaze tracking\nmodel accordingly. Our system integrates a pre-trained visual gaze estimator\nand an IMU-based activity recognition model with a clustering-based hybrid\ndecision-making mechanism that triggers recalibration when motion patterns\ndeviate significantly from previously encountered states. To enable\naccumulative learning of new motion conditions while mitigating catastrophic\nforgetting, we employ replay-based continual learning, allowing the model to\nmaintain performance across previously encountered motion conditions. We\nevaluate our system through extensive experiments on the publicly available\nRGBDGaze dataset and our own 10-hour multimodal MotionGaze dataset (481K+\nimages, 800K+ IMU readings), encompassing a wide range of postures under\nvarious motion conditions including sitting, standing, lying, and walking.\nResults demonstrate that our method reduces gaze estimation error by 19.9% on\nRGBDGaze (from 1.73 cm to 1.41 cm) and by 31.7% on MotionGaze (from 2.81 cm to\n1.92 cm) compared to traditional calibration approaches. Our framework provides\na robust solution for maintaining gaze estimation accuracy in mobile scenarios.",
    "pdf_url": "http://arxiv.org/pdf/2505.22769v3",
    "published": "2025-05-28T18:38:04+00:00",
    "categories": [
      "cs.HC",
      "cs.CV",
      "68T10, 68U35",
      "H.5.2; H.1.2; C.2.4; I.5.4"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2505.22768v3",
    "title": "Multivariate de Bruijn Graphs: A Symbolic Graph Framework for Time Series Forecasting",
    "authors": [
      "Mert Onur Cakiroglu",
      "Idil Bilge Altun",
      "Mehmet Dalkilic",
      "Elham Buxton",
      "Hasan Kurban"
    ],
    "abstract": "Time series forecasting remains a challenging task for foundation models due\nto temporal heterogeneity, high dimensionality, and the lack of inherent\nsymbolic structure. In this work, we propose DRAGON (Discrete Representation\nand Augmented Graph encoding Over de BruijN Graphs), a novel encoder that\nintroduces Multivariate de Bruijn Graphs (MdBGs) to bridge the gap between\nsymbolic representations and neural modeling. DRAGON discretizes continuous\ninput sequences and maps them onto a fixed graph structure, enabling dynamic\ncontext recovery via graph-based attention. Integrated as an auxiliary module\nwithin a dual-branch architecture, DRAGON augments conventional CNN-based\nencoders with symbolic, structure-aware representations. All code developed for\nthis study is available at:\nhttps://github.com/KurbanIntelligenceLab/MultdBG-Time-Series-Library",
    "pdf_url": "http://arxiv.org/pdf/2505.22768v3",
    "published": "2025-05-28T18:36:26+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.22767v2",
    "title": "In Dialogue with Intelligence: Rethinking Large Language Models as Collective Knowledge",
    "authors": [
      "Eleni Vasilaki"
    ],
    "abstract": "Large Language Models (LLMs) are typically analysed through architectural,\nbehavioural, or training-data lenses. This article offers a theoretical and\nexperiential re-framing: LLMs as dynamic instantiations of Collective human\nKnowledge (CK), where intelligence is evoked through dialogue rather than\nstored statically. Drawing on concepts from neuroscience and AI, and grounded\nin sustained interaction with ChatGPT-4, I examine emergent dialogue patterns,\nthe implications of fine-tuning, and the notion of co-augmentation: mutual\nenhancement between human and machine cognition. This perspective offers a new\nlens for understanding interaction, representation, and agency in contemporary\nAI systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.22767v2",
    "published": "2025-05-28T18:36:00+00:00",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2505.22766v2",
    "title": "On the independent set polynomial of graphs and claw-free graphs",
    "authors": [
      "Paula M. S. Fialho",
      "Aldo Procacci"
    ],
    "abstract": "We present two new contributions to the study of the independence polynomial\n$Z_G(z)$ of a finite simple graph $G = (V,E)$. First, we provide an improved\nlower bound for the zero-free region of $Z_G(z)$ for the important class of\nclaw-free graphs. Our bound exceeds the classical Shearer radius and it is\nderived through a refined application of the Fern\\'andez-Procacci criterion\nusing properties of the local neighborhood structure in claw-free graphs.\nSecond, we establish a novel combinatorial expression for $Z_G(z)$, inspired by\nthe connection with the abstract polymer gas models in statistical mechanics,\nwhich offers a new structural interpretation of the polynomial and may be of\nindependent interest. These results strengthen the connection between\nstatistical physics, combinatorics, and graph theory, and suggest new\napproaches for analytic exploration.",
    "pdf_url": "http://arxiv.org/pdf/2505.22766v2",
    "published": "2025-05-28T18:34:34+00:00",
    "categories": [
      "math.CO",
      "math-ph",
      "math.MP",
      "05C31"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.22765v1",
    "title": "StressTest: Can YOUR Speech LM Handle the Stress?",
    "authors": [
      "Iddo Yosha",
      "Gallil Maimon",
      "Yossi Adi"
    ],
    "abstract": "Sentence stress refers to emphasis, placed on specific words within a spoken\nutterance to highlight or contrast an idea, or to introduce new information. It\nis often used to imply an underlying intention that is not explicitly stated.\nRecent advances in speech-aware language models (SLMs) have enabled direct\nprocessing of audio, allowing models to bypass transcription and access the\nfull richness of the speech signal and perform audio reasoning tasks such as\nspoken question answering. Despite the crucial role of sentence stress in\nshaping meaning and speaker intent, it remains largely overlooked in evaluation\nand development of such models. In this work, we address this gap by\nintroducing StressTest, a benchmark specifically designed to evaluate a model's\nability to distinguish between interpretations of spoken sentences based on the\nstress pattern. We assess the performance of several leading SLMs and find\nthat, despite their overall capabilities, they perform poorly on such tasks. To\novercome this limitation, we propose a novel synthetic data generation\npipeline, and create Stress17k, a training set that simulates change of meaning\nimplied by stress variation. Then, we empirically show that optimizing models\nwith this synthetic dataset aligns well with real-world recordings and enables\neffective finetuning of SLMs. Results suggest, that our finetuned model,\nStresSLM, significantly outperforms existing models on both sentence stress\nreasoning and detection tasks. Code, models, data, and audio samples -\npages.cs.huji.ac.il/adiyoss-lab/stresstest.",
    "pdf_url": "http://arxiv.org/pdf/2505.22765v1",
    "published": "2025-05-28T18:32:56+00:00",
    "categories": [
      "cs.CL",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.22764v1",
    "title": "Test-time augmentation improves efficiency in conformal prediction",
    "authors": [
      "Divya Shanmugam",
      "Helen Lu",
      "Swami Sankaranarayanan",
      "John Guttag"
    ],
    "abstract": "A conformal classifier produces a set of predicted classes and provides a\nprobabilistic guarantee that the set includes the true class. Unfortunately, it\nis often the case that conformal classifiers produce uninformatively large\nsets. In this work, we show that test-time augmentation (TTA)--a technique that\nintroduces inductive biases during inference--reduces the size of the sets\nproduced by conformal classifiers. Our approach is flexible, computationally\nefficient, and effective. It can be combined with any conformal score, requires\nno model retraining, and reduces prediction set sizes by 10%-14% on average. We\nconduct an evaluation of the approach spanning three datasets, three models,\ntwo established conformal scoring methods, different guarantee strengths, and\nseveral distribution shifts to show when and why test-time augmentation is a\nuseful addition to the conformal pipeline.",
    "pdf_url": "http://arxiv.org/pdf/2505.22764v1",
    "published": "2025-05-28T18:29:31+00:00",
    "categories": [
      "cs.LG",
      "cs.CV"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.22763v3",
    "title": "Probability of the Initial Conditions for Inflation and Slow Contraction",
    "authors": [
      "Mark P. Hertzberg",
      "Daniel Jim√©nez-Aguilar"
    ],
    "abstract": "Some recent studies based on numerical relativity simulations claim that slow\ncontraction/ekpyrosis is strongly preferred over inflation as the smoothing\nmechanism that brought the universe into the homogeneous, isotropic and flat\nstate we observe today on large scales. In this paper, we evaluate the\nlikelihood of the initial conditions employed in the aforementioned simulations\nby estimating the probability that a free scalar field dominating the universe\nat the beginning of inflation or ekpyrosis will be sufficiently homogeneous on\nscales comparable to the Hubble radius at that time. We explore the space of\nparameters that characterize the initial power spectrum of the scalar field,\nfinding that either can be more likely than the other for a fixed choice of\nparameters. On the other hand, when we extremize over these parameters, we find\nthat the maximal probability for inflation is much higher than that of\nekpyrosis.",
    "pdf_url": "http://arxiv.org/pdf/2505.22763v3",
    "published": "2025-05-28T18:27:39+00:00",
    "categories": [
      "gr-qc",
      "astro-ph.CO",
      "hep-ph",
      "hep-th"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2505.22762v1",
    "title": "MIAS-SAM: Medical Image Anomaly Segmentation without thresholding",
    "authors": [
      "Marco Colussi",
      "Dragan Ahmetovic",
      "Sergio Mascetti"
    ],
    "abstract": "This paper presents MIAS-SAM, a novel approach for the segmentation of\nanomalous regions in medical images. MIAS-SAM uses a patch-based memory bank to\nstore relevant image features, which are extracted from normal data using the\nSAM encoder. At inference time, the embedding patches extracted from the SAM\nencoder are compared with those in the memory bank to obtain the anomaly map.\nFinally, MIAS-SAM computes the center of gravity of the anomaly map to prompt\nthe SAM decoder, obtaining an accurate segmentation from the previously\nextracted features. Differently from prior works, MIAS-SAM does not require to\ndefine a threshold value to obtain the segmentation from the anomaly map.\nExperimental results conducted on three publicly available datasets, each with\na different imaging modality (Brain MRI, Liver CT, and Retina OCT) show\naccurate anomaly segmentation capabilities measured using DICE score. The code\nis available at: https://github.com/warpcut/MIAS-SAM",
    "pdf_url": "http://arxiv.org/pdf/2505.22762v1",
    "published": "2025-05-28T18:25:37+00:00",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.22761v1",
    "title": "A comprehensive analysis of PINNs: Variants, Applications, and Challenges",
    "authors": [
      "Afila Ajithkumar Sophiya",
      "Akarsh K Nair",
      "Sepehr Maleki",
      "Senthil K. Krishnababu"
    ],
    "abstract": "Physics Informed Neural Networks (PINNs) have been emerging as a powerful\ncomputational tool for solving differential equations. However, the\napplicability of these models is still in its initial stages and requires more\nstandardization to gain wider popularity. Through this survey, we present a\ncomprehensive overview of PINNs approaches exploring various aspects related to\ntheir architecture, variants, areas of application, real-world use cases,\nchallenges, and so on. Even though existing surveys can be identified, they\nfail to provide a comprehensive view as they primarily focus on either\ndifferent application scenarios or limit their study to a superficial level.\nThis survey attempts to bridge the gap in the existing literature by presenting\na detailed analysis of all these factors combined with recent advancements and\nstate-of-the-art research in PINNs. Additionally, we discuss prevalent\nchallenges in PINNs implementation and present some of the future research\ndirections as well. The overall contributions of the survey can be summarised\ninto three sections: A detailed overview of PINNs architecture and variants, a\nperformance analysis of PINNs on different equations and application domains\nhighlighting their features. Finally, we present a detailed discussion of\ncurrent issues and future research directions.",
    "pdf_url": "http://arxiv.org/pdf/2505.22761v1",
    "published": "2025-05-28T18:25:17+00:00",
    "categories": [
      "cs.CE",
      "cs.AI"
    ],
    "primary_category": "cs.CE"
  },
  {
    "id": "http://arxiv.org/abs/2505.22760v1",
    "title": "Non-convex entropic mean-field optimization via Best Response flow",
    "authors": [
      "Razvan-Andrei Lascu",
      "Mateusz B. Majka"
    ],
    "abstract": "We study the problem of minimizing non-convex functionals on the space of\nprobability measures, regularized by the relative entropy (KL divergence) with\nrespect to a fixed reference measure, as well as the corresponding problem of\nsolving entropy-regularized non-convex-non-concave min-max problems. We utilize\nthe Best Response flow (also known in the literature as the fictitious play\nflow) and study how its convergence is influenced by the relation between the\ndegree of non-convexity of the functional under consideration, the\nregularization parameter and the tail behaviour of the reference measure. In\nparticular, we demonstrate how to choose the regularizer, given the non-convex\nfunctional, so that the Best Response operator becomes a contraction with\nrespect to the $L^1$-Wasserstein distance, which then ensures the existence of\nits unique fixed point, which is then shown to be the unique global minimizer\nfor our optimization problem. This extends recent results where the Best\nResponse flow was applied to solve convex optimization problems regularized by\nthe relative entropy with respect to arbitrary reference measures, and with\narbitrary values of the regularization parameter. Our results explain precisely\nhow the assumption of convexity can be relaxed, at the expense of making a\nspecific choice of the regularizer. Additionally, we demonstrate how these\nresults can be applied in reinforcement learning in the context of policy\noptimization for Markov Decision Processes and Markov games with softmax\nparametrized policies in the mean-field regime.",
    "pdf_url": "http://arxiv.org/pdf/2505.22760v1",
    "published": "2025-05-28T18:22:08+00:00",
    "categories": [
      "math.OC",
      "cs.LG",
      "math.PR"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2505.22759v2",
    "title": "FAMA: The First Large-Scale Open-Science Speech Foundation Model for English and Italian",
    "authors": [
      "Sara Papi",
      "Marco Gaido",
      "Luisa Bentivogli",
      "Alessio Brutti",
      "Mauro Cettolo",
      "Roberto Gretter",
      "Marco Matassoni",
      "Mohamed Nabih",
      "Matteo Negri"
    ],
    "abstract": "The development of speech foundation models (SFMs) like Whisper and\nSeamlessM4T has significantly advanced the field of speech processing. However,\ntheir closed nature--with inaccessible training data and code--poses major\nreproducibility and fair evaluation challenges. While other domains have made\nsubstantial progress toward open science by developing fully transparent models\ntrained on open-source (OS) code and data, similar efforts in speech remain\nlimited. To fill this gap, we introduce FAMA, the first family of open science\nSFMs for English and Italian, trained on 150k+ hours of OS speech data.\nMoreover, we present a new dataset containing 16k hours of cleaned and\npseudo-labeled speech for both languages. Results show that FAMA achieves\ncompetitive performance compared to existing SFMs while being up to 8 times\nfaster. All artifacts, including code, datasets, and models, are released under\nOS-compliant licenses, promoting openness in speech technology research.",
    "pdf_url": "http://arxiv.org/pdf/2505.22759v2",
    "published": "2025-05-28T18:19:34+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.SD"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.22758v1",
    "title": "FlashFormer: Whole-Model Kernels for Efficient Low-Batch Inference",
    "authors": [
      "Aniruddha Nrusimha",
      "William Brandon",
      "Mayank Mishra",
      "Yikang Shen",
      "Rameswar Panda",
      "Jonathan Ragan-Kelley",
      "Yoon Kim"
    ],
    "abstract": "The size and compute characteristics of modern large language models have led\nto an increased interest in developing specialized kernels tailored for\ntraining and inference. Existing kernels primarily optimize for compute\nutilization, targeting the large-batch training and inference settings.\nHowever, low-batch inference, where memory bandwidth and kernel launch\noverheads contribute are significant factors, remains important for many\napplications of interest such as in edge deployment and latency-sensitive\napplications. This paper describes FlashFormer, a proof-of-concept kernel for\naccelerating single-batch inference for transformer-based large language\nmodels. Across various model sizes and quantizations settings, we observe\nnontrivial speedups compared to existing state-of-the-art inference kernels.",
    "pdf_url": "http://arxiv.org/pdf/2505.22758v1",
    "published": "2025-05-28T18:19:30+00:00",
    "categories": [
      "cs.LG",
      "cs.CL"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.22757v1",
    "title": "Pre-Training Curriculum for Multi-Token Prediction in Language Models",
    "authors": [
      "Ansar Aynetdinov",
      "Alan Akbik"
    ],
    "abstract": "Multi-token prediction (MTP) is a recently proposed pre-training objective\nfor language models. Rather than predicting only the next token (NTP), MTP\npredicts the next $k$ tokens at each prediction step, using multiple prediction\nheads. MTP has shown promise in improving downstream performance, inference\nspeed, and training efficiency, particularly for large models. However, prior\nwork has shown that smaller language models (SLMs) struggle with the MTP\nobjective. To address this, we propose a curriculum learning strategy for MTP\ntraining, exploring two variants: a forward curriculum, which gradually\nincreases the complexity of the pre-training objective from NTP to MTP, and a\nreverse curriculum, which does the opposite. Our experiments show that the\nforward curriculum enables SLMs to better leverage the MTP objective during\npre-training, improving downstream NTP performance and generative output\nquality, while retaining the benefits of self-speculative decoding. The reverse\ncurriculum achieves stronger NTP performance and output quality, but fails to\nprovide any self-speculative decoding benefits.",
    "pdf_url": "http://arxiv.org/pdf/2505.22757v1",
    "published": "2025-05-28T18:19:18+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.23847v3",
    "title": "Seven Security Challenges That Must be Solved in Cross-domain Multi-agent LLM Systems",
    "authors": [
      "Ronny Ko",
      "Jiseong Jeong",
      "Shuyuan Zheng",
      "Chuan Xiao",
      "Tae-Wan Kim",
      "Makoto Onizuka",
      "Won-Yong Shin"
    ],
    "abstract": "Large language models (LLMs) are rapidly evolving into autonomous agents that\ncooperate across organizational boundaries, enabling joint disaster response,\nsupply-chain optimization, and other tasks that demand decentralized expertise\nwithout surrendering data ownership. Yet, cross-domain collaboration shatters\nthe unified trust assumptions behind current alignment and containment\ntechniques. An agent benign in isolation may, when receiving messages from an\nuntrusted peer, leak secrets or violate policy, producing risks driven by\nemergent multi-agent dynamics rather than classical software bugs. This\nposition paper maps the security agenda for cross-domain multi-agent LLM\nsystems. We introduce seven categories of novel security challenges, for each\nof which we also present plausible attacks, security evaluation metrics, and\nfuture research guidelines.",
    "pdf_url": "http://arxiv.org/pdf/2505.23847v3",
    "published": "2025-05-28T18:19:03+00:00",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.22756v1",
    "title": "Decomposing Elements of Problem Solving: What \"Math\" Does RL Teach?",
    "authors": [
      "Tian Qin",
      "Core Francisco Park",
      "Mujin Kwun",
      "Aaron Walsman",
      "Eran Malach",
      "Nikhil Anand",
      "Hidenori Tanaka",
      "David Alvarez-Melis"
    ],
    "abstract": "Mathematical reasoning tasks have become prominent benchmarks for assessing\nthe reasoning capabilities of LLMs, especially with reinforcement learning (RL)\nmethods such as GRPO showing significant performance gains. However, accuracy\nmetrics alone do not support fine-grained assessment of capabilities and fail\nto reveal which problem-solving skills have been internalized. To better\nunderstand these capabilities, we propose to decompose problem solving into\nfundamental capabilities: Plan (mapping questions to sequences of steps),\nExecute (correctly performing solution steps), and Verify (identifying the\ncorrectness of a solution). Empirically, we find that GRPO mainly enhances the\nexecution skill-improving execution robustness on problems the model already\nknows how to solve-a phenomenon we call temperature distillation. More\nimportantly, we show that RL-trained models struggle with fundamentally new\nproblems, hitting a 'coverage wall' due to insufficient planning skills. To\nexplore RL's impact more deeply, we construct a minimal, synthetic\nsolution-tree navigation task as an analogy for mathematical problem-solving.\nThis controlled setup replicates our empirical findings, confirming RL\nprimarily boosts execution robustness. Importantly, in this setting, we\nidentify conditions under which RL can potentially overcome the coverage wall\nthrough improved exploration and generalization to new solution paths. Our\nfindings provide insights into the role of RL in enhancing LLM reasoning,\nexpose key limitations, and suggest a path toward overcoming these barriers.\nCode is available at https://github.com/cfpark00/RL-Wall.",
    "pdf_url": "http://arxiv.org/pdf/2505.22756v1",
    "published": "2025-05-28T18:18:49+00:00",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.22755v1",
    "title": "A canonical Makanin-Razborov diagram and a pseudo topology for sets of tuples in free groups, semigroups, associative algebras and Lie algebras I",
    "authors": [
      "Z. Sela"
    ],
    "abstract": "The JSJ decomposition and the Makanin-Razborov diagram were proved to be\nessential in studying varieties over free groups, semigroups and associative\nalgebras. In this paper we suggest a unified conceptual approach to the\napplicability of these structures over all these algebraic categories. With a\nvariety over each of these algebraic categories we naturally associate a set of\ntuples in a free group. Then we show how to associate a Makanin-Razborov\ndiagram with any set of tuples over a free group. Furthermore, in case the MR\ndiagram that is associated with a set of tuples is single ended, we prove that\nthere is a canonical Makanin-Razborov diagram that can be associated with such\na set. This canonical diagram is a main key in studying varieties over free\nsemigroups, associative algebras and Lie algebras, and encodes the global\nstructure of these varieties. It enables us to define a (pseudo) closure of a\nset of tuples over each of the algebraic objects, associate a rank with it\n(analogous to Shelah and Lascar ranks), and over free groups the closure\nprovides a canonical envelope that is essential in studying the structure and\nthe properties of definable sets.",
    "pdf_url": "http://arxiv.org/pdf/2505.22755v1",
    "published": "2025-05-28T18:15:25+00:00",
    "categories": [
      "math.GR",
      "math.LO",
      "math.RA"
    ],
    "primary_category": "math.GR"
  },
  {
    "id": "http://arxiv.org/abs/2505.22754v2",
    "title": "`Dark' Matter Effect as a Novel Solution to the KM3-230213A Puzzle",
    "authors": [
      "P. S. Bhupal Dev",
      "Bhaskar Dutta",
      "Aparajitha Karthikeyan",
      "Writasree Maitra",
      "Louis E. Strigari",
      "Ankur Verma"
    ],
    "abstract": "The recent KM3NeT observation of an ${\\cal{O}}(100~{\\rm PeV})$ event\nKM3-230213A is puzzling because IceCube with much larger effective area times\nexposure has not found any such events. We propose a novel solution to this\nconundrum in terms of dark matter (DM) scattering in the Earth's crust. We show\nthat intermediate dark-sector particles that decay into muons are copiously\nproduced when high-energy ($\\sim100~\\text{PeV}$) DM propagates through a\nsufficient amount of Earth overburden. The same interactions responsible for DM\nscattering in Earth also source the boosted DM flux from a high-luminosity\nblazar. We address the non-observation of similar events at IceCube via two\nexamples of weakly coupled long-lived dark sector scenarios that satisfy all\nexisting constraints. We calculate the corresponding dark sector cross\nsections, lifetimes and blazar luminosities required to yield one event at\nKM3NeT, and also predict the number of IceCube events for these parameters that\ncan be tested very soon. Our proposed DM explanation of the event can also be\ndistinguished from a neutrino-induced event in future high-energy neutrino\nflavor analyses, large-scale DM direct detection experiments, as well as at\nfuture colliders.",
    "pdf_url": "http://arxiv.org/pdf/2505.22754v2",
    "published": "2025-05-28T18:13:58+00:00",
    "categories": [
      "hep-ph",
      "astro-ph.HE"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.22753v1",
    "title": "Enhancing Lifelong Multi-Agent Path-finding by Using Artificial Potential Fields",
    "authors": [
      "Arseniy Pertzovsky",
      "Roni Stern",
      "Ariel Felner",
      "Roie Zivan"
    ],
    "abstract": "We explore the use of Artificial Potential Fields (APFs) to solve Multi-Agent\nPath Finding (MAPF) and Lifelong MAPF (LMAPF) problems. In MAPF, a team of\nagents must move to their goal locations without collisions, whereas in LMAPF,\nnew goals are generated upon arrival. We propose methods for incorporating APFs\nin a range of MAPF algorithms, including Prioritized Planning, MAPF-LNS2, and\nPriority Inheritance with Backtracking (PIBT). Experimental results show that\nusing APF is not beneficial for MAPF but yields up to a 7-fold increase in\noverall system throughput for LMAPF.",
    "pdf_url": "http://arxiv.org/pdf/2505.22753v1",
    "published": "2025-05-28T18:13:10+00:00",
    "categories": [
      "cs.AI",
      "cs.MA",
      "cs.RO"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.22752v1",
    "title": "Climate Finance Bench",
    "authors": [
      "Rafik Mankour",
      "Yassine Chafai",
      "Hamada Saleh",
      "Ghassen Ben Hassine",
      "Thibaud Barreau",
      "Peter Tankov"
    ],
    "abstract": "Climate Finance Bench introduces an open benchmark that targets\nquestion-answering over corporate climate disclosures using Large Language\nModels. We curate 33 recent sustainability reports in English drawn from\ncompanies across all 11 GICS sectors and annotate 330 expert-validated\nquestion-answer pairs that span pure extraction, numerical reasoning, and\nlogical reasoning. Building on this dataset, we propose a comparison of RAG\n(retrieval-augmented generation) approaches. We show that the retriever's\nability to locate passages that actually contain the answer is the chief\nperformance bottleneck. We further argue for transparent carbon reporting in\nAI-for-climate applications, highlighting advantages of techniques such as\nWeight Quantization.",
    "pdf_url": "http://arxiv.org/pdf/2505.22752v1",
    "published": "2025-05-28T18:12:29+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.22751v1",
    "title": "A complex logistic equation for universal energy evolution in hadronic elastic scattering",
    "authors": [
      "Anderson Kendi Kohara"
    ],
    "abstract": "We introduce a universal evolution equation for elastic scattering of\nhadrons, derived from Regge field theory (RFT) and solved in closed analytical\nform. The equation emerges from a complex logistic structure and evolves\ninitial amplitude profiles taken from existing models at fixed energy,\nreproducing both the differential cross sections and the integrated quantities\nin a broad energy range. We prove that it admits a unique solution for each\ninitial condition and rigorously satisfies unitarity, the Froissart-Martin\nbound, and dispersion relations. The dynamics are governed by two physically\nmeaningful parameters: the effective Pomeron mass $\\epsilon_{\\mathcal{P}}$ and\nthe nonlinear coupling $\\lambda$, both fitted at a single energy. Our approach\noffers a minimal, yet predictive framework for saturation and unitarization in\nelastic scattering and may provide a useful bridge toward small-$x$ QCD\nevolution.",
    "pdf_url": "http://arxiv.org/pdf/2505.22751v1",
    "published": "2025-05-28T18:11:57+00:00",
    "categories": [
      "hep-ph",
      "hep-th"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.22750v2",
    "title": "Quadratic convergence of an SQP method for some optimization problems with applications to control theory",
    "authors": [
      "Eduardo Casas",
      "Mariano Mateos"
    ],
    "abstract": "We analyze a sequential quadratic programming algorithm for solving a class\nof abstract optimization problems. Assuming that the initial point is in an\n$L^2$ neighborhood of a local solution that satisfies no-gap second-order\nsufficient optimality conditions and a strict complementarity condition, we\nobtain stability and quadratic convergence in $L^q$ for all $q\\in[p,\\infty]$\nwhere $p\\geq 2$ depends on the problem. Many of the usual optimal control\nproblems of partial differential equations fit into this abstract formulation.\nSome examples are given in the paper. Finally, a computational comparison with\nother versions of the SQP method is presented.",
    "pdf_url": "http://arxiv.org/pdf/2505.22750v2",
    "published": "2025-05-28T18:10:11+00:00",
    "categories": [
      "math.OC",
      "math.AP",
      "49M15, 49M05, 49M41, 35Q93"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2505.22749v1",
    "title": "Self-orthogonalizing attractor neural networks emerging from the free energy principle",
    "authors": [
      "Tamas Spisak",
      "Karl Friston"
    ],
    "abstract": "Attractor dynamics are a hallmark of many complex systems, including the\nbrain. Understanding how such self-organizing dynamics emerge from first\nprinciples is crucial for advancing our understanding of neuronal computations\nand the design of artificial intelligence systems. Here we formalize how\nattractor networks emerge from the free energy principle applied to a universal\npartitioning of random dynamical systems. Our approach obviates the need for\nexplicitly imposed learning and inference rules and identifies emergent, but\nefficient and biologically plausible inference and learning dynamics for such\nself-organizing systems. These result in a collective, multi-level Bayesian\nactive inference process. Attractors on the free energy landscape encode prior\nbeliefs; inference integrates sensory data into posterior beliefs; and learning\nfine-tunes couplings to minimize long-term surprise. Analytically and via\nsimulations, we establish that the proposed networks favor approximately\northogonalized attractor representations, a consequence of simultaneously\noptimizing predictive accuracy and model complexity. These attractors\nefficiently span the input subspace, enhancing generalization and the mutual\ninformation between hidden causes and observable effects. Furthermore, while\nrandom data presentation leads to symmetric and sparse couplings, sequential\ndata fosters asymmetric couplings and non-equilibrium steady-state dynamics,\noffering a natural extension to conventional Boltzmann Machines. Our findings\noffer a unifying theory of self-organizing attractor networks, providing novel\ninsights for AI and neuroscience.",
    "pdf_url": "http://arxiv.org/pdf/2505.22749v1",
    "published": "2025-05-28T18:10:03+00:00",
    "categories": [
      "q-bio.NC",
      "cs.AI",
      "cs.LG",
      "cs.NE"
    ],
    "primary_category": "q-bio.NC"
  },
  {
    "id": "http://arxiv.org/abs/2505.22748v1",
    "title": "Nonparametric Estimation of Conditional Survival Function with Time-Varying Covariates Using DeepONet",
    "authors": [
      "Bingqing Hu",
      "Bin Nan"
    ],
    "abstract": "Traditional survival models often rely on restrictive assumptions such as\nproportional hazards or instantaneous effects of time-varying covariates on the\nhazard function, which limit their applicability in real-world settings. We\nconsider the nonparametric estimation of the conditional survival function,\nwhich leverages the flexibility of neural networks to capture the complex,\npotentially long-term non-instantaneous effects of time-varying covariates. In\nthis work, we use Deep Operator Networks (DeepONet), a deep learning\narchitecture designed for operator learning, to model the arbitrary effects of\nboth time-varying and time-invariant covariates. Specifically, our method\nrelaxes commonly used assumptions in hazard regressions by modeling the\nconditional hazard function as an unknown nonlinear operator of entire\nhistories of time-varying covariates. The estimation is based on a loss\nfunction constructed from the nonparametric full likelihood for censored\nsurvival data. Simulation studies demonstrate that our method performs well,\nwhereas the Cox model yields biased results when the assumption of\ninstantaneous time-varying covariate effects is violated. We further illustrate\nits utility with the ADNI data, for which it yields a lower integrated Brier\nscore than the Cox model.",
    "pdf_url": "http://arxiv.org/pdf/2505.22748v1",
    "published": "2025-05-28T18:05:49+00:00",
    "categories": [
      "stat.ME"
    ],
    "primary_category": "stat.ME"
  },
  {
    "id": "http://arxiv.org/abs/2505.22747v1",
    "title": "Frictional Contact Network in Dense Suspension Flow",
    "authors": [
      "Shweta Sharma",
      "Abhishek Sharma",
      "Abhinendra Singh"
    ],
    "abstract": "Dense particulate suspensions often exhibit a dramatic increase in viscosity\nin response to external deformation. This shear thickening behavior has been\nrelated to a transition from lubricated, unconstrained pairwise motion to a\nfrictional contact network (FCN) at high stresses. Here, we study the\ncharacteristics of the FCN formed during shear thickening to investigate the\nrole of constraints, emphasizing the impact of resistance to gear-like rolling.\nWe contrast the FCN formed by sliding friction alone with that formed by\nparticles with sliding and rolling constraints. Particles with sliding\nconstraints only form a highly interconnected network with primary force chains\nin the compressive direction, which requires orthogonal support from other\nforce chains. However, orthogonal support is not required for mechanical\nstability when particles have both sliding and rolling constraints. In\naddition, the force chains appear linear and longer, reducing the jamming\nvolume fraction for rough/faceted particles. Finally, we propose a novel\nmechanical stability picture for rough/faceted particles with sliding and\nrolling constraints, which is crucial for understanding the flow behavior of\nreal-life suspensions.",
    "pdf_url": "http://arxiv.org/pdf/2505.22747v1",
    "published": "2025-05-28T18:05:41+00:00",
    "categories": [
      "cond-mat.soft"
    ],
    "primary_category": "cond-mat.soft"
  },
  {
    "id": "http://arxiv.org/abs/2505.22746v1",
    "title": "StarBASE-GP: Biologically-Guided Automated Machine Learning for Genotype-to-Phenotype Association Analysis",
    "authors": [
      "Jose Guadalupe Hernandez",
      "Attri Ghosh",
      "Philip J. Freda",
      "Yufei Meng",
      "Nicholas Matsumoto",
      "Jason H. Moore"
    ],
    "abstract": "We present the Star-Based Automated Single-locus and Epistasis analysis tool\n- Genetic Programming (StarBASE-GP), an automated framework for discovering\nmeaningful genetic variants associated with phenotypic variation in large-scale\ngenomic datasets. StarBASE-GP uses a genetic programming-based multi-objective\noptimization strategy to evolve machine learning pipelines that simultaneously\nmaximize explanatory power (r2) and minimize pipeline complexity. Biological\ndomain knowledge is integrated at multiple stages, including the use of nine\ninheritance encoding strategies to model deviations from additivity, a custom\nlinkage disequilibrium pruning node that minimizes redundancy among features,\nand a dynamic variant recommendation system that prioritizes informative\ncandidates for pipeline inclusion. We evaluate StarBASE-GP on a cohort of\nRattus norvegicus (brown rat) to identify variants associated with body mass\nindex, benchmarking its performance against a random baseline and a\nbiologically naive version of the tool. StarBASE-GP consistently evolves Pareto\nfronts with superior performance, yielding higher accuracy in identifying both\nground truth and novel quantitative trait loci, highlighting relevant targets\nfor future validation. By incorporating evolutionary search and relevant\nbiological theory into a flexible automated machine learning framework,\nStarBASE-GP demonstrates robust potential for advancing variant discovery in\ncomplex traits.",
    "pdf_url": "http://arxiv.org/pdf/2505.22746v1",
    "published": "2025-05-28T18:05:15+00:00",
    "categories": [
      "cs.NE",
      "cs.LG"
    ],
    "primary_category": "cs.NE"
  },
  {
    "id": "http://arxiv.org/abs/2505.22745v1",
    "title": "An Accurate Modeling of Nano-Hertz Gravitational Wave Signal from Eccentric Supermassive Binary Black Holes: Essential Step Towards a Robust Discovery",
    "authors": [
      "Mohit Raj Sah",
      "Akash Maurya",
      "Suvodip Mukherjee",
      "Prayush Kumar",
      "Vida Saeedzadeh",
      "Arif Babul",
      "Chandra Kant Mishra",
      "Kaushik Paul",
      "Thomas R. Quinn",
      "Michael Tremmel"
    ],
    "abstract": "The stochastic gravitational wave background (SGWB) in the nanohertz (nHz)\nregime, detectable by pulsar timing arrays (PTAs), offers a promising avenue to\nprobe the cosmic population of supermassive black hole binaries (SMBHBs). These\nSMBHBs are expected to retain substantial eccentricity throughout their\nevolution due to their formation history. In this study, we propose a new\nmodeling scenario of the nHz SGWB by incorporating the eccentricity of SMBHBs\ninto a multi-scale adaptive simulation-based framework. We employ a time-domain\neccentric waveform model, \\esigmahm{}, to generate realistic gravitational wave\n(GW) signals from an astrophysical population of SMBHB, including physical\neffects from sub-parsec scales to Gpc scales. The eccentric inspiraling binary,\nunlike circular binaries, emits GW signal in multiple frequencies. As a\nconsequence, the SGWB energy density in each frequency bin is not independent;\ninstead, the presence of eccentricity introduces a spectral correlation between\ndifferent frequencies. We show that these spectral correlations are absent for\ncircular binaries but become increasingly significant for populations with\nhigher eccentricities. Our novel approach can capture this effect and opens up\nthe window towards measuring this with a high signal-to-noise ratio with future\nobservations. This work develops the frontier of nHz signal modeling using\neccentricity at small scales and can model realistic nHz signal, which will be\nessential for robust inference from future observations to shed light on the\nastrophysical properties of SMBHBs.",
    "pdf_url": "http://arxiv.org/pdf/2505.22745v1",
    "published": "2025-05-28T18:04:48+00:00",
    "categories": [
      "astro-ph.CO",
      "astro-ph.HE",
      "gr-qc"
    ],
    "primary_category": "astro-ph.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.22744v1",
    "title": "Geometry of chiral temporal structures II: The formalism",
    "authors": [
      "Aycke Roos",
      "Pablo M. Maier",
      "Andres F. Ordonez",
      "Olga Smirnova"
    ],
    "abstract": "We develop a mathematical formalism underlying the emergence of\nenantio-sensitive molecular orientation due to photoionization or\nphotoexitation of chiral molecules. We consider geometric quantities such as\nthe Berry connection and Berry curvature in light-driven chiral electronic\nstates in the space of complex light polarization vectors. The parametric\ndependence of the light-driven electronic wavefunction on such vectors emerges\ndue to various possible mutual orientations between the laser field and a\nchiral molecule. Using the tools of differential geometry we show how the\nenantio-sensitive observables emerge from the geometry of the molecular\nresponse in such spaces.",
    "pdf_url": "http://arxiv.org/pdf/2505.22744v1",
    "published": "2025-05-28T18:04:14+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.22743v2",
    "title": "Information-Computation Gaps in Quantum Learning via Low-Degree Likelihood",
    "authors": [
      "Sitan Chen",
      "Weiyuan Gong",
      "Jonas Haferkamp",
      "Yihui Quek"
    ],
    "abstract": "In a variety of physically relevant settings for learning from quantum data,\ndesigning protocols that can computationally efficiently extract information\nremains largely an art, and there are important cases where we believe this to\nbe impossible, that is, where there is an information-computation gap. While\nthere is a large array of tools in the classical literature for giving evidence\nfor average-case hardness of statistical inference problems, the corresponding\ntools in the quantum literature are far more limited. One such framework in the\nclassical literature, the low-degree method, makes predictions about hardness\nof inference problems based on the failure of estimators given by low-degree\npolynomials. In this work, we extend this framework to the quantum setting.\n  We establish a general connection between state designs and low-degree\nhardness. We use this to obtain the first information-computation gaps for\nlearning Gibbs states of random, sparse, non-local Hamiltonians. We also use it\nto prove hardness for learning random shallow quantum circuit states in a\nchallenging model where states can be measured in adaptively chosen bases. To\nour knowledge, the ability to model adaptivity within the low-degree framework\nwas open even in classical settings. In addition, we also obtain a low-degree\nhardness result for quantum error mitigation against strategies with\nsingle-qubit measurements.\n  We define a new quantum generalization of the planted biclique problem and\nidentify the threshold at which this problem becomes computationally hard for\nprotocols that perform local measurements. Interestingly, the complexity\nlandscape for this problem shifts when going from local measurements to more\nentangled single-copy measurements.\n  We show average-case hardness for the \"standard\" variant of Learning\nStabilizers with Noise and for agnostically learning product states.",
    "pdf_url": "http://arxiv.org/pdf/2505.22743v2",
    "published": "2025-05-28T18:04:10+00:00",
    "categories": [
      "quant-ph",
      "cs.CC",
      "cs.DS",
      "cs.LG"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.22742v2",
    "title": "Survivors and Zombies: The Quenching and Disruption of Satellites around Milky Way Analogs",
    "authors": [
      "Debosmita Pathak",
      "Charlotte R. Christensen",
      "Alyson M. Brooks",
      "Ferah Munshi",
      "Anna C. Wright",
      "Courtney Carter"
    ],
    "abstract": "It is necessary to understand the full accretion history of the Milky Way in\norder to contextualize the properties of observed Milky Way satellite galaxies\nand the stellar halo. This paper compares the dynamical properties and\nstar-formation histories of surviving and disrupted satellites around Milky\nWay-like galaxies using the DC Justice League suite of very high-resolution\ncosmological zoom-in simulations of Milky Way analogs and their halo\nenvironments. We analyze the full census of galaxies accreted within the past\n12 Gyrs, which including both surviving satellites at $z=0$, and dwarf galaxies\nthat disrupted and merged with the host prior to $z=0$. Our simulations\nsuccessfully reproduce the trends in $M_*$-[Fe/H]-[$\\alpha$/Fe] observed in\nsurviving Milky Way satellites and disrupted stellar streams, indicating\nearlier star-formation for disrupted progenitors. We find the likelihood and\ntimescales for quenching and disruption are strongly correlated with the mass\nand time of infall. In particular, none of the galaxies accreted more than 12\nGyrs ago survived, and only 20% of all accreted galaxies with $M_*>10^8M_\\odot$\nsurvive. Additionally, satellites with highly radial trajectories are more\nlikely to quench and disrupt. Disruption proceeds quickly for $\\geq10^6M_\\odot$\nsatellites accreted $10{-}12$ Gyr ago, often on timescales similar to the\n$\\sim300$ Myr snapshot spacing. For high-mass satellites, the disruption\ntimescale is faster than the quenching timescale. As a result, 92% of disrupted\ngalaxies remain star-forming up until disruption. In contrast, Ultra Faint\nDwarfs (UFDs) tend to quench prior to accretion, and 94% of UFDs accreted up to\n12 Gyr ago survive at $z=0$.",
    "pdf_url": "http://arxiv.org/pdf/2505.22742v2",
    "published": "2025-05-28T18:03:23+00:00",
    "categories": [
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2505.22741v1",
    "title": "Sample importance for data-driven decoding",
    "authors": [
      "Evan Peters"
    ],
    "abstract": "Data-driven decoding (DDD) -- learning to decode syndromes of (quantum)\nerror-correcting codes using training examples -- can be a difficult problem\ndue to several atypical and poorly understood properties of the training data.\nWe introduce a theory of example importance that clarifies these unusual\naspects of DDD: For instance, we show that DDD of a simple error-correcting\ncode is equivalent to a noisy, imbalanced binary classification problem. This\nsuggests that an existing data augmentation technique -- turning the knob to\nincrease error rates in training data -- actually introduces a tradeoff between\nclass imbalance and label noise. We apply this technique in experiments showing\nrobust improvements to decoder accuracy while explaining the failures of this\ntechnique in terms of example importance. We show similar improvements for\ndecoding quantum codes involving multiple rounds of syndrome measurements and\nwe characterize example importance in random stabilizer codes, suggesting broad\napplicability of both example importance and turning the knob for improving\nexperimentally relevant data-driven decoders.",
    "pdf_url": "http://arxiv.org/pdf/2505.22741v1",
    "published": "2025-05-28T18:02:54+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.22740v1",
    "title": "Current-current operator contribution to the decay matrix in $B$-meson mixing at next-to-next-to-leading order of QCD",
    "authors": [
      "Marvin Gerlach",
      "Ulrich Nierste",
      "Pascal Reeck",
      "Vladyslav Shtabovenko",
      "Matthias Steinhauser"
    ],
    "abstract": "We compute next-to-next-to-leading order perturbative corrections to the\ndecay width difference of mass eigenstates and the charge-parity asymmetry\n$a_{\\rm fs}$ in flavour-specific decays of neutral $B$ mesons. In our\ncalculation we take into account the full dependence on the charm and bottom\nquark masses for the current-current operator contributions up to three-loop\norder. Special emphasis is put on the proper construction of the so-called\n$|\\Delta B|=2$ theory such that Fierz symmetry is preserved. We provide updated\nphenomenological predictions, for $\\Delta\\Gamma$, $\\Delta\\Gamma/\\Delta M$ and\n$a_{\\rm fs}$ for the $B_d$ and $B_s$ system, including a detailed analysis of\nthe uncertainties of our predictions. The calculated NNLO correction reduce the\nperturbative uncertainty of the leading term of the $1/m_b$ expansion of the\nwidth difference $\\dg_s$ in the $B_s$ system to the level of the current\nexperimental error. The uncertainty of our prediction $\\dg_s=({0.077}\\pm\n0.016)\\,\\mbox{ps}^{-1}$ is dominated by the sub-leading term of this expansion.\nWe further illustrate how better future measurements of $\\dg_d$ and $a_{\\rm\nfs}^d$ will help to gain a better understanding of $B_d$-$\\bar B_d$ mixing.",
    "pdf_url": "http://arxiv.org/pdf/2505.22740v1",
    "published": "2025-05-28T18:02:28+00:00",
    "categories": [
      "hep-ph"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.22739v1",
    "title": "The Phase Space of Low-Mass Binary Compact Objects from LIGO-Virgo-KAGRA Catalog: Hints on the Chances of Different Formation Scenarios",
    "authors": [
      "Samsuzzaman Afroz",
      "Suvodip Mukherjee"
    ],
    "abstract": "Gravitational wave (GW) observations have significantly advanced our\nunderstanding of binary compact object (BCO) formation, yet directly linking\nthese observations to specific formation scenarios remains challenging. The BCO\nphase space provides a robust and data-driven approach to discover the likely\nformation scenarios of these binaries. In this study, we expand the previously\nintroduced binary black hole phase-space technique to encompass low-mass\ncompact objects (LMCOs), establishing a novel framework to investigate their\ndiverse formation mechanisms. Applying this approach to selected low-mass\nevents $(\\lesssim 5 M_\\odot)$ from the GWTC-3 catalog and the recently observed\nGW230529 event, we show for the first time the phase-space demonstration of the\nLMCOs and find the associated probabilities for different formation scenarios\nincluding neutron stars, astrophysical black holes, or primordial black holes.\nOur analysis includes the astrophysical modelling uncertainties in and how it\ncauses degeneracy between different formation scenarios. In future, with\nimprovements in GW detector sensitivity and with detection of more GW events,\nthe LMCO phase-space framework will significantly strengthen our capacity to\nassociate more likely formation scenarios over the other, thereby refining our\nunderstanding of compact object formation for both astrophysical and primordial\nscenarios, and its evolution across the cosmic redshift.",
    "pdf_url": "http://arxiv.org/pdf/2505.22739v1",
    "published": "2025-05-28T18:01:53+00:00",
    "categories": [
      "astro-ph.HE",
      "astro-ph.CO",
      "gr-qc"
    ],
    "primary_category": "astro-ph.HE"
  },
  {
    "id": "http://arxiv.org/abs/2505.22738v1",
    "title": "Basic Elements of Strong Gravitational Lensing",
    "authors": [
      "Paul L. Schechter",
      "Jeremy D. Schnittman"
    ],
    "abstract": "Even when used to describe the same phenomenon, equations, graphics and words\neach give different perspectives and lead to complementary insights. The basic\nelements of strong gravitational lensing are introduced here favoring words and\ngraphics over equations whenever possible. Fermat's principle is the\nfundamental driver of strong lensing. Three \"D's'' encapsulate the essential\neffects of lensing: Delay, Deflection and Distortion. Gravity and geometry both\ncontribute to the delay of photons from a lensed source. Their interplay\ndetermines how the images of a source are deflected and how they are stretched\nor compressed. Caustics and critical curves are explained. Images of doubly,\ntriply, quadruply and quintuply lensed sources are displayed. A table of\nsymbols, their definitions and distinctions provides a summary of the basic\nelements of strong lensing.",
    "pdf_url": "http://arxiv.org/pdf/2505.22738v1",
    "published": "2025-05-28T18:01:47+00:00",
    "categories": [
      "astro-ph.CO"
    ],
    "primary_category": "astro-ph.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.22737v3",
    "title": "Nonlinear Diffusion and Decay of an Expanding Turbulent Blob",
    "authors": [
      "Takumi Matsuzawa",
      "Minhui Zhu",
      "Nigel Goldenfeld",
      "William T. M. Irvine"
    ],
    "abstract": "Turbulence, left unforced, decays and invades the surrounding quiescent\nfluid. Though ubiquitous, this simple phenomenon has proven hard to capture\nwithin a simple and general framework. Experiments in conventional turbulent\nflow chambers are inevitably complicated by proximity to boundaries and mean\nflow, obscuring the fundamental aspects of the relaxation to the quiescent\nfluid state. Here, we circumvent these issues by creating a spatially-localized\nblob of turbulent fluid using eight converging vortex generators focused\ntowards the center of a tank of water, and observe its decay and spread over\ndecades in time, using particle image velocimetry with a logarithmic sampling\nrate. The blob initially expands and decays until it reaches the walls of the\ntank and eventually transitions to a second regime of approximately spatially\nuniform decay. We interpret these dynamics within the framework of a nonlinear\ndiffusion equation, which predicts that the ideal quiescent-turbulent fluid\nboundary is sharp and propagates non-diffusively, driven by turbulent eddies\nwhile decaying with characteristic scaling laws. We find direct evidence for\nthis model within the expansion phase of our turbulent blob and use it to\naccount for the detailed behavior we observe, in contrast to earlier studies.\nOur work provides a detailed spatially-resolved narrative for the behavior of\nturbulence once the forcing is removed, and demonstrates unexpectedly that the\nturbulent cascade leaves an indelible footprint far into the decay process.",
    "pdf_url": "http://arxiv.org/pdf/2505.22737v3",
    "published": "2025-05-28T18:01:35+00:00",
    "categories": [
      "physics.flu-dyn"
    ],
    "primary_category": "physics.flu-dyn"
  },
  {
    "id": "http://arxiv.org/abs/2505.22736v1",
    "title": "Lorentz Violation with Gravitational Waves: Constraints from NANOGrav and IPTA Data",
    "authors": [
      "Alireza Allahyari",
      "Mohammadreza Davari",
      "David F. Mota"
    ],
    "abstract": "We explore a theoretical framework in which Lorentz symmetry is explicitly\nbroken by incorporating derivative terms of the extrinsic curvature into the\ngravitational action. These modifications introduce a scale-dependent damping\neffect in the propagation of gravitational waves (GWs), governed by a\ncharacteristic energy scale denoted as $M_{{LV}}$ . We derive the modified\nspectral energy density of GWs within this model and confront it with recent\nobservational data from the NANOGrav 15-year dataset and the second data\nrelease of the International Pulsar Timing Array (IPTA). Our analysis yields a\nlower bound on the Lorentz-violating energy scale, finding $M_{{LV}} >\n10^{-19}$ GeV at 68\\% confidence level. This result significantly improves upon\nprevious constraints derived from LIGO/VIRGO binary merger observations. Our\nfindings demonstrate the potential of pulsar timing arrays to probe fundamental\nsymmetries of spacetime and offer new insights into possible extensions of\ngeneral relativity.",
    "pdf_url": "http://arxiv.org/pdf/2505.22736v1",
    "published": "2025-05-28T18:00:35+00:00",
    "categories": [
      "astro-ph.CO",
      "astro-ph.HE",
      "gr-qc"
    ],
    "primary_category": "astro-ph.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.22735v1",
    "title": "TensorShield: Safeguarding On-Device Inference by Shielding Critical DNN Tensors with TEE",
    "authors": [
      "Tong Sun",
      "Bowen Jiang",
      "Hailong Lin",
      "Borui Li",
      "Yixiao Teng",
      "Yi Gao",
      "Wei Dong"
    ],
    "abstract": "To safeguard user data privacy, on-device inference has emerged as a\nprominent paradigm on mobile and Internet of Things (IoT) devices. This\nparadigm involves deploying a model provided by a third party on local devices\nto perform inference tasks. However, it exposes the private model to two\nprimary security threats: model stealing (MS) and membership inference attacks\n(MIA). To mitigate these risks, existing wisdom deploys models within Trusted\nExecution Environments (TEEs), which is a secure isolated execution space.\nNonetheless, the constrained secure memory capacity in TEEs makes it\nchallenging to achieve full model security with low inference latency. This\npaper fills the gap with TensorShield, the first efficient on-device inference\nwork that shields partial tensors of the model while still fully defending\nagainst MS and MIA. The key enabling techniques in TensorShield include: (i) a\nnovel eXplainable AI (XAI) technique exploits the model's attention transition\nto assess critical tensors and shields them in TEE to achieve secure inference,\nand (ii) two meticulous designs with critical feature identification and\nlatency-aware placement to accelerate inference while maintaining security.\nExtensive evaluations show that TensorShield delivers almost the same security\nprotection as shielding the entire model inside TEE, while being up to\n25.35$\\times$ (avg. 5.85$\\times$) faster than the state-of-the-art work,\nwithout accuracy loss.",
    "pdf_url": "http://arxiv.org/pdf/2505.22735v1",
    "published": "2025-05-28T18:00:24+00:00",
    "categories": [
      "cs.CR"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.22733v1",
    "title": "The Co-Evolution of Stellar Wind-blown Bubbles and Photoionized Gas II: 3D RMHD Simulations and Tests of Semi-Analytic Models",
    "authors": [
      "Lachlan Lancaster",
      "Chang-Goo Kim",
      "Jeong-Gyu Kim",
      "Eve C. Ostriker",
      "Greg L. Bryan"
    ],
    "abstract": "In a companion paper (Paper I) we presented a Co-Evolution Model (CEM) in\nwhich to consider the evolution of feedback bubbles driven by massive stars\nthrough both stellar winds and ionizing radiation, outlining when either of\nthese effects is dominant and providing a model for how they evolve together.\nHere we present results from three-dimensional radiation magneto-hydrodynamical\n(RMHD) simulations of this scenario for parameters typical of massive\nstar-forming clouds in the Milky Way: precisely the regime where we expect both\nfeedback mechanisms to matter. While we find that the CEM agrees with the\nsimulations to within 25% for key parameters and modestly outperforms previous\nidealized models, disagreements remain. We show that these deviations originate\nmainly from the CEM's lack of (i) background inhomogeneity caused by turbulence\nand (ii) time-variable momentum enhancements in the wind-blown bubble (WBB).\nAdditionally, we find that photoionized gas acts similarly to magnetic fields\n([as in Lancaster et al. 2024a) by decreasing the WBB's surface area. This\ncauses a decrease in the amount of cooling at the WBB's interface, resulting in\nan enhanced WBB dynamical impact.",
    "pdf_url": "http://arxiv.org/pdf/2505.22733v1",
    "published": "2025-05-28T18:00:08+00:00",
    "categories": [
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2505.22734v1",
    "title": "Interpretable Scaling Behavior in Sparse Subnetwork Representations of Quantum States",
    "authors": [
      "Brandon Barton",
      "Juan Carrasquilla",
      "Christopher Roth",
      "Agnes Valenti"
    ],
    "abstract": "The Lottery Ticket Hypothesis (LTH) posits that within overparametrized\nneural networks, there exist sparse subnetworks that are capable of matching\nthe performance of the original model when trained in isolation from the\noriginal initialization. We extend this hypothesis to the unsupervised task of\napproximating the ground state of quantum many-body Hamiltonians, a problem\nequivalent to finding a neural-network compression of the lowest-lying\neigenvector of an exponentially large matrix. Focusing on two representative\nquantum Hamiltonians, the transverse field Ising model (TFIM) and the toric\ncode (TC), we demonstrate that sparse neural networks can reach accuracies\ncomparable to their dense counterparts, even when pruned by more than an order\nof magnitude in parameter count. Crucially, and unlike the original LTH, we\nfind that performance depends only on the structure of the sparse subnetwork,\nnot on the specific initialization, when trained in isolation. Moreover, we\nidentify universal scaling behavior that persists across network sizes and\nphysical models, where the boundaries of scaling regions are determined by the\nunderlying Hamiltonian. At the onset of high-error scaling, we observe\nsignatures of a sparsity-induced quantum phase transition that is first-order\nin shallow networks. Finally, we demonstrate that pruning enhances\ninterpretability by linking the structure of sparse subnetworks to the\nunderlying physics of the Hamiltonian.",
    "pdf_url": "http://arxiv.org/pdf/2505.22734v1",
    "published": "2025-05-28T18:00:08+00:00",
    "categories": [
      "quant-ph",
      "cond-mat.dis-nn"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.22732v1",
    "title": "Langer's nucleation rate reproduced on the lattice",
    "authors": [
      "Joonas Hirvonen",
      "Oliver Gould"
    ],
    "abstract": "We show that Langer's rate of bubble nucleation is quantitatively correct up\nto small higher-loop corrections, in comparison to lattice simulations. These\nresults are a significant advancement on decades of lattice studies showing\nonly qualitative trends, and the first showing agreement for any conservative\nsystem. We confirm that the failure to fully thermalize the metastable phase\nexplains discrepancies with recent lattice studies that found disagreement with\nLanger's rate. The key theoretical development is the translation of Langer's\nperturbative definition of a thermal metastable phase into a nonperturbative\nstatement that can be implemented on the lattice. Our statistical and\nsystematic errors are small enough to allow us to measure on the lattice the\ncoefficient of the two-loop contribution, missing from the perturbative\nprediction. Our conclusions also exclude a possible systematic uncertainty in\n$^3$He experiments.",
    "pdf_url": "http://arxiv.org/pdf/2505.22732v1",
    "published": "2025-05-28T18:00:06+00:00",
    "categories": [
      "hep-ph",
      "astro-ph.CO",
      "cond-mat.stat-mech",
      "hep-lat",
      "hep-th"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.22730v1",
    "title": "The Co-Evolution of Stellar Wind-blown Bubbles and Photoionized Gas I: Physical Principles and a Semi-Analytic Model",
    "authors": [
      "Lachlan Lancaster",
      "Jeong-Gyu Kim",
      "Greg L. Bryan",
      "Shyam H. Menon",
      "Eve C. Ostriker",
      "Chang-Goo Kim"
    ],
    "abstract": "We propose a new framework for the simultaneous feedback of stellar winds and\nphoto-ionizing radiation from massive stars, distinguishing the locations where\nforces are applied, and consequences for internal spatio-temporal evolution of\nthe whole feedback bubble (FB). We quantify the relative dynamical importance\nof wind-blown bubbles (WBB) versus the photoionized region (PIR) by the ratio\nof the radius at which the WBB is in pressure equilibrium with the PIR, $R_{\\rm\neq}$, to the Str\\\"{o}mgren radius, $R_{\\rm St}$. $\\zeta \\equiv R_{\\rm\neq}/R_{\\rm St}$ quantifies the dynamical dominance of WBBs ($\\zeta > 1$) or the\nPIR ($\\zeta < 1$). We calculate $\\zeta$ and find that, for momentum-driven\nwinds, $0.1 \\lesssim \\zeta \\lesssim 1$ for the star-forming regions in (i)\ntypical Milky Way-like giant molecular clouds (GMCs), (ii) the most massive of\nindividual OB stars, and (iii) dense, low-metallicity environments, relevant in\nthe early universe. In this regime, both WBBs and the PIR are dynamically\nimportant to the expansion of the FB. We develop a semi-analytic Co-Evolution\nModel (CEM) that takes into account the spatial distribution of forces and the\nback reactions of both the WBB and PIR. In the $\\zeta <1$ regime where the CEM\nis most relevant, the model differs in the total FB momentum by up to 25%\ncompared to naive predictions. In the weak-wind limit of $\\zeta \\ll 1$,\napplicable to individual OB stars or low-mass clusters, the CEM has factors\n$\\gtrsim 2$ differences in WBB properties. In a companion paper we compare\nthese models to three-dimensional, turbulent hydro-dynamical simulations.",
    "pdf_url": "http://arxiv.org/pdf/2505.22730v1",
    "published": "2025-05-28T18:00:05+00:00",
    "categories": [
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2505.22731v1",
    "title": "Exact analysis of AC sensors based on Floquet time crystals",
    "authors": [
      "Andrei Tsypilnikov",
      "Matheus Fibger",
      "Fernando Iemini"
    ],
    "abstract": "We discuss the behavior of general Floquet Time Crystals (FTCs), including\nprethermal ones, in closed systems acting as AC sensors. We provide an\nanalytical treatment of their quantum Fisher information (QFI) dynamics, which\ncharacterizes the ultimate sensor accuracy. By tuning the direction and\nfrequency of the AC field, we show how to resonantly induce transitions between\nmacroscopic paired cat states in the FTC sensor, allowing a robust Heisenberg\nscaling precision (QFI $\\sim N^2 t^2$) for exponentially long times in the\nsystem size. The QFI dynamics exhibit, moreover, a characteristic step-like\nstructure in time due to the eventual dephasing along the cat subspaces. The\nbehavior is discussed for different relevant initial preparations of the\nsensor, including ground states, low and high correlated states. Furthermore,\nwe examine the performance of the sensor along the FTC phase transition, with\nthe QFI capturing its critical exponents. We present our findings for both\nlinear and nonlinear response regimes, and illustrate them for a specific FTC\nbased on the long-range interacting LMG model.",
    "pdf_url": "http://arxiv.org/pdf/2505.22731v1",
    "published": "2025-05-28T18:00:05+00:00",
    "categories": [
      "quant-ph",
      "cond-mat.other",
      "cond-mat.stat-mech"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.22729v2",
    "title": "Quantum Simulation of Charge and Exciton Transfer in Multi-mode Models using Engineered Reservoirs",
    "authors": [
      "Visal So",
      "Midhuna Duraisamy Suganthi",
      "Mingjian Zhu",
      "Abhishek Menon",
      "George Tomaras",
      "Roman Zhuravel",
      "Han Pu",
      "Peter G. Wolynes",
      "Jos√© N. Onuchic",
      "Guido Pagano"
    ],
    "abstract": "Quantum simulation offers a route to study open-system molecular dynamics in\nnon-perturbative regimes by programming the interactions among electronic,\nvibrational, and environmental degrees of freedom on similar energy scales.\nTrapped-ion systems possess this capability, with their native spins, phonons,\nand tunable dissipation integrated within a single platform. Here, we\ndemonstrate an open-system quantum simulation of charge and exciton transfer in\na multi-mode linear vibronic coupling model. Employing tailored spin-phonon\ninteractions alongside reservoir engineering techniques, we emulate a system\nwith two dissipative vibrational modes coupled to donor and acceptor electronic\nsites and follow its non-equilibrium dynamics. We continuously tune the system\nfrom the charge transfer (CT) regime to the vibrationally assisted exciton\ntransfer (VAET) regime by controlling the vibronic coupling strengths. We find\nthat degenerate modes enhance CT and VAET rates at large energy gaps, while\nnon-degenerate modes activate slow-mode pathways that reduce the energy-gap\ndependence, thus enlarging the window for efficient transfer. These results\nshow that the presence of one additional vibration introduces interfering\nvibrationally assisted pathways and reshapes non-perturbative quantum\nexcitation transfer. Our work establishes a scalable and hardware-efficient\nroute to simulating chemically relevant, many-mode vibronic processes with\nengineered environments, guiding the design of next-generation organic\nphotovoltaics and molecular electronics.",
    "pdf_url": "http://arxiv.org/pdf/2505.22729v2",
    "published": "2025-05-28T18:00:04+00:00",
    "categories": [
      "quant-ph",
      "cond-mat.quant-gas",
      "physics.atom-ph",
      "physics.chem-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.22728v1",
    "title": "The fraction of polar aligned circumbinary disks",
    "authors": [
      "Ted M. Johnson",
      "Rebecca G. Martin",
      "Stephen Lepp",
      "Stephen H. Lubow"
    ],
    "abstract": "Circumbinary gas disks that are misaligned to the binary orbital plane evolve\ntoward either a coplanar or a polar-aligned configuration with respect to the\nbinary host. The preferred alignment depends on the dynamics of the disk:\nwhether it undergoes librating or circulating nodal precession, with librating\ndisks evolving to polar inclinations and circulating disks evolving to\ncoplanar. We quantify the fraction of binary star systems whose disks are\nexpected to have polar orbits $f_\\text{polar}$, extending previous work to\ninclude disks with non-zero mass. Our results suggest that, for low mass disks,\nthe polar fraction is highly sensitive to the distribution of binary\neccentricity with a higher fraction expected for higher binary eccentricities,\n$f_{\\rm polar}\\sim e_{\\rm b}$. However, for massive discs, the fraction is\nindependent of the binary eccentricity and $f_{\\rm polar}\\approx 0.37$. The\nvalue of $f_\\text{polar}$ is always reduced in a population with a greater\npreference for low initial mutual inclination. We also explore the consequences\nof the finite lifetime and non-zero radial extent of a real disk, both of which\naffect a disk's ability to complete its evolution to a stationary\nconfiguration. Our findings can be used to make predictions given populations\nwith well-understood distributions of binary eccentricity, initial mutual\ninclination, and disk angular momentum.",
    "pdf_url": "http://arxiv.org/pdf/2505.22728v1",
    "published": "2025-05-28T18:00:03+00:00",
    "categories": [
      "astro-ph.EP",
      "astro-ph.SR"
    ],
    "primary_category": "astro-ph.EP"
  },
  {
    "id": "http://arxiv.org/abs/2505.22725v1",
    "title": "Kekul√© order from diffuse nesting near higher-order Van Hove points",
    "authors": [
      "Jonas Beck",
      "Jonathan Bodky",
      "Matteo D√ºrrnagel",
      "Ronny Thomale",
      "Julian Ingham",
      "Lennart Klebl",
      "Hendrik Hohmann"
    ],
    "abstract": "Translation symmetry-breaking order is assumed to be suppressed by the lack\nof Fermi surface nesting near certain higher-order Van Hove singularities\n(HOVHS). We show the anisotropic band-flattening inherent to such HOVHS,\ncombined with broadening of the Fermi surface due to elevated critical\ntemperatures, results in the Fermi surface becoming approximately nested at a\nwavevector unrelated to the precise shape of the Fermi surface - leading to a\n$\\sqrt{3}\\times\\sqrt{3}$ Kekul\\'e density wave formation. The effect is\ndemonstrated using unbiased renormalization group calculations for a model of\nthe breathing kagome lattice. Our mechanism - termed diffuse nesting -\nrepresents an entirely new notion in the study of Fermi surface instabilities.",
    "pdf_url": "http://arxiv.org/pdf/2505.22725v1",
    "published": "2025-05-28T18:00:02+00:00",
    "categories": [
      "cond-mat.str-el",
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.str-el"
  },
  {
    "id": "http://arxiv.org/abs/2505.22726v1",
    "title": "Black hole thermodynamics at 4 derivatives, natural variables and BPS limits",
    "authors": [
      "Kiril Hristov",
      "Peng-Ju Hu",
      "Yi Pang"
    ],
    "abstract": "We study Einstein-Maxwell theory in $D \\geq 3$ spacetime dimensions including\nall Lorentz-invariant parity-even four-derivative couplings. Building on the\nresults of arXiv:2312.11610, we consider static, charged, asymptotically flat\nblack hole solutions to first order in the higher-derivative expansion. In\n$D=4$ and $D=5$, we compute the corrected black hole thermodynamics and compare\nwith the Reall-Santos prescription based on the two-derivative background,\nhighlighting a subtlety when both inner and outer horizons are involved. By\nintroducing natural variables, as in arXiv:2304.07320, we recast the on-shell\nactions in terms of left- and right-moving chemical potentials, which\nsignificantly simplifies the analysis.\n  We also compute first-order thermodynamic corrections for the most general\nrotating black holes in $D=4$ and $D=5$, without modifying the background\nsolutions. We identify a novel BPS-like limit in $D=4$, extending known\nsupergravity results beyond their traditional domain of validity. Finally, in\n$D=5$, the analysis of BPS and almost BPS limits enables an independent\nverification of the five-dimensional BPS thermodynamics. We clarify the origin\nof a discrepancy in the literature concerning higher-derivative supergravity\nlocalization, sharpening the tension between direct computations and\npredictions based on the $D=4$/$D=5$ connection.",
    "pdf_url": "http://arxiv.org/pdf/2505.22726v1",
    "published": "2025-05-28T18:00:02+00:00",
    "categories": [
      "hep-th",
      "gr-qc"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2505.22727v3",
    "title": "The galaxy-halo connection of disc galaxies over six orders of magnitude in stellar mass",
    "authors": [
      "Pavel E. Mancera Pi√±a",
      "Justin I. Read",
      "Stacy Kim",
      "Antonino Marasco",
      "Jos√© A. Benavides",
      "Marcin Glowacki",
      "Gabriele Pezzulli",
      "Claudia del P. Lagos"
    ],
    "abstract": "(Abridged) The relations between stellar ($M_\\ast$), gas ($M_{\\rm gas}$),\nbaryonic ($M_{\\rm bar} = M_\\ast + M_{\\rm gas}$), and dark matter halo mass\n($M_{200}$) provide unique constraints on galaxy formation and cosmology. The\nshape of the relations constrains how galaxies regulate their growth through\ngas accretion, star formation, and feedback; their scatter probes the\nstochasticity of galaxy assembly.\n  Here, we assemble a sample of 49 nearby gas-rich dwarf and massive disc\ngalaxies with unmatched ancillary data. We obtain their gas kinematics and\nderive their dark matter properties through rotation curve decomposition. Our\nsample allows us to study the galaxy-halo connection across nearly six orders\nof magnitude in $M_\\ast$. We find that the $M_{\\rm gas}-M_{200}$ relation rises\nmonotonically, with galaxies having around 4 per cent of the average\ncosmological baryon fraction in cold gas. Contrastingly, the $M_\\ast-M_{200}$\nrelation shows a more complex behaviour. A particularly interesting finding is\nthat of a population of baryon-deficient' dwarfs (BDDs) with stellar masses\n$\\sim 1-1.5$ orders of magnitude lower than expected from current models. Yet,\nbaryon-rich galaxies also exist, and we find a large spread in the baryon\nretention fraction across our galaxies. We compare our findings with\nsemi-analytic and hydrodynamical galaxy formation simulations. While the\nsimulations broadly reproduce most observed features, they struggle to match\nthe BDDs and do not capture the diversity in baryon fractions. Understanding\nthese differences will shed new light on how feedback regulates galaxy\nformation. Finally, we study the dark matter halo concentration-mass relation.\nWe find that below $M_{200} \\sim 10^{11}\\,M_\\odot$, the concentrations are\nsystematically lower than expected. We discuss whether these results stem from\nthe influence of baryonic physics or the environment.",
    "pdf_url": "http://arxiv.org/pdf/2505.22727v3",
    "published": "2025-05-28T18:00:02+00:00",
    "categories": [
      "astro-ph.GA",
      "astro-ph.CO"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2505.22715v1",
    "title": "Routing-Aware Placement for Zoned Neutral Atom-based Quantum Computing",
    "authors": [
      "Yannick Stade",
      "Wan-Hsuan Lin",
      "Jason Cong",
      "Robert Wille"
    ],
    "abstract": "Quantum computing promises to solve previously intractable problems, with\nneutral atoms emerging as a promising technology. Zoned neutral atom\narchitectures allow for immense parallelism and higher coherence times by\nshielding idling atoms from interference with laser beams. However, in addition\nto hardware, successful quantum computation requires sophisticated software\nsupport, particularly compilers that optimize quantum algorithms for hardware\nexecution. In the compilation flow for zoned neutral atom architectures, the\neffective interplay of the placement and routing stages decides the overhead\ncaused by rearranging the atoms during the quantum computation. Sub-optimal\nplacements can lead to unnecessary serialization of the rearrangements in the\nsubsequent routing stage. Despite this, all existing compilers treat placement\nand routing independently thus far - focusing solely on minimizing travel\ndistances. This work introduces the first routing-aware placement method to\naddress this shortcoming. It groups compatible movements into parallel\nrearrangement steps to minimize both rearrangement steps and travel distances.\nThe implementation utilizing the A* algorithm reduces the rearrangement time by\n17% on average and by 49% in the best case compared to the state-of-the-art.\nThe complete code is publicly available in open-source as part of the Munich\nQuantum Toolkit (MQT) at https://github.com/munich-quantum-toolkit/qmap.",
    "pdf_url": "http://arxiv.org/pdf/2505.22715v1",
    "published": "2025-05-28T18:00:01+00:00",
    "categories": [
      "quant-ph",
      "cs.ET"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.22716v3",
    "title": "Building the Holographic Dictionary of the DSSYK from Chords, Complexity & Wormholes with Matter",
    "authors": [
      "Sergio E. Aguilar-Gutierrez"
    ],
    "abstract": "In this work, we formulate the holographic dictionary for the double-scaled\nSYK (DSSYK) model with matter operators. Based on the two-sided Hartle-Hawking\n(HH) state, we derive several properties of the DSSYK model, without making\nassumptions about the specific dual theory, including its semiclassical\nthermodynamics, correlation functions, and Krylov complexity. We derive these\nquantities from the saddle points of the DSSYK path integral preparing the HH\nstate. We also construct a Lanczos algorithm that simultaneously evaluates\nKrylov state and operator complexity in the two-sided Hamiltonian system\nincluding finite temperature effects. In the semiclassical limit, both measures\nare encoded in the saddle points of the path integral. They have a bulk\ninterpretation in terms of minimal geodesic lengths in an effective AdS$_2$\nspace with matter backreaction. Different saddle points correspond to geodesic\ndistances with different evolution, and they display different scrambling\nproperties. We also discuss about the quantization of the bulk theory dual to\nthe DSSYK model. At last, we formulate the double-scaled algebra in bulk terms,\nand the dual entry of the proper radial momentum of a bulk probe.",
    "pdf_url": "http://arxiv.org/pdf/2505.22716v3",
    "published": "2025-05-28T18:00:01+00:00",
    "categories": [
      "hep-th"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2505.22717v1",
    "title": "Stellar Mass Segregation in Dark Matter Halos",
    "authors": [
      "Rapha√´l Errani",
      "Jorge Pe√±arrubia",
      "Matthew G. Walker"
    ],
    "abstract": "We study the effect of stellar mass segregation driven by collisional\nrelaxation within the potential well of a smooth dark matter halo. This effect\nis of particular relevance for old stellar systems with short crossing times,\nwhere small collisional perturbations accumulate over many dynamical time\nscales. We run collisional $N$-body simulations tailored to the ambiguous\nstellar systems Ursa Major 3/Unions 1, Delve 1 and Eridanus 3, modelling their\nstellar populations as two-component systems of high- and low-mass stars,\nrespectively. For Ursa Major 3/Unions 1 (Delve 1), assuming a\ndynamical-to-stellar mass ratio of 10, we find that after 10 Gyr of evolution,\nthe radial extent of its low-mass stars will be twice as large (40 per cent\nlarger) than that of its high-mass stars. We show that weak tides do not alter\nthis relative separation of half-light radii, whereas for the case of strong\ntidal fields, mass segregation facilitates the tidal stripping of low-mass\nstars. We further find that as the population of high-mass stars contracts and\ncools, the number of dynamically formed binaries within that population\nincreases. Our results call for caution when using stellar mass segregation as\na criterion to separate star clusters from dwarf galaxies, and suggest that\nmass segregation increases the abundance of massive binaries in the central\nregions of dark matter-dominated dwarf galaxies.",
    "pdf_url": "http://arxiv.org/pdf/2505.22717v1",
    "published": "2025-05-28T18:00:01+00:00",
    "categories": [
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2505.22718v2",
    "title": "$\\texttt{SwiftC}_\\ell$: fast differentiable angular power spectra beyond Limber",
    "authors": [
      "Laura Reymond",
      "Alexander Reeves",
      "Pierre Zhang",
      "Alexandre Refregier"
    ],
    "abstract": "The upcoming stage IV wide-field surveys will provide high precision\nmeasurements of the large-scale structure (LSS) of the universe. Their\ninterpretation requires fast and accurate theoretical predictions including\nlarge scales. For this purpose, we introduce $\\texttt{SwiftC}_\\ell$, a fast,\naccurate and differentiable $\\texttt{JAX}$-based pipeline for the computation\nof the angular power spectrum beyond the Limber approximation. It uses a new\nFFTLog-based method which can reach arbitrary precision and includes\ninterpolation along $k$, allowing for $k$-dependent growth factor and biases.\n$\\texttt{SwiftC}_\\ell$ includes a wide range of probes and effects such as\ngalaxy clustering, including magnification bias, redshift-space distortions and\nprimordial non-Gaussianity, weak lensing, including intrinsic alignment, cosmic\nmicrowave background (CMB) lensing and CMB integrated Sachs-Wolfe effect. We\ncompare our pipeline to the other available beyond-Limber codes within the N5K\nchallenge from the Rubin Observatory Legacy Survey of Space and Time (LSST)\nDark Energy Science Collaboration. $\\texttt{SwiftC}_\\ell$ computes the 120\ndifferent angular power spectra over 103 $\\ell$-multipoles in 5 ms on one GPU\ncore while the computation of the gradient is approximately 4$\\times$ slower.\nUsing a pre-calculation, $\\texttt{SwiftC}_\\ell$ is thus about 40$\\times$ faster\nthan the winner of the N5K challenge with comparable accuracy. Furthermore, all\noutputs are auto-differentiable, facilitating gradient-based sampling and\nrobust and accurate Fisher forecasts. We showcase a Markov Chain Monte Carlo, a\nHamiltonian Monte Carlo and a Fisher forecast on an LSST-like survey,\nillustrating $\\texttt{SwiftC}_\\ell$'s differentiability, speed and reliability\nin measuring cosmological parameters. The code is publicly available at\nhttps://cosmo-gitlab.phys.ethz.ch/cosmo_public/swiftcl.",
    "pdf_url": "http://arxiv.org/pdf/2505.22718v2",
    "published": "2025-05-28T18:00:01+00:00",
    "categories": [
      "astro-ph.CO"
    ],
    "primary_category": "astro-ph.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.22719v1",
    "title": "On Pulsar Timing Detection of Ultralight Vector Dark Matter",
    "authors": [
      "Jeff A. Dror",
      "Qiushi Wei"
    ],
    "abstract": "Ultralight vector dark matter induces metric fluctuations that generate\ntiming residuals in the arrival times of pulsar emissions through two distinct\nmodes: a fast mode, sourced by coherent field oscillations, and a slow mode,\narising from interference patterns. These modes enable the detection of vector\ndark matter with masses $m \\sim 10^{-24} - 10^{-22}\\ \\mathrm{eV}$ and $m \\sim\n10^{-18} - 10^{-16}\\ \\mathrm{eV}$, respectively, using pulsar timing arrays.\nWhile previous studies have explored the fast mode, they neglect the full\nstatistical treatment of the vector field and a precise treatment of its\npolarization structure. In this work, we investigate the timing residuals from\nboth modes, fully accounting for the statistical properties of ultralight\nvector dark matter, assuming equipartition among its three polarization states.\nThe two-point correlation functions of timing residuals that we derive serve as\ndirect tools for identifying vector dark matter signatures as a stochastic\nbackground in pulsar timing data.",
    "pdf_url": "http://arxiv.org/pdf/2505.22719v1",
    "published": "2025-05-28T18:00:01+00:00",
    "categories": [
      "hep-ph",
      "astro-ph.HE"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.22720v1",
    "title": "Flow to Nishimori universality in weakly monitored quantum circuits with qubit loss",
    "authors": [
      "Malte P√ºtz",
      "Romain Vasseur",
      "Andreas W. W. Ludwig",
      "Simon Trebst",
      "Guo-Yi Zhu"
    ],
    "abstract": "In circuit-based quantum state preparation, qubit loss and coherent errors\nare circuit imperfections that imperil the formation of long-range entanglement\nbeyond a certain threshold. The critical theory at the threshold is a\ncontinuous entanglement transition known to be described by a (2+0)-dimensional\nnon-unitary conformal field theory which, for the two types of imperfections of\ncertain circuits, is described by either percolation or Nishimori criticality,\nrespectively. Here we study the threshold behavior when the two types of errors\nsimultaneously occur and show that, when moving away from the Clifford-regime\nof projective stabilizer measurements, the percolation critical point becomes\nunstable and the critical theory flows to Nishimori universality. We track this\ncritical renormalization group (RG) crossover flow by mapping out the\nentanglement phase diagrams, parametrized by the probability and strength of\nrandom weak measurements, of two dual protocols preparing surface code or\nGHZ-class cat states from a parent cluster state via constant-depth circuits.\nExtensive numerical simulations, using hybrid Gaussian fermion and tensor\nnetwork / Monte Carlo sampling techniques on systems with more than a million\nqubits, demonstrate that an infinitesimal deviation from the Clifford regime\nleads to a sudden, strongly non-monotonic entanglement growth at the incipient\nnon-unitary RG flow. We argue that spectra of scaling dimensions of both the\npercolation and Nishimori fixed points exhibit multifractality. For\npercolation, we provide the exact (non-quadratic) multifractal spectrum of\nexponents, while for the Nishimori fixed point we show high-precision numerical\nresults for five leading exponents characterizing multifractality.",
    "pdf_url": "http://arxiv.org/pdf/2505.22720v1",
    "published": "2025-05-28T18:00:01+00:00",
    "categories": [
      "quant-ph",
      "cond-mat.dis-nn",
      "cond-mat.stat-mech",
      "cond-mat.str-el"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.22721v1",
    "title": "Markovian dissipation can stabilize a (localization) quantum phase transition",
    "authors": [
      "Naushad A. Kamar",
      "Mostafa Ali",
      "Mohammad Maghrebi"
    ],
    "abstract": "Quantum phase transitions are a cornerstone of many-body physics at low\ntemperatures but have remained elusive far from equilibrium. Driven open\nquantum systems -- a prominent non-equilibrium platform where coherent dynamics\ncompetes with Markovian dissipation from the environment -- often exhibit an\neffective classical behavior. In this work, we present a nontrivial quantum\nphase transition that is stabilized, rather than destroyed, by Markovian\ndissipation. We consider a variant of the paradigmatic spin-boson model where\nthe spin is driven and bosons are subject to Markovian loss proportional to\nfrequency (hence, vanishing at low frequencies). We show that the steady state\nexhibits a localization phase transition where the spin's dynamics is frozen,\nto be contrasted with the ground-state transition in the absence of\ndissipation. Furthermore, this transition occurs when the steady state becomes\npure. The latter is not simply a dark state of dissipation but rather emerges\nfrom a nontrivial renormalization of the spin dynamics by low-frequency bosonic\nmodes. Our work provides a nontrivial example where quantumness, typically\nreserved for ground states, also emerges in dynamical settings, with potential\napplications in quantum computation.",
    "pdf_url": "http://arxiv.org/pdf/2505.22721v1",
    "published": "2025-05-28T18:00:01+00:00",
    "categories": [
      "cond-mat.quant-gas",
      "quant-ph"
    ],
    "primary_category": "cond-mat.quant-gas"
  },
  {
    "id": "http://arxiv.org/abs/2505.22722v1",
    "title": "Explaining the PeV Neutrino Fluxes at KM3NeT and IceCube with Quasi-Extremal Primordial Black Holes",
    "authors": [
      "Michael J. Baker",
      "Joaquim Iguaz Juan",
      "Aidan Symons",
      "Andrea Thamm"
    ],
    "abstract": "The KM3NeT experiment has recently observed a neutrino with an energy around\n100 PeV, and IceCube has detected five neutrinos with energies above 1 PeV.\nWhile there are no known astrophysical sources, exploding primordial black\nholes could have produced these high-energy neutrinos. For Schwarzschild black\nholes this interpretation results in tensions between the burst rates inferred\nfrom the KM3NeT and IceCube observations, and with indirect constraints from\nthe extragalactic gamma ray background. In this letter we show that if there is\na population of primordial black holes charged under a new dark $u(1)$ symmetry\nwhich spend most of their time in a quasi-extremal state, the neutrino emission\nat 1 PeV may be more suppressed than at 100 PeV. The burst rates implied by the\nKM3NeT and IceCube observations and the indirect constraints can then all be\nconsistent at $1\\sigma$. Furthermore, these black holes could constitute all of\nthe observed dark matter in the universe.",
    "pdf_url": "http://arxiv.org/pdf/2505.22722v1",
    "published": "2025-05-28T18:00:01+00:00",
    "categories": [
      "hep-ph",
      "astro-ph.CO"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.22723v2",
    "title": "Quantum multicriticality and emergent symmetry in Dirac systems with two order parameters at three-loop order",
    "authors": [
      "Max Uetrecht",
      "Igor F. Herbut",
      "Michael M. Scherer",
      "Emmanuel Stamou",
      "Tom Steudtner"
    ],
    "abstract": "Two-dimensional materials with interacting Dirac excitations can host quantum\nmulticritical behavior near the phase boundaries of the semimetallic and\ntwo-ordered phases. We study such behavior in Gross--Neveu--Yukawa field\ntheories where $N_f$ flavors of Dirac fermions are coupled to two\norder-parameter fields with $SO(N_A)$ and $SO(N_B)$ symmetry, respectively. To\nthat end, we employ the perturbative renormalization group up to three-loop\norder in $4-\\epsilon$ spacetime dimensions. We distinguish two key scenarios:\n(i) The two orders are compatible as characterized by anticommuting mass terms,\nand (ii) the orders are incompatible. For the first case, we explore the\nstability of a quantum multicritical point with emergent $SO(N_A\\!+\\!N_B)$\nsymmetry. We find that the stability is controlled by increasing the number of\nDirac fermion flavors. Moreover, we extract the series expansion of the leading\ncritical exponents for the chiral $SO(4)$ and $SO(5)$ models up to third order\nin $\\epsilon$. Notably, we find a tendency towards rapidly growing expansion\ncoefficients at higher orders, rendering an extrapolation to $\\epsilon=1$\ndifficult. For the second scenario, we study a model with $SO(4) \\simeq SO(3)\n\\times SO(3)$ symmetry, which was recently suggested to describe criticality of\nantiferromagnetism and superconductivity in Dirac systems. However, it was also\nargued that a physically admissible renormalization-group fixed point only\nexists for $N_f$ above a critical number $N_{c}^>$. We determine the\ncorresponding series expansion at three-loop order as $N_{c}^>\\approx\n16.83-7.14\\epsilon-7.12\\epsilon^2$. This suggests that the physical choice of\n$N_f=2$ may be a borderline case, where true criticality and pseudocriticality,\nas induced by fixed-point annihilation, are extremely challenging to\ndistinguish.",
    "pdf_url": "http://arxiv.org/pdf/2505.22723v2",
    "published": "2025-05-28T18:00:01+00:00",
    "categories": [
      "cond-mat.str-el",
      "hep-th"
    ],
    "primary_category": "cond-mat.str-el"
  },
  {
    "id": "http://arxiv.org/abs/2505.22724v1",
    "title": "Connecting Planetary Composition with Formation: a New Paradigm Emerges",
    "authors": [
      "Ralph E. Pudritz",
      "Alex J. Cridland",
      "Julie Inglis",
      "Mathew Alessi"
    ],
    "abstract": "Extensive ground and space based surveys have now characterized the\nproperties of thousands of exoplanets; their radii, masses, orbits around their\nhost stars, and the beginnings of accurate measurements of the chemical\ncompositions of their atmospheres and cores. How are these properties linked to\ntheir formation in physically and chemically evolving protoplanetary disks\nwherein they accrete pebbles, planetesimals, and gas as they undergo migration?\nTo address this challenge, our review assembles a large and varied body of\nexoplanet observations as well as recent Atacama Large Millimeter Array (ALMA)\nand James Webb Space Telescope (JWST) observations of disk structure,\nchemistry, kinematics, and winds. The latest advances in theory and MHD\nsimulations that bear on these issues are also reviewed and compared with the\nobservations. Taken together, this review argues that a new dynamic paradigm\nfor planet formation is emerging wherein MHD disk winds and not disk turbulence\nplay a central role in disk evolution and planet formation including: angular\nmomentum transport, gap and ring formation. disk astrochemistry, and planet\nformation and migration. These processes leave their mark on the resulting\natmospheric composition, radii, and orbital characteristics of exoplanet\npopulations, offering the possibility of future observational tests.",
    "pdf_url": "http://arxiv.org/pdf/2505.22724v1",
    "published": "2025-05-28T18:00:01+00:00",
    "categories": [
      "astro-ph.EP"
    ],
    "primary_category": "astro-ph.EP"
  },
  {
    "id": "http://arxiv.org/abs/2505.22706v1",
    "title": "Variability in the massive black hole binary candidate SDSS J2320+0024: no evidence for periodic modulation",
    "authors": [
      "Fabio Rigamonti",
      "Lorenzo Bertassi",
      "Riccardo Buscicchio",
      "Fabiola Cocchiararo",
      "Stefano Covino",
      "Massimo Dotti",
      "Alberto Sesana",
      "Paola Severgnini"
    ],
    "abstract": "Massive black hole binaries (MBHBs) are a natural outcome of galaxy mergers,\nand they are expected to be among the loudest gravitational wave sources at low\nfrequencies. SDSS J2320+0024 has been recently proposed as a promising MBHB\ncandidate due to a possible periodicity in its light-curve and variability in\nthe MgII emission line. In this work, we re-analyse the optical (g and r bands)\nlight-curves of J2320+0024 within the framework of Bayesian model selection.\nWhen a periodicity is searched for together with red noise, the analysis of the\ng-band light-curve finds a peak in the posterior of the period at ~290 days.\nThe posterior profile is too broad to result in a preference for the periodic\nmodels with respect to models including only red-noise. Furthermore, the same\npeak is not present in the analysis of the r-band light-curve. A periodic model\nwithout red-noise identifies a different (~1100 days) periodicity, and it is\nsignificantly statistically disfavoured with respect to the other tested\nmodels. In summary, no significant evidence in favour of a true periodic signal\nover red noise variability is found. Our analysis questions the robustness of\nthe previously claimed periodicity and emphasizes the importance of rigorous\nstatistical treatment. While our findings challenge the binary interpretation\nfor J2320+0024, they do not rule it out. A statistically robust joint analysis\nof the photometric light-curves and of the evolving broad line profiles can\nshed further light on the real nature of this object.",
    "pdf_url": "http://arxiv.org/pdf/2505.22706v1",
    "published": "2025-05-28T18:00:00+00:00",
    "categories": [
      "astro-ph.GA",
      "astro-ph.HE"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2505.22707v3",
    "title": "The non-relativistic limit of HSZ Theory",
    "authors": [
      "Eric Lescano"
    ],
    "abstract": "We study the non-relativistic (NR) limit of HSZ theory, a higher-derivative\ntheory of gravity with exact and manifest T-duality invariance. Since the\ntheory can be formulated using the generalized metric formalism, the HSZ\nLagrangian remains convergent to all orders in derivatives when taking the NR\nlimit. In this work, we analyze the three-derivative corrections to the\nsymmetry transformations of the fields in the NR case, as well as the\nfour-derivative action in the absence of a b-field. Interestingly, the\ncorrections to the metric degrees of freedom cannot be fully trivialized, as in\nthe relativistic case, in order to preserve the convergence of the theory. As\nHSZ theory interpolates order by order between heterotic and bosonic string\ntheories, the results of this work can be interpreted as a truncation of the\nfour-derivative structure of heterotic supergravity in the NR limit.",
    "pdf_url": "http://arxiv.org/pdf/2505.22707v3",
    "published": "2025-05-28T18:00:00+00:00",
    "categories": [
      "hep-th"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2505.22708v2",
    "title": "Quantum gravity observables: observation, algebras, and mathematical structure",
    "authors": [
      "Steven B. Giddings"
    ],
    "abstract": "The questions of describing observables and observation in quantum gravity\nappear to be centrally important to its physics. A relational approach holds\nsignificant promise, and a classification of different types of relational\nobservables (gravitationally dressed, field relational, and more general) is\noutlined. Plausibly gravitationally dressed observables are particularly\nclosely tied to the fundamental structure of the theory. These may be\nconstructed in the quantum theory to leading order in Newton's constant, and\nraise important questions about localization of information. Approximate\nlocalization is given by a \"standard dressing\" construction of a \"gravitational\nsplitting.\" It is also argued that such gravitational dressings give a\ngeneralization of the crossed product construction, reducing to this and\nyielding type II von Neumann algebras in special cases. Gravity therefore\nintroduces a significantly more general alteration of the algebraic structure\nof local quantum field theory, also with apparent connections to holography,\nbut whose implications have not been fully understood. In particular,\nproperties of the algebra of gravitationally dressed observables suggest a\npossible role for other non-algebraic structure on the Hilbert space for\nquantum gravity.",
    "pdf_url": "http://arxiv.org/pdf/2505.22708v2",
    "published": "2025-05-28T18:00:00+00:00",
    "categories": [
      "hep-th",
      "gr-qc"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2505.22709v1",
    "title": "Haskap Pie: A Halo finding Algorithm with efficient Sampling, K-means clustering, tree-Assembly, Particle tracking, Python modules, Inter-code applicability, and Energy solving",
    "authors": [
      "Kirk S. S. Barrow",
      "Thinh Huu Nguyen",
      "Edward C. Skrabacz"
    ],
    "abstract": "We describe a new Python-based stand-alone halo finding algorithm, Haskap\nPie, that combines several methods of halo finding and tracking into a single\ncalculation. Our halo-finder flexibly solves halos for simulations produced by\neight simulation codes (ART-I, ENZO, RAMSES, CHANGA, GADGET-3, GEAR, AREPO and\nGIZMO) and for both zoom-in or full-box N-body or hydrodynamical simulations\nwithout the need for additional tuning or user-specified modeling parameters.\nWhen compared to Rockstar and Consistent Trees, our halo-finder tracks subhalos\nmuch longer and more consistently, produces halos with better constrained\nphysical parameters, and returns a much denser halo mass function for halos\nwith more than 100 particles. Our results also compare favorably to recently\ndescribed specialized particle-tracking extensions to Rockstar. Our algorithm\nis well-suited to a variety of studies of simulated galaxies and is\nparticularly robust for a new generation of studies of merging and satellite\ngalaxies.",
    "pdf_url": "http://arxiv.org/pdf/2505.22709v1",
    "published": "2025-05-28T18:00:00+00:00",
    "categories": [
      "astro-ph.CO",
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.22710v1",
    "title": "Genesis of Baryon and Dark Matter Asymmetries through Ultraviolet Scattering Freeze-in",
    "authors": [
      "Pouya Asadi",
      "Marianne Moore",
      "David E. Morrissey",
      "Michael Shamma"
    ],
    "abstract": "We introduce a new mechanism for the simultaneous generation of baryon and\ndark matter asymmetries through ultraviolet-dominated freeze-in scatterings.\nThe mechanism relies on heavy Majorana neutrinos that connect the visible\nStandard Model sector to a dark sector through the neutrino portal. Following\nreheating of the visible sector to a temperature well below the heavy neutrino\nmasses, we show that 2-to-2 scattering processes can populate the dark sector\nand generate both baryon and dark matter asymmetries. In some parameter\nregions, the dominant source of baryon asymmetry can be charge transfer from\nthe dark sector, a process we call dark wash-in. We also demonstrate that\nannihilation of the dark matter to massless states within the dark sector can\ndeplete the symmetric population without destroying the net baryon charge to\nleave only an asymmetric dark matter abundance today. Depending on the specific\nmodel parameters, the observed baryon and dark matter abundances can be\nattained with heavy neutrino masses $M_N \\gtrsim 10^{10}$ GeV, and dark matter\nmasses in the range 0.1 GeV $\\lesssim m_\\chi \\lesssim 10^3$ GeV if the dark\nmatter relic abundance is mainly asymmetric and even lower masses if it is\nsymmetric.",
    "pdf_url": "http://arxiv.org/pdf/2505.22710v1",
    "published": "2025-05-28T18:00:00+00:00",
    "categories": [
      "hep-ph"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.22711v2",
    "title": "Astrophysical flux of dark particles as a solution to the KM3NeT and IceCube tension over KM3-230213A",
    "authors": [
      "Yasaman Farzan",
      "Matheus Hostert"
    ],
    "abstract": "We entertain the possibility that transient astrophysical sources can produce\na flux of dark particles that induce ultra-high-energy signatures at neutrino\ntelescopes such as IceCube and KM3NeT. We construct scenarios where such ``dark\nflux\" can produce meta-stable dark particles inside the Earth that subsequently\ndecay to muons, inducing through-going tracks in large-volume neutrino\ndetectors. We consider such a scenario in light of the $\\mathcal{O}(70)$~PeV\nultra-high-energy muon observed by KM3NeT and argue that because of its\nlocation in the sky and the strong geometrical dependence of the signal, such\nevents would not necessarily have been observed by IceCube. Our model relies on\nthe upscattering of a new particle $X$ onto new metastable particles that decay\nto dimuons with decay lengths of $\\mathcal{O}(100)$~km. This scenario can\nexplain the observation by KM3NeT without being in conflict with the IceCube\ndata.",
    "pdf_url": "http://arxiv.org/pdf/2505.22711v2",
    "published": "2025-05-28T18:00:00+00:00",
    "categories": [
      "hep-ph"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.22712v2",
    "title": "Explaining the Weak Evolution of the High-Redshift Mass-Metallicity Relation with Galaxy Burst Cycles",
    "authors": [
      "Andrew Marszewski",
      "Claude-Andr√© Faucher-Gigu√®re",
      "Robert Feldmann",
      "Guochao Sun"
    ],
    "abstract": "Recent observations suggest a nearly constant gas-phase mass-metallicity\nrelation (MZR) at $z \\gtrsim 5$, in agreement with many theoretical\npredictions. This lack of evolution contrasts with observations at $z \\lesssim\n3$, which find an increasing normalization of the MZR with decreasing redshift.\nWe analyze a high-redshift suite of FIRE-2 cosmological zoom-in simulations to\nidentify the physical drivers of the MZR. Previous studies have explained the\nweak evolution of the high-redshift MZR in terms of weakly evolving or\nsaturated gas fractions, but we find this alone does not explain the evolution\nin FIRE-2. Instead, stellar feedback following intense bursts of star formation\ndrives enriched gas out of galaxies, resetting their interstellar medium and\nseparating their histories into distinct ``burst cycles\". We develop the\n``Reduced Burst Model\", a simplified gas-regulator model that successfully\nreproduces the simulated MZR and identifies the dominant drivers of its\nevolution. As redshift decreases, the metallicity of inflows within burst\ncycles increases at fixed stellar mass due to increased wind recycling of\nenriched gas. Meanwhile, the metal mass produced by stars per inflowing gas\nmass within these cycles decreases because of decreased star formation per gas\nmass inflowing into the galaxy. The effects of these two processes on the\nmedian metallicity largely cancel, holding the MZR constant for $z = 5 - 12$.\nAt fixed stellar mass, the simulations predict lower gas metallicities at\nhigher $\\rm H\\alpha$-derived star formation rates, in qualitative agreement\nwith the fundamental metallicity relation (FMR), but this effect is reduced in\nrest UV-selected samples.",
    "pdf_url": "http://arxiv.org/pdf/2505.22712v2",
    "published": "2025-05-28T18:00:00+00:00",
    "categories": [
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2505.22713v1",
    "title": "Co-Scaling and Alignment of Electric and Magnetic Towers",
    "authors": [
      "Matthew Reece",
      "Tom Rudelius",
      "Christopher Tudball"
    ],
    "abstract": "Towers of electrically and magnetically charged states in quantum gravity\noften exhibit two important properties. First, the ratio of the mass (or\ntension) of electrically charged states to magnetically charged states is of\norder $e^2/(4\\pi)$, which we refer to as \"co-scaling.\" Second, in theories of\nmultiple gauge fields, the towers of states that exhibit co-scaling have\ncharges that point in approximately the same direction in charge space as\nmeasured by the gauge kinetic matrix, which we refer to as \"alignment.\" After\nmotivating these ideas with some heuristic arguments, we examine the spectrum\nof BPS states in the 5d supergravity landscape arising from M-theory on a\nCalabi-Yau threefold. In this setting, every tower of magnetically charged\nstrings is paired with a corresponding tower of electrically charged particles\nthat exhibits co-scaling and rapid alignment. In particular, this motivates a\nsharp mathematical characterization of the magnetic infinity cone in Calabi-Yau\ngeometry. We conjecture that co-scaling and alignment are universal properties\nof towers of states which, in some limit in moduli space, have maximally\ndivergent charge-to-mass ratios. Co-scaling is not a general feature of\nextremal black hole solutions in theories of gauge fields and scalars,\nsuggesting that it is a principle of UV complete quantum gravity. We briefly\nremark on possible phenomenological applications, including to axion physics.",
    "pdf_url": "http://arxiv.org/pdf/2505.22713v1",
    "published": "2025-05-28T18:00:00+00:00",
    "categories": [
      "hep-th"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2505.22714v1",
    "title": "Localized Triplons and Site Stuffing in the Quantum Dimer Magnet BiYbGeO$_5$",
    "authors": [
      "Rachit Kapoor",
      "D. Yahne",
      "V. O. Garlea",
      "G. Hester"
    ],
    "abstract": "Thermodynamic and muon spin-relaxation measurements have recently highlighted\nBiYbGeO$_5$ as a new example of a rare-earth-based quantum dimer magnet with\nisolated Yb$^{3+}$ spin-$\\frac{1}{2}$ dimers. However, direct spectroscopic\nevidence of the triplet excitations and measurements of the structural disorder\nare lacking. In this work, polycrystalline BiYbGeO$_5$ was synthesized using\nconventional high-temperature solid-state methods and investigated via\nhigh-resolution neutron powder diffraction and inelastic neutron scattering.\nDiffraction measurements down to 58 mK reveal no signatures of magnetic order\nand indicate that nearly 20\\% of Yb$^{3+}$ sites are replaced by non-magnetic\nBi$^{3+}$, introducing significant structural disorder. Inelastic neutron\nscattering shows dispersionless triplon excitations, consistent with localized,\nnon-interacting spin dimers. Fits to the triplet excitation spectrum identify\nan XXZ-type anisotropic exchange with $J_{XX}$ = 0.11(2) meV and $J_Z =\n0.15(1)$ meV. These findings establish BiYbGeO$_5$ as a structurally disordered\nbut magnetically well-isolated quantum dimer system, providing a model platform\nfor studying the resilience of entangled spin states to site dilution.",
    "pdf_url": "http://arxiv.org/pdf/2505.22714v1",
    "published": "2025-05-28T18:00:00+00:00",
    "categories": [
      "cond-mat.str-el",
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.str-el"
  },
  {
    "id": "http://arxiv.org/abs/2505.22664v2",
    "title": "Zero-Shot Vision Encoder Grafting via LLM Surrogates",
    "authors": [
      "Kaiyu Yue",
      "Vasu Singla",
      "Menglin Jia",
      "John Kirchenbauer",
      "Rifaa Qadri",
      "Zikui Cai",
      "Abhinav Bhatele",
      "Furong Huang",
      "Tom Goldstein"
    ],
    "abstract": "Vision language models (VLMs) typically pair a modestly sized vision encoder\nwith a large language model (LLM), e.g., Llama-70B, making the decoder the\nprimary computational burden during training. To reduce costs, a potential\npromising strategy is to first train the vision encoder using a small language\nmodel before transferring it to the large one. We construct small \"surrogate\nmodels\" that share the same embedding space and representation language as the\nlarge target LLM by directly inheriting its shallow layers. Vision encoders\ntrained on the surrogate can then be directly transferred to the larger model,\na process we call zero-shot grafting -- when plugged directly into the\nfull-size target LLM, the grafted pair surpasses the encoder-surrogate pair\nand, on some benchmarks, even performs on par with full decoder training with\nthe target LLM. Furthermore, our surrogate training approach reduces overall\nVLM training costs by ~45% when using Llama-70B as the decoder. The code is at\nhttps://github.com/facebookresearch/zero.",
    "pdf_url": "http://arxiv.org/pdf/2505.22664v2",
    "published": "2025-05-28T17:59:59+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.22663v2",
    "title": "Training Free Stylized Abstraction",
    "authors": [
      "Aimon Rahman",
      "Kartik Narayan",
      "Vishal M. Patel"
    ],
    "abstract": "Stylized abstraction synthesizes visually exaggerated yet semantically\nfaithful representations of subjects, balancing recognizability with perceptual\ndistortion. Unlike image-to-image translation, which prioritizes structural\nfidelity, stylized abstraction demands selective retention of identity cues\nwhile embracing stylistic divergence, especially challenging for\nout-of-distribution individuals. We propose a training-free framework that\ngenerates stylized abstractions from a single image using inference-time\nscaling in vision-language models (VLLMs) to extract identity-relevant\nfeatures, and a novel cross-domain rectified flow inversion strategy that\nreconstructs structure based on style-dependent priors. Our method adapts\nstructural restoration dynamically through style-aware temporal scheduling,\nenabling high-fidelity reconstructions that honor both subject and style. It\nsupports multi-round abstraction-aware generation without fine-tuning. To\nevaluate this task, we introduce StyleBench, a GPT-based human-aligned metric\nsuited for abstract styles where pixel-level similarity fails. Experiments\nacross diverse abstraction (e.g., LEGO, knitted dolls, South Park) show strong\ngeneralization to unseen identities and styles in a fully open-source setup.",
    "pdf_url": "http://arxiv.org/pdf/2505.22663v2",
    "published": "2025-05-28T17:59:57+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.22662v1",
    "title": "AutoL2S: Auto Long-Short Reasoning for Efficient Large Language Models",
    "authors": [
      "Feng Luo",
      "Yu-Neng Chuang",
      "Guanchu Wang",
      "Hoang Anh Duy Le",
      "Shaochen Zhong",
      "Hongyi Liu",
      "Jiayi Yuan",
      "Yang Sui",
      "Vladimir Braverman",
      "Vipin Chaudhary",
      "Xia Hu"
    ],
    "abstract": "The reasoning-capable large language models (LLMs) demonstrate strong\nperformance on complex reasoning tasks but often suffer from overthinking,\ngenerating unnecessarily long chain-of-thought (CoT) reasoning paths for easy\nreasoning questions, thereby increasing inference cost and latency. Recent\napproaches attempt to address this challenge by manually deciding when to apply\nlong or short reasoning. However, they lack the flexibility to adapt CoT length\ndynamically based on question complexity. In this paper, we propose Auto\nLong-Short Reasoning (AutoL2S), a dynamic and model-agnostic framework that\nenables LLMs to dynamically compress their generated reasoning path based on\nthe complexity of the reasoning question. AutoL2S enables a learned paradigm,\nin which LLMs themselves can decide when longer reasoning is necessary and when\nshorter reasoning suffices, by training on data annotated with our proposed\nmethod, which includes both long and short CoT paths and a special <EASY>\ntoken. We then use <EASY> token to indicate when the model can skip generating\nlengthy CoT reasoning. This proposed annotation strategy can enhance the LLMs'\nability to generate shorter CoT reasoning paths with improved quality after\ntraining. Extensive evaluation results show that AutoL2S reduces the length of\nreasoning generation by up to 57% without compromising performance,\ndemonstrating the effectiveness of AutoL2S for scalable and efficient LLM\nreasoning.",
    "pdf_url": "http://arxiv.org/pdf/2505.22662v1",
    "published": "2025-05-28T17:59:53+00:00",
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.22661v1",
    "title": "GuessArena: Guess Who I Am? A Self-Adaptive Framework for Evaluating LLMs in Domain-Specific Knowledge and Reasoning",
    "authors": [
      "Qingchen Yu",
      "Zifan Zheng",
      "Ding Chen",
      "Simin Niu",
      "Bo Tang",
      "Feiyu Xiong",
      "Zhiyu Li"
    ],
    "abstract": "The evaluation of large language models (LLMs) has traditionally relied on\nstatic benchmarks, a paradigm that poses two major limitations: (1) predefined\ntest sets lack adaptability to diverse application domains, and (2)\nstandardized evaluation protocols often fail to capture fine-grained\nassessments of domain-specific knowledge and contextual reasoning abilities. To\novercome these challenges, we propose GuessArena, an adaptive evaluation\nframework grounded in adversarial game-based interactions. Inspired by the\ninteractive structure of the Guess Who I Am? game, our framework seamlessly\nintegrates dynamic domain knowledge modeling with progressive reasoning\nassessment to improve evaluation fidelity. Empirical studies across five\nvertical domains-finance, healthcare, manufacturing, information technology,\nand education-demonstrate that GuessArena effectively distinguishes LLMs in\nterms of domain knowledge coverage and reasoning chain completeness. Compared\nto conventional benchmarks, our method provides substantial advantages in\ninterpretability, scalability, and scenario adaptability.",
    "pdf_url": "http://arxiv.org/pdf/2505.22661v1",
    "published": "2025-05-28T17:59:43+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.22660v4",
    "title": "Maximizing Confidence Alone Improves Reasoning",
    "authors": [
      "Mihir Prabhudesai",
      "Lili Chen",
      "Alex Ippoliti",
      "Katerina Fragkiadaki",
      "Hao Liu",
      "Deepak Pathak"
    ],
    "abstract": "Reinforcement learning (RL) has enabled machine learning models to achieve\nsignificant advances in many fields. Most recently, RL has empowered frontier\nlanguage models to solve challenging math, science, and coding problems.\nHowever, central to any RL algorithm is the reward function, and reward\nengineering is a notoriously difficult problem in any domain. In this paper, we\npropose RENT: Reinforcement Learning via Entropy Minimization -- a fully\nunsupervised RL method that requires no external reward or ground-truth\nanswers, and instead uses the model's entropy of its underlying distribution as\nan intrinsic reward. We find that by reinforcing the chains of thought that\nyield high model confidence on its generated answers, the model improves its\nreasoning ability. In our experiments, we showcase these improvements on an\nextensive suite of commonly-used reasoning benchmarks, including GSM8K,\nMATH500, AMC, AIME, and GPQA, and models of varying sizes from the Qwen,\nMistral, and Llama families. The generality of our unsupervised learning method\nlends itself to applicability in a wide range of domains where external\nsupervision is unavailable.",
    "pdf_url": "http://arxiv.org/pdf/2505.22660v4",
    "published": "2025-05-28T17:59:37+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.22659v1",
    "title": "Network Generating Processes With Self Exciting Arrival Times",
    "authors": [
      "Duncan A Clark",
      "Conor J. Kresin",
      "Charlotte M. Jones-Todd"
    ],
    "abstract": "In this paper, we propose a novel modeling framework for time-evolving\nnetworks allowing for long-term dependence in network features that update in\ncontinuous time. Dynamic network growth is functionally parameterized via the\nconditional intensity of a marked point process. This characterization enables\nflexible modeling of both the time of updates and the network updates\nthemselves, dependent on the entire left-continuous sample path. We propose a\npath-dependent nonlinear marked Hawkes process as an expressive platform for\nmodeling such data; its dynamic mark space embeds the time-evolving network. We\nestablish stability conditions, demonstrate simulation and subsequent feasible\nlikelihood-based inference through numerical study, and present an application\nto conference attendee social network data. The resulting methodology serves as\na general framework that can be readily adapted to a wide range of network\ntopologies and point process model specifications.",
    "pdf_url": "http://arxiv.org/pdf/2505.22659v1",
    "published": "2025-05-28T17:59:29+00:00",
    "categories": [
      "stat.ME"
    ],
    "primary_category": "stat.ME"
  },
  {
    "id": "http://arxiv.org/abs/2505.22658v1",
    "title": "A multimode cavity QED Ising spin glass",
    "authors": [
      "Brendan P. Marsh",
      "David Atri Schuller",
      "Yunpeng Ji",
      "Henry S. Hunt",
      "Giulia Z. Socolof",
      "Deven P. Bowman",
      "Jonathan Keeling",
      "Benjamin L. Lev"
    ],
    "abstract": "We realize a driven-dissipative Ising spin glass using cavity QED in a novel\n``4/7\" multimode geometry. Gases of ultracold atoms trapped within the cavity\nby optical tweezers serve as effective spins. They are coupled via randomly\nsigned, all-to-all Ising cavity-mediated interactions. Networks of up to n = 25\nspins are holographically imaged via cavity emission. The system is driven\nthrough a frustrated transverse-field Ising transition, and we show that the\nentropy of the spin glass states depends on the rate at which the transition is\ncrossed. Despite being intrinsically nonequilibrium, the system exhibits\nphenomena associated with Parisi's theory of equilibrium spin glasses, namely\nreplica symmetry breaking (RSB) and ultrametric structure. For system sizes up\nto n = 16, we measure the Parisi function q(x), Edwards-Anderson overlap q_EA,\nand ultrametricity K-correlator; all indicate a deeply ordered spin glass under\nRSB. The system can serve as an associative memory and enable aging and\nrejuvenation studies in driven-dissipative spin glasses at the microscopic\nlevel.",
    "pdf_url": "http://arxiv.org/pdf/2505.22658v1",
    "published": "2025-05-28T17:59:15+00:00",
    "categories": [
      "quant-ph",
      "cond-mat.dis-nn",
      "cond-mat.quant-gas",
      "cond-mat.stat-mech",
      "physics.atom-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.22705v1",
    "title": "HiDream-I1: A High-Efficient Image Generative Foundation Model with Sparse Diffusion Transformer",
    "authors": [
      "Qi Cai",
      "Jingwen Chen",
      "Yang Chen",
      "Yehao Li",
      "Fuchen Long",
      "Yingwei Pan",
      "Zhaofan Qiu",
      "Yiheng Zhang",
      "Fengbin Gao",
      "Peihan Xu",
      "Yimeng Wang",
      "Kai Yu",
      "Wenxuan Chen",
      "Ziwei Feng",
      "Zijian Gong",
      "Jianzhuang Pan",
      "Yi Peng",
      "Rui Tian",
      "Siyu Wang",
      "Bo Zhao",
      "Ting Yao",
      "Tao Mei"
    ],
    "abstract": "Recent advancements in image generative foundation models have prioritized\nquality improvements but often at the cost of increased computational\ncomplexity and inference latency. To address this critical trade-off, we\nintroduce HiDream-I1, a new open-source image generative foundation model with\n17B parameters that achieves state-of-the-art image generation quality within\nseconds. HiDream-I1 is constructed with a new sparse Diffusion Transformer\n(DiT) structure. Specifically, it starts with a dual-stream decoupled design of\nsparse DiT with dynamic Mixture-of-Experts (MoE) architecture, in which two\nseparate encoders are first involved to independently process image and text\ntokens. Then, a single-stream sparse DiT structure with dynamic MoE\narchitecture is adopted to trigger multi-model interaction for image generation\nin a cost-efficient manner. To support flexiable accessibility with varied\nmodel capabilities, we provide HiDream-I1 in three variants: HiDream-I1-Full,\nHiDream-I1-Dev, and HiDream-I1-Fast.\n  Furthermore, we go beyond the typical text-to-image generation and remould\nHiDream-I1 with additional image conditions to perform precise,\ninstruction-based editing on given images, yielding a new instruction-based\nimage editing model namely HiDream-E1. Ultimately, by integrating text-to-image\ngeneration and instruction-based image editing, HiDream-I1 evolves to form a\ncomprehensive image agent (HiDream-A1) capable of fully interactive image\ncreation and refinement. To accelerate multi-modal AIGC research, we have\nopen-sourced all the codes and model weights of HiDream-I1-Full,\nHiDream-I1-Dev, HiDream-I1-Fast, HiDream-E1 through our project websites:\nhttps://github.com/HiDream-ai/HiDream-I1 and\nhttps://github.com/HiDream-ai/HiDream-E1. All features can be directly\nexperienced via https://vivago.ai/studio.",
    "pdf_url": "http://arxiv.org/pdf/2505.22705v1",
    "published": "2025-05-28T17:59:15+00:00",
    "categories": [
      "cs.CV",
      "cs.MM"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.22656v1",
    "title": "Asymptotic-preserving schemes for the initial-boundary value problem of hyperbolic relaxation systems",
    "authors": [
      "Yizhou Zhou"
    ],
    "abstract": "In this work, we present a numerical method for the initial-boundary value\nproblem (IBVP) of first-order hyperbolic systems with source terms. The scheme\ndirectly solves the relaxation system using a relatively coarse mesh and\ncaptures the equilibrium behavior quite well, even in the presence of boundary\nlayers. This method extends the concept of asymptotic-preserving schemes from\ninitial-value problems to IBVPs. Moreover, we apply this idea to design a\nunified numerical scheme for the interface problem of relaxation systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.22656v1",
    "published": "2025-05-28T17:59:13+00:00",
    "categories": [
      "math.NA",
      "cs.NA"
    ],
    "primary_category": "math.NA"
  },
  {
    "id": "http://arxiv.org/abs/2505.22657v1",
    "title": "3DLLM-Mem: Long-Term Spatial-Temporal Memory for Embodied 3D Large Language Model",
    "authors": [
      "Wenbo Hu",
      "Yining Hong",
      "Yanjun Wang",
      "Leison Gao",
      "Zibu Wei",
      "Xingcheng Yao",
      "Nanyun Peng",
      "Yonatan Bitton",
      "Idan Szpektor",
      "Kai-Wei Chang"
    ],
    "abstract": "Humans excel at performing complex tasks by leveraging long-term memory\nacross temporal and spatial experiences. In contrast, current Large Language\nModels (LLMs) struggle to effectively plan and act in dynamic, multi-room 3D\nenvironments. We posit that part of this limitation is due to the lack of\nproper 3D spatial-temporal memory modeling in LLMs. To address this, we first\nintroduce 3DMem-Bench, a comprehensive benchmark comprising over 26,000\ntrajectories and 2,892 embodied tasks, question-answering and captioning,\ndesigned to evaluate an agent's ability to reason over long-term memory in 3D\nenvironments. Second, we propose 3DLLM-Mem, a novel dynamic memory management\nand fusion model for embodied spatial-temporal reasoning and actions in LLMs.\nOur model uses working memory tokens, which represents current observations, as\nqueries to selectively attend to and fuse the most useful spatial and temporal\nfeatures from episodic memory, which stores past observations and interactions.\nOur approach allows the agent to focus on task-relevant information while\nmaintaining memory efficiency in complex, long-horizon environments.\nExperimental results demonstrate that 3DLLM-Mem achieves state-of-the-art\nperformance across various tasks, outperforming the strongest baselines by\n16.5% in success rate on 3DMem-Bench's most challenging in-the-wild embodied\ntasks.",
    "pdf_url": "http://arxiv.org/pdf/2505.22657v1",
    "published": "2025-05-28T17:59:13+00:00",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.22654v2",
    "title": "VScan: Rethinking Visual Token Reduction for Efficient Large Vision-Language Models",
    "authors": [
      "Ce Zhang",
      "Kaixin Ma",
      "Tianqing Fang",
      "Wenhao Yu",
      "Hongming Zhang",
      "Zhisong Zhang",
      "Yaqi Xie",
      "Katia Sycara",
      "Haitao Mi",
      "Dong Yu"
    ],
    "abstract": "Recent Large Vision-Language Models (LVLMs) have advanced multi-modal\nunderstanding by incorporating finer-grained visual perception and encoding.\nHowever, such methods incur significant computational costs due to longer\nvisual token sequences, posing challenges for real-time deployment. To mitigate\nthis, prior studies have explored pruning unimportant visual tokens either at\nthe output layer of the visual encoder or at the early layers of the language\nmodel. In this work, we revisit these design choices and reassess their\neffectiveness through comprehensive empirical studies of how visual tokens are\nprocessed throughout the visual encoding and language decoding stages. Guided\nby these insights, we propose VScan, a two-stage visual token reduction\nframework that addresses token redundancy by: (1) integrating complementary\nglobal and local scans with token merging during visual encoding, and (2)\nintroducing pruning at intermediate layers of the language model. Extensive\nexperimental results across four LVLMs validate the effectiveness of VScan in\naccelerating inference and demonstrate its superior performance over current\nstate-of-the-arts on sixteen benchmarks. Notably, when applied to\nLLaVA-NeXT-7B, VScan achieves a 2.91$\\times$ speedup in prefilling and a\n10$\\times$ reduction in FLOPs, while retaining 95.4\\% of the original\nperformance. Code is available at\nhttps://github.com/Tencent/SelfEvolvingAgent/tree/main/VScan.",
    "pdf_url": "http://arxiv.org/pdf/2505.22654v2",
    "published": "2025-05-28T17:59:08+00:00",
    "categories": [
      "cs.CV",
      "cs.CL"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.22655v1",
    "title": "Position: Uncertainty Quantification Needs Reassessment for Large-language Model Agents",
    "authors": [
      "Michael Kirchhof",
      "Gjergji Kasneci",
      "Enkelejda Kasneci"
    ],
    "abstract": "Large-language models (LLMs) and chatbot agents are known to provide wrong\noutputs at times, and it was recently found that this can never be fully\nprevented. Hence, uncertainty quantification plays a crucial role, aiming to\nquantify the level of ambiguity in either one overall number or two numbers for\naleatoric and epistemic uncertainty. This position paper argues that this\ntraditional dichotomy of uncertainties is too limited for the open and\ninteractive setup that LLM agents operate in when communicating with a user,\nand that we need to research avenues that enrich uncertainties in this novel\nscenario. We review the literature and find that popular definitions of\naleatoric and epistemic uncertainties directly contradict each other and lose\ntheir meaning in interactive LLM agent settings. Hence, we propose three novel\nresearch directions that focus on uncertainties in such human-computer\ninteractions: Underspecification uncertainties, for when users do not provide\nall information or define the exact task at the first go, interactive learning,\nto ask follow-up questions and reduce the uncertainty about the current\ncontext, and output uncertainties, to utilize the rich language and speech\nspace to express uncertainties as more than mere numbers. We expect that these\nnew ways of dealing with and communicating uncertainties will lead to LLM agent\ninteractions that are more transparent, trustworthy, and intuitive.",
    "pdf_url": "http://arxiv.org/pdf/2505.22655v1",
    "published": "2025-05-28T17:59:08+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.22653v1",
    "title": "The Climb Carves Wisdom Deeper Than the Summit: On the Noisy Rewards in Learning to Reason",
    "authors": [
      "Ang Lv",
      "Ruobing Xie",
      "Xingwu Sun",
      "Zhanhui Kang",
      "Rui Yan"
    ],
    "abstract": "Recent studies on post-training large language models (LLMs) for reasoning\nthrough reinforcement learning (RL) typically focus on tasks that can be\naccurately verified and rewarded, such as solving math problems. In contrast,\nour research investigates the impact of reward noise, a more practical\nconsideration for real-world scenarios involving the post-training of LLMs\nusing reward models. We found that LLMs demonstrate strong robustness to\nsubstantial reward noise. For example, manually flipping 40% of the reward\nfunction's outputs in math tasks still allows a Qwen-2.5-7B model to achieve\nrapid convergence, improving its performance on math tasks from 5% to 72%,\ncompared to the 75% accuracy achieved by a model trained with noiseless\nrewards. Surprisingly, by only rewarding the appearance of key reasoning\nphrases (namely reasoning pattern reward, RPR), such as ``first, I need\nto''-without verifying the correctness of answers, the model achieved peak\ndownstream performance (over 70% accuracy for Qwen-2.5-7B) comparable to models\ntrained with strict correctness verification and accurate rewards. Recognizing\nthe importance of the reasoning process over the final results, we combined RPR\nwith noisy reward models. RPR helped calibrate the noisy reward models,\nmitigating potential false negatives and enhancing the LLM's performance on\nopen-ended tasks. These findings suggest the importance of improving models'\nfoundational abilities during the pre-training phase while providing insights\nfor advancing post-training techniques. Our code and scripts are available at\nhttps://github.com/trestad/Noisy-Rewards-in-Learning-to-Reason.",
    "pdf_url": "http://arxiv.org/pdf/2505.22653v1",
    "published": "2025-05-28T17:59:03+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.22652v2",
    "title": "PyRigi -- a general-purpose Python package for the rigidity and flexibility of bar-and-joint frameworks",
    "authors": [
      "Matteo Gallet",
      "Georg Grasegger",
      "Matthias Himmelmann",
      "Jan Legersk√Ω"
    ],
    "abstract": "We present PyRigi, a novel Python package designed to study the rigidity\nproperties of graphs and frameworks. Among many other capabilities, PyRigi can\ndetermine whether a graph admits only finitely many ways, up to isometries, of\nbeing drawn in the plane once the edge lengths are fixed, whether it has a\nunique embedding, or whether it satisfied such properties even after the\nremoval of any of its edges. By implementing algorithms from the scientific\nliterature, PyRigi enables the exploration of rigidity properties of structures\nthat would be out of reach for computations by hand. With reliable and robust\nalgorithms, as well as clear, well-documented methods that are closely\nconnected to the underlying mathematical definitions and results, PyRigi aims\nto be a practical and powerful general-purpose tool for the working\nmathematician interested in rigidity theory. PyRigi is open source and easy to\nuse, and awaits researchers to benefit from its computational potential.",
    "pdf_url": "http://arxiv.org/pdf/2505.22652v2",
    "published": "2025-05-28T17:58:25+00:00",
    "categories": [
      "math.MG",
      "cs.CG",
      "cs.SC",
      "math.CO"
    ],
    "primary_category": "math.MG"
  },
  {
    "id": "http://arxiv.org/abs/2505.22651v1",
    "title": "Sherlock: Self-Correcting Reasoning in Vision-Language Models",
    "authors": [
      "Yi Ding",
      "Ruqi Zhang"
    ],
    "abstract": "Reasoning Vision-Language Models (VLMs) have shown promising performance on\ncomplex multimodal tasks. However, they still face significant challenges: they\nare highly sensitive to reasoning errors, require large volumes of annotated\ndata or accurate verifiers, and struggle to generalize beyond specific domains.\nTo address these limitations, we explore self-correction as a strategy to\nenhance reasoning VLMs. We first conduct an in-depth analysis of reasoning\nVLMs' self-correction abilities and identify key gaps. Based on our findings,\nwe introduce Sherlock, a self-correction and self-improvement training\nframework. Sherlock introduces a trajectory-level self-correction objective, a\npreference data construction method based on visual perturbation, and a dynamic\n$\\beta$ for preference tuning. Once the model acquires self-correction\ncapabilities using only 20k randomly sampled annotated data, it continues to\nself-improve without external supervision. Built on the Llama3.2-Vision-11B\nmodel, Sherlock achieves remarkable results across eight benchmarks, reaching\nan average accuracy of 64.1 with direct generation and 65.4 after\nself-correction. It outperforms LLaVA-CoT (63.2), Mulberry (63.9), and\nLlamaV-o1 (63.4) while using less than 20% of the annotated data.",
    "pdf_url": "http://arxiv.org/pdf/2505.22651v1",
    "published": "2025-05-28T17:58:03+00:00",
    "categories": [
      "cs.CV",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.22704v1",
    "title": "Training Language Models to Generate Quality Code with Program Analysis Feedback",
    "authors": [
      "Feng Yao",
      "Zilong Wang",
      "Liyuan Liu",
      "Junxia Cui",
      "Li Zhong",
      "Xiaohan Fu",
      "Haohui Mai",
      "Vish Krishnan",
      "Jianfeng Gao",
      "Jingbo Shang"
    ],
    "abstract": "Code generation with large language models (LLMs), often termed vibe coding,\nis increasingly adopted in production but fails to ensure code quality,\nparticularly in security (e.g., SQL injection vulnerabilities) and\nmaintainability (e.g., missing type annotations). Existing methods, such as\nsupervised fine-tuning and rule-based post-processing, rely on labor-intensive\nannotations or brittle heuristics, limiting their scalability and\neffectiveness. We propose REAL, a reinforcement learning framework that\nincentivizes LLMs to generate production-quality code using program\nanalysis-guided feedback. Specifically, REAL integrates two automated signals:\n(1) program analysis detecting security or maintainability defects and (2) unit\ntests ensuring functional correctness. Unlike prior work, our framework is\nprompt-agnostic and reference-free, enabling scalable supervision without\nmanual intervention. Experiments across multiple datasets and model scales\ndemonstrate that REAL outperforms state-of-the-art methods in simultaneous\nassessments of functionality and code quality. Our work bridges the gap between\nrapid prototyping and production-ready code, enabling LLMs to deliver both\nspeed and quality.",
    "pdf_url": "http://arxiv.org/pdf/2505.22704v1",
    "published": "2025-05-28T17:57:47+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.22650v1",
    "title": "On Learning Verifiers for Chain-of-Thought Reasoning",
    "authors": [
      "Maria-Florina Balcan",
      "Avrim Blum",
      "Zhiyuan Li",
      "Dravyansh Sharma"
    ],
    "abstract": "Chain-of-Thought reasoning has emerged as a powerful approach for solving\ncomplex mathematical and logical problems. However, it can often veer off track\nthrough incorrect or unsubstantiated inferences. Formal mathematical reasoning,\nwhich can be checked with a formal verifier, is one approach to addressing this\nissue. However, currently LLMs are simply not good enough to solve complex\nproblems in a formal way, and even just formalizing an informal problem\nstatement can be challenging. Motivated by this fact, in this work we consider\nthe problem of learning reliable verifiers for natural language\nChain-of-Thought reasoning. That is, given a problem statement and step-by-step\nsolution in natural language, the aim of the verifier is to output [Yes] if the\nreasoning steps in the solution are all valid, and [No] otherwise. In this work\nwe give a formal PAC-learning framework for studying this problem. We propose\nand analyze several natural verification goals, at different levels of\nstrength, in this framework. We provide sample complexity upper-bounds for\nlearning verifiers satisfying these goals, as well as lower-bound and\nimpossibility results for learning other natural verification objectives\nwithout additional assumptions.",
    "pdf_url": "http://arxiv.org/pdf/2505.22650v1",
    "published": "2025-05-28T17:57:29+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.22649v2",
    "title": "Pre-training for Recommendation Unlearning",
    "authors": [
      "Guoxuan Chen",
      "Lianghao Xia",
      "Chao Huang"
    ],
    "abstract": "Modern recommender systems powered by Graph Neural Networks (GNNs) excel at\nmodeling complex user-item interactions, yet increasingly face scenarios\nrequiring selective forgetting of training data. Beyond user requests to remove\nspecific interactions due to privacy concerns or preference changes, regulatory\nframeworks mandate recommender systems' ability to eliminate the influence of\ncertain user data from models. This recommendation unlearning challenge\npresents unique difficulties as removing connections within interaction graphs\ncreates ripple effects throughout the model, potentially impacting\nrecommendations for numerous users. Traditional approaches suffer from\nsignificant drawbacks: fragmentation methods damage graph structure and\ndiminish performance, while influence function techniques make assumptions that\nmay not hold in complex GNNs, particularly with self-supervised or random\narchitectures. To address these limitations, we propose a novel model-agnostic\npre-training paradigm UnlearnRec that prepares systems for efficient unlearning\noperations. Our Influence Encoder takes unlearning requests together with\nexisting model parameters and directly produces updated parameters of unlearned\nmodel with little fine-tuning, avoiding complete retraining while preserving\nmodel performance characteristics. Extensive evaluation on public benchmarks\ndemonstrates that our method delivers exceptional unlearning effectiveness\nwhile providing more than 10x speedup compared to retraining approaches. We\nrelease our method implementation at: https://github.com/HKUDS/UnlearnRec.",
    "pdf_url": "http://arxiv.org/pdf/2505.22649v2",
    "published": "2025-05-28T17:57:11+00:00",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2505.22648v3",
    "title": "WebDancer: Towards Autonomous Information Seeking Agency",
    "authors": [
      "Jialong Wu",
      "Baixuan Li",
      "Runnan Fang",
      "Wenbiao Yin",
      "Liwen Zhang",
      "Zhengwei Tao",
      "Dingchu Zhang",
      "Zekun Xi",
      "Gang Fu",
      "Yong Jiang",
      "Pengjun Xie",
      "Fei Huang",
      "Jingren Zhou"
    ],
    "abstract": "Addressing intricate real-world problems necessitates in-depth information\nseeking and multi-step reasoning. Recent progress in agentic systems,\nexemplified by Deep Research, underscores the potential for autonomous\nmulti-step research. In this work, we present a cohesive paradigm for building\nend-to-end agentic information seeking agents from a data-centric and\ntraining-stage perspective. Our approach consists of four key stages: (1)\nbrowsing data construction, (2) trajectories sampling, (3) supervised\nfine-tuning for effective cold start, and (4) reinforcement learning for\nenhanced generalisation. We instantiate this framework in a web agent based on\nthe ReAct, WebDancer. Empirical evaluations on the challenging information\nseeking benchmarks, GAIA and WebWalkerQA, demonstrate the strong performance of\nWebDancer, achieving considerable results and highlighting the efficacy of our\ntraining paradigm. Further analysis of agent training provides valuable\ninsights and actionable, systematic pathways for developing more capable\nagentic models. The codes and demo will be released in\nhttps://github.com/Alibaba-NLP/WebAgent.",
    "pdf_url": "http://arxiv.org/pdf/2505.22648v3",
    "published": "2025-05-28T17:57:07+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.22647v1",
    "title": "Let Them Talk: Audio-Driven Multi-Person Conversational Video Generation",
    "authors": [
      "Zhe Kong",
      "Feng Gao",
      "Yong Zhang",
      "Zhuoliang Kang",
      "Xiaoming Wei",
      "Xunliang Cai",
      "Guanying Chen",
      "Wenhan Luo"
    ],
    "abstract": "Audio-driven human animation methods, such as talking head and talking body\ngeneration, have made remarkable progress in generating synchronized facial\nmovements and appealing visual quality videos. However, existing methods\nprimarily focus on single human animation and struggle with multi-stream audio\ninputs, facing incorrect binding problems between audio and persons.\nAdditionally, they exhibit limitations in instruction-following capabilities.\nTo solve this problem, in this paper, we propose a novel task: Multi-Person\nConversational Video Generation, and introduce a new framework, MultiTalk, to\naddress the challenges during multi-person generation. Specifically, for audio\ninjection, we investigate several schemes and propose the Label Rotary Position\nEmbedding (L-RoPE) method to resolve the audio and person binding problem.\nFurthermore, during training, we observe that partial parameter training and\nmulti-task training are crucial for preserving the instruction-following\nability of the base model. MultiTalk achieves superior performance compared to\nother methods on several datasets, including talking head, talking body, and\nmulti-person datasets, demonstrating the powerful generation capabilities of\nour approach.",
    "pdf_url": "http://arxiv.org/pdf/2505.22647v1",
    "published": "2025-05-28T17:57:06+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.22646v1",
    "title": "Path-Dependent SDEs: Solutions and Parameter Estimation",
    "authors": [
      "Pardis Semnani",
      "Vincent Guan",
      "Elina Robeva",
      "Darrick Lee"
    ],
    "abstract": "We develop a consistent method for estimating the parameters of a rich class\nof path-dependent SDEs, called signature SDEs, which can model general\npath-dependent phenomena. Path signatures are iterated integrals of a given\npath with the property that any sufficiently nice function of the path can be\napproximated by a linear functional of its signatures. This is why we model the\ndrift and diffusion of our signature SDE as linear functions of path\nsignatures. We provide conditions that ensure the existence and uniqueness of\nsolutions to a general signature SDE. We then introduce the Expected Signature\nMatching Method (ESMM) for linear signature SDEs, which enables inference of\nthe signature-dependent drift and diffusion coefficients from observed\ntrajectories. Furthermore, we prove that ESMM is consistent: given sufficiently\nmany samples and Picard iterations used by the method, the parameters estimated\nby the ESMM approach the true parameter with arbitrary precision. Finally, we\ndemonstrate on a variety of empirical simulations that our ESMM accurately\ninfers the drift and diffusion parameters from observed trajectories. While\nparameter estimation is often restricted by the need for a suitable parametric\nmodel, this work makes progress toward a completely general framework for SDE\nparameter estimation, using signature terms to model arbitrary path-independent\nand path-dependent processes.",
    "pdf_url": "http://arxiv.org/pdf/2505.22646v1",
    "published": "2025-05-28T17:56:53+00:00",
    "categories": [
      "math.ST",
      "math.PR",
      "stat.TH",
      "60L20, 60L90, 62M99, 62M09"
    ],
    "primary_category": "math.ST"
  },
  {
    "id": "http://arxiv.org/abs/2505.22645v1",
    "title": "Characterizing Bias: Benchmarking Large Language Models in Simplified versus Traditional Chinese",
    "authors": [
      "Hanjia Lyu",
      "Jiebo Luo",
      "Jian Kang",
      "Allison Koenecke"
    ],
    "abstract": "While the capabilities of Large Language Models (LLMs) have been studied in\nboth Simplified and Traditional Chinese, it is yet unclear whether LLMs exhibit\ndifferential performance when prompted in these two variants of written\nChinese. This understanding is critical, as disparities in the quality of LLM\nresponses can perpetuate representational harms by ignoring the different\ncultural contexts underlying Simplified versus Traditional Chinese, and can\nexacerbate downstream harms in LLM-facilitated decision-making in domains such\nas education or hiring. To investigate potential LLM performance disparities,\nwe design two benchmark tasks that reflect real-world scenarios: regional term\nchoice (prompting the LLM to name a described item which is referred to\ndifferently in Mainland China and Taiwan), and regional name choice (prompting\nthe LLM to choose who to hire from a list of names in both Simplified and\nTraditional Chinese). For both tasks, we audit the performance of 11 leading\ncommercial LLM services and open-sourced models -- spanning those primarily\ntrained on English, Simplified Chinese, or Traditional Chinese. Our analyses\nindicate that biases in LLM responses are dependent on both the task and\nprompting language: while most LLMs disproportionately favored Simplified\nChinese responses in the regional term choice task, they surprisingly favored\nTraditional Chinese names in the regional name choice task. We find that these\ndisparities may arise from differences in training data representation, written\ncharacter preferences, and tokenization of Simplified and Traditional Chinese.\nThese findings highlight the need for further analysis of LLM biases; as such,\nwe provide an open-sourced benchmark dataset to foster reproducible evaluations\nof future LLM behavior across Chinese language variants\n(https://github.com/brucelyu17/SC-TC-Bench).",
    "pdf_url": "http://arxiv.org/pdf/2505.22645v1",
    "published": "2025-05-28T17:56:49+00:00",
    "categories": [
      "cs.CL",
      "cs.CY"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.22644v1",
    "title": "On the Intractability of Chaotic Symbolic Walks: Toward a Non-Algebraic Post-Quantum Hardness Assumption",
    "authors": [
      "Mohamed Aly Bouke"
    ],
    "abstract": "Most classical and post-quantum cryptographic assumptions, including integer\nfactorization, discrete logarithms, and Learning with Errors (LWE), rely on\nalgebraic structures such as rings or vector spaces. While mathematically\npowerful, these structures can be exploited by quantum algorithms or advanced\nalgebraic attacks, raising a pressing need for structure-free alternatives. To\naddress this gap, we introduce the Symbolic Path Inversion Problem (SPIP), a\nnew computational hardness assumption based on symbolic trajectories generated\nby contractive affine maps with bounded noise over Z2. Unlike traditional\nsystems, SPIP is inherently non-algebraic and relies on chaotic symbolic\nevolution and rounding-induced non-injectivity to render inversion\ncomputationally infeasible. We prove that SPIP is PSPACE-hard and #P-hard, and\ndemonstrate through empirical simulation that even short symbolic sequences\n(e.g., n = 3, m = 2) can produce over 500 valid trajectories for a single\nendpoint, with exponential growth reaching 2256 paths for moderate parameters.\nA quantum security analysis further shows that Grover-style search offers no\npractical advantage due to oracle ambiguity and verification instability. These\nresults position SPIP as a viable foundation for post-quantum cryptography that\navoids the vulnerabilities of algebraic symmetry while offering scalability,\nunpredictability, and resistance to both classical and quantum inversion.",
    "pdf_url": "http://arxiv.org/pdf/2505.22644v1",
    "published": "2025-05-28T17:56:00+00:00",
    "categories": [
      "cs.CR",
      "math.DS"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.22643v1",
    "title": "SPIRAL: Semantic-Aware Progressive LiDAR Scene Generation",
    "authors": [
      "Dekai Zhu",
      "Yixuan Hu",
      "Youquan Liu",
      "Dongyue Lu",
      "Lingdong Kong",
      "Slobodan Ilic"
    ],
    "abstract": "Leveraging recent diffusion models, LiDAR-based large-scale 3D scene\ngeneration has achieved great success. While recent voxel-based approaches can\ngenerate both geometric structures and semantic labels, existing range-view\nmethods are limited to producing unlabeled LiDAR scenes. Relying on pretrained\nsegmentation models to predict the semantic maps often results in suboptimal\ncross-modal consistency. To address this limitation while preserving the\nadvantages of range-view representations, such as computational efficiency and\nsimplified network design, we propose Spiral, a novel range-view LiDAR\ndiffusion model that simultaneously generates depth, reflectance images, and\nsemantic maps. Furthermore, we introduce novel semantic-aware metrics to\nevaluate the quality of the generated labeled range-view data. Experiments on\nthe SemanticKITTI and nuScenes datasets demonstrate that Spiral achieves\nstate-of-the-art performance with the smallest parameter size, outperforming\ntwo-step methods that combine the generative and segmentation models.\nAdditionally, we validate that range images generated by Spiral can be\neffectively used for synthetic data augmentation in the downstream segmentation\ntraining, significantly reducing the labeling effort on LiDAR data.",
    "pdf_url": "http://arxiv.org/pdf/2505.22643v1",
    "published": "2025-05-28T17:55:35+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.22642v3",
    "title": "FastTD3: Simple, Fast, and Capable Reinforcement Learning for Humanoid Control",
    "authors": [
      "Younggyo Seo",
      "Carmelo Sferrazza",
      "Haoran Geng",
      "Michal Nauman",
      "Zhao-Heng Yin",
      "Pieter Abbeel"
    ],
    "abstract": "Reinforcement learning (RL) has driven significant progress in robotics, but\nits complexity and long training times remain major bottlenecks. In this\nreport, we introduce FastTD3, a simple, fast, and capable RL algorithm that\nsignificantly speeds up training for humanoid robots in popular suites such as\nHumanoidBench, IsaacLab, and MuJoCo Playground. Our recipe is remarkably\nsimple: we train an off-policy TD3 agent with several modifications -- parallel\nsimulation, large-batch updates, a distributional critic, and carefully tuned\nhyperparameters. FastTD3 solves a range of HumanoidBench tasks in under 3 hours\non a single A100 GPU, while remaining stable during training. We also provide a\nlightweight and easy-to-use implementation of FastTD3 to accelerate RL research\nin robotics.",
    "pdf_url": "http://arxiv.org/pdf/2505.22642v3",
    "published": "2025-05-28T17:55:26+00:00",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.22703v1",
    "title": "Private Rate-Constrained Optimization with Applications to Fair Learning",
    "authors": [
      "Mohammad Yaghini",
      "Tudor Cebere",
      "Michael Menart",
      "Aur√©lien Bellet",
      "Nicolas Papernot"
    ],
    "abstract": "Many problems in trustworthy ML can be formulated as minimization of the\nmodel error under constraints on the prediction rates of the model for\nsuitably-chosen marginals, including most group fairness constraints\n(demographic parity, equality of odds, etc.). In this work, we study such\nconstrained minimization problems under differential privacy (DP). Standard DP\noptimization techniques like DP-SGD rely on the loss function's decomposability\ninto per-sample contributions. However, rate constraints introduce inter-sample\ndependencies, violating the decomposability requirement. To address this, we\ndevelop RaCO-DP, a DP variant of the Stochastic Gradient Descent-Ascent (SGDA)\nalgorithm which solves the Lagrangian formulation of rate constraint problems.\nWe demonstrate that the additional privacy cost of incorporating these\nconstraints reduces to privately estimating a histogram over the mini-batch at\neach optimization step. We prove the convergence of our algorithm through a\nnovel analysis of SGDA that leverages the linear structure of the dual\nparameter. Finally, empirical results on learning under group fairness\nconstraints demonstrate that our method Pareto-dominates existing private\nlearning approaches in fairness-utility trade-offs.",
    "pdf_url": "http://arxiv.org/pdf/2505.22703v1",
    "published": "2025-05-28T17:55:01+00:00",
    "categories": [
      "cs.LG",
      "cs.CR",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.22641v1",
    "title": "Spectral Survival Analysis",
    "authors": [
      "Chengzhi Shi",
      "Stratis Ioannidis"
    ],
    "abstract": "Survival analysis is widely deployed in a diverse set of fields, including\nhealthcare, business, ecology, etc. The Cox Proportional Hazard (CoxPH) model\nis a semi-parametric model often encountered in the literature. Despite its\npopularity, wide deployment, and numerous variants, scaling CoxPH to large\ndatasets and deep architectures poses a challenge, especially in the\nhigh-dimensional regime. We identify a fundamental connection between rank\nregression and the CoxPH model: this allows us to adapt and extend the\nso-called spectral method for rank regression to survival analysis. Our\napproach is versatile, naturally generalizing to several CoxPH variants,\nincluding deep models. We empirically verify our method's scalability on\nmultiple real-world high-dimensional datasets; our method outperforms legacy\nmethods w.r.t. predictive performance and efficiency.",
    "pdf_url": "http://arxiv.org/pdf/2505.22641v1",
    "published": "2025-05-28T17:54:39+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.22640v1",
    "title": "On the categorification of homology",
    "authors": [
      "Hadrian Heine"
    ],
    "abstract": "We categorify the concept of homology theories, which we term categorical\nhomology theories. More precisely, we extend the notion of homology theory from\nhomotopy theory to the realm of $(\\infty,\\infty)$-categories and show that\nseveral desirable features remain: we prove that categorical homology theories\nare homological in a precise categorified sense, satisfy a categorified\nWhitehead theorem and are classified by a higher categorical analogue of\nspectra. To study categorical homology theories we categorify stable homotopy\ntheory and the concept of stable $(\\infty,1)$-category. As guiding example of a\ncategorical homology theory we study the categorification of homology, the\ncategorical homology theory whose coefficients are the commutative monoid of\nnatural numbers, which we term categorical homology. We prove that categorical\nhomology admits a description analogous to singular homology that replaces the\nsingular complex of a space by the nerve of an $(\\infty,\\infty)$-category. We\nshow a categorified version of the Dold-Thom theorem and Hurewicz theorem,\ncompute categorical homology of the globes, the walking higher cells, and prove\nthat categorical $R$-homology with coeffients in a rig $R$ multiplicatively\nlifts to the higher category of $(R,R)$-bimodules.",
    "pdf_url": "http://arxiv.org/pdf/2505.22640v1",
    "published": "2025-05-28T17:54:34+00:00",
    "categories": [
      "math.AT",
      "math.CT",
      "math.KT"
    ],
    "primary_category": "math.AT"
  },
  {
    "id": "http://arxiv.org/abs/2505.22639v1",
    "title": "Navigating the AI-Energy Nexus with Geopolitical Insight",
    "authors": [
      "Nidhi Kalra",
      "Robin Wang",
      "Ismael Arciniegas Rueda"
    ],
    "abstract": "This working paper examines how geopolitical strategies and energy resource\nmanagement intersect with Artificial Intelligence (AI) development, delineating\nthe AI-energy nexus as critical to sustaining U.S. AI leadership. By analyzing\nthe centralized approaches of authoritarian regimes like China and Gulf\nnations, alongside market-driven approaches in the U.S., the paper explores\ndivergent strategies to allocate resources for AI energy needs. It underscores\nthe role of energy infrastructure, market dynamics, and state-led initiatives\nin shaping global AI competition. Recommendations include adopting\ngeopolitically informed analyses and leveraging both market and non-market\nstrengths to enhance U.S. competitiveness. This research aims to inform\npolicymakers, technologists, and researchers about the strategic implications\nof the AI-energy nexus and offers insights into advancing U.S. global\nleadership in AI amidst evolving technological paradigms.",
    "pdf_url": "http://arxiv.org/pdf/2505.22639v1",
    "published": "2025-05-28T17:54:30+00:00",
    "categories": [
      "cs.CY"
    ],
    "primary_category": "cs.CY"
  },
  {
    "id": "http://arxiv.org/abs/2505.22638v1",
    "title": "SimProcess: High Fidelity Simulation of Noisy ICS Physical Processes",
    "authors": [
      "Denis Donadel",
      "Gabriele Crestanello",
      "Giulio Morandini",
      "Daniele Antonioli",
      "Mauro Conti",
      "Massimo Merro"
    ],
    "abstract": "Industrial Control Systems (ICS) manage critical infrastructures like power\ngrids and water treatment plants. Cyberattacks on ICSs can disrupt operations,\ncausing severe economic, environmental, and safety issues. For example,\nundetected pollution in a water plant can put the lives of thousands at stake.\nICS researchers have increasingly turned to honeypots -- decoy systems designed\nto attract attackers, study their behaviors, and eventually improve defensive\nmechanisms. However, existing ICS honeypots struggle to replicate the ICS\nphysical process, making them susceptible to detection. Accurately simulating\nthe noise in ICS physical processes is challenging because different factors\nproduce it, including sensor imperfections and external interferences.\n  In this paper, we propose SimProcess, a novel framework to rank the fidelity\nof ICS simulations by evaluating how closely they resemble real-world and noisy\nphysical processes. It measures the simulation distance from a target system by\nestimating the noise distribution with machine learning models like Random\nForest. Unlike existing solutions that require detailed mathematical models or\nare limited to simple systems, SimProcess operates with only a timeseries of\nmeasurements from the real system, making it applicable to a broader range of\ncomplex dynamic systems. We demonstrate the framework's effectiveness through a\ncase study using real-world power grid data from the EPIC testbed. We compare\nthe performance of various simulation methods, including static and generative\nnoise techniques. Our model correctly classifies real samples with a recall of\nup to 1.0. It also identifies Gaussian and Gaussian Mixture as the best\ndistribution to simulate our power systems, together with a generative solution\nprovided by an autoencoder, thereby helping developers to improve honeypot\nfidelity. Additionally, we make our code publicly available.",
    "pdf_url": "http://arxiv.org/pdf/2505.22638v1",
    "published": "2025-05-28T17:54:23+00:00",
    "categories": [
      "cs.CR",
      "cs.LG"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.22637v1",
    "title": "Understanding (Un)Reliability of Steering Vectors in Language Models",
    "authors": [
      "Joschka Braun",
      "Carsten Eickhoff",
      "David Krueger",
      "Seyed Ali Bahrainian",
      "Dmitrii Krasheninnikov"
    ],
    "abstract": "Steering vectors are a lightweight method to control language model behavior\nby adding a learned bias to the activations at inference time. Although\nsteering demonstrates promising performance, recent work shows that it can be\nunreliable or even counterproductive in some cases. This paper studies the\ninfluence of prompt types and the geometry of activation differences on\nsteering reliability. First, we find that all seven prompt types used in our\nexperiments produce a net positive steering effect, but exhibit high variance\nacross samples, and often give an effect opposite of the desired one. No prompt\ntype clearly outperforms the others, and yet the steering vectors resulting\nfrom the different prompt types often differ directionally (as measured by\ncosine similarity). Second, we show that higher cosine similarity between\ntraining set activation differences predicts more effective steering. Finally,\nwe observe that datasets where positive and negative activations are better\nseparated are more steerable. Our results suggest that vector steering is\nunreliable when the target behavior is not represented by a coherent direction.",
    "pdf_url": "http://arxiv.org/pdf/2505.22637v1",
    "published": "2025-05-28T17:53:31+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.22636v1",
    "title": "ObjectClear: Complete Object Removal via Object-Effect Attention",
    "authors": [
      "Jixin Zhao",
      "Shangchen Zhou",
      "Zhouxia Wang",
      "Peiqing Yang",
      "Chen Change Loy"
    ],
    "abstract": "Object removal requires eliminating not only the target object but also its\neffects, such as shadows and reflections. However, diffusion-based inpainting\nmethods often produce artifacts, hallucinate content, alter background, and\nstruggle to remove object effects accurately. To address this challenge, we\nintroduce a new dataset for OBject-Effect Removal, named OBER, which provides\npaired images with and without object effects, along with precise masks for\nboth objects and their associated visual artifacts. The dataset comprises\nhigh-quality captured and simulated data, covering diverse object categories\nand complex multi-object scenes. Building on OBER, we propose a novel\nframework, ObjectClear, which incorporates an object-effect attention mechanism\nto guide the model toward the foreground removal regions by learning attention\nmasks, effectively decoupling foreground removal from background\nreconstruction. Furthermore, the predicted attention map enables an\nattention-guided fusion strategy during inference, greatly preserving\nbackground details. Extensive experiments demonstrate that ObjectClear\noutperforms existing methods, achieving improved object-effect removal quality\nand background fidelity, especially in complex scenarios.",
    "pdf_url": "http://arxiv.org/pdf/2505.22636v1",
    "published": "2025-05-28T17:51:17+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.22635v1",
    "title": "Learning Composable Chains-of-Thought",
    "authors": [
      "Fangcong Yin",
      "Zeyu Leo Liu",
      "Liu Leqi",
      "Xi Ye",
      "Greg Durrett"
    ],
    "abstract": "A common approach for teaching large language models (LLMs) to reason is to\ntrain on chain-of-thought (CoT) traces of in-distribution reasoning problems,\nbut such annotated data is costly to obtain for every problem of interest. We\nwant reasoning models to generalize beyond their training distribution, and\nideally to generalize compositionally: combine atomic reasoning skills to solve\nharder, unseen reasoning tasks. We take a step towards compositional\ngeneralization of reasoning skills when addressing a target compositional task\nthat has no labeled CoT data. We find that simply training models on CoT data\nof atomic tasks leads to limited generalization, but minimally modifying CoT\nformats of constituent atomic tasks to be composable can lead to improvements.\nWe can train \"atomic CoT\" models on the atomic tasks with Composable CoT data\nand combine them with multitask learning or model merging for better zero-shot\nperformance on the target compositional task. Such a combined model can be\nfurther bootstrapped on a small amount of compositional data using rejection\nsampling fine-tuning (RFT). Results on string operations and natural language\nskill compositions show that training LLMs on Composable CoT outperforms\nmultitask learning and continued fine-tuning baselines within a given training\ndata budget.",
    "pdf_url": "http://arxiv.org/pdf/2505.22635v1",
    "published": "2025-05-28T17:51:10+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.22634v1",
    "title": "LabUtopia: High-Fidelity Simulation and Hierarchical Benchmark for Scientific Embodied Agents",
    "authors": [
      "Rui Li",
      "Zixuan Hu",
      "Wenxi Qu",
      "Jinouwen Zhang",
      "Zhenfei Yin",
      "Sha Zhang",
      "Xuantuo Huang",
      "Hanqing Wang",
      "Tai Wang",
      "Jiangmiao Pang",
      "Wanli Ouyang",
      "Lei Bai",
      "Wangmeng Zuo",
      "Ling-Yu Duan",
      "Dongzhan Zhou",
      "Shixiang Tang"
    ],
    "abstract": "Scientific embodied agents play a crucial role in modern laboratories by\nautomating complex experimental workflows. Compared to typical household\nenvironments, laboratory settings impose significantly higher demands on\nperception of physical-chemical transformations and long-horizon planning,\nmaking them an ideal testbed for advancing embodied intelligence. However, its\ndevelopment has been long hampered by the lack of suitable simulator and\nbenchmarks. In this paper, we address this gap by introducing LabUtopia, a\ncomprehensive simulation and benchmarking suite designed to facilitate the\ndevelopment of generalizable, reasoning-capable embodied agents in laboratory\nsettings. Specifically, it integrates i) LabSim, a high-fidelity simulator\nsupporting multi-physics and chemically meaningful interactions; ii) LabScene,\na scalable procedural generator for diverse scientific scenes; and iii)\nLabBench, a hierarchical benchmark spanning five levels of complexity from\natomic actions to long-horizon mobile manipulation. LabUtopia supports 30\ndistinct tasks and includes more than 200 scene and instrument assets, enabling\nlarge-scale training and principled evaluation in high-complexity environments.\nWe demonstrate that LabUtopia offers a powerful platform for advancing the\nintegration of perception, planning, and control in scientific-purpose agents\nand provides a rigorous testbed for exploring the practical capabilities and\ngeneralization limits of embodied intelligence in future research.",
    "pdf_url": "http://arxiv.org/pdf/2505.22634v1",
    "published": "2025-05-28T17:50:53+00:00",
    "categories": [
      "cs.RO",
      "cs.SE"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.22633v1",
    "title": "Spatial Knowledge Graph-Guided Multimodal Synthesis",
    "authors": [
      "Yida Xue",
      "Zhen Bi",
      "Jinnan Yang",
      "Jungang Lou",
      "Huajun Chen",
      "Ningyu Zhang"
    ],
    "abstract": "Recent advances in multimodal large language models (MLLMs) have\nsignificantly enhanced their capabilities; however, their spatial perception\nabilities remain a notable limitation. To address this challenge, multimodal\ndata synthesis offers a promising solution. Yet, ensuring that synthesized data\nadhere to spatial common sense is a non-trivial task. In this work, we\nintroduce SKG2Data, a novel multimodal synthesis approach guided by spatial\nknowledge graphs, grounded in the concept of knowledge-to-data generation.\nSKG2Data automatically constructs a Spatial Knowledge Graph (SKG) to emulate\nhuman-like perception of spatial directions and distances, which is\nsubsequently utilized to guide multimodal data synthesis. Extensive experiments\ndemonstrate that data synthesized from diverse types of spatial knowledge,\nincluding direction and distance, not only enhance the spatial perception and\nreasoning abilities of MLLMs but also exhibit strong generalization\ncapabilities. We hope that the idea of knowledge-based data synthesis can\nadvance the development of spatial intelligence.",
    "pdf_url": "http://arxiv.org/pdf/2505.22633v1",
    "published": "2025-05-28T17:50:21+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV",
      "cs.LG",
      "cs.MM"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.22632v1",
    "title": "Towards the Efficient Inference by Incorporating Automated Computational Phenotypes under Covariate Shift",
    "authors": [
      "Chao Ying",
      "Jun Jin",
      "Yi Guo",
      "Xiudi Li",
      "Muxuan Liang",
      "Jiwei Zhao"
    ],
    "abstract": "Collecting gold-standard phenotype data via manual extraction is typically\nlabor-intensive and slow, whereas automated computational phenotypes (ACPs)\noffer a systematic and much faster alternative. However, simply replacing the\ngold-standard with ACPs, without acknowledging their differences, could lead to\nbiased results and misleading conclusions. Motivated by the complexity of\nincorporating ACPs while maintaining the validity of downstream analyses, in\nthis paper, we consider a semi-supervised learning setting that consists of\nboth labeled data (with gold-standard) and unlabeled data (without\ngold-standard), under the covariate shift framework. We develop doubly robust\nand semiparametrically efficient estimators that leverage ACPs for general\ntarget parameters in the unlabeled and combined populations. In addition, we\ncarefully analyze the efficiency gains achieved by incorporating ACPs,\ncomparing scenarios with and without their inclusion. Notably, we identify that\nACPs for the unlabeled data, instead of for the labeled data, drive the\nenhanced efficiency gains. To validate our theoretical findings, we conduct\ncomprehensive synthetic experiments and apply our method to multiple real-world\ndatasets, confirming the practical advantages of our approach.\n\\hfill{\\texttt{Code}:\n\\href{https://github.com/brucejunjin/ICML2025-ACPCS}{\\faGithub}}",
    "pdf_url": "http://arxiv.org/pdf/2505.22632v1",
    "published": "2025-05-28T17:50:20+00:00",
    "categories": [
      "stat.ME"
    ],
    "primary_category": "stat.ME"
  },
  {
    "id": "http://arxiv.org/abs/2505.23846v1",
    "title": "Scalable, Symbiotic, AI and Non-AI Agent Based Parallel Discrete Event Simulations",
    "authors": [
      "Atanu Barai",
      "Stephan Eidenbenz",
      "Nandakishore Santhi"
    ],
    "abstract": "To fully leverage the potential of artificial intelligence (AI) systems in a\ntrustworthy manner, it is desirable to couple multiple AI and non-AI systems\ntogether seamlessly for constraining and ensuring correctness of the output.\nThis paper introduces a novel parallel discrete event simulation (PDES) based\nmethodology to combine multiple AI and non-AI agents in a causal, rule-based\nway. Our approach tightly integrates the concept of passage of time, with each\nagent considered as an entity in the PDES framework and responding to prior\nrequests from other agents. Such coupling mechanism enables the agents to work\nin a co-operative environment towards a common goal while many tasks run in\nparallel throughout the simulation. It further enables setting up boundaries to\nthe outputs of the AI agents by applying necessary dynamic constraints using\nnon-AI agents while allowing for scalability through deployment of hundreds of\nsuch agents in a larger compute cluster. Distributing smaller AI agents can\nenable extremely scalable simulations in the future, addressing local memory\nbottlenecks for model parameter storage. Within a PDES involving both AI and\nnon-AI agents, we break down the problem at hand into structured steps, when\nnecessary, providing a set of multiple choices to the AI agents, and then\nprogressively solve these steps towards a final goal. At each step, the non-AI\nagents act as unbiased auditors, verifying each action by the AI agents so that\ncertain rules of engagement are followed. We evaluate our approach by solving\nfour problems from four different domains and comparing the results with those\nfrom AI models alone. Our results show greater accuracy in solving problems\nfrom various domains where the AI models struggle to solve the problems solely\nby themselves. Results show that overall accuracy of our approach is 68% where\nas the accuracy of vanilla models is less than 23%.",
    "pdf_url": "http://arxiv.org/pdf/2505.23846v1",
    "published": "2025-05-28T17:50:01+00:00",
    "categories": [
      "cs.CL",
      "cs.MA"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.22631v1",
    "title": "GPU-Accelerated Simulated Oscillator Ising/Potts Machine Solving Combinatorial Optimization Problems",
    "authors": [
      "Yilmaz Ege Gonul",
      "Ceyhun Efe Kayan",
      "Ilknur Mustafazade",
      "Nagarajan Kandasamy",
      "Baris Taskin"
    ],
    "abstract": "Oscillator-based Ising machines (OIMs) and oscillator-based Potts machines\n(OPMs) have emerged as promising hardware accelerators for solving NP-hard\ncombinatorial optimization problems by leveraging the phase dynamics of coupled\noscillators. In this work, a GPU-accelerated simulated OIM/OPM digital\ncomputation framework capable of solving combinatorial optimization problems is\npresented. The proposed implementation harnesses the parallel processing\ncapabilities of GPUs to simulate large-scale OIM/OPMs, leveraging the\nadvantages of digital computing to offer high precision, programmability, and\nscalability. The performance of the proposed GPU framework is evaluated on the\nmax-cut problems from the GSET benchmark dataset and graph coloring problems\nfrom the SATLIB benchmarks dataset, demonstrating competitive speed and\naccuracy in tackling large-scale problems. The results from simulations,\nreaching up to 11295x speed-up over CPUs with up to 99% accuracy, establish\nthis framework as a scalable, massively parallelized, and high-fidelity digital\nrealization of OIM/OPMs.",
    "pdf_url": "http://arxiv.org/pdf/2505.22631v1",
    "published": "2025-05-28T17:49:55+00:00",
    "categories": [
      "cs.AR"
    ],
    "primary_category": "cs.AR"
  },
  {
    "id": "http://arxiv.org/abs/2505.22702v1",
    "title": "Are there stars in Bluesky after the return of Donald Trump to the White House?",
    "authors": [
      "Wenceslao Arroyo-Machado",
      "Nicolas Robinson-Garcia",
      "Daniel Torres-Salinas"
    ],
    "abstract": "This study examines the shift in the scientific community from X (formerly\nTwitter) to Bluesky, its impact on scientific communication, and consequently\non social metrics (altmetrics). We analysed 14,497 publications from\nmultidisciplinary and Library and Information Science (LIS) journals between\nJanuary 2024 and March 2025. The results reveal a notable increase in Bluesky\nactivity for multidisciplinary journals in November 2024, likely influenced by\npolitical and platform changes, with mentions multiplying for journals like\nNature and Science. In LIS, the adoption of Bluesky is different and shows\nmarked variation between European and United States journals. Although Bluesky\nremains a minority platform compared to X over the whole period, when focusing\non user engagement after the United States elections, we see a much more even\ndistribution between the two platforms. In two LIS journals, Bluesky even\nsurpasses X, while in most others, the difference in user engagement was no\nlonger as pronounced, marking a significant change from previous patterns in\naltmetrics.",
    "pdf_url": "http://arxiv.org/pdf/2505.22702v1",
    "published": "2025-05-28T17:49:18+00:00",
    "categories": [
      "cs.DL"
    ],
    "primary_category": "cs.DL"
  },
  {
    "id": "http://arxiv.org/abs/2505.22630v2",
    "title": "Stochastic Chameleons: Irrelevant Context Hallucinations Reveal Class-Based (Mis)Generalization in LLMs",
    "authors": [
      "Ziling Cheng",
      "Meng Cao",
      "Marc-Antoine Rondeau",
      "Jackie Chi Kit Cheung"
    ],
    "abstract": "The widespread success of large language models (LLMs) on NLP benchmarks has\nbeen accompanied by concerns that LLMs function primarily as stochastic parrots\nthat reproduce texts similar to what they saw during pre-training, often\nerroneously. But what is the nature of their errors, and do these errors\nexhibit any regularities? In this work, we examine irrelevant context\nhallucinations, in which models integrate misleading contextual cues into their\npredictions. Through behavioral analysis, we show that these errors result from\na structured yet flawed mechanism that we term class-based (mis)generalization,\nin which models combine abstract class cues with features extracted from the\nquery or context to derive answers. Furthermore, mechanistic interpretability\nexperiments on Llama-3, Mistral, and Pythia across 39 factual recall relation\ntypes reveal that this behavior is reflected in the model's internal\ncomputations: (i) abstract class representations are constructed in lower\nlayers before being refined into specific answers in higher layers, (ii)\nfeature selection is governed by two competing circuits -- one prioritizing\ndirect query-based reasoning, the other incorporating contextual cues -- whose\nrelative influences determine the final output. Our findings provide a more\nnuanced perspective on the stochastic parrot argument: through form-based\ntraining, LLMs can exhibit generalization leveraging abstractions, albeit in\nunreliable ways based on contextual cues -- what we term stochastic chameleons.",
    "pdf_url": "http://arxiv.org/pdf/2505.22630v2",
    "published": "2025-05-28T17:47:52+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.22629v1",
    "title": "Disambiguating Pauli noise in quantum computers",
    "authors": [
      "Edward H. Chen",
      "Senrui Chen",
      "Laurin E. Fischer",
      "Andrew Eddins",
      "Luke C. G. Govia",
      "Brad Mitchell",
      "Andre He",
      "Youngseok Kim",
      "Liang Jiang",
      "Alireza Seif"
    ],
    "abstract": "To successfully perform quantum computations, it is often necessary to first\naccurately characterize the noise in the underlying hardware. However, it is\nwell known that fundamental limitations prevent the unique identification of\nthe noise. This raises the question of whether these limitations impact the\nability to predict noisy dynamics and mitigate errors. Here, we show, both\ntheoretically and experimentally, that when learnable parameters are\nself-consistently characterized, the unlearnable (gauge) degrees of freedom do\nnot impact predictions of noisy dynamics or error mitigation. We use the\nrecently introduced framework of gate set Pauli noise learning to efficiently\nand self-consistently characterize and mitigate noise of a complete gate set,\nincluding state preparation, measurements, single-qubit gates and multi-qubit\nentangling Clifford gates. We validate our approach through experiments with up\nto 92 qubits and show that while the gauge choice does not affect\nerror-mitigated observable values, optimizing it reduces sampling overhead. Our\nfindings address an outstanding issue involving the ambiguities in\ncharacterizing and mitigating quantum noise.",
    "pdf_url": "http://arxiv.org/pdf/2505.22629v1",
    "published": "2025-05-28T17:46:17+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.22628v1",
    "title": "Lattice Compatibility and Energy Barriers in Intercalation Compounds",
    "authors": [
      "Delin Zhang",
      "Ananya Renuka Balakrishna"
    ],
    "abstract": "We present a continuum model for symmetry-breaking phase transformations in\nintercalation compounds, based on Ericksen's multi-well energy formulation. The\nmodel predicts the nucleation and growth of crystallographic microstructures in\nLi$_{2}$Mn$_{2}$O$_{4}$ -- a representative intercalation compound -- with twin\nboundary orientations and volume fractions that closely match experimental\nobservations. Our chemo-mechanically coupled model not only generates\ngeometrically accurate microstructures through energy minimization, but also\nreveals a subtle interplay between twinned domains and electro-chemo-mechanical\nbehavior. A key finding is that intercalation compounds satisfying specific\ncompatibility conditions (e.g., $\\lambda_{2} = 1$ or $|\\det \\mathbf{U} - 1| =\n0)$ show lower elastic energy barriers, require smaller driving forces, and\ndisplay narrower voltage hysteresis loops. Furthermore, we show that twinned\ndomains act as conduits for fast Li-diffusion. These results establish\nquantitative design guidelines for intercalation compounds, which focuses on\ntailoring lattice deformations (rather than suppressing them) and reducing\nenergy barriers to mitigate structural degradation and enhance the\nelectrochemical performance of battery electrodes.",
    "pdf_url": "http://arxiv.org/pdf/2505.22628v1",
    "published": "2025-05-28T17:46:14+00:00",
    "categories": [
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2505.22627v2",
    "title": "Chain-of-Talkers (CoTalk): Fast Human Annotation of Dense Image Captions",
    "authors": [
      "Yijun Shen",
      "Delong Chen",
      "Fan Liu",
      "Xingyu Wang",
      "Chuanyi Zhang",
      "Liang Yao",
      "Yuhui Zheng"
    ],
    "abstract": "While densely annotated image captions significantly facilitate the learning\nof robust vision-language alignment, methodologies for systematically\noptimizing human annotation efforts remain underexplored. We introduce\nChain-of-Talkers (CoTalk), an AI-in-the-loop methodology designed to maximize\nthe number of annotated samples and improve their comprehensiveness under fixed\nbudget constraints (e.g., total human annotation time). The framework is built\nupon two key insights. First, sequential annotation reduces redundant workload\ncompared to conventional parallel annotation, as subsequent annotators only\nneed to annotate the ``residual'' -- the missing visual information that\nprevious annotations have not covered. Second, humans process textual input\nfaster by reading while outputting annotations with much higher throughput via\ntalking; thus a multimodal interface enables optimized efficiency. We evaluate\nour framework from two aspects: intrinsic evaluations that assess the\ncomprehensiveness of semantic units, obtained by parsing detailed captions into\nobject-attribute trees and analyzing their effective connections; extrinsic\nevaluation measures the practical usage of the annotated captions in\nfacilitating vision-language alignment. Experiments with eight participants\nshow our Chain-of-Talkers (CoTalk) improves annotation speed (0.42 vs. 0.30\nunits/sec) and retrieval performance (41.13% vs. 40.52%) over the parallel\nmethod.",
    "pdf_url": "http://arxiv.org/pdf/2505.22627v2",
    "published": "2025-05-28T17:45:55+00:00",
    "categories": [
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.22626v2",
    "title": "SCIZOR: A Self-Supervised Approach to Data Curation for Large-Scale Imitation Learning",
    "authors": [
      "Yu Zhang",
      "Yuqi Xie",
      "Huihan Liu",
      "Rutav Shah",
      "Michael Wan",
      "Linxi Fan",
      "Yuke Zhu"
    ],
    "abstract": "Imitation learning advances robot capabilities by enabling the acquisition of\ndiverse behaviors from human demonstrations. However, large-scale datasets used\nfor policy training often introduce substantial variability in quality, which\ncan negatively impact performance. As a result, automatically curating datasets\nby filtering low-quality samples to improve quality becomes essential. Existing\nrobotic curation approaches rely on costly manual annotations and perform\ncuration at a coarse granularity, such as the dataset or trajectory level,\nfailing to account for the quality of individual state-action pairs. To address\nthis, we introduce SCIZOR, a self-supervised data curation framework that\nfilters out low-quality state-action pairs to improve the performance of\nimitation learning policies. SCIZOR targets two complementary sources of\nlow-quality data: suboptimal data, which hinders learning with undesirable\nactions, and redundant data, which dilutes training with repetitive patterns.\nSCIZOR leverages a self-supervised task progress predictor for suboptimal data\nto remove samples lacking task progression, and a deduplication module\noperating on joint state-action representation for samples with redundant\npatterns. Empirically, we show that SCIZOR enables imitation learning policies\nto achieve higher performance with less data, yielding an average improvement\nof 15.4% across multiple benchmarks. More information is available at:\nhttps://ut-austin-rpl.github.io/SCIZOR/",
    "pdf_url": "http://arxiv.org/pdf/2505.22626v2",
    "published": "2025-05-28T17:45:05+00:00",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.22625v1",
    "title": "A Proof of the Biquadratic Linear AFL for GL(4)",
    "authors": [
      "Qirui Li"
    ],
    "abstract": "We prove both the biquadratic Guo--Jacquet Fundamental Lemma (FL) and the\nbiquadratic linear Arithmetic Fundamental Lemma (AFL) for GL(4) with the unit\ntest function. Our approach relies on a detailed study of pairs of quadratic\nembeddings, which ultimately enables a reduction from the biquadratic case of\nGL(4) to the coquadratic case of GL(2). We further identify conditions under\nwhich the biquadratic case can be derived from the coquadratic case, and show\nthat this reduction allows us to establish the conjectures for all orbits in\nGL(4). As an additional consequence, we also prove the biquadratic FL for the\nidentity test function in certain special families of orbits in GL(2n). All\nresults hold over both p-adic fields and local fields of positive\ncharacteristic.",
    "pdf_url": "http://arxiv.org/pdf/2505.22625v1",
    "published": "2025-05-28T17:45:02+00:00",
    "categories": [
      "math.NT"
    ],
    "primary_category": "math.NT"
  },
  {
    "id": "http://arxiv.org/abs/2505.22624v1",
    "title": "Spectroscopic Observations of Supra-Arcade Downflows",
    "authors": [
      "Ryan J. French",
      "Maria D. Kazachenko",
      "Teodora Mihailescu",
      "Katharine K. Reeves"
    ],
    "abstract": "Despite their somewhat-frequent appearance in EUV imaging of off-limb flares,\nthe origins of Supra-Arcade Downflows (SADs) remain a mystery. Appearing as\ndark, tendril-like downflows above growing flare loop arcades, SADs themselves\nare yet to be tied into the standard model of solar flares. The uncertainty of\ntheir origin is, in part, due to a lack of spectral observations, with the last\npublished SAD spectral observations dating back to the Solar and Heliospheric\nObservatory / Solar Ultraviolet Measurements of Emitted Radiation (SOHO/SUMER)\nera in 2003. In this work, we present new observations of SADs within an\nM-class solar flare on April 2nd, 2022, observed by the Hinode EUV Imaging\nSpectrometer (EIS) and NASA Solar Dynamics Observatory. We measure Fe XXIV\n192.02 Angstrom Doppler downflows and non-thermal velocities in the\nlow-intensity SAD features, exceeding values measured in the surrounding flare\nfan. The ratio of temperature-sensitive Fe XXIV 255.11 Angstrom and Fe XXIII\n263.41 Angstrom lines also allow the measurement of electron temperature,\nrevealing temperatures within the range of the surrounding flare fan. We\ncompare EIS line-of-sight Doppler velocities with plane-of-sky velocities\nmeasured by AIA, to construct the 3D velocity profile of four prominent SADs,\nfinding evidence for their divergence above the flare loop arcade - possibly\nrelated to the presence of a high altitude termination shock. Finally, we\ndetect 'stealth' SADs, which produce SAD-like Doppler signals, yet with no\nchange in intensity.",
    "pdf_url": "http://arxiv.org/pdf/2505.22624v1",
    "published": "2025-05-28T17:44:37+00:00",
    "categories": [
      "astro-ph.SR",
      "physics.plasm-ph",
      "physics.space-ph"
    ],
    "primary_category": "astro-ph.SR"
  },
  {
    "id": "http://arxiv.org/abs/2505.22623v2",
    "title": "A theory for diffusion-controlled reactions within nonequilibrium steady states",
    "authors": [
      "Seokjin Moon",
      "David T. Limmer"
    ],
    "abstract": "We study diffusion-controlled processes in nonequilibrium steady states,\nwhere standard rate theory assumptions break down. Using transition path\ntheory, we generalize the relations between reactive probability fluxes and\nmeasures of the rate of the reaction. Stochastic thermodynamics analysis\nreveals how work constrains the enhancement of rates relative to their\nequilibrium values. An analytically solvable ion pairing model under a strong\nelectric field illustrates and validates our approach and theory. These\nfindings provide deeper insights into diffusion-controlled reaction dynamics\nbeyond equilibrium.",
    "pdf_url": "http://arxiv.org/pdf/2505.22623v2",
    "published": "2025-05-28T17:44:24+00:00",
    "categories": [
      "physics.chem-ph",
      "cond-mat.stat-mech"
    ],
    "primary_category": "physics.chem-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.22622v1",
    "title": "Principled Out-of-Distribution Generalization via Simplicity",
    "authors": [
      "Jiawei Ge",
      "Amanda Wang",
      "Shange Tang",
      "Chi Jin"
    ],
    "abstract": "Modern foundation models exhibit remarkable out-of-distribution (OOD)\ngeneralization, solving tasks far beyond the support of their training data.\nHowever, the theoretical principles underpinning this phenomenon remain\nelusive. This paper investigates this problem by examining the compositional\ngeneralization abilities of diffusion models in image generation. Our analysis\nreveals that while neural network architectures are expressive enough to\nrepresent a wide range of models -- including many with undesirable behavior on\nOOD inputs -- the true, generalizable model that aligns with human expectations\ntypically corresponds to the simplest among those consistent with the training\ndata.\n  Motivated by this observation, we develop a theoretical framework for OOD\ngeneralization via simplicity, quantified using a predefined simplicity metric.\nWe analyze two key regimes: (1) the constant-gap setting, where the true model\nis strictly simpler than all spurious alternatives by a fixed gap, and (2) the\nvanishing-gap setting, where the fixed gap is replaced by a smoothness\ncondition ensuring that models close in simplicity to the true model yield\nsimilar predictions. For both regimes, we study the regularized maximum\nlikelihood estimator and establish the first sharp sample complexity guarantees\nfor learning the true, generalizable, simple model.",
    "pdf_url": "http://arxiv.org/pdf/2505.22622v1",
    "published": "2025-05-28T17:44:10+00:00",
    "categories": [
      "stat.ML",
      "cs.LG",
      "math.ST",
      "stat.TH"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2505.22621v2",
    "title": "Mass-feeding of jet-launching white dwarfs in grazing and common envelope evolution",
    "authors": [
      "Noam Soker"
    ],
    "abstract": "I propose a scenario that allows white dwarfs (WDs) to launch relatively\npowerful jets when they enter a common envelope evolution (CEE) or experience a\ngrazing envelope evolution (GEE) with a red giant branch star (RGB) or an\nasymptotic giant branch (AGB) star. In this, still a speculative scenario, the\naccretion for a time is mainly onto an accretion disk with a radius of ~1Ro\nthat increases in mass. The accretion disk launches the powerful two opposite\njets by releasing gravitational energy, up to several times super-Eddington, as\nits mass increases. The jets launched by the disk remove high-entropy gas from\nits outskirts and the envelope that the WD inflates due to nuclear burning on\nits surface. The motivations to allow WDs to launch powerful jets are recent\nfindings, from the morphologies of post-CEE planetary nebulae, that jets play a\nmajor role in the CEE and the accumulating evidence that jets power luminous\nred novae by jets, as their morphologies indicate. I strengthen my call to\ninclude jets in the simulation and modeling of the CEE, consider the GEE as a\nphase preceding the CEE in many (but not all) cases, and include jets as a\nmajor ingredient in modeling and simulating all energetic luminous red novae.",
    "pdf_url": "http://arxiv.org/pdf/2505.22621v2",
    "published": "2025-05-28T17:43:55+00:00",
    "categories": [
      "astro-ph.SR",
      "astro-ph.HE"
    ],
    "primary_category": "astro-ph.SR"
  },
  {
    "id": "http://arxiv.org/abs/2505.22620v2",
    "title": "Counting big Ramsey degrees of the homogeneous and universal $K_4$-free graph",
    "authors": [
      "Jan Hubiƒçka",
      "Matƒõj Koneƒçn√Ω",
      "≈†tƒõp√°n Vodseƒè√°lek",
      "Andy Zucker"
    ],
    "abstract": "Big Ramsey degrees of Fra\\\"iss\\'e limits of finitely constrained free\namalgamation classes in finite binary languages have been recently fully\ncharacterised by Balko, Chodounsk\\'y, Dobrinen, Hubi\\v{c}ka, Kone\\v{c}n\\'y,\nVena, and Zucker. A special case of this characterisation is the universal\nhomogeneous $K_4$-free graph. We give a self-contained and relatively compact\npresentation of this case and compute the actual big Ramsey degrees of small\ngraphs.",
    "pdf_url": "http://arxiv.org/pdf/2505.22620v2",
    "published": "2025-05-28T17:43:21+00:00",
    "categories": [
      "math.CO",
      "cs.DM",
      "math.LO",
      "05C55, 05D10, 05C30",
      "G.2.1; G.2.2"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.22619v1",
    "title": "Smart Contracts for SMEs and Large Companies",
    "authors": [
      "C. G. Liu",
      "P. Bodorik",
      "D. Jutla"
    ],
    "abstract": "Research on blockchains addresses multiple issues, with one being writing\nsmart contracts. In our previous research we described methodology and a tool\nto generate, in automated fashion, smart contracts from BPMN models. The\ngenerated smart contracts provide support for multi-step transactions that\nfacilitate repair/upgrade of smart contracts. In this paper we show how the\napproach is used to support collaborations via smart contracts for companies\nranging from SMEs with little IT capabilities to companies with IT using\nblockchain smart contracts. Furthermore, we also show how the approach is used\nfor certain applications to generate smart contracts by a BPMN modeler who does\nnot need any knowledge of blockchain technology or smart contract development -\nthus we are hoping to facilitate democratization of smart contracts and\nblockchain technology.",
    "pdf_url": "http://arxiv.org/pdf/2505.22619v1",
    "published": "2025-05-28T17:40:21+00:00",
    "categories": [
      "cs.SE",
      "cs.CR",
      "cs.DC"
    ],
    "primary_category": "cs.SE"
  },
  {
    "id": "http://arxiv.org/abs/2505.22701v1",
    "title": "Frequency-Adaptive Discrete Cosine-ViT-ResNet Architecture for Sparse-Data Vision",
    "authors": [
      "Ziyue Kang",
      "Weichuan Zhang"
    ],
    "abstract": "A major challenge in rare animal image classification is the scarcity of\ndata, as many species usually have only a small number of labeled samples.\n  To address this challenge, we designed a hybrid deep-learning framework\ncomprising a novel adaptive DCT preprocessing module, ViT-B16 and ResNet50\nbackbones, and a Bayesian linear classification head. To our knowledge, we are\nthe first to introduce an adaptive frequency-domain selection mechanism that\nlearns optimal low-, mid-, and high-frequency boundaries suited to the\nsubsequent backbones.\n  Our network first captures image frequency-domain cues via this adaptive DCT\npartitioning. The adaptively filtered frequency features are then fed into\nViT-B16 to model global contextual relationships, while ResNet50 concurrently\nextracts local, multi-scale spatial representations from the original image. A\ncross-level fusion strategy seamlessly integrates these frequency- and\nspatial-domain embeddings, and the fused features are passed through a Bayesian\nlinear classifier to output the final category predictions. On our self-built\n50-class wildlife dataset, this approach outperforms conventional CNN and\nfixed-band DCT pipelines, achieving state-of-the-art accuracy under extreme\nsample scarcity.",
    "pdf_url": "http://arxiv.org/pdf/2505.22701v1",
    "published": "2025-05-28T17:39:58+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.22618v3",
    "title": "Fast-dLLM: Training-free Acceleration of Diffusion LLM by Enabling KV Cache and Parallel Decoding",
    "authors": [
      "Chengyue Wu",
      "Hao Zhang",
      "Shuchen Xue",
      "Zhijian Liu",
      "Shizhe Diao",
      "Ligeng Zhu",
      "Ping Luo",
      "Song Han",
      "Enze Xie"
    ],
    "abstract": "Diffusion-based large language models (Diffusion LLMs) have shown promise for\nnon-autoregressive text generation with parallel decoding capabilities.\nHowever, the practical inference speed of open-sourced Diffusion LLMs often\nlags behind autoregressive models due to the lack of Key-Value (KV) Cache and\nquality degradation when decoding multiple tokens simultaneously. To bridge\nthis gap, we introduce a novel block-wise approximate KV Cache mechanism\ntailored for bidirectional diffusion models, enabling cache reuse with\nnegligible performance drop. Additionally, we identify the root cause of\ngeneration quality degradation in parallel decoding as the disruption of token\ndependencies under the conditional independence assumption. To address this, we\npropose a confidence-aware parallel decoding strategy that selectively decodes\ntokens exceeding a confidence threshold, mitigating dependency violations and\nmaintaining generation quality. Experimental results on LLaDA and Dream models\nacross multiple LLM benchmarks demonstrate up to \\textbf{27.6$\\times$\nthroughput} improvement with minimal accuracy loss, closing the performance gap\nwith autoregressive models and paving the way for practical deployment of\nDiffusion LLMs.",
    "pdf_url": "http://arxiv.org/pdf/2505.22618v3",
    "published": "2025-05-28T17:39:15+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.22617v1",
    "title": "The Entropy Mechanism of Reinforcement Learning for Reasoning Language Models",
    "authors": [
      "Ganqu Cui",
      "Yuchen Zhang",
      "Jiacheng Chen",
      "Lifan Yuan",
      "Zhi Wang",
      "Yuxin Zuo",
      "Haozhan Li",
      "Yuchen Fan",
      "Huayu Chen",
      "Weize Chen",
      "Zhiyuan Liu",
      "Hao Peng",
      "Lei Bai",
      "Wanli Ouyang",
      "Yu Cheng",
      "Bowen Zhou",
      "Ning Ding"
    ],
    "abstract": "This paper aims to overcome a major obstacle in scaling RL for reasoning with\nLLMs, namely the collapse of policy entropy. Such phenomenon is consistently\nobserved across vast RL runs without entropy intervention, where the policy\nentropy dropped sharply at the early training stage, this diminished\nexploratory ability is always accompanied with the saturation of policy\nperformance. In practice, we establish a transformation equation R=-a*e^H+b\nbetween entropy H and downstream performance R. This empirical law strongly\nindicates that, the policy performance is traded from policy entropy, thus\nbottlenecked by its exhaustion, and the ceiling is fully predictable H=0,\nR=-a+b. Our finding necessitates entropy management for continuous exploration\ntoward scaling compute for RL. To this end, we investigate entropy dynamics\nboth theoretically and empirically. Our derivation highlights that, the change\nin policy entropy is driven by the covariance between action probability and\nthe change in logits, which is proportional to its advantage when using Policy\nGradient-like algorithms. Empirical study shows that, the values of covariance\nterm and entropy differences matched exactly, supporting the theoretical\nconclusion. Moreover, the covariance term stays mostly positive throughout\ntraining, further explaining why policy entropy would decrease monotonically.\nThrough understanding the mechanism behind entropy dynamics, we motivate to\ncontrol entropy by restricting the update of high-covariance tokens.\nSpecifically, we propose two simple yet effective techniques, namely Clip-Cov\nand KL-Cov, which clip and apply KL penalty to tokens with high covariances\nrespectively. Experiments show that these methods encourage exploration, thus\nhelping policy escape entropy collapse and achieve better downstream\nperformance.",
    "pdf_url": "http://arxiv.org/pdf/2505.22617v1",
    "published": "2025-05-28T17:38:45+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.22616v1",
    "title": "PS4PRO: Pixel-to-pixel Supervision for Photorealistic Rendering and Optimization",
    "authors": [
      "Yezhi Shen",
      "Qiuchen Zhai",
      "Fengqing Zhu"
    ],
    "abstract": "Neural rendering methods have gained significant attention for their ability\nto reconstruct 3D scenes from 2D images. The core idea is to take multiple\nviews as input and optimize the reconstructed scene by minimizing the\nuncertainty in geometry and appearance across the views. However, the\nreconstruction quality is limited by the number of input views. This limitation\nis further pronounced in complex and dynamic scenes, where certain angles of\nobjects are never seen. In this paper, we propose to use video frame\ninterpolation as the data augmentation method for neural rendering.\nFurthermore, we design a lightweight yet high-quality video frame interpolation\nmodel, PS4PRO (Pixel-to-pixel Supervision for Photorealistic Rendering and\nOptimization). PS4PRO is trained on diverse video datasets, implicitly modeling\ncamera movement as well as real-world 3D geometry. Our model performs as an\nimplicit world prior, enriching the photo supervision for 3D reconstruction. By\nleveraging the proposed method, we effectively augment existing datasets for\nneural rendering methods. Our experimental results indicate that our method\nimproves the reconstruction performance on both static and dynamic scenes.",
    "pdf_url": "http://arxiv.org/pdf/2505.22616v1",
    "published": "2025-05-28T17:35:39+00:00",
    "categories": [
      "cs.CV",
      "eess.IV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.22615v1",
    "title": "The peculiar composition of the Sun is not related to giant planets",
    "authors": [
      "M. Carlos",
      "A. M. Amarsi",
      "P. E. Nissen",
      "G. Canocchi"
    ],
    "abstract": "Highly-differential spectroscopic studies have revealed that the Sun is\ndeficient in refractory elements relative to solar twins. To investigate the\nrole of giant planets on this signature, we present a high precision abundance\nanalysis of HARPS spectra for 50 F- and G-type stars spanning -0.4<[Fe/H]<+0.5.\nThere are 29 stars in the sample which host planets of masses > 0.01 MJup. We\nderive abundances for 19 elements, and apply corrections to 14 of them for\nsystematic errors associated with one dimensional (1D) model atmospheres, or\nthe assumption of local thermodynamic equilibrium (LTE), or both. We find that,\namong the solar twins in our sample, the Sun is Li poor in comparison to other\nstars at similar age, in agreement to previous studies. The sample shows a\nvariety of trends in elemental abundances as a function of condensation\ntemperature. We find a strong correlation in these trends with [Fe/H], with a\nmarginally-significant difference in the gradients for stars with and without\ngiants planets detected, that increases after applying 3D and non-LTE\ncorrections. Our overall results suggests that the peculiar composition of the\nSun is primarily related to Galactic chemical evolution rather than the\npresence of giant planets.",
    "pdf_url": "http://arxiv.org/pdf/2505.22615v1",
    "published": "2025-05-28T17:31:28+00:00",
    "categories": [
      "astro-ph.SR",
      "astro-ph.EP"
    ],
    "primary_category": "astro-ph.SR"
  },
  {
    "id": "http://arxiv.org/abs/2505.22614v2",
    "title": "Cosmological constraints on small-scale primordial non-Gaussianity",
    "authors": [
      "Jing-Zhi Zhou",
      "Zhi-Chao Li",
      "Di Wu"
    ],
    "abstract": "In contrast to the large-scale primordial power spectrum\n$\\mathcal{P}_{\\zeta}(k)$ and primordial non-Gaussianity $f_{\\mathrm{NL}}$,\nwhich are strictly constrained, the small-scale $\\mathcal{P}_{\\zeta}(k)$ and\n$f_{\\mathrm{NL}}$ remain less restricted. Considering local-type primordial\nnon-Gaussianity, we study the PBH and SIGW caused by large-amplitude\nsmall-scale primordial power spectrum. By analyzing current observational data\nfrom PTA, CMB, BAO, and abundance of PBH, and combining them with the SNR\nanalysis of LISA, we rigorously constrain the parameter space of\n$\\mathcal{P}_{\\zeta}(k)$ and $f_{\\mathrm{NL}}$. Furthermore, we examine the\neffects of different shapes of the primordial power spectrum on these\nconstraints and comprehensively calculate the Bayes factors for various models.\nOur results indicate that SIGW generated by a monochromatic primordial power\nspectrum are more likely to dominate current PTA observations, with the\ncorresponding constraint on the primordial non-Gaussian parameter being\n$-10.0<f_{\\mathrm{NL}}<1.2$.",
    "pdf_url": "http://arxiv.org/pdf/2505.22614v2",
    "published": "2025-05-28T17:30:00+00:00",
    "categories": [
      "astro-ph.CO",
      "gr-qc",
      "hep-ph",
      "hep-th"
    ],
    "primary_category": "astro-ph.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.22613v1",
    "title": "RICO: Improving Accuracy and Completeness in Image Recaptioning via Visual Reconstruction",
    "authors": [
      "Yuchi Wang",
      "Yishuo Cai",
      "Shuhuai Ren",
      "Sihan Yang",
      "Linli Yao",
      "Yuanxin Liu",
      "Yuanxing Zhang",
      "Pengfei Wan",
      "Xu Sun"
    ],
    "abstract": "Image recaptioning is widely used to generate training datasets with enhanced\nquality for various multimodal tasks. Existing recaptioning methods typically\nrely on powerful multimodal large language models (MLLMs) to enhance textual\ndescriptions, but often suffer from inaccuracies due to hallucinations and\nincompleteness caused by missing fine-grained details. To address these\nlimitations, we propose RICO, a novel framework that refines captions through\nvisual reconstruction. Specifically, we leverage a text-to-image model to\nreconstruct a caption into a reference image, and prompt an MLLM to identify\ndiscrepancies between the original and reconstructed images to refine the\ncaption. This process is performed iteratively, further progressively promoting\nthe generation of more faithful and comprehensive descriptions. To mitigate the\nadditional computational cost induced by the iterative process, we introduce\nRICO-Flash, which learns to generate captions like RICO using DPO. Extensive\nexperiments demonstrate that our approach significantly improves caption\naccuracy and completeness, outperforms most baselines by approximately 10% on\nboth CapsBench and CompreCap. Code released at\nhttps://github.com/wangyuchi369/RICO.",
    "pdf_url": "http://arxiv.org/pdf/2505.22613v1",
    "published": "2025-05-28T17:29:34+00:00",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.22612v1",
    "title": "BPMN to Smart Contract by Business Analyst",
    "authors": [
      "C. G. Liu",
      "P. Bodorik",
      "D. Jutla"
    ],
    "abstract": "This paper addresses the challenge of creating smart contracts for\napplications represented using Business Process Management and Notation (BPMN)\nmodels. In our prior work we presented a methodology that automates the\ngeneration of smart contracts from BPMN models. This approach abstracts the\nBPMN flow control, making it independent of the underlying blockchain\ninfrastructure, with only the BPMN task elements requiring coding. In\nsubsequent research, we enhanced our approach by adding support for nested\ntransactions and enabling a smart contract repair and/or upgrade. To empower\nBusiness Analysts (BAs) to generate smart contracts without relying on software\ndevelopers, we tackled the challenge of generating smart contracts from BPMN\nmodels without assistance of a software developer. We exploit the Decision\nModel and Notation (DMN) standard to represent the decisions and the business\nlogic of the BPMN task elements and amended our methodology for transformation\nof BPMN models into smart contracts to support also the generation script to\nrepresent the business logic represented by the DMN models. To support such\ntransformation, we describe how the BA documents, using the BPMN elements, the\nflow of information along with the flow of execution. Thus, if the BA is\nsuccessful in representing the blockchain application requirements using BPMN\nand DMN models, our methodology and the tool, called TABS, that we developed as\na proof of concept, is used to generate the smart contracts directly from those\nmodels without developer assistance.",
    "pdf_url": "http://arxiv.org/pdf/2505.22612v1",
    "published": "2025-05-28T17:28:38+00:00",
    "categories": [
      "cs.SE",
      "cs.CR"
    ],
    "primary_category": "cs.SE"
  },
  {
    "id": "http://arxiv.org/abs/2505.22611v1",
    "title": "Turbulent separation control with a tilted wavy wall: a promising approach for energy savings in aerodynamic systems",
    "authors": [
      "Piotr Kami≈Ñski",
      "Artur Tyliszczak",
      "Witold Elsner",
      "Pawe≈Ç Niegodajew"
    ],
    "abstract": "Recently, Kami\\'nski et al. [1] demonstrated that a two-dimensional\nstreamwise waviness with carefully selected amplitude and period can be\neffectively used in postponement of a flow separation at high Reynolds number\nwhich is out of reach for other commonly known passive flow control strategies.\nThis paper demonstrates that this approach can be substantially improved by\nintroducing a novel type of surface waviness characterized by tilting the\nsubsequent waves. The research is performed by applying the Large Eddy\nSimulation (LES) method allowing for a detailed analysis of both instantaneous\nand time-averaged flow characteristics. It is shown that the tilting eliminates\nthe occurrence of separation zones in waviness troughs, which minimizes the\nshape drag and maximizes the wall shear stress. In particular, compared to an\noptimal classical sinusoidal waviness shape the drag coefficient drops 14%.\nSimultaneously, 70% better performance in separation control is achieved.\nMoreover, it is also shown that when this issue is a priority, even further\nimprovement can be achieved, though at the expense of greater drag.",
    "pdf_url": "http://arxiv.org/pdf/2505.22611v1",
    "published": "2025-05-28T17:27:40+00:00",
    "categories": [
      "physics.flu-dyn"
    ],
    "primary_category": "physics.flu-dyn"
  },
  {
    "id": "http://arxiv.org/abs/2505.22610v1",
    "title": "TPDE: A Fast Adaptable Compiler Back-End Framework",
    "authors": [
      "Tobias Schwarz",
      "Tobias Kamm",
      "Alexis Engelke"
    ],
    "abstract": "Fast machine code generation is especially important for fast start-up\njust-in-time compilation, where the compilation time is part of the end-to-end\nlatency. However, widely used compiler frameworks like LLVM do not prioritize\nfast compilation and require an extra IR translation step increasing latency\neven further; and rolling a custom code generator is a substantial engineering\neffort, especially when targeting multiple architectures.\n  Therefore, in this paper, we present TPDE, a compiler back-end framework that\nadapts to existing code representations in SSA form. Using an IR-specific\nadapter providing canonical access to IR data structures and a specification of\nthe IR semantics, the framework performs one analysis pass and then performs\nthe compilation in just a single pass, combining instruction selection,\nregister allocation, and instruction encoding. The generated target\ninstructions are primarily derived code written in high-level language through\nLLVM's Machine IR, easing portability to different architectures while enabling\noptimizations during code generation.\n  To show the generality of our framework, we build a new back-end for LLVM\nfrom scratch targeting x86-64 and AArch64. Performance results on SPECint 2017\nshow that we can compile LLVM-IR 8--24x faster than LLVM -O0 while being on-par\nin terms of run-time performance. We also demonstrate the benefits of adapting\nto domain-specific IRs in JIT contexts, particularly WebAssembly and database\nquery compilation, where avoiding the extra IR translation further reduces\ncompilation latency.",
    "pdf_url": "http://arxiv.org/pdf/2505.22610v1",
    "published": "2025-05-28T17:25:53+00:00",
    "categories": [
      "cs.PL"
    ],
    "primary_category": "cs.PL"
  },
  {
    "id": "http://arxiv.org/abs/2505.22609v1",
    "title": "Chest Disease Detection In X-Ray Images Using Deep Learning Classification Method",
    "authors": [
      "Alanna Hazlett",
      "Naomi Ohashi",
      "Timothy Rodriguez",
      "Sodiq Adewole"
    ],
    "abstract": "In this work, we investigate the performance across multiple classification\nmodels to classify chest X-ray images into four categories of COVID-19,\npneumonia, tuberculosis (TB), and normal cases. We leveraged transfer learning\ntechniques with state-of-the-art pre-trained Convolutional Neural Networks\n(CNNs) models. We fine-tuned these pre-trained architectures on a labeled\nmedical x-ray images. The initial results are promising with high accuracy and\nstrong performance in key classification metrics such as precision, recall, and\nF1 score. We applied Gradient-weighted Class Activation Mapping (Grad-CAM) for\nmodel interpretability to provide visual explanations for classification\ndecisions, improving trust and transparency in clinical applications.",
    "pdf_url": "http://arxiv.org/pdf/2505.22609v1",
    "published": "2025-05-28T17:24:33+00:00",
    "categories": [
      "eess.IV",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "eess.IV"
  },
  {
    "id": "http://arxiv.org/abs/2505.22608v1",
    "title": "Effective and Efficient One-pass Compression of Speech Foundation Models Using Sparsity-aware Self-pinching Gates",
    "authors": [
      "Haoning Xu",
      "Zhaoqing Li",
      "Youjun Chen",
      "Huimeng Wang",
      "Guinan Li",
      "Mengzhe Geng",
      "Chengxi Deng",
      "Xunying Liu"
    ],
    "abstract": "This paper presents a novel approach for speech foundation models compression\nthat tightly integrates model pruning and parameter update into a single stage.\nHighly compact layer-level tied self-pinching gates each containing only a\nsingle learnable threshold are jointly trained with uncompressed models and\nused in fine-grained neuron level pruning. Experiments conducted on the\nLibriSpeech-100hr corpus suggest that our approach reduces the number of\nparameters of wav2vec2.0-base and HuBERT-large models by 65% and 60%\nrespectively, while incurring no statistically significant word error rate\n(WER) increase on the test-clean dataset. Compared to previously published\nmethods on the same task, our approach not only achieves the lowest WER of\n7.05% on the test-clean dataset under a comparable model compression ratio of\n4.26x, but also operates with at least 25% less model compression time.",
    "pdf_url": "http://arxiv.org/pdf/2505.22608v1",
    "published": "2025-05-28T17:24:21+00:00",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD"
  },
  {
    "id": "http://arxiv.org/abs/2505.22607v1",
    "title": "Collapse of the $ \\mathfrak{sl}_2 $-triple associated to the $ (k, a) $-generalized Fourier transform",
    "authors": [
      "Tatsuro Hikawa"
    ],
    "abstract": "Ben Sa\\\"id--Kobayashi--{\\O}rsted introduced a family of $ \\mathfrak{sl}_2\n$-triples of differential operators $ \\mathbb{H}_{k, a} $, $ \\mathbb{E}^+_{k,\na} $ and $ \\mathbb{E}^-_{k, a} $ on $ \\mathbb{R}^N \\setminus \\{0\\} $ indexed by\na Dunkl parameter $ k $ and a deformation parameter $ a \\neq 0 $. In the\npresent paper, we fix $ k = 0 $ and study the behavior as the parameter $ a $\napproaches $ 0 $. In this limit, the Lie algebra $ \\mathfrak{g}_a =\n\\operatorname{span}_{\\mathbb{R}} \\{\\mathbb{H}_a, \\mathbb{E}^+_a,\n\\mathbb{E}^-_a\\} \\cong \\mathfrak{sl}(2, \\mathbb{R}) $ degenerates into a\nthree-dimensional commutative Lie algebra $ \\mathfrak{g}_0 $, and its spectral\nproperties change. We describe the simultaneous spectral decomposition for $\n\\mathfrak{g}_0 $, and discuss formulas for operator semigroups with\ninfinitesimal generators in $ \\mathfrak{g}_0 $. In particular, we describe the\nintegral kernel of $ \\exp(z \\lvert x \\rvert^2 \\Delta) $ as an infinite series,\nwhich, in some low-dimensional cases, can be expressed in a closed form using\nthe theta function.",
    "pdf_url": "http://arxiv.org/pdf/2505.22607v1",
    "published": "2025-05-28T17:23:53+00:00",
    "categories": [
      "math.RT",
      "math.FA",
      "43A32, 22E45, 47D03"
    ],
    "primary_category": "math.RT"
  },
  {
    "id": "http://arxiv.org/abs/2505.22606v1",
    "title": "Dynamical Sweet and Sour Regions in Bichromatically Driven Floquet Qubits",
    "authors": [
      "D. Dominic Brise√±o-Colunga",
      "Bibek Bhandari",
      "Debmalya Das",
      "Long B. Nguyen",
      "Yosep Kim",
      "David I. Santiago",
      "Irfan Siddiqi",
      "Andrew N. Jordan",
      "Justin Dressel"
    ],
    "abstract": "Modern superconducting and semiconducting quantum hardware use external\ncharge and microwave flux drives to both tune and operate devices. However,\neach external drive is susceptible to low-frequency (e.g., $1/f$) noise that\ncan drastically reduce the decoherence lifetime of the device unless the drive\nis placed at specific operating points that minimize the sensitivity to\nfluctuations. We show that operating a qubit in a driven frame using two\nperiodic drives of distinct commensurate frequencies can have advantages over\nboth monochromatically driven frames and static frames with constant offset\ndrives. Employing Floquet theory, we analyze the spectral and lifetime\ncharacteristics of a two-level system under weak and strong bichromatic drives,\nidentifying drive-parameter regions with high coherence (sweet spots) and\nhighlighting regions where coherence is limited by additional sensitivity to\nnoise at the drive frequencies (sour spots). We present analytical expressions\nfor quasienergy gaps and dephasing rates, demonstrating that bichromatic\ndriving can alleviate the trade-off between DC and AC noise robustness observed\nin monochromatic drives. This approach reveals continuous manifolds of doubly\ndynamical sweet spots, along which drive parameters can be varied without\ncompromising coherence. Our results motivate further study of bichromatic\nFloquet engineering as a powerful strategy for maintaining tunability in\nhigh-coherence quantum systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.22606v1",
    "published": "2025-05-28T17:22:35+00:00",
    "categories": [
      "quant-ph",
      "cond-mat.mes-hall"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.22605v1",
    "title": "Transformers for Secure Hardware Systems: Applications, Challenges, and Outlook",
    "authors": [
      "Banafsheh Saber Latibari",
      "Najmeh Nazari",
      "Avesta Sasan",
      "Houman Homayoun",
      "Pratik Satam",
      "Soheil Salehi",
      "Hossein Sayadi"
    ],
    "abstract": "The rise of hardware-level security threats, such as side-channel attacks,\nhardware Trojans, and firmware vulnerabilities, demands advanced detection\nmechanisms that are more intelligent and adaptive. Traditional methods often\nfall short in addressing the complexity and evasiveness of modern attacks,\ndriving increased interest in machine learning-based solutions. Among these,\nTransformer models, widely recognized for their success in natural language\nprocessing and computer vision, have gained traction in the security domain due\nto their ability to model complex dependencies, offering enhanced capabilities\nin identifying vulnerabilities, detecting anomalies, and reinforcing system\nintegrity. This survey provides a comprehensive review of recent advancements\non the use of Transformers in hardware security, examining their application\nacross key areas such as side-channel analysis, hardware Trojan detection,\nvulnerability classification, device fingerprinting, and firmware security.\nFurthermore, we discuss the practical challenges of applying Transformers to\nsecure hardware systems, and highlight opportunities and future research\ndirections that position them as a foundation for next-generation\nhardware-assisted security. These insights pave the way for deeper integration\nof AI-driven techniques into hardware security frameworks, enabling more\nresilient and intelligent defenses.",
    "pdf_url": "http://arxiv.org/pdf/2505.22605v1",
    "published": "2025-05-28T17:22:14+00:00",
    "categories": [
      "cs.CR"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2506.00048v1",
    "title": "Graph Contrastive Learning for Optimizing Sparse Data in Recommender Systems with LightGCL",
    "authors": [
      "Aravinda Jatavallabha",
      "Prabhanjan Bharadwaj",
      "Ashish Chander"
    ],
    "abstract": "Graph Neural Networks (GNNs) are powerful tools for recommendation systems,\nbut they often struggle under data sparsity and noise. To address these issues,\nwe implemented LightGCL, a graph contrastive learning model that uses Singular\nValue Decomposition (SVD) for robust graph augmentation, preserving semantic\nintegrity without relying on stochastic or heuristic perturbations. LightGCL\nenables structural refinement and captures global collaborative signals,\nachieving significant gains over state-of-the-art models across benchmark\ndatasets. Our experiments also demonstrate improved fairness and resilience to\npopularity bias, making it well-suited for real-world recommender systems.",
    "pdf_url": "http://arxiv.org/pdf/2506.00048v1",
    "published": "2025-05-28T17:21:41+00:00",
    "categories": [
      "cs.IR",
      "cs.LG"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2505.22604v2",
    "title": "Adversarially Robust AI-Generated Image Detection for Free: An Information Theoretic Perspective",
    "authors": [
      "Ruixuan Zhang",
      "He Wang",
      "Zhengyu Zhao",
      "Zhiqing Guo",
      "Xun Yang",
      "Yunfeng Diao",
      "Meng Wang"
    ],
    "abstract": "Rapid advances in Artificial Intelligence Generated Images (AIGI) have\nfacilitated malicious use, such as forgery and misinformation. Therefore,\nnumerous methods have been proposed to detect fake images. Although such\ndetectors have been proven to be universally vulnerable to adversarial attacks,\ndefenses in this field are scarce. In this paper, we first identify that\nadversarial training (AT), widely regarded as the most effective defense,\nsuffers from performance collapse in AIGI detection. Through an\ninformation-theoretic lens, we further attribute the cause of collapse to\nfeature entanglement, which disrupts the preservation of feature-label mutual\ninformation. Instead, standard detectors show clear feature separation.\nMotivated by this difference, we propose Training-free Robust Detection via\nInformation-theoretic Measures (TRIM), the first training-free adversarial\ndefense for AIGI detection. TRIM builds on standard detectors and quantifies\nfeature shifts using prediction entropy and KL divergence. Extensive\nexperiments across multiple datasets and attacks validate the superiority of\nour TRIM, e.g., outperforming the state-of-the-art defense by 33.88% (28.91%)\non ProGAN (GenImage), while well maintaining original accuracy.",
    "pdf_url": "http://arxiv.org/pdf/2505.22604v2",
    "published": "2025-05-28T17:20:49+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.22603v1",
    "title": "Oscillating subalgebras of the atomless countable Boolean algebra",
    "authors": [
      "Dana Barto≈°ov√°",
      "David Chodounsk√Ω",
      "Barbara Csima",
      "Jan Hubiƒçka",
      "Matƒõj Koneƒçn√Ω",
      "Joey Lakerdas-Gayle",
      "Spencer Unger",
      "Andy Zucker"
    ],
    "abstract": "We show that the big Ramsey degree of the Boolean algebra with 3 atoms within\nthe countable atomless Boolean algebra is infinite.",
    "pdf_url": "http://arxiv.org/pdf/2505.22603v1",
    "published": "2025-05-28T17:17:39+00:00",
    "categories": [
      "math.LO",
      "cs.DM",
      "math.CO",
      "05C55, 06E05, 03E02, 05D10",
      "G.2.1"
    ],
    "primary_category": "math.LO"
  },
  {
    "id": "http://arxiv.org/abs/2505.22602v1",
    "title": "One Rank at a Time: Cascading Error Dynamics in Sequential Learning",
    "authors": [
      "Mahtab Alizadeh Vandchali",
      "Fangshuo",
      "Liao",
      "Anastasios Kyrillidis"
    ],
    "abstract": "Sequential learning -- where complex tasks are broken down into simpler,\nhierarchical components -- has emerged as a paradigm in AI. This paper views\nsequential learning through the lens of low-rank linear regression, focusing\nspecifically on how errors propagate when learning rank-1 subspaces\nsequentially. We present an analysis framework that decomposes the learning\nprocess into a series of rank-1 estimation problems, where each subsequent\nestimation depends on the accuracy of previous steps. Our contribution is a\ncharacterization of the error propagation in this sequential process,\nestablishing bounds on how errors -- e.g., due to limited computational budgets\nand finite precision -- affect the overall model accuracy. We prove that these\nerrors compound in predictable ways, with implications for both algorithmic\ndesign and stability guarantees.",
    "pdf_url": "http://arxiv.org/pdf/2505.22602v1",
    "published": "2025-05-28T17:16:24+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.OC"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.22601v1",
    "title": "Machine Unlearning under Overparameterization",
    "authors": [
      "Jacob L. Block",
      "Aryan Mokhtari",
      "Sanjay Shakkottai"
    ],
    "abstract": "Machine unlearning algorithms aim to remove the influence of specific\ntraining samples, ideally recovering the model that would have resulted from\ntraining on the remaining data alone. We study unlearning in the\noverparameterized setting, where many models interpolate the data, and defining\nthe unlearning solution as any loss minimizer over the retained\nset$\\unicode{x2013}$as in prior work in the underparameterized\nsetting$\\unicode{x2013}$is inadequate, since the original model may already\ninterpolate the retained data and satisfy this condition. In this regime, loss\ngradients vanish, rendering prior methods based on gradient perturbations\nineffective, motivating both new unlearning definitions and algorithms. For\nthis setting, we define the unlearning solution as the minimum-complexity\ninterpolator over the retained data and propose a new algorithmic framework\nthat only requires access to model gradients on the retained set at the\noriginal solution. We minimize a regularized objective over perturbations\nconstrained to be orthogonal to these model gradients, a first-order relaxation\nof the interpolation condition. For different model classes, we provide exact\nand approximate unlearning guarantees, and we demonstrate that an\nimplementation of our framework outperforms existing baselines across various\nunlearning experiments.",
    "pdf_url": "http://arxiv.org/pdf/2505.22601v1",
    "published": "2025-05-28T17:14:57+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.22600v1",
    "title": "Dust Budget Crisis in Little Red Dots",
    "authors": [
      "Kejian Chen",
      "Zhengrong Li",
      "Kohei Inayoshi",
      "Luis C. Ho"
    ],
    "abstract": "Little red dots (LRDs), a population of active galactic nuclei (AGNs)\nrecently identified by JWST, are characterized by their compact morphology and\nred optical continuum emission, which is often interpreted as evidence for\nsignificant dust extinction of $A_V \\gtrsim 3$ mag. However, the dust-reddened\nAGN scenario is increasingly challenged by their faint near-to-far infrared\nemission and a potential \"dust budget crisis\" in cases when the host galaxy is\neither undetectably low-mass or absent. In this study, we re-evaluate the dust\nextinction level in LRDs by modeling the UV-to-infrared spectra for various\nextinction laws and a broad range of dusty distribution parameters. Comparing\nthe predicted infrared fluxes with observational data from the JWST MIRI,\nHerschel, and ALMA, our analysis finds that the visual extinction is tightly\nconstrained to $A_V \\lesssim 1.0$ mag for A2744-45924 and $A_V \\lesssim 1.5$\nmag for RUBIES-BLAGN-1 under the SMC extinction laws, with slightly weaker\nconstraints for those with gray extinction in the UV range. The revised $A_V$\nvalues yield a radiative efficiencies of $10\\%$ for the LRD population, easing\nthe tension with the Soltan argument for the bulk AGN population at lower\nredshifts. Moreover, this moderate extinction (or dust-free) scenario, with\nreprocessed emission spectra testable by future far-infrared observatories,\nprovides a paradigm shift in understanding their natures, environments, and\nevolutionary pathways of massive black holes in the early universe.",
    "pdf_url": "http://arxiv.org/pdf/2505.22600v1",
    "published": "2025-05-28T17:14:52+00:00",
    "categories": [
      "astro-ph.GA",
      "astro-ph.CO"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2505.22599v1",
    "title": "VR-Based Control of Multi-Copter Operation",
    "authors": [
      "Jack T. Hughes",
      "Mohammad Ghufran",
      "Hossein Rastgoftar"
    ],
    "abstract": "We aim to use virtual reality (VR) to improve the spatial awareness of pilots\nby real-time scanning of the environment around the drone using onboard\nsensors, live streaming of this environment to a VR headset, and rendering a\nvirtual representation of the drone and its environment for the pilot. This\nway, the pilot can see the immediate environment of the drone up close from a\nthird-person perspective, as opposed to the first-person perspective that most\ndrone cameras provide. This provides much more information about the drone\nsurroundings for the pilot while operating the drone than existing\nteleoperation solutions. Previous solutions using VR have relied upon pre-made\ndesigns of the environment, which makes it difficult to adapt to changing\nenvironments. Our solution, in contrast, scans the environment as you fly,\nmaking it much more flexible for use in unknown environments.",
    "pdf_url": "http://arxiv.org/pdf/2505.22599v1",
    "published": "2025-05-28T17:14:30+00:00",
    "categories": [
      "cs.RO"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.22598v3",
    "title": "On the performance of machine-learning-assisted Monte Carlo in sampling from simple statistical physics models",
    "authors": [
      "Luca Maria Del Bono",
      "Federico Ricci-Tersenghi",
      "Francesco Zamponi"
    ],
    "abstract": "Recent years have seen a rise in the application of machine learning\ntechniques to aid the simulation of hard-to-sample systems that cannot be\nstudied using traditional methods. Despite the introduction of many different\narchitectures and procedures, a wide theoretical understanding is still\nlacking, with the risk of suboptimal implementations. As a first step to\naddress this gap, we provide here a complete analytic study of the widely-used\nSequential Tempering procedure applied to a shallow MADE architecture for the\nCurie-Weiss model. The contribution of this work is twofold: firstly, we give a\ndescription of the optimal weights and of the training under Gradient Descent\noptimization. Secondly, we compare what happens in Sequential Tempering with\nand without the addition of local Metropolis Monte Carlo steps. We are thus\nable to give theoretical predictions on the best procedure to apply in this\ncase. This work establishes a clear theoretical basis for the integration of\nmachine learning techniques into Monte Carlo sampling and optimization.",
    "pdf_url": "http://arxiv.org/pdf/2505.22598v3",
    "published": "2025-05-28T17:13:11+00:00",
    "categories": [
      "cond-mat.dis-nn",
      "cond-mat.stat-mech",
      "cs.AI",
      "cs.LG",
      "physics.comp-ph"
    ],
    "primary_category": "cond-mat.dis-nn"
  },
  {
    "id": "http://arxiv.org/abs/2505.22597v1",
    "title": "HDDLGym: A Tool for Studying Multi-Agent Hierarchical Problems Defined in HDDL with OpenAI Gym",
    "authors": [
      "Ngoc La",
      "Ruaridh Mon-Williams",
      "Julie A. Shah"
    ],
    "abstract": "In recent years, reinforcement learning (RL) methods have been widely tested\nusing tools like OpenAI Gym, though many tasks in these environments could also\nbenefit from hierarchical planning. However, there is a lack of a tool that\nenables seamless integration of hierarchical planning with RL. Hierarchical\nDomain Definition Language (HDDL), used in classical planning, introduces a\nstructured approach well-suited for model-based RL to address this gap. To\nbridge this integration, we introduce HDDLGym, a Python-based tool that\nautomatically generates OpenAI Gym environments from HDDL domains and problems.\nHDDLGym serves as a link between RL and hierarchical planning, supporting\nmulti-agent scenarios and enabling collaborative planning among agents. This\npaper provides an overview of HDDLGym's design and implementation, highlighting\nthe challenges and design choices involved in integrating HDDL with the Gym\ninterface, and applying RL policies to support hierarchical planning. We also\nprovide detailed instructions and demonstrations for using the HDDLGym\nframework, including how to work with existing HDDL domains and problems from\nInternational Planning Competitions, exemplified by the Transport domain.\nAdditionally, we offer guidance on creating new HDDL domains for multi-agent\nscenarios and demonstrate the practical use of HDDLGym in the Overcooked\ndomain. By leveraging the advantages of HDDL and Gym, HDDLGym aims to be a\nvaluable tool for studying RL in hierarchical planning, particularly in\nmulti-agent contexts.",
    "pdf_url": "http://arxiv.org/pdf/2505.22597v1",
    "published": "2025-05-28T17:10:43+00:00",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.MA"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.22596v1",
    "title": "SAM-R1: Leveraging SAM for Reward Feedback in Multimodal Segmentation via Reinforcement Learning",
    "authors": [
      "Jiaqi Huang",
      "Zunnan Xu",
      "Jun Zhou",
      "Ting Liu",
      "Yicheng Xiao",
      "Mingwen Ou",
      "Bowen Ji",
      "Xiu Li",
      "Kehong Yuan"
    ],
    "abstract": "Leveraging multimodal large models for image segmentation has become a\nprominent research direction. However, existing approaches typically rely\nheavily on manually annotated datasets that include explicit reasoning\nprocesses, which are costly and time-consuming to produce. Recent advances\nsuggest that reinforcement learning (RL) can endow large models with reasoning\ncapabilities without requiring such reasoning-annotated data. In this paper, we\npropose SAM-R1, a novel framework that enables multimodal large models to\nperform fine-grained reasoning in image understanding tasks. Our approach is\nthe first to incorporate fine-grained segmentation settings during the training\nof multimodal reasoning models. By integrating task-specific, fine-grained\nrewards with a tailored optimization objective, we further enhance the model's\nreasoning and segmentation alignment. We also leverage the Segment Anything\nModel (SAM) as a strong and flexible reward provider to guide the learning\nprocess. With only 3k training samples, SAM-R1 achieves strong performance\nacross multiple benchmarks, demonstrating the effectiveness of reinforcement\nlearning in equipping multimodal models with segmentation-oriented reasoning\ncapabilities.",
    "pdf_url": "http://arxiv.org/pdf/2505.22596v1",
    "published": "2025-05-28T17:08:28+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.22595v1",
    "title": "Off-shell form factor: factorization is violated",
    "authors": [
      "A. V. Belitsky",
      "V. A. Smirnov"
    ],
    "abstract": "We study the Sudakov form factor on the Coulomb branch of N=4 sYM, which\nendows only external states with masses, and implies that the former is\noff-shell in the traditional sense. Our consideration is performed at\nthree-loop order in the near mass-shell limit. We use a combination of tools to\nperform required calculations centered around the Method of Regions as the main\ngo-to formalism for the asymptotic expansion of emerging parametric Feynman\nintegrals. Explicit separation of quantum loops in terms of hard, collinear,\nand ultrasoft modes allows us to explore the factorization properties of this\ninfrared-sensitive quantity. While the hard region is cleanly separated from\nthe rest, the ultrasoft-collinear modes remain intertwined. We exhibit effects\nof factorization violation explicitly in the momentum space making use of the\ninfrared power counting.",
    "pdf_url": "http://arxiv.org/pdf/2505.22595v1",
    "published": "2025-05-28T17:07:01+00:00",
    "categories": [
      "hep-th",
      "hep-ph"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2505.22594v2",
    "title": "Multi-Environment GLAMP: Approximate Message Passing for Transfer Learning with Applications to Lasso-based Estimators",
    "authors": [
      "Longlin Wang",
      "Yanke Song",
      "Kuanhao Jiang",
      "Pragya Sur"
    ],
    "abstract": "Approximate Message Passing (AMP) algorithms enable precise characterization\nof certain classes of random objects in the high-dimensional limit, and have\nfound widespread applications in fields such as signal processing, statistics,\nand communications. In this work, we introduce Multi-Environment Generalized\nLong AMP, a novel AMP framework that applies to transfer learning problems with\nmultiple data sources and distribution shifts. We rigorously establish state\nevolution for multi-environment GLAMP. We demonstrate the utility of this\nframework by precisely characterizing the risk of three Lasso-based transfer\nlearning estimators for the first time: the Stacked Lasso, the Model Averaging\nEstimator, and the Second Step Estimator. We also demonstrate the remarkable\nfinite sample accuracy of our theory via extensive simulations.",
    "pdf_url": "http://arxiv.org/pdf/2505.22594v2",
    "published": "2025-05-28T17:05:09+00:00",
    "categories": [
      "math.ST",
      "stat.ML",
      "stat.TH"
    ],
    "primary_category": "math.ST"
  },
  {
    "id": "http://arxiv.org/abs/2505.22593v1",
    "title": "Special anisotropic conformal changes of conic pseudo-Finsler surfaces",
    "authors": [
      "Nabil L. Youssef",
      "Ebtsam H. Taha",
      "A. A. Kotb",
      "S. G. Elgendi"
    ],
    "abstract": "This study presents many special anisotropic conformal changes of a conic\npseudo-Finsler surface $(M,F)$, such as $C$-anisotropic and horizontal\n$C$-anisotropic conformal transformations, which reduce to $C$-conformal when\nthe conformal factor is solely position-dependent. Furthermore, we present\nvertical $C$-anisotropic conformal changes and demonstrate that they are\ncharacterized by the property of $(M,F)$ being Riemannian. Additionally, we\nexamine the anisotropic conformal transformation that fulfils the $\\phi\nT$-condition, the horizontal $\\phi T$-condition, and the vertical $\\phi\nT$-condition. The first two conditions reduce to the $\\boldsymbol{\\sigma}\nT$-condition when the conformal factor relies solely on a positional variable.\nWe demonstrate that, under the vertical $\\phi T$-condition change, every\nLandsberg surface is Berwaldian. Thus, the vertical $\\phi T$-condition is\nequivalent to the $T$-condition. Furthermore, we examine the scenario when the\nanisotropic conformal factor becomes the main scalar of the non-Riemannian\nsurface $(M,F)$. We present an example of a Finslerian Schwarzschild-de Sitter\nsolution having Finslerian spherical symmetry and apply our results to it.",
    "pdf_url": "http://arxiv.org/pdf/2505.22593v1",
    "published": "2025-05-28T17:04:48+00:00",
    "categories": [
      "math.DG",
      "53B40, 53C60"
    ],
    "primary_category": "math.DG"
  },
  {
    "id": "http://arxiv.org/abs/2505.22592v1",
    "title": "Comparative Analysis of Machine Learning Models for Lung Cancer Mutation Detection and Staging Using 3D CT Scans",
    "authors": [
      "Yiheng Li",
      "Francisco Carrillo-Perez",
      "Mohammed Alawad",
      "Olivier Gevaert"
    ],
    "abstract": "Lung cancer is the leading cause of cancer mortality worldwide, and\nnon-invasive methods for detecting key mutations and staging are essential for\nimproving patient outcomes. Here, we compare the performance of two machine\nlearning models - FMCIB+XGBoost, a supervised model with domain-specific\npretraining, and Dinov2+ABMIL, a self-supervised model with attention-based\nmultiple-instance learning - on 3D lung nodule data from the Stanford\nRadiogenomics and Lung-CT-PT-Dx cohorts. In the task of KRAS and EGFR mutation\ndetection, FMCIB+XGBoost consistently outperformed Dinov2+ABMIL, achieving\naccuracies of 0.846 and 0.883 for KRAS and EGFR mutations, respectively. In\ncancer staging, Dinov2+ABMIL demonstrated competitive generalization, achieving\nan accuracy of 0.797 for T-stage prediction in the Lung-CT-PT-Dx cohort,\nsuggesting SSL's adaptability across diverse datasets. Our results emphasize\nthe clinical utility of supervised models in mutation detection and highlight\nthe potential of SSL to improve staging generalization, while identifying areas\nfor enhancement in mutation sensitivity.",
    "pdf_url": "http://arxiv.org/pdf/2505.22592v1",
    "published": "2025-05-28T17:04:35+00:00",
    "categories": [
      "eess.IV",
      "cs.CV"
    ],
    "primary_category": "eess.IV"
  },
  {
    "id": "http://arxiv.org/abs/2505.22591v1",
    "title": "Self-Error-Instruct: Generalizing from Errors for LLMs Mathematical Reasoning",
    "authors": [
      "Erxin Yu",
      "Jing Li",
      "Ming Liao",
      "Qi Zhu",
      "Boyang Xue",
      "Minghui Xu",
      "Baojun Wang",
      "Lanqing Hong",
      "Fei Mi",
      "Lifeng Shang"
    ],
    "abstract": "Although large language models demonstrate strong performance across various\ndomains, they still struggle with numerous bad cases in mathematical reasoning.\nPrevious approaches to learning from errors synthesize training data by solely\nextrapolating from isolated bad cases, thereby failing to generalize the\nextensive patterns inherent within these cases. This paper presents\nSelf-Error-Instruct (SEI), a framework that addresses these model weaknesses\nand synthesizes more generalized targeted training data. Specifically, we\nexplore a target model on two mathematical datasets, GSM8K and MATH, to\npinpoint bad cases. Then, we generate error keyphrases for these cases based on\nthe instructor model's (GPT-4o) analysis and identify error types by clustering\nthese keyphrases. Next, we sample a few bad cases during each generation for\neach identified error type and input them into the instructor model, which\nsynthesizes additional training data using a self-instruct approach. This new\ndata is refined through a one-shot learning process to ensure that only the\nmost effective examples are kept. Finally, we use these curated data to\nfine-tune the target model, iteratively repeating the process to enhance\nperformance. We apply our framework to various models and observe improvements\nin their reasoning abilities across both in-domain and out-of-domain\nmathematics datasets. These results demonstrate the effectiveness of self-error\ninstruction in improving LLMs' mathematical reasoning through error\ngeneralization.",
    "pdf_url": "http://arxiv.org/pdf/2505.22591v1",
    "published": "2025-05-28T17:02:47+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.23845v1",
    "title": "Read Your Own Mind: Reasoning Helps Surface Self-Confidence Signals in LLMs",
    "authors": [
      "Jakub Podolak",
      "Rajeev Verma"
    ],
    "abstract": "We study the source of uncertainty in DeepSeek R1-32B by analyzing its\nself-reported verbal confidence on question answering (QA) tasks. In the\ndefault answer-then-confidence setting, the model is regularly over-confident,\nwhereas semantic entropy - obtained by sampling many responses - remains\nreliable. We hypothesize that this is because of semantic entropy's larger\ntest-time compute, which lets us explore the model's predictive distribution.\nWe show that granting DeepSeek the budget to explore its distribution by\nforcing a long chain-of-thought before the final answer greatly improves its\nverbal score effectiveness, even on simple fact-retrieval questions that\nnormally require no reasoning. Furthermore, a separate reader model that sees\nonly the chain can reconstruct very similar confidences, indicating the verbal\nscore might be merely a statistic of the alternatives surfaced during\nreasoning. Our analysis concludes that reliable uncertainty estimation requires\nexplicit exploration of the generative space, and self-reported confidence is\ntrustworthy only after such exploration.",
    "pdf_url": "http://arxiv.org/pdf/2505.23845v1",
    "published": "2025-05-28T17:01:30+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.22590v1",
    "title": "Local well-posedness of the initial value problem in Einstein-Cartan theory",
    "authors": [
      "Paulo Luz",
      "Filipe C. Mena"
    ],
    "abstract": "We study the initial value problem in Einstein-Cartan theory which includes\ntorsion and, therefore, a non-symmetric connection on the spacetime manifold.\nGeneralizing the path of a classical theorem by Choquet-Bruhat and York for the\nEinstein equations, we use a $n+1$ splitting of the manifold and compute the\nevolution and constraint equations for the Einstein-Cartan system. In the\nprocess, we derive the Gauss-Codazzi-Ricci equations including torsion. We\nprove that the constraint equations are preserved during evolution. Imposing a\ngeneralized harmonic gauge, it is shown that the evolution equations can be\ncast as a quasilinear system in a Cauchy regular form with a characteristic\ndeterminant having a non-trivial multiplicity of characteristics. Using the\nLeray-Ohya theory for non-strictly hyperbolic systems we then establish the\nlocal geometric well-posedness of the Cauchy problem, for sufficiently regular\ninitial data. For vanishing torsion we recover the classical results for the\nEinstein equations.",
    "pdf_url": "http://arxiv.org/pdf/2505.22590v1",
    "published": "2025-05-28T17:00:04+00:00",
    "categories": [
      "gr-qc"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2505.22589v2",
    "title": "On dual regime in Yang-Baxter deformed $\\mathrm{O}(2N)$ sigma models",
    "authors": [
      "Alexey Bychkov",
      "Alexey Litvinov"
    ],
    "abstract": "In this paper, we explore a new class of integrable sigma models, which we\nrefer to as the \"dual regime\" of Yang-Baxter (YB) deformed $\\mathrm{O}(2N)$\nsigma models. This dual regime manifests itself in the conformal perturbation\napproach. Namely, it is well known that conventional YB-deformed\n$\\mathrm{O}(N)$ sigma models are described in the UV by a collection of free\nbosonic fields perturbed by some relevant operators. The holomorphic parts of\nthese operators play the role of screening operators which define certain\nintegrable systems in the free theory. All of these integrable systems depend\non a continuous parameter $b$, which parametrizes the central charge, and are\nknown to possess the duality under $b^2\\longleftrightarrow -1-b^2$. Although\n$\\mathrm{O}(2N+1)$ integrable systems are self-dual, $\\mathrm{O}(2N)$ systems\nare not. In particular, the $\\mathrm{O}(2N)$ integrable systems provide new\nperturbations of the sigma model type. We identify the corresponding one-loop\nmetric and $B-$field and show that they solve the generalized Ricci flow\nequation.",
    "pdf_url": "http://arxiv.org/pdf/2505.22589v2",
    "published": "2025-05-28T16:59:24+00:00",
    "categories": [
      "hep-th",
      "math-ph",
      "math.MP"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2505.22588v1",
    "title": "Overpartitions and Kaur, Rana, and Eyyunni's mex sequences",
    "authors": [
      "Brian Hopkins",
      "James A. Sellers"
    ],
    "abstract": "Kaur, Rana, and Eyyunni recently defined the mex sequence of a partition and\nestablished, by analytic methods, connections to two disparate types of\npartition-related objects. We make a bijection between partitions with certain\nmex sequences and a uniform family of overpartitions which allows us to provide\ncombinatorial proofs of their results, as they requested.",
    "pdf_url": "http://arxiv.org/pdf/2505.22588v1",
    "published": "2025-05-28T16:59:17+00:00",
    "categories": [
      "math.CO",
      "math.NT",
      "05A17 (primary) 11P81 (secondary)"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.22587v1",
    "title": "Bayesian Non-Parametric Inference for L√©vy Measures in State-Space Models",
    "authors": [
      "Bill Z. Lin",
      "Simon Godsill"
    ],
    "abstract": "L\\'evy processes, known for their ability to model complex dynamics with\nskewness, heavy tails and discontinuities, play a critical role in stochastic\nmodeling across various domains. However, inference for most L\\'evy processes,\nwhether in parametric or non-parametric settings, remains a significant\nchallenge. In this work, we present a novel Bayesian non-parametric inference\nframework for inferring the L\\'evy measures of subordinators and normal\nvariance-mean (NVM) processes within a linear L\\'evy state space model, a setup\nthat significantly extends existing methodologies. We employ the Dirichlet\nprocess which further results in a Student-t mixture representation to enable\ninference for the L\\'evy measures. An efficient augmented Markov Chain Monte\nCarlo algorithm is developed for this problem that ensures both accuracy and\ncomputational feasibility. The effectiveness of the method is demonstrated on\nsynthetic and tick-level (high-frequency) financial datasets, and we show the\npractical utility of the inference results using the forecasting performance.",
    "pdf_url": "http://arxiv.org/pdf/2505.22587v1",
    "published": "2025-05-28T16:59:09+00:00",
    "categories": [
      "stat.ME"
    ],
    "primary_category": "stat.ME"
  },
  {
    "id": "http://arxiv.org/abs/2505.22586v1",
    "title": "Precise In-Parameter Concept Erasure in Large Language Models",
    "authors": [
      "Yoav Gur-Arieh",
      "Clara Suslik",
      "Yihuai Hong",
      "Fazl Barez",
      "Mor Geva"
    ],
    "abstract": "Large language models (LLMs) often acquire knowledge during pretraining that\nis undesirable in downstream deployments, e.g., sensitive information or\ncopyrighted content. Existing approaches for removing such knowledge rely on\nfine-tuning, training low-rank adapters or fact-level editing, but these are\neither too coarse, too shallow, or ineffective. In this work, we propose PISCES\n(Precise In-parameter Suppression for Concept EraSure), a novel framework for\nprecisely erasing entire concepts from model parameters by directly editing\ndirections that encode them in parameter space. PISCES uses a disentangler\nmodel to decompose MLP vectors into interpretable features, identifies those\nassociated with a target concept using automated interpretability techniques,\nand removes them from model parameters. Experiments on Gemma 2 and Llama 3.1\nover various concepts show that PISCES achieves modest gains in efficacy over\nleading erasure methods, reducing accuracy on the target concept to as low as\n7.7%, while dramatically improving erasure specificity (by up to 31%) and\nrobustness (by up to 38%). Overall, these results demonstrate that\nfeature-based in-parameter editing enables a more precise and reliable approach\nfor removing conceptual knowledge in language models.",
    "pdf_url": "http://arxiv.org/pdf/2505.22586v1",
    "published": "2025-05-28T16:58:23+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.22585v1",
    "title": "A recursive method for computing singular solutions in corners with homogeneous Dirichlet-Robin boundary condition with power-law coefficient variation",
    "authors": [
      "N. Pi√±a-Le√≥n",
      "V. Mantiƒç",
      "S. Jim√©nez-Alfaro"
    ],
    "abstract": "This study introduces a recursive method for computing asymptotic solutions\nof the Laplace equation in corner domains with the homogeneous Dirichlet\nboundary condition on one side and the Robin boundary condition with a\npower-law coefficient variation with exponent $\\alpha\\in \\mathbb{R}$ on the\nother side (D-R corner problem). An asymptotic solution of this D-R corner\nproblem is given as the sum of a main term, the solution of either a\nhomogeneous Dirichlet-Neumann (D-N) or Dirichlet-Dirichlet (D-D) corner\nproblem, and a finite or infinite series of the associated higher-order shadow\nterms by using harmonic basis functions with power-logarithmic terms. To\ndetermine this series of shadow terms, it is shown that the recursive\nprocedures based on recursive non-homogeneous D-N or D-D corner problems are\nalways convergent for $\\alpha > -1$ or $\\alpha < -1$, respectively. For the\ncritical case $\\alpha=-1$, the closed form expression of the asymptotic\nsolution is given. Asymptotic solutions for several relevant D-R corner\nproblems are derived and analysed. Two of these examples are applied to the\nproblem of bridged cracks in antiplane Mode III in linear elastic fracture\nmechanics. The results presented can be applied to many other physical and\nengineering applications, such as heat transfer with the thermal resistance\ncondition, acoustics and electrostatics with the impedance condition, and\nelasticity and structural analysis with the Winkler spring boundary condition.",
    "pdf_url": "http://arxiv.org/pdf/2505.22585v1",
    "published": "2025-05-28T16:58:19+00:00",
    "categories": [
      "math.AP"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2505.22584v1",
    "title": "DocReRank: Single-Page Hard Negative Query Generation for Training Multi-Modal RAG Rerankers",
    "authors": [
      "Navve Wasserman",
      "Oliver Heinimann",
      "Yuval Golbari",
      "Tal Zimbalist",
      "Eli Schwartz",
      "Michal Irani"
    ],
    "abstract": "Rerankers play a critical role in multimodal Retrieval-Augmented Generation\n(RAG) by refining ranking of an initial set of retrieved documents. Rerankers\nare typically trained using hard negative mining, whose goal is to select pages\nfor each query which rank high, but are actually irrelevant. However, this\nselection process is typically passive and restricted to what the retriever can\nfind in the available corpus, leading to several inherent limitations. These\ninclude: limited diversity, negative examples which are often not hard enough,\nlow controllability, and frequent false negatives which harm training. Our\npaper proposes an alternative approach: Single-Page Hard Negative Query\nGeneration, which goes the other way around. Instead of retrieving negative\npages per query, we generate hard negative queries per page. Using an automated\nLLM-VLM pipeline, and given a page and its positive query, we create hard\nnegatives by rephrasing the query to be as similar as possible in form and\ncontext, yet not answerable from the page. This paradigm enables fine-grained\ncontrol over the generated queries, resulting in diverse, hard, and targeted\nnegatives. It also supports efficient false negative verification. Our\nexperiments show that rerankers trained with data generated using our approach\noutperform existing models and significantly improve retrieval performance.",
    "pdf_url": "http://arxiv.org/pdf/2505.22584v1",
    "published": "2025-05-28T16:56:41+00:00",
    "categories": [
      "cs.IR"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2505.22583v1",
    "title": "GitGoodBench: A Novel Benchmark For Evaluating Agentic Performance On Git",
    "authors": [
      "Tobias Lindenbauer",
      "Egor Bogomolov",
      "Yaroslav Zharov"
    ],
    "abstract": "Benchmarks for Software Engineering (SE) AI agents, most notably SWE-bench,\nhave catalyzed progress in programming capabilities of AI agents. However, they\noverlook critical developer workflows such as Version Control System (VCS)\noperations. To address this issue, we present GitGoodBench, a novel benchmark\nfor evaluating AI agent performance on VCS tasks. GitGoodBench covers three\ncore Git scenarios extracted from permissive open-source Python, Java, and\nKotlin repositories. Our benchmark provides three datasets: a comprehensive\nevaluation suite (900 samples), a rapid prototyping version (120 samples), and\na training corpus (17,469 samples). We establish baseline performance on the\nprototyping version of our benchmark using GPT-4o equipped with custom tools,\nachieving a 21.11% solve rate overall. We expect GitGoodBench to serve as a\ncrucial stepping stone toward truly comprehensive SE agents that go beyond mere\nprogramming.",
    "pdf_url": "http://arxiv.org/pdf/2505.22583v1",
    "published": "2025-05-28T16:56:11+00:00",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE"
  },
  {
    "id": "http://arxiv.org/abs/2505.22582v1",
    "title": "Less, but Better: Efficient Multilingual Expansion for LLMs via Layer-wise Mixture-of-Experts",
    "authors": [
      "Xue Zhang",
      "Yunlong Liang",
      "Fandong Meng",
      "Songming Zhang",
      "Yufeng Chen",
      "Jinan Xu",
      "Jie Zhou"
    ],
    "abstract": "Continually expanding new languages for existing large language models (LLMs)\nis a promising yet challenging approach to building powerful multilingual LLMs.\nThe biggest challenge is to make the model continuously learn new languages\nwhile preserving the proficient ability of old languages. To achieve this,\nrecent work utilizes the Mixture-of-Experts (MoE) architecture to expand new\nlanguages by adding new experts and avoid catastrophic forgetting of old\nlanguages by routing corresponding tokens to the original model backbone (old\nexperts). Although intuitive, this kind of method is parameter-costly when\nexpanding new languages and still inevitably impacts the performance of old\nlanguages. To address these limitations, we analyze the language\ncharacteristics of different layers in LLMs and propose a layer-wise expert\nallocation algorithm (LayerMoE) to determine the appropriate number of new\nexperts for each layer. Specifically, we find different layers in LLMs exhibit\ndifferent representation similarities between languages and then utilize the\nsimilarity as the indicator to allocate experts for each layer, i.e., the\nhigher similarity, the fewer experts. Additionally, to further mitigate the\nforgetting of old languages, we add a classifier in front of the router network\non the layers with higher similarity to guide the routing of old language\ntokens. Experimental results show that our method outperforms the previous\nstate-of-the-art baseline with 60% fewer experts in the single-expansion\nsetting and with 33.3% fewer experts in the lifelong-expansion setting,\ndemonstrating the effectiveness of our method.",
    "pdf_url": "http://arxiv.org/pdf/2505.22582v1",
    "published": "2025-05-28T16:54:53+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.22581v1",
    "title": "Tell me Habibi, is it Real or Fake?",
    "authors": [
      "Kartik Kuckreja",
      "Parul Gupta",
      "Injy Hamed",
      "Thamar Solorio",
      "Muhammad Haris Khan",
      "Abhinav Dhall"
    ],
    "abstract": "Deepfake generation methods are evolving fast, making fake media harder to\ndetect and raising serious societal concerns. Most deepfake detection and\ndataset creation research focuses on monolingual content, often overlooking the\nchallenges of multilingual and code-switched speech, where multiple languages\nare mixed within the same discourse. Code-switching, especially between Arabic\nand English, is common in the Arab world and is widely used in digital\ncommunication. This linguistic mixing poses extra challenges for deepfake\ndetection, as it can confuse models trained mostly on monolingual data. To\naddress this, we introduce \\textbf{ArEnAV}, the first large-scale\nArabic-English audio-visual deepfake dataset featuring intra-utterance\ncode-switching, dialectal variation, and monolingual Arabic content. It\n\\textbf{contains 387k videos and over 765 hours of real and fake videos}. Our\ndataset is generated using a novel pipeline integrating four Text-To-Speech and\ntwo lip-sync models, enabling comprehensive analysis of multilingual multimodal\ndeepfake detection. We benchmark our dataset against existing monolingual and\nmultilingual datasets, state-of-the-art deepfake detection models, and a human\nevaluation, highlighting its potential to advance deepfake research. The\ndataset can be accessed\n\\href{https://huggingface.co/datasets/kartik060702/ArEnAV-Full}{here}.",
    "pdf_url": "http://arxiv.org/pdf/2505.22581v1",
    "published": "2025-05-28T16:54:36+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.22580v1",
    "title": "A hybrid PDE-ABM model for angiogenesis and tumour microenvironment with application to resistance in cancer treatment",
    "authors": [
      "Louis Shuo Wang",
      "Jiguang Yu",
      "Zonghao Liu"
    ],
    "abstract": "The main obstacle to effective cancer treatment is the development of drug\nresistance, which can be divided into two categories: spontaneous and acquired\ndrug resistance. Non-small cell lung cancer (NSCLC) is the main cause of\ncancer-related deaths worldwide. A subset of lung cancer, adenocarcinomas, is\ncharacterised by mutations in the epidermal growth factor receptor (EGFR) gene.\nTreatment of EGFR-mutated lung adenocarcinomas has become less effective over\ntime due to drug resistance development, which is associated with a second\nmutation in the EGFR gene. An important factor in the development of cancer is\nangiogenesis, which is the formation of blood vessels from the existing\nvasculature. These newly formed blood vessels provide oxygen and nutrients to\ntumour cells to maintain tumour growth and proliferation. We applied a hybrid\ndiscrete-continuous (HDC) model to capture the dynamic vasculature in the\ntumour microenvironment (TME). In the case of pre-existing resistance, the\nformation of angiogenic networks creates a microenvironment that supports\ntumour survival and enhances drug resistance. In the case of spontaneous\nmutation-induced resistance, earlier and more frequent mutations confer a\ngreater survival advantage to the tumour population. There is also a mutually\nreinforcing relationship between a high proliferation rate and high resistance\ncharacteristics. These findings explain two conflicting experimental results\nabout the second mutation in NSCLC.",
    "pdf_url": "http://arxiv.org/pdf/2505.22580v1",
    "published": "2025-05-28T16:54:29+00:00",
    "categories": [
      "math.NA",
      "cs.NA"
    ],
    "primary_category": "math.NA"
  },
  {
    "id": "http://arxiv.org/abs/2505.22579v2",
    "title": "Applying TDI to Hardware-Simulated Data",
    "authors": [
      "Reid Ferguson",
      "Olaf Hartwig",
      "Guido Mueller"
    ],
    "abstract": "Many years of development have gone into producing instruments that meet the\nrequired noise performance of the LISA interferometric detection system.\nConcurrently, software simulations have been used to extensively develop the\ndata analysis libraries to be used in the LISA pipeline, not least among which\nare the Time Delay Interferometry (TDI) algorithms. To bridge the gap between\nthese two, we are developing a hardware-in-the-loop testbed to apply realistic,\ntime-varying delays to signals traveling between phasemeters. We have shown\nthat the testbed adds a sufficiently low amount of noise across the entire\nrelevant LISA spectrum. We have also injected a realistic gravitational wave\nsignal, generated via the LISA Data Challenge codebase, and successfully\nextracted it using TDI to remove the obscuring frequency noise of the carrier\nsignal. Future efforts will expand the testbed to create a representative\nsimulation of the entire LISA constellation, with an eye towards its use as a\ntool to aid in the development of the LISA data analysis pipelines.",
    "pdf_url": "http://arxiv.org/pdf/2505.22579v2",
    "published": "2025-05-28T16:54:25+00:00",
    "categories": [
      "gr-qc",
      "astro-ph.IM",
      "physics.ins-det"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2505.22578v1",
    "title": "Benignity of loss landscape with weight decay requires both large overparametrization and initialization",
    "authors": [
      "Etienne Boursier",
      "Matthew Bowditch",
      "Matthias Englert",
      "Ranko Lazic"
    ],
    "abstract": "The optimization of neural networks under weight decay remains poorly\nunderstood from a theoretical standpoint. While weight decay is standard\npractice in modern training procedures, most theoretical analyses focus on\nunregularized settings. In this work, we investigate the loss landscape of the\n$\\ell_2$-regularized training loss for two-layer ReLU networks. We show that\nthe landscape becomes benign -- i.e., free of spurious local minima -- under\nlarge overparametrization, specifically when the network width $m$ satisfies $m\n\\gtrsim \\min(n^d, 2^n)$, where $n$ is the number of data points and $d$ the\ninput dimension. More precisely in this regime, almost all constant activation\nregions contain a global minimum and no spurious local minima. We further show\nthat this level of overparametrization is not only sufficient but also\nnecessary via the example of orthogonal data. Finally, we demonstrate that such\nloss landscape results primarily hold relevance in the large initialization\nregime. In contrast, for small initializations -- corresponding to the feature\nlearning regime -- optimization can still converge to spurious local minima,\ndespite the global benignity of the landscape.",
    "pdf_url": "http://arxiv.org/pdf/2505.22578v1",
    "published": "2025-05-28T16:53:48+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.00047v1",
    "title": "Risks of AI-driven product development and strategies for their mitigation",
    "authors": [
      "Jan G√∂pfert",
      "Jann M. Weinand",
      "Patrick Kuckertz",
      "Noah Pflugradt",
      "Jochen Lin√üen"
    ],
    "abstract": "Humanity is progressing towards automated product development, a trend that\npromises faster creation of better products and thus the acceleration of\ntechnological progress. However, increasing reliance on non-human agents for\nthis process introduces many risks. This perspective aims to initiate a\ndiscussion on these risks and appropriate mitigation strategies. To this end,\nwe outline a set of principles for safer AI-driven product development which\nemphasize human oversight, accountability, and explainable design, among\nothers. The risk assessment covers both technical risks which affect product\nquality and safety, and sociotechnical risks which affect society. While\nAI-driven product development is still in its early stages, this discussion\nwill help balance its opportunities and risks without delaying essential\nprogress in understanding, norm-setting, and regulation.",
    "pdf_url": "http://arxiv.org/pdf/2506.00047v1",
    "published": "2025-05-28T16:52:44+00:00",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.CE"
    ],
    "primary_category": "cs.CY"
  },
  {
    "id": "http://arxiv.org/abs/2505.22577v1",
    "title": "Positive curvature and rational ellipticity in cohomogeneity three",
    "authors": [
      "Elahe Khalili Samani",
      "Marco Radeschi"
    ],
    "abstract": "We prove that a closed, simply connected, positively curved,\ncohomogeneity-three manifold whose quotient space has no boundary is rationally\nelliptic, thus providing a generalization of similar results regarding rational\nellipticity of homogeneous, cohomogeneity-one, and almost non-negatively curved\ncohomogeneity-two manifolds.",
    "pdf_url": "http://arxiv.org/pdf/2505.22577v1",
    "published": "2025-05-28T16:51:35+00:00",
    "categories": [
      "math.DG",
      "53C21, 54H15, 57S15"
    ],
    "primary_category": "math.DG"
  },
  {
    "id": "http://arxiv.org/abs/2505.22576v1",
    "title": "ExoPhoto: A Database of Temperature-Dependent Photodissociation Cross Sections",
    "authors": [
      "Qing-He Ni",
      "Christian Hill",
      "Sergei N. Yurchenko",
      "Marco Pezzella",
      "Alexander Fateev",
      "Zhi Qin",
      "Olivia Venot",
      "Jonathan Tennyson"
    ],
    "abstract": "We present the ExoPhoto database (https://exomol.com/exophoto/), an extension\nof the ExoMol database, specifically developed to address the growing need for\nhigh-accuracy, temperature-dependent photodissociation cross section data\ntowards short-UV wavelengths. ExoPhoto combines theoretical models from three\nmajor computational databases (ExoMol, UGAMOP and PhoMol) and experimental\ndatasets from two experimental groups, providing extensive wavelength and\ntemperature coverage. ExoPhoto currently includes photodissociation data for 20\nmolecules: AlH, HCl, HF, MgH, OH, NaO, MgO, O2, AlCl, AlF, CS, HeH+, CO, CO2,\nH2O, SO2, C2H2, C2H4, H2CO, and NH3, derived from theoretical models and\nsupported by experimental data from 5 databases.\n  ExoPhoto also includes detailed data on branching ratios and quantum yields\nfor selected datasets. The data structure of ExoPhoto follows the ExoMol\nframework, with a consistent naming convention and hierarchical JSON-based\norganization. Photodissociation cross sections are stored in a set of .photo\nfiles which provide data as a function of wavelength with one file for each\ntarget molecule temperature. Future developments aim to include more\nphotodissociation cross section data and to provide data for molecules in\nnon-local thermodynamic equilibrium (non-LTE). These will expand the utility of\nExoPhoto for advanced astrophysical, planetary modeling and industrial\napplications.",
    "pdf_url": "http://arxiv.org/pdf/2505.22576v1",
    "published": "2025-05-28T16:51:17+00:00",
    "categories": [
      "astro-ph.EP",
      "astro-ph.IM",
      "physics.chem-ph"
    ],
    "primary_category": "astro-ph.EP"
  },
  {
    "id": "http://arxiv.org/abs/2505.22575v1",
    "title": "Minimal Quantum Reservoirs with Hamiltonian Encoding",
    "authors": [
      "Gerard McCaul",
      "Juan Sebastian Totero Gongora",
      "Wendy Otieno",
      "Sergey Savelev",
      "Alexandre Zagoskin",
      "Alexander G. Balanov"
    ],
    "abstract": "We investigate a minimal architecture for quantum reservoir computing based\non Hamiltonian encoding, in which input data is injected via modulation of\nsystem parameters rather than state preparation. This approach circumvents many\nof the experimental overheads typically associated with quantum machine\nlearning, enabling computation without feedback, memory, or state tomography.\nWe demonstrate that such a minimal quantum reservoir, despite lacking intrinsic\nmemory, can perform nonlinear regression and prediction tasks when augmented\nwith post-processing delay embeddings. Our results provide a conceptually and\npractically streamlined framework for quantum information processing, offering\na clear baseline for future implementations on near-term quantum hardware.",
    "pdf_url": "http://arxiv.org/pdf/2505.22575v1",
    "published": "2025-05-28T16:50:05+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.22574v2",
    "title": "Attention-based Neural Network Emulators for Multi-Probe Data Vectors Part III: Modeling The Next Generation Surveys",
    "authors": [
      "Yijie Zhu",
      "Evan Saraivanov",
      "Joshua A. Kable",
      "Artemis Sofia Giannakopoulou",
      "Amritpal Nijjar",
      "Vivian Miranda",
      "Marco Bonici",
      "Tim Eifler",
      "Elisabeth Krause"
    ],
    "abstract": "Machine learning can accelerate cosmological inferences that involve many\nsequential evaluations of computationally expensive data vectors. Previous\nworks in this series have examined how machine learning architectures impact\nemulator accuracy and training time for optical shear and galaxy clustering\n2-point function. In this final manuscript, we explore neural network\nperformance when emulating Cosmic Microwave Background temperature and\npolarization power spectra. We maximize the volume of applicability in the\nparameter space of our emulators within the standard $\\Lambda$-cold-dark-matter\nmodel while ensuring that errors are below cosmic variance. Relative to\nstandard multi-layer perceptron architectures, we find the\ndot-product-attention mechanism reduces the number of outliers among testing\ncosmologies, defined as the fraction of testing points with $\\Delta \\chi^2 >\n0.2$ relative to \\textsc{CAMB} outputs, for a wide range of training set sizes.\nSuch precision enables attention-based emulators to be directly applied to real\ndata without requiring any additional correction via importance sampling.\nCombined with pre-processing techniques and optimized activation and loss\nfunctions, attention-based models can meet the precision criteria set by\ncurrent and future CMB and lensing experiments. For each of Planck, Simons\nObservatory, CMB S4, and CMB HD, we find the fraction of outlier points to be\nless than $10\\%$ with around $2\\times10^5$ to $4\\times10^5$ training data\nvectors. We further explore the applications of these methods to supernova\ndistance, weak lensing, and galaxy clustering, as well as alternative\narchitectures and pre-processing techniques.",
    "pdf_url": "http://arxiv.org/pdf/2505.22574v2",
    "published": "2025-05-28T16:47:02+00:00",
    "categories": [
      "astro-ph.CO"
    ],
    "primary_category": "astro-ph.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.22573v1",
    "title": "FNOPE: Simulation-based inference on function spaces with Fourier Neural Operators",
    "authors": [
      "Guy Moss",
      "Leah Sophie Muhle",
      "Reinhard Drews",
      "Jakob H. Macke",
      "Cornelius Schr√∂der"
    ],
    "abstract": "Simulation-based inference (SBI) is an established approach for performing\nBayesian inference on scientific simulators. SBI so far works best on\nlow-dimensional parametric models. However, it is difficult to infer\nfunction-valued parameters, which frequently occur in disciplines that model\nspatiotemporal processes such as the climate and earth sciences. Here, we\nintroduce an approach for efficient posterior estimation, using a Fourier\nNeural Operator (FNO) architecture with a flow matching objective. We show that\nour approach, FNOPE, can perform inference of function-valued parameters at a\nfraction of the simulation budget of state of the art methods. In addition,\nFNOPE supports posterior evaluation at arbitrary discretizations of the domain,\nas well as simultaneous estimation of vector-valued parameters. We demonstrate\nthe effectiveness of our approach on several benchmark tasks and a challenging\nspatial inference task from glaciology. FNOPE extends the applicability of SBI\nmethods to new scientific domains by enabling the inference of function-valued\nparameters.",
    "pdf_url": "http://arxiv.org/pdf/2505.22573v1",
    "published": "2025-05-28T16:46:56+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.22572v1",
    "title": "Fusion Steering: Prompt-Specific Activation Control",
    "authors": [
      "Waldemar Chang",
      "Alhassan Yasin"
    ],
    "abstract": "We present Fusion Steering, an activation steering methodology that improves\nfactual accuracy in large language models (LLMs) for question-answering (QA)\ntasks. This approach introduces flexible steering configurations, including\nfull-layer steering and segmented steering. Unlike traditional methods\nconstrained to single-layer or fixed-layer operations, Fusion Steering employs\ndynamic injection of prompt-specific activation deltas across all transformer\nlayers. These activation deltas are derived from reference completions that\ncombine the ground-truth answer with a model-generated explanation to\nfacilitate semantically enriched, example-specific steering. The injection\nweights are optimized per prompt using Optuna, targeting a joint objective that\nbalances token overlap (factual alignment) and perplexity (fluency proxy).\nEvaluation employs a composite score integrating token overlap and LLM-graded\nquality, encompassing factual accuracy, coherence, and relevance. Empirical\nresults on 260 SimpleQA prompts (selected from 500 where the baseline failed)\nshowcase the efficacy of segmented steering. Using Gemma-2-2B-IT with 8-bit\nquantization, segmented steering achieves an accuracy of 25.4% (outputs scoring\n$\\geq 0.6$), outperforming the baseline at 3.5% and full-layer steering at\n16.2%. Under the stricter SimpleQA rubric, segmented steering boosts fully\ncorrect responses from 0.0% to 13.1%. These findings highlight the strengths of\nsegmented, dynamic intervention strategies and the promise of per-prompt,\nfull-network activation control. Fusion Steering is also amenable to sparse\nrepresentations, such as Neuronpedia or sparse crosscoders, suggesting a\npromising direction for interpretable and scalable activation-level control in\nLLMs.",
    "pdf_url": "http://arxiv.org/pdf/2505.22572v1",
    "published": "2025-05-28T16:46:55+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.22571v3",
    "title": "Agent-UniRAG: A Trainable Open-Source LLM Agent Framework for Unified Retrieval-Augmented Generation Systems",
    "authors": [
      "Hoang Pham",
      "Thuy-Duong Nguyen",
      "Khac-Hoai Nam Bui"
    ],
    "abstract": "This paper presents a novel approach for unified retrieval-augmented\ngeneration (RAG) systems using the recent emerging large language model (LLM)\nagent concept. Specifically, Agent LLM, which utilizes LLM as fundamental\ncontrollers, has become a promising approach to enable the interpretability of\nRAG tasks, especially for complex reasoning question-answering systems (e.g.,\nmulti-hop queries). Nonetheless, previous works mainly focus on solving RAG\nsystems with either single-hop or multi-hop approaches separately, which limits\nthe application of those approaches to real-world applications. In this study,\nwe propose a trainable agent framework called Agent-UniRAG for unified\nretrieval-augmented LLM systems, which enhances the effectiveness and\ninterpretability of RAG systems. The main idea is to design an LLM agent\nframework to solve RAG tasks step-by-step based on the complexity of the\ninputs, simultaneously including single-hop and multi-hop queries in an\nend-to-end manner. Furthermore, we introduce SynAgent-RAG, a synthetic dataset\nto enable the proposed agent framework for small open-source LLMs (e.g.,\nLlama-3-8B). The results show comparable performances with closed-source and\nlarger open-source LLMs across various RAG benchmarks. Our source code and\ndataset are publicly available for further exploitation.",
    "pdf_url": "http://arxiv.org/pdf/2505.22571v3",
    "published": "2025-05-28T16:46:31+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.DB",
      "cs.IR"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.22570v1",
    "title": "Tensor product formulas for the Bollob√°s-Riordan and Krushkal polynomials",
    "authors": [
      "Iain Moffatt",
      "Maya Thompson"
    ],
    "abstract": "Brylawski's tensor product formula expresses the Tutte polynomial of the\ntensor product of two graphs in terms of Tutte polynomials arising from the\ntensor factors. Analogous tensor product formulas are known for the ribbon\ngraph polynomial and transition polynomials of graphs embedded in surfaces, as\nwell as for the Bollob\\'as-Riordan polynomial in some special cases. We define\nthe tensor product of graphs embedded in pseudo-surfaces and use this to\ngeneralize and unify all of the above results, providing Brylawski-style\nformulas for both the Bollob\\'as-Riordan and Krushkal polynomials.",
    "pdf_url": "http://arxiv.org/pdf/2505.22570v1",
    "published": "2025-05-28T16:45:20+00:00",
    "categories": [
      "math.CO",
      "05C31, 05C10"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.22569v1",
    "title": "ImageReFL: Balancing Quality and Diversity in Human-Aligned Diffusion Models",
    "authors": [
      "Dmitrii Sorokin",
      "Maksim Nakhodnov",
      "Andrey Kuznetsov",
      "Aibek Alanov"
    ],
    "abstract": "Recent advances in diffusion models have led to impressive image generation\ncapabilities, but aligning these models with human preferences remains\nchallenging. Reward-based fine-tuning using models trained on human feedback\nimproves alignment but often harms diversity, producing less varied outputs. In\nthis work, we address this trade-off with two contributions. First, we\nintroduce \\textit{combined generation}, a novel sampling strategy that applies\na reward-tuned diffusion model only in the later stages of the generation\nprocess, while preserving the base model for earlier steps. This approach\nmitigates early-stage overfitting and helps retain global structure and\ndiversity. Second, we propose \\textit{ImageReFL}, a fine-tuning method that\nimproves image diversity with minimal loss in quality by training on real\nimages and incorporating multiple regularizers, including diffusion and ReFL\nlosses. Our approach outperforms conventional reward tuning methods on standard\nquality and diversity metrics. A user study further confirms that our method\nbetter balances human preference alignment and visual diversity. The source\ncode can be found at https://github.com/ControlGenAI/ImageReFL .",
    "pdf_url": "http://arxiv.org/pdf/2505.22569v1",
    "published": "2025-05-28T16:45:07+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.22568v1",
    "title": "Multipath cycleGAN for harmonization of paired and unpaired low-dose lung computed tomography reconstruction kernels",
    "authors": [
      "Aravind R. Krishnan",
      "Thomas Z. Li",
      "Lucas W. Remedios",
      "Michael E. Kim",
      "Chenyu Gao",
      "Gaurav Rudravaram",
      "Elyssa M. McMaster",
      "Adam M. Saunders",
      "Shunxing Bao",
      "Kaiwen Xu",
      "Lianrui Zuo",
      "Kim L. Sandler",
      "Fabien Maldonado",
      "Yuankai Huo",
      "Bennett A. Landman"
    ],
    "abstract": "Reconstruction kernels in computed tomography (CT) affect spatial resolution\nand noise characteristics, introducing systematic variability in quantitative\nimaging measurements such as emphysema quantification. Choosing an appropriate\nkernel is therefore essential for consistent quantitative analysis. We propose\na multipath cycleGAN model for CT kernel harmonization, trained on a mixture of\npaired and unpaired data from a low-dose lung cancer screening cohort. The\nmodel features domain-specific encoders and decoders with a shared latent space\nand uses discriminators tailored for each domain.We train the model on 42\nkernel combinations using 100 scans each from seven representative kernels in\nthe National Lung Screening Trial (NLST) dataset. To evaluate performance, 240\nscans from each kernel are harmonized to a reference soft kernel, and emphysema\nis quantified before and after harmonization. A general linear model assesses\nthe impact of age, sex, smoking status, and kernel on emphysema. We also\nevaluate harmonization from soft kernels to a reference hard kernel. To assess\nanatomical consistency, we compare segmentations of lung vessels, muscle, and\nsubcutaneous adipose tissue generated by TotalSegmentator between harmonized\nand original images. Our model is benchmarked against traditional and\nswitchable cycleGANs. For paired kernels, our approach reduces bias in\nemphysema scores, as seen in Bland-Altman plots (p<0.05). For unpaired kernels,\nharmonization eliminates confounding differences in emphysema (p>0.05). High\nDice scores confirm preservation of muscle and fat anatomy, while lung vessel\noverlap remains reasonable. Overall, our shared latent space multipath cycleGAN\nenables robust harmonization across paired and unpaired CT kernels, improving\nemphysema quantification and preserving anatomical fidelity.",
    "pdf_url": "http://arxiv.org/pdf/2505.22568v1",
    "published": "2025-05-28T16:44:42+00:00",
    "categories": [
      "eess.IV",
      "cs.CV"
    ],
    "primary_category": "eess.IV"
  },
  {
    "id": "http://arxiv.org/abs/2506.03169v1",
    "title": "Improvement of human health lifespan with hybrid group pose estimation methods",
    "authors": [
      "Arindam Chaudhuri"
    ],
    "abstract": "Human beings rely heavily on estimation of poses in order to access their\nbody movements. Human pose estimation methods take advantage of computer vision\nadvances in order to track human body movements in real life applications. This\ncomes from videos which are recorded through available devices. These\npara-digms provide potential to make human movement measurement more accessible\nto users. The consumers of pose estimation movements believe that human poses\ncontent tend to supplement available videos. This has increased pose estimation\nsoftware usage to estimate human poses. In order to address this problem, we\ndevelop hybrid-ensemble-based group pose estimation method to improve human\nhealth. This proposed hybrid-ensemble-based group pose estimation method aims\nto detect multi-person poses using modified group pose estimation and modified\nreal time pose estimation. This ensemble allows fusion of performance of stated\nmethods in real time. The input poses from images are fed into individual\nmeth-ods. The pose transformation method helps to identify relevant features\nfor en-semble to perform training effectively. After this, customized\npre-trained hybrid ensemble is trained on public benchmarked datasets which is\nbeing evaluated through test datasets. The effectiveness and viability of\nproposed method is estab-lished based on comparative analysis of group pose\nestimation methods and ex-periments conducted on benchmarked datasets. It\nprovides best optimized results in real-time pose estimation. It makes pose\nestimation method more robust to oc-clusion and improves dense regression\naccuracy. These results have affirmed po-tential application of this method in\nseveral real-time situations with improvement in human health life span",
    "pdf_url": "http://arxiv.org/pdf/2506.03169v1",
    "published": "2025-05-28T16:43:28+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.22567v2",
    "title": "A black hole in a near-pristine galaxy 700 million years after the Big Bang",
    "authors": [
      "Roberto Maiolino",
      "Hannah Uebler",
      "Francesco D'Eugenio",
      "Jan Scholtz",
      "Ignas Juodzbalis",
      "Xihan Ji",
      "Michele Perna",
      "Volker Bromm",
      "Pratika Dayal",
      "Sophie Koudmani",
      "Boyuan Liu",
      "Raffaella Schneider",
      "Debora Sijacki",
      "Rosa Valiante",
      "Alessandro Trinca",
      "Saiyang Zhang",
      "Marta Volonteri",
      "Kohei Inayoshi",
      "Stefano Carniani",
      "Kimihiko Nakajima",
      "Yuki Isobe",
      "Joris Witstok",
      "Gareth C. Jones",
      "Sandro Tacchella",
      "Santiago Arribas",
      "Andrew Bunker",
      "Elisa Cataldi",
      "Stephane Charlot",
      "Giovanni Cresci",
      "Mirko Curti",
      "Andrew C. Fabian",
      "Harley Katz",
      "Nimisha Kumari",
      "Nicolas Laporte",
      "Giovanni Mazzolari",
      "Brant Robertson",
      "Fengwu Sun",
      "Bruno Rodriguez Del Pino",
      "Giacomo Venturi"
    ],
    "abstract": "The recent discovery of a large number of massive black holes within the\nfirst two billion years after the Big Bang, as well as their peculiar\nproperties, have been largely unexpected based on the extrapolation of the\nproperties of luminous quasars. These findings have prompted the development of\nseveral theoretical models for the early formation and growth of black holes,\nwhich are, however, difficult to differentiate. We report the metallicity\nmeasurement around a gravitationally lensed massive black hole at redshift\n7.04, hosted in a galaxy with very low dynamical mass. The weakness of the\n[OIII]5007 emission line relative to the narrow Hbeta emission indicates an\nextremely low chemical enrichment, less than 0.01 solar. We argue that such\nproperties cannot be uncommon among accreting black holes around this early\ncosmic epoch. Explaining such a low chemical enrichment in a system that has\ndeveloped a massive black hole is challenging for most theories. Models\nassuming heavy black hole seeds (such as Direct Collapse Black Holes) or\nsuper-Eddington accretion scenarios struggle to explain the observations,\nalthough they can potentially reproduce the observed properties in rare cases.\nModels invoking \"primordial black holes\" (i.e. putative black holes formed\nshortly after the Big Bang) may potentially explain the low chemical enrichment\nassociated with this black hole.",
    "pdf_url": "http://arxiv.org/pdf/2505.22567v2",
    "published": "2025-05-28T16:43:24+00:00",
    "categories": [
      "astro-ph.GA",
      "astro-ph.CO"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2505.22566v1",
    "title": "Universal Visuo-Tactile Video Understanding for Embodied Interaction",
    "authors": [
      "Yifan Xie",
      "Mingyang Li",
      "Shoujie Li",
      "Xingting Li",
      "Guangyu Chen",
      "Fei Ma",
      "Fei Richard Yu",
      "Wenbo Ding"
    ],
    "abstract": "Tactile perception is essential for embodied agents to understand physical\nattributes of objects that cannot be determined through visual inspection\nalone. While existing approaches have made progress in visual and language\nmodalities for physical understanding, they fail to effectively incorporate\ntactile information that provides crucial haptic feedback for real-world\ninteraction. In this paper, we present VTV-LLM, the first multi-modal large\nlanguage model for universal Visuo-Tactile Video (VTV) understanding that\nbridges the gap between tactile perception and natural language. To address the\nchallenges of cross-sensor and cross-modal integration, we contribute VTV150K,\na comprehensive dataset comprising 150,000 video frames from 100 diverse\nobjects captured across three different tactile sensors (GelSight Mini, DIGIT,\nand Tac3D), annotated with four fundamental tactile attributes (hardness,\nprotrusion, elasticity, and friction). We develop a novel three-stage training\nparadigm that includes VTV enhancement for robust visuo-tactile representation,\nVTV-text alignment for cross-modal correspondence, and text prompt finetuning\nfor natural language generation. Our framework enables sophisticated tactile\nreasoning capabilities including feature assessment, comparative analysis,\nscenario-based decision making and so on. Experimental evaluations demonstrate\nthat VTV-LLM achieves superior performance in tactile video understanding\ntasks, establishing a foundation for more intuitive human-machine interaction\nin tactile domains.",
    "pdf_url": "http://arxiv.org/pdf/2505.22566v1",
    "published": "2025-05-28T16:43:01+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.22565v1",
    "title": "The Ingleton inequality holds for metacyclic groups and fails for supersoluble groups",
    "authors": [
      "David A. Craven"
    ],
    "abstract": "The Ingleton inequality first appeared in matroid theory, where Ingleton\nproved in 1971 that every rank function coming from a representable matroid on\nfour subsets satisfies a particular inequality. Because this inequality is not\nimplied by submodularity, Shannon-type axioms alone, it and various analogues\nplay a central role in separately linear and non-linear phenomena in a variety\nof areas of mathematics. The Ingleton inequality for finite groups concerns the\nvarious intersections of four subgroups. It holds for many quadruples of\nsubgroups of finite groups, but not all, the smallest example being four\nsubgroups of $S_5$, of order 120. Open questions are whether the Inlgeton\ninequality always holds for metacycle and nilpotent groups. (There is a proof\nin the literature due to Oggier and Stancu, but there is an already known issue\nwith their proof, which we address in this article.)\n  In this paper we prove that the Ingleton inequality always holds for\nmetacycle groups, but that it fails for supersoluble groups, a class of groups\nonly a little larger than nilpotent groups. Although we do not resolve the\nnilpotent case here we do make some reductions, and also prove that there are\nno nilpotent violators of the Ingleton inequality of order less than 1024. We\nend with a list of Ingleton inequality violating groups of order at most 1023.\n  The article comes with a Magma package that allows reproduction of all\nresults in the paper and for the reader to check the Ingleton inequality for\nany given finite group.",
    "pdf_url": "http://arxiv.org/pdf/2505.22565v1",
    "published": "2025-05-28T16:42:48+00:00",
    "categories": [
      "math.GR",
      "cs.IT",
      "math.IT"
    ],
    "primary_category": "math.GR"
  },
  {
    "id": "http://arxiv.org/abs/2505.22564v1",
    "title": "PRISM: Video Dataset Condensation with Progressive Refinement and Insertion for Sparse Motion",
    "authors": [
      "Jaehyun Choi",
      "Jiwan Hur",
      "Gyojin Han",
      "Jaemyung Yu",
      "Junmo Kim"
    ],
    "abstract": "Video dataset condensation has emerged as a critical technique for addressing\nthe computational challenges associated with large-scale video data processing\nin deep learning applications. While significant progress has been made in\nimage dataset condensation, the video domain presents unique challenges due to\nthe complex interplay between spatial content and temporal dynamics. This paper\nintroduces PRISM, Progressive Refinement and Insertion for Sparse Motion, for\nvideo dataset condensation, a novel approach that fundamentally reconsiders how\nvideo data should be condensed. Unlike the previous method that separates\nstatic content from dynamic motion, our method preserves the essential\ninterdependence between these elements. Our approach progressively refines and\ninserts frames to fully accommodate the motion in an action while achieving\nbetter performance but less storage, considering the relation of gradients for\neach frame. Extensive experiments across standard video action recognition\nbenchmarks demonstrate that PRISM outperforms existing disentangled approaches\nwhile maintaining compact representations suitable for resource-constrained\nenvironments.",
    "pdf_url": "http://arxiv.org/pdf/2505.22564v1",
    "published": "2025-05-28T16:42:10+00:00",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.22563v1",
    "title": "Do Large Language Models Think Like the Brain? Sentence-Level Evidence from fMRI and Hierarchical Embeddings",
    "authors": [
      "Yu Lei",
      "Xingyang Ge",
      "Yi Zhang",
      "Yiming Yang",
      "Bolei Ma"
    ],
    "abstract": "Understanding whether large language models (LLMs) and the human brain\nconverge on similar computational principles remains a fundamental and\nimportant question in cognitive neuroscience and AI. Do the brain-like patterns\nobserved in LLMs emerge simply from scaling, or do they reflect deeper\nalignment with the architecture of human language processing? This study\nfocuses on the sentence-level neural mechanisms of language models,\nsystematically investigating how hierarchical representations in LLMs align\nwith the dynamic neural responses during human sentence comprehension. By\ncomparing hierarchical embeddings from 14 publicly available LLMs with fMRI\ndata collected from participants, who were exposed to a naturalistic narrative\nstory, we constructed sentence-level neural prediction models to precisely\nidentify the model layers most significantly correlated with brain region\nactivations. Results show that improvements in model performance drive the\nevolution of representational architectures toward brain-like hierarchies,\nparticularly achieving stronger functional and anatomical correspondence at\nhigher semantic abstraction levels.",
    "pdf_url": "http://arxiv.org/pdf/2505.22563v1",
    "published": "2025-05-28T16:40:06+00:00",
    "categories": [
      "cs.CL",
      "q-bio.NC"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.22562v2",
    "title": "Equidistant Hypersurfaces Of The Complex Bidisk $\\mathbb{H}^2_{\\mathbb{C}}\\times \\mathbb{H}^2_{\\mathbb{C}}$",
    "authors": [
      "Krishnendu Gongopadhyay",
      "Lokenath Kundu",
      "Aditya Tiwari"
    ],
    "abstract": "We consider the isometries of the complex hyperbolic bidisk, that is, the\nproduct space $\\mathbb{H}^2_{\\mathbb{C}} \\times \\mathbb{H}^2_{\\mathbb{C}} $,\nwhere each factor $ \\mathbb{H}^2_{\\mathbb{C}} $ denotes the complex hyperbolic\nplane. We investigate the Dirichlet domain formed by the action of a cyclic\nsubgroup $(g_1, g_2)$, where each $g_i$ is loxodromic. We prove that such a\nDirichlet domain has two sides.",
    "pdf_url": "http://arxiv.org/pdf/2505.22562v2",
    "published": "2025-05-28T16:39:45+00:00",
    "categories": [
      "math.GT",
      "51M10, 53A35, 57M50"
    ],
    "primary_category": "math.GT"
  },
  {
    "id": "http://arxiv.org/abs/2505.22561v2",
    "title": "On Big Ramsey degrees of universal $œâ$-edge-labeled hypergraphs",
    "authors": [
      "Jan Hubiƒçka",
      "Matƒõj Koneƒçn√Ω",
      "Stevo Todorcevic",
      "Andy Zucker"
    ],
    "abstract": "We show that the big Ramsey degrees of every countable universal $u$-uniform\n$\\omega$-edge-labeled hypergraph are infinite for every $u\\geq 2$. Together\nwith a recent result of Braunfeld, Chodounsk\\'y, de Rancourt, Hubi\\v{c}ka,\nKawach, and Kone\\v{c}n\\'y this finishes full characterisation of unrestricted\nrelational structures with finite big Ramsey degrees.",
    "pdf_url": "http://arxiv.org/pdf/2505.22561v2",
    "published": "2025-05-28T16:38:40+00:00",
    "categories": [
      "math.CO",
      "cs.DM",
      "math.LO",
      "05C55, 03E02, 05D10, 05C15",
      "G.2.1"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.22560v1",
    "title": "Geometric Hyena Networks for Large-scale Equivariant Learning",
    "authors": [
      "Artem Moskalev",
      "Mangal Prakash",
      "Junjie Xu",
      "Tianyu Cui",
      "Rui Liao",
      "Tommaso Mansi"
    ],
    "abstract": "Processing global geometric context while preserving equivariance is crucial\nwhen modeling biological, chemical, and physical systems. Yet, this is\nchallenging due to the computational demands of equivariance and global context\nat scale. Standard methods such as equivariant self-attention suffer from\nquadratic complexity, while local methods such as distance-based message\npassing sacrifice global information. Inspired by the recent success of\nstate-space and long-convolutional models, we introduce Geometric Hyena, the\nfirst equivariant long-convolutional model for geometric systems. Geometric\nHyena captures global geometric context at sub-quadratic complexity while\nmaintaining equivariance to rotations and translations. Evaluated on all-atom\nproperty prediction of large RNA molecules and full protein molecular dynamics,\nGeometric Hyena outperforms existing equivariant models while requiring\nsignificantly less memory and compute that equivariant self-attention. Notably,\nour model processes the geometric context of 30k tokens 20x faster than the\nequivariant transformer and allows 72x longer context within the same budget.",
    "pdf_url": "http://arxiv.org/pdf/2505.22560v1",
    "published": "2025-05-28T16:38:35+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.22559v2",
    "title": "Observation of Coherent Ferrons",
    "authors": [
      "Jeongheon Choe",
      "Taketo Handa",
      "Chun-Ying Huang",
      "Andr√© Koch Liston",
      "Jordan Cox",
      "Jonathan Stensberg",
      "Yongseok Hong",
      "Daniel G. Chica",
      "Ding Xu",
      "Fuyang Tay",
      "Samra Husremovic",
      "Vinicius da Silveira Lanza Avelar",
      "Eric A. Arsenault",
      "Zhuquan Zhang",
      "James McIver",
      "Dmitri N. Basov",
      "Milan Delor",
      "Xavier Roy",
      "X. -Y. Zhu"
    ],
    "abstract": "Excitation of ordered quantum phases gives rise to collective modes and\nquasiparticles, as exemplified by spin waves and magnons emerging from magnetic\norder. Extending this paradigm to ferroelectric materials suggests the\nexistence of polarization waves and their fundamental quanta, ferrons. Here, we\nreport the generation and transport of polarization waves, i.e., coherent\nferrons, in the van der Waals ferroelectric material NbOI2. Upon excitation by\na short laser pulse, the polarization wave emits intense and narrow-band\nterahertz (THz) radiation at the ferroelectric transverse optical phonon\nfrequency, modulates the ferroelectric order parameter, and propagates\nuniaxially along the polar axis at hypersonic velocities of ~105 m/s. These\nlong-lived, uniaxial, and dipole-carrying polarization waves may find\napplications in narrow-band THz emission, ferronic information processing, and\ncoherent electric control.",
    "pdf_url": "http://arxiv.org/pdf/2505.22559v2",
    "published": "2025-05-28T16:38:26+00:00",
    "categories": [
      "cond-mat.mtrl-sci",
      "physics.app-ph",
      "physics.optics"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2505.22558v1",
    "title": "Homotopical Observables and the Langlands Program via $\\infty$-Topoi",
    "authors": [
      "Anatoly Galikhanov"
    ],
    "abstract": "We introduce a pro-\\'etale geometric object $D_\\infty$ arising naturally from\nthe tower of Artin-Schreier extensions in characteristic 2, equipped with a\ncanonical endofunctor $O$ whose fixed points correspond to automorphic\nrepresentations of $\\mathrm{GL}_2(\\mathbb{A}_{\\mathbb{F}_2})$. The main theorem\nestablishes that invariant predicates on $D_\\infty$ parametrize cuspidal\nautomorphic representations, preserving $L$-functions. We provide complete\nproofs using $\\infty$-categorical techniques, explicit computations for small\ncases, and establish connections to discrete conformal field theory. As\napplications, we resolve the Carlitz-Drinfeld uniformization conjecture for\nfunction fields and compute previously unknown motivic cohomology groups. Our\napproach differs fundamentally from coalgebraic models by working internally in\ntopoi and connecting to arithmetic geometry.",
    "pdf_url": "http://arxiv.org/pdf/2505.22558v1",
    "published": "2025-05-28T16:38:22+00:00",
    "categories": [
      "math.GM",
      "11F70, 14G32, 18N50, 55U40",
      "F.4.1; G.0; F.1.1"
    ],
    "primary_category": "math.GM"
  },
  {
    "id": "http://arxiv.org/abs/2505.22557v3",
    "title": "On lattice-polarized K3 surfaces",
    "authors": [
      "Valery Alexeev",
      "Philip Engel"
    ],
    "abstract": "We correct the commonly used definitions of lattice-polarized and\nlattice-quasipolarized K3 surfaces.",
    "pdf_url": "http://arxiv.org/pdf/2505.22557v3",
    "published": "2025-05-28T16:38:02+00:00",
    "categories": [
      "math.AG",
      "14J28, 14J10"
    ],
    "primary_category": "math.AG"
  },
  {
    "id": "http://arxiv.org/abs/2505.23974v1",
    "title": "Representation of Symmetric Shift Registers",
    "authors": [
      "Jan S√∏reng"
    ],
    "abstract": "The objective of this work is to establish a mathematical framework for the\nstudy of symmetric shift registers over the field GF(2). The present paper\ngives a new approach where the symmetric shift registers are represented by\nassociated systems of nonlinear difference equations. Arithmetical progressions\nwill play a central part. This approach clarifies the underlying structures and\nmakes it easier to determine the minimal periods of the sequences generated by\nthe symmetric shift registers. Key words: Shift registers, nonlinear difference\nequations, periods, arithmetical progressions, GF(2).",
    "pdf_url": "http://arxiv.org/pdf/2505.23974v1",
    "published": "2025-05-28T16:37:12+00:00",
    "categories": [
      "math.CO",
      "cs.IT",
      "math.IT"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.22556v1",
    "title": "Products of exact dynamical systems and Lorentzian continued fractions",
    "authors": [
      "Brandon G. Barreto-Rosa",
      "Jean-Philippe Burelle",
      "Anton Lukyanenko",
      "Martha Richey"
    ],
    "abstract": "We describe a new continued fraction system in Minkowski space $\\mathbb\nR^{1,1}$, proving convergence, ergodicity with respect to an explicit invariant\nmeasure, and Lagrange's theorem. The proof of ergodicity leads us to the\nquestion of exactness for products of dynamical systems. Under technical\nassumptions, namely Renyi's condition, we show that products of exact dynamical\nsystems are again exact, allowing us to study $\\alpha$-type perturbations of\nthe system. In addition, we describe new CF systems in $\\mathbb R^{1,1}$ and\n$\\mathbb R^{2,1}\\cong \\mathrm{Sym}_2(\\mathbb R)$ that, based on experimental\nevidence, we conjecture to be convergent and ergodic with respect to a finite\ninvariant measure.",
    "pdf_url": "http://arxiv.org/pdf/2505.22556v1",
    "published": "2025-05-28T16:36:59+00:00",
    "categories": [
      "math.DS",
      "math.NT",
      "37A44, 11K50"
    ],
    "primary_category": "math.DS"
  },
  {
    "id": "http://arxiv.org/abs/2505.22555v2",
    "title": "MultiFormer: A Multi-Person Pose Estimation System Based on CSI and Attention Mechanism",
    "authors": [
      "Yanyi Qu",
      "Haoyang Ma",
      "Wenhui Xiong"
    ],
    "abstract": "Human pose estimation based on Channel State Information (CSI) has emerged as\na promising approach for non-intrusive and precise human activity monitoring,\nyet faces challenges including accurate multi-person pose recognition and\neffective CSI feature learning. This paper presents MultiFormer, a wireless\nsensing system that accurately estimates human pose through CSI. The proposed\nsystem adopts a Transformer based time-frequency dual-token feature extractor\nwith multi-head self-attention. This feature extractor is able to model\ninter-subcarrier correlations and temporal dependencies of the CSI. The\nextracted CSI features and the pose probability heatmaps are then fused by\nMulti-Stage Feature Fusion Network (MSFN) to enforce the anatomical\nconstraints. Extensive experiments conducted on on the public MM-Fi dataset and\nour self-collected dataset show that the MultiFormer achieves higher accuracy\nover state-of-the-art approaches, especially for high-mobility keypoints\n(wrists, elbows) that are particularly difficult for previous methods to\naccurately estimate.",
    "pdf_url": "http://arxiv.org/pdf/2505.22555v2",
    "published": "2025-05-28T16:36:02+00:00",
    "categories": [
      "cs.CV",
      "eess.SP"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.22554v1",
    "title": "Can Copulas Be Used for Feature Selection? A Machine Learning Study on Diabetes Risk Prediction",
    "authors": [
      "Agnideep Aich",
      "Md Monzur Murshed",
      "Amanda Mayeaux",
      "Sameera Hewage"
    ],
    "abstract": "Accurate diabetes risk prediction relies on identifying key features from\ncomplex health datasets, but conventional methods like mutual information (MI)\nfilters and genetic algorithms (GAs) often overlook extreme dependencies\ncritical for high-risk subpopulations. In this study we introduce a\nfeature-selection framework using the upper-tail dependence coefficient\n({\\lambda}U) of the novel A2 copula, which quantifies how often extreme higher\nvalues of a predictor co-occur with diabetes diagnoses (target variable).\nApplied to the CDC Diabetes Health Indicators dataset (n=253,680), our method\nprioritizes five predictors (self-reported general health, high blood pressure,\nbody mass index, mobility limitations, and high cholesterol levels) based on\nupper tail dependencies. These features match or outperform MI and GA selected\nsubsets across four classifiers (Random Forest, XGBoost, Logistic Regression,\nGradient Boosting), achieving accuracy up to 86.5% (XGBoost) and AUC up to\n0.806 (Gradient Boosting), rivaling the full 21-feature model. Permutation\nimportance confirms clinical relevance, with BMI and general health driving\naccuracy. To our knowledge, this is the first work to apply a copula's\nupper-tail dependence for supervised feature selection, bridging extreme-value\ntheory and machine learning to deliver a practical toolkit for diabetes\nprevention.",
    "pdf_url": "http://arxiv.org/pdf/2505.22554v1",
    "published": "2025-05-28T16:34:58+00:00",
    "categories": [
      "stat.ML",
      "cs.LG",
      "62H05, 62H12, 62P10, 68T07"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2505.22553v1",
    "title": "The old problem of the cosmological constant solved?",
    "authors": [
      "Jan Nov√°k",
      "Oem Trivedi"
    ],
    "abstract": "We formulate an approach to quantum gravity, called the ring paradigm.\nGravity is mediated superluminally, and the graviton is described as a phonon\non the grid of matter in the Universe. This theory has very interesting\napplications to cosmology and would ultimately solve the old problem of the\ncosmological constant. It further gives new impulses to the scalar field\ntheories because the gravitational ring decays to some phantom field. As is\nobvious, we radically break the Lorentz invariance, which means that some\ngeneralization of the Haag-Lopuszanski-Sohnius theorem in quantum field theory\nis possible.",
    "pdf_url": "http://arxiv.org/pdf/2505.22553v1",
    "published": "2025-05-28T16:34:48+00:00",
    "categories": [
      "gr-qc",
      "astro-ph.CO",
      "hep-th"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2505.22552v1",
    "title": "ClaimPKG: Enhancing Claim Verification via Pseudo-Subgraph Generation with Lightweight Specialized LLM",
    "authors": [
      "Hoang Pham",
      "Thanh-Do Nguyen",
      "Khac-Hoai Nam Bui"
    ],
    "abstract": "Integrating knowledge graphs (KGs) to enhance the reasoning capabilities of\nlarge language models (LLMs) is an emerging research challenge in claim\nverification. While KGs provide structured, semantically rich representations\nwell-suited for reasoning, most existing verification methods rely on\nunstructured text corpora, limiting their ability to effectively leverage KGs.\nAdditionally, despite possessing strong reasoning abilities, modern LLMs\nstruggle with multi-step modular pipelines and reasoning over KGs without\nadaptation. To address these challenges, we propose ClaimPKG, an end-to-end\nframework that seamlessly integrates LLM reasoning with structured knowledge\nfrom KGs. Specifically, the main idea of ClaimPKG is to employ a lightweight,\nspecialized LLM to represent the input claim as pseudo-subgraphs, guiding a\ndedicated subgraph retrieval module to identify relevant KG subgraphs. These\nretrieved subgraphs are then processed by a general-purpose LLM to produce the\nfinal verdict and justification. Extensive experiments on the FactKG dataset\ndemonstrate that ClaimPKG achieves state-of-the-art performance, outperforming\nstrong baselines in this research field by 9%-12% accuracy points across\nmultiple categories. Furthermore, ClaimPKG exhibits zero-shot generalizability\nto unstructured datasets such as HoVer and FEVEROUS, effectively combining\nstructured knowledge from KGs with LLM reasoning across various LLM backbones.",
    "pdf_url": "http://arxiv.org/pdf/2505.22552v1",
    "published": "2025-05-28T16:34:14+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.DB"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.22551v1",
    "title": "Deep Learning-Based BMD Estimation from Radiographs with Conformal Uncertainty Quantification",
    "authors": [
      "Long Hui",
      "Wai Lok Yeung"
    ],
    "abstract": "Limited DXA access hinders osteoporosis screening. This proof-of-concept\nstudy proposes using widely available knee X-rays for opportunistic Bone\nMineral Density (BMD) estimation via deep learning, emphasizing robust\nuncertainty quantification essential for clinical use. An EfficientNet model\nwas trained on the OAI dataset to predict BMD from bilateral knee radiographs.\nTwo Test-Time Augmentation (TTA) methods were compared: traditional averaging\nand a multi-sample approach. Crucially, Split Conformal Prediction was\nimplemented to provide statistically rigorous, patient-specific prediction\nintervals with guaranteed coverage. Results showed a Pearson correlation of\n0.68 (traditional TTA). While traditional TTA yielded better point predictions,\nthe multi-sample approach produced slightly tighter confidence intervals (90%,\n95%, 99%) while maintaining coverage. The framework appropriately expressed\nhigher uncertainty for challenging cases. Although anatomical mismatch between\nknee X-rays and standard DXA limits immediate clinical use, this method\nestablishes a foundation for trustworthy AI-assisted BMD screening using\nroutine radiographs, potentially improving early osteoporosis detection.",
    "pdf_url": "http://arxiv.org/pdf/2505.22551v1",
    "published": "2025-05-28T16:33:49+00:00",
    "categories": [
      "cs.CV",
      "stat.AP"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.22550v1",
    "title": "Domain specific ontologies from Linked Open Data (LOD)",
    "authors": [
      "Rosario Uceda-Sosa",
      "Nandana Mihindukulasooriya",
      "Atul Kumar",
      "Sahil Bansal",
      "Seema Nagar"
    ],
    "abstract": "Logical and probabilistic reasoning tasks that require a deeper knowledge of\nsemantics are increasingly relying on general purpose ontologies such as\nWikidata and DBpedia. However, tasks such as entity disambiguation and linking\nmay benefit from domain specific knowledge graphs, which make it more efficient\nto consume the knowledge and easier to extend with proprietary content. We\ndiscuss our experience bootstrapping one such ontology for IT with a\ndomain-agnostic pipeline, and extending it using domain-specific glossaries.",
    "pdf_url": "http://arxiv.org/pdf/2505.22550v1",
    "published": "2025-05-28T16:33:01+00:00",
    "categories": [
      "cs.IR"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2505.22549v1",
    "title": "DES-LOC: Desynced Low Communication Adaptive Optimizers for Training Foundation Models",
    "authors": [
      "Alex Iacob",
      "Lorenzo Sani",
      "Mher Safaryan",
      "Paris Giampouras",
      "Samuel Horv√°th",
      "Andrej Jovanovic",
      "Meghdad Kurmanji",
      "Preslav Aleksandrov",
      "William F. Shen",
      "Xinchi Qiu",
      "Nicholas D. Lane"
    ],
    "abstract": "Scaling foundation model training with Distributed Data Parallel (DDP)\nmethods is bandwidth-limited. Existing infrequent communication methods like\nLocal SGD were designed to synchronize only model parameters and cannot be\ntrivially applied to adaptive optimizers due to additional optimizer states.\nCurrent approaches extending Local SGD either lack convergence guarantees or\nrequire synchronizing all optimizer states, tripling communication costs. We\npropose Desynced Low Communication Adaptive Optimizers (DES-LOC), a family of\noptimizers assigning independent synchronization periods to parameters and\nmomenta, enabling lower communication costs while preserving convergence.\nThrough extensive experiments on language models of up to 1.7B, we show that\nDES-LOC can communicate 170x less than DDP and 2x less than the previous\nstate-of-the-art Local ADAM. Furthermore, unlike previous heuristic approaches,\nDES-LOC is suited for practical training scenarios prone to system failures.\nDES-LOC offers a scalable, bandwidth-efficient, and fault-tolerant solution for\nfoundation model training.",
    "pdf_url": "http://arxiv.org/pdf/2505.22549v1",
    "published": "2025-05-28T16:32:33+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.22548v2",
    "title": "Emotion-o1: Adaptive Long Reasoning for Emotion Understanding in LLMs",
    "authors": [
      "Changhao Song",
      "Yazhou Zhang",
      "Hui Gao",
      "Kaiyun Huang",
      "Peng Zhang"
    ],
    "abstract": "Long chain-of-thought (CoT) reasoning has shown great promise in enhancing\nthe emotion understanding performance of large language models (LLMs). However,\ncurrent fixed-length CoT methods struggle to balance reasoning depth and\nefficiency. Simple tasks (e.g., sentiment classification) are over-reasoned,\nwhile complex tasks (e.g., sarcasm understanding) lack depth. To fill this gap,\nwe present Emotion-o1, an adaptive CoT framework that dynamically adjusts\nreasoning length based on emotion-task complexity. Emotion-o1 is trained by\ndistilling adaptive CoT patterns from a reasoning-oriented LLM, followed by\nsupervised fine-tuning and reinforcement learning with a four-part reward\ntargeting accuracy, brevity, structure, and redundancy. Experimental results on\nfour emotion tasks highlight: (1) Emotion-o1 demonstrates significant\nimprovements over its backbone, with F1 score increases of 10%(Sentiment),\n5%(Emotion), 18%(Humor), and 27%(Sarcasm). (2) In sentiment and sarcasm tasks,\nour 8B model demonstrates superior performance against advanced LLMs,\noutperforming Grok-3 by 1.1% and Claude-3.7 by 2%. (3) The framework maintains\naccuracy while reducing reasoning length by 83% compared to OpenAI-o1,\ndemonstrating effective precision-efficiency optimization. Emotion-o1\neffectively balances reasoning depth and efficiency for emotion understanding\nin LLMs.",
    "pdf_url": "http://arxiv.org/pdf/2505.22548v2",
    "published": "2025-05-28T16:32:16+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.22547v2",
    "title": "First measurement of neutron capture multiplicity in neutrino-oxygen neutral-current quasi-elastic-like interactions using an accelerator neutrino beam",
    "authors": [
      "T2K Collaboration",
      "K. Abe",
      "S. Abe",
      "R. Akutsu",
      "H. Alarakia-Charles",
      "Y. I. Alj Hakim",
      "S. Alonso Monsalve",
      "L. Anthony",
      "M. Antonova",
      "S. Aoki",
      "K. A. Apte",
      "T. Arai",
      "T. Arihara",
      "S. Arimoto",
      "Y. Asada",
      "Y. Ashida",
      "N. Babu",
      "G. Barr",
      "D. Barrow",
      "P. Bates",
      "M. Batkiewicz-Kwasniak",
      "V. Berardi",
      "L. Berns",
      "S. Bordoni",
      "S. B. Boyd",
      "C. Bronner",
      "A. Bubak",
      "M. Buizza Avanzini",
      "J. A. Caballero",
      "N. F. Calabria",
      "S. Cao",
      "D. Carabadjac",
      "S. L. Cartwright",
      "M. P. Casado",
      "M. G. Catanesi",
      "J. Chakrani",
      "A. Chalumeau",
      "P. S. Chong",
      "A. Chvirova",
      "G. Collazuol",
      "F. Cormier",
      "A. Cudd",
      "D. D'ago",
      "C. Dalmazzone",
      "T. Daret",
      "P. Dasgupta",
      "C. Davis",
      "Yu. I. Davydov",
      "A. De Roeck",
      "G. De Rosa",
      "T. Dealtry",
      "C. Densham",
      "A. Dergacheva",
      "R. Dharmapal Banerjee",
      "F. Di Lodovico",
      "G. Diaz Lopez",
      "S. Dolan",
      "D. Douqa",
      "T. A. Doyle",
      "O. Drapier",
      "K. E. Duffy",
      "J. Dumarchez",
      "K. Dygnarowicz",
      "A. Eguchi",
      "J. Elias",
      "S. Emery-Schrenk",
      "G. Erofeev",
      "A. Ershova",
      "G. Eurin",
      "D. Fedorova",
      "S. Fedotov",
      "M. Feltre",
      "L. Feng",
      "D. Ferlewicz",
      "A. J. Finch",
      "G. Fiorillo",
      "M. D. Fitton",
      "J. M. Franco Pati√±o",
      "M. Friend",
      "Y. Fujii",
      "Y. Fukuda",
      "Y. Furui",
      "L. Giannessi",
      "C. Giganti",
      "V. Glagolev",
      "M. Gonin",
      "J. Gonz√°lez Rosa",
      "K. Gorshanov",
      "M. Guigue",
      "D. R. Hadley",
      "J. T. Haigh",
      "S. Han",
      "D. A. Harris",
      "T. Hasegawa",
      "S. Hassani",
      "Y. Hayato",
      "I. Heitkamp",
      "D. Henaff",
      "Y. Hino",
      "M. Hogan",
      "J. Holeczek",
      "A. Holin",
      "T. Holvey",
      "N. T. Hong Van",
      "T. Honjo",
      "K. Hosokawa",
      "J. Hu",
      "A. K. Ichikawa",
      "K. Ieki",
      "M. Ikeda",
      "T. Ishida",
      "M. Ishitsuka",
      "A. Izmaylov",
      "S. J. Jenkins",
      "C. Jes√∫s-Valls",
      "M. Jia",
      "J. J. Jiang",
      "J. Y. Ji",
      "P. Jonsson",
      "S. Joshi",
      "A. C. Kaboth",
      "T. Kajita",
      "H. Kakuno",
      "J. Kameda",
      "S. Karpova",
      "V. S. Kasturi",
      "Y. Kataoka",
      "T. Katori",
      "Y. Kawamura",
      "M. Kawaue",
      "E. Kearns",
      "M. Khabibullin",
      "T. Kikawa",
      "S. King",
      "V. Kiseeva",
      "J. Kisiel",
      "L. Kneale",
      "H. Kobayashi",
      "L. Koch",
      "S. Kodama",
      "M. Kolupanova",
      "A. Konaka",
      "L. L. Kormos",
      "Y. Koshio",
      "T. Koto",
      "K. Kowalik",
      "Y. Kudo",
      "R. Kurjata",
      "V. Kurochka",
      "M. Kuze",
      "M. La Commara",
      "L. Labarga",
      "M. Lachat",
      "K. Lachner",
      "J. Lagoda",
      "S. M. Lakshmi",
      "M. Lamers James",
      "A. Langella",
      "J. -F. Laporte",
      "L. Lavitola",
      "M. Lawe",
      "Y. Lee",
      "D. Leon Silverio",
      "S. Levorato",
      "S. V. Lewis",
      "C. Lin",
      "S. L. Liu",
      "W. Li",
      "A. Longhin",
      "K. R. Long",
      "A. Lopez Moreno",
      "L. Ludovici",
      "X. Lu",
      "T. Lux",
      "L. Magaletti",
      "K. Mahn",
      "K. K. Mahtani",
      "M. Mandal",
      "S. Manly",
      "A. D. Marino",
      "D. G. R. Martin",
      "M. Martini",
      "T. Matsubara",
      "R. Matsumoto",
      "V. Matveev",
      "C. Mauger",
      "K. Mavrokoridis",
      "N. McCauley",
      "J. McKean",
      "A. Mefodiev",
      "P. Mehta",
      "L. Mellet",
      "S. Miki",
      "E. W. Miller",
      "A. Minamino",
      "S. Mine",
      "J. Mirabito",
      "M. Miura",
      "S. Moriyama",
      "S. Moriyama",
      "P. Morrison",
      "Th. A. Mueller",
      "D. Munford",
      "A. Mu√±oz",
      "L. Munteanu",
      "Y. Nagai",
      "T. Nakadaira",
      "K. Nakagiri",
      "M. Nakahata",
      "Y. Nakajima",
      "K. D. Nakamura",
      "Y. Nakano",
      "S. Nakayama",
      "T. Nakaya",
      "K. Nakayoshi",
      "C. E. R. Naseby",
      "D. T. Nguyen",
      "V. Q. Nguyen",
      "S. Nishimori",
      "Y. Nishimura",
      "Y. Noguchi",
      "T. Nosek",
      "P. Novella",
      "J. C. Nugent",
      "H. M. O'Keeffe",
      "L. O'Sullivan",
      "R. Okazaki",
      "W. Okinaga",
      "K. Okumura",
      "T. Okusawa",
      "N. Onda",
      "N. Ospina",
      "L. Osu",
      "Y. Oyama",
      "V. Paolone",
      "J. Pasternak",
      "M. Pfaff",
      "L. Pickering",
      "B. Popov",
      "A. J. Portocarrero Yrey",
      "M. Posiadala-Zezula",
      "Y. S. Prabhu",
      "H. Prasad",
      "F. Pupilli",
      "B. Quilain",
      "P. T. Quyen",
      "E. Radicioni",
      "B. Radics",
      "M. A. Ramirez",
      "P. N. Ratoff",
      "M. Reh",
      "C. Riccio",
      "E. Rondio",
      "S. Roth",
      "N. Roy",
      "L. Russo",
      "A. Rychter",
      "W. Saenz",
      "K. Sakashita",
      "E. M. Sandford",
      "Y. Sato",
      "T. Schefke",
      "C. M. Schloesser",
      "K. Scholberg",
      "M. Scott",
      "Y. Seiya",
      "T. Sekiguchi",
      "H. Sekiya",
      "D. Sgalaberna",
      "M. Shiozawa",
      "Y. Shiraishi",
      "A. Shvartsman",
      "N. Skrobova",
      "K. Skwarczynski",
      "D. Smyczek",
      "M. Smy",
      "J. T. Sobczyk",
      "H. Sobel",
      "F. J. P. Soler",
      "A. J. Speers",
      "R. Spina",
      "Y. Stroke",
      "I. A. Suslov",
      "A. Suzuki",
      "S. Y. Suzuki",
      "M. Tada",
      "S. Tairafune",
      "A. Takeda",
      "Y. Takeuchi",
      "K. Takifuji",
      "H. K. Tanaka",
      "H. Tanigawa",
      "A. Teklu",
      "V. V. Tereshchenko",
      "N. Thamm",
      "N. Tran",
      "T. Tsukamoto",
      "Y. Uchida",
      "M. Vagins",
      "M. Varghese",
      "E. Villa",
      "U. Virginet",
      "T. Vladisavljevic",
      "T. Wachala",
      "D. Wakabayashi",
      "H. T. Wallace",
      "J. G. Walsh",
      "L. Wan",
      "D. Wark",
      "A. Weber",
      "R. Wendell",
      "M. J. Wilking",
      "C. Wilkinson",
      "J. R. Wilson",
      "K. Wood",
      "C. Wret",
      "J. Xia",
      "K. Yamamoto",
      "T. Yamamoto",
      "T. Yamamoto",
      "C. Yanagisawa",
      "T. Yano",
      "N. Yershov",
      "U. Yevarouskaya",
      "M. Yokoyama",
      "Y. Yoshimoto",
      "N. Yoshimura",
      "R. Zaki",
      "A. Zalewska",
      "J. Zalipska",
      "G. Zarnecki",
      "J. Zhang",
      "X. Y. Zhao",
      "H. Zhong",
      "T. Zhu",
      "M. Ziembicki",
      "E. D. Zimmerman",
      "M. Zito",
      "S. Zsoldos"
    ],
    "abstract": "We report the first measurement of neutron capture multiplicity in\nneutrino-oxygen neutral-current quasi-elastic-like interactions at the\ngadolinium-loaded Super-Kamiokande detector using the T2K neutrino beam, which\nhas a peak energy of about 0.6 GeV. A total of 30 neutral-current\nquasi-elastic-like event candidates were selected from T2K data corresponding\nto an exposure of $1.76\\times10^{20}$ protons on target. The $\\gamma$ ray\nsignals resulting from neutron captures were identified using a neural network.\nThe flux-averaged mean neutron capture multiplicity was measured to be\n$1.37\\pm0.33\\text{ (stat.)}$$^{+0.17}_{-0.27}\\text{ (syst.)}$, which is\ncompatible within $2.3\\,\\sigma$ than predictions obtained using our nominal\nsimulation. We discuss potential sources of systematic uncertainty in the\nprediction and demonstrate that a significant portion of this discrepancy\narises from the modeling of hadron-nucleus interactions in the detector medium.",
    "pdf_url": "http://arxiv.org/pdf/2505.22547v2",
    "published": "2025-05-28T16:32:06+00:00",
    "categories": [
      "hep-ex",
      "physics.ins-det"
    ],
    "primary_category": "hep-ex"
  },
  {
    "id": "http://arxiv.org/abs/2505.22546v1",
    "title": "Prediction and Synthesis of Mg$_4$Pt$_3$H$_6$: A Metallic Complex Transition Metal Hydride Stabilized at Ambient Pressure",
    "authors": [
      "Wencheng Lu",
      "Michael J. Hutcheon",
      "Mads F. Hansen",
      "Kapildeb Dolui",
      "Shubham Sinha",
      "Mihir R. Sahoo",
      "Chris J. Pickard",
      "Christoph Heil",
      "Anna Pakhomova",
      "Mohamed Mezouar",
      "Dominik Daisenberger",
      "Stella Chariton",
      "Vitali Prakapenka",
      "Matthew N. Julian",
      "Rohit P. Prasankumar",
      "Timothy A. Strobel"
    ],
    "abstract": "The low-pressure stabilization of superconducting hydrides with high critical\ntemperatures ($T_c$s) remains a significant challenge, and experimentally\nverified superconducting hydrides are generally constrained to a limited number\nof structural prototypes. Ternary transition-metal complex hydrides (hydrido\ncomplexes)-typically regarded as hydrogen storage materials-exhibit a large\nrange of compounds stabilized at low pressure with recent predictions for\nhigh-$T_c$ superconductivity. Motivated by this class of materials, we\ninvestigated complex hydride formation in the Mg-Pt-H system, which has no\nknown ternary hydride compounds. Guided by ab initio structural predictions, we\nsuccessfully synthesized a novel complex transition-metal hydride,\nMg$_4$Pt$_3$H$_6$, using laser-heated diamond anvil cells. The compound forms\nin a body-centered cubic structural prototype at moderate pressures between\n8-25 GPa. Unlike the majority of known hydrido complexes, Mg$_4$Pt$_3$H$_6$ is\nmetallic, with formal charge described as 4[Mg]$^{2+}$.3[PtH$_2$]$^{2-}$. X-ray\ndiffraction (XRD) measurements obtained during decompression reveal that\nMg$_4$Pt$_3$H$_6$ remains stable upon quenching to ambient conditions.\nMagnetic-field and temperature-dependent electrical transport measurements\nindicate ambient-pressure superconductivity with $T_c$ (50%) = 2.9 K, in\nreasonable agreement with theoretical calculations. These findings clarify the\nphase behavior in the Mg-Pt-H system and provide valuable insights for\ntransition-metal complex hydrides as a new class of hydrogen-rich\nsuperconductors.",
    "pdf_url": "http://arxiv.org/pdf/2505.22546v1",
    "published": "2025-05-28T16:28:16+00:00",
    "categories": [
      "cond-mat.supr-con",
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.supr-con"
  },
  {
    "id": "http://arxiv.org/abs/2505.22545v1",
    "title": "The Optical Design of the Carbon Investigation(Carbon-I) Imaging Spectrometer",
    "authors": [
      "Christine L. Bradley",
      "Rami W. Wehbe",
      "Matthew Smith",
      "Sharmila Padmanabhan",
      "Valerie Scott",
      "David R. Thompson",
      "Daniel W. Wilson",
      "Pantazis Mouroulis",
      "Robert O. Green",
      "Christian Frankenberg"
    ],
    "abstract": "The proposed Carbon Investigation (Carbon-I) Imaging Spectrometer is designed\nto measure variations of greenhouse gases in Earth's atmosphere. The instrument\nwill survey the Earth from its own spacecraft at an altitude of approximately\n610 km. It will use a coarse ground sampling distance (GSD) of <400 m in global\nmode for land and coastal monitoring and finer 35 m GSD in target mode to\nsample key regions. The identification and quantification of greenhouse gases\nrequire continuous spectral sampling over the 2040-2380 nm wavelength range\nwith <1 nm spectral sampling. The proposed design builds upon Jet Propulsion\nLaboratory's (JPL) experience of spaceflight Dyson imaging spectrometers to\nachieve spectral sampling of 0.7 nm per pixel. This paper presents the proposed\nCarbon-I optical design comprised of a freeform three-mirror anastigmat\ntelescope that couples to a F/2.2, highly uniform Dyson-inspired imaging\nspectrometer. The high uniformity and throughput enables Carbon-I to measure\nEarth's greenhouse gas concentrations with unprecedented precision and spatial\nsampling.",
    "pdf_url": "http://arxiv.org/pdf/2505.22545v1",
    "published": "2025-05-28T16:25:29+00:00",
    "categories": [
      "physics.optics",
      "astro-ph.IM"
    ],
    "primary_category": "physics.optics"
  },
  {
    "id": "http://arxiv.org/abs/2505.22544v1",
    "title": "Nonlinear time-reversal symmetry breaking in kagome spin ice HoAgGe",
    "authors": [
      "Kan Zhao",
      "Hao Deng",
      "Hua Chen",
      "Nvsen Ma",
      "Noah Oefele",
      "Jiesen Guo",
      "Xueling Cui",
      "Chen Tang",
      "Matthias J. Gutmann",
      "Thomas Mueller",
      "Yixi Su",
      "Vladimir Hutanu",
      "Changqing Jin",
      "Philipp Gegenwart"
    ],
    "abstract": "Kagome spin ice is an intriguing class of spin systems constituted by\nin-plane Ising spins with ferromagnetic interaction residing on the kagome\nlattice, theoretically predicted to host a plethora of magnetic transitions and\nexcitations. In particular, different variants of kagome spin ice models can\nexhibit different sequences of symmetry breaking upon cooling from the\nparamagnetic to the fully ordered ground state. Recently, it has been\ndemonstrated that the frustrated intermetallic HoAgGe stands as a faithful\nsolid-state realization of kagome spin ice. Here we use single crystal neutron\ndiffuse scattering to map the spin ordering of HoAgGe at various temperatures\nmore accurately and surprisingly find that the ordering sequence appears to be\ndifferent from previously known scenarios: From the paramagnetic state, the\nsystem first enters a partially ordered state with fluctuating magnetic\ncharges, in contrast to a charge-ordered paramagnetic phase before reaching the\nfully ordered state. Through state-of-the-art Monte Carlo simulations and\nscaling analyses using a quasi-2D model for the distorted Kagome spin ice in\nHoAgGe, we elucidate a single three-dimensional (3D) XY phase transition into\nthe ground state with broken time-reversal symmetry (TRS). However, the 3D XY\ntransition has a long crossover tail before the fluctuating magnetic charges\nfully order. More interestingly, we find both experimentally and theoretically\nthat the TRS breaking phase of HoAgGe features an unusual, hysteretic response:\nIn spite of their vanishing magnetization, the two time-reversal partners are\ndistinguished and selected by a nonlinear magnetic susceptibility tied to the\nkagome ice rule. Our discovery not only unveils a new symmetry breaking\nhierarchy of kagome spin ice, but also demonstrates the potential of\nTRS-breaking frustrated spin systems for information technology applications.",
    "pdf_url": "http://arxiv.org/pdf/2505.22544v1",
    "published": "2025-05-28T16:25:28+00:00",
    "categories": [
      "cond-mat.str-el",
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.str-el"
  },
  {
    "id": "http://arxiv.org/abs/2505.22543v1",
    "title": "Scaling-up Perceptual Video Quality Assessment",
    "authors": [
      "Ziheng Jia",
      "Zicheng Zhang",
      "Zeyu Zhang",
      "Yingji Liang",
      "Xiaorong Zhu",
      "Chunyi Li",
      "Jinliang Han",
      "Haoning Wu",
      "Bin Wang",
      "Haoran Zhang",
      "Guanyu Zhu",
      "Qiyong Zhao",
      "Xiaohong Liu",
      "Guangtao Zhai",
      "Xiongkuo Min"
    ],
    "abstract": "The data scaling law has been shown to significantly enhance the performance\nof large multi-modal models (LMMs) across various downstream tasks. However, in\nthe domain of perceptual video quality assessment (VQA), the potential of\nscaling law remains unprecedented due to the scarcity of labeled resources and\nthe insufficient scale of datasets. To address this, we propose\n\\textbf{OmniVQA}, an efficient framework designed to efficiently build\nhigh-quality, human-in-the-loop VQA multi-modal instruction databases (MIDBs).\nWe then scale up to create \\textbf{OmniVQA-Chat-400K}, the largest MIDB in the\nVQA field concurrently. Our focus is on the technical and aesthetic quality\ndimensions, with abundant in-context instruction data to provide fine-grained\nVQA knowledge. Additionally, we have built the \\textbf{OmniVQA-MOS-20K} dataset\nto enhance the model's quantitative quality rating capabilities. We then\nintroduce a \\textbf{complementary} training strategy that effectively leverages\nthe knowledge from datasets for quality understanding and quality rating tasks.\nFurthermore, we propose the \\textbf{OmniVQA-FG (fine-grain)-Benchmark} to\nevaluate the fine-grained performance of the models. Our results demonstrate\nthat our models achieve state-of-the-art performance in both quality\nunderstanding and rating tasks.",
    "pdf_url": "http://arxiv.org/pdf/2505.22543v1",
    "published": "2025-05-28T16:24:52+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.23844v1",
    "title": "Enabling Flexible Multi-LLM Integration for Scalable Knowledge Aggregation",
    "authors": [
      "Zhenglun Kong",
      "Zheng Zhan",
      "Shiyue Hou",
      "Yifan Gong",
      "Xin Meng",
      "Pengwei Sui",
      "Peiyan Dong",
      "Xuan Shen",
      "Zifeng Wang",
      "Pu Zhao",
      "Hao Tang",
      "Stratis Ioannidis",
      "Yanzhi Wang"
    ],
    "abstract": "Large language models (LLMs) have shown remarkable promise but remain\nchallenging to continually improve through traditional finetuning, particularly\nwhen integrating capabilities from other specialized LLMs. Popular methods like\nensemble and weight merging require substantial memory and struggle to adapt to\nchanging data environments. Recent efforts have transferred knowledge from\nmultiple LLMs into a single target model; however, they suffer from\ninterference and degraded performance among tasks, largely due to limited\nflexibility in candidate selection and training pipelines. To address these\nissues, we propose a framework that adaptively selects and aggregates knowledge\nfrom diverse LLMs to build a single, stronger model, avoiding the high memory\noverhead of ensemble and inflexible weight merging. Specifically, we design an\nadaptive selection network that identifies the most relevant source LLMs based\non their scores, thereby reducing knowledge interference. We further propose a\ndynamic weighted fusion strategy that accounts for the inherent strengths of\ncandidate LLMs, along with a feedback-driven loss function that prevents the\nselector from converging on a single subset of sources. Experimental results\ndemonstrate that our method can enable a more stable and scalable knowledge\naggregation process while reducing knowledge interference by up to 50% compared\nto existing approaches. Code is avaliable at\nhttps://github.com/ZLKong/LLM_Integration",
    "pdf_url": "http://arxiv.org/pdf/2505.23844v1",
    "published": "2025-05-28T16:24:50+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.22542v2",
    "title": "Renormalizing the Quark-Meson-Diquark Model",
    "authors": [
      "Hosein Gholami",
      "Lennart Kurth",
      "Ugo Mire",
      "Michael Buballa",
      "Bernd-Jochen Schaefer"
    ],
    "abstract": "We present a comprehensive study of the two-flavor Quark--Meson--Diquark\n(QMD) model by comparing a renormalization approach with a\nrenormalization-group (RG) consistent mean-field formulation based on the\nfunctional renormalization group (FRG). The renormalized QMD model allows\nanalytical investigations of key quantities such as the zero-temperature\ndiquark gap and the critical temperature for color superconductivity,\nultimately reproducing the exact BCS relation in the high-density limit. We\ncarry out the same analysis for different schemes of RG-consistent QMD models.\nWe show that the RG-consistent approach yields a phase diagram and\nthermodynamic properties qualitatively similar to those of the renormalized\nmodel, provided both are embedded within a unified scheme that ensures\nconsistent vacuum properties. In particular, both treatments recover the\nStefan--Boltzmann limit at high densities. On the other hand, whether the BCS\nrelation for the critical temperature is satisfied depends on the details of\nthe RG-consistent setup. Our results highlight the relevance of renormalization\nand RG-consistent methods for accurately capturing the thermodynamics of QMD\nand related effective models with diquark degrees of freedom.",
    "pdf_url": "http://arxiv.org/pdf/2505.22542v2",
    "published": "2025-05-28T16:24:49+00:00",
    "categories": [
      "hep-ph",
      "hep-th",
      "nucl-th"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.22541v1",
    "title": "A Human-Centric Approach to Explainable AI for Personalized Education",
    "authors": [
      "Vinitra Swamy"
    ],
    "abstract": "Deep neural networks form the backbone of artificial intelligence research,\nwith potential to transform the human experience in areas ranging from\nautonomous driving to personal assistants, healthcare to education. However,\ntheir integration into the daily routines of real-world classrooms remains\nlimited. It is not yet common for a teacher to assign students individualized\nhomework targeting their specific weaknesses, provide students with instant\nfeedback, or simulate student responses to a new exam question. While these\nmodels excel in predictive performance, this lack of adoption can be attributed\nto a significant weakness: the lack of explainability of model decisions,\nleading to a lack of trust from students, parents, and teachers. This thesis\naims to bring human needs to the forefront of eXplainable AI (XAI) research,\ngrounded in the concrete use case of personalized learning and teaching. We\nframe the contributions along two verticals: technical advances in XAI and\ntheir aligned human studies. We investigate explainability in AI for education,\nrevealing systematic disagreements between post-hoc explainers and identifying\na need for inherently interpretable model architectures. We propose four novel\ntechnical contributions in interpretability with a multimodal modular\narchitecture (MultiModN), an interpretable mixture-of-experts model\n(InterpretCC), adversarial training for explainer stability, and a\ntheory-driven LLM-XAI framework to present explanations to students\n(iLLuMinaTE), which we evaluate in diverse settings with professors, teachers,\nlearning scientists, and university students. By combining empirical\nevaluations of existing explainers with novel architectural designs and human\nstudies, our work lays a foundation for human-centric AI systems that balance\nstate-of-the-art performance with built-in transparency and trust.",
    "pdf_url": "http://arxiv.org/pdf/2505.22541v1",
    "published": "2025-05-28T16:23:48+00:00",
    "categories": [
      "cs.LG",
      "cs.CY"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.22540v1",
    "title": "A Graph-Based Laser Path Solver Algorithm for Virtual Reality Laboratory Simulations",
    "authors": [
      "Andreas M√ºller",
      "Stefan Mueller",
      "Tobias Brixner",
      "Sebastian von Mammen"
    ],
    "abstract": "femtoPro is an interactive virtual reality (VR) laser laboratory balancing\nthe contrasting challenges of accuracy and computational efficiency in optics\nsimulations. It can simulate linear and nonlinear optical phenomena in real\ntime, a task that pushes the boundaries of current consumer hardware. This\npaper details the concept, implementation, and evaluation of a dynamic\ngraph-based solution tailored to the specific requirements and challenges of\nthe simulation. Resource usage is optimized through a selective updating\nstrategy that identifies and preserves laser paths unchanged between simulation\nframes, eliminating the need for unnecessary recalculations. Benchmarking of\nreal-world scenarios confirms that our approach delivers a smooth user\nexperience, even on mobile VR platforms with limited computing power. The\nmethodologies, solutions and insights outlined in this paper may be applicable\nto other interactive, dynamic graph-based real-time simulations.",
    "pdf_url": "http://arxiv.org/pdf/2505.22540v1",
    "published": "2025-05-28T16:23:32+00:00",
    "categories": [
      "physics.optics",
      "physics.ed-ph"
    ],
    "primary_category": "physics.optics"
  },
  {
    "id": "http://arxiv.org/abs/2505.22539v1",
    "title": "Spot-On: A Mixed Reality Interface for Multi-Robot Cooperation",
    "authors": [
      "Tim Engelbracht",
      "Petar Lukovic",
      "Tjark Behrens",
      "Kai Lascheit",
      "Ren√© Zurbr√ºgg",
      "Marc Pollefeys",
      "Hermann Blum",
      "Zuria Bauer"
    ],
    "abstract": "Recent progress in mixed reality (MR) and robotics is enabling increasingly\nsophisticated forms of human-robot collaboration. Building on these\ndevelopments, we introduce a novel MR framework that allows multiple quadruped\nrobots to operate in semantically diverse environments via a MR interface. Our\nsystem supports collaborative tasks involving drawers, swing doors, and\nhigher-level infrastructure such as light switches. A comprehensive user study\nverifies both the design and usability of our app, with participants giving a\n\"good\" or \"very good\" rating in almost all cases. Overall, our approach\nprovides an effective and intuitive framework for MR-based multi-robot\ncollaboration in complex, real-world scenarios.",
    "pdf_url": "http://arxiv.org/pdf/2505.22539v1",
    "published": "2025-05-28T16:23:28+00:00",
    "categories": [
      "cs.HC",
      "cs.RO"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2505.22538v1",
    "title": "Uncertainty Quantification with Proper Scoring Rules: Adjusting Measures to Prediction Tasks",
    "authors": [
      "Paul Hofman",
      "Yusuf Sale",
      "Eyke H√ºllermeier"
    ],
    "abstract": "We address the problem of uncertainty quantification and propose measures of\ntotal, aleatoric, and epistemic uncertainty based on a known decomposition of\n(strictly) proper scoring rules, a specific type of loss function, into a\ndivergence and an entropy component. This leads to a flexible framework for\nuncertainty quantification that can be instantiated with different losses\n(scoring rules), which makes it possible to tailor uncertainty quantification\nto the use case at hand. We show that this flexibility is indeed advantageous.\nIn particular, we analyze the task of selective prediction and show that the\nscoring rule should ideally match the task loss. In addition, we perform\nexperiments on two other common tasks. For out-of-distribution detection, our\nresults confirm that a widely used measure of epistemic uncertainty, mutual\ninformation, performs best. Moreover, in the setting of active learning, our\nmeasure of epistemic uncertainty based on the zero-one-loss consistently\noutperforms other uncertainty measures.",
    "pdf_url": "http://arxiv.org/pdf/2505.22538v1",
    "published": "2025-05-28T16:22:53+00:00",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.22537v1",
    "title": "ConfLUNet: Multiple sclerosis lesion instance segmentation in presence of confluent lesions",
    "authors": [
      "Maxence Wynen",
      "Pedro M. Gordaliza",
      "Maxime Istasse",
      "Anna St√∂lting",
      "Pietro Maggi",
      "Beno√Æt Macq",
      "Meritxell Bach Cuadra"
    ],
    "abstract": "Accurate lesion-level segmentation on MRI is critical for multiple sclerosis\n(MS) diagnosis, prognosis, and disease monitoring. However, current evaluation\npractices largely rely on semantic segmentation post-processed with connected\ncomponents (CC), which cannot separate confluent lesions (aggregates of\nconfluent lesion units, CLUs) due to reliance on spatial connectivity. To\naddress this misalignment with clinical needs, we introduce formal definitions\nof CLUs and associated CLU-aware detection metrics, and include them in an\nexhaustive instance segmentation evaluation framework. Within this framework,\nwe systematically evaluate CC and post-processing-based Automated Confluent\nSplitting (ACLS), the only existing methods for lesion instance segmentation in\nMS. Our analysis reveals that CC consistently underestimates CLU counts, while\nACLS tends to oversplit lesions, leading to overestimated lesion counts and\nreduced precision. To overcome these limitations, we propose ConfLUNet, the\nfirst end-to-end instance segmentation framework for MS lesions. ConfLUNet\njointly optimizes lesion detection and delineation from a single FLAIR image.\nTrained on 50 patients, ConfLUNet significantly outperforms CC and ACLS on the\nheld-out test set (n=13) in instance segmentation (Panoptic Quality: 42.0% vs.\n37.5%/36.8%; p = 0.017/0.005) and lesion detection (F1: 67.3% vs. 61.6%/59.9%;\np = 0.028/0.013). For CLU detection, ConfLUNet achieves the highest F1[CLU]\n(81.5%), improving recall over CC (+12.5%, p = 0.015) and precision over ACLS\n(+31.2%, p = 0.003). By combining rigorous definitions, new CLU-aware metrics,\na reproducible evaluation framework, and the first dedicated end-to-end model,\nthis work lays the foundation for lesion instance segmentation in MS.",
    "pdf_url": "http://arxiv.org/pdf/2505.22537v1",
    "published": "2025-05-28T16:22:27+00:00",
    "categories": [
      "eess.IV"
    ],
    "primary_category": "eess.IV"
  },
  {
    "id": "http://arxiv.org/abs/2505.22536v1",
    "title": "Quantum engineering of high harmonic generation",
    "authors": [
      "Neda Boroumand",
      "Adam Thorpe",
      "Graeme Bart",
      "Lu Wang",
      "David N. Purschke",
      "Giulio Vampa",
      "Thomas Brabec"
    ],
    "abstract": "In quantum sideband high harmonic generation (QSHHG), high harmonic\ngeneration is perturbed by a bright quantum field resulting in harmonic\nsidebands, with the intent to transfer non-classical properties from the\nquantum perturbation to the harmonic sidebands. So far, non-classical features\nhave not been found in QSHHG yet. The closed form theory of QSHHG in atoms and\nsolids developed here answers the question under which conditions non-classical\nfeatures can be realized. QSHHG results in a multi-mode entanglement between\nharmonic sideband modes and perturbative quantum mode. A projective measurement\non either creates a variety of non-classical states commonly used in quantum\ninformation science. This opens a pathway towards quantum engineering high\nharmonic generation as a short wavelength source for quantum information\nscience.",
    "pdf_url": "http://arxiv.org/pdf/2505.22536v1",
    "published": "2025-05-28T16:22:01+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.22535v2",
    "title": "RiverMamba: A State Space Model for Global River Discharge and Flood Forecasting",
    "authors": [
      "Mohamad Hakam Shams Eddin",
      "Yikui Zhang",
      "Stefan Kollet",
      "Juergen Gall"
    ],
    "abstract": "Recent deep learning approaches for river discharge forecasting have improved\nthe accuracy and efficiency in flood forecasting, enabling more reliable early\nwarning systems for risk management. Nevertheless, existing deep learning\napproaches in hydrology remain largely confined to local-scale applications and\ndo not leverage the inherent spatial connections of bodies of water. Thus,\nthere is a strong need for new deep learning methodologies that are capable of\nmodeling spatio-temporal relations to improve river discharge and flood\nforecasting for scientific and operational applications. To address this, we\npresent RiverMamba, a novel deep learning model that is pretrained with\nlong-term reanalysis data and that can forecast global river discharge and\nfloods on a $0.05^\\circ$ grid up to 7 days lead time, which is of high\nrelevance in early warning. To achieve this, RiverMamba leverages efficient\nMamba blocks that enable the model to capture global-scale channel network\nrouting and enhance its forecast capability for longer lead times. The forecast\nblocks integrate ECMWF HRES meteorological forecasts, while accounting for\ntheir inaccuracies through spatio-temporal modeling. Our analysis demonstrates\nthat RiverMamba delivers reliable predictions of river discharge, including\nextreme floods across return periods and lead times, surpassing both\noperational AI- and physics-based models.",
    "pdf_url": "http://arxiv.org/pdf/2505.22535v2",
    "published": "2025-05-28T16:21:58+00:00",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.22534v2",
    "title": "Bayesian reconstruction of primordial perturbations from induced gravitational waves",
    "authors": [
      "Aya Ghaleb",
      "Ameek Malhotra",
      "Gianmassimo Tasinato",
      "Ivonne Zavala"
    ],
    "abstract": "The formation of primordial black holes or other dark matter relics from\namplified density fluctuations in the early universe may also generate\nscalar-induced gravitational waves (GW), carrying vital information about the\nprimordial power spectrum and the early expansion history of our universe. We\npresent a Bayesian approach aimed at reconstructing both the shape of the\nscalar power spectrum and the universe's equation of state from GW\nobservations, using interpolating splines to flexibly capture features in the\nGW data. The optimal number of spline nodes is chosen via Bayesian evidence,\naiming at balancing complexity of the model and the fidelity of the\nreconstruction. We test our method using both representative mock data and\nrecent Pulsar Timing Array measurements, demonstrating that it can accurately\nreconstruct the curvature power spectrum as well as the underlying equation of\nstate, if different from radiation.",
    "pdf_url": "http://arxiv.org/pdf/2505.22534v2",
    "published": "2025-05-28T16:21:00+00:00",
    "categories": [
      "astro-ph.CO",
      "gr-qc"
    ],
    "primary_category": "astro-ph.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.22700v1",
    "title": "Aggregation of vortex structures in 2D: the blob-wave system and its role in zonal flows",
    "authors": [
      "Franco Flandoli",
      "Matteo Palmieri",
      "Milo Viviani"
    ],
    "abstract": "We give a rigorous mathematical result, supported by accurate numerical\nsimulations, of the aggregation of a concentrated vortex blob with an\nunderlying non constant vorticity field: the blob moves in the direction of the\ngradient of the field. It is a unique example of Lagrangian explanation of\naggregation of vortex structures of the same sign in 2D inviscid fluids. A\nconceptual model of zonal flow maintenance and modulation based on this idea is\nthen developed, which produces shapes in accordance with observations.",
    "pdf_url": "http://arxiv.org/pdf/2505.22700v1",
    "published": "2025-05-28T16:20:19+00:00",
    "categories": [
      "math-ph",
      "math.MP",
      "physics.flu-dyn"
    ],
    "primary_category": "math-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.22533v1",
    "title": "TabularQGAN: A Quantum Generative Model for Tabular Data",
    "authors": [
      "Pallavi Bhardwaj",
      "Caitlin Jones",
      "Lasse Dierich",
      "Aleksandar Vuƒçkoviƒá"
    ],
    "abstract": "In this paper, we introduce a novel quantum generative model for synthesizing\ntabular data. Synthetic data is valuable in scenarios where real-world data is\nscarce or private, it can be used to augment or replace existing datasets.\nReal-world enterprise data is predominantly tabular and heterogeneous, often\ncomprising a mixture of categorical and numerical features, making it highly\nrelevant across various industries such as healthcare, finance, and software.\nWe propose a quantum generative adversarial network architecture with flexible\ndata encoding and a novel quantum circuit ansatz to effectively model tabular\ndata. The proposed approach is tested on the MIMIC III healthcare and Adult\nCensus datasets, with extensive benchmarking against leading classical models,\nCTGAN, and CopulaGAN. Experimental results demonstrate that our quantum model\noutperforms classical models by an average of 8.5% with respect to an overall\nsimilarity score from SDMetrics, while using only 0.072% of the parameters of\nthe classical models. Additionally, we evaluate the generalization capabilities\nof the models using two custom-designed metrics that demonstrate the ability of\nthe proposed quantum model to generate useful and novel samples. To our\nknowledge, this is one of the first demonstrations of a successful quantum\ngenerative model for handling tabular data, indicating that this task could be\nwell-suited to quantum computers.",
    "pdf_url": "http://arxiv.org/pdf/2505.22533v1",
    "published": "2025-05-28T16:19:39+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "quant-ph"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.22532v1",
    "title": "Gautschi-type and implicit-explicit integrators for constrained wave equations",
    "authors": [
      "R. Altmann",
      "B. D√∂rich",
      "C. Zimmer"
    ],
    "abstract": "This paper deals with the construction and analysis of two integrators for\n(semi-linear) second-order partial differential-algebraic equations of\nsemi-explicit type. More precisely, we consider an implicit-explicit\nCrank-Nicolson scheme as well as an exponential integrator of Gautschi type.\nFor this, well-known wave integrators for unconstrained systems are combined\nwith techniques known from the field of differential-algebraic equations. The\nresult are efficient time stepping schemes, which are provable of second order.\nMoreover, we discuss the practical implementation of the Gautschi-type method,\nwhich involves the solution of certain saddle point problems. The theoretical\nresults are verified by numerical experiments for the the wave equation with\nkinetic boundary conditions.",
    "pdf_url": "http://arxiv.org/pdf/2505.22532v1",
    "published": "2025-05-28T16:19:22+00:00",
    "categories": [
      "math.NA",
      "cs.NA"
    ],
    "primary_category": "math.NA"
  },
  {
    "id": "http://arxiv.org/abs/2505.22531v2",
    "title": "Training RL Agents for Multi-Objective Network Defense Tasks",
    "authors": [
      "Andres Molina-Markham",
      "Luis Robaina",
      "Sean Steinle",
      "Akash Trivedi",
      "Derek Tsui",
      "Nicholas Potteiger",
      "Lauren Brandt",
      "Ransom Winder",
      "Ahmad Ridley"
    ],
    "abstract": "Open-ended learning (OEL) -- which emphasizes training agents that achieve\nbroad capability over narrow competency -- is emerging as a paradigm to develop\nartificial intelligence (AI) agents to achieve robustness and generalization.\nHowever, despite promising results that demonstrate the benefits of OEL,\napplying OEL to develop autonomous agents for real-world cybersecurity\napplications remains a challenge.\n  We propose a training approach, inspired by OEL, to develop autonomous\nnetwork defenders. Our results demonstrate that like in other domains, OEL\nprinciples can translate into more robust and generalizable agents for cyber\ndefense. To apply OEL to network defense, it is necessary to address several\ntechnical challenges. Most importantly, it is critical to provide a task\nrepresentation approach over a broad universe of tasks that maintains a\nconsistent interface over goals, rewards and action spaces. This way, the\nlearning agent can train with varying network conditions, attacker behaviors,\nand defender goals while being able to build on previously gained knowledge.\n  With our tools and results, we aim to fundamentally impact research that\napplies AI to solve cybersecurity problems. Specifically, as researchers\ndevelop gyms and benchmarks for cyber defense, it is paramount that they\nconsider diverse tasks with consistent representations, such as those we\npropose in our work.",
    "pdf_url": "http://arxiv.org/pdf/2505.22531v2",
    "published": "2025-05-28T16:18:21+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.22530v1",
    "title": "Amalgamations along surfaces with boundary in a handlebody",
    "authors": [
      "Siqi Ding",
      "Fengchun Lei",
      "Wei Lin",
      "Andrei Vesnin"
    ],
    "abstract": "Let M be a connected orientable 3-manifold, and F a compact connected\norientable surface properly embedded in M. If F cuts M into two connected\n3-manifolds X and Y, that is, M=X \\cup_F Y, we say that M is an amalgamation of\nX and Y along F; and if F cuts M into a connected 3-manifold X, we say that M\nis a self-amalgamation of X along F. A characterization of an amalgamation of\ntwo handlebodies along a surface, incompressible in both, to be a handlebody\nwas obtained by Lei, Liu, Li, and Vesnin. The case of amalgamation of two\nhandelbodies along a compressional surface was studdied by Xu, Fang, and Lei.\nIn the present paper, a characterization of an amalgamation and\nself-amalgamation of a handlebody to be a handlebody is given.",
    "pdf_url": "http://arxiv.org/pdf/2505.22530v1",
    "published": "2025-05-28T16:16:58+00:00",
    "categories": [
      "math.GT",
      "57N10"
    ],
    "primary_category": "math.GT"
  },
  {
    "id": "http://arxiv.org/abs/2505.22529v1",
    "title": "Discrete Boltzmann Equation for Anyons",
    "authors": [
      "Niclas Bernhoff"
    ],
    "abstract": "A semi-classical approach to the study of the evolution of anyonic\nexcitations--elementary particles with fractional statistics, complementing\nbosons and fermions--is through the Boltzmann equation for anyons. This work\nreviews a discretized version--a system of partial differential equations--of\nsuch a quantum equation. Trend to equilibrium is studied for a planar\nstationary system, as well as the spatially homogeneous system. Essential\nproperties of the linearized operator are proven, implying that results for\ngeneral steady half-space problems for the discrete Boltzmann equation in a\nslab geometry can be applied.",
    "pdf_url": "http://arxiv.org/pdf/2505.22529v1",
    "published": "2025-05-28T16:15:31+00:00",
    "categories": [
      "math-ph",
      "math.MP",
      "82C40 (Primary) 82C10, 81Q10 (Secondary)"
    ],
    "primary_category": "math-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.22528v1",
    "title": "$Œ¥$-invariants of log Fano planes",
    "authors": [
      "Elena Denisova"
    ],
    "abstract": "We compute the $\\delta$-invariant for pairs $(\\mathbb{P}^2, \\lambda C_d)$,\nwhere $C_d$ is a plane curve of degree $d \\leq 4$. These computations provide\nnew examples of $K$-stable and $K$-semistable log Fano pairs, and contribute to\nthe study of $K$-stability of log Fano varieties via the Abban-Zhuang method,\nwhich reduces higher-dimensional problems to the surface case.",
    "pdf_url": "http://arxiv.org/pdf/2505.22528v1",
    "published": "2025-05-28T16:14:36+00:00",
    "categories": [
      "math.AG",
      "14J45, 32Q20, 14E05, 14J17"
    ],
    "primary_category": "math.AG"
  },
  {
    "id": "http://arxiv.org/abs/2505.22527v1",
    "title": "Symplectic Generative Networks (SGNs): A Hamiltonian Framework for Invertible Deep Generative Modeling",
    "authors": [
      "Agnideep Aich",
      "Ashit Aich",
      "Bruce Wade"
    ],
    "abstract": "We introduce the Symplectic Generative Network (SGN), a deep generative model\nthat leverages Hamiltonian mechanics to construct an invertible,\nvolume-preserving mapping between a latent space and the data space. By\nendowing the latent space with a symplectic structure and modeling data\ngeneration as the time evolution of a Hamiltonian system, SGN achieves exact\nlikelihood evaluation without incurring the computational overhead of Jacobian\ndeterminant calculations. In this work, we provide a rigorous mathematical\nfoundation for SGNs through a comprehensive theoretical framework that\nincludes: (i) complete proofs of invertibility and volume preservation, (ii) a\nformal complexity analysis with theoretical comparisons to Variational\nAutoencoders and Normalizing Flows, (iii) strengthened universal approximation\nresults with quantitative error bounds, (iv) an information-theoretic analysis\nbased on the geometry of statistical manifolds, and (v) an extensive stability\nanalysis with adaptive integration guarantees. These contributions highlight\nthe fundamental advantages of SGNs and establish a solid foundation for future\nempirical investigations and applications to complex, high-dimensional data.",
    "pdf_url": "http://arxiv.org/pdf/2505.22527v1",
    "published": "2025-05-28T16:13:36+00:00",
    "categories": [
      "stat.ML",
      "cs.LG",
      "68T07, 37J39, 65P10, 62B10, 53D22, 94A17"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2505.22526v1",
    "title": "AI instructional agent improves student's perceived learner control and learning outcome: empirical evidence from a randomized controlled trial",
    "authors": [
      "Fei Qin",
      "Zhanxin Hao",
      "Jifan Yu",
      "Zhiyuan Liu",
      "Yu Zhang"
    ],
    "abstract": "This study examines the impact of an AI instructional agent on students'\nperceived learner control and academic performance in a medium demanding course\nwith lecturing as the main teaching strategy. Based on a randomized controlled\ntrial, three instructional conditions were compared: a traditional human\nteacher, a self-paced MOOC with chatbot support, and an AI instructional agent\ncapable of delivering lectures and responding to questions in real time.\nStudents in the AI instructional agent group reported significantly higher\nlevels of perceived learner control compared to the other groups. They also\ncompleted the learning task more efficiently and engaged in more frequent\ninteractions with the instructional system. Regression analyzes showed that\nperceived learner control positively predicted post-test performance, with\nbehavioral indicators such as reduced learning time and higher interaction\nfrequency supporting this relationship. These findings suggest that AI\ninstructional agents, when designed to support personalized pace and responsive\ninteraction, can enhance both students' learning experience and learning\noutcomes.",
    "pdf_url": "http://arxiv.org/pdf/2505.22526v1",
    "published": "2025-05-28T16:13:27+00:00",
    "categories": [
      "cs.CY"
    ],
    "primary_category": "cs.CY"
  },
  {
    "id": "http://arxiv.org/abs/2505.22525v1",
    "title": "Thinking with Generated Images",
    "authors": [
      "Ethan Chern",
      "Zhulin Hu",
      "Steffi Chern",
      "Siqi Kou",
      "Jiadi Su",
      "Yan Ma",
      "Zhijie Deng",
      "Pengfei Liu"
    ],
    "abstract": "We present Thinking with Generated Images, a novel paradigm that\nfundamentally transforms how large multimodal models (LMMs) engage with visual\nreasoning by enabling them to natively think across text and vision modalities\nthrough spontaneous generation of intermediate visual thinking steps. Current\nvisual reasoning with LMMs is constrained to either processing fixed\nuser-provided images or reasoning solely through text-based chain-of-thought\n(CoT). Thinking with Generated Images unlocks a new dimension of cognitive\ncapability where models can actively construct intermediate visual thoughts,\ncritique their own visual hypotheses, and refine them as integral components of\ntheir reasoning process. We demonstrate the effectiveness of our approach\nthrough two complementary mechanisms: (1) vision generation with intermediate\nvisual subgoals, where models decompose complex visual tasks into manageable\ncomponents that are generated and integrated progressively, and (2) vision\ngeneration with self-critique, where models generate an initial visual\nhypothesis, analyze its shortcomings through textual reasoning, and produce\nrefined outputs based on their own critiques. Our experiments on vision\ngeneration benchmarks show substantial improvements over baseline approaches,\nwith our models achieving up to 50% (from 38% to 57%) relative improvement in\nhandling complex multi-object scenarios. From biochemists exploring novel\nprotein structures, and architects iterating on spatial designs, to forensic\nanalysts reconstructing crime scenes, and basketball players envisioning\nstrategic plays, our approach enables AI models to engage in the kind of visual\nimagination and iterative refinement that characterizes human creative,\nanalytical, and strategic thinking. We release our open-source suite at\nhttps://github.com/GAIR-NLP/thinking-with-generated-images.",
    "pdf_url": "http://arxiv.org/pdf/2505.22525v1",
    "published": "2025-05-28T16:12:45+00:00",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.22524v2",
    "title": "Test-Time Alignment of Discrete Diffusion Models with Sequential Monte Carlo",
    "authors": [
      "Chinmay Pani",
      "Zijing Ou",
      "Yingzhen Li"
    ],
    "abstract": "Discrete diffusion models have become highly effective across various\ndomains. However, real-world applications often require the generative process\nto adhere to certain constraints but without task-specific fine-tuning. To this\nend, we propose a training-free method based on Sequential Monte Carlo (SMC) to\nsample from the reward-aligned target distribution at the test time. Our\napproach leverages twisted SMC with an approximate locally optimal proposal,\nobtained via a first-order Taylor expansion of the reward function. To address\nthe challenge of ill-defined gradients in discrete spaces, we incorporate a\nGumbel-Softmax relaxation, enabling efficient gradient-based approximation\nwithin the discrete generative framework. Empirical results on both synthetic\ndatasets and image modelling validate the effectiveness of our approach.",
    "pdf_url": "http://arxiv.org/pdf/2505.22524v2",
    "published": "2025-05-28T16:12:03+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.14791v1",
    "title": "SemIRNet: A Semantic Irony Recognition Network for Multimodal Sarcasm Detection",
    "authors": [
      "Jingxuan Zhou",
      "Yuehao Wu",
      "Yibo Zhang",
      "Yeyubei Zhang",
      "Yunchong Liu",
      "Bolin Huang",
      "Chunhong Yuan"
    ],
    "abstract": "Aiming at the problem of difficulty in accurately identifying graphical\nimplicit correlations in multimodal irony detection tasks, this paper proposes\na Semantic Irony Recognition Network (SemIRNet). The model contains three main\ninnovations: (1) The ConceptNet knowledge base is introduced for the first time\nto acquire conceptual knowledge, which enhances the model's common-sense\nreasoning ability; (2) Two cross-modal semantic similarity detection modules at\nthe word level and sample level are designed to model graphic-textual\ncorrelations at different granularities; and (3) A contrastive learning loss\nfunction is introduced to optimize the spatial distribution of the sample\nfeatures, which improves the separability of positive and negative samples.\nExperiments on a publicly available multimodal irony detection benchmark\ndataset show that the accuracy and F1 value of this model are improved by 1.64%\nand 2.88% to 88.87% and 86.33%, respectively, compared with the existing\noptimal methods. Further ablation experiments verify the important role of\nknowledge fusion and semantic similarity detection in improving the model\nperformance.",
    "pdf_url": "http://arxiv.org/pdf/2506.14791v1",
    "published": "2025-05-28T16:09:34+00:00",
    "categories": [
      "cs.CV",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.22523v1",
    "title": "PrismLayers: Open Data for High-Quality Multi-Layer Transparent Image Generative Models",
    "authors": [
      "Junwen Chen",
      "Heyang Jiang",
      "Yanbin Wang",
      "Keming Wu",
      "Ji Li",
      "Chao Zhang",
      "Keiji Yanai",
      "Dong Chen",
      "Yuhui Yuan"
    ],
    "abstract": "Generating high-quality, multi-layer transparent images from text prompts can\nunlock a new level of creative control, allowing users to edit each layer as\neffortlessly as editing text outputs from LLMs. However, the development of\nmulti-layer generative models lags behind that of conventional text-to-image\nmodels due to the absence of a large, high-quality corpus of multi-layer\ntransparent data. In this paper, we address this fundamental challenge by: (i)\nreleasing the first open, ultra-high-fidelity PrismLayers (PrismLayersPro)\ndataset of 200K (20K) multilayer transparent images with accurate alpha mattes,\n(ii) introducing a trainingfree synthesis pipeline that generates such data on\ndemand using off-the-shelf diffusion models, and (iii) delivering a strong,\nopen-source multi-layer generation model, ART+, which matches the aesthetics of\nmodern text-to-image generation models. The key technical contributions\ninclude: LayerFLUX, which excels at generating high-quality single transparent\nlayers with accurate alpha mattes, and MultiLayerFLUX, which composes multiple\nLayerFLUX outputs into complete images, guided by human-annotated semantic\nlayout. To ensure higher quality, we apply a rigorous filtering stage to remove\nartifacts and semantic mismatches, followed by human selection. Fine-tuning the\nstate-of-the-art ART model on our synthetic PrismLayersPro yields ART+, which\noutperforms the original ART in 60% of head-to-head user study comparisons and\neven matches the visual quality of images generated by the FLUX.1-[dev] model.\nWe anticipate that our work will establish a solid dataset foundation for the\nmulti-layer transparent image generation task, enabling research and\napplications that require precise, editable, and visually compelling layered\nimagery.",
    "pdf_url": "http://arxiv.org/pdf/2505.22523v1",
    "published": "2025-05-28T16:09:33+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.22522v1",
    "title": "PathFL: Multi-Alignment Federated Learning for Pathology Image Segmentation",
    "authors": [
      "Yuan Zhang",
      "Feng Chen",
      "Yaolei Qi",
      "Guanyu Yang",
      "Huazhu Fu"
    ],
    "abstract": "Pathology image segmentation across multiple centers encounters significant\nchallenges due to diverse sources of heterogeneity including imaging\nmodalities, organs, and scanning equipment, whose variability brings\nrepresentation bias and impedes the development of generalizable segmentation\nmodels. In this paper, we propose PathFL, a novel multi-alignment Federated\nLearning framework for pathology image segmentation that addresses these\nchallenges through three-level alignment strategies of image, feature, and\nmodel aggregation. Firstly, at the image level, a collaborative style\nenhancement module aligns and diversifies local data by facilitating style\ninformation exchange across clients. Secondly, at the feature level, an\nadaptive feature alignment module ensures implicit alignment in the\nrepresentation space by infusing local features with global insights, promoting\nconsistency across heterogeneous client features learning. Finally, at the\nmodel aggregation level, a stratified similarity aggregation strategy\nhierarchically aligns and aggregates models on the server, using layer-specific\nsimilarity to account for client discrepancies and enhance global\ngeneralization. Comprehensive evaluations on four sets of heterogeneous\npathology image datasets, encompassing cross-source, cross-modality,\ncross-organ, and cross-scanner variations, validate the effectiveness of our\nPathFL in achieving better performance and robustness against data\nheterogeneity.",
    "pdf_url": "http://arxiv.org/pdf/2505.22522v1",
    "published": "2025-05-28T16:09:02+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.22521v1",
    "title": "Evaluating Supervised Learning Models for Fraud Detection: A Comparative Study of Classical and Deep Architectures on Imbalanced Transaction Data",
    "authors": [
      "Chao Wang",
      "Chuanhao Nie",
      "Yunbo Liu"
    ],
    "abstract": "Fraud detection remains a critical task in high-stakes domains such as\nfinance and e-commerce, where undetected fraudulent transactions can lead to\nsignificant economic losses. In this study, we systematically compare the\nperformance of four supervised learning models - Logistic Regression, Random\nForest, Light Gradient Boosting Machine (LightGBM), and a Gated Recurrent Unit\n(GRU) network - on a large-scale, highly imbalanced online transaction dataset.\nWhile ensemble methods such as Random Forest and LightGBM demonstrated superior\nperformance in both overall and class-specific metrics, Logistic Regression\noffered a reliable and interpretable baseline. The GRU model showed strong\nrecall for the minority fraud class, though at the cost of precision,\nhighlighting a trade-off relevant for real-world deployment. Our evaluation\nemphasizes not only weighted averages but also per-class precision, recall, and\nF1-scores, providing a nuanced view of each model's effectiveness in detecting\nrare but consequential fraudulent activity. The findings underscore the\nimportance of choosing models based on the specific risk tolerance and\noperational needs of fraud detection systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.22521v1",
    "published": "2025-05-28T16:08:04+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.22520v1",
    "title": "Softness and Hydrodynamic Interactions Regulate Lipoprotein Transport in Crowded Yolk Environments",
    "authors": [
      "Nimmi Das Anthuparambil",
      "Michelle Dargasz",
      "Sonja Timmermann",
      "Anita Girelli",
      "Sebastian Retzbach",
      "Johannes M√∂ller",
      "Wonhyuk Jo",
      "Agha Mohammad Raza",
      "Aliaksandr Leonau",
      "James Wrigley",
      "Frederik Unger",
      "Maddalena Bin",
      "Prince Prabhu Rajaiah",
      "Iason Andronis",
      "William Ch√®vremont",
      "J√∂rg Hallmann",
      "Angel Rodriguez-Fernandez",
      "Jan-Etienne Pudell",
      "Felix Brausse",
      "Ulrike Boesenberg",
      "Mohamed Youssef",
      "Roman Shayduk",
      "Rustam Rysov",
      "Anders Madsen",
      "Felix Lehmk√ºhler",
      "Michael Paulus",
      "Fajun Zhang",
      "Fivos Perakis",
      "Frank Schreiber",
      "Christian Gutt"
    ],
    "abstract": "Low-density lipoproteins (LDLs) serve as nutrient reservoirs in egg yolk for\nembryonic development and as promising drug carriers. Both roles critically\ndepend on their mobility in densely crowded biological environments. Under\nthese crowded conditions, diffusion is hindered by transient confinement within\ndynamic cages formed by neighboring particles, driven by solvent-mediated\nhydrodynamic interactions and memory effects -- phenomena that have remained\nchallenging to characterize computationally and experimentally. Here, we employ\nmegahertz X-ray photon correlation spectroscopy to directly probe the cage\ndynamics of LDLs in yolk-plasma across various concentrations. We find that\nLDLs undergo anomalous diffusion, experiencing $\\approx$ 100-fold reduction in\nself-diffusion at high concentrations compared to dilute solutions. This\ndrastic slowing-down is attributed to a combination of hydrodynamic\ninteractions, direct particle-particle interactions, and the inherent softness\nof LDL particles. Despite reduced dynamics, yolk-plasma remains as a liquid,\nyet sluggish, balancing dense packing, structural stability, and fluidity\nessential for controlled lipid release during embryogenesis.",
    "pdf_url": "http://arxiv.org/pdf/2505.22520v1",
    "published": "2025-05-28T16:07:49+00:00",
    "categories": [
      "cond-mat.soft"
    ],
    "primary_category": "cond-mat.soft"
  },
  {
    "id": "http://arxiv.org/abs/2505.22519v1",
    "title": "Connectivity for quantum graphs via quantum adjacency operators",
    "authors": [
      "Kristin Courtney",
      "Priyanga Ganesan",
      "Mateusz Wasilewski"
    ],
    "abstract": "Connectivity is a fundamental property of quantum graphs, previously studied\nin the operator system model for matrix quantum graphs and via graph\nhomomorphisms in the quantum adjacency matrix model. In this paper, we develop\nan algebraic characterization of connectivity for general quantum graphs within\nthe quantum adjacency matrix framework. Our approach extends earlier results to\nthe non-tracial setting and beyond regular quantum graphs. We utilize a quantum\nPerron-Frobenius theorem that provides a spectral characterization of\nconnectivity, and we further characterize connectivity in terms of the\nirreducibility of the quantum adjacency matrix and the nullity of the\nassociated graph Laplacian. These results are obtained using the KMS inner\nproduct, which unifies and generalizes existing formulations.",
    "pdf_url": "http://arxiv.org/pdf/2505.22519v1",
    "published": "2025-05-28T16:05:35+00:00",
    "categories": [
      "math.OA",
      "math-ph",
      "math.MP"
    ],
    "primary_category": "math.OA"
  },
  {
    "id": "http://arxiv.org/abs/2505.22518v4",
    "title": "IGNIS: A Robust Neural Network Framework for Constrained Parameter Estimation in Archimedean Copulas",
    "authors": [
      "Agnideep Aich"
    ],
    "abstract": "Classical estimators, the cornerstones of statistical inference, face\ninsurmountable challenges when applied to important emerging classes of\nArchimedean copulas. These models exhibit pathological properties, including\nnumerically unstable densities, non-monotonic parameter-to-dependence mappings,\nand vanishingly small likelihood gradients, rendering methods like Maximum\nLikelihood (MLE) and Method of Moments (MoM) inconsistent or computationally\ninfeasible. We introduce IGNIS, a unified neural estimation framework that\nsidesteps these barriers by learning a direct, robust mapping from data-driven\ndependency measures to the underlying copula parameter theta. IGNIS utilizes a\nmulti-input architecture and a theory-guided output layer (softplus(z) + 1) to\nautomatically enforce the domain constraint theta_hat >= 1. Trained and\nvalidated on four families (Gumbel, Joe, and the numerically challenging\nA1/A2), IGNIS delivers accurate and stable estimates for real-world financial\nand health datasets, demonstrating its necessity for reliable inference in\nmodern, complex dependence models where traditional methods fail.",
    "pdf_url": "http://arxiv.org/pdf/2505.22518v4",
    "published": "2025-05-28T16:04:17+00:00",
    "categories": [
      "stat.ML",
      "cs.LG",
      "62H05, 62H12, 62F10, 68T07, 62-08"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2505.22517v1",
    "title": "Multi-MLLM Knowledge Distillation for Out-of-Context News Detection",
    "authors": [
      "Yimeng Gu",
      "Zhao Tong",
      "Ignacio Castro",
      "Shu Wu",
      "Gareth Tyson"
    ],
    "abstract": "Multimodal out-of-context news is a type of misinformation in which the image\nis used outside of its original context. Many existing works have leveraged\nmultimodal large language models (MLLMs) for detecting out-of-context news.\nHowever, observing the limited zero-shot performance of smaller MLLMs, they\ngenerally require label-rich fine-tuning and/or expensive API calls to GPT\nmodels to improve the performance, which is impractical in low-resource\nscenarios. In contrast, we aim to improve the performance of small MLLMs in a\nmore label-efficient and cost-effective manner. To this end, we first prompt\nmultiple teacher MLLMs to generate both label predictions and corresponding\nrationales, which collectively serve as the teachers' knowledge. We then\nintroduce a two-stage knowledge distillation framework to transfer this\nknowledge to a student MLLM. In Stage 1, we apply LoRA fine-tuning to the\nstudent model using all training data. In Stage 2, we further fine-tune the\nstudent model using both LoRA fine-tuning and DPO on the data points where\nteachers' predictions conflict. This two-stage strategy reduces annotation\ncosts and helps the student model uncover subtle patterns in more challenging\ncases. Experimental results demonstrate that our approach achieves\nstate-of-the-art performance using less than 10% labeled data.",
    "pdf_url": "http://arxiv.org/pdf/2505.22517v1",
    "published": "2025-05-28T16:03:41+00:00",
    "categories": [
      "cs.CL",
      "cs.MM"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.22516v1",
    "title": "Updated predictions for gravitational wave emission from TDEs for next generation observatories",
    "authors": [
      "Martina Toscani",
      "Luca Broggi",
      "Alberto Sesana",
      "Elena Maria Rossi"
    ],
    "abstract": "In this paper, we investigate the gravitational wave (GW) emission from stars\ntidally disrupted by black holes (TDEs), using a semi-analytical approach.\nContrary to previous works where this signal is modeled as a monochromatic\nburst, we here take into account all its harmonic components. On top of this,\nwe also extend the analysis to a population of repeated-partial TDEs, where the\nstar undergoes multiple passages around the black hole before complete\ndisruption. For both populations, we estimate the rate of individual\nGW-detections considering future observatories like LISA and a potential\ndeci-Hertz (dHz) mission, and derive the GW background from these sources. Our\nconclusions, even if more conservative, are consistent with previous results\npresented in literature. In fact, full disruptions of stars will not be seen by\nLISA but will be important targets for dHz observatories. In contrast, GWs from\nrepeated disruptions will not be detectable in the near future.",
    "pdf_url": "http://arxiv.org/pdf/2505.22516v1",
    "published": "2025-05-28T16:03:37+00:00",
    "categories": [
      "astro-ph.HE"
    ],
    "primary_category": "astro-ph.HE"
  },
  {
    "id": "http://arxiv.org/abs/2505.22515v1",
    "title": "Towards General Discrete Speech Codec for Complex Acoustic Environments: A Study of Reconstruction and Downstream Task Consistency",
    "authors": [
      "Haoran Wang",
      "Guanyu Chen",
      "Bohan Li",
      "Hankun Wang",
      "Yiwei Guo",
      "Zhihan Li",
      "Xie Chen",
      "Kai Yu"
    ],
    "abstract": "Neural speech codecs excel in reconstructing clean speech signals; however,\ntheir efficacy in complex acoustic environments and downstream signal\nprocessing tasks remains underexplored. In this study, we introduce a novel\nbenchmark named Environment-Resilient Speech Codec Benchmark (ERSB) to\nsystematically evaluate whether neural speech codecs are environment-resilient.\nSpecifically, we assess two key capabilities: (1) robust reconstruction, which\nmeasures the preservation of both speech and non-speech acoustic details, and\n(2) downstream task consistency, which ensures minimal deviation in downstream\nsignal processing tasks when using reconstructed speech instead of the\noriginal. Our comprehensive experiments reveal that complex acoustic\nenvironments significantly degrade signal reconstruction and downstream task\nconsistency. This work highlights the limitations of current speech codecs and\nraises a future direction that improves them for greater environmental\nresilience.",
    "pdf_url": "http://arxiv.org/pdf/2505.22515v1",
    "published": "2025-05-28T16:03:03+00:00",
    "categories": [
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.SD"
  },
  {
    "id": "http://arxiv.org/abs/2505.22514v1",
    "title": "Closing the Quantum-Classical Scaling Gap in Approximate Optimization",
    "authors": [
      "J. Pawlowski",
      "P. Tarasiuk",
      "J. Tuziemski",
      "L. Pawela",
      "B. Gardas"
    ],
    "abstract": "In a recent study (Ref. [1]), quantum annealing was reported to exhibit a\nscaling advantage for approximately solving Quadratic Unconstrained Binary\nOptimization (QUBO). However, this claim critically depends on the choice of\nclassical reference algorithm -- Parallel Tempering with Isoenergetic Cluster\nMoves (PT-ICM). Here, we reassess these findings with different classical\nparadigm -- Simulated Bifurcation Machine (SBM) -- that harnesses nonlinear\nHamiltonian dynamics. By leveraging chaotic behavior rather than thermal\nfluctuations, SBM achieves comparable or superior scaling performance,\neffectively closing the previously reported quantum-classical gap. We show that\nsmall problem sizes analyzed in [1] are insufficient for inferring asymptotic\nscaling, due to sensitivity to runtime and hardware-specific factors. By\nextending the benchmark to larger instances -- beyond current quantum annealing\ncapabilities -- we establish strong classical scaling behavior. And as a\nresult, we conclude that it is unlikely that current generation of quantum\nannealers, can demonstrate supremacy in discrete approximate optimization under\noperationally meaningful conditions.",
    "pdf_url": "http://arxiv.org/pdf/2505.22514v1",
    "published": "2025-05-28T16:02:57+00:00",
    "categories": [
      "quant-ph",
      "physics.comp-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.22513v1",
    "title": "Strengthening Proportionality in Temporal Voting",
    "authors": [
      "Bradley Phillips",
      "Edith Elkind",
      "Nicholas Teh",
      "Tomasz WƒÖs"
    ],
    "abstract": "We study proportional representation in the framework of temporal voting with\napproval ballots. Prior work adapted basic proportional representation concepts\n-- justified representation (JR), proportional JR (PJR), and extended JR (EJR)\n-- from the multiwinner setting to the temporal setting. Our work introduces\nand examines ways of going beyond EJR. Specifically, we consider stronger\nvariants of JR, PJR, and EJR, and introduce temporal adaptations of more\ndemanding multiwinner axioms, such as EJR+, full JR (FJR), full proportional JR\n(FPJR), and the Core. For each of these concepts, we investigate its existence\nand study its relationship to existing notions, thereby establishing a rich\nhierarchy of proportionality concepts. Notably, we show that two of our\nproposed axioms -- EJR+ and FJR -- strengthen EJR while remaining satisfiable\nin every temporal election.",
    "pdf_url": "http://arxiv.org/pdf/2505.22513v1",
    "published": "2025-05-28T16:02:52+00:00",
    "categories": [
      "cs.GT",
      "cs.AI"
    ],
    "primary_category": "cs.GT"
  },
  {
    "id": "http://arxiv.org/abs/2505.22512v1",
    "title": "The stellar evolution perspective on the metallicity dependence of classical Cepheid Leavitt laws",
    "authors": [
      "Saniya Khan",
      "Richard I. Anderson",
      "Sylvia Ekstr√∂m",
      "Cyril Georgy",
      "Louise Breuval"
    ],
    "abstract": "The impact of metallicity on the Cepheid Leavitt law (LL) and, in turn, the\nHubble constant, has been the subject of much recent debate. Here, we present a\ncomprehensive analysis of metallicity effects on Cepheid LLs based on synthetic\nCepheid populations computed using Geneva models and the SYCLIST tool. We\ncomputed 296 co-eval populations in the age range of 5-300 Myr for\nmetallicities representative of the Sun, the LMC, and the SMC ($Z \\in [0.014,\n0.006, 0.002]$). We computed LLs in fourteen optical-to-infrared passbands and\nfive reddening-free Wesenheit magnitudes. All Cepheid populations take into\naccount distributions of rotation rates and companion stars. We show excellent\nagreement between the predicted populations and key observational constraints\nfrom the literature. Our simulations predict a significant LL slope-metallicity\ndependence ($\\beta_{\\rm M} > 0$) that renders LLs steeper at lower metallicity\nat all wavelengths. Importantly, $\\beta_{\\rm M} \\ne 0$ implies that the\nintercept-metallicity dependence, $\\alpha_{\\rm M}$, depends on pivot period; an\nissue not previously considered. Comparison with $\\alpha_{\\rm M}$ measurements\nin individual passbands reported in the literature yields acceptable agreement\non the order of agreement found among different observational studies. The\nwavelength dependence and magnitude of the disagreement suggests a possible\norigin in reddening-related systematics. Conversely, we report excellent\nagreement between our $\\alpha_{\\rm M} = -0.20 \\pm 0.03$ mag dex$^{-1}$ and the\nvalue determined by the SH0ES distance ladder in the reddening-free H-band\nWesenheit magnitude ($-0.217 \\pm 0.046$), the currently tightest and\nconceptually simplest empirical constraint.",
    "pdf_url": "http://arxiv.org/pdf/2505.22512v1",
    "published": "2025-05-28T16:01:45+00:00",
    "categories": [
      "astro-ph.SR",
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.SR"
  },
  {
    "id": "http://arxiv.org/abs/2505.22511v2",
    "title": "Surf2CT: Cascaded 3D Flow Matching Models for Torso 3D CT Synthesis from Skin Surface",
    "authors": [
      "Siyeop Yoon",
      "Yujin Oh",
      "Pengfei Jin",
      "Sifan Song",
      "Matthew Tivnan",
      "Dufan Wu",
      "Xiang Li",
      "Quanzheng Li"
    ],
    "abstract": "We present Surf2CT, a novel cascaded flow matching framework that synthesizes\nfull 3D computed tomography (CT) volumes of the human torso from external\nsurface scans and simple demographic data (age, sex, height, weight). This is\nthe first approach capable of generating realistic volumetric internal anatomy\nimages solely based on external body shape and demographics, without any\ninternal imaging. Surf2CT proceeds through three sequential stages: (1) Surface\nCompletion, reconstructing a complete signed distance function (SDF) from\npartial torso scans using conditional 3D flow matching; (2) Coarse CT\nSynthesis, generating a low-resolution CT volume from the completed SDF and\ndemographic information; and (3) CT Super-Resolution, refining the coarse\nvolume into a high-resolution CT via a patch-wise conditional flow model. Each\nstage utilizes a 3D-adapted EDM2 backbone trained via flow matching. We trained\nour model on a combined dataset of 3,198 torso CT scans (approximately 1.13\nmillion axial slices) sourced from Massachusetts General Hospital (MGH) and the\nAutoPET challenge. Evaluation on 700 paired torso surface-CT cases demonstrated\nstrong anatomical fidelity: organ volumes exhibited small mean percentage\ndifferences (range from -11.1% to 4.4%), and muscle/fat body composition\nmetrics matched ground truth with strong correlation (range from 0.67 to 0.96).\nLung localization had minimal bias (mean difference -2.5 mm), and surface\ncompletion significantly improved metrics (Chamfer distance: from 521.8 mm to\n2.7 mm; Intersection-over-Union: from 0.87 to 0.98). Surf2CT establishes a new\nparadigm for non-invasive internal anatomical imaging using only external data,\nopening opportunities for home-based healthcare, preventive medicine, and\npersonalized clinical assessments without the risks associated with\nconventional imaging techniques.",
    "pdf_url": "http://arxiv.org/pdf/2505.22511v2",
    "published": "2025-05-28T16:01:36+00:00",
    "categories": [
      "eess.IV",
      "cs.CV"
    ],
    "primary_category": "eess.IV"
  },
  {
    "id": "http://arxiv.org/abs/2505.22510v1",
    "title": "Enhanced thermopower in two-dimensional ruthenium dichalcogenides $RuX_2$ (X = S, Se): a first-principles study",
    "authors": [
      "Parbati Senapati",
      "Ajay Kumar",
      "Prakash Parida"
    ],
    "abstract": "Transition metal dichalcogenides (TMDs) have garnered attention for their\npotential in thermoelectric applications due to their unique electronic\nproperties and tunable bandgaps. In this study, we systematically explore the\nelectronic and thermoelectric properties of $T^{\\prime}-RuX_2$ (X = S, Se)\nusing first-principles calculations and semi-classical Boltzmann transport\nequations. Our findings confirm that $T^{\\prime}-RuX_2$ is energetically and\nmechanically stable, with high thermopower values such that $T^{\\prime}-RuS_2$\nexhibits a Seebeck coefficient of $2685~\\mu V/K$ for hole doping and $2585~\\mu\nV/K$ for electron doping, while $T^{\\prime}-RuSe_2$ shows values of $1515~\\mu\nV/K$ and $1533~\\mu V/K$ for hole and electron doping, respectively. Both\nmaterials exhibit reasonable power factors and $ZT$ values, with p-type\n$T^{\\prime}-RuS_2$ and $T^{\\prime}-RuSe_2$ achieving maximum ZT values of 0.85\nand 0.87, respectively, at 1200~K along the y-direction. These results\nhighlight $T^{\\prime}$-$RuS_2$ and $T^{\\prime}$-$RuSe_2$ as promising\ncandidates for high-temperature TMD-based thermoelectric devices.",
    "pdf_url": "http://arxiv.org/pdf/2505.22510v1",
    "published": "2025-05-28T16:00:12+00:00",
    "categories": [
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2505.22509v1",
    "title": "Accelerating Optimization via Differentiable Stopping Time",
    "authors": [
      "Zhonglin Xie",
      "Yiman Fong",
      "Haoran Yuan",
      "Zaiwen Wen"
    ],
    "abstract": "Optimization is an important module of modern machine learning applications.\nTremendous efforts have been made to accelerate optimization algorithms. A\ncommon formulation is achieving a lower loss at a given time. This enables a\ndifferentiable framework with respect to the algorithm hyperparameters. In\ncontrast, its dual, minimizing the time to reach a target loss, is believed to\nbe non-differentiable, as the time is not differentiable. As a result, it\nusually serves as a conceptual framework or is optimized using zeroth-order\nmethods. To address this limitation, we propose a differentiable stopping time\nand theoretically justify it based on differential equations. An efficient\nalgorithm is designed to backpropagate through it. As a result, the proposed\ndifferentiable stopping time enables a new differentiable formulation for\naccelerating algorithms. We further discuss its applications, such as online\nhyperparameter tuning and learning to optimize. Our proposed methods show\nsuperior performance in comprehensive experiments across various problems,\nwhich confirms their effectiveness.",
    "pdf_url": "http://arxiv.org/pdf/2505.22509v1",
    "published": "2025-05-28T15:59:13+00:00",
    "categories": [
      "cs.LG",
      "math.OC"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.22508v1",
    "title": "Toward Fully Neuromorphic Receivers for Ultra-Power Efficient Communications",
    "authors": [
      "George N. Katsaros",
      "Konstantinos Nikitopoulos"
    ],
    "abstract": "Neuromorphic computing, inspired by biological neural systems, has emerged as\na promising approach for ultra-energy-efficient data processing by leveraging\nanalog neuron structures and spike-based computation. However, its application\nin communication systems remains largely unexplored, with existing efforts\nmainly focused on mapping isolated communication algorithms onto spiking\nnetworks, often accompanied by substantial, traditional computational overhead\ndue to transformations required to adapt problems to the spiking paradigm. In\nthis work, we take a fundamentally different route and, for the first time,\npropose a fully neuromorphic communication receiver by applying neuromorphic\nprinciples directly in the analog domain from the very start of the receiver\nprocessing chain. Specifically, we examine a simple transmission scenario: a\nBPSK receiver with repetition coding, and show that we can achieve joint\ndetection and decoding entirely through spiking signals. Our approach\ndemonstrates error-rate performance gains over conventional digital\nrealizations with power consumption on the order of microwatts, comparable with\na single very low-resolution Analog-to-Digital Converter (ADC) utilized in\ndigital receivers. To maintain performance under varying noise conditions, we\nalso introduce a novel noise-tracking mechanism that dynamically adjusts neural\nparameters during transmission. Finally, we discuss the key challenges and\ndirections toward ultra-efficient neuromorphic transceivers.",
    "pdf_url": "http://arxiv.org/pdf/2505.22508v1",
    "published": "2025-05-28T15:57:16+00:00",
    "categories": [
      "eess.SP",
      "94A12",
      "C.1.3; C.2.1"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2505.22507v1",
    "title": "Modeling and estimating skewed and heavy-tailed populations via unsupervised mixture models",
    "authors": [
      "Marco Bee",
      "Flavio Santi"
    ],
    "abstract": "We develop an unsupervised mixture model for non-negative, skewed and\nheavy-tailed data, such as losses in actuarial and risk management\napplications. The mixture has a lognormal component, which is usually\nappropriate for the body of the distribution, and a Pareto-type tail, aimed at\naccommodating the largest observations, since the lognormal tail often decays\ntoo fast. We show that maximum likelihood estimation can be performed by means\nof the EM algorithm and that the model is quite flexible in fitting data from\ndifferent data-generating processes. Simulation experiments and a real-data\napplication to automobiles claims suggest that the approach is equivalent in\nterms of goodness-of-fit, but easier to estimate, with respect to two existing\ndistributions with similar features.",
    "pdf_url": "http://arxiv.org/pdf/2505.22507v1",
    "published": "2025-05-28T15:54:40+00:00",
    "categories": [
      "stat.ME"
    ],
    "primary_category": "stat.ME"
  },
  {
    "id": "http://arxiv.org/abs/2505.22506v1",
    "title": "Sparsification and Reconstruction from the Perspective of Representation Geometry",
    "authors": [
      "Wenjie Sun",
      "Bingzhe Wu",
      "Zhile Yang",
      "Chengke Wu"
    ],
    "abstract": "Sparse Autoencoders (SAEs) have emerged as a predominant tool in mechanistic\ninterpretability, aiming to identify interpretable monosemantic features.\nHowever, how does sparse encoding organize the representations of activation\nvector from language models? What is the relationship between this\norganizational paradigm and feature disentanglement as well as reconstruction\nperformance? To address these questions, we propose the SAEMA, which validates\nthe stratified structure of the representation by observing the variability of\nthe rank of the symmetric semipositive definite (SSPD) matrix corresponding to\nthe modal tensor unfolded along the latent tensor with the level of noise added\nto the residual stream. To systematically investigate how sparse encoding\nalters representational structures, we define local and global representations,\ndemonstrating that they amplify inter-feature distinctions by merging similar\nsemantic features and introducing additional dimensionality. Furthermore, we\nintervene the global representation from an optimization perspective, proving a\nsignificant causal relationship between their separability and the\nreconstruction performance. This study explains the principles of sparsity from\nthe perspective of representational geometry and demonstrates the impact of\nchanges in representational structure on reconstruction performance.\nParticularly emphasizes the necessity of understanding representations and\nincorporating representational constraints, providing empirical references for\ndeveloping new interpretable tools and improving SAEs. The code is available at\n\\hyperlink{https://github.com/wenjie1835/SAERepGeo}{https://github.com/wenjie1835/SAERepGeo}.",
    "pdf_url": "http://arxiv.org/pdf/2505.22506v1",
    "published": "2025-05-28T15:54:33+00:00",
    "categories": [
      "cs.LG",
      "22-08",
      "I.2.4; I.2.7"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.22505v1",
    "title": "Data-Driven Control of Continuous-Time LTI Systems via Non-Minimal Realizations",
    "authors": [
      "Alessandro Bosso",
      "Marco Borghesi",
      "Andrea Iannelli",
      "Giuseppe Notarstefano",
      "Andrew R. Teel"
    ],
    "abstract": "This article proposes an approach to design output-feedback controllers for\nunknown continuous-time linear time-invariant systems using only input-output\ndata from a single experiment. To address the lack of state and derivative\nmeasurements, we introduce non-minimal realizations whose states can be\nobserved by filtering the available data. We first apply this concept to the\ndisturbance-free case, formulating linear matrix inequalities (LMIs) from\nbatches of sampled signals to design a dynamic, filter-based stabilizing\ncontroller. The framework is then extended to the problem of asymptotic\ntracking and disturbance rejection - in short, output regulation - by\nincorporating an internal model based on prior knowledge of the\ndisturbance/reference frequencies. Finally, we discuss tuning strategies for a\nclass of multi-input multi-output systems and illustrate the method via\nnumerical examples.",
    "pdf_url": "http://arxiv.org/pdf/2505.22505v1",
    "published": "2025-05-28T15:53:55+00:00",
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2505.22504v1",
    "title": "Geometric GNNs for Charged Particle Tracking at GlueX",
    "authors": [
      "Ahmed Hossam Mohammed",
      "Kishansingh Rajput",
      "Simon Taylor",
      "Denis Furletov",
      "Sergey Furletov",
      "Malachi Schram"
    ],
    "abstract": "Nuclear physics experiments are aimed at uncovering the fundamental building\nblocks of matter. The experiments involve high-energy collisions that produce\ncomplex events with many particle trajectories. Tracking charged particles\nresulting from collisions in the presence of a strong magnetic field is\ncritical to enable the reconstruction of particle trajectories and precise\ndetermination of interactions. It is traditionally achieved through\ncombinatorial approaches that scale worse than linearly as the number of hits\ngrows. Since particle hit data naturally form a 3-dimensional point cloud and\ncan be structured as graphs, Graph Neural Networks (GNNs) emerge as an\nintuitive and effective choice for this task. In this study, we evaluate the\nGNN model for track finding on the data from the GlueX experiment at Jefferson\nLab. We use simulation data to train the model and test on both simulation and\nreal GlueX measurements. We demonstrate that GNN-based track finding\noutperforms the currently used traditional method at GlueX in terms of\nsegment-based efficiency at a fixed purity while providing faster inferences.\nWe show that the GNN model can achieve significant speedup by processing\nmultiple events in batches, which exploits the parallel computation capability\nof Graphical Processing Units (GPUs). Finally, we compare the GNN\nimplementation on GPU and FPGA and describe the trade-off.",
    "pdf_url": "http://arxiv.org/pdf/2505.22504v1",
    "published": "2025-05-28T15:52:22+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.22503v1",
    "title": "From Strangers to Assistants: Fast Desire Alignment for Embodied Agent-User Adaptation",
    "authors": [
      "Yuanfei Wang",
      "Xinju Huang",
      "Fangwei Zhong",
      "Yaodong Yang",
      "Yizhou Wang",
      "Yuanpei Chen",
      "Hao Dong"
    ],
    "abstract": "While embodied agents have made significant progress in performing complex\nphysical tasks, real-world applications demand more than pure task execution.\nThe agents must collaborate with unfamiliar agents and human users, whose goals\nare often vague and implicit. In such settings, interpreting ambiguous\ninstructions and uncovering underlying desires is essential for effective\nassistance. Therefore, fast and accurate desire alignment becomes a critical\ncapability for embodied agents. In this work, we first develop a home\nassistance simulation environment HA-Desire that integrates an LLM-driven human\nuser agent exhibiting realistic value-driven goal selection and communication.\nThe ego agent must interact with this proxy user to infer and adapt to the\nuser's latent desires. To achieve this, we present a novel framework FAMER for\nfast desire alignment, which introduces a desire-based mental reasoning\nmechanism to identify user intent and filter desire-irrelevant actions. We\nfurther design a reflection-based communication module that reduces redundant\ninquiries, and incorporate goal-relevant information extraction with memory\npersistence to improve information reuse and reduce unnecessary exploration.\nExtensive experiments demonstrate that our framework significantly enhances\nboth task execution and communication efficiency, enabling embodied agents to\nquickly adapt to user-specific desires in complex embodied environments.",
    "pdf_url": "http://arxiv.org/pdf/2505.22503v1",
    "published": "2025-05-28T15:51:13+00:00",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.22502v2",
    "title": "Assessing Quantum Advantage for Gaussian Process Regression",
    "authors": [
      "Dominic Lowe",
      "M. S. Kim",
      "Roberto Bondesan"
    ],
    "abstract": "Gaussian Process Regression is a well-known machine learning technique for\nwhich several quantum algorithms have been proposed. We show here that in a\nwide range of scenarios these algorithms show no exponential speedup. We\nachieve this by rigorously proving that the condition number of a kernel matrix\nscales at least linearly with the matrix size under general assumptions on the\ndata and kernel. We additionally prove that the sparsity and Frobenius norm of\na kernel matrix scale linearly under similar assumptions. The implications for\nthe quantum algorithms runtime are independent of the complexity of loading\nclassical data on a quantum computer and also apply to dequantised algorithms.\nWe supplement our theoretical analysis with numerical verification for popular\nkernels in machine learning.",
    "pdf_url": "http://arxiv.org/pdf/2505.22502v2",
    "published": "2025-05-28T15:50:56+00:00",
    "categories": [
      "quant-ph",
      "cs.LG"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.22501v1",
    "title": "EvolveSearch: An Iterative Self-Evolving Search Agent",
    "authors": [
      "Dingchu Zhang",
      "Yida Zhao",
      "Jialong Wu",
      "Baixuan Li",
      "Wenbiao Yin",
      "Liwen Zhang",
      "Yong Jiang",
      "Yufeng Li",
      "Kewei Tu",
      "Pengjun Xie",
      "Fei Huang"
    ],
    "abstract": "The rapid advancement of large language models (LLMs) has transformed the\nlandscape of agentic information seeking capabilities through the integration\nof tools such as search engines and web browsers. However, current mainstream\napproaches for enabling LLM web search proficiency face significant challenges:\nsupervised fine-tuning struggles with data production in open-search domains,\nwhile RL converges quickly, limiting their data utilization efficiency. To\naddress these issues, we propose EvolveSearch, a novel iterative self-evolution\nframework that combines SFT and RL to enhance agentic web search capabilities\nwithout any external human-annotated reasoning data. Extensive experiments on\nseven multi-hop question-answering (MHQA) benchmarks demonstrate that\nEvolveSearch consistently improves performance across iterations, ultimately\nachieving an average improvement of 4.7\\% over the current state-of-the-art\nacross seven benchmarks, opening the door to self-evolution agentic\ncapabilities in open web search domains.",
    "pdf_url": "http://arxiv.org/pdf/2505.22501v1",
    "published": "2025-05-28T15:50:48+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.22500v1",
    "title": "Deformed Bivariate $q$-Appell Polynomials",
    "authors": [
      "Ronald Orozco L√≥pez"
    ],
    "abstract": "In this paper, we introduce bivariate polynomial sets of deformed $q$-Appell\ntype, and we study the algebraic properties of these sets. We show the relation\nbetween deformed bivariate $q$-Appell polynomials and deformed homogeneous\npolynomials. Next, we give some of their characterizations and algebraic\nstructure. Then, we introduce the deformed $q$-Appell operators and obtain\nMehler's and Rogers-type formulas of quasi-$q$-Appell polynomials. Finally,\nsome examples of polynomial sequences of deformed $q$-Appell type are given:\nBernoulli, Euler, and Genocchi types.",
    "pdf_url": "http://arxiv.org/pdf/2505.22500v1",
    "published": "2025-05-28T15:50:34+00:00",
    "categories": [
      "math.CO",
      "05A30, 11B83, 11B68"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.22499v2",
    "title": "The Meeseeks Mesh: Spatially Consistent 3D Adversarial Objects for BEV Detector",
    "authors": [
      "Aixuan Li",
      "Mochu Xiang",
      "Jing Zhang",
      "Yuchao Dai"
    ],
    "abstract": "3D object detection is a critical component in autonomous driving systems. It\nallows real-time recognition and detection of vehicles, pedestrians and\nobstacles under varying environmental conditions. Among existing methods, 3D\nobject detection in the Bird's Eye View (BEV) has emerged as the mainstream\nframework. To guarantee a safe, robust and trustworthy 3D object detection, 3D\nadversarial attacks are investigated, where attacks are placed in 3D\nenvironments to evaluate the model performance, e.g. putting a film on a car,\nclothing a pedestrian. The vulnerability of 3D object detection models to 3D\nadversarial attacks serves as an important indicator to evaluate the robustness\nof the model against perturbations. To investigate this vulnerability, we\ngenerate non-invasive 3D adversarial objects tailored for real-world attack\nscenarios. Our method verifies the existence of universal adversarial objects\nthat are spatially consistent across time and camera views. Specifically, we\nemploy differentiable rendering techniques to accurately model the spatial\nrelationship between adversarial objects and the target vehicle. Furthermore,\nwe introduce an occlusion-aware module to enhance visual consistency and\nrealism under different viewpoints. To maintain attack effectiveness across\nmultiple frames, we design a BEV spatial feature-guided optimization strategy.\nExperimental results demonstrate that our approach can reliably suppress\nvehicle predictions from state-of-the-art 3D object detectors, serving as an\nimportant tool to test robustness of 3D object detection models before\ndeployment. Moreover, the generated adversarial objects exhibit strong\ngeneralization capabilities, retaining its effectiveness at various positions\nand distances in the scene.",
    "pdf_url": "http://arxiv.org/pdf/2505.22499v2",
    "published": "2025-05-28T15:49:54+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.22498v1",
    "title": "Lanczos with compression for symmetric matrix Lyapunov equations",
    "authors": [
      "Angelo A. Casulli",
      "Francesco Hrobat",
      "Daniel Kressner"
    ],
    "abstract": "This work considers large-scale Lyapunov matrix equations of the form $AX +\nXA = \\boldsymbol{c}\\boldsymbol{c}^T$, where $A$ is a symmetric positive\ndefinite matrix and $\\boldsymbol{c}$ is a vector. Motivated by the need to\nsolve such equations in a wide range of applications, various numerical methods\nhave been developed to compute low-rank approximations of the solution matrix\n$X$. In this work, we focus on the Lanczos method, which has the distinct\nadvantage of requiring only matrix-vector products with $A$, making it broadly\napplicable. However, the Lanczos method may suffer from slow convergence when\n$A$ is ill-conditioned, leading to excessive memory requirements for storing\nthe Krylov subspace basis generated by the algorithm. To address this issue, we\npropose a novel compression strategy for the Krylov subspace basis that\nsignificantly reduces memory usage without hindering convergence. This is\nsupported by both numerical experiments and a convergence analysis. Our\nanalysis also accounts for the loss of orthogonality due to round-off errors in\nthe Lanczos process.",
    "pdf_url": "http://arxiv.org/pdf/2505.22498v1",
    "published": "2025-05-28T15:49:35+00:00",
    "categories": [
      "math.NA",
      "cs.NA",
      "65F45, 65F50, 65F55"
    ],
    "primary_category": "math.NA"
  },
  {
    "id": "http://arxiv.org/abs/2505.22497v1",
    "title": "Fully Packed and Ready to Go: High-Density, Rearrangement-Free, Grid-Based Storage and Retrieval",
    "authors": [
      "Tzvika Geft",
      "Kostas Bekris",
      "Jingjin Yu"
    ],
    "abstract": "Grid-based storage systems with uniformly shaped loads (e.g., containers,\npallets, totes) are commonplace in logistics, industrial, and transportation\ndomains. A key performance metric for such systems is the maximization of space\nutilization, which requires some loads to be placed behind or below others,\npreventing direct access to them. Consequently, dense storage settings bring up\nthe challenge of determining how to place loads while minimizing costly\nrearrangement efforts necessary during retrieval. This paper considers the\nsetting involving an inbound phase, during which loads arrive, followed by an\noutbound phase, during which loads depart. The setting is prevalent in\ndistribution centers, automated parking garages, and container ports. In both\nphases, minimizing the number of rearrangement actions results in more optimal\n(e.g., fast, energy-efficient, etc.) operations. In contrast to previous work\nfocusing on stack-based systems, this effort examines the case where loads can\nbe freely moved along the grid, e.g., by a mobile robot, expanding the range of\npossible motions. We establish that for a range of scenarios, such as having\nlimited prior knowledge of the loads' arrival sequences or grids with a narrow\nopening, a (best possible) rearrangement-free solution always exists, including\nwhen the loads fill the grid to its capacity. In particular, when the sequences\nare fully known, we establish an intriguing characterization showing that\nrearrangement can always be avoided if and only if the open side of the grid\n(used to access the storage) is at least 3 cells wide. We further discuss\nuseful practical implications of our solutions.",
    "pdf_url": "http://arxiv.org/pdf/2505.22497v1",
    "published": "2025-05-28T15:47:43+00:00",
    "categories": [
      "cs.RO",
      "cs.DS"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.22496v1",
    "title": "Risk-Sensitive Conformal Prediction for Catheter Placement Detection in Chest X-rays",
    "authors": [
      "Long Hui"
    ],
    "abstract": "This paper presents a novel approach to catheter and line position detection\nin chest X-rays, combining multi-task learning with risk-sensitive conformal\nprediction to address critical clinical requirements. Our model simultaneously\nperforms classification, segmentation, and landmark detection, leveraging the\nsynergistic relationship between these tasks to improve overall performance. We\nfurther enhance clinical reliability through risk-sensitive conformal\nprediction, which provides statistically guaranteed prediction sets with higher\nreliability for clinically critical findings. Experimental results demonstrate\nexcellent performance with 90.68\\% overall empirical coverage and 99.29\\%\ncoverage for critical conditions, while maintaining remarkable precision in\nprediction sets. Most importantly, our risk-sensitive approach achieves zero\nhigh-risk mispredictions (cases where the system dangerously declares\nproblematic tubes as confidently normal), making the system particularly\nsuitable for clinical deployment. This work offers both accurate predictions\nand reliably quantified uncertainty -- essential features for life-critical\nmedical applications.",
    "pdf_url": "http://arxiv.org/pdf/2505.22496v1",
    "published": "2025-05-28T15:47:10+00:00",
    "categories": [
      "eess.IV",
      "cs.CV",
      "stat.AP"
    ],
    "primary_category": "eess.IV"
  },
  {
    "id": "http://arxiv.org/abs/2505.22495v1",
    "title": "Reduced order modelling of air puff test for corneal material characterisation",
    "authors": [
      "Osama M. Maklad",
      "Muting Hao"
    ],
    "abstract": "Models of the fluid-structure interaction (FSI) model for the air puff test\nwere analysed. Using Abaqus, the air puff test is applied to eyes with varying\nbiomechanical parameters, such as material properties, corneal thickness, and\nradius. A reduced order model of the air puff (a turbulent impinging jet) has\nbeen acquired to decrease simulation time from 48 hours for the FSI model to\napproximately 12 minutes for the finite element analysis (FEA) model alone. To\nfurther accelerate simulations and improve model accuracy, Physics-Informed\nNeural Networks (PINNs) will be integrated with the reduced-order model. This\nhybrid approach will help expand the model to a larger dataset, enhancing\nintraocular pressure (IOP) estimation accuracy and the corneal material\nproperties algorithm through inverse FEA. Additionally, a neural network (NN)\nframework with embedded Gaussian-modulated waveforms is proposed to model the\npressure and deformation distributions on the corneal surface as functions of\nspatial and temporal parameters. By learning the relationship between corneal\nbiomechanical inputs such as Corneal Central Thickness (CCT), Intraocular\nPressure (IOP), and baseline properties (Mu), and the governing coefficients of\npressure and deformation, the network accurately reconstructs the result that\nmatches well with the high-fidelity CFD data. This approach can quickly capture\nthe distribution of pressure and deformation. It can also provide insights into\nthe distinct spatial and temporal dynamics of pressure and deformation, giving\na more comprehensive understanding of fluid-structure interaction phenomena in\nthe air puff test.",
    "pdf_url": "http://arxiv.org/pdf/2505.22495v1",
    "published": "2025-05-28T15:46:21+00:00",
    "categories": [
      "physics.flu-dyn",
      "physics.bio-ph",
      "physics.comp-ph"
    ],
    "primary_category": "physics.flu-dyn"
  },
  {
    "id": "http://arxiv.org/abs/2505.22494v1",
    "title": "ProSpero: Active Learning for Robust Protein Design Beyond Wild-Type Neighborhoods",
    "authors": [
      "Michal Kmicikiewicz",
      "Vincent Fortuin",
      "Ewa Szczurek"
    ],
    "abstract": "Designing protein sequences of both high fitness and novelty is a challenging\ntask in data-efficient protein engineering. Exploration beyond wild-type\nneighborhoods often leads to biologically implausible sequences or relies on\nsurrogate models that lose fidelity in novel regions. Here, we propose\nProSpero, an active learning framework in which a frozen pre-trained generative\nmodel is guided by a surrogate updated from oracle feedback. By integrating\nfitness-relevant residue selection with biologically-constrained Sequential\nMonte Carlo sampling, our approach enables exploration beyond wild-type\nneighborhoods while preserving biological plausibility. We show that our\nframework remains effective even when the surrogate is misspecified. ProSpero\nconsistently outperforms or matches existing methods across diverse protein\nengineering tasks, retrieving sequences of both high fitness and novelty.",
    "pdf_url": "http://arxiv.org/pdf/2505.22494v1",
    "published": "2025-05-28T15:45:43+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.22493v2",
    "title": "Convergence in law for quasi-linear SPDEs",
    "authors": [
      "Maria Jolis",
      "Salvador Ortiz-Latorre",
      "Llu√≠s Quer-Sardanyons"
    ],
    "abstract": "We consider the quasi-linear stochastic wave and heat equations in\n$\\mathbb{R}^d$ with $d\\in \\{1,2,3\\}$ and $d\\geq 1$, respectively, and perturbed\nby an additive Gaussian noise which is white in time and has a homogeneous\nspatial correlation with spectral measure $\\mu_n$. We allow the Fourier\ntransform of $\\mu_n$ to be a genuine distribution. Let $u^n$ be the mild\nsolution to these equations. We provide sufficient conditions on the measures\n$\\mu_n$ and the initial data to ensure that $u^n$ converges in law, in the\nspace of continuous functions, to the solution of our equations driven by a\nnoise with spectral measure $\\mu$, where $\\mu_n\\to\\mu$ in some sense. We apply\nour main result to various types of noises, such as the anisotropic fractional\nnoise. We also show that we cover existing results in the literature, such as\nthe case of Riesz kernels and the fractional noise with $d=1$.",
    "pdf_url": "http://arxiv.org/pdf/2505.22493v2",
    "published": "2025-05-28T15:45:23+00:00",
    "categories": [
      "math.PR",
      "60H15, 60B10"
    ],
    "primary_category": "math.PR"
  },
  {
    "id": "http://arxiv.org/abs/2505.22492v1",
    "title": "Demystifying the Paradox of Importance Sampling with an Estimated History-Dependent Behavior Policy in Off-Policy Evaluation",
    "authors": [
      "Hongyi Zhou",
      "Josiah P. Hanna",
      "Jin Zhu",
      "Ying Yang",
      "Chengchun Shi"
    ],
    "abstract": "This paper studies off-policy evaluation (OPE) in reinforcement learning with\na focus on behavior policy estimation for importance sampling. Prior work has\nshown empirically that estimating a history-dependent behavior policy can lead\nto lower mean squared error (MSE) even when the true behavior policy is\nMarkovian. However, the question of why the use of history should lower MSE\nremains open. In this paper, we theoretically demystify this paradox by\nderiving a bias-variance decomposition of the MSE of ordinary importance\nsampling (IS) estimators, demonstrating that history-dependent behavior policy\nestimation decreases their asymptotic variances while increasing their\nfinite-sample biases. Additionally, as the estimated behavior policy conditions\non a longer history, we show a consistent decrease in variance. We extend these\nfindings to a range of other OPE estimators, including the sequential IS\nestimator, the doubly robust estimator and the marginalized IS estimator, with\nthe behavior policy estimated either parametrically or non-parametrically.",
    "pdf_url": "http://arxiv.org/pdf/2505.22492v1",
    "published": "2025-05-28T15:42:20+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.06320v1",
    "title": "EvoGrad: Metaheuristics in a Differentiable Wonderland",
    "authors": [
      "Beatrice F. R. Citterio",
      "Andrea Tangherloni"
    ],
    "abstract": "Differentiable programming has revolutionised optimisation by enabling\nefficient gradient-based training of complex models, such as Deep Neural\nNetworks (NNs) with billions and trillions of parameters. However, traditional\nEvolutionary Computation (EC) and Swarm Intelligence (SI) algorithms, widely\nsuccessful in discrete or complex search spaces, typically do not leverage\nlocal gradient information, limiting their optimisation efficiency. In this\npaper, we introduce EvoGrad, a unified differentiable framework that integrates\nEC and SI with gradient-based optimisation through backpropagation. EvoGrad\nconverts conventional evolutionary and swarm operators (e.g., selection,\nmutation, crossover, and particle updates) into differentiable operators,\nfacilitating end-to-end gradient optimisation. Extensive experiments on\nbenchmark optimisation functions and training of small NN regressors reveal\nthat our differentiable versions of EC and SI metaheuristics consistently\noutperform traditional, gradient-agnostic algorithms in most scenarios. Our\nresults show the substantial benefits of fully differentiable evolutionary and\nswarm optimisation, setting a new standard for hybrid optimisation frameworks.",
    "pdf_url": "http://arxiv.org/pdf/2506.06320v1",
    "published": "2025-05-28T15:42:07+00:00",
    "categories": [
      "cs.NE"
    ],
    "primary_category": "cs.NE"
  },
  {
    "id": "http://arxiv.org/abs/2505.22491v1",
    "title": "On the Surprising Effectiveness of Large Learning Rates under Standard Width Scaling",
    "authors": [
      "Moritz Haas",
      "Sebastian Bordt",
      "Ulrike von Luxburg",
      "Leena Chennuru Vankadara"
    ],
    "abstract": "The dominant paradigm for training large-scale vision and language models is\nHe initialization and a single global learning rate (\\textit{standard\nparameterization}, SP). Despite its practical success, standard parametrization\nremains poorly understood from a theoretical perspective: Existing\ninfinite-width theory would predict instability under large learning rates and\nvanishing feature learning under stable learning rates. However, empirically\noptimal learning rates consistently decay much slower than theoretically\npredicted. By carefully studying neural network training dynamics, we\ndemonstrate that this discrepancy is not fully explained by finite-width\nphenomena such as catapult effects or a lack of alignment between weights and\nincoming activations. We instead show that the apparent contradiction can be\nfundamentally resolved by taking the loss function into account: In contrast to\nMean Squared Error (MSE) loss, we prove that under cross-entropy (CE) loss, an\nintermediate \\textit{controlled divergence} regime emerges, where logits\ndiverge but loss, gradients, and activations remain stable. Stable training\nunder large learning rates enables persistent feature evolution at scale in all\nhidden layers, which is crucial for the practical success of SP. In experiments\nacross optimizers (SGD, Adam), architectures (MLPs, GPT) and data modalities\n(vision, language), we validate that neural networks operate in this controlled\ndivergence regime under CE loss but not under MSE loss. Our empirical evidence\nsuggests that width-scaling considerations are surprisingly useful for\npredicting empirically optimal learning rate exponents. Finally, our analysis\nclarifies the effectiveness and limitations of recently proposed layerwise\nlearning rate scalings for standard initialization.",
    "pdf_url": "http://arxiv.org/pdf/2505.22491v1",
    "published": "2025-05-28T15:40:48+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.22490v1",
    "title": "ProCrop: Learning Aesthetic Image Cropping from Professional Compositions",
    "authors": [
      "Ke Zhang",
      "Tianyu Ding",
      "Jiachen Jiang",
      "Tianyi Chen",
      "Ilya Zharkov",
      "Vishal M. Patel",
      "Luming Liang"
    ],
    "abstract": "Image cropping is crucial for enhancing the visual appeal and narrative\nimpact of photographs, yet existing rule-based and data-driven approaches often\nlack diversity or require annotated training data. We introduce ProCrop, a\nretrieval-based method that leverages professional photography to guide\ncropping decisions. By fusing features from professional photographs with those\nof the query image, ProCrop learns from professional compositions,\nsignificantly boosting performance. Additionally, we present a large-scale\ndataset of 242K weakly-annotated images, generated by out-painting professional\nimages and iteratively refining diverse crop proposals. This composition-aware\ndataset generation offers diverse high-quality crop proposals guided by\naesthetic principles and becomes the largest publicly available dataset for\nimage cropping. Extensive experiments show that ProCrop significantly\noutperforms existing methods in both supervised and weakly-supervised settings.\nNotably, when trained on the new dataset, our ProCrop surpasses previous\nweakly-supervised methods and even matches fully supervised approaches. Both\nthe code and dataset will be made publicly available to advance research in\nimage aesthetics and composition analysis.",
    "pdf_url": "http://arxiv.org/pdf/2505.22490v1",
    "published": "2025-05-28T15:38:44+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.22489v1",
    "title": "Cascaded 3D Diffusion Models for Whole-body 3D 18-F FDG PET/CT synthesis from Demographics",
    "authors": [
      "Siyeop Yoon",
      "Sifan Song",
      "Pengfei Jin",
      "Matthew Tivnan",
      "Yujin Oh",
      "Sekeun Kim",
      "Dufan Wu",
      "Xiang Li",
      "Quanzheng Li"
    ],
    "abstract": "We propose a cascaded 3D diffusion model framework to synthesize\nhigh-fidelity 3D PET/CT volumes directly from demographic variables, addressing\nthe growing need for realistic digital twins in oncologic imaging, virtual\ntrials, and AI-driven data augmentation. Unlike deterministic phantoms, which\nrely on predefined anatomical and metabolic templates, our method employs a\ntwo-stage generative process. An initial score-based diffusion model\nsynthesizes low-resolution PET/CT volumes from demographic variables alone,\nproviding global anatomical structures and approximate metabolic activity. This\nis followed by a super-resolution residual diffusion model that refines spatial\nresolution. Our framework was trained on 18-F FDG PET/CT scans from the AutoPET\ndataset and evaluated using organ-wise volume and standardized uptake value\n(SUV) distributions, comparing synthetic and real data between demographic\nsubgroups. The organ-wise comparison demonstrated strong concordance between\nsynthetic and real images. In particular, most deviations in metabolic uptake\nvalues remained within 3-5% of the ground truth in subgroup analysis. These\nfindings highlight the potential of cascaded 3D diffusion models to generate\nanatomically and metabolically accurate PET/CT images, offering a robust\nalternative to traditional phantoms and enabling scalable, population-informed\nsynthetic imaging for clinical and research applications.",
    "pdf_url": "http://arxiv.org/pdf/2505.22489v1",
    "published": "2025-05-28T15:38:33+00:00",
    "categories": [
      "eess.IV",
      "cs.CV",
      "cs.GR"
    ],
    "primary_category": "eess.IV"
  },
  {
    "id": "http://arxiv.org/abs/2505.22488v1",
    "title": "Raman Optical Activity Induced by Ferroaxial Order in $\\textrm{NiTiO}_3$",
    "authors": [
      "Gakuto Kusuno",
      "Takeshi Hayashida",
      "Takayuki Nagai",
      "Hikaru Watanabe",
      "Rikuto Oiwa",
      "Tsuyoshi Kimura",
      "Takuya Satoh"
    ],
    "abstract": "Raman optical activity (ROA) -- the dependence of Raman scattered light\nintensity on the circular polarization of incident and scattered light -- has\ntraditionally been associated with chiral molecules and magnetic materials. In\nthis study, we demonstrate that ROA can also arise in ferroaxial materials that\npossess spatial inversion and time-reversal symmetries. Using circularly\npolarized Raman spectroscopy on single-crystalline $\\textrm{NiTiO}_3$, we\nobserved a pronounced ROA signal in the cross-circular polarization\nconfiguration, which correlates with the ferroaxial domain structure. Our\nsymmetry analysis and tight-binding model calculations reveal that the natural\nROA (NROA) originates from the ferroaxial order and persists even within the\nelectric dipole approximation. These results establish ROA as a powerful probe\nof ferroaxial order in centrosymmetric systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.22488v1",
    "published": "2025-05-28T15:36:50+00:00",
    "categories": [
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2505.22487v1",
    "title": "Effective Context in Neural Speech Models",
    "authors": [
      "Yen Meng",
      "Sharon Goldwater",
      "Hao Tang"
    ],
    "abstract": "Modern neural speech models benefit from having longer context, and many\napproaches have been proposed to increase the maximum context a model can use.\nHowever, few have attempted to measure how much context these models actually\nuse, i.e., the effective context. Here, we propose two approaches to measuring\nthe effective context, and use them to analyze different speech Transformers.\nFor supervised models, we find that the effective context correlates well with\nthe nature of the task, with fundamental frequency tracking, phone\nclassification, and word classification requiring increasing amounts of\neffective context. For self-supervised models, we find that effective context\nincreases mainly in the early layers, and remains relatively short -- similar\nto the supervised phone model. Given that these models do not use a long\ncontext during prediction, we show that HuBERT can be run in streaming mode\nwithout modification to the architecture and without further fine-tuning.",
    "pdf_url": "http://arxiv.org/pdf/2505.22487v1",
    "published": "2025-05-28T15:36:44+00:00",
    "categories": [
      "cs.SD",
      "cs.CL",
      "eess.AS"
    ],
    "primary_category": "cs.SD"
  },
  {
    "id": "http://arxiv.org/abs/2505.22486v1",
    "title": "Understanding Adversarial Training with Energy-based Models",
    "authors": [
      "Mujtaba Hussain Mirza",
      "Maria Rosaria Briglia",
      "Filippo Bartolucci",
      "Senad Beadini",
      "Giuseppe Lisanti",
      "Iacopo Masi"
    ],
    "abstract": "We aim at using Energy-based Model (EBM) framework to better understand\nadversarial training (AT) in classifiers, and additionally to analyze the\nintrinsic generative capabilities of robust classifiers. By viewing standard\nclassifiers through an energy lens, we begin by analyzing how the energies of\nadversarial examples, generated by various attacks, differ from those of the\nnatural samples. The central focus of our work is to understand the critical\nphenomena of Catastrophic Overfitting (CO) and Robust Overfitting (RO) in AT\nfrom an energy perspective. We analyze the impact of existing AT approaches on\nthe energy of samples during training and observe that the behavior of the\n``delta energy' -- change in energy between original sample and its adversarial\ncounterpart -- diverges significantly when CO or RO occurs. After a thorough\nanalysis of these energy dynamics and their relationship with overfitting, we\npropose a novel regularizer, the Delta Energy Regularizer (DER), designed to\nsmoothen the energy landscape during training. We demonstrate that DER is\neffective in mitigating both CO and RO across multiple benchmarks. We further\nshow that robust classifiers, when being used as generative models, have limits\nin handling trade-off between image quality and variability. We propose an\nimproved technique based on a local class-wise principal component analysis\n(PCA) and energy-based guidance for better class-specific initialization and\nadaptive stopping, enhancing sample diversity and generation quality.\nConsidering that we do not explicitly train for generative modeling, we achieve\na competitive Inception Score (IS) and Fr\\'echet inception distance (FID)\ncompared to hybrid discriminative-generative models.",
    "pdf_url": "http://arxiv.org/pdf/2505.22486v1",
    "published": "2025-05-28T15:36:02+00:00",
    "categories": [
      "cs.LG",
      "cs.CV"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.22485v1",
    "title": "Random Schr√∂dinger operators and convolution on wreath products",
    "authors": [
      "Adam Arras"
    ],
    "abstract": "We establish a spectral correspondence between random Schr\\\"odinger operators\nand deterministic convolution operators on wreath products, generalizing\nprevious results that relate Lamplighter groups to Schr\\\"odinger operators with\nBernoulli potentials. Using this correspondence in both directions, we obtain\nan elementary criterion for the absolute continuity of convolutions on wreath\nproducts, Lifschitz tail estimates for Schr\\\"odinger operators on Cayley graphs\nof polynomial growth, and an exact formula for the second moment of the Green\nfunction, expressed in terms of the wreath product with an Abelian group of\nlamps.",
    "pdf_url": "http://arxiv.org/pdf/2505.22485v1",
    "published": "2025-05-28T15:35:45+00:00",
    "categories": [
      "math.PR",
      "math.GR",
      "math.SP"
    ],
    "primary_category": "math.PR"
  },
  {
    "id": "http://arxiv.org/abs/2505.22484v2",
    "title": "Comparative analysis of robust entanglement generation in engineered XX spin chains",
    "authors": [
      "Eduardo K. Soares",
      "Gentil D. de Moraes Neto",
      "Fabiano M. Andrade"
    ],
    "abstract": "We present a numerical investigation comparing two entanglement generation\nprotocols in finite XX spin chains with varying spin magnitudes ($s = 1/2, 1,\n3/2 $). Protocol 1 (P1) relies on staggered couplings to steer correlations\ntoward the ends of the chain. At the same time, Protocol 2 (P2) adopts a\ndual-port architecture that uses optimized boundary fields to mediate virtual\nexcitations between terminal spins. Our results show that P2 consistently\noutperforms P1 in all spin values, generating higher-fidelity entanglement in\nshorter timescales when evaluated under the same system parameters.\nFurthermore, P2 exhibits superior robustness under realistic imperfections,\nincluding diagonal and off-diagonal disorder, as well as dephasing noise. These\nadvantages stem from its ability to suppress the bulk population and minimize\nsusceptibility to decoherence. Together, the scalability, efficiency, and noise\nresilience of the dual-port approach position it as a promising framework for\nentanglement distribution in solid-state quantum information platforms.",
    "pdf_url": "http://arxiv.org/pdf/2505.22484v2",
    "published": "2025-05-28T15:35:41+00:00",
    "categories": [
      "quant-ph",
      "math-ph",
      "math.MP"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.22483v2",
    "title": "A Closer Look at Multimodal Representation Collapse",
    "authors": [
      "Abhra Chaudhuri",
      "Anjan Dutta",
      "Tu Bui",
      "Serban Georgescu"
    ],
    "abstract": "We aim to develop a fundamental understanding of modality collapse, a\nrecently observed empirical phenomenon wherein models trained for multimodal\nfusion tend to rely only on a subset of the modalities, ignoring the rest. We\nshow that modality collapse happens when noisy features from one modality are\nentangled, via a shared set of neurons in the fusion head, with predictive\nfeatures from another, effectively masking out positive contributions from the\npredictive features of the former modality and leading to its collapse. We\nfurther prove that cross-modal knowledge distillation implicitly disentangles\nsuch representations by freeing up rank bottlenecks in the student encoder,\ndenoising the fusion-head outputs without negatively impacting the predictive\nfeatures from either modality. Based on the above findings, we propose an\nalgorithm that prevents modality collapse through explicit basis reallocation,\nwith applications in dealing with missing modalities. Extensive experiments on\nmultiple multimodal benchmarks validate our theoretical claims. Project page:\nhttps://abhrac.github.io/mmcollapse/.",
    "pdf_url": "http://arxiv.org/pdf/2505.22483v2",
    "published": "2025-05-28T15:31:53+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.22482v1",
    "title": "Inline calibration of spatial light modulators in nonlinear microscopy",
    "authors": [
      "Dani√´l W. S. Cox",
      "Harish Sasikumar",
      "Ivo M. Vellekoop"
    ],
    "abstract": "We present a method for calibrating the response of a phase-only spatial\nlight modulator in nonlinear microscopy. Our method uses the microscope image\nitself as calibration measurement and requires no additional hardware\ncomponents. Our method is adapted to the nonlinear signals encountered in\nmulti-photon excitation fluorescence microscopes, and works well even under low\nlight conditions and with strong photobleaching.",
    "pdf_url": "http://arxiv.org/pdf/2505.22482v1",
    "published": "2025-05-28T15:31:30+00:00",
    "categories": [
      "physics.optics"
    ],
    "primary_category": "physics.optics"
  },
  {
    "id": "http://arxiv.org/abs/2505.22481v1",
    "title": "Hypothesis Testing in Imaging Inverse Problems",
    "authors": [
      "Yiming Xi",
      "Konstantinos Zygalakis",
      "Marcelo Pereyra"
    ],
    "abstract": "This paper proposes a framework for semantic hypothesis testing tailored to\nimaging inverse problems. Modern imaging methods struggle to support hypothesis\ntesting, a core component of the scientific method that is essential for the\nrigorous interpretation of experiments and robust interfacing with\ndecision-making processes. There are three main reasons why image-based\nhypothesis testing is challenging. First, the difficulty of using a single\nobservation to simultaneously reconstruct an image, formulate hypotheses, and\nquantify their statistical significance. Second, the hypotheses encountered in\nimaging are mostly of semantic nature, rather than quantitative statements\nabout pixel values. Third, it is challenging to control test error\nprobabilities because the null and alternative distributions are often unknown.\nOur proposed approach addresses these difficulties by leveraging concepts from\nself-supervised computational imaging, vision-language models, and\nnon-parametric hypothesis testing with e-values. We demonstrate our proposed\nframework through numerical experiments related to image-based phenotyping,\nwhere we achieve excellent power while robustly controlling Type I errors.",
    "pdf_url": "http://arxiv.org/pdf/2505.22481v1",
    "published": "2025-05-28T15:29:43+00:00",
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2505.22480v2",
    "title": "Hybrid High-Order formulations with turbulence modelling capabilities for incompressible flow problems",
    "authors": [
      "Lorenzo Botti",
      "Daniele Antonio Di Pietro",
      "Francesco Carlo Massa"
    ],
    "abstract": "We propose a Hybrid High-Order (HHO) formulation of the incompressible\nNavier--Stokes equations, that is well suited to be employed for the simulation\nof turbulent flows. The spatial discretization relies on hybrid velocity and\npressure spaces and the temporal discretization is based on Explicit Singly\nDiagonal Implicit Runge-Kutta (ESDIRK) methods. The formulation possesses some\nattractive features that can be fruitfully exploited when high-fidelity\ncomputations are required, namely: pressure-robustness, conservation of mass\nenforced cell-by-cell up to machine precision, robustness in the inviscid\nlimit, implicit high-order accurate time stepping with local time step\nadaptation, reduced memory footprint thanks to static condensation of both\nvelocity and pressure, possibility to exploit inherited $p$-multilevel solution\nstrategies to improve performance of iterative solvers. After demonstrating the\nrelevant properties of the scheme in practice, performing challenging 2D and 3D\ntest cases, we consider the simulation of the Taylor--Green Vortex flow problem\nat Reynolds 1600.",
    "pdf_url": "http://arxiv.org/pdf/2505.22480v2",
    "published": "2025-05-28T15:29:00+00:00",
    "categories": [
      "physics.flu-dyn",
      "cs.NA",
      "math.NA"
    ],
    "primary_category": "physics.flu-dyn"
  },
  {
    "id": "http://arxiv.org/abs/2505.22479v1",
    "title": "Impact of Pre-Assessment and Post-Assessment in an Introductory Real Analysis Course",
    "authors": [
      "Chamila Malagoda Gamage"
    ],
    "abstract": "This study explores how pre- and post-assessments shape learning outcomes in\nan Introductory Real Analysis course. Pre-assessments act as learning roadmaps,\nhighlighting prior knowledge and guiding student focus, while post-assessments\nmeasure growth and conceptual mastery. By analyzing student performance and\nfeedback, we assess their impact on engagement, self-efficacy, and deeper\nmathematical understanding. The findings offer valuable insights for enhancing\ninstructional strategies and fostering a more effective, student-centered\nlearning experience in advanced mathematics.",
    "pdf_url": "http://arxiv.org/pdf/2505.22479v1",
    "published": "2025-05-28T15:28:52+00:00",
    "categories": [
      "math.HO"
    ],
    "primary_category": "math.HO"
  },
  {
    "id": "http://arxiv.org/abs/2505.22478v1",
    "title": "Invariant Gibbs measures for the one-dimensional quintic nonlinear Schr√∂dinger equation in infinite volume",
    "authors": [
      "Bjoern Bringmann",
      "Gigliola Staffilani"
    ],
    "abstract": "We prove the invariance of the Gibbs measure for the defocusing quintic\nnonlinear Schr\\\"odinger equation on the real line. This builds on earlier work\nby Bourgain, who treated the cubic nonlinearity. The key new ingredient is a\ngrowth estimate for the infinite-volume $\\Phi^{p+1}_1$-measures, which is\nproven via the stochastic quantization method.",
    "pdf_url": "http://arxiv.org/pdf/2505.22478v1",
    "published": "2025-05-28T15:28:32+00:00",
    "categories": [
      "math.AP",
      "math.PR",
      "35R60, 35Q55, 81T08"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2505.22477v1",
    "title": "Human-Centered Human-AI Collaboration (HCHAC)",
    "authors": [
      "Qi Gao",
      "Wei Xu",
      "Hanxi Pan",
      "Mowei Shen",
      "Zaifeng Gao"
    ],
    "abstract": "In the intelligent era, the interaction between humans and intelligent\nsystems fundamentally involves collaboration with autonomous intelligent\nagents. Human-AI Collaboration (HAC) represents a novel type of human-machine\nrelationship facilitated by autonomous intelligent machines equipped with AI\ntechnologies. In this paradigm, AI agents serve not only as auxiliary tools but\nalso as active teammates, partnering with humans to accomplish tasks\ncollaboratively. Human-centered AI (HCAI) emphasizes that humans play critical\nleadership roles in the collaboration. This human-led collaboration imparts new\ndimensions to the human-machine relationship, necessitating innovative research\nperspectives, paradigms, and agenda to address the unique challenges posed by\nHAC. This chapter delves into the essence of HAC from the human-centered\nperspective, outlining its core concepts and distinguishing features. It\nreviews the current research methodologies and research agenda within the HAC\nfield from the HCAI perspective, highlighting advancements and ongoing studies.\nFurthermore, a framework for human-centered HAC (HCHAC) is proposed by\nintegrating these reviews and analyses. A case study of HAC in the context of\nautonomous vehicles is provided, illustrating practical applications and the\nsynergistic interactions between humans and AI agents. Finally, it identifies\npotential future research directions aimed at enhancing the effectiveness,\nreliability, and ethical integration of human-centered HAC systems in diverse\ndomains.",
    "pdf_url": "http://arxiv.org/pdf/2505.22477v1",
    "published": "2025-05-28T15:27:52+00:00",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2505.22476v1",
    "title": "Science for Peace and the need for Civil Clauses at universities and civilian research institutions",
    "authors": [
      "J. Altmann",
      "U. Amaldi",
      "M. Barone",
      "A. Bassalat",
      "M. Bona",
      "J. Beullens",
      "H. Brand",
      "S. Brentjes",
      "D. Britzger",
      "J. Ellis",
      "S. Franchoo",
      "A. Giammanco",
      "A. Glazov",
      "C. Heck",
      "H. Jung",
      "S. Kraml",
      "L. L√∂nnblad",
      "M. Mangano",
      "M. Renneberg",
      "Th. Riebe",
      "A. Sabio-Vera",
      "R. Sanders",
      "J. Scheffran",
      "M. Schmelling",
      "T. Schucker",
      "T. Suzuki",
      "A. Tanasijczuk",
      "I. Tsakov",
      "D. Valls-Gabaud",
      "M. Walker"
    ],
    "abstract": "After the end of World War II, the commitment to confine scientific\nactivities in universities and research institutions to peaceful and civilian\npurposes has entered, in the form of {\\it Civil Clauses}, the charters of many\nresearch institutions and universities. In the wake of recent world events, the\nrelevance and scope of such Civil Clauses has been questioned in reports issued\nby some governments and by the EU Commission, a development that opens the door\nto a possible blurring of the distinction between peaceful and military\nresearch.\n  This paper documents the reflections stimulated by a panel discussion on this\nissue recently organized by the Science4Peace Forum. We review the adoptions of\nCivil Clauses in research organizations and institutions in various countries,\npresent evidence of the challenges that are emerging to such Civil Clauses, and\ncollect arguments in favour of maintaining the purely civilian and peaceful\nfocus of public (non-military) research.",
    "pdf_url": "http://arxiv.org/pdf/2505.22476v1",
    "published": "2025-05-28T15:27:22+00:00",
    "categories": [
      "physics.soc-ph",
      "hep-ex",
      "hep-ph"
    ],
    "primary_category": "physics.soc-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.22475v1",
    "title": "Non-Asymptotic Analysis of (Sticky) Track-and-Stop",
    "authors": [
      "Riccardo Poiani",
      "Martino Bernasconi",
      "Andrea Celli"
    ],
    "abstract": "In pure exploration problems, a statistician sequentially collects\ninformation to answer a question about some stochastic and unknown environment.\nThe probability of returning a wrong answer should not exceed a maximum risk\nparameter $\\delta$ and good algorithms make as few queries to the environment\nas possible. The Track-and-Stop algorithm is a pioneering method to solve these\nproblems. Specifically, it is well-known that it enjoys asymptotic optimality\nsample complexity guarantees for $\\delta\\to 0$ whenever the map from the\nenvironment to its correct answers is single-valued (e.g., best-arm\nidentification with a unique optimal arm). The Sticky Track-and-Stop algorithm\nextends these results to settings where, for each environment, there might\nexist multiple correct answers (e.g., $\\epsilon$-optimal arm identification).\nAlthough both methods are optimal in the asymptotic regime, their\nnon-asymptotic guarantees remain unknown. In this work, we fill this gap and\nprovide non-asymptotic guarantees for both algorithms.",
    "pdf_url": "http://arxiv.org/pdf/2505.22475v1",
    "published": "2025-05-28T15:26:55+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.22474v2",
    "title": "Forecasting Multivariate Urban Data via Decomposition and Spatio-Temporal Graph Analysis",
    "authors": [
      "Amirhossein Sohrabbeig",
      "Omid Ardakanian",
      "Petr Musilek"
    ],
    "abstract": "Long-term forecasting of multivariate urban data poses a significant\nchallenge due to the complex spatiotemporal dependencies inherent in such\ndatasets. This paper presents DST, a novel multivariate time-series forecasting\nmodel that integrates graph attention and temporal convolution within a Graph\nNeural Network (GNN) to effectively capture spatial and temporal dependencies,\nrespectively. To enhance model performance, we apply a decomposition-based\npreprocessing step that isolates trend, seasonal, and residual components of\nthe time series, enabling the learning of distinct graph structures for\ndifferent time-series components. Extensive experiments on real-world urban\ndatasets, including electricity demand, weather metrics, carbon intensity, and\nair pollution, demonstrate the effectiveness of DST across a range of forecast\nhorizons, from several days to one month. Specifically, our approach achieves\nan average improvement of 2.89% to 9.10% in long-term forecasting accuracy over\nstate-of-the-art time-series forecasting models.",
    "pdf_url": "http://arxiv.org/pdf/2505.22474v2",
    "published": "2025-05-28T15:24:04+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.22473v1",
    "title": "Pure Exploration with Infinite Answers",
    "authors": [
      "Riccardo Poiani",
      "Martino Bernasconi",
      "Andrea Celli"
    ],
    "abstract": "We study pure exploration problems where the set of correct answers is\npossibly infinite, e.g., the regression of any continuous function of the means\nof the bandit. We derive an instance-dependent lower bound for these problems.\nBy analyzing it, we discuss why existing methods (i.e., Sticky Track-and-Stop)\nfor finite answer problems fail at being asymptotically optimal in this more\ngeneral setting. Finally, we present a framework, Sticky-Sequence\nTrack-and-Stop, which generalizes both Track-and-Stop and Sticky\nTrack-and-Stop, and that enjoys asymptotic optimality. Due to its generality,\nour analysis also highlights special cases where existing methods enjoy\noptimality.",
    "pdf_url": "http://arxiv.org/pdf/2505.22473v1",
    "published": "2025-05-28T15:23:36+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.22472v1",
    "title": "Quantum transport phenomena induced by time-dependent fields",
    "authors": [
      "Matteo Acciai",
      "Liliana Arrachea",
      "Janine Splettstoesser"
    ],
    "abstract": "We present an overview of time-dependent transport phenomena in quantum\nsystems, with a particular emphasis on steady-state regimes. We present the\nideas after the main theoretical frameworks to study open-quantum systems out\nof equilibrium, that are useful to study quantum transport under time-dependent\ndriving. We discuss the fundamentals of the key mechanisms such as dissipation,\nquantum pumping, noise, and energy conversion that are associated to the\nproblem of quantum transport.\n  Our primary focus is on electronic systems, where decades of research have\nestablished a rich theoretical foundation and a wealth of experimental\nrealizations. Topics of interest include quantum optics with electrons,\nhigh-precision electron spectroscopy, quantum electrical metrology, and the\ncritical role of quantum fluctuations in transport and thermodynamics. We also\nextend the discussion to atomic, molecular, and optical systems, as well as\nnanomechanical platforms, which offer complementary perspectives and are\ncurrently experiencing rapid experimental development. Finally, we examine the\nintersection of time-dependent transport and topological matter, a domain of\nactive investigation.\n  This review aims to gather the diverse approaches and emerging trends that\ndefine the current landscape of quantum transport research under time-dependent\nconditions, bridging theoretical insights with experimental advances across\nmultiple physical platforms.",
    "pdf_url": "http://arxiv.org/pdf/2505.22472v1",
    "published": "2025-05-28T15:23:15+00:00",
    "categories": [
      "cond-mat.mes-hall"
    ],
    "primary_category": "cond-mat.mes-hall"
  },
  {
    "id": "http://arxiv.org/abs/2505.22471v1",
    "title": "Phase transitions for contact processes on sparse random graphs via metastability and local limits",
    "authors": [
      "Benedikt Jahnel",
      "Lukas L√ºchtrath",
      "Christian M√∂nch"
    ],
    "abstract": "We propose a new perspective on the asymptotic regimes of fast and slow\nextinction in the contact process on locally converging sequences of sparse\nfinite graphs. We characterise the phase boundary by the existence of a\nmetastable density, which makes the study of the phase transition particularly\namenable to local-convergence techniques. We use this approach to derive\ngeneral conditions for the coincidence of the critical threshold with the\nsurvival/extinction threshold in the local limit. We further argue that the\ncorrect time scale to separate fast extinction from slow extinction in sparse\ngraphs is, in general, the exponential scale, by showing that fast extinction\nmay occur on stretched exponential time scales in sparse scale-free spatial\nnetworks. Together with recent results by Nam, Nguyen and Sly (Trans. Am. Math.\nSoc. 375, 2022), our methods can be applied to deduce that the fast/slow\nthreshold in sparse configuration models coincides with the survival/extinction\nthreshold on the limiting Galton-Watson tree.",
    "pdf_url": "http://arxiv.org/pdf/2505.22471v1",
    "published": "2025-05-28T15:23:13+00:00",
    "categories": [
      "math.PR",
      "60K35 (primary), 05C82, 91D30 (secondary)"
    ],
    "primary_category": "math.PR"
  },
  {
    "id": "http://arxiv.org/abs/2505.22470v2",
    "title": "Infinitely many genus two and three curves of small fixed positive rank",
    "authors": [
      "Stevan Gajoviƒá",
      "Sun Woo Park"
    ],
    "abstract": "We prove that there exist infinitely many genus two curves over $\\mathbb{Q}$\nwhose Jacobians have ranks between $0$ and $11$, and genus three curves over\n$\\mathbb{Q}$ whose Jacobians have ranks $0$, $1$, and $2$. Furthermore, we\nconsider a generalisation of these results over number fields satisfying some\nconditions.",
    "pdf_url": "http://arxiv.org/pdf/2505.22470v2",
    "published": "2025-05-28T15:22:40+00:00",
    "categories": [
      "math.NT",
      "! 11G05, 11G30, 14G05"
    ],
    "primary_category": "math.NT"
  },
  {
    "id": "http://arxiv.org/abs/2505.22469v1",
    "title": "CPINN-ABPI: Physics-Informed Neural Networks for Accurate Power Estimation in MPSoCs",
    "authors": [
      "Mohamed R. Elshamy",
      "Mehdi Elahi",
      "Ahmad Patooghy",
      "Abdel-Hameed A. Badawy"
    ],
    "abstract": "Efficient thermal and power management in modern multiprocessor\nsystems-on-chip (MPSoCs) demands accurate power consumption estimation. One of\nthe state-of-the-art approaches, Alternative Blind Power Identification (ABPI),\ntheoretically eliminates the dependence on steady-state temperatures,\naddressing a major shortcoming of previous approaches. However, ABPI\nperformance has remained unverified in actual hardware implementations. In this\nstudy, we conduct the first empirical validation of ABPI on commercial hardware\nusing the NVIDIA Jetson Xavier AGX platform. Our findings reveal that, while\nABPI provides computational efficiency and independence from steady-state\ntemperature, it exhibits considerable accuracy deficiencies in real-world\nscenarios. To overcome these limitations, we introduce a novel approach that\nintegrates Custom Physics-Informed Neural Networks (CPINNs) with the underlying\nthermal model of ABPI. Our approach employs a specialized loss function that\nharmonizes physical principles with data-driven learning, complemented by\nmulti-objective genetic algorithm optimization to balance estimation accuracy\nand computational cost. In experimental validation, CPINN-ABPI achieves a\nreduction of 84.7\\% CPU and 73.9\\% GPU in the mean absolute error (MAE)\nrelative to ABPI, with the weighted mean absolute percentage error (WMAPE)\nimproving from 47\\%--81\\% to $\\sim$12\\%. The method maintains real-time\nperformance with 195.3~$\\mu$s of inference time, with similar 85\\%--99\\%\naccuracy gains across heterogeneous SoCs.",
    "pdf_url": "http://arxiv.org/pdf/2505.22469v1",
    "published": "2025-05-28T15:22:15+00:00",
    "categories": [
      "cs.PF",
      "cs.LG"
    ],
    "primary_category": "cs.PF"
  },
  {
    "id": "http://arxiv.org/abs/2505.22468v1",
    "title": "Continuity and approximability of competitive spectral radii",
    "authors": [
      "Marianne Akian",
      "St√©phane Gaubert",
      "Lo√Øc Marchesini",
      "Ian Morris"
    ],
    "abstract": "The competitive spectral radius extends the notion of joint spectral radius\nto the two-player case: two players alternatively select matrices in prescribed\ncompact sets, resulting in an infinite matrix product; one player wishes to\nmaximize the growth rate of this product, whereas the other player wishes to\nminimize it. We show that when the matrices represent linear operators\npreserving a cone and satisfying a \"strict positivity\" assumption, the\ncompetitive spectral radius depends continuously - and even in a\nLipschitz-continuous way - on the matrix sets. Moreover, we show that the\ncompetive spectral radius can be approximated up to any accuracy. This relies\non the solution of a discretized infinite dimensional non-linear eigenproblem.\nWe illustrate the approach with an example of age-structured population\ndynamics.",
    "pdf_url": "http://arxiv.org/pdf/2505.22468v1",
    "published": "2025-05-28T15:20:25+00:00",
    "categories": [
      "math.OC",
      "cs.NA",
      "math.DS",
      "math.NA"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2505.22467v2",
    "title": "Topological Structure Learning Should Be A Research Priority for LLM-Based Multi-Agent Systems",
    "authors": [
      "Jiaxi Yang",
      "Mengqi Zhang",
      "Yiqiao Jin",
      "Hao Chen",
      "Qingsong Wen",
      "Lu Lin",
      "Yi He",
      "Weijie Xu",
      "James Evans",
      "Jindong Wang"
    ],
    "abstract": "Large Language Model-based Multi-Agent Systems (MASs) have emerged as a\npowerful paradigm for tackling complex tasks through collaborative\nintelligence. Nevertheless, the question of how agents should be structurally\norganized for optimal cooperation remains largely unexplored. In this position\npaper, we aim to gently redirect the focus of the MAS research community toward\nthis critical dimension: develop topology-aware MASs for specific tasks.\nSpecifically, the system consists of three core components - agents,\ncommunication links, and communication patterns - that collectively shape its\ncoordination performance and efficiency. To this end, we introduce a\nsystematic, three-stage framework: agent selection, structure profiling, and\ntopology synthesis. Each stage would trigger new research opportunities in\nareas such as language models, reinforcement learning, graph learning, and\ngenerative modeling; together, they could unleash the full potential of MASs in\ncomplicated real-world applications. Then, we discuss the potential challenges\nand opportunities in the evaluation of multiple systems. We hope our\nperspective and framework can offer critical new insights in the era of agentic\nAI.",
    "pdf_url": "http://arxiv.org/pdf/2505.22467v2",
    "published": "2025-05-28T15:20:09+00:00",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.MA"
  },
  {
    "id": "http://arxiv.org/abs/2505.22466v1",
    "title": "Spontaneous Raman scattering from metastable states of Ba$^+$",
    "authors": [
      "Timothy J. Burke",
      "Xiaoyang Shi",
      "Jasmine Sinanan-Singh",
      "Isaac L. Chuang",
      "John Chiaverini"
    ],
    "abstract": "Quantum logic gates performed via two-photon stimulated-Raman transitions in\nions and atoms are fundamentally limited by spontaneous scattering errors.\nRecent theoretical treatment of these scattering processes has predicted no\nlower bound on the error rate of such gates when implemented with far-detuned\nlasers, while also providing an extension to metastable qubits. To validate\nthis theoretical model, we provide experimental measurements of Raman\nscattering rates due to near-, and far-detuned lasers for initial states in the\nmetastable D$_{5/2}$ level of $^{137}$Ba$^+$. The measured spontaneous Raman\nscattering rate is consistent with the theoretical prediction and suggests that\nmetastable-level two-qubit gates with an error rate $\\approx10^{-4}$ are\npossible with laser excitation detuned by tens of terahertz or more.",
    "pdf_url": "http://arxiv.org/pdf/2505.22466v1",
    "published": "2025-05-28T15:19:21+00:00",
    "categories": [
      "quant-ph",
      "physics.atom-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.22465v2",
    "title": "Single Domain Generalization for Alzheimer's Detection from 3D MRIs with Pseudo-Morphological Augmentations and Contrastive Learning",
    "authors": [
      "Zobia Batool",
      "Huseyin Ozkan",
      "Erchan Aptoula"
    ],
    "abstract": "Although Alzheimer's disease detection via MRIs has advanced significantly\nthanks to contemporary deep learning models, challenges such as class\nimbalance, protocol variations, and limited dataset diversity often hinder\ntheir generalization capacity. To address this issue, this article focuses on\nthe single domain generalization setting, where given the data of one domain, a\nmodel is designed and developed with maximal performance w.r.t. an unseen\ndomain of distinct distribution. Since brain morphology is known to play a\ncrucial role in Alzheimer's diagnosis, we propose the use of learnable\npseudo-morphological modules aimed at producing shape-aware, anatomically\nmeaningful class-specific augmentations in combination with a supervised\ncontrastive learning module to extract robust class-specific representations.\nExperiments conducted across three datasets show improved performance and\ngeneralization capacity, especially under class imbalance and imaging protocol\nvariations. The source code will be made available upon acceptance at\nhttps://github.com/zobia111/SDG-Alzheimer.",
    "pdf_url": "http://arxiv.org/pdf/2505.22465v2",
    "published": "2025-05-28T15:18:16+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.22464v1",
    "title": "A Paley-Wiener-Schwartz Theorem for smooth valuations on convex functions",
    "authors": [
      "Jonas Knoerr"
    ],
    "abstract": "Continuous dually epi-translation invariant valuations on convex functions\nare characterized in terms of the Fourier-Laplace transform of the associated\nGoodey-Weil distributions. This description is used to obtain integral\nrepresentations of the smooth vectors of the natural representation of the\ngroup of translations on the space of these valuations. As an application, a\ncomplete classification of all closed and affine invariant subspaces is\nestablished, yielding density results for valuations defined in terms of mixed\nMonge-Amp\\`ere operators.",
    "pdf_url": "http://arxiv.org/pdf/2505.22464v1",
    "published": "2025-05-28T15:18:04+00:00",
    "categories": [
      "math.FA",
      "math.MG",
      "52B45, 26B25, 53C65, 52A39, 13P10"
    ],
    "primary_category": "math.FA"
  },
  {
    "id": "http://arxiv.org/abs/2505.23843v1",
    "title": "Evaluation Hallucination in Multi-Round Incomplete Information Lateral-Driven Reasoning Tasks",
    "authors": [
      "Wenhan Dong",
      "Tianyi Hu",
      "Jingyi Zheng",
      "Zhen Sun",
      "Yuemeng Zhao",
      "Yule Liu",
      "Xinlei He",
      "Xinyi Huang"
    ],
    "abstract": "Multi-round incomplete information tasks are crucial for evaluating the\nlateral thinking capabilities of large language models (LLMs). Currently,\nresearch primarily relies on multiple benchmarks and automated evaluation\nmetrics to assess these abilities. However, our study reveals novel insights\ninto the limitations of existing methods, as they often yield misleading\nresults that fail to uncover key issues, such as shortcut-taking behaviors,\nrigid patterns, and premature task termination. These issues obscure the true\nreasoning capabilities of LLMs and undermine the reliability of evaluations. To\naddress these limitations, we propose a refined set of evaluation standards,\nincluding inspection of reasoning paths, diversified assessment metrics, and\ncomparative analyses with human performance.",
    "pdf_url": "http://arxiv.org/pdf/2505.23843v1",
    "published": "2025-05-28T15:17:34+00:00",
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.22463v2",
    "title": "Opening up New Parameter Space for Sterile Neutrino Dark Matter",
    "authors": [
      "P. S. Bhupal Dev",
      "Bhaskar Dutta",
      "Srubabati Goswami",
      "Jianrong Paul Tang",
      "Aaroodd Ujjayini Ramachandran"
    ],
    "abstract": "Sterile neutrinos are compelling dark matter (DM) candidates, yet the minimal\nproduction mechanism solely based on active ($\\nu_a$)-sterile ($\\nu_s$)\noscillations is excluded by astrophysical observations. Non-standard\nself-interactions in either active ($\\nu_a-\\nu_a$) or sterile ($\\nu_s-\\nu_s$)\nsector are known to alter the sterile neutrino DM production in the early\nUniverse, which could alleviate the tension with astrophysical constraints to\nsome extent. Here we propose a novel solution where scalar-mediated\nnon-standard interactions between active and sterile neutrinos ($\\nu_a-\\nu_s$)\ngenerate new production channels for $\\nu_s$, independent of the active-sterile\nmixing and without the need for any fine-tuned resonance or primordial lepton\nasymmetry. This framework enables efficient sterile neutrino DM production even\nat vanishingly small mixing angles and opens up new viable regions of parameter\nspace that can be tested with future $X$-ray and gamma-ray observations.",
    "pdf_url": "http://arxiv.org/pdf/2505.22463v2",
    "published": "2025-05-28T15:17:25+00:00",
    "categories": [
      "hep-ph",
      "astro-ph.CO"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.23342v1",
    "title": "Euclid: Early Release Observations of ram-pressure stripping in the Perseus cluster. Detection of parsec scale star formation with in the low surface brightness stripped tails of UGC 2665 and MCG +07-07-070",
    "authors": [
      "Koshy George",
      "A. Boselli",
      "J. -C. Cuillandre",
      "M. K√ºmmel",
      "A. Lan√ßon",
      "C. Bellhouse",
      "T. Saifollahi",
      "M. Mondelin",
      "M. Bolzonella",
      "P. Joseph",
      "I. D. Roberts",
      "R. J. van Weeren",
      "Q. Liu",
      "E. Sola",
      "M. Urbano",
      "M. Baes",
      "R. F. Peletier",
      "M. Klein",
      "C. T. Davies",
      "I. A. Zinchenko",
      "J. G. Sorce",
      "M. Poulain",
      "N. Aghanim",
      "B. Altieri",
      "A. Amara",
      "S. Andreon",
      "N. Auricchio",
      "C. Baccigalupi",
      "M. Baldi",
      "A. Balestra",
      "S. Bardelli",
      "P. Battaglia",
      "A. Biviano",
      "D. Bonino",
      "E. Branchini",
      "M. Brescia",
      "J. Brinchmann",
      "S. Camera",
      "G. Ca√±as-Herrera",
      "V. Capobianco",
      "C. Carbone",
      "J. Carretero",
      "S. Casas",
      "M. Castellano",
      "G. Castignani",
      "S. Cavuoti",
      "K. C. Chambers",
      "A. Cimatti",
      "C. Colodro-Conde",
      "G. Congedo",
      "C. J. Conselice",
      "L. Conversi",
      "Y. Copin",
      "F. Courbin",
      "H. M. Courtois",
      "M. Cropper",
      "A. Da Silva",
      "H. Degaudenzi",
      "G. De Lucia",
      "A. M. Di Giorgio",
      "H. Dole",
      "M. Douspis",
      "F. Dubath",
      "X. Dupac",
      "S. Dusini",
      "S. Escoffier",
      "M. Farina",
      "F. Faustini",
      "S. Ferriol",
      "S. Fotopoulou",
      "M. Frailis",
      "E. Franceschi",
      "S. Galeotta",
      "B. Gillis",
      "C. Giocoli",
      "J. Gracia-Carpio",
      "A. Grazian",
      "F. Grupp",
      "S. V. H. Haugan",
      "W. Holmes",
      "I. M. Hook",
      "F. Hormuth",
      "A. Hornstrup",
      "P. Hudelot",
      "K. Jahnke",
      "M. Jhabvala",
      "E. Keih√§nen",
      "S. Kermiche",
      "A. Kiessling",
      "B. Kubik",
      "M. Kunz",
      "H. Kurki-Suonio",
      "A. M. C. Le Brun",
      "D. Le Mignant",
      "S. Ligori",
      "P. B. Lilje",
      "V. Lindholm",
      "I. Lloro",
      "G. Mainetti",
      "D. Maino",
      "E. Maiorano",
      "O. Mansutti",
      "O. Marggraf",
      "K. Markovic",
      "M. Martinelli",
      "N. Martinet",
      "F. Marulli",
      "R. Massey",
      "S. Maurogordato",
      "E. Medinaceli",
      "S. Mei",
      "Y. Mellier",
      "M. Meneghetti",
      "E. Merlin",
      "G. Meylan",
      "J. J. Mohr",
      "A. Mora",
      "M. Moresco",
      "L. Moscardini",
      "R. Nakajima",
      "C. Neissner",
      "R. C. Nichol",
      "S. -M. Niemi",
      "J. W. Nightingale",
      "C. Padilla",
      "S. Paltani",
      "F. Pasian",
      "K. Pedersen",
      "W. J. Percival",
      "V. Pettorino",
      "S. Pires",
      "G. Polenta",
      "M. Poncet",
      "L. A. Popa",
      "L. Pozzetti",
      "F. Raison",
      "R. Rebolo",
      "A. Renzi",
      "J. Rhodes",
      "G. Riccio",
      "E. Romelli",
      "M. Roncarelli",
      "E. Rossetti",
      "R. Saglia",
      "Z. Sakr",
      "D. Sapone",
      "B. Sartoris",
      "J. A. Schewtschenko",
      "M. Schirmer",
      "P. Schneider",
      "A. Secroun",
      "G. Seidel",
      "M. Seiffert",
      "S. Serrano",
      "C. Sirignano",
      "G. Sirri",
      "L. Stanco",
      "J. Steinwagner",
      "P. Tallada-Cresp√≠",
      "A. N. Taylor",
      "I. Tereno",
      "S. Toft",
      "R. Toledo-Moreo",
      "F. Torradeflot",
      "I. Tutusaus",
      "E. A. Valentijn",
      "L. Valenziano",
      "J. Valiviita",
      "T. Vassallo",
      "G. Verdoes Kleijn",
      "A. Veropalumbo",
      "Y. Wang",
      "J. Weller",
      "G. Zamorani",
      "F. M. Zerbi",
      "E. Zucca",
      "C. Burigana",
      "L. Gabarra",
      "J. Mart√≠n-Fleitas",
      "V. Scottez"
    ],
    "abstract": "Euclid is delivering optical and near-infrared imaging data over 14,000\ndeg$^2$ on the sky at spatial resolution and surface brightness levels that can\nbe used to understand the morphological transformation of galaxies within\ngroups and clusters. Using the Early Release Observations (ERO) of the Perseus\ncluster, we demonstrate the capability offered by Euclid in studying the nature\nof perturbations for galaxies in clusters. Filamentary structures are observed\nalong the discs of two spiral galaxies with no extended diffuse emission\nexpected from tidal interactions at surface brightness levels of $\\sim$\n$30\\,{\\rm mag}\\,{\\rm arcsec}^{-2}$. The detected features exhibit a good\ncorrespondence in morphology between optical and near-infrared wavelengths,\nwith a surface brightness of $\\sim$ $25\\,{\\rm mag}\\,{\\rm arcsec}^{-2}$, and the\nknots within the features have sizes of $\\sim$ 100 pc, as observed through\n$I_E$ imaging. Using the Euclid, CFHT, UVIT, and LOFAR $144\\,{\\rm MHz}$ radio\ncontinuum observations, we conduct a detailed analysis to understand the origin\nof the detected features. We constructed the \\textit{Euclid} $I_E-Y_E$,\n$Y_E-H_E$, and CFHT $u - r$, $g - i$ colour-colour plane and showed that these\nfeatures contain recent star formation events, which are also indicated by\ntheir H$\\alpha$ and NUV emissions. Euclid colours alone are insufficient for\nstudying stellar population ages in unresolved star-forming regions, which\nrequire multi-wavelength optical imaging data. The morphological shape,\norientation, and mean age of the stellar population, combined with the presence\nof extended radio continuum cometary tails can be consistently explained if\nthese features have been formed during a recent ram-pressure stripping event.\nThis result further confirms the exceptional qualities of Euclid in the study\nof galaxy evolution in dense environments.",
    "pdf_url": "http://arxiv.org/pdf/2505.23342v1",
    "published": "2025-05-28T15:17:18+00:00",
    "categories": [
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2505.22462v1",
    "title": "X-ray View of Light-Induced Spin Reorientation in TmFeO$_{3}$: Direct Observation of a 90$^\\circ$ N√©el Vector Rotation",
    "authors": [
      "Somnath Jana",
      "Ronny Knut",
      "Dima Afanasiev",
      "Niko Pontius",
      "Christian Sch√º√üler-Langeheine",
      "Christian Tzschaschel",
      "Daniel Schick",
      "Alexey V. Kimel",
      "Olof Karis",
      "Clemens von Korff Schmising",
      "Stefan Eisebitt"
    ],
    "abstract": "Using time-resolved X-ray magnetic linear dichroism in reflection, we provide\na direct probe of the N\\'eel vector dynamics in TmFeO$_3$ on a ultrafast\ntimescale. Our measurements reveal that, following optical excitation, the\nN\\'eel vector undergoes a spin reorientation transition primarily within the\na-c plane, completing a full 90{\\deg} rotation within approximately 20 ps. This\nstudy highlights the ability to probe dynamics of antiferromagnets at its\nintrinsic timescale in reflection geometry, paving the way for investigations\nof a wide range of antiferromagnets grown on application relevant substrates.",
    "pdf_url": "http://arxiv.org/pdf/2505.22462v1",
    "published": "2025-05-28T15:17:12+00:00",
    "categories": [
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2505.22461v2",
    "title": "SHTOcc: Effective 3D Occupancy Prediction with Sparse Head and Tail Voxels",
    "authors": [
      "Qiucheng Yu",
      "Yuan Xie",
      "Xin Tan"
    ],
    "abstract": "3D occupancy prediction has attracted much attention in the field of\nautonomous driving due to its powerful geometric perception and object\nrecognition capabilities. However, existing methods have not explored the most\nessential distribution patterns of voxels, resulting in unsatisfactory results.\nThis paper first explores the inter-class distribution and geometric\ndistribution of voxels, thereby solving the long-tail problem caused by the\ninter-class distribution and the poor performance caused by the geometric\ndistribution. Specifically, this paper proposes SHTOcc (Sparse Head-Tail\nOccupancy), which uses sparse head-tail voxel construction to accurately\nidentify and balance key voxels in the head and tail classes, while using\ndecoupled learning to reduce the model's bias towards the dominant (head)\ncategory and enhance the focus on the tail class. Experiments show that\nsignificant improvements have been made on multiple baselines: SHTOcc reduces\nGPU memory usage by 42.2%, increases inference speed by 58.6%, and improves\naccuracy by about 7%, verifying its effectiveness and efficiency. The code is\navailable at https://github.com/ge95net/SHTOcc",
    "pdf_url": "http://arxiv.org/pdf/2505.22461v2",
    "published": "2025-05-28T15:16:15+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.22460v1",
    "title": "Electronegativity effects on plasma dynamics in He/O$_2$ RF microplasma jets at atmospheric pressure",
    "authors": [
      "Lukas Vogelhuber",
      "Ihor Korolov",
      "Mate Vass",
      "Katharina Noesges",
      "Tim Bolles",
      "Kevin K√∂hn",
      "Maximilian Klich",
      "Ralf Peter Brinkmann",
      "Thomas Mussenbrock"
    ],
    "abstract": "This work investigates the transitions between ohmic mode and Penning-Gamma\nmode in a capacitively coupled radio frequency micro atmospheric pressure\nplasma jets (CCRF $\\mu$APPJ) operated in He/O$_2$ mixtures by comparing\nphase-resolved optical emission spectroscopy (PROES) measurements of helium\nexcitation with numerical simulations. The simulations employ a hybrid model\nthat treats electrons kinetically via PIC/MCC, while ions and neutrals are\nmodeled fluid dynamically. These results reveal that increasing\nelectronegativity causes inhomogeneities in the bulk electric field,\nconsequently modulating electron impact excitation dynamics. A good agreement\nwas found between experiments and simulations.",
    "pdf_url": "http://arxiv.org/pdf/2505.22460v1",
    "published": "2025-05-28T15:15:58+00:00",
    "categories": [
      "physics.plasm-ph"
    ],
    "primary_category": "physics.plasm-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.22459v1",
    "title": "A Unified Framework for Community Detection and Model Selection in Blockmodels",
    "authors": [
      "Subhankar Bhadra",
      "Minh Tang",
      "Srijan Sengupta"
    ],
    "abstract": "Blockmodels are a foundational tool for modeling community structure in\nnetworks, with the stochastic blockmodel (SBM), degree-corrected blockmodel\n(DCBM), and popularity-adjusted blockmodel (PABM) forming a natural hierarchy\nof increasing generality. While community detection under these models has been\nextensively studied, much less attention has been paid to the model selection\nproblem, i.e., determining which model best fits a given network. Building on\nrecent theoretical insights about the spectral geometry of these models, we\npropose a unified framework for simultaneous community detection and model\nselection across the full blockmodel hierarchy. A key innovation is the use of\nloss functions that serve a dual role: they act as objective functions for\ncommunity detection and as test statistics for hypothesis testing. We develop a\ngreedy algorithm to minimize these loss functions and establish theoretical\nguarantees for exact label recovery and model selection consistency under each\nmodel. Extensive simulation studies demonstrate that our method achieves high\naccuracy in both tasks, outperforming or matching state-of-the-art\nalternatives. Applications to five real-world networks further illustrate the\ninterpretability and practical utility of our approach.",
    "pdf_url": "http://arxiv.org/pdf/2505.22459v1",
    "published": "2025-05-28T15:15:36+00:00",
    "categories": [
      "stat.ME"
    ],
    "primary_category": "stat.ME"
  },
  {
    "id": "http://arxiv.org/abs/2505.23842v2",
    "title": "Document Valuation in LLM Summaries: A Cluster Shapley Approach",
    "authors": [
      "Zikun Ye",
      "Hema Yoganarasimhan"
    ],
    "abstract": "Large Language Models (LLMs) are increasingly used in systems that retrieve\nand summarize content from multiple sources, such as search engines and AI\nassistants. While these models enhance user experience by generating coherent\nsummaries, they obscure the contributions of original content creators, raising\nconcerns about credit attribution and compensation. We address the challenge of\nvaluing individual documents used in LLM-generated summaries. We propose using\nShapley values, a game-theoretic method that allocates credit based on each\ndocument's marginal contribution. Although theoretically appealing, Shapley\nvalues are expensive to compute at scale. We therefore propose Cluster Shapley,\nan efficient approximation algorithm that leverages semantic similarity between\ndocuments. By clustering documents using LLM-based embeddings and computing\nShapley values at the cluster level, our method significantly reduces\ncomputation while maintaining attribution quality. We demonstrate our approach\nto a summarization task using Amazon product reviews. Cluster Shapley\nsignificantly reduces computational complexity while maintaining high accuracy,\noutperforming baseline methods such as Monte Carlo sampling and Kernel SHAP\nwith a better efficient frontier. Our approach is agnostic to the exact LLM\nused, the summarization process used, and the evaluation procedure, which makes\nit broadly applicable to a variety of summarization settings.",
    "pdf_url": "http://arxiv.org/pdf/2505.23842v2",
    "published": "2025-05-28T15:14:21+00:00",
    "categories": [
      "cs.CL",
      "econ.GN",
      "q-fin.EC"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.22458v2",
    "title": "Universal Domain Adaptation for Semantic Segmentation",
    "authors": [
      "Seun-An Choe",
      "Keon-Hee Park",
      "Jinwoo Choi",
      "Gyeong-Moon Park"
    ],
    "abstract": "Unsupervised domain adaptation for semantic segmentation (UDA-SS) aims to\ntransfer knowledge from labeled source data to unlabeled target data. However,\ntraditional UDA-SS methods assume that category settings between source and\ntarget domains are known, which is unrealistic in real-world scenarios. This\nleads to performance degradation if private classes exist. To address this\nlimitation, we propose Universal Domain Adaptation for Semantic Segmentation\n(UniDA-SS), achieving robust adaptation even without prior knowledge of\ncategory settings. We define the problem in the UniDA-SS scenario as low\nconfidence scores of common classes in the target domain, which leads to\nconfusion with private classes. To solve this problem, we propose UniMAP:\nUniDA-SS with Image Matching and Prototype-based Distinction, a novel framework\ncomposed of two key components. First, Domain-Specific Prototype-based\nDistinction (DSPD) divides each class into two domain-specific prototypes,\nenabling finer separation of domain-specific features and enhancing the\nidentification of common classes across domains. Second, Target-based Image\nMatching (TIM) selects a source image containing the most common-class pixels\nbased on the target pseudo-label and pairs it in a batch to promote effective\nlearning of common classes. We also introduce a new UniDA-SS benchmark and\ndemonstrate through various experiments that UniMAP significantly outperforms\nbaselines. The code is available at https://github.com/KU-VGI/UniMAP.",
    "pdf_url": "http://arxiv.org/pdf/2505.22458v2",
    "published": "2025-05-28T15:14:11+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.22457v1",
    "title": "Fostering Video Reasoning via Next-Event Prediction",
    "authors": [
      "Haonan Wang",
      "Hongfu Liu",
      "Xiangyan Liu",
      "Chao Du",
      "Kenji Kawaguchi",
      "Ye Wang",
      "Tianyu Pang"
    ],
    "abstract": "Next-token prediction serves as the foundational learning task enabling\nreasoning in LLMs. But what should the learning task be when aiming to equip\nMLLMs with temporal reasoning capabilities over video inputs? Existing tasks\nsuch as video question answering often rely on annotations from humans or much\nstronger MLLMs, while video captioning tends to entangle temporal reasoning\nwith spatial information. To address this gap, we propose next-event prediction\n(NEP), a learning task that harnesses future video segments as a rich,\nself-supervised signal to foster temporal reasoning. We segment each video into\npast and future frames: the MLLM takes the past frames as input and predicts a\nsummary of events derived from the future frames, thereby encouraging the model\nto reason temporally in order to complete the task. To support this task, we\ncurate V1-33K, a dataset comprising 33,000 automatically extracted video\nsegments spanning diverse real-world scenarios. We further explore a range of\nvideo instruction-tuning strategies to study their effects on temporal\nreasoning. To evaluate progress, we introduce FutureBench to assess coherence\nin predicting unseen future events. Experiments validate that NEP offers a\nscalable and effective training paradigm for fostering temporal reasoning in\nMLLMs.",
    "pdf_url": "http://arxiv.org/pdf/2505.22457v1",
    "published": "2025-05-28T15:13:34+00:00",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.22456v2",
    "title": "Beyond Leaders and Laggards: A Typology of Renewable Energy Adoption Trajectories with Evidence from Off-Grid Communities",
    "authors": [
      "Roni Blushtein-Livnon",
      "Tal Svoray",
      "Itai Ficshhendler",
      "Havatzelet Yahel",
      "Emir Galilee",
      "Michael Dorman"
    ],
    "abstract": "Understanding the dynamics of renewable energy adoption is essential for\ndesigning strategies that accelerate its spread - an urgent priority for\nadvancing climate goals and improving well-being, especially in off-grid\nregions facing energy poverty. This study introduces a time-series-based\nanalytical framework that quantifies and classifies adoption behaviors of\ngeographic entities within a region. A novel metric, the Adoption over Time\nIndex (ATI), captures cumulative adoption intensity and identifies shifts in\nadoption trends, improving the ability to distinguish between fundamental\nadoption paths. By combining ATI with three key features found to be indicative\nof adoption dynamics, we define a typology of eight distinct paths, including\ntwo newly identified trajectories - the decelerating path and the declining\nmoderate path. Applying this framework to a case study of an off-grid Bedouin\npopulation in southern Israel reveals that these retreating paths exist in\nsubstantial proportions. Identifying such trends is critical for addressing\nstagnation and preventing backsliding in the diffusion process. The leaping\npath, by contrast, was nearly absent. We also identify behavioral diversity\nwithin both front-runner and trailing groups. Differentiating among these\ngroups can help tailor acceleration strategies. The analysis further reveals\nsignificant disparities in adoption levels across the region, with lagging\nclusters being widespread and overall adoption falling short of the region's\npotential.",
    "pdf_url": "http://arxiv.org/pdf/2505.22456v2",
    "published": "2025-05-28T15:13:05+00:00",
    "categories": [
      "econ.GN",
      "q-fin.EC"
    ],
    "primary_category": "econ.GN"
  },
  {
    "id": "http://arxiv.org/abs/2505.22455v1",
    "title": "Articulatory modeling of the S-shaped F2 trajectories observed in √ñhman's spectrographic analysis of VCV syllables",
    "authors": [
      "Fr√©d√©ric Berthommier"
    ],
    "abstract": "The synthesis of Ohman's VCV sequences with intervocalic plosive consonants\nwas first achieved 30 years ago using the DRM model. However, this approach\nremains primarily acoustic and lacks articulatory constraints. In this study,\nthe same 75 VCVs are analyzed, but generated with the Maeda model, using\ntrajectory planning that differentiates vowel-to-vowel transitions from\nconsonantal influences. Synthetic data exhibit similar characteristics to\nOhman's sequences, including the presence of S-shaped F2 trajectories.\nFurthermore, locus equations (LEs) for F2 and F3 are computed from synthetic CV\ndata to investigate their underlying determinism, leading to a reassessment of\nconventional interpretations. The findings indicate that, although articulatory\nplanning is structured separately for vowel and consonant groups, S-shaped F2\ntrajectories emerge from a composite mechanism governed by the coordinated\nsynergy of all articulators.",
    "pdf_url": "http://arxiv.org/pdf/2505.22455v1",
    "published": "2025-05-28T15:12:53+00:00",
    "categories": [
      "eess.AS",
      "cs.SD"
    ],
    "primary_category": "eess.AS"
  },
  {
    "id": "http://arxiv.org/abs/2505.22454v1",
    "title": "Depth-Based Matrix Classification for the HHL Quantum Algorithm",
    "authors": [
      "Mark Danza",
      "Sonia Lopez Alarcon",
      "Cory Merkel"
    ],
    "abstract": "Under the nearing error-corrected era of quantum computing, it is necessary\nto understand the suitability of certain post-NISQ algorithms for practical\nproblems. One of the most promising, applicable and yet difficult to implement\nin practical terms is the Harrow, Hassidim and Lloyd (HHL) algorithm for linear\nsystems of equations. An enormous number of problems can be expressed as linear\nsystems of equations, from Machine Learning to fluid dynamics. However, in most\ncases, HHL will not be able to provide a practical, reasonable solution to\nthese problems. This paper's goal inquires about whether problems can be\nlabeled using Machine Learning classifiers as suitable or unsuitable for HHL\nimplementation when some numerical information about the problem is known\nbeforehand. This work demonstrates that training on significantly\nrepresentative data distributions is critical to achieve good classifications\nof the problems based on the numerical properties of the matrix representing\nthe system of equations. Accurate classification is possible through\nMulti-Layer Perceptrons, although with careful design of the training data\ndistribution and classifier parameters.",
    "pdf_url": "http://arxiv.org/pdf/2505.22454v1",
    "published": "2025-05-28T15:11:53+00:00",
    "categories": [
      "quant-ph",
      "cs.LG"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.22453v1",
    "title": "Unsupervised Post-Training for Multi-Modal LLM Reasoning via GRPO",
    "authors": [
      "Lai Wei",
      "Yuting Li",
      "Chen Wang",
      "Yue Wang",
      "Linghe Kong",
      "Weiran Huang",
      "Lichao Sun"
    ],
    "abstract": "Improving Multi-modal Large Language Models (MLLMs) in the post-training\nstage typically relies on supervised fine-tuning (SFT) or reinforcement\nlearning (RL). However, these supervised methods require expensive and manually\nannotated multi-modal data--an ultimately unsustainable resource. While recent\nefforts have explored unsupervised post-training, their methods are complex and\ndifficult to iterate. In this work, we are the first to investigate the use of\nGRPO, a stable and scalable online RL algorithm, for enabling continual\nself-improvement without any external supervision. We propose MM-UPT, a simple\nyet effective framework for unsupervised post-training of MLLMs. MM-UPT builds\nupon GRPO, replacing traditional reward signals with a self-rewarding mechanism\nbased on majority voting over multiple sampled responses. Our experiments\ndemonstrate that MM-UPT significantly improves the reasoning ability of\nQwen2.5-VL-7B (e.g., 66.3 %$\\rightarrow$72.9 % on MathVista, 62.9\n%$\\rightarrow$68.7 % on We-Math), using standard dataset without ground truth\nlabels. MM-UPT also outperforms prior unsupervised baselines and even\napproaches the results of supervised GRPO. Furthermore, we show that\nincorporating synthetic questions, generated solely by MLLM itself, can boost\nperformance as well, highlighting a promising approach for scalable\nself-improvement. Overall, MM-UPT offers a new paradigm for continual,\nautonomous enhancement of MLLMs in the absence of external supervision. Our\ncode is available at https://github.com/waltonfuture/MM-UPT.",
    "pdf_url": "http://arxiv.org/pdf/2505.22453v1",
    "published": "2025-05-28T15:11:16+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.22452v1",
    "title": "Spin transport and lack of quantisation in the $A\\mathrm{II}$ class on the honeycomb structure",
    "authors": [
      "Luca Fresta",
      "Giovanna Marcelli"
    ],
    "abstract": "We investigate spin transport in a class of two-dimensional $A\\mathrm{II}$\ninsulators on the honeycomb structure, the Kane-Mele model being an emblematic\nexample in this class. We derive the spin conductivity by the linear response\n\\`a la Kubo and show that it is well-defined and independent of the choice of\nthe spin current. For models that do not conserve the spin, we demonstrate that\nthe deviation of the spin conductivity from the quantised value is, at worst,\nquadratic in the spin-non-conserving terms, thus improving previous results.\nAdditionally, we show that the leading-order corrections are actually quadratic\nfor some models in the class, demonstrating that the spin conductivity is not\nuniversally quantised. Consequently, our results show that, in general, there\nis no direct connection between the spin conductivity and the Fu-Kane-Mele\nindex.",
    "pdf_url": "http://arxiv.org/pdf/2505.22452v1",
    "published": "2025-05-28T15:10:54+00:00",
    "categories": [
      "math-ph",
      "math.MP"
    ],
    "primary_category": "math-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.22451v1",
    "title": "AI Mathematician: Towards Fully Automated Frontier Mathematical Research",
    "authors": [
      "Yuanhang Liu",
      "Yanxing Huang",
      "Yanqiao Wang",
      "Peng Li",
      "Yang Liu"
    ],
    "abstract": "Large Reasoning Models (LRMs) have made significant progress in mathematical\ncapabilities in recent times. However, these successes have been primarily\nconfined to competition-level problems. In this work, we propose AI\nMathematician (AIM) framework, which harnesses the reasoning strength of LRMs\nto support frontier mathematical research. We have identified two critical\nchallenges of mathematical research compared to competition, {\\it the intrinsic\ncomplexity of research problems} and {\\it the requirement of procedural rigor}.\nTo address these challenges, AIM incorporates two core strategies: an\nexploration mechanism to foster longer solution paths, and the pessimistic\nreasonable verification method to ensure reliability.\n  This early version of AIM already exhibits strong capability in tackling\nresearch-level tasks. We conducted extensive experiments across several\nreal-world mathematical topics and obtained promising results. AIM is able to\nautonomously construct substantial portions of proofs and uncover non-trivial\ninsights within each research area. These findings highlight the potential of\nLRMs in mathematical discovery and suggest that LRM-based agent systems could\nsignificantly accelerate mathematical research in the future.",
    "pdf_url": "http://arxiv.org/pdf/2505.22451v1",
    "published": "2025-05-28T15:10:37+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.22450v1",
    "title": "Position: All Current Generative Fidelity and Diversity Metrics are Flawed",
    "authors": [
      "Ossi R√§is√§",
      "Boris van Breugel",
      "Mihaela van der Schaar"
    ],
    "abstract": "Any method's development and practical application is limited by our ability\nto measure its reliability. The popularity of generative modeling emphasizes\nthe importance of good synthetic data metrics. Unfortunately, previous works\nhave found many failure cases in current metrics, for example lack of outlier\nrobustness and unclear lower and upper bounds. We propose a list of desiderata\nfor synthetic data metrics, and a suite of sanity checks: carefully chosen\nsimple experiments that aim to detect specific and known generative modeling\nfailure modes. Based on these desiderata and the results of our checks, we\narrive at our position: all current generative fidelity and diversity metrics\nare flawed. This significantly hinders practical use of synthetic data. Our aim\nis to convince the research community to spend more effort in developing\nmetrics, instead of models. Additionally, through analyzing how current metrics\nfail, we provide practitioners with guidelines on how these metrics should\n(not) be used.",
    "pdf_url": "http://arxiv.org/pdf/2505.22450v1",
    "published": "2025-05-28T15:10:33+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.22449v1",
    "title": "Private Lossless Multiple Release",
    "authors": [
      "Joel Daniel Andersson",
      "Lukas Retschmeier",
      "Boel Nelson",
      "Rasmus Pagh"
    ],
    "abstract": "Koufogiannis et al. (2016) showed a $\\textit{gradual release}$ result for\nLaplace noise-based differentially private mechanisms: given an\n$\\varepsilon$-DP release, a new release with privacy parameter $\\varepsilon' >\n\\varepsilon$ can be computed such that the combined privacy loss of both\nreleases is at most $\\varepsilon'$ and the distribution of the latter is the\nsame as a single release with parameter $\\varepsilon'$. They also showed\ngradual release techniques for Gaussian noise, later also explored by\nWhitehouse et al. (2022).\n  In this paper, we consider a more general $\\textit{multiple release}$ setting\nin which analysts hold private releases with different privacy parameters\ncorresponding to different access/trust levels. These releases are determined\none by one, with privacy parameters in arbitrary order. A multiple release is\n$\\textit{lossless}$ if having access to a subset $S$ of the releases has the\nsame privacy guarantee as the least private release in $S$, and each release\nhas the same distribution as a single release with the same privacy parameter.\nOur main result is that lossless multiple release is possible for a large class\nof additive noise mechanisms. For the Gaussian mechanism we give a simple\nmethod for lossless multiple release with a short, self-contained analysis that\ndoes not require knowledge of the mathematics of Brownian motion. We also\npresent lossless multiple release for the Laplace and Poisson mechanisms.\nFinally, we consider how to efficiently do gradual release of sparse\nhistograms, and present a mechanism with running time independent of the number\nof dimensions.",
    "pdf_url": "http://arxiv.org/pdf/2505.22449v1",
    "published": "2025-05-28T15:10:27+00:00",
    "categories": [
      "cs.CR",
      "cs.DS"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.22448v1",
    "title": "Self-adjoint operators in Z-stable C$^*$-algebras with prescribed spectral data",
    "authors": [
      "Andrew S. Toms",
      "Hao Wan"
    ],
    "abstract": "We consider the variety of spectral measures that are induced by quasitraces\non the spectrum of a self-adjoint operator in a simple separable unital and\nZ-stable C$^*$-algebra. This amounts to a continuous map from the simplex of\nquasitraces of the C$^*$-algebra into regular Borel probability measures on the\nspectrum of the operator under consideration. In the case of a connected\nspectrum this data determines the unitary equivalence class of the operator,\nand may be reduced to to the case of an operator with spectrum equal to the\nclosed unit interval. We prove that any continuous map from the simplex of\nquasitraces with the topology of pointwise convergence into regular faithful\nBorel probability measures on $[0,1]$ with the Levy-Prokhorov metric is\nrealized by some self-adjoint operator in the C$^*$-algebra.",
    "pdf_url": "http://arxiv.org/pdf/2505.22448v1",
    "published": "2025-05-28T15:10:20+00:00",
    "categories": [
      "math.OA",
      "math.FA",
      "46L35"
    ],
    "primary_category": "math.OA"
  },
  {
    "id": "http://arxiv.org/abs/2505.22447v1",
    "title": "Privacy-preserving Prompt Personalization in Federated Learning for Multimodal Large Language Models",
    "authors": [
      "Sizai Hou",
      "Songze Li",
      "Baturalp Buyukates"
    ],
    "abstract": "Prompt learning is a crucial technique for adapting pre-trained multimodal\nlanguage models (MLLMs) to user tasks. Federated prompt personalization (FPP)\nis further developed to address data heterogeneity and local overfitting,\nhowever, it exposes personalized prompts - valuable intellectual assets - to\nprivacy risks like prompt stealing or membership inference attacks.\nWidely-adopted techniques like differential privacy add noise to prompts,\nwhereas degrading personalization performance. We propose SecFPP, a secure FPP\nprotocol harmonizing generalization, personalization, and privacy guarantees.\nSecFPP employs hierarchical prompt adaptation with domain-level and class-level\ncomponents to handle multi-granular data imbalance. For privacy, it uses a\nnovel secret-sharing-based adaptive clustering algorithm for domain-level\nadaptation while keeping class-level components private. While theoretically\nand empirically secure, SecFPP achieves state-of-the-art accuracy under severe\nheterogeneity in data distribution. Extensive experiments show it significantly\noutperforms both non-private and privacy-preserving baselines, offering a\nsuperior privacy-performance trade-off.",
    "pdf_url": "http://arxiv.org/pdf/2505.22447v1",
    "published": "2025-05-28T15:09:56+00:00",
    "categories": [
      "cs.CR"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.22446v1",
    "title": "$ œÅ\\to œÄœÄ$ Hadronic Decay in the Nambu-Jona-Lasinio Model: Mass-Width Interplay and Beyond-RPA Corrections",
    "authors": [
      "Qing-Wu Wang",
      "Xiao-Fu ≈Å\\text√º",
      "Hua-Zhong Guo"
    ],
    "abstract": "We present a novel framework for analyzing unstable composite particles using\nGreen's functions and dispersion relations. As an illustrative example, we\nexplore the\n  $\\rho$ vector meson decay process $\\rho\\to\\pi\\pi$\n  within the Nambu -- Jona - Lasinio (NJL) model. Our approach addresses a key\nlimitation of the four-quark interaction description, which adequately\ndescribes two-quark bound states but fails to describe decay\n  processes. The Bethe-Salpeter(BS) wave function of the $\\rho$ meson exhibits\ntime evolution that leads to the physical mass\n  $M$ incorporating a correction $\\Delta M $. This correction depends on the\ndecay width $\\Gamma(M)$. This work provides crucial insights into the dynamical\nrelationship between resonance masses and their decay properties, addressing a\nlong-standing challenge in hadron physics. The calculated mass and width are in\ngood agreement with the experimental values, demonstrating the effectiveness of\nthis approach for studying unstable hadronic systems beyond conventional\nbound-state approximations.",
    "pdf_url": "http://arxiv.org/pdf/2505.22446v1",
    "published": "2025-05-28T15:09:40+00:00",
    "categories": [
      "hep-ph"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.22445v1",
    "title": "NFR: Neural Feature-Guided Non-Rigid Shape Registration",
    "authors": [
      "Puhua Jiang",
      "Zhangquan Chen",
      "Mingze Sun",
      "Ruqi Huang"
    ],
    "abstract": "In this paper, we propose a novel learning-based framework for 3D shape\nregistration, which overcomes the challenges of significant non-rigid\ndeformation and partiality undergoing among input shapes, and, remarkably,\nrequires no correspondence annotation during training. Our key insight is to\nincorporate neural features learned by deep learning-based shape matching\nnetworks into an iterative, geometric shape registration pipeline. The\nadvantage of our approach is two-fold -- On one hand, neural features provide\nmore accurate and semantically meaningful correspondence estimation than\nspatial features (e.g., coordinates), which is critical in the presence of\nlarge non-rigid deformations; On the other hand, the correspondences are\ndynamically updated according to the intermediate registrations and filtered by\nconsistency prior, which prominently robustify the overall pipeline. Empirical\nresults show that, with as few as dozens of training shapes of limited\nvariability, our pipeline achieves state-of-the-art results on several\nbenchmarks of non-rigid point cloud matching and partial shape matching across\nvarying settings, but also delivers high-quality correspondences between unseen\nchallenging shape pairs that undergo both significant extrinsic and intrinsic\ndeformations, in which case neither traditional registration methods nor\nintrinsic methods work.",
    "pdf_url": "http://arxiv.org/pdf/2505.22445v1",
    "published": "2025-05-28T15:08:49+00:00",
    "categories": [
      "cs.CV",
      "cs.AI",
      "I.4.m; I.2.6"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.22444v1",
    "title": "On Geometry-Enhanced Parameter-Efficient Fine-Tuning for 3D Scene Segmentation",
    "authors": [
      "Liyao Tang",
      "Zhe Chen",
      "Dacheng Tao"
    ],
    "abstract": "The emergence of large-scale pre-trained point cloud models has significantly\nadvanced 3D scene understanding, but adapting these models to specific\ndownstream tasks typically demands full fine-tuning, incurring high\ncomputational and storage costs. Parameter-efficient fine-tuning (PEFT)\ntechniques, successful in natural language processing and 2D vision tasks,\nwould underperform when naively applied to 3D point cloud models due to\nsignificant geometric and spatial distribution shifts. Existing PEFT methods\ncommonly treat points as orderless tokens, neglecting important local spatial\nstructures and global geometric contexts in 3D modeling. To bridge this gap, we\nintroduce the Geometric Encoding Mixer (GEM), a novel geometry-aware PEFT\nmodule specifically designed for 3D point cloud transformers. GEM explicitly\nintegrates fine-grained local positional encodings with a lightweight latent\nattention mechanism to capture comprehensive global context, thereby\neffectively addressing the spatial and geometric distribution mismatch.\nExtensive experiments demonstrate that GEM achieves performance comparable to\nor sometimes even exceeding full fine-tuning, while only updating 1.6% of the\nmodel's parameters, fewer than other PEFT methods. With significantly reduced\ntraining time and memory requirements, our approach thus sets a new benchmark\nfor efficient, scalable, and geometry-aware fine-tuning of large-scale 3D point\ncloud models. Code will be released.",
    "pdf_url": "http://arxiv.org/pdf/2505.22444v1",
    "published": "2025-05-28T15:08:36+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.22443v1",
    "title": "Frequency Resource Management in 6G User-Centric CFmMIMO: A Hybrid Reinforcement Learning and Metaheuristic Approach",
    "authors": [
      "Selina Cheggour",
      "Valeria Loscri"
    ],
    "abstract": "As sixth-generation (6G) networks continue to evolve, AI-driven solutions are\nplaying a crucial role in enabling more efficient and adaptive resource\nmanagement in wireless communication. One of the key innovations in 6G is\nuser-centric cell-free massive Multiple-Input Multiple-Output (UC-CFmMIMO), a\nparadigm that eliminates traditional cell boundaries and enhances network\nperformance by dynamically assigning access points (APs) to users. This\napproach is particularly well-suited for vehicular networks, offering seamless,\nhomogeneous, ultra-reliable, and low-latency connectivity. However, in dense\nnetworks, a key challenge lies in efficiently allocating frequency resources\nwithin a limited shared subband spectrum while accounting for frequency\nselectivity and the dependency of signal propagation on bandwidth. These\nfactors make resource allocation increasingly complex, especially in dynamic\nenvironments where maintaining Quality of Service (QoS) is critical. This paper\ntackles these challenges by proposing a hybrid multi-user allocation strategy\nthat integrates reinforcement learning (RL) and metaheuristic optimization to\nenhance spectral efficiency (SE), ensure fairness, and mitigate interference\nwithin shared subbands. To assess its effectiveness, we compare this hybrid\napproach with two other methods: the bio-inspired Aquila Optimizer (AO) and\nDeep Deterministic Policy Gradient (DDPG)-based Actor-Critic Reinforcement\nLearning (AC-RL). Our evaluation is grounded in real-world patterns and channel\ncharacteristics, utilizing the 3GPP-3D channel modeling framework (QuaDRiGa) to\ncapture realistic propagation conditions. The results demonstrate that the\nproposed hybrid strategy achieves a superior balance among competing\nobjectives, underscoring the role of AI-driven resource allocation in advancing\nUC-CFmMIMO systems for next-generation wireless networks.",
    "pdf_url": "http://arxiv.org/pdf/2505.22443v1",
    "published": "2025-05-28T15:07:56+00:00",
    "categories": [
      "cs.NI",
      "eess.SP"
    ],
    "primary_category": "cs.NI"
  },
  {
    "id": "http://arxiv.org/abs/2505.22442v2",
    "title": "SOReL and TOReL: Two Methods for Fully Offline Reinforcement Learning",
    "authors": [
      "Mattie Fellows",
      "Clarisse Wibault",
      "Uljad Berdica",
      "Johannes Forkel",
      "Michael A. Osborne",
      "Jakob N. Foerster"
    ],
    "abstract": "Sample efficiency remains a major obstacle for real world adoption of\nreinforcement learning (RL): success has been limited to settings where\nsimulators provide access to essentially unlimited environment interactions,\nwhich in reality are typically costly or dangerous to obtain. Offline RL in\nprinciple offers a solution by exploiting offline data to learn a near-optimal\npolicy before deployment. In practice, however, current offline RL methods rely\non extensive online interactions for hyperparameter tuning, and have no\nreliable bound on their initial online performance. To address these two\nissues, we introduce two algorithms. Firstly, SOReL: an algorithm for safe\noffline reinforcement learning. Using only offline data, our Bayesian approach\ninfers a posterior over environment dynamics to obtain a reliable estimate of\nthe online performance via the posterior predictive uncertainty. Crucially, all\nhyperparameters are also tuned fully offline. Secondly, we introduce TOReL: a\ntuning for offline reinforcement learning algorithm that extends our\ninformation rate based offline hyperparameter tuning methods to general offline\nRL approaches. Our empirical evaluation confirms SOReL's ability to accurately\nestimate regret in the Bayesian setting whilst TOReL's offline hyperparameter\ntuning achieves competitive performance with the best online hyperparameter\ntuning methods using only offline data. Thus, SOReL and TOReL make a\nsignificant step towards safe and reliable offline RL, unlocking the potential\nfor RL in the real world. Our implementations are publicly available:\nhttps://github.com/CWibault/sorel\\_torel.",
    "pdf_url": "http://arxiv.org/pdf/2505.22442v2",
    "published": "2025-05-28T15:07:24+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.22441v2",
    "title": "Can NeRFs See without Cameras?",
    "authors": [
      "Chaitanya Amballa",
      "Sattwik Basu",
      "Yu-Lin Wei",
      "Zhijian Yang",
      "Mehmet Ergezer",
      "Romit Roy Choudhury"
    ],
    "abstract": "Neural Radiance Fields (NeRFs) have been remarkably successful at\nsynthesizing novel views of 3D scenes by optimizing a volumetric scene\nfunction. This scene function models how optical rays bring color information\nfrom a 3D object to the camera pixels. Radio frequency (RF) or audio signals\ncan also be viewed as a vehicle for delivering information about the\nenvironment to a sensor. However, unlike camera pixels, an RF/audio sensor\nreceives a mixture of signals that contain many environmental reflections (also\ncalled \"multipath\"). Is it still possible to infer the environment using such\nmultipath signals? We show that with redesign, NeRFs can be taught to learn\nfrom multipath signals, and thereby \"see\" the environment. As a grounding\napplication, we aim to infer the indoor floorplan of a home from sparse WiFi\nmeasurements made at multiple locations inside the home. Although a difficult\ninverse problem, our implicitly learnt floorplans look promising, and enables\nforward applications, such as indoor signal prediction and basic ray tracing.",
    "pdf_url": "http://arxiv.org/pdf/2505.22441v2",
    "published": "2025-05-28T15:04:46+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.22440v1",
    "title": "Data-Driven Antenna Miniaturization: A Knowledge-Based System Integrating Quantum PSO and Predictive Machine Learning Models",
    "authors": [
      "Khan Masood Parvez",
      "Sk Md Abidar Rahaman",
      "Ali Shiri Sichani"
    ],
    "abstract": "The rapid evolution of wireless technologies necessitates automated design\nframeworks to address antenna miniaturization and performance optimization\nwithin constrained development cycles. This study demonstrates a machine\nlearning enhanced workflow integrating Quantum-Behaved Dynamic Particle Swarm\nOptimization (QDPSO) with ANSYS HFSS simulations to accelerate antenna design.\nThe QDPSO algorithm autonomously optimized loop dimensions in 11.53 seconds,\nachieving a resonance frequency of 1.4208 GHz a 12.7 percent reduction compared\nto conventional 1.60 GHz designs. Machine learning models (SVM, Random Forest,\nXGBoost, and Stacked ensembles) predicted resonance frequencies in 0.75 seconds\nusing 936 simulation datasets, with stacked models showing superior training\naccuracy (R2=0.9825) and SVM demonstrating optimal validation performance\n(R2=0.7197). The complete design cycle, encompassing optimization, prediction,\nand ANSYS validation, required 12.42 minutes on standard desktop hardware\n(Intel i5-8500, 16GB RAM), contrasting sharply with the 50-hour benchmark of\nPSADEA-based approaches. This 240 times of acceleration eliminates traditional\ntrial-and-error methods that often extend beyond seven expert-led days. The\nsystem enables precise specifications of performance targets with automated\ngeneration of fabrication-ready parameters, particularly benefiting compact\nconsumer devices requiring rapid frequency tuning. By bridging AI-driven\noptimization with CAD validation, this framework reduces engineering workloads\nwhile ensuring production-ready designs, establishing a scalable paradigm for\nnext-generation RF systems in 6G and IoT applications.",
    "pdf_url": "http://arxiv.org/pdf/2505.22440v1",
    "published": "2025-05-28T15:04:36+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.22439v1",
    "title": "Rigidity of surfaces with nonpositive Euler characteristic by the second eigenvalue of the Jacobi operator",
    "authors": [
      "M√°rcio Batista",
      "Marcos P. Cavalcante",
      "Abra√£o Mendes",
      "Ivaldo Nunes"
    ],
    "abstract": "In this paper, we investigate the spectral properties of the Jacobi operator\nfor immersed surfaces with nonpositive Euler characteristic, extending previous\nresults in the field. We first prove a sharp upper bound for the second\neigenvalue of the Jacobi operator for compact surfaces with nonpositive Euler\ncharacteristic that are fully immersed in the Euclidean sphere, and then we\nclassify all such surfaces attaining this upper bound. Furthermore, we\ndemonstrate that totally geodesic tori maximize the second eigenvalue among all\ncompact orientable surfaces with positive genus in the product space\n$\\mathbb{S}^1(r) \\times \\mathbb{S}^2(s)$.",
    "pdf_url": "http://arxiv.org/pdf/2505.22439v1",
    "published": "2025-05-28T15:04:30+00:00",
    "categories": [
      "math.DG",
      "Primary 53C24, 58J50, Secondary 49Q05, 53A10"
    ],
    "primary_category": "math.DG"
  },
  {
    "id": "http://arxiv.org/abs/2505.22438v1",
    "title": "Synonymous Variational Inference for Perceptual Image Compression",
    "authors": [
      "Zijian Liang",
      "Kai Niu",
      "Changshuo Wang",
      "Jin Xu",
      "Ping Zhang"
    ],
    "abstract": "Recent contributions of semantic information theory reveal the set-element\nrelationship between semantic and syntactic information, represented as\nsynonymous relationships. In this paper, we propose a synonymous variational\ninference (SVI) method based on this synonymity viewpoint to re-analyze the\nperceptual image compression problem. It takes perceptual similarity as a\ntypical synonymous criterion to build an ideal synonymous set (Synset), and\napproximate the posterior of its latent synonymous representation with a\nparametric density by minimizing a partial semantic KL divergence. This\nanalysis theoretically proves that the optimization direction of perception\nimage compression follows a triple tradeoff that can cover the existing\nrate-distortion-perception schemes. Additionally, we introduce synonymous image\ncompression (SIC), a new image compression scheme that corresponds to the\nanalytical process of SVI, and implement a progressive SIC codec to fully\nleverage the model's capabilities. Experimental results demonstrate comparable\nrate-distortion-perception performance using a single progressive SIC codec,\nthus verifying the effectiveness of our proposed analysis method.",
    "pdf_url": "http://arxiv.org/pdf/2505.22438v1",
    "published": "2025-05-28T15:03:27+00:00",
    "categories": [
      "cs.IT",
      "cs.AI",
      "cs.CV",
      "cs.LG",
      "eess.IV",
      "math.IT"
    ],
    "primary_category": "cs.IT"
  },
  {
    "id": "http://arxiv.org/abs/2505.22699v1",
    "title": "Correspondence between particle creation and dark components interaction in the context of $f(\\mathcal{G})$ gravity",
    "authors": [
      "S. Ganjizadeh",
      "Alireza Amani",
      "M. A. Ramzanpour"
    ],
    "abstract": "In this paper, we explore the particle creation scenario in the context of\n$f(\\mathcal{G})$ gravity in flat-FLRW metric. For this purpose, from the\nperspective of thermodynamics and considering an adiabatic universe, we obtain\nthe modified continuity equation in terms of the dynamic number of particles\n$N$. On the other hand, we obtain Friedmann's equations in $f(\\mathcal{G})$\ngravity and then write down the continuity equations of the components of\nmatter and dark energy, taking into account the interaction between them. In\nwhat follows, by establishing a correspondence between the particle production\nscenario and $f(\\mathcal{G})$ gravity, we obtain the cosmological parameters in\nterms of $N$. After that, we find cosmological solutions using power-law\ncosmology and compare them with Hubble parameter data. Finally, we fit the\ncurrent model with Hubble data and plot the best fit in terms of the redshift\nparameter.",
    "pdf_url": "http://arxiv.org/pdf/2505.22699v1",
    "published": "2025-05-28T15:02:47+00:00",
    "categories": [
      "gr-qc",
      "hep-th"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2505.22437v1",
    "title": "Estimation of the number of principal components in high-dimensional multivariate extremes",
    "authors": [
      "Lucas Butsch",
      "Vicky Fasen-Hartmann"
    ],
    "abstract": "For multivariate regularly random vectors of dimension $d$, the dependence\nstructure of the extremes is modeled by the so-called angular measure. When the\ndimension $d$ is high, estimating the angular measure is challenging because of\nits complexity. In this paper, we use Principal Component Analysis (PCA) as a\nmethod for dimension reduction and estimate the number of significant principal\ncomponents of the empirical covariance matrix of the angular measure under the\nassumption of a spiked covariance structure. Therefore, we develop Akaike\nInformation Criteria (AIC) and Bayesian Information Criteria (BIC) to estimate\nthe location of the spiked eigenvalue of the covariance matrix, reflecting the\nnumber of significant components, and explore these information criteria on\nconsistency. On the one hand, we investigate the case where the dimension $d$\nis fixed, and on the other hand, where the dimension $d$ converges to $\\infty$\nunder different high-dimensional scenarios. When the dimension $d$ is fixed, we\nestablish that the AIC is not consistent, whereas the BIC is weakly consistent.\nIn the high-dimensional setting, with techniques from random matrix theory, we\nderive sufficient conditions for the AIC and the BIC to be consistent. Finally,\nthe performance of the different AIC and BIC versions is compared in a\nsimulation study and applied to high-dimensional precipitation data.",
    "pdf_url": "http://arxiv.org/pdf/2505.22437v1",
    "published": "2025-05-28T15:01:10+00:00",
    "categories": [
      "stat.ME",
      "62G32, 62H25, 60G70, 62G20"
    ],
    "primary_category": "stat.ME"
  },
  {
    "id": "http://arxiv.org/abs/2505.22436v1",
    "title": "COSMOS: A Data-Driven Probabilistic Time Series simulator for Chemical Plumes across Spatial Scales",
    "authors": [
      "Arunava Nag",
      "Floris van Breugel"
    ],
    "abstract": "The development of robust odor navigation strategies for automated\nenvironmental monitoring applications requires realistic simulations of odor\ntime series for agents moving across large spatial scales. Traditional\napproaches that rely on computational fluid dynamics (CFD) methods can capture\nthe spatiotemporal dynamics of odor plumes, but are impractical for large-scale\nsimulations due to their computational expense. On the other hand, puff-based\nsimulations, although computationally tractable for large scales and capable of\ncapturing the stochastic nature of plumes, fail to reproduce naturalistic odor\nstatistics. Here, we present COSMOS (Configurable Odor Simulation Model over\nScalable Spaces), a data-driven probabilistic framework that synthesizes\nrealistic odor time series from spatial and temporal features of real datasets.\nCOSMOS generates similar distributions of key statistical features such as\nwhiff frequency, duration, and concentration as observed in real data, while\ndramatically reducing computational overhead. By reproducing critical\nstatistical properties across a variety of flow regimes and scales, COSMOS\nenables the development and evaluation of agent-based navigation strategies\nwith naturalistic odor experiences. To demonstrate its utility, we compare\nodor-tracking agents exposed to CFD-generated plumes versus COSMOS simulations,\nshowing that both their odor experiences and resulting behaviors are quite\nsimilar.",
    "pdf_url": "http://arxiv.org/pdf/2505.22436v1",
    "published": "2025-05-28T15:00:22+00:00",
    "categories": [
      "stat.AP",
      "cs.RO"
    ],
    "primary_category": "stat.AP"
  },
  {
    "id": "http://arxiv.org/abs/2505.22435v1",
    "title": "Does Johnny Get the Message? Evaluating Cybersecurity Notifications for Everyday Users",
    "authors": [
      "Victor J√ºttner",
      "Erik Buchmann"
    ],
    "abstract": "Due to the increasing presence of networked devices in everyday life, not\nonly cybersecurity specialists but also end users benefit from security\napplications such as firewalls, vulnerability scanners, and intrusion detection\nsystems. Recent approaches use large language models (LLMs) to rewrite brief,\ntechnical security alerts into intuitive language and suggest actionable\nmeasures, helping everyday users understand and respond appropriately to\nsecurity risks. However, it remains an open question how well such alerts are\nexplained to users. LLM outputs can also be hallucinated, inconsistent, or\nmisleading. In this work, we introduce the Human-Centered Security Alert\nEvaluation Framework (HCSAEF). HCSAEF assesses LLM-generated cybersecurity\nnotifications to support researchers who want to compare notifications\ngenerated for everyday users, improve them, or analyze the capabilities of\ndifferent LLMs in explaining cybersecurity issues. We demonstrate HCSAEF\nthrough three use cases, which allow us to quantify the impact of prompt\ndesign, model selection, and output consistency. Our findings indicate that\nHCSAEF effectively differentiates generated notifications along dimensions such\nas intuitiveness, urgency, and correctness.",
    "pdf_url": "http://arxiv.org/pdf/2505.22435v1",
    "published": "2025-05-28T14:58:29+00:00",
    "categories": [
      "cs.CR"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.22434v1",
    "title": "Distance Transform Guided Mixup for Alzheimer's Detection",
    "authors": [
      "Zobia Batool",
      "Huseyin Ozkan",
      "Erchan Aptoula"
    ],
    "abstract": "Alzheimer's detection efforts aim to develop accurate models for early\ndisease diagnosis. Significant advances have been achieved with convolutional\nneural networks and vision transformer based approaches. However, medical\ndatasets suffer heavily from class imbalance, variations in imaging protocols,\nand limited dataset diversity, which hinder model generalization. To overcome\nthese challenges, this study focuses on single-domain generalization by\nextending the well-known mixup method. The key idea is to compute the distance\ntransform of MRI scans, separate them spatially into multiple layers and then\ncombine layers stemming from distinct samples to produce augmented images. The\nproposed approach generates diverse data while preserving the brain's\nstructure. Experimental results show generalization performance improvement\nacross both ADNI and AIBL datasets.",
    "pdf_url": "http://arxiv.org/pdf/2505.22434v1",
    "published": "2025-05-28T14:56:59+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.22433v4",
    "title": "Enantiosensitive locking of photoelectron spin and cation orientation",
    "authors": [
      "Philip Caesar M. Flores",
      "Stefanos Carlstr√∂m",
      "Serguei Patchkovskii",
      "Misha Ivanov",
      "Vladimiro Mujica",
      "Andres F. Ordonez",
      "Olga Smirnova"
    ],
    "abstract": "Chirality describes the asymmetry between an object and its mirror image,\nunderpinning diverse functionalities across all scales of matter-from molecules\nand aggregates to thin films and bulk chiral materials. A particularly\nintriguing example is chirality-induced spin selectivity (CISS), where chiral\nstructures orient electron spins enantio-sensitively. Despite extensive\nresearch, the fundamental origin of spin-chirality coupling, the unexpectedly\nlarge magnitude of the CISS effect, and the possible role of electromagnetic\nfields remain unclear. Here, we address these issues by examining the simplest\nscenario: spin-resolved photoionization of randomly oriented chiral molecules.\nWe uncover two universal geometric mechanisms of spin-selective photodynamics,\narising solely from electric-dipole interactions and previously unrecognized.\nThese mechanisms operate effectively even in amorphous chiral media under\nisotropic illumination and persist at weak spin-orbit coupling, underscoring\nfundamental aspects of spin-chirality interplay. We further identify an\nunreported phenomenon central to CISS: locking of photoelectron spin\norientation to molecular geometry. Our findings provide a unified geometric\nframework with broad implications, extending from CISS and asymmetric catalysis\nto spin textures in chiral crystals and chiral quantum materials such as Weyl\nsemimetals.",
    "pdf_url": "http://arxiv.org/pdf/2505.22433v4",
    "published": "2025-05-28T14:56:48+00:00",
    "categories": [
      "cond-mat.mes-hall",
      "physics.optics",
      "quant-ph"
    ],
    "primary_category": "cond-mat.mes-hall"
  },
  {
    "id": "http://arxiv.org/abs/2505.22432v1",
    "title": "Oblique Multiple Scattering by Gyrotropic Cylinders",
    "authors": [
      "Grigorios P. Zouros",
      "Konstantinos Delimaris",
      "Carsten Rockstuhl",
      "Georgios D. Kolezas"
    ],
    "abstract": "In this work, we develop a full-wave vectorial solution for the\n2.5-dimensional (2.5-D), i.e., at oblique plane wave incidence, electromagnetic\n(EM) multiple scattering (MS) by a collection of gyrotropic cylinders. All\ncylinders are infinitely long and share a common $z$-axis. However, each\ncylinder can have a different cross-section with an arbitrary shape and\ndifferent gyrotropic material properties, i.e., both gyroelectric and\ngyromagnetic anisotropies are considered. The solution to the problem combines\nthe following three elements: (i) development of a superpotentials-based\ncylindrical vector wave function (CVWF) expansion to express the EM field in\nthe gyrotropic region; (ii) utilization of the extended boundary condition\nmethod (EBCM) to account for non-circular cylinders; (iii) use of Graf's\nformulas, specifically adapted for the CVWFs, to apply the EBCM at each\ncylinder. The developed theory allows us to calculate various scattering\ncharacteristics, including the scattering and extinction cross-sections and the\nmultipole decomposition, enabling the design and in-depth investigation of\nvarious contemporary engineering and physics applications. The method is\nexhaustively validated with analytical techniques and COMSOL Multiphysics. The\ncomputational performance is also discussed. Finally, we study a potential\nmicrowave application of the MS by ferrite configurations, and demonstrate\nbroadband forward scattering by introducing oblique incidence and anisotropy.\nOur method may be used to analyze, design, and optimize contemporary microwave,\noptical, and photonic applications by beneficially tailoring the scattering\nproperties via oblique incidence and anisotropy.",
    "pdf_url": "http://arxiv.org/pdf/2505.22432v1",
    "published": "2025-05-28T14:56:04+00:00",
    "categories": [
      "physics.optics"
    ],
    "primary_category": "physics.optics"
  },
  {
    "id": "http://arxiv.org/abs/2505.22431v1",
    "title": "Brightify: A tool for calculating brightness in neutron sources",
    "authors": [
      "Mina Akhyani",
      "Luca Zanini",
      "Henrik R√∏nnow"
    ],
    "abstract": "Brightness is a critical metric for optimizing the design of neutron sources\nand beamlines, yet there is no direct way to calculate brightness within most\nMonte Carlo packages used for neutron source simulation. In this paper, we\npresent Brightify, an open-source Python-based tool designed to calculate\nbrightness from Monte Carlo Particle List (MCPL) files, which can be extracted\nfrom several Monte Carlo simulation packages. Brightify provides an efficient\ncomputational approach to calculate brightness for any particle type and energy\nspectrum recorded in the MCPL file. It enables localized,\ndirectionally-resolved brightness evaluations by scanning across both spatial\nand angular domains, facilitating the identification of positions and\ndirections corresponding to maximum brightness. This functionality is\nparticularly valuable for identifying brightness hotspots and helping fine-tune\nthe design of neutron sources for optimal performance. We validate Brightify\nagainst standard methods, such as surface current tally and point estimator\ntally, and demonstrate its accuracy and adaptability, particularly in\nhigh-resolution analyses. By overcoming the limitations of traditional methods,\nBrightify streamlines neutron source re-optimization, reduces computational\nburden, and accelerates source development workflows. The full code is\navailable on the Brightify GitHub repository.",
    "pdf_url": "http://arxiv.org/pdf/2505.22431v1",
    "published": "2025-05-28T14:55:36+00:00",
    "categories": [
      "physics.data-an",
      "physics.app-ph"
    ],
    "primary_category": "physics.data-an"
  },
  {
    "id": "http://arxiv.org/abs/2505.22430v1",
    "title": "RAG-Zeval: Towards Robust and Interpretable Evaluation on RAG Responses through End-to-End Rule-Guided Reasoning",
    "authors": [
      "Kun Li",
      "Yunxiang Li",
      "Tianhua Zhang",
      "Hongyin Luo",
      "Xixin Wu",
      "James Glass",
      "Helen Meng"
    ],
    "abstract": "Robust evaluation is critical for deploying trustworthy retrieval-augmented\ngeneration (RAG) systems. However, current LLM-based evaluation frameworks\npredominantly rely on directly prompting resource-intensive models with complex\nmulti-stage prompts, underutilizing models' reasoning capabilities and\nintroducing significant computational cost. In this paper, we present RAG-Zeval\n(RAG-Zero Evaluator), a novel end-to-end framework that formulates faithfulness\nand correctness evaluation as a rule-guided reasoning task. Our approach trains\nevaluators with reinforcement learning, facilitating compact models to generate\ncomprehensive and sound assessments with detailed explanation in one-pass. We\nintroduce a ranking-based outcome reward mechanism, using preference judgments\nrather than absolute scores, to address the challenge of obtaining precise\npointwise reward signals. To this end, we synthesize the ranking references by\ngenerating quality-controlled responses with zero human annotation. Experiments\ndemonstrate RAG-Zeval's superior performance, achieving the strongest\ncorrelation with human judgments and outperforming baselines that rely on LLMs\nwith 10-100 times more parameters. Our approach also exhibits superior\ninterpretability in response evaluation.",
    "pdf_url": "http://arxiv.org/pdf/2505.22430v1",
    "published": "2025-05-28T14:55:33+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.22429v1",
    "title": "Zero-Shot 3D Visual Grounding from Vision-Language Models",
    "authors": [
      "Rong Li",
      "Shijie Li",
      "Lingdong Kong",
      "Xulei Yang",
      "Junwei Liang"
    ],
    "abstract": "3D Visual Grounding (3DVG) seeks to locate target objects in 3D scenes using\nnatural language descriptions, enabling downstream applications such as\naugmented reality and robotics. Existing approaches typically rely on labeled\n3D data and predefined categories, limiting scalability to open-world settings.\nWe present SeeGround, a zero-shot 3DVG framework that leverages 2D\nVision-Language Models (VLMs) to bypass the need for 3D-specific training. To\nbridge the modality gap, we introduce a hybrid input format that pairs\nquery-aligned rendered views with spatially enriched textual descriptions. Our\nframework incorporates two core components: a Perspective Adaptation Module\nthat dynamically selects optimal viewpoints based on the query, and a Fusion\nAlignment Module that integrates visual and spatial signals to enhance\nlocalization precision. Extensive evaluations on ScanRefer and Nr3D confirm\nthat SeeGround achieves substantial improvements over existing zero-shot\nbaselines -- outperforming them by 7.7% and 7.1%, respectively -- and even\nrivals fully supervised alternatives, demonstrating strong generalization under\nchallenging conditions.",
    "pdf_url": "http://arxiv.org/pdf/2505.22429v1",
    "published": "2025-05-28T14:53:53+00:00",
    "categories": [
      "cs.CV",
      "cs.RO"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.22428v1",
    "title": "Parental Collaboration and Closeness: Envisioning with New Couple Parents",
    "authors": [
      "Ya-Fang Lin",
      "Xiaotian Li",
      "Wan-Hsuan Huang",
      "Charan Pushpanathan Prabavathi",
      "Jie Cai",
      "John M. Carroll"
    ],
    "abstract": "Couples often experience a decrease in closeness as they cope with the\ndemands of parenthood. Existing technologies have supported parenting and\nparental collaboration. However, these technologies do not adequately support\ncloseness in co-parenting. We use scenarios and design probes to brainstorm\nwith 10 new parent couples to explore and envision possibilities for\ntechnologies to support closeness. We reported parents' current technology use\nfor co-parenting and how participants considered and envisioned co-parenting\ntechnology for closeness, including information and task sharing, emotion\nawareness and disclosure, and fostering fun interaction. We discuss the\npotential technology has for fostering closeness in co-parenting by (1)\nfostering interdependence by supporting parental competence and (2) integrating\npositive emotions and experiences, such as validation and fun, in parenting.\nBased on our findings, we expand the design space of technology for closeness\nto include interdependence. We also expand the design space for co-parenting\ntechnology by integrating more positive emotions.",
    "pdf_url": "http://arxiv.org/pdf/2505.22428v1",
    "published": "2025-05-28T14:53:08+00:00",
    "categories": [
      "cs.HC",
      "cs.CY"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2505.22427v1",
    "title": "RC-AutoCalib: An End-to-End Radar-Camera Automatic Calibration Network",
    "authors": [
      "Van-Tin Luu",
      "Yon-Lin Cai",
      "Vu-Hoang Tran",
      "Wei-Chen Chiu",
      "Yi-Ting Chen",
      "Ching-Chun Huang"
    ],
    "abstract": "This paper presents a groundbreaking approach - the first online automatic\ngeometric calibration method for radar and camera systems. Given the\nsignificant data sparsity and measurement uncertainty in radar height data,\nachieving automatic calibration during system operation has long been a\nchallenge. To address the sparsity issue, we propose a Dual-Perspective\nrepresentation that gathers features from both frontal and bird's-eye views.\nThe frontal view contains rich but sensitive height information, whereas the\nbird's-eye view provides robust features against height uncertainty. We thereby\npropose a novel Selective Fusion Mechanism to identify and fuse reliable\nfeatures from both perspectives, reducing the effect of height uncertainty.\nMoreover, for each view, we incorporate a Multi-Modal Cross-Attention Mechanism\nto explicitly find location correspondences through cross-modal matching.\nDuring the training phase, we also design a Noise-Resistant Matcher to provide\nbetter supervision and enhance the robustness of the matching mechanism against\nsparsity and height uncertainty. Our experimental results, tested on the\nnuScenes dataset, demonstrate that our method significantly outperforms\nprevious radar-camera auto-calibration methods, as well as existing\nstate-of-the-art LiDAR-camera calibration techniques, establishing a new\nbenchmark for future research. The code is available at\nhttps://github.com/nycu-acm/RC-AutoCalib.",
    "pdf_url": "http://arxiv.org/pdf/2505.22427v1",
    "published": "2025-05-28T14:52:31+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.22426v1",
    "title": "Improved direct measurement of low-energy resonances in the $^{21}$Ne(p,$Œ≥$)$^{22}$Na reaction",
    "authors": [
      "R. S. Sidhu",
      "F. Casaburo",
      "E. Masha",
      "M. Aliotta",
      "C. Ananna",
      "L. Barbieri",
      "F. Barile",
      "C. Baron",
      "D. Bemmerer",
      "A. Best",
      "R. Biassisi",
      "A. Boeltzig",
      "R. Bonnel",
      "C. Broggini",
      "C. G. Bruno",
      "A. Caciolli",
      "M. Campostrini",
      "F. Cavanna",
      "T. Chillery",
      "G. F. Ciani",
      "P. Colombetti",
      "A. Compagnucci",
      "P. Corvisiero",
      "L. Csedreki",
      "T. Davinson",
      "R. Depalo",
      "A. Di Leva",
      "A. D'Ottavi",
      "Z. Elekes",
      "F. Ferraro",
      "A. Formicola",
      "Zs. Fulop",
      "G. Gervino",
      "R. Gesue",
      "G. Gosta",
      "A. Guglielmetti",
      "C. Gustavino",
      "Gy. Gyurky",
      "G. Imbriani",
      "J. Jones",
      "J. Jose",
      "M. Junker",
      "M. Lugaro",
      "P. Marigo",
      "J. Marsh",
      "R. Menegazzo",
      "D. Mercogliano",
      "D. Piatti",
      "P. Prati",
      "D. Rapagnani",
      "V. Rigato",
      "D. Robb",
      "M. Rossi",
      "R. Sariyal",
      "J. Skowronski",
      "O. Straniero",
      "T. Szucs",
      "S. Turkat",
      "M. Vagnoni",
      "S. Zavatarelli"
    ],
    "abstract": "In the nova temperature range, 0.1 GK $< T <$ 0.4 GK, several low-energy\nresonances dominate the $^{21}$Ne(p,$\\gamma$)$^{22}$Na reaction rate, which is\ncurrently affected by large uncertainties. We present a high-precision study of\nthe resonances at $E^{\\rm{lab}}_{\\rm{r}}$ = 127.3, 271.4, 272.3, 291.5, and\n352.6 keV, measured directly at the Laboratory for Underground Nuclear\nAstrophysics in Italy. The strengths of the 127.3, 271.4, and 291.5 keV\nresonances are consistent with previous measurements within 1$\\sigma$. However,\nfor the 272.3 keV and 352.6 keV resonances, we report strength values of (129.9\n$\\pm$ 5.8) meV and (14.9 $\\pm$ 0.8) meV, respectively, more than a factor of\n1.5 higher than literature values. In addition, we report on new branching\nratios for the 127.3, 272.3, and 352.6 keV resonances, leading to updated decay\nschemes. Finally, we present a revised thermonuclear reaction rate and\ninvestigate its impact on the NeNa nucleosynthesis.",
    "pdf_url": "http://arxiv.org/pdf/2505.22426v1",
    "published": "2025-05-28T14:52:27+00:00",
    "categories": [
      "nucl-ex",
      "hep-ex"
    ],
    "primary_category": "nucl-ex"
  },
  {
    "id": "http://arxiv.org/abs/2505.22425v1",
    "title": "Scaling Reasoning without Attention",
    "authors": [
      "Xueliang Zhao",
      "Wei Wu",
      "Lingpeng Kong"
    ],
    "abstract": "Large language models (LLMs) have made significant advances in complex\nreasoning tasks, yet they remain bottlenecked by two core challenges:\narchitectural inefficiency due to reliance on Transformers, and a lack of\nstructured fine-tuning for high-difficulty domains. We introduce \\ourmodel, an\nattention-free language model that addresses both issues through architectural\nand data-centric innovations. Built on the state space dual (SSD) layers of\nMamba-2, our model eliminates the need for self-attention and key-value\ncaching, enabling fixed-memory, constant-time inference. To train it for\ncomplex reasoning, we propose a two-phase curriculum fine-tuning strategy based\non the \\textsc{PromptCoT} synthesis paradigm, which generates pedagogically\nstructured problems via abstract concept selection and rationale-guided\ngeneration. On benchmark evaluations, \\ourmodel-7B outperforms strong\nTransformer and hybrid models of comparable scale, and even surpasses the much\nlarger Gemma3-27B by 2.6\\% on AIME 24, 0.6\\% on AIME 25, and 3.0\\% on\nLivecodebench. These results highlight the potential of state space models as\nefficient and scalable alternatives to attention-based architectures for\nhigh-capacity reasoning.",
    "pdf_url": "http://arxiv.org/pdf/2505.22425v1",
    "published": "2025-05-28T14:52:15+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.22424v1",
    "title": "Hybrid Learning for Cold-Start-Aware Microservice Scheduling in Dynamic Edge Environments",
    "authors": [
      "Jingxi Lu",
      "Wenhao Li",
      "Jianxiong Guo",
      "Xingjian Ding",
      "Zhiqing Tang",
      "Tian Wang",
      "Weijia Jia"
    ],
    "abstract": "With the rapid growth of IoT devices and their diverse workloads,\ncontainer-based microservices deployed at edge nodes have become a lightweight\nand scalable solution. However, existing microservice scheduling algorithms\noften assume static resource availability, which is unrealistic when multiple\ncontainers are assigned to an edge node. Besides, containers suffer from\ncold-start inefficiencies during early-stage training in currently popular\nreinforcement learning (RL) algorithms. In this paper, we propose a hybrid\nlearning framework that combines offline imitation learning (IL) with online\nSoft Actor-Critic (SAC) optimization to enable a cold-start-aware microservice\nscheduling with dynamic allocation for computing resources. We first formulate\na delay-and-energy-aware scheduling problem and construct a rule-based expert\nto generate demonstration data for behavior cloning. Then, a GRU-enhanced\npolicy network is designed in the policy network to extract the correlation\namong multiple decisions by separately encoding slow-evolving node states and\nfast-changing microservice features, and an action selection mechanism is given\nto speed up the convergence. Extensive experiments show that our method\nsignificantly accelerates convergence and achieves superior final performance.\nCompared with baselines, our algorithm improves the total objective by $50\\%$\nand convergence speed by $70\\%$, and demonstrates the highest stability and\nrobustness across various edge configurations.",
    "pdf_url": "http://arxiv.org/pdf/2505.22424v1",
    "published": "2025-05-28T14:51:57+00:00",
    "categories": [
      "cs.NI",
      "eess.SP"
    ],
    "primary_category": "cs.NI"
  },
  {
    "id": "http://arxiv.org/abs/2505.22423v1",
    "title": "Max-laws of large numbers for weakly dependent high dimensional arrays with applications",
    "authors": [
      "Jonathan B. Hill"
    ],
    "abstract": "We derive so-called weak and strong \\textit{max-laws of large numbers} for $%\n\\max_{1\\leq i\\leq k_{n}}|1/n\\sum_{t=1}^{n}x_{i,n,t}|$ for zero mean stochastic\ntriangular arrays $\\{x_{i,n,t}$ $:$ $1$ $\\leq $ $t$ $\\leq n\\}_{n\\geq 1}$, with\ndimension counter $i$ $=$ $1,...,k_{n}$ and dimension $% k_{n}$ $\\rightarrow $\n$\\infty $. Rates of convergence are also analyzed based on feasible sequences\n$\\{k_{n}\\}$. We work in three dependence settings: independence, Dedecker and\nPrieur's (2004) $\\tau $-mixing and Wu's (2005) physical dependence. We\ninitially ignore cross-coordinate $i$ dependence as a benchmark. We then work\nwith martingale, nearly martingale, and mixing coordinates to deliver improved\nbounds on $k_{n}$. Finally, we use the results in three applications, each\nrepresenting a key novelty: we ($i$) bound $k_{n}$\\ for a max-correlation\nstatistic for regression residuals under $\\alpha $-mixing or physical\ndependence; ($ii$) extend correlation screening, or marginal regressions, to\nphysical dependent data with diverging dimension $k_{n}$ $\\rightarrow $ $\\infty\n$; and ($iii$) test a high dimensional parameter after partialling out a fixed\ndimensional nuisance parameter in a linear time series regression model under\n$\\tau $% -mixing.",
    "pdf_url": "http://arxiv.org/pdf/2505.22423v1",
    "published": "2025-05-28T14:50:36+00:00",
    "categories": [
      "math.ST",
      "stat.TH",
      "62E99, 60F99, 60F10"
    ],
    "primary_category": "math.ST"
  },
  {
    "id": "http://arxiv.org/abs/2506.06319v2",
    "title": "Limits of Disclosure in Search Markets",
    "authors": [
      "Raphael Boleslavsky",
      "Silvana Krasteva"
    ],
    "abstract": "This paper examines competitive information disclosure in search markets with\na mix of savvy consumers, who search costlessly, and inexperienced consumers,\nwho face positive search costs. Savvy consumers incentivize truthful\ndisclosure; inexperienced consumers, concealment. With both types, equilibrium\nfeatures partial disclosure, which persists despite intense competition: in\nlarge markets, firms always conceal low valuations. Inexperienced consumers may\nsearch actively, but only in small markets. While savvy consumers benefit from\nincreased competition, inexperienced consumers may be harmed. Changes in search\ncosts have non-monotone effects: when costs are low, sufficient reductions\nincrease informativeness and welfare; when costs are high, the opposite.",
    "pdf_url": "http://arxiv.org/pdf/2506.06319v2",
    "published": "2025-05-28T14:49:13+00:00",
    "categories": [
      "econ.TH"
    ],
    "primary_category": "econ.TH"
  },
  {
    "id": "http://arxiv.org/abs/2505.22422v1",
    "title": "STaR-Bets: Sequential Target-Recalculating Bets for Tighter Confidence Intervals",
    "authors": [
      "V√°clav Vor√°ƒçek",
      "Francesco Orabona"
    ],
    "abstract": "The construction of confidence intervals for the mean of a bounded random\nvariable is a classical problem in statistics with numerous applications in\nmachine learning and virtually all scientific fields. In particular, obtaining\nthe tightest possible confidence intervals is vital every time the sampling of\nthe random variables is expensive. The current state-of-the-art method to\nconstruct confidence intervals is by using betting algorithms. This is a very\nsuccessful approach for deriving optimal confidence sequences, even matching\nthe rate of law of iterated logarithms. However, in the fixed horizon setting,\nthese approaches are either sub-optimal or based on heuristic solutions with\nstrong empirical performance but without a finite-time guarantee. Hence, no\nbetting-based algorithm guaranteeing the optimal\n$\\mathcal{O}(\\sqrt{\\frac{\\sigma^2\\log\\frac1\\delta}{n}})$ width of the\nconfidence intervals are known. This work bridges this gap. We propose a\nbetting-based algorithm to compute confidence intervals that empirically\noutperforms the competitors. Our betting strategy uses the optimal strategy in\nevery step (in a certain sense), whereas the standard betting methods choose a\nconstant strategy in advance. Leveraging this fact results in strict\nimprovements even for classical concentration inequalities, such as the ones of\nHoeffding or Bernstein. Moreover, we also prove that the width of our\nconfidence intervals is optimal up to an $1+o(1)$ factor diminishing with $n$.\nThe code is available\non~https://github.com/vvoracek/STaR-bets-confidence-interval.",
    "pdf_url": "http://arxiv.org/pdf/2505.22422v1",
    "published": "2025-05-28T14:48:07+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.22421v2",
    "title": "GeoDrive: 3D Geometry-Informed Driving World Model with Precise Action Control",
    "authors": [
      "Anthony Chen",
      "Wenzhao Zheng",
      "Yida Wang",
      "Xueyang Zhang",
      "Kun Zhan",
      "Peng Jia",
      "Kurt Keutzer",
      "Shanghang Zhang"
    ],
    "abstract": "Recent advancements in world models have revolutionized dynamic environment\nsimulation, allowing systems to foresee future states and assess potential\nactions. In autonomous driving, these capabilities help vehicles anticipate the\nbehavior of other road users, perform risk-aware planning, accelerate training\nin simulation, and adapt to novel scenarios, thereby enhancing safety and\nreliability. Current approaches exhibit deficiencies in maintaining robust 3D\ngeometric consistency or accumulating artifacts during occlusion handling, both\ncritical for reliable safety assessment in autonomous navigation tasks. To\naddress this, we introduce GeoDrive, which explicitly integrates robust 3D\ngeometry conditions into driving world models to enhance spatial understanding\nand action controllability. Specifically, we first extract a 3D representation\nfrom the input frame and then obtain its 2D rendering based on the\nuser-specified ego-car trajectory. To enable dynamic modeling, we propose a\ndynamic editing module during training to enhance the renderings by editing the\npositions of the vehicles. Extensive experiments demonstrate that our method\nsignificantly outperforms existing models in both action accuracy and 3D\nspatial awareness, leading to more realistic, adaptable, and reliable scene\nmodeling for safer autonomous driving. Additionally, our model can generalize\nto novel trajectories and offers interactive scene editing capabilities, such\nas object editing and object trajectory control.",
    "pdf_url": "http://arxiv.org/pdf/2505.22421v2",
    "published": "2025-05-28T14:46:51+00:00",
    "categories": [
      "cs.CV",
      "cs.RO"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.23841v1",
    "title": "SkewRoute: Training-Free LLM Routing for Knowledge Graph Retrieval-Augmented Generation via Score Skewness of Retrieved Context",
    "authors": [
      "Hairu Wang",
      "Yuan Feng",
      "Yukun Cao",
      "Xike Xie",
      "S Kevin Zhou"
    ],
    "abstract": "Large language models excel at many tasks but often incur high inference\ncosts during deployment. To mitigate hallucination, many systems use a\nknowledge graph to enhance retrieval-augmented generation (KG-RAG). However,\nthe large amount of retrieved knowledge contexts increase these inference costs\nfurther. A promising solution to balance performance and cost is LLM routing,\nwhich directs simple queries to smaller LLMs and complex ones to larger LLMs.\nHowever, no dedicated routing methods currently exist for RAG, and existing\ntraining-based routers face challenges scaling to this domain due to the need\nfor extensive training data. We observe that the score distributions produced\nby the retrieval scorer strongly correlate with query difficulty. Based on\nthis, we propose a novel, training-free routing framework, the first tailored\nto KG-RAG that effectively balances performance and cost in a plug-and-play\nmanner. Experiments show our method reduces calls to larger LLMs by up to 50%\nwithout sacrificing response quality, demonstrating its potential for efficient\nand scalable LLM deployment.",
    "pdf_url": "http://arxiv.org/pdf/2505.23841v1",
    "published": "2025-05-28T14:45:56+00:00",
    "categories": [
      "cs.IR",
      "cs.CL"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2506.10015v1",
    "title": "Identifying critical residues of a protein using meaningfully-thresholded Random Geometric Graphs",
    "authors": [
      "Chuqiao Zhang",
      "Sarath Chandra Dantu",
      "Debarghya Mitra",
      "Dalia Chakrabarty"
    ],
    "abstract": "Identification of critical residues of a protein is actively pursued, since\nsuch residues are essential for protein function. We present three ways of\nrecognising critical residues of an example protein, the evolution of which is\ntracked via molecular dynamical simulations. Our methods are based on learning\na Random Geometric Graph (RGG) variable, where the state variable of each of\n156 residues, is attached to a node of this graph, with the RGG learnt using\nthe matrix of correlations between state variables of each residue-pair. Given\nthe categorical nature of the state variable, correlation between a residue\npair is computed using Cramer's V. We advance an organic thresholding to learn\nan RGG, and compare results against extant thresholding techniques, when\nparametrising criticality as the nodal degree in the learnt RGG. Secondly, we\ndevelop a criticality measure by ranking the computed differences between the\nposterior probability of the full graph variable defined on all 156 residues,\nand that of the graph with all but one residue omitted. A third parametrisation\nof criticality informs on the dynamical variation of nodal degrees as the\nprotein evolves during the simulation. Finally, we compare results obtained\nwith the three distinct criticality parameters, against\nexperimentally-ascertained critical residues.",
    "pdf_url": "http://arxiv.org/pdf/2506.10015v1",
    "published": "2025-05-28T14:45:33+00:00",
    "categories": [
      "q-bio.BM",
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "q-bio.BM"
  },
  {
    "id": "http://arxiv.org/abs/2505.22420v2",
    "title": "Robustness of topological edge states in alternating spin chains against environment",
    "authors": [
      "Alexander Sattler",
      "Maria Daghofer"
    ],
    "abstract": "Both the Haldane spin-$1$ chain and dimerized chains of\n  spin-$1/2$ exhibit topologically protected edge states that\n  are robust against specific perturbations. Recently, such spin\n  chains have been specifically assembled on surfaces and we\n  investigate here the robustness of these edge states against\n  coupling to the surface. Since no physical system can be considered perfectly\nisolated, it\n  is crucial to examine whether topological robustness is maintained in the\n  presence of environmental coupling.\n  We apply exact diagonalization to a Lindblad master equation that couples an\n  alternating Heisenberg spin chain based on spins $1/2$ to a surface via\n  various jump operators. The robustness of topological states is assessed via\nthe\n  time evolution of quantities such as the ground-state degeneracy, correlation\n  function, entropy, and magnetization of edge states.\n  We investigate chains built from dimers with antiferromagnetic and\n  ferromagnetic intra-dimer coupling, which resemble\n  Su-Schrieffer-Heeger and the Haldane models, resp., and assess the\n  impact of $z$-axis anisotropy and longer-ranged couplings. Generally,\n  we find that signatures of topological properties are\n  more robust in Su-Schrieffer-Heeger-like chains than in\n  Haldane-like chains.",
    "pdf_url": "http://arxiv.org/pdf/2505.22420v2",
    "published": "2025-05-28T14:45:16+00:00",
    "categories": [
      "cond-mat.str-el"
    ],
    "primary_category": "cond-mat.str-el"
  },
  {
    "id": "http://arxiv.org/abs/2505.22419v1",
    "title": "Structural Hole Traps in III-V Quantum Dots",
    "authors": [
      "Ezra Alexander",
      "Alexandra Alexiu",
      "Matthias Kick",
      "Troy Van Voorhis"
    ],
    "abstract": "Non-toxic III-V quantum dots (QDs) are plagued with a higher density of\nperformance-limiting trap states than II-VI and IV-VI QDs. Such trap states are\ngenerally understood to arise from under-coordinated atoms on the QD surface.\nHere, we present computational evidence for, and an exploration of, trap states\nin InP and GaP QDs that arise from fully-coordinated atoms with distorted\ngeometries, denoted here as structural traps. In particular, we focus on the\nproperties of anion-centered hole traps, which we show to be relatively\ninsensitive to the choice of the (typically cation-coordinating) ligand.\nThrough interpolation of trap center cutouts, we arrive at a simple molecular\norbital (MO) argument for the existence of structural traps, finding two main\nmodalities: bond stretches and angular distortion to a see-saw-like geometry.\nThese structural trap states will be important for understanding the low\nperformance of III-V QDs, as even core-shell passivation may not remove these\ndefects unless they can rigidify the structure. Moreover, they may lead to\ninteresting dynamical properties as distorted structures could form\ntransiently.",
    "pdf_url": "http://arxiv.org/pdf/2505.22419v1",
    "published": "2025-05-28T14:44:42+00:00",
    "categories": [
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2505.22418v1",
    "title": "AI Trust Reshaping Administrative Burdens: Understanding Trust-Burden Dynamics in LLM-Assisted Benefits Systems",
    "authors": [
      "Jeongwon Jo",
      "He Zhang",
      "Jie Cai",
      "Nitesh Goyal"
    ],
    "abstract": "Supplemental Nutrition Assistance Program (SNAP) is an essential benefit\nsupport system provided by the US administration to 41 million federally\ndetermined low-income applicants. Through interviews with such applicants\nacross a diverse set of experiences with the SNAP system, our findings reveal\nthat new AI technologies like LLMs can alleviate traditional burdens but also\nintroduce new burdens. We introduce new types of learning, compliance, and\npsychological costs that transform the administrative burden on applicants. We\nalso identify how trust in AI across three dimensions--competence, integrity,\nand benevolence--is perceived to reduce administrative burdens, which may stem\nfrom unintended and untoward overt trust in the system. We discuss calibrating\nappropriate levels of user trust in LLM-based administrative systems,\nmitigating newly introduced burdens. In particular, our findings suggest that\nevidence-based information disclosure is necessary in benefits administration\nand propose directions for future research on trust-burden dynamics in\nAI-assisted administration systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.22418v1",
    "published": "2025-05-28T14:43:55+00:00",
    "categories": [
      "cs.HC"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2505.22417v1",
    "title": "High-Dimensional Binary Variates: Maximum Likelihood Estimation with Nonstationary Covariates and Factors",
    "authors": [
      "Xinbing Kong",
      "Bin Wu",
      "Wuyi Ye"
    ],
    "abstract": "This paper introduces a high-dimensional binary variate model that\naccommodates nonstationary covariates and factors, and studies their asymptotic\ntheory. This framework encompasses scenarios where single indices are\nnonstationary or cointegrated. For nonstationary single indices, the maximum\nlikelihood estimator (MLE) of the coefficients has dual convergence rates and\nis collectively consistent under the condition $T^{1/2}/N\\to0$, as both the\ncross-sectional dimension $N$ and the time horizon $T$ approach infinity. The\nMLE of all nonstationary factors is consistent when $T^{\\delta}/N\\to0$, where\n$\\delta$ depends on the link function. The limiting distributions of the\nfactors depend on time $t$, governed by the convergence of the Hessian matrix\nto zero. In the case of cointegrated single indices, the MLEs of both factors\nand coefficients converge at a higher rate of $\\min(\\sqrt{N},\\sqrt{T})$. A\ndistinct feature compared to nonstationary single indices is that the dual rate\nof convergence of the coefficients increases from $(T^{1/4},T^{3/4})$ to\n$(T^{1/2},T)$. Moreover, the limiting distributions of the factors do not\ndepend on $t$ in the cointegrated case. Monte Carlo simulations verify the\naccuracy of the estimates. In an empirical application, we analyze jump\narrivals in financial markets using this model, extract jump arrival factors,\nand demonstrate their efficacy in large-cross-section asset pricing.",
    "pdf_url": "http://arxiv.org/pdf/2505.22417v1",
    "published": "2025-05-28T14:43:44+00:00",
    "categories": [
      "math.ST",
      "stat.TH"
    ],
    "primary_category": "math.ST"
  },
  {
    "id": "http://arxiv.org/abs/2505.22416v1",
    "title": "Neural Face Skinning for Mesh-agnostic Facial Expression Cloning",
    "authors": [
      "Sihun Cha",
      "Serin Yoon",
      "Kwanggyoon Seo",
      "Junyong Noh"
    ],
    "abstract": "Accurately retargeting facial expressions to a face mesh while enabling\nmanipulation is a key challenge in facial animation retargeting. Recent\ndeep-learning methods address this by encoding facial expressions into a global\nlatent code, but they often fail to capture fine-grained details in local\nregions. While some methods improve local accuracy by transferring deformations\nlocally, this often complicates overall control of the facial expression. To\naddress this, we propose a method that combines the strengths of both global\nand local deformation models. Our approach enables intuitive control and\ndetailed expression cloning across diverse face meshes, regardless of their\nunderlying structures. The core idea is to localize the influence of the global\nlatent code on the target mesh. Our model learns to predict skinning weights\nfor each vertex of the target face mesh through indirect supervision from\npredefined segmentation labels. These predicted weights localize the global\nlatent code, enabling precise and region-specific deformations even for meshes\nwith unseen shapes. We supervise the latent code using Facial Action Coding\nSystem (FACS)-based blendshapes to ensure interpretability and allow\nstraightforward editing of the generated animation. Through extensive\nexperiments, we demonstrate improved performance over state-of-the-art methods\nin terms of expression fidelity, deformation transfer accuracy, and\nadaptability across diverse mesh structures.",
    "pdf_url": "http://arxiv.org/pdf/2505.22416v1",
    "published": "2025-05-28T14:43:43+00:00",
    "categories": [
      "cs.GR",
      "cs.CV"
    ],
    "primary_category": "cs.GR"
  },
  {
    "id": "http://arxiv.org/abs/2505.22415v2",
    "title": "ABEL: The Adaptable Beginning-to-End Linac simulation framework",
    "authors": [
      "J. B. B. Chen",
      "E. Adli",
      "P. Drobniak",
      "O. G. Finnerud",
      "E. H√∏rlyk",
      "D. Kalvik",
      "C. A. Lindstr√∏m",
      "F. Pe√±a",
      "K. Sjobak"
    ],
    "abstract": "We introduce ABEL, the Adaptable Beginning-to-End Linac simulation framework\ndeveloped for agile design studies of plasma-based accelerators and colliders.\nABEL's modular architecture allows users to simulate particle acceleration\nacross various beamline components. The framework supports specialised codes\nsuch as HiPACE++, Wake-T, ELEGANT, GUINEA-PIG, CLICopti and ImpactX, which\nfacilitate precise modelling of complex machine components. Key features\ninclude simplified models for addressing transverse instabilities, radiation\nreactions, and ion motion, alongside comprehensive diagnostics and optimisation\ncapabilities. Our simulation studies focus on the HALHF plasma linac, examining\ntolerances for drive beam jitter, including effects of self-correction\nmechanisms. Simulation results demonstrate ABEL's ability to model emittance\ngrowth due to transverse instability and ion motion, highlighting the\nframework's adaptability in balancing simulation fidelity with computational\nefficiency. The findings point towards ABEL's potential for advancing compact\naccelerator designs and contribute to the broader goals of enhancing control\nand precision in plasma-based acceleration.",
    "pdf_url": "http://arxiv.org/pdf/2505.22415v2",
    "published": "2025-05-28T14:42:25+00:00",
    "categories": [
      "physics.acc-ph"
    ],
    "primary_category": "physics.acc-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.22414v1",
    "title": "ToPSen: Task-Oriented Priming and Sensory Alignment for Comparing Coding Strategies Between Sighted and Blind Programmers",
    "authors": [
      "Md Ehtesham-Ul-Haque",
      "Syed Masum Billah"
    ],
    "abstract": "This paper examines how the coding strategies of sighted and blind\nprogrammers differ when working with audio feedback alone. The goal is to\nidentify challenges in mixed-ability collaboration, particularly when sighted\nprogrammers work with blind peers or teach programming to blind students. To\novercome limitations of traditional blindness simulation studies, we proposed\nTask-Oriented Priming and Sensory Alignment (ToPSen), a design framework that\nreframes sensory constraints as technical requirements rather than as a\ndisability. Through a study of 12 blind and 12 sighted participants coding\nnon-visually, we found that expert blind programmers maintain more accurate\nmental models and process more information in working memory than sighted\nprogrammers using ToPSen. Our analysis revealed that blind and sighted\nprogrammers process structural information differently, exposing gaps in\ncurrent IDE designs. These insights inform our guidelines for improving the\naccessibility of programming tools and fostering effective mixed-ability\ncollaboration.",
    "pdf_url": "http://arxiv.org/pdf/2505.22414v1",
    "published": "2025-05-28T14:41:29+00:00",
    "categories": [
      "cs.HC"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2505.22413v2",
    "title": "Thermodynamical aspects of fermions in external electromagnetic fields",
    "authors": [
      "Romeo Brunetti",
      "Klaus Fredenhagen",
      "Nicola Pinamonti"
    ],
    "abstract": "The thermodynamics of Dirac fields under the influence of external\nelectromagnetic fields is studied. For perturbations which act only for finite\ntime, the influence of the perturbation can be described by an automorphism\nwhich can be unitarily implemented in the GNS representations of KMS states, a\nresult long known for the Fock representation. For time-independent\nperturbations, however, the time evolution cannot be implemented in typical\ncases, so the standard methods of quantum statistical mechanics do not apply.\nInstead we show that a smooth switching on of the external potential allows a\ncomparison of the free and the perturbed time evolution, and approach to\nequilibrium, a possible existence of non-equilibrium stationary states (NESS)\nand Araki's relative entropy can be investigated. As a byproduct, we find an\nexplicit formula for the relative entropy of gauge invariant quasi-free states.",
    "pdf_url": "http://arxiv.org/pdf/2505.22413v2",
    "published": "2025-05-28T14:40:50+00:00",
    "categories": [
      "math-ph",
      "hep-th",
      "math.MP"
    ],
    "primary_category": "math-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.22412v2",
    "title": "Neutron Magic Numbers in $sd$ Shell from Nuclear Charge Radii within Neutron-Proton Correction around the Fermi Surface",
    "authors": [
      "Yu-Ting Rong",
      "Ping-Mo Liu",
      "Dan Yang",
      "Rong An"
    ],
    "abstract": "Charge radii are sensitive indicators to identify the nuclear structure\nphenomena throughout the whole nuclide chart. In particular, the shrunken trend\nof changes of charge radii along a long isotopic chain is intimately associated\nwith the shell quenching effect. In this work, the systematic evolution of\ncharge radii along the proton numbers $Z=8$, $10$, $12$, $14$, $18$ isotopes is\ninvestigated by a relativistic Hartree Bogoliubov model. A ansatz about\nneutron-proton correlation around Fermi surface is considered for describing\nthe abnormal behavior of nuclear charge radii. Our results show that the\nneutron-proton pairing corrections around the Fermi surface lead to a sudden\nstrengthening of the charge radii of these isotopic chains at $N=8$, 20 and 28,\nreflecting the fact that this correction enhances the shell closure across\n$N=8$, 20 and 28. The reproduction of the $N=14$ charge radius in the Mg\nisotopes is affected by the way in which pairing correlations are handled, with\nBCS theory overestimating the shell effect of $N=14$, and the Bogoliubov\nquasiparticle transformation suggests a stronger pairing correlation near the\nproton Fermi surface, which is more consistent with experimental results. An\nanalysis of the deviations from the theoretical and available experimental data\nfor the charge radii of the 24 selected even-even nuclei shows that the\nneutron-proton pairing correction around the Fermi surface has an improved\neffect on the calculation of the charge {radii} using the meson-exchange\neffective interactions, but it does not help to significantly improve the\nresults calculated by the density-dependent effective interactions.",
    "pdf_url": "http://arxiv.org/pdf/2505.22412v2",
    "published": "2025-05-28T14:39:48+00:00",
    "categories": [
      "nucl-th"
    ],
    "primary_category": "nucl-th"
  },
  {
    "id": "http://arxiv.org/abs/2505.22411v1",
    "title": "Mitigating Overthinking in Large Reasoning Models via Manifold Steering",
    "authors": [
      "Yao Huang",
      "Huanran Chen",
      "Shouwei Ruan",
      "Yichi Zhang",
      "Xingxing Wei",
      "Yinpeng Dong"
    ],
    "abstract": "Recent advances in Large Reasoning Models (LRMs) have demonstrated remarkable\ncapabilities in solving complex tasks such as mathematics and coding. However,\nthese models frequently exhibit a phenomenon known as overthinking during\ninference, characterized by excessive validation loops and redundant\ndeliberation, leading to substantial computational overheads. In this paper, we\naim to mitigate overthinking by investigating the underlying mechanisms from\nthe perspective of mechanistic interpretability. We first showcase that the\ntendency of overthinking can be effectively captured by a single direction in\nthe model's activation space and the issue can be eased by intervening the\nactivations along this direction. However, this efficacy soon reaches a plateau\nand even deteriorates as the intervention strength increases. We therefore\nsystematically explore the activation space and find that the overthinking\nphenomenon is actually tied to a low-dimensional manifold, which indicates that\nthe limited effect stems from the noises introduced by the high-dimensional\nsteering direction. Based on this insight, we propose Manifold Steering, a\nnovel approach that elegantly projects the steering direction onto the\nlow-dimensional activation manifold given the theoretical approximation of the\ninterference noise. Extensive experiments on DeepSeek-R1 distilled models\nvalidate that our method reduces output tokens by up to 71% while maintaining\nand even improving the accuracy on several mathematical benchmarks. Our method\nalso exhibits robust cross-domain transferability, delivering consistent token\nreduction performance in code generation and knowledge-based QA tasks. Code is\navailable at: https://github.com/Aries-iai/Manifold_Steering.",
    "pdf_url": "http://arxiv.org/pdf/2505.22411v1",
    "published": "2025-05-28T14:39:26+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.22410v1",
    "title": "Faster Convolutions: Yates and Strassen Revisited",
    "authors": [
      "Cornelius Brand",
      "Radu Curticapean",
      "Baitian Li",
      "Kevin Pratt"
    ],
    "abstract": "Given two vectors $u,v \\in \\mathbb{Q}^D$ over a finite domain $D$ and a\nfunction $f : D\\times D\\to D$, the convolution problem asks to compute the\nvector $w \\in \\mathbb{Q}^D$ whose entries are defined by $w(d) =\n\\sum_{\\substack{x,y \\in D \\\\ f(x,y)=d}} u(x)v(y).$ In parameterized and\nexponential-time algorithms, convolutions on product domains are particularly\nprominent: Here, a finite domain $B$ and a function $h : B \\times B \\to B$ are\nfixed, and convolution is done over the product domain $D = B^k$, using the\nfunction $h^k :D \\times D\\to D$ that applies $h$ coordinate-wise to its input\ntuples.\n  We present a new perspective on product-domain convolutions through\nmultilinear algebra. This viewpoint streamlines the presentation and analysis\nof existing algorithms, such as those by van Rooij et al. (ESA 2009). Moreover,\nusing established results from the theory of fast matrix multiplication, we\nderive improved $O^\\ast(|B|^{2\\omega/3 \\cdot k}) = O(|D|^{1.582})$ time\nalgorithms, improving upon previous upper bounds by Esmer et al. (Algorithmica\n86(1), 2024) of the form $c^k |B|^{2k}$ for $c < 1$. Using the setup described\nin this note, Strassen's asymptotic rank conjecture from algebraic complexity\ntheory would imply quasi-linear $|D|^{1+o(1)}$ time algorithms. This conjecture\nhas recently gained attention in the algorithms community. (Bj\\\"orklund-Kaski\nand Pratt, STOC 2024, Bj\\\"orklund et al., SODA 2025)\n  Our paper is intended as a self-contained exposition for an algorithms\naudience, and it includes all essential mathematical prerequisites with\nexplicit coordinate-based notation. In particular, we assume no knowledge in\nabstract algebra.",
    "pdf_url": "http://arxiv.org/pdf/2505.22410v1",
    "published": "2025-05-28T14:38:22+00:00",
    "categories": [
      "cs.DS",
      "cs.CC"
    ],
    "primary_category": "cs.DS"
  },
  {
    "id": "http://arxiv.org/abs/2505.22409v1",
    "title": "Precision Measurement of Spin-Dependent Dipolar Splitting in $^6$Li p-Wave Feshbach Resonances",
    "authors": [
      "Shuai Peng",
      "Sijia Peng",
      "Lijun Ren",
      "Shaokun Liu",
      "Bin Liu",
      "Jiaming Li",
      "Le Luo"
    ],
    "abstract": "The magnetic dipolar splitting of a p-wave Feshbach resonance is governed by\nthe spin-orbital configuration of the valence electrons in the triplet\nmolecular state. We perform high-resolution trap loss spectroscopy on ultracold\n6Li atoms to resolve this splitting with sub-milligauss precision. By comparing\nspin-polarized (|mS| = 1) and spin-mixture (mS = 0) configurations of the\ntriplet state, we observe a clear spin-dependent reversal in the splitting\nstructure, confirmed via momentumresolved absorption imaging. This behavior\ndirectly reflects the interplay between electron spin projection mS and orbital\nangular momentum ml in the molecular states. Our results provide a stringent\nbenchmark for dipole-dipole interaction models and lay the groundwork for\ncontrolling the pairing in p-wave superfluid systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.22409v1",
    "published": "2025-05-28T14:38:21+00:00",
    "categories": [
      "cond-mat.quant-gas"
    ],
    "primary_category": "cond-mat.quant-gas"
  },
  {
    "id": "http://arxiv.org/abs/2505.22408v1",
    "title": "Frugal Incremental Generative Modeling using Variational Autoencoders",
    "authors": [
      "Victor Enescu",
      "Hichem Sahbi"
    ],
    "abstract": "Continual or incremental learning holds tremendous potential in deep learning\nwith different challenges including catastrophic forgetting. The advent of\npowerful foundation and generative models has propelled this paradigm even\nfurther, making it one of the most viable solution to train these models.\nHowever, one of the persisting issues lies in the increasing volume of data\nparticularly with replay-based methods. This growth introduces challenges with\nscalability since continuously expanding data becomes increasingly demanding as\nthe number of tasks grows. In this paper, we attenuate this issue by devising a\nnovel replay-free incremental learning model based on Variational Autoencoders\n(VAEs). The main contribution of this work includes (i) a novel incremental\ngenerative modelling, built upon a well designed multi-modal latent space, and\nalso (ii) an orthogonality criterion that mitigates catastrophic forgetting of\nthe learned VAEs. The proposed method considers two variants of these VAEs:\nstatic and dynamic with no (or at most a controlled) growth in the number of\nparameters. Extensive experiments show that our method is (at least) an order\nof magnitude more ``memory-frugal'' compared to the closely related works while\nachieving SOTA accuracy scores.",
    "pdf_url": "http://arxiv.org/pdf/2505.22408v1",
    "published": "2025-05-28T14:37:57+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.22407v1",
    "title": "Self-Reflective Reinforcement Learning for Diffusion-based Image Reasoning Generation",
    "authors": [
      "Jiadong Pan",
      "Zhiyuan Ma",
      "Kaiyan Zhang",
      "Ning Ding",
      "Bowen Zhou"
    ],
    "abstract": "Diffusion models have recently demonstrated exceptional performance in image\ngeneration task. However, existing image generation methods still significantly\nsuffer from the dilemma of image reasoning, especially in logic-centered image\ngeneration tasks. Inspired by the success of Chain of Thought (CoT) and\nReinforcement Learning (RL) in LLMs, we propose SRRL, a self-reflective RL\nalgorithm for diffusion models to achieve reasoning generation of logical\nimages by performing reflection and iteration across generation trajectories.\nThe intermediate samples in the denoising process carry noise, making accurate\nreward evaluation difficult. To address this challenge, SRRL treats the entire\ndenoising trajectory as a CoT step with multi-round reflective denoising\nprocess and introduces condition guided forward process, which allows for\nreflective iteration between CoT steps. Through SRRL-based iterative diffusion\ntraining, we introduce image reasoning through CoT into generation tasks\nadhering to physical laws and unconventional physical phenomena for the first\ntime. Notably, experimental results of case study exhibit that the superior\nperformance of our SRRL algorithm even compared with GPT-4o. The project page\nis https://jadenpan0.github.io/srrl.github.io/.",
    "pdf_url": "http://arxiv.org/pdf/2505.22407v1",
    "published": "2025-05-28T14:37:21+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.22406v1",
    "title": "Complete Catalog of Laser Locking Configurations for LISA",
    "authors": [
      "Gerhard Heinzel",
      "Javier √Ålvarez-Vizoso",
      "Miguel Dovale-√Ålvarez"
    ],
    "abstract": "The Laser Interferometer Space Antenna (LISA) will enable direct observations\nof low-frequency gravitational waves, offering unprecedented insight into\nastrophysical and cosmological phenomena. LISA's heterodyne interferometric\nmeasurement system requires phase-locking five of its six onboard lasers with\ntunable frequency offsets to ensure that all beatnotes remain within the\nmetrology system's operational range, despite Doppler-induced frequency shifts.\nThe selection of these offset frequencies -- collectively forming a frequency\nplan -- is a complex optimization problem constrained by the spacecraft's\norbital dynamics and instrument limitations. While previous work established an\nalgorithmic solution for deriving time-dependent frequency plans, this study\ntakes a complementary approach by systematically analyzing and cataloging all\npossible laser locking configurations. We present an automated method to\nexplore, validate, and classify viable locking schemes, identifying 36 unique\nnon-frequency-swapping configurations and 72 additional frequency-swapping\nconfigurations for an arbitrary choice of primary laser. This exhaustive\nclassification provides a foundation for frequency planning across the full\nrange of operational scenarios.",
    "pdf_url": "http://arxiv.org/pdf/2505.22406v1",
    "published": "2025-05-28T14:37:13+00:00",
    "categories": [
      "physics.ins-det",
      "astro-ph.IM",
      "gr-qc",
      "physics.space-ph"
    ],
    "primary_category": "physics.ins-det"
  },
  {
    "id": "http://arxiv.org/abs/2505.22405v1",
    "title": "Quantum Search on Computation Trees",
    "authors": [
      "Jevgƒìnijs Vihrovs"
    ],
    "abstract": "We show a simple generalization of the quantum walk algorithm for search in\nbacktracking trees by Montanaro (ToC 2018) to the case where vertices can have\ndifferent times of computation. If a vertex $v$ in the tree of depth $D$ is\ncomputed in $t_v$ steps from its parent, then we show that detection of a\nmarked vertex requires $\\text{O}(\\sqrt{TD})$ queries to the steps of the\ncomputing procedures, where $T = \\sum_v t_v^2$. This framework provides an easy\nand convenient way to re-obtain a number of other quantum frameworks like\nvariable time search, quantum divide & conquer and bomb query algorithms. The\nunderlying algorithm is simple, explicitly constructed, and has low\npoly-logarithmic factors in the complexity.\n  As a corollary, this gives a quantum algorithm for variable time search with\nunknown times with optimal query complexity $\\text{O}(\\sqrt{T \\log\n\\min(n,t_{\\max})})$, where $T = \\sum_i t_i^2$ and $t_{\\max} = \\max_i t_i$ if\n$t_i$ is the number of steps required to compute the $i$-th variable. This\nresolves the open question of the query complexity of variable time search, as\nthe matching lower bound was recently shown by Ambainis, Kokainis and Vihrovs\n(TQC'23). As another result, we obtain an $\\widetilde{\\text{O}}(n)$ time\nalgorithm for the geometric task of determining if any three lines among $n$\ngiven intersect at the same point, improving the $\\text{O}(n^{1+\\text{o}(1)})$\nalgorithm of Ambainis and Larka (TQC'20).",
    "pdf_url": "http://arxiv.org/pdf/2505.22405v1",
    "published": "2025-05-28T14:35:18+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.22404v2",
    "title": "Efficient Precision-Scalable Hardware for Microscaling (MX) Processing in Robotics Learning",
    "authors": [
      "Stef Cuyckens",
      "Xiaoling Yi",
      "Nitish Satya Murthy",
      "Chao Fang",
      "Marian Verhelst"
    ],
    "abstract": "Autonomous robots require efficient on-device learning to adapt to new\nenvironments without cloud dependency. For this edge training, Microscaling\n(MX) data types offer a promising solution by combining integer and\nfloating-point representations with shared exponents, reducing energy\nconsumption while maintaining accuracy. However, the state-of-the-art\ncontinuous learning processor, namely Dacapo, faces limitations with its\nMXINT-only support and inefficient vector-based grouping during\nbackpropagation. In this paper, we present, to the best of our knowledge, the\nfirst work that addresses these limitations with two key innovations: (1) a\nprecision-scalable arithmetic unit that supports all six MX data types by\nexploiting sub-word parallelism and unified integer and floating-point\nprocessing; and (2) support for square shared exponent groups to enable\nefficient weight handling during backpropagation, removing storage redundancy\nand quantization overhead. We evaluate our design against Dacapo under\niso-peak-throughput on four robotics workloads in TSMC 16nm FinFET technology\nat 400MHz, reaching a 51% lower memory footprint, and 4x higher effective\ntraining throughput, while achieving comparable energy efficiency, enabling\nefficient robotics continual learning at the edge.",
    "pdf_url": "http://arxiv.org/pdf/2505.22404v2",
    "published": "2025-05-28T14:34:32+00:00",
    "categories": [
      "cs.AR",
      "cs.RO"
    ],
    "primary_category": "cs.AR"
  },
  {
    "id": "http://arxiv.org/abs/2505.22698v1",
    "title": "Design and testing of an agent chatbot supporting decision making with public transport data",
    "authors": [
      "Luca Fantin",
      "Marco Antonelli",
      "Margherita Cesetti",
      "Daniele Irto",
      "Bruno Zamengo",
      "Francesco Silvestri"
    ],
    "abstract": "Assessing the quality of public transportation services requires the analysis\nof large quantities of data on the scheduled and actual trips and documents\nlisting the quality constraints each service needs to meet. Interrogating such\ndatasets with SQL queries, organizing and visualizing the data can be quite\ncomplex for most users. This paper presents a chatbot offering a user-friendly\ntool to interact with these datasets and support decision making. It is based\non an agent architecture, which expands the capabilities of the core Large\nLanguage Model (LLM) by allowing it to interact with a series of tools that can\nexecute several tasks, like performing SQL queries, plotting data and creating\nmaps from the coordinates of a trip and its stops. This paper also tackles one\nof the main open problems of such Generative AI projects: collecting data to\nmeasure the system's performance. Our chatbot has been extensively tested with\na workflow that asks several questions and stores the generated query, the\nretrieved data and the natural language response for each of them. Such\nquestions are drawn from a set of base examples which are then completed with\nactual data from the database. This procedure yields a dataset for the\nevaluation of the chatbot's performance, especially the consistency of its\nanswers and the correctness of the generated queries.",
    "pdf_url": "http://arxiv.org/pdf/2505.22698v1",
    "published": "2025-05-28T14:31:14+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.22403v3",
    "title": "Knot invariants from representations of braids by automorphisms of a free group",
    "authors": [
      "Vladimir Shpilrain"
    ],
    "abstract": "We describe an alternative way of computing Alexander polynomials of\nknots/links, based on the Artin representation of the corresponding braids by\nautomorphisms of a free group. Then we apply the same method to other\nrepresentations of braid groups discovered by Wada and compare the\ncorresponding isotopic invariants to Alexander polynomials.",
    "pdf_url": "http://arxiv.org/pdf/2505.22403v3",
    "published": "2025-05-28T14:29:28+00:00",
    "categories": [
      "math.GT",
      "math.GR"
    ],
    "primary_category": "math.GT"
  },
  {
    "id": "http://arxiv.org/abs/2505.22402v2",
    "title": "Machine-Learned Potentials for Solvation Modeling",
    "authors": [
      "Roopshree Banchode",
      "Surajit Das",
      "Shampa Raghunathan",
      "Raghunathan Ramakrishnan"
    ],
    "abstract": "Solvent environments play a central role in determining molecular structure,\nenergetics, reactivity, and interfacial phenomena. However, modeling solvation\nfrom first principles remains difficult due to the complex interplay of\ninteractions and unfavorable computational scaling of first-principles\ntreatment with system size. Machine-learned potentials (MLPs) have recently\nemerged as efficient surrogates for quantum chemistry methods, offering\nfirst-principles accuracy at greatly reduced computational cost. MLPs\napproximate the underlying potential energy surface, enabling efficient\ncomputation of energies and forces in solvated systems, and are capable of\naccounting for effects such as hydrogen bonding, long-range polarization, and\nconformational changes. This review surveys the development and application of\nMLPs in solvation modeling. We summarize the theoretical basis of MLP-based\nenergy and force predictions and present a classification of MLPs based on\ntraining targets, model types, and design choices related to architectures,\ndescriptors, and training protocols. Integration into established solvation\nworkflows is discussed, with case studies spanning small molecules, interfaces,\nand reactive systems. We conclude by outlining open challenges and future\ndirections toward transferable, robust, and physically grounded MLPs for\nsolvation-aware atomistic modeling.",
    "pdf_url": "http://arxiv.org/pdf/2505.22402v2",
    "published": "2025-05-28T14:29:09+00:00",
    "categories": [
      "physics.chem-ph"
    ],
    "primary_category": "physics.chem-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.22401v1",
    "title": "Facial Age Estimation: A Research Roadmap for Technological and Legal Development and Deployment",
    "authors": [
      "Richard Guest",
      "Eva Lievens",
      "Martin Sas",
      "Elena Botoeva",
      "Temitope Adeyemo",
      "Valerie Verdoodt",
      "Elora Fernandes",
      "Chris Allgrove"
    ],
    "abstract": "Automated facial age assessment systems operate in either estimation mode -\npredicting age based on facial traits, or verification mode - confirming a\nclaimed age. These systems support access control to age-restricted goods,\nservices, and content, and can be used in areas like e-commerce, social media,\nforensics, and refugee support. They may also personalise services in\nhealthcare, finance, and advertising. While improving technological accuracy is\nessential, deployment must consider legal, ethical, sociological, alongside\ntechnological factors. This white paper reviews the current challenges in\ndeploying such systems, outlines the relevant legal and regulatory landscape,\nand explores future research for fair, robust, and ethical age estimation\ntechnologies.",
    "pdf_url": "http://arxiv.org/pdf/2505.22401v1",
    "published": "2025-05-28T14:28:31+00:00",
    "categories": [
      "cs.CY"
    ],
    "primary_category": "cs.CY"
  },
  {
    "id": "http://arxiv.org/abs/2505.22400v1",
    "title": "STDR: Spatio-Temporal Decoupling for Real-Time Dynamic Scene Rendering",
    "authors": [
      "Zehao Li",
      "Hao Jiang",
      "Yujun Cai",
      "Jianing Chen",
      "Baolong Bi",
      "Shuqin Gao",
      "Honglong Zhao",
      "Yiwei Wang",
      "Tianlu Mao",
      "Zhaoqi Wang"
    ],
    "abstract": "Although dynamic scene reconstruction has long been a fundamental challenge\nin 3D vision, the recent emergence of 3D Gaussian Splatting (3DGS) offers a\npromising direction by enabling high-quality, real-time rendering through\nexplicit Gaussian primitives. However, existing 3DGS-based methods for dynamic\nreconstruction often suffer from \\textit{spatio-temporal incoherence} during\ninitialization, where canonical Gaussians are constructed by aggregating\nobservations from multiple frames without temporal distinction. This results in\nspatio-temporally entangled representations, making it difficult to model\ndynamic motion accurately. To overcome this limitation, we propose\n\\textbf{STDR} (Spatio-Temporal Decoupling for Real-time rendering), a\nplug-and-play module that learns spatio-temporal probability distributions for\neach Gaussian. STDR introduces a spatio-temporal mask, a separated deformation\nfield, and a consistency regularization to jointly disentangle spatial and\ntemporal patterns. Extensive experiments demonstrate that incorporating our\nmodule into existing 3DGS-based dynamic scene reconstruction frameworks leads\nto notable improvements in both reconstruction quality and spatio-temporal\nconsistency across synthetic and real-world benchmarks.",
    "pdf_url": "http://arxiv.org/pdf/2505.22400v1",
    "published": "2025-05-28T14:26:41+00:00",
    "categories": [
      "cs.GR",
      "cs.CV"
    ],
    "primary_category": "cs.GR"
  },
  {
    "id": "http://arxiv.org/abs/2505.22399v1",
    "title": "Learning to Pursue AC Optimal Power Flow Solutions with Feasibility Guarantees",
    "authors": [
      "Damola Ajeyemi",
      "Yiting Chen",
      "Antonin Colot",
      "Jorge Cortes",
      "Emiliano Dall'Anese"
    ],
    "abstract": "This paper focuses on an AC optimal power flow (OPF) problem for distribution\nfeeders equipped with controllable distributed energy resources (DERs). We\nconsider a solution method that is based on a continuous approximation of the\nprojected gradient flow - referred to as the safe gradient flow - that\nincorporates voltage and current information obtained either through real-time\nmeasurements or power flow computations. These two setups enable both online\nand offline implementations. The safe gradient flow involves the solution of\nconvex quadratic programs (QPs). To enhance computational efficiency, we\npropose a novel framework that employs a neural network approximation of the\noptimal solution map of the QP. The resulting method has two key features: (a)\nit ensures that the DERs' setpoints are practically feasible, even for an\nonline implementation or when an offline algorithm has an early termination;\n(b) it ensures convergence to a neighborhood of a strict local optimizer of the\nAC OPF. The proposed method is tested on a 93-node distribution system with\nrealistic loads and renewable generation. The test shows that our method\nsuccessfully regulates voltages within limits during periods with high\nrenewable generation.",
    "pdf_url": "http://arxiv.org/pdf/2505.22399v1",
    "published": "2025-05-28T14:26:21+00:00",
    "categories": [
      "math.OC",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2505.22398v2",
    "title": "Numerical Optimization Strategies for the Variational Hamiltonian Ansatz in Noisy Quantum Environments",
    "authors": [
      "S. Ill√©sov√°",
      "V. Nov√°k",
      "T. Bezdƒõk",
      "C. Possel",
      "M. Beseda"
    ],
    "abstract": "We conduct a benchmark of eight optimization algorithms for variational\nquantum chemistry using the tVHA, evaluating performance on $H_2$, $H_4$, and\n$LiH$ (in both full and active spaces) under noiseless and sampling noise\nconditions. Sampling noise fundamentally alters optimizer behavior, with\ngradient-based methods performing best in ideal conditions, while\npopulation-based algorithms, such as CMA-ES, show greater resilience under\nnoise. Hartree-Fock initialization reduces the number of function evaluations\nby 27-60% and consistently yields higher final accuracy compared to random\nstarting points. We identify a precision limit set by sampling noise, with\ndiminishing returns beyond approximately 1000 shots.",
    "pdf_url": "http://arxiv.org/pdf/2505.22398v2",
    "published": "2025-05-28T14:26:04+00:00",
    "categories": [
      "quant-ph",
      "cs.NA",
      "math.NA",
      "65Zxx"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.22397v2",
    "title": "Machine Learning Interatomic Potentials: library for efficient training, model development and simulation of molecular systems",
    "authors": [
      "Christoph Brunken",
      "Olivier Peltre",
      "Heloise Chomet",
      "Lucien Walewski",
      "Manus McAuliffe",
      "Valentin Heyraud",
      "Solal Attias",
      "Martin Maarand",
      "Yessine Khanfir",
      "Edan Toledo",
      "Fabio Falcioni",
      "Marie Bluntzer",
      "Silvia Acosta-Guti√©rrez",
      "Jules Tilly"
    ],
    "abstract": "Machine Learning Interatomic Potentials (MLIP) are a novel in silico approach\nfor molecular property prediction, creating an alternative to disrupt the\naccuracy/speed trade-off of empirical force fields and density functional\ntheory (DFT). In this white paper, we present our MLIP library which was\ncreated with two core aims: (1) provide to industry experts without machine\nlearning background a user-friendly and computationally efficient set of tools\nto experiment with MLIP models, (2) provide machine learning developers a\nframework to develop novel approaches fully integrated with molecular dynamics\ntools. The library includes in this release three model architectures (MACE,\nNequIP, and ViSNet), and two molecular dynamics (MD) wrappers (ASE, and\nJAX-MD), along with a set of pre-trained organics models. The seamless\nintegration with JAX-MD, in particular, facilitates highly efficient MD\nsimulations, bringing MLIP models significantly closer to industrial\napplication. The library is available on GitHub and on PyPI under the Apache\nlicense 2.0.",
    "pdf_url": "http://arxiv.org/pdf/2505.22397v2",
    "published": "2025-05-28T14:24:47+00:00",
    "categories": [
      "physics.chem-ph"
    ],
    "primary_category": "physics.chem-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.22396v1",
    "title": "Zooming from Context to Cue: Hierarchical Preference Optimization for Multi-Image MLLMs",
    "authors": [
      "Xudong Li",
      "Mengdan Zhang",
      "Peixian Chen",
      "Xiawu Zheng",
      "Yan Zhang",
      "Jingyuan Zheng",
      "Yunhang Shen",
      "Ke Li",
      "Chaoyou Fu",
      "Xing Sun",
      "Rongrong Ji"
    ],
    "abstract": "Multi-modal Large Language Models (MLLMs) excel at single-image tasks but\nstruggle with multi-image understanding due to cross-modal misalignment,\nleading to hallucinations (context omission, conflation, and\nmisinterpretation). Existing methods using Direct Preference Optimization (DPO)\nconstrain optimization to a solitary image reference within the input sequence,\nneglecting holistic context modeling. We propose Context-to-Cue Direct\nPreference Optimization (CcDPO), a multi-level preference optimization\nframework that enhances per-image perception in multi-image settings by zooming\ninto visual clues -- from sequential context to local details. It features: (i)\nContext-Level Optimization : Re-evaluates cognitive biases underlying MLLMs'\nmulti-image context comprehension and integrates a spectrum of low-cost global\nsequence preferences for bias mitigation. (ii) Needle-Level Optimization :\nDirects attention to fine-grained visual details through region-targeted visual\nprompts and multimodal preference supervision. To support scalable\noptimization, we also construct MultiScope-42k, an automatically generated\ndataset with high-quality multi-level preference pairs. Experiments show that\nCcDPO significantly reduces hallucinations and yields consistent performance\ngains across general single- and multi-image tasks.",
    "pdf_url": "http://arxiv.org/pdf/2505.22396v1",
    "published": "2025-05-28T14:24:02+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.22395v1",
    "title": "Configuration-dependent precision in magnetometry and thermometry using multi-qubit quantum sensors",
    "authors": [
      "Asghar Ullah",
      "√ñzg√ºr E. M√ºstecaplƒ±oƒülu",
      "Matteo G. A. Paris"
    ],
    "abstract": "We study the performance of quantum sensors composed of four qubits arranged\nin different geometries for magnetometry and thermometry. The qubits interact\nvia the transverse-field Ising model with both ferromagnetic and\nantiferromagnetic couplings, maintained in thermal equilibrium with a heat bath\nunder an external magnetic field. Using quantum Fisher information (QFI), we\nevaluate the metrological precision of these sensors. For ferromagnetic\ncouplings, weakly connected graphs (e.g., the chain graph, P_4) perform\noptimally in estimating weak magnetic fields, whereas highly connected graphs\n(e.g., the complete graph, K_4) excel at strong fields. Conversely, K_4\nachieves the highest sensitivity for temperature estimation in the weak-field\nregime. In the antiferromagnetic case, we uncover a fundamental trade-off\ndictated by spectral degeneracy: configurations with non-degenerate energy\nspectra - such as the pan-like graph (three qubits in a triangle with the\nfourth attached) - exhibit strong magnetic field sensitivity due to their\npronounced response to perturbations. In contrast, symmetric structures like\nthe square graph, featuring degenerate energy levels (particularly ground-state\ndegeneracy), are better suited for precise thermometry. Notably, our four-qubit\nsensors achieve peak precision in the low-temperature, weak-field regime.\nFinally, we introduce a spectral sensitivity measure that quantifies energy\nspectrum deformations under small perturbations, offering a tool to optimize\nmagnetometric performance.",
    "pdf_url": "http://arxiv.org/pdf/2505.22395v1",
    "published": "2025-05-28T14:23:51+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.22394v1",
    "title": "PacTure: Efficient PBR Texture Generation on Packed Views with Visual Autoregressive Models",
    "authors": [
      "Fan Fei",
      "Jiajun Tang",
      "Fei-Peng Tian",
      "Boxin Shi",
      "Ping Tan"
    ],
    "abstract": "We present PacTure, a novel framework for generating physically-based\nrendering (PBR) material textures from an untextured 3D mesh, a text\ndescription, and an optional image prompt. Early 2D generation-based texturing\napproaches generate textures sequentially from different views, resulting in\nlong inference times and globally inconsistent textures. More recent approaches\nadopt multi-view generation with cross-view attention to enhance global\nconsistency, which, however, limits the resolution for each view. In response\nto these weaknesses, we first introduce view packing, a novel technique that\nsignificantly increases the effective resolution for each view during\nmulti-view generation without imposing additional inference cost, by\nformulating the arrangement of multi-view maps as a 2D rectangle bin packing\nproblem. In contrast to UV mapping, it preserves the spatial proximity\nessential for image generation and maintains full compatibility with current 2D\ngenerative models. To further reduce the inference cost, we enable fine-grained\ncontrol and multi-domain generation within the next-scale prediction\nautoregressive framework to create an efficient multi-view multi-domain\ngenerative backbone. Extensive experiments show that PacTure outperforms\nstate-of-the-art methods in both quality of generated PBR textures and\nefficiency in training and inference.",
    "pdf_url": "http://arxiv.org/pdf/2505.22394v1",
    "published": "2025-05-28T14:23:30+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.22393v1",
    "title": "Exploring Charm Bound States: Mass Spectra and Decay Dynamics of D Mesons and $Cq\\bar{q}\\bar{q}$ Tetraquarks",
    "authors": [
      "Chetan lodha",
      "Manak Parmar",
      "Ajay Kumar Rai"
    ],
    "abstract": "Motivated by the discovery of several charm states exhibiting tetraquark-like\ncharacteristics at BESIII and LHCb, this study investigates the spectroscopy\nand decay properties of D mesons and tetraquark states with quark content\n$Cq\\bar{q}\\bar{q}$ within the diquark - antidiquark framework. The analysis is\nperformed using a potential model based on the Cornell potential, considering\ncolor antitriplet - triplet configurations. Mass spectra are computed for both\nmesons and tetraquarks, while their decay behaviors are examined using the\nfactorization approach for D mesons and Fierz rearrangement for tetraquark\ndecays. Theoretical results are compared with experimentally observed\nresonances to improve our understanding of charm quark bound systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.22393v1",
    "published": "2025-05-28T14:21:42+00:00",
    "categories": [
      "hep-ph"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.22392v1",
    "title": "Weak valley-layer coupling and valley polarization in centrosymmetric $\\mathrm{FeCl_2}$ monolayer",
    "authors": [
      "San-Dong Guo",
      "Liguo Zhang",
      "Xiao-Shu Guo",
      "Gangqiang Zhu"
    ],
    "abstract": "Using the valley degree of freedom as a carrier of information for storage\nand processing, valley polarization plays a crucial role. A variety of\nmechanisms for valley polarization have been proposed, among which the\nvalley-layer coupling mechanism involves the induction of valley polarization\nby an out-of-plane electric field. Here, through first-principles calculations,\nit is found that the weak valley-layer coupling can exist in centrosymmetric\n$\\mathrm{FeCl_2}$ monolayer. It is crucial to note that valley-layer coupling\nonly occurs with out-of-plane magnetization and vanishes with in-plane\nmagnetization. Compared to monolayers with strong valley-layer coupling,\n$\\mathrm{FeCl_2}$ requires an extremely strong electric field to achieve the\nsame magnitude of valley splitting. Valley polarization switching can be\nachieved by manipulating the directions of magnetization and electric field.\nReversing only one of these directions switches the valley polarization,\nwhereas reversing both simultaneously leaves it unchanged. Moreover, the simply\nstacked bilayer $\\mathrm{FeCl_2}$, as a $PT$-antiferromagnet, can spontaneously\nachieve valley polarization without an external electric field, highlighting\nits potential for miniaturization, ultradensity, and ultrafast performance. Our\nwork provides guidelines for identifying materials with weak valley-layer\ncoupling, and further enables the regulation of valley polarization through\nelectric field and stacking engineering.",
    "pdf_url": "http://arxiv.org/pdf/2505.22392v1",
    "published": "2025-05-28T14:18:31+00:00",
    "categories": [
      "cond-mat.mtrl-sci",
      "cond-mat.mes-hall"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2505.22391v1",
    "title": "Physics-Informed Distillation of Diffusion Models for PDE-Constrained Generation",
    "authors": [
      "Yi Zhang",
      "Difan Zou"
    ],
    "abstract": "Modeling physical systems in a generative manner offers several advantages,\nincluding the ability to handle partial observations, generate diverse\nsolutions, and address both forward and inverse problems. Recently, diffusion\nmodels have gained increasing attention in the modeling of physical systems,\nparticularly those governed by partial differential equations (PDEs). However,\ndiffusion models only access noisy data $\\boldsymbol{x}_t$ at intermediate\nsteps, making it infeasible to directly enforce constraints on the clean sample\n$\\boldsymbol{x}_0$ at each noisy level. As a workaround, constraints are\ntypically applied to the expectation of clean samples\n$\\mathbb{E}[\\boldsymbol{x}_0|\\boldsymbol{x}_t]$, which is estimated using the\nlearned score network. However, imposing PDE constraints on the expectation\ndoes not strictly represent the one on the true clean data, known as Jensen's\nGap. This gap creates a trade-off: enforcing PDE constraints may come at the\ncost of reduced accuracy in generative modeling. To address this, we propose a\nsimple yet effective post-hoc distillation approach, where PDE constraints are\nnot injected directly into the diffusion process, but instead enforced during a\npost-hoc distillation stage. We term our method as Physics-Informed\nDistillation of Diffusion Models (PIDDM). This distillation not only\nfacilitates single-step generation with improved PDE satisfaction, but also\nsupport both forward and inverse problem solving and reconstruction from\nrandomly partial observation. Extensive experiments across various PDE\nbenchmarks demonstrate that PIDDM significantly improves PDE satisfaction over\nseveral recent and competitive baselines, such as PIDM, DiffusionPDE, and\nECI-sampling, with less computation overhead. Our approach can shed light on\nmore efficient and effective strategies for incorporating physical constraints\ninto diffusion models.",
    "pdf_url": "http://arxiv.org/pdf/2505.22391v1",
    "published": "2025-05-28T14:17:58+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CE",
      "cs.NA",
      "math.NA"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.22390v1",
    "title": "Calibrating quantum gates up to 52 qubits in a superconducting processor",
    "authors": [
      "Daojin Fan",
      "Guoding Liu",
      "Shaowei Li",
      "Ming Gong",
      "Dachao Wu",
      "Yiming Zhang",
      "Chen Zha",
      "Fusheng Chen",
      "Sirui Cao",
      "Yangsen Ye",
      "Qingling Zhu",
      "Chong Ying",
      "Shaojun Guo",
      "Haoran Qian",
      "Yulin Wu",
      "Hui Deng",
      "Gang Wu",
      "Cheng-Zhi Peng",
      "Xiongfeng Ma",
      "Xiaobo Zhu",
      "Jian-Wei Pan"
    ],
    "abstract": "Benchmarking large-scale quantum gates, typically involving multiple native\ntwo-qubit and singlequbit gates, is crucial in quantum computing. Global\nfidelity, encompassing information about intergate correlations, offers a\ncomprehensive metric for evaluating and optimizing gate performance, unlike the\nfidelities of individual local native gates. In this work, utilizing the\ncharacter-average benchmarking protocol implementable in a shallow circuit, we\nsuccessfully benchmark gate fidelities up to 52 qubits. Notably, we achieved a\nfidelity of 63.09$\\pm $0.23% for a 44-qubit parallel CZ gate. Utilizing the\nglobal fidelity of the parallel CZ gate, we explore the correlations among\nlocal CZ gates by introducing an inter-gate correlation metric, enabling one to\nsimultaneously quantify crosstalk error when benchmarking gate fidelity.\nFinally, we apply our methods in gate optimization. By leveraging global\nfidelity for optimization, we enhance the fidelity of a 6-qubit parallel CZ\ngate from 87.65% to 92.04% and decrease the gate correlation from 3.53% to\n3.22%, compared to local gate fidelitybased optimization. The experimental\nresults align well with our established composite noise model, incorporating\ndepolarizing and ZZ-coupling noises, and provide valuable insight into further\nstudy and mitigation of correlated noise.",
    "pdf_url": "http://arxiv.org/pdf/2505.22390v1",
    "published": "2025-05-28T14:17:00+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.22389v3",
    "title": "Train with Perturbation, Infer after Merging: A Two-Stage Framework for Continual Learning",
    "authors": [
      "Haomiao Qiu",
      "Miao Zhang",
      "Ziyue Qiao",
      "Liqiang Nie"
    ],
    "abstract": "Continual Learning (CL) aims to enable models to continuously acquire new\nknowledge from a sequence of tasks with avoiding the forgetting of learned\ninformation. However, existing CL methods only rely on the parameters of the\nmost recent task for inference, which makes them susceptible to catastrophic\nforgetting. Inspired by the recent success of model merging techniques, we\npropose \\textbf{Perturb-and-Merge (P\\&M)}, a novel continual learning framework\nthat integrates model merging into the CL paradigm to mitigate forgetting.\nSpecifically, after training on each task, P\\&M constructs a new model by\nforming a convex combination of the previous model and the newly trained\ntask-specific model. Through theoretical analysis, we minimize the total loss\nincrease across all tasks and derive an analytical solution for the optimal\nmerging coefficient. To further improve the performance of the merged model, we\nobserve that the degradation introduced during merging can be alleviated by a\nregularization term composed of the task vector and the Hessian matrix of the\nloss function. Interestingly, we show that this term can be efficiently\napproximated using second-order symmetric finite differences, and a stochastic\nperturbation strategy along the task vector direction is accordingly devised\nwhich incurs no additional forward or backward passes while providing an\neffective approximation of the regularization term. Finally, we combine P\\&M\nwith LoRA, a parameter-efficient fine-tuning method, to reduce memory overhead.\nOur proposed approach achieves state-of-the-art performance on several\ncontinual learning benchmark datasets.",
    "pdf_url": "http://arxiv.org/pdf/2505.22389v3",
    "published": "2025-05-28T14:14:19+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.22388v1",
    "title": "A Synthetic Business Cycle Approach to Counterfactual Analysis with Nonstationary Macroeconomic Data",
    "authors": [
      "Zhentao Shi",
      "Jin Xi",
      "Haitian Xie"
    ],
    "abstract": "This paper investigates the use of synthetic control methods for causal\ninference in macroeconomic settings when dealing with possibly nonstationary\ndata. While the synthetic control approach has gained popularity for estimating\ncounterfactual outcomes, we caution researchers against assuming a common\nnonstationary trend factor across units for macroeconomic outcomes, as doing so\nmay result in misleading causal estimation-a pitfall we refer to as the\nspurious synthetic control problem. To address this issue, we propose a\nsynthetic business cycle framework that explicitly separates trend and cyclical\ncomponents. By leveraging the treated unit's historical data to forecast its\ntrend and using control units only for cyclical fluctuations, our\ndivide-and-conquer strategy eliminates spurious correlations and improves the\nrobustness of counterfactual prediction in macroeconomic applications. As\nempirical illustrations, we examine the cases of German reunification and the\nhandover of Hong Kong, demonstrating the advantages of the proposed approach.",
    "pdf_url": "http://arxiv.org/pdf/2505.22388v1",
    "published": "2025-05-28T14:14:14+00:00",
    "categories": [
      "econ.EM"
    ],
    "primary_category": "econ.EM"
  },
  {
    "id": "http://arxiv.org/abs/2505.22387v1",
    "title": "DAM: Domain-Aware Module for Multi-Domain Dataset Condensation",
    "authors": [
      "Jaehyun Choi",
      "Gyojin Han",
      "Dong-Jae Lee",
      "Sunghyun Baek",
      "Junmo Kim"
    ],
    "abstract": "Dataset Condensation (DC) has emerged as a promising solution to mitigate the\ncomputational and storage burdens associated with training deep learning\nmodels. However, existing DC methods largely overlook the multi-domain nature\nof modern datasets, which are increasingly composed of heterogeneous images\nspanning multiple domains. In this paper, we extend DC and introduce\nMulti-Domain Dataset Condensation (MDDC), which aims to condense data that\ngeneralizes across both single-domain and multi-domain settings. To this end,\nwe propose the Domain-Aware Module (DAM), a training-time module that embeds\ndomain-related features into each synthetic image via learnable spatial masks.\nAs explicit domain labels are mostly unavailable in real-world datasets, we\nemploy frequency-based pseudo-domain labeling, which leverages low-frequency\namplitude statistics. DAM is only active during the condensation process, thus\npreserving the same images per class (IPC) with prior methods. Experiments show\nthat DAM consistently improves in-domain, out-of-domain, and cross-architecture\nperformance over baseline dataset condensation methods.",
    "pdf_url": "http://arxiv.org/pdf/2505.22387v1",
    "published": "2025-05-28T14:13:38+00:00",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.22386v1",
    "title": "Ensemble Modeling of the Solar Wind Flow with Boundary Conditions Governed by Synchronic Photospheric Magnetograms. I. Multi-point Validation in the Inner Heliosphere",
    "authors": [
      "Dinesha V. Hegde",
      "Tae K. Kim",
      "Nikolai V. Pogorelov",
      "Shaela I. Jones",
      "Charles N. Arge"
    ],
    "abstract": "The solar wind (SW) is a vital component of space weather, providing a\nbackground for solar transients such as coronal mass ejections, stream\ninteraction regions, and energetic particles propagating toward Earth. Accurate\nprediction of space weather events requires a precise description and thorough\nunderstanding of physical processes occurring in the ambient SW plasma.\nEnsemble simulations of the three-dimensional SW flow are performed using an\nempirically-driven magnetohydrodynamic heliosphere model implemented in the\nMulti-Scale Fluid-Kinetic Simulation Suite (MS-FLUKSS). The effect of\nuncertainties in the photospheric boundary conditions on the simulation outcome\nis investigated. The results are in good overall agreement with the\nobservations from the Parker Solar Probe, Solar Orbiter, Solar Terrestrial\nRelations Observatory, and OMNI data at Earth, specifically during 2020-2021.\nThis makes it possible to shed more light on the properties of the SW\npropagating through the heliosphere and perspectives for improving space\nweather forecasts.",
    "pdf_url": "http://arxiv.org/pdf/2505.22386v1",
    "published": "2025-05-28T14:13:09+00:00",
    "categories": [
      "astro-ph.SR",
      "physics.comp-ph",
      "physics.space-ph"
    ],
    "primary_category": "astro-ph.SR"
  },
  {
    "id": "http://arxiv.org/abs/2505.22385v1",
    "title": "Does the Forced Van der Pol Oscillator Exhibit Irregular Behavior?",
    "authors": [
      "Samaira Tibrewal",
      "Soumyajit Seth"
    ],
    "abstract": "Nonlinear oscillators are commonly encountered in a wide range of physical\nand engineering systems, exhibiting rich and complex dynamics. Among these, the\nVan der Pol oscillator is well known for its self-sustained limit cycle\nbehavior. However, when subjected to external sinusoidal forcing, its dynamics\ncan deviate significantly from this regular behavior. This study explores the\nemergence of complex dynamical regimes in the sinusoidally forced Van der Pol\noscillator, focusing on identifying the transition from regular to aperiodic\nbehavior. The primary research objective is to determine whether the system\nexhibits irregular dynamics such as quasi-periodicity or chaos and to identify\nthe conditions under which these arise. We hypothesize that varying the\namplitude and frequency ratio of the external forcing relative to the natural\nfrequency of the oscillator can induce a spectrum of dynamical responses,\nincluding higher-order periodic and chaotic regimes. We perform numerical\nsimulations using Python and examine the behavior of the system through time\nseries analysis, phase portraits, and bifurcation diagrams to test this. The\nresults demonstrate that as the forcing amplitude and frequency ratio are\nvaried, the system undergoes transitions through periodic, quasi-periodic, and\nchaotic states. These findings highlight the complex nonlinear interactions in\nforced oscillatory systems and have significant implications for applications\nin biological rhythms, electronic circuits, and astrophysical phenomena.",
    "pdf_url": "http://arxiv.org/pdf/2505.22385v1",
    "published": "2025-05-28T14:12:38+00:00",
    "categories": [
      "nlin.CD",
      "physics.comp-ph"
    ],
    "primary_category": "nlin.CD"
  },
  {
    "id": "http://arxiv.org/abs/2505.22384v1",
    "title": "Exact Algorithms and Lower Bounds for Forming Coalitions of Constrained Maximum Size",
    "authors": [
      "Foivos Fioravantes",
      "Harmender Gahlawat",
      "Nikolaos Melissinos"
    ],
    "abstract": "Imagine we want to split a group of agents into teams in the most\n\\emph{efficient} way, considering that each agent has their own preferences\nabout their teammates. This scenario is modeled by the extensively studied\n\\textsc{Coalition Formation} problem. Here, we study a version of this problem\nwhere each team must additionally be of bounded size.\n  We conduct a systematic algorithmic study, providing several intractability\nresults as well as multiple exact algorithms that scale well as the input grows\n(FPT), which could prove useful in practice.\n  Our main contribution is an algorithm that deals efficiently with tree-like\nstructures (bounded \\emph{treewidth}) for ``small'' teams. We complement this\nresult by proving that our algorithm is asymptotically optimal. Particularly,\nthere can be no algorithm that vastly outperforms the one we present, under\nreasonable theoretical assumptions, even when considering star-like structures\n(bounded \\emph{vertex cover number}).",
    "pdf_url": "http://arxiv.org/pdf/2505.22384v1",
    "published": "2025-05-28T14:11:14+00:00",
    "categories": [
      "cs.DS",
      "cs.AI"
    ],
    "primary_category": "cs.DS"
  },
  {
    "id": "http://arxiv.org/abs/2505.22383v1",
    "title": "Hyperbolic polytrope",
    "authors": [
      "M. Carrasco-H",
      "E. Contreras",
      "E. Fuenmayor",
      "P. Le√≥n"
    ],
    "abstract": "In this work, we study self-gravitating objects that obey a polytropic\nequation of state in hyperbolic symmetry. Specifically, we describe in detail\nthe steps to derive the Lane-Emden equation from the structure equations of the\nsystem. To integrate the equations numerically, we propose the\nCosenza-Herrera-Esculpi-Witten anisotropy and study the cases $\\gamma \\ne 1$\nand $\\gamma = 1$ in the parameter space of the models. We find that the matter\nsector exhibits the usual and expected behavior for certain values in this\nparameter space: energy density (in absolute value) and radial pressure are\ndecreasing functions and vanish at the surface, while the mass function is\nincreasing toward the surface. We find that the anisotropy of the system is\npositive and decreasing, consistent with the behavior of the radial pressure,\nwhich reaches a local minimum at the surface (i.e., the pressure gradient is\nzero at the surface). We also study the compactness of the dense objects as a\nfunction of the polytropic index and obtain that it has an upper bound given by\nthe maximum value it reaches for a certain $n$. Some extensions of the work and\nfuture proposals are discussed.",
    "pdf_url": "http://arxiv.org/pdf/2505.22383v1",
    "published": "2025-05-28T14:10:03+00:00",
    "categories": [
      "gr-qc"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2505.22382v1",
    "title": "Fast evaluation of Riemann theta functions in any dimension",
    "authors": [
      "Noam D. Elkies",
      "Jean Kieffer"
    ],
    "abstract": "We describe an algorithm to numerically evaluate Riemann theta functions in\nany dimension in quasi-linear time in terms of the required precision,\nuniformly on reduced input. This algorithm is implemented in the FLINT number\ntheory library and vastly outperforms existing software.",
    "pdf_url": "http://arxiv.org/pdf/2505.22382v1",
    "published": "2025-05-28T14:09:57+00:00",
    "categories": [
      "math.NT",
      "cs.NA",
      "math.AG",
      "math.NA"
    ],
    "primary_category": "math.NT"
  },
  {
    "id": "http://arxiv.org/abs/2505.22381v1",
    "title": "A Divide-and-Conquer Approach for Modeling Arrival Times in Business Process Simulation",
    "authors": [
      "Lukas Kirchdorfer",
      "Konrad √ñzdemir",
      "Stjepan Kusenic",
      "Han van der Aa",
      "Heiner Stuckenschmidt"
    ],
    "abstract": "Business Process Simulation (BPS) is a critical tool for analyzing and\nimproving organizational processes by estimating the impact of process changes.\nA key component of BPS is the case-arrival model, which determines the pattern\nof new case entries into a process. Although accurate case-arrival modeling is\nessential for reliable simulations, as it influences waiting and overall cycle\ntimes, existing approaches often rely on oversimplified static distributions of\ninter-arrival times. These approaches fail to capture the dynamic and temporal\ncomplexities inherent in organizational environments, leading to less accurate\nand reliable outcomes. To address this limitation, we propose Auto Time Kernel\nDensity Estimation (AT-KDE), a divide-and-conquer approach that models arrival\ntimes of processes by incorporating global dynamics, day-of-week variations,\nand intraday distributional changes, ensuring both precision and scalability.\nExperiments conducted across 20 diverse processes demonstrate that AT-KDE is\nfar more accurate and robust than existing approaches while maintaining\nsensible execution time efficiency.",
    "pdf_url": "http://arxiv.org/pdf/2505.22381v1",
    "published": "2025-05-28T14:09:51+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.03168v1",
    "title": "Farm-LightSeek: An Edge-centric Multimodal Agricultural IoT Data Analytics Framework with Lightweight LLMs",
    "authors": [
      "Dawen Jiang",
      "Zhishu Shen",
      "Qiushi Zheng",
      "Tiehua Zhang",
      "Wei Xiang",
      "Jiong Jin"
    ],
    "abstract": "Amid the challenges posed by global population growth and climate change,\ntraditional agricultural Internet of Things (IoT) systems is currently\nundergoing a significant digital transformation to facilitate efficient big\ndata processing. While smart agriculture utilizes artificial intelligence (AI)\ntechnologies to enable precise control, it still encounters significant\nchallenges, including excessive reliance on agricultural expert knowledge,\ndifficulties in fusing multimodal data, poor adaptability to dynamic\nenvironments, and bottlenecks in real-time decision-making at the edge. Large\nlanguage models (LLMs), with their exceptional capabilities in knowledge\nacquisition and semantic understanding, provide a promising solution to address\nthese challenges. To this end, we propose Farm-LightSeek, an edge-centric\nmultimodal agricultural IoT data analytics framework that integrates LLMs with\nedge computing. This framework collects real-time farmland multi-source data\n(images, weather, geographic information) via sensors, performs cross-modal\nreasoning and disease detection at edge nodes, conducts low-latency management\ndecisions, and enables cloud collaboration for model updates. The main\ninnovations of Farm-LightSeek include: (1) an agricultural\n\"perception-decision-action\" closed-loop architecture; (2) cross-modal adaptive\nmonitoring; and (3)a lightweight LLM deployment strategy balancing performance\nand efficiency. Experiments conducted on two real-world datasets demonstrate\nthat Farm-LightSeek consistently achieves reliable performance in\nmission-critical tasks, even under the limitations of edge computing resources.\nThis work advances intelligent real-time agricultural solutions and highlights\nthe potential for deeper integration of agricultural IoT with LLMs.",
    "pdf_url": "http://arxiv.org/pdf/2506.03168v1",
    "published": "2025-05-28T14:09:36+00:00",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.22380v1",
    "title": "Intrinsic enumerative mirror symmetry: Takahashi's log mirror symmetry for $(\\mathbb{P}^2,E)$ revisited",
    "authors": [
      "Michel van Garrel",
      "Helge Ruddat",
      "Bernd Siebert"
    ],
    "abstract": "Let $E$ be a smooth cubic in the projective plane $\\mathbb{P}^2$. Nobuyoshi\nTakahashi formulated a conjecture that expresses counts of rational curves of\nvarying degree in $\\mathbb{P}^2\\setminus E$ as the Taylor coefficients of a\nparticular period integral of a pencil of affine plane cubics after\nreparametrizing the pencil using the exponential of a second period integral.\n  The intrinsic mirror construction introduced by Mark Gross and the third\nauthor associates to a degeneration of $(\\mathbb{P}^2, E)$ a canonical wall\nstructure from which one constructs a family of projective plane cubics that is\nbirational to Takahashi's pencil in its reparametrized form. By computing the\nperiod integral of the positive real locus explicitly, we find that it equals\nthe logarithm of the product of all asymptotic wall functions. The coefficients\nof these asymptotic wall functions are logarithmic Gromov-Witten counts of the\ncentral fiber of the degeneration that agree with the algebraic curve counts in\n$(\\mathbb{P}^2,E)$ in question. We conclude that Takahashi's conjecture is a\nnatural consequence of intrinsic mirror symmetry. Our method generalizes to\ngive similar results for log Calabi-Yau varieties of arbitrary dimension.",
    "pdf_url": "http://arxiv.org/pdf/2505.22380v1",
    "published": "2025-05-28T14:08:32+00:00",
    "categories": [
      "math.AG",
      "14J33, 14N35"
    ],
    "primary_category": "math.AG"
  },
  {
    "id": "http://arxiv.org/abs/2505.22379v1",
    "title": "Dynamics of thin film flows on a vertical fibre with vapor absorption",
    "authors": [
      "Souradip Chattopadhyay",
      "Zihao Yu",
      "Y. Sungtaek Ju",
      "Hangjie Ji"
    ],
    "abstract": "Water vapor capture through free surface flows plays a crucial role in\nvarious industrial applications, such as liquid desiccant air conditioning\nsystems, water harvesting, and dewatering. This paper studies the dynamics of a\nsilicone liquid sorbent (also known as water-absorbing silicone oil) flowing\ndown a vertical cylindrical fibre while absorbing water vapor. We propose a\none-sided thin-film-type model for these dynamics, where the governing\nequations form a coupled system of nonlinear fourth-order partial differential\nequations for the liquid film thickness and oil concentration. The model\nincorporates gravity, surface tension, Marangoni effects induced by\nconcentration gradients, and non-mass-conserving effects due to absorption\nflux. Interfacial instabilities, driven by the competition between\nmass-conserving and non-mass-conserving effects, are investigated via stability\nanalysis. We numerically show that water absorption can lead to the formation\nof irregular wavy patterns and trigger droplet coalescence downstream.\nSystematic simulations further identify parameter ranges for the Marangoni\nnumber and absorption parameter that lead to the onset of droplet coalescence\ndynamics and regime transitions.",
    "pdf_url": "http://arxiv.org/pdf/2505.22379v1",
    "published": "2025-05-28T14:07:56+00:00",
    "categories": [
      "physics.flu-dyn"
    ],
    "primary_category": "physics.flu-dyn"
  },
  {
    "id": "http://arxiv.org/abs/2505.22378v2",
    "title": "Current trends and future directions in event-based control",
    "authors": [
      "Michael Hertneck",
      "David Meister",
      "Frank Allg√∂wer"
    ],
    "abstract": "The defining characteristic of event-based control is that feedback loops are\nonly closed when indicated by a triggering condition that takes recent\ninformation about the system into account. This stands in contrast to periodic\ncontrol where the feedback loop is closed periodically. Benefits of event-based\ncontrol arise when sampling comes at a cost, which occurs, e.g., for Networked\nControl Systems or in other setups with resource constraints. A rapidly growing\nnumber of publications deals with event-based control. Nevertheless, some\nfundamental questions about event-based control are still unsolved. In this\narticle, we provide an overview of current research trends in event-based\ncontrol. We focus on results that aim for a better understanding of effects\nthat occur in feedback loops with event-based control. Based on this summary,\nwe identify important open directions for future research.",
    "pdf_url": "http://arxiv.org/pdf/2505.22378v2",
    "published": "2025-05-28T14:06:32+00:00",
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2505.22377v1",
    "title": "Multiprecision computing for multistage fractional physics-informed neural networks",
    "authors": [
      "Na Xue",
      "Minghua Chen"
    ],
    "abstract": "Fractional physics-informed neural networks (fPINNs) have been successfully\nintroduced in [Pang, Lu and Karniadakis, SIAM J. Sci. Comput. 41 (2019)\nA2603-A2626], which observe relative errors of $10^{-3} \\, \\sim \\, 10^{-4}$ for\nthe subdiffusion equations. However their high-precision (multiprecision)\nnumerical solution remains challenging, due to the limited regularity of the\nsubdiffusion model caused by the nonlocal operator. To fill in the gap, we\npresent the multistage fPINNs based on traditional multistage PINNs [Wang and\nLai, J. Comput. Phys. 504 (2024) 112865]. Numerical experiments show that the\nrelative errors improve to $10^{-7} \\, \\sim \\, 10^{-8}$ for the subdiffusion\nequations on uniform or nouniform meshes.",
    "pdf_url": "http://arxiv.org/pdf/2505.22377v1",
    "published": "2025-05-28T14:06:11+00:00",
    "categories": [
      "math.NA",
      "cs.NA"
    ],
    "primary_category": "math.NA"
  },
  {
    "id": "http://arxiv.org/abs/2505.23840v3",
    "title": "Measuring Sycophancy of Language Models in Multi-turn Dialogues",
    "authors": [
      "Jiseung Hong",
      "Grace Byun",
      "Seungone Kim",
      "Kai Shu",
      "Jinho D. Choi"
    ],
    "abstract": "Large Language Models (LLMs) are expected to provide helpful and harmless\nresponses, yet they often exhibit sycophancy--conforming to user beliefs\nregardless of factual accuracy or ethical soundness. Prior research on\nsycophancy has primarily focused on single-turn factual correctness,\noverlooking the dynamics of real-world interactions. In this work, we introduce\nSYCON Bench, a novel benchmark for evaluating sycophantic behavior in\nmulti-turn, free-form conversational settings. Our benchmark measures how\nquickly a model conforms to the user (Turn of Flip) and how frequently it\nshifts its stance under sustained user pressure (Number of Flip). Applying\nSYCON Bench to 17 LLMs across three real-world scenarios, we find that\nsycophancy remains a prevalent failure mode. Our analysis shows that alignment\ntuning amplifies sycophantic behavior, whereas model scaling and reasoning\noptimization strengthen the model's ability to resist undesirable user views.\nReasoning models generally outperform instruction-tuned models but often fail\nwhen they over-index on logical exposition instead of directly addressing the\nuser's underlying beliefs. Finally, we evaluate four additional prompting\nstrategies and demonstrate that adopting a third-person perspective reduces\nsycophancy by up to 63.8% in debate scenario. We release our code and data at\nhttps://github.com/JiseungHong/SYCON-Bench.",
    "pdf_url": "http://arxiv.org/pdf/2505.23840v3",
    "published": "2025-05-28T14:05:46+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.22376v1",
    "title": "Functoriality of the Klein-Williams Invariant and Universality Theory",
    "authors": [
      "Ba≈üak K√º√ß√ºk"
    ],
    "abstract": "Both the Klein-Williams invariant $\\ell_G(f)$ from \\cite{KW2} and the\ngeneralized equivariant Lefschetz invariant $\\lambda_G(f)$ from \\cite{weber07}\nserve as complete obstructions to the fixed point problem in the equivariant\nsetting. The latter is functorial in the sense of Definition \\ref{functorial}.\nThe first part of this paper aims to demonstrate that $\\ell_G(f)$ is also\nfunctorial. The second part summarizes the ``universality\" theory of such\nfunctorial invariants, developed in \\cites{lueck1999, Weber06}, and explicitly\ncomputes the group in which the universal invariant lies, under a certain\nhypothesis. The final part explores the relationship between $\\ell_G(f)$ and\n$\\lambda_G(f)$, and presents examples to compare $\\ell_G(f)$, $\\lambda_G(f)$,\nand the universal invariant.",
    "pdf_url": "http://arxiv.org/pdf/2505.22376v1",
    "published": "2025-05-28T14:03:22+00:00",
    "categories": [
      "math.AT"
    ],
    "primary_category": "math.AT"
  },
  {
    "id": "http://arxiv.org/abs/2505.22375v2",
    "title": "Pangu Embedded: An Efficient Dual-system LLM Reasoner with Metacognition",
    "authors": [
      "Hanting Chen",
      "Yasheng Wang",
      "Kai Han",
      "Dong Li",
      "Lin Li",
      "Zhenni Bi",
      "Jinpeng Li",
      "Haoyu Wang",
      "Fei Mi",
      "Mingjian Zhu",
      "Bin Wang",
      "Kaikai Song",
      "Yifei Fu",
      "Xu He",
      "Yu Luo",
      "Chong Zhu",
      "Quan He",
      "Xueyu Wu",
      "Wei He",
      "Hailin Hu",
      "Yehui Tang",
      "Dacheng Tao",
      "Xinghao Chen",
      "Yunhe Wang"
    ],
    "abstract": "This work presents Pangu Embedded, an efficient Large Language Model (LLM)\nreasoner developed on Ascend Neural Processing Units (NPUs), featuring flexible\nfast and slow thinking capabilities. Pangu Embedded addresses the significant\ncomputational costs and inference latency challenges prevalent in existing\nreasoning-optimized LLMs. We propose a two-stage training framework for its\nconstruction. In Stage 1, the model is finetuned via an iterative distillation\nprocess, incorporating inter-iteration model merging to effectively aggregate\ncomplementary knowledge. This is followed by reinforcement learning on Ascend\nclusters, optimized by a latency-tolerant scheduler that combines stale\nsynchronous parallelism with prioritized data queues. The RL process is guided\nby a Multi-source Adaptive Reward System (MARS), which generates dynamic,\ntask-specific reward signals using deterministic metrics and lightweight LLM\nevaluators for mathematics, coding, and general problem-solving tasks. Stage 2\nintroduces a dual-system framework, endowing Pangu Embedded with a \"fast\" mode\nfor routine queries and a deeper \"slow\" mode for complex inference. This\nframework offers both manual mode switching for user control and an automatic,\ncomplexity-aware mode selection mechanism that dynamically allocates\ncomputational resources to balance latency and reasoning depth. Experimental\nresults on benchmarks including AIME 2024, GPQA, and LiveCodeBench demonstrate\nthat Pangu Embedded with 7B parameters, outperforms similar-size models like\nQwen3-8B and GLM4-9B. It delivers rapid responses and state-of-the-art\nreasoning quality within a single, unified model architecture, highlighting a\npromising direction for developing powerful yet practically deployable LLM\nreasoners.",
    "pdf_url": "http://arxiv.org/pdf/2505.22375v2",
    "published": "2025-05-28T14:03:02+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.05369v1",
    "title": "MR.NAVI: Mixed-Reality Navigation Assistant for the Visually Impaired",
    "authors": [
      "Nicolas Pfitzer",
      "Yifan Zhou",
      "Marco Poggensee",
      "Defne Kurtulus",
      "Bessie Dominguez-Dager",
      "Mihai Dusmanu",
      "Marc Pollefeys",
      "Zuria Bauer"
    ],
    "abstract": "Over 43 million people worldwide live with severe visual impairment, facing\nsignificant challenges in navigating unfamiliar environments. We present\nMR.NAVI, a mixed reality system that enhances spatial awareness for visually\nimpaired users through real-time scene understanding and intuitive audio\nfeedback. Our system combines computer vision algorithms for object detection\nand depth estimation with natural language processing to provide contextual\nscene descriptions, proactive collision avoidance, and navigation instructions.\nThe distributed architecture processes sensor data through MobileNet for object\ndetection and employs RANSAC-based floor detection with DBSCAN clustering for\nobstacle avoidance. Integration with public transit APIs enables navigation\nwith public transportation directions. Through our experiments with user\nstudies, we evaluated both scene description and navigation functionalities in\nunfamiliar environments, showing promising usability and effectiveness.",
    "pdf_url": "http://arxiv.org/pdf/2506.05369v1",
    "published": "2025-05-28T14:02:56+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.22374v2",
    "title": "On face angles of tetrahedra with a given base",
    "authors": [
      "E. V. Nikitenko",
      "Yu. G. Nikonorov"
    ],
    "abstract": "Let us consider the set $\\Omega (\\triangle ABC)$ of all tetrahedra $ABCD$\nwith a given non-degenerate base $ABC$ in $\\mathbb{E}^3$ and $D$ lying outside\nthe plane $ABC$. Let us denote by $\\Sigma(\\triangle ABC)$ the set\n$\\left\\{\\Bigl(\\cos \\overline{\\alpha},\\cos \\overline{\\beta},\\cos\n\\overline{\\gamma} \\Bigr)\\in \\mathbb{R}^3\\,|\\, ABCD \\in \\Omega (\\triangle\nABC)\\right\\}$, where $\\overline{\\alpha}=\\angle BDC$, $\\overline{\\beta}=\\angle\nADC$, and $\\overline{\\gamma}=\\angle ADB$. The paper is devoted to the problem\nof determining of the closure of $\\Sigma(\\triangle ABC)$ in $\\mathbb{R}^3$ and\nits boundary.",
    "pdf_url": "http://arxiv.org/pdf/2505.22374v2",
    "published": "2025-05-28T14:02:46+00:00",
    "categories": [
      "math.MG",
      "math.DG",
      "51M16, 51M25, 53A04, 53A05, 57N35"
    ],
    "primary_category": "math.MG"
  },
  {
    "id": "http://arxiv.org/abs/2505.22373v1",
    "title": "Synaptic shot-noise triggers fast and slow global oscillations in balanced neural networks",
    "authors": [
      "Denis S. Goldobin",
      "Maria V. Ageeva",
      "Matteo di Volo",
      "Ferdinand Tixidre",
      "Alessandro Torcini"
    ],
    "abstract": "Neural dynamics is determined by the transmission of discrete synaptic pulses\n(synaptic shot-noise) among neurons. However, the neural responses are usually\nobtained within the diffusion approximation modeling synaptic inputs as\ncontinuous Gaussian noise. Here, we present a rigorous mean-field theory that\nencompasses synaptic shot-noise for sparse balanced inhibitory neural networks\ndriven by an excitatory drive. Our theory predicts new dynamical regimes, in\nagreement with numerical simulations, which are not captured by the classical\ndiffusion approximation. Notably, these regimes feature self-sustained global\noscillations emerging at low connectivity (in-degree) via either continuous or\nhysteretic transitions and characterized by irregular neural activity, as\nexpected for balanced dynamics. For sufficiently weak (strong) excitatory drive\n(inhibitory feedback) the transition line displays a peculiar re-entrant shape\nrevealing the existence of global oscillations at low and high in-degrees,\nseparated by an asynchronous regime at intermediate levels of connectivity. The\nmechanisms leading to the emergence of these global oscillations are distinct:\ndrift-driven at high connectivity and cluster activation at low connectivity.\nThe frequency of these two kinds of global oscillations can be varied from slow\n(around 1 Hz) to fast (around 100 Hz), without altering their microscopic and\nmacroscopic features, by adjusting the excitatory drive and the synaptic\ninhibition strength in a prescribed way. Furthermore, the cluster-activated\noscillations at low in-degrees could correspond to the gamma rhythms reported\nin mammalian cortex and hippocampus and attributed to ensembles of inhibitory\nneurons sharing few synaptic connections [G. Buzsaki and X.-J. Wang, Annual\nReview of Neuroscience 35, 203 (2012)].",
    "pdf_url": "http://arxiv.org/pdf/2505.22373v1",
    "published": "2025-05-28T13:59:01+00:00",
    "categories": [
      "cond-mat.dis-nn",
      "q-bio.NC"
    ],
    "primary_category": "cond-mat.dis-nn"
  },
  {
    "id": "http://arxiv.org/abs/2505.22372v1",
    "title": "More nonamalgamable forcing extensions",
    "authors": [
      "Miha E. Habiƒç",
      "Charles Weng",
      "Cathy Zhang"
    ],
    "abstract": "We extend the results of arXiv:1808.01509 on nonamalgamable forcing\nextensions to families of posets with wide projections. We also use a different\ncoding method to obtain nonamalgamable extensions by filter-based Mathias\nforcing.",
    "pdf_url": "http://arxiv.org/pdf/2505.22372v1",
    "published": "2025-05-28T13:58:38+00:00",
    "categories": [
      "math.LO",
      "03E40"
    ],
    "primary_category": "math.LO"
  },
  {
    "id": "http://arxiv.org/abs/2505.23839v1",
    "title": "GeneBreaker: Jailbreak Attacks against DNA Language Models with Pathogenicity Guidance",
    "authors": [
      "Zaixi Zhang",
      "Zhenghong Zhou",
      "Ruofan Jin",
      "Le Cong",
      "Mengdi Wang"
    ],
    "abstract": "DNA, encoding genetic instructions for almost all living organisms, fuels\ngroundbreaking advances in genomics and synthetic biology. Recently, DNA\nFoundation Models have achieved success in designing synthetic functional DNA\nsequences, even whole genomes, but their susceptibility to jailbreaking remains\nunderexplored, leading to potential concern of generating harmful sequences\nsuch as pathogens or toxin-producing genes. In this paper, we introduce\nGeneBreaker, the first framework to systematically evaluate jailbreak\nvulnerabilities of DNA foundation models. GeneBreaker employs (1) an LLM agent\nwith customized bioinformatic tools to design high-homology, non-pathogenic\njailbreaking prompts, (2) beam search guided by PathoLM and log-probability\nheuristics to steer generation toward pathogen-like sequences, and (3) a\nBLAST-based evaluation pipeline against a curated Human Pathogen Database\n(JailbreakDNABench) to detect successful jailbreaks. Evaluated on our\nJailbreakDNABench, GeneBreaker successfully jailbreaks the latest Evo series\nmodels across 6 viral categories consistently (up to 60\\% Attack Success Rate\nfor Evo2-40B). Further case studies on SARS-CoV-2 spike protein and HIV-1\nenvelope protein demonstrate the sequence and structural fidelity of jailbreak\noutput, while evolutionary modeling of SARS-CoV-2 underscores biosecurity\nrisks. Our findings also reveal that scaling DNA foundation models amplifies\ndual-use risks, motivating enhanced safety alignment and tracing mechanisms.\nOur code is at https://github.com/zaixizhang/GeneBreaker.",
    "pdf_url": "http://arxiv.org/pdf/2505.23839v1",
    "published": "2025-05-28T13:58:32+00:00",
    "categories": [
      "cs.CR",
      "q-bio.GN"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.22371v2",
    "title": "Adaptive tail index estimation: minimal assumptions and non-asymptotic guarantees",
    "authors": [
      "Johannes Lederer",
      "Anne Sabourin",
      "Mahsa Taheri"
    ],
    "abstract": "A notoriously difficult challenge in extreme value theory is the choice of\nthe number $k\\ll n$, where $n$ is the total sample size, of extreme data points\nto consider for inference of tail quantities. Existing theoretical guarantees\nfor adaptive methods typically require second-order assumptions or von Mises\nassumptions that are difficult to verify and often come with tuning parameters\nthat are challenging to calibrate. This paper revisits the problem of adaptive\nselection of $k$ for the Hill estimator. Our goal is not an `optimal' $k$ but\none that is `good enough', in the sense that we strive for non-asymptotic\nguarantees that might be sub-optimal but are explicit and require minimal\nconditions. We propose a transparent adaptive rule that does not require\npreliminary calibration of constants, inspired by `adaptive validation'\ndeveloped in high-dimensional statistics. A key feature of our approach is the\nconsideration of a grid for $k$ of size $ \\ll n $, which aligns with common\npractice among practitioners but has remained unexplored in theoretical\nanalysis. Our rule only involves an explicit expression of a variance-type\nterm; in particular, it does not require controlling or estimating a biasterm.\nOur theoretical analysis is valid for all heavy-tailed distributions,\nspecifically for all regularly varying survival functions. Furthermore, when\nvon Mises conditions hold, our method achieves `almost' minimax optimality with\na rate of $\\sqrt{\\log \\log n}~ n^{-|\\rho|/(1+2|\\rho|)}$ when the grid size is\nof order $\\log n$, in contrast to the $ (\\log \\log (n)/n)^{|\\rho|/(1+2|\\rho|)}\n$ rate in existing work. Our simulations show that our approach performs\nparticularly well for ill-behaved distributions.",
    "pdf_url": "http://arxiv.org/pdf/2505.22371v2",
    "published": "2025-05-28T13:58:20+00:00",
    "categories": [
      "stat.OT",
      "math.ST",
      "stat.TH"
    ],
    "primary_category": "stat.OT"
  },
  {
    "id": "http://arxiv.org/abs/2505.22370v3",
    "title": "SplitLoRA: Balancing Stability and Plasticity in Continual Learning Through Gradient Space Splitting",
    "authors": [
      "Haomiao Qiu",
      "Miao Zhang",
      "Ziyue Qiao",
      "Weili Guan",
      "Min Zhang",
      "Liqiang Nie"
    ],
    "abstract": "Continual Learning requires a model to learn multiple tasks in sequence while\nmaintaining both stability:preserving knowledge from previously learned tasks,\nand plasticity:effectively learning new tasks. Gradient projection has emerged\nas an effective and popular paradigm in CL, where it partitions the gradient\nspace of previously learned tasks into two orthogonal subspaces: a primary\nsubspace and a minor subspace. New tasks are learned effectively within the\nminor subspace, thereby reducing interference with previously acquired\nknowledge. However, existing Gradient Projection methods struggle to achieve an\noptimal balance between plasticity and stability, as it is hard to\nappropriately partition the gradient space. In this work, we consider a\ncontinual learning paradigm based on Low-Rank Adaptation, which has gained\nconsiderable attention due to its efficiency and wide applicability, and\npropose a novel approach for continual learning, called SplitLoRA. We first\nprovide a theoretical analysis of how subspace partitioning affects model\nstability and plasticity. Informed by this analysis, we then introduce an\neffective method that derives the optimal partition of the gradient space for\npreviously learned tasks. This approach effectively balances stability and\nplasticity in continual learning. Experimental results on multiple datasets\ndemonstrate that the proposed method achieves state-of-the-art performance.",
    "pdf_url": "http://arxiv.org/pdf/2505.22370v3",
    "published": "2025-05-28T13:57:56+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.22369v1",
    "title": "Model-independent cosmological inference after the DESI DR2 data with improved inverse distance ladder",
    "authors": [
      "Jia-Le Ling",
      "Guo-Hong Du",
      "Tian-Nuo Li",
      "Jing-Fei Zhang",
      "Shao-Jiang Wang",
      "Xin Zhang"
    ],
    "abstract": "Recently, the baryon acoustic oscillations (BAO) measurements from the DESI\nsurvey have suggested hints of dynamical dark energy, challenging the standard\n$\\Lambda $CDM model. In this work, we adopt an improved inverse distance ladder\napproach based on the latest cosmological data to provide a model-independent\nperspective, employing a global parametrization based on cosmic age (PAge). Our\nanalysis incorporates DESI DR2 BAO measurements, cosmic chronometer (CC) data,\nand type Ia supernovae (SNe) observations from either the DESY5 or PantheonPlus\ndatasets. For the DESY5+DESI DR2+CC datasets, we obtain $H_0 = 67.91 \\pm\n2.33~\\mathrm{km~s^{-1}~Mpc^{-1}}$. This value is consistent with the Planck\n2018 result, while shows $2.0 \\sigma$ tension with the SH0ES measurement.\nFurthermore, by mapping specific cosmological models into PAge approximation\nparameter space $(p_{\\mathrm{age}}, \\eta)$, our model-independent analysis\nreveals a notable deviation from the $\\Lambda \\mathrm{CDM}$ model, as indicated\nby the DESY5 and DESI DR2 datasets. Finally, DESY5+DESI DR2+CC datasets provide\nnearly decisive evidence favoring the PAge model over the standard $\\Lambda\n\\mathrm{CDM}$ model. These findings highlight the need for further\ninvestigation into the expansion history to better understand the deviations\nfrom the $\\Lambda \\mathrm{CDM}$ model.",
    "pdf_url": "http://arxiv.org/pdf/2505.22369v1",
    "published": "2025-05-28T13:56:48+00:00",
    "categories": [
      "astro-ph.CO",
      "gr-qc",
      "hep-ph",
      "hep-th"
    ],
    "primary_category": "astro-ph.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.22368v1",
    "title": "AgentDNS: A Root Domain Naming System for LLM Agents",
    "authors": [
      "Enfang Cui",
      "Yujun Cheng",
      "Rui She",
      "Dan Liu",
      "Zhiyuan Liang",
      "Minxin Guo",
      "Tianzheng Li",
      "Qian Wei",
      "Wenjuan Xing",
      "Zhijie Zhong"
    ],
    "abstract": "The rapid evolution of Large Language Model (LLM) agents has highlighted\ncritical challenges in cross-vendor service discovery, interoperability, and\ncommunication. Existing protocols like model context protocol and\nagent-to-agent protocol have made significant strides in standardizing\ninteroperability between agents and tools, as well as communication among\nmulti-agents. However, there remains a lack of standardized protocols and\nsolutions for service discovery across different agent and tool vendors. In\nthis paper, we propose AgentDNS, a root domain naming and service discovery\nsystem designed to enable LLM agents to autonomously discover, resolve, and\nsecurely invoke third-party agent and tool services across organizational and\ntechnological boundaries. Inspired by the principles of the traditional DNS,\nAgentDNS introduces a structured mechanism for service registration, semantic\nservice discovery, secure invocation, and unified billing. We detail the\narchitecture, core functionalities, and use cases of AgentDNS, demonstrating\nits potential to streamline multi-agent collaboration in real-world scenarios.\nThe source code will be published on https://github.com/agentdns.",
    "pdf_url": "http://arxiv.org/pdf/2505.22368v1",
    "published": "2025-05-28T13:56:22+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2506.00046v1",
    "title": "Behavioral alignment in social networks",
    "authors": [
      "Yu Xia",
      "Alex McAvoy",
      "Qi Su"
    ],
    "abstract": "The orderly behaviors observed in large-scale groups, such as fish schooling\nand the organized movement of crowds, are both ubiquitous and essential for the\nsurvival and stability of these systems. Such complex collective behaviors\noften emerge from simple local interactions and strategy adjustments among\nindividuals. Understanding how these basic rules shape complex group dynamics\nhas long been a significant scientific challenge. Historically, research has\npredominantly focused on imitation and social learning, where individuals adopt\nthe strategies of more successful peers to refine their behavior. However, in\nrecent years, an alternative learning approach, self-exploration and\nintrospective learning, has garnered increasing attention. In this paradigm,\nindividuals assess their own circumstances and select strategies that best\nalign with their specific conditions. Two primary forms of this learning are\ncoordination and anti-coordination, where individuals align with and diverge\nfrom the local majority, respectively. In this study, we analyze networked\nsystems of coordinating and anti-coordinating individuals, exploring the\ncombined effects of system dynamics, network structure, and behavioral\npatterns. We address several practical questions, including the number of\nequilibria, their characteristics, the equilibrium time, and the resilience of\nsystems. We find that the number of equilibrium states can be extremely large,\neven increasing exponentially with minor alternations to the network structure.\nMoreover, the network structure has a significant impact on the average\nequilibrium time. Despite the complexity of these findings, variations can be\ncaptured by a single, simple network characteristic: the average path length.\nOur research offers valuable insights into how modifications to the interaction\nstructure can influence behavioral alignment in social networks.",
    "pdf_url": "http://arxiv.org/pdf/2506.00046v1",
    "published": "2025-05-28T13:55:58+00:00",
    "categories": [
      "physics.soc-ph",
      "cs.MA",
      "cs.SI",
      "nlin.AO"
    ],
    "primary_category": "physics.soc-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.22697v1",
    "title": "Update Your Transformer to the Latest Release: Re-Basin of Task Vectors",
    "authors": [
      "Filippo Rinaldi",
      "Giacomo Capitani",
      "Lorenzo Bonicelli",
      "Donato Crisostomi",
      "Federico Bolelli",
      "Elisa Ficarra",
      "Emanuele Rodol√†",
      "Simone Calderara",
      "Angelo Porrello"
    ],
    "abstract": "Foundation models serve as the backbone for numerous specialized models\ndeveloped through fine-tuning. However, when the underlying pretrained model is\nupdated or retrained (e.g., on larger and more curated datasets), the\nfine-tuned model becomes obsolete, losing its utility and requiring retraining.\nThis raises the question: is it possible to transfer fine-tuning to a new\nrelease of the model? In this work, we investigate how to transfer fine-tuning\nto a new checkpoint without having to re-train, in a data-free manner. To do\nso, we draw principles from model re-basin and provide a recipe based on weight\npermutations to re-base the modifications made to the original base model,\noften called task vector. In particular, our approach tailors model re-basin\nfor Transformer models, taking into account the challenges of residual\nconnections and multi-head attention layers. Specifically, we propose a\ntwo-level method rooted in spectral theory, initially permuting the attention\nheads and subsequently adjusting parameters within select pairs of heads.\nThrough extensive experiments on visual and textual tasks, we achieve the\nseamless transfer of fine-tuned knowledge to new pre-trained backbones without\nrelying on a single training step or datapoint. Code is available at\nhttps://github.com/aimagelab/TransFusion.",
    "pdf_url": "http://arxiv.org/pdf/2505.22697v1",
    "published": "2025-05-28T13:55:12+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.22367v1",
    "title": "Probing nuclear structure in relativistic p-O and O-O collisions at the LHC through the measurement of anisotropic flow coefficients",
    "authors": [
      "Aswathy Menon K R",
      "Suraj Prasad",
      "Neelkamal Mallick",
      "Raghunath Sahoo",
      "Gergely G√°bor Barnaf√∂ldi"
    ],
    "abstract": "RHIC and LHC plan to inject $^{16}\\rm O$ nuclei with a focus to investigate\ncollectivity and the origin of quark-gluon plasma signatures in small collision\nsystems. $^{16}\\rm O$ nuclei is known to possess clusters of $\\alpha$-particles\n($^{4}\\rm He$) inside the nucleus. In this paper, we study the anisotropic flow\ncoefficients such as elliptic flow ($v_2$) and triangular flow ($v_3$), which\nare sensitive to the nuclear geometry of colliding nuclei, for p-O and O-O\ncollisions at $\\sqrt{s_{\\rm NN}}=9.61$ TeV and 7 TeV respectively. The study is\nperformed employing a hybrid model encompassing IPGlasma + MUSIC + iSS + UrQMD.\nThe results of the clustered nuclear geometry are compared with those of the\nWoods-Saxon nuclear profile. Both initial and final state anisotropies are\nexplored. This study is thus one of its first kind, where the study of\nanisotropic flow coefficients for p-O and O-O collisions is presented using a\nhybrid hydrodynamics model. We find a small effect of $\\alpha$-clustering in\np-O, while a significant one for O-O collisions. It is also observed that the\nmagnitude of the effect correlates with the size of the $^{4}$He.",
    "pdf_url": "http://arxiv.org/pdf/2505.22367v1",
    "published": "2025-05-28T13:55:02+00:00",
    "categories": [
      "hep-ph",
      "hep-ex",
      "hep-th",
      "nucl-ex",
      "nucl-th"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.22366v1",
    "title": "EStacker: Explaining Battery-Less IoT System Performance with Energy Stacks",
    "authors": [
      "Lukas Liedtke",
      "Per Gunnar Kjeldsberg",
      "Frank Alexander Kraemer",
      "Magnus Jahre"
    ],
    "abstract": "The number of Internet of Things (IoT) devices is increasing exponentially,\nand it is environmentally and economically unsustainable to power all these\ndevices with batteries. The key alternative is energy harvesting, but\nbattery-less IoT systems require extensive evaluation to demonstrate that they\nare sufficiently performant across the full range of expected operating\nconditions. IoT developers thus need an evaluation platform that (i) ensures\nthat each evaluated application and configuration is exposed to exactly the\nsame energy environment and events, and (ii) provides a detailed account of\nwhat the application spends the harvested energy on. We therefore developed the\nEStacker evaluation platform which (i) provides fair and repeatable evaluation,\nand (ii) generates energy stacks. Energy stacks break down the total energy\nconsumption of an application across hardware components and application\nactivities, thereby explaining what the application specifically uses energy\non. We augment EStacker with the ST-SP optimization which, in our experiments,\nreduces evaluation time by 6.3x on average while retaining the temporal\nbehavior of the battery-less IoT system (average throughput error of 7.7%) by\nproportionally scaling time and power. We demonstrate the utility of EStacker\nthrough two case studies. In the first case study, we use energy stack profiles\nto identify a performance problem that, once addressed, improves performance by\n3.3x. The second case study focuses on ST-SP, and we use it to explore the\ndesign space required to dimension the harvester and energy storage sizes of a\nsmart parking application in roughly one week (7.7 days). Without ST-SP,\nsweeping this design space would have taken well over one month (41.7 days).",
    "pdf_url": "http://arxiv.org/pdf/2505.22366v1",
    "published": "2025-05-28T13:49:23+00:00",
    "categories": [
      "cs.AR",
      "B.8.2; C.3"
    ],
    "primary_category": "cs.AR"
  },
  {
    "id": "http://arxiv.org/abs/2505.22365v1",
    "title": "Quantitative regularity properties for the optimal design problem",
    "authors": [
      "Lorenzo Lamberti",
      "Antoine Lemenant"
    ],
    "abstract": "In this paper we slightly improve the regularity theory for the so called\noptimal design problem. We first establish the uniform rectifiability of the\nboundary of the optimal set, for a larger class of minimizers, in any\ndimension. As an application, we improve the bound obtained by Larsen in\ndimension~2 about the mutual distance between two connected components. Finally\nwe also prove that the full regularity in dimension 2 holds true provided that\nthe ratio between the two constants in front of the Dirichlet energy is not\nlarger than 4, which partially answers to a question raised by Larsen.",
    "pdf_url": "http://arxiv.org/pdf/2505.22365v1",
    "published": "2025-05-28T13:48:55+00:00",
    "categories": [
      "math.OC"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2506.15698v2",
    "title": "Global Context-aware Representation Learning for Spatially Resolved Transcriptomics",
    "authors": [
      "Yunhak Oh",
      "Junseok Lee",
      "Yeongmin Kim",
      "Sangwoo Seo",
      "Namkyeong Lee",
      "Chanyoung Park"
    ],
    "abstract": "Spatially Resolved Transcriptomics (SRT) is a cutting-edge technique that\ncaptures the spatial context of cells within tissues, enabling the study of\ncomplex biological networks. Recent graph-based methods leverage both gene\nexpression and spatial information to identify relevant spatial domains.\nHowever, these approaches fall short in obtaining meaningful spot\nrepresentations, especially for spots near spatial domain boundaries, as they\nheavily emphasize adjacent spots that have minimal feature differences from an\nanchor node. To address this, we propose Spotscape, a novel framework that\nintroduces the Similarity Telescope module to capture global relationships\nbetween multiple spots. Additionally, we propose a similarity scaling strategy\nto regulate the distances between intra- and inter-slice spots, facilitating\neffective multi-slice integration. Extensive experiments demonstrate the\nsuperiority of Spotscape in various downstream tasks, including single-slice\nand multi-slice scenarios. Our code is available at the following link: https:\n//github.com/yunhak0/Spotscape.",
    "pdf_url": "http://arxiv.org/pdf/2506.15698v2",
    "published": "2025-05-28T13:47:50+00:00",
    "categories": [
      "cs.LG",
      "cs.CV"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.22364v1",
    "title": "Computing Optimal Transport Maps and Wasserstein Barycenters Using Conditional Normalizing Flows",
    "authors": [
      "Gabriele Visentin",
      "Patrick Cheridito"
    ],
    "abstract": "We present a novel method for efficiently computing optimal transport maps\nand Wasserstein barycenters in high-dimensional spaces. Our approach uses\nconditional normalizing flows to approximate the input distributions as\ninvertible pushforward transformations from a common latent space. This makes\nit possible to directly solve the primal problem using gradient-based\nminimization of the transport cost, unlike previous methods that rely on dual\nformulations and complex adversarial optimization. We show how this approach\ncan be extended to compute Wasserstein barycenters by solving a conditional\nvariance minimization problem. A key advantage of our conditional architecture\nis that it enables the computation of barycenters for hundreds of input\ndistributions, which was computationally infeasible with previous methods. Our\nnumerical experiments illustrate that our approach yields accurate results\nacross various high-dimensional tasks and compares favorably with previous\nstate-of-the-art methods.",
    "pdf_url": "http://arxiv.org/pdf/2505.22364v1",
    "published": "2025-05-28T13:46:07+00:00",
    "categories": [
      "stat.ML",
      "cs.LG",
      "65K99 (Primary) 68T07, 68T99 (Secondary)"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2505.22363v1",
    "title": "Operator-Splitting Methods for Neuromorphic Circuit Simulation",
    "authors": [
      "Amir Shahhosseini",
      "Thomas Chaffey",
      "Rodolphe Sepulchre"
    ],
    "abstract": "A novel splitting algorithm is proposed for the numerical simulation of\nneuromorphic circuits. The algorithm is grounded in the operator-theoretic\nconcept of monotonicity, which bears both physical and algorithmic\nsignificance. The splitting exploits this correspondence to translate the\ncircuit architecture into the algorithmic architecture. The paper illustrates\nthe many advantages of the proposed operator-theoretic framework over\nconventional numerical integration for the simulation of multiscale\nhierarchical events that characterize neuromorphic behaviors.",
    "pdf_url": "http://arxiv.org/pdf/2505.22363v1",
    "published": "2025-05-28T13:42:26+00:00",
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2505.22362v2",
    "title": "Directed Homophily-Aware Graph Neural Network",
    "authors": [
      "Aihu Zhang",
      "Jiaxing Xu",
      "Mengcheng Lan",
      "Shili Xiang",
      "Yiping Ke"
    ],
    "abstract": "Graph Neural Networks (GNNs) have achieved significant success in various\nlearning tasks on graph-structured data. Nevertheless, most GNNs struggle to\ngeneralize to heterophilic neighborhoods. Additionally, many GNNs ignore the\ndirectional nature of real-world graphs, resulting in suboptimal performance on\ndirected graphs with asymmetric structures. In this work, we propose Directed\nHomophily-aware Graph Neural Network (DHGNN), a novel framework that addresses\nthese limitations by incorporating homophily-aware and direction-sensitive\ncomponents. DHGNN employs a resettable gating mechanism to adaptively modulate\nmessage contributions based on homophily levels and informativeness, and a\nstructure-aware noise-tolerant fusion module to effectively integrate node\nrepresentations from the original and reverse directions. Extensive experiments\non both homophilic and heterophilic directed graph datasets demonstrate that\nDHGNN outperforms state-of-the-art methods in node classification and link\nprediction. In particular, DHGNN improves over the best baseline by up to\n15.07% in link prediction. Our analysis further shows that the gating mechanism\ncaptures directional homophily gaps and fluctuating homophily across layers,\nproviding deeper insights into message-passing behavior on complex graph\nstructures.",
    "pdf_url": "http://arxiv.org/pdf/2505.22362v2",
    "published": "2025-05-28T13:41:04+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.22361v1",
    "title": "Continuum-armed Bandit Optimization with Batch Pairwise Comparison Oracles",
    "authors": [
      "Xiangyu Chang",
      "Xi Chen",
      "Yining Wang",
      "Zhiyi Zeng"
    ],
    "abstract": "This paper studies a bandit optimization problem where the goal is to\nmaximize a function $f(x)$ over $T$ periods for some unknown strongly concave\nfunction $f$. We consider a new pairwise comparison oracle, where the\ndecision-maker chooses a pair of actions $(x, x')$ for a consecutive number of\nperiods and then obtains an estimate of $f(x)-f(x')$. We show that such a\npairwise comparison oracle finds important applications to joint pricing and\ninventory replenishment problems and network revenue management. The challenge\nin this bandit optimization is twofold. First, the decision-maker not only\nneeds to determine a pair of actions $(x, x')$ but also a stopping time $n$\n(i.e., the number of queries based on $(x, x')$). Second, motivated by our\ninventory application, the estimate of the difference $f(x)-f(x')$ is biased,\nwhich is different from existing oracles in stochastic optimization literature.\nTo address these challenges, we first introduce a discretization technique and\nlocal polynomial approximation to relate this problem to linear bandits. Then\nwe developed a tournament successive elimination technique to localize the\ndiscretized cell and run an interactive batched version of LinUCB algorithm on\ncells. We establish regret bounds that are optimal up to poly-logarithmic\nfactors. Furthermore, we apply our proposed algorithm and analytical framework\nto the two operations management problems and obtain results that improve\nstate-of-the-art results in the existing literature.",
    "pdf_url": "http://arxiv.org/pdf/2505.22361v1",
    "published": "2025-05-28T13:41:00+00:00",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.22360v1",
    "title": "Identity-Preserving Text-to-Image Generation via Dual-Level Feature Decoupling and Expert-Guided Fusion",
    "authors": [
      "Kewen Chen",
      "Xiaobin Hu",
      "Wenqi Ren"
    ],
    "abstract": "Recent advances in large-scale text-to-image generation models have led to a\nsurge in subject-driven text-to-image generation, which aims to produce\ncustomized images that align with textual descriptions while preserving the\nidentity of specific subjects. Despite significant progress, current methods\nstruggle to disentangle identity-relevant information from identity-irrelevant\ndetails in the input images, resulting in overfitting or failure to maintain\nsubject identity. In this work, we propose a novel framework that improves the\nseparation of identity-related and identity-unrelated features and introduces\nan innovative feature fusion mechanism to improve the quality and text\nalignment of generated images. Our framework consists of two key components: an\nImplicit-Explicit foreground-background Decoupling Module (IEDM) and a Feature\nFusion Module (FFM) based on a Mixture of Experts (MoE). IEDM combines\nlearnable adapters for implicit decoupling at the feature level with inpainting\ntechniques for explicit foreground-background separation at the image level.\nFFM dynamically integrates identity-irrelevant features with identity-related\nfeatures, enabling refined feature representations even in cases of incomplete\ndecoupling. In addition, we introduce three complementary loss functions to\nguide the decoupling process. Extensive experiments demonstrate the\neffectiveness of our proposed method in enhancing image generation quality,\nimproving flexibility in scene adaptation, and increasing the diversity of\ngenerated outputs across various textual descriptions.",
    "pdf_url": "http://arxiv.org/pdf/2505.22360v1",
    "published": "2025-05-28T13:40:46+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.22359v1",
    "title": "Multiclass Loss Geometry Matters for Generalization of Gradient Descent in Separable Classification",
    "authors": [
      "Matan Schliserman",
      "Tomer Koren"
    ],
    "abstract": "We study the generalization performance of unregularized gradient methods for\nseparable linear classification. While previous work mostly deal with the\nbinary case, we focus on the multiclass setting with $k$ classes and establish\nnovel population risk bounds for Gradient Descent for loss functions that decay\nto zero. In this setting, we show risk bounds that reveal that convergence\nrates are crucially influenced by the geometry of the loss template, as\nformalized by Wang and Scott (2024), rather than of the loss function itself.\nParticularly, we establish risk upper bounds that holds for any decay rate of\nthe loss whose template is smooth with respect to the $p$-norm. In the case of\nexponentially decaying losses, our results indicates a contrast between the\n$p=\\infty$ case, where the risk exhibits a logarithmic dependence on $k$, and\n$p=2$ where the risk scales linearly with $k$. To establish this separation\nformally, we also prove a lower bound in the latter scenario, demonstrating\nthat the polynomial dependence on $k$ is unavoidable. Central to our analysis\nis a novel bound on the Rademacher complexity of low-noise vector-valued linear\npredictors with a loss template smooth w.r.t.~general $p$-norms.",
    "pdf_url": "http://arxiv.org/pdf/2505.22359v1",
    "published": "2025-05-28T13:39:14+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.22358v1",
    "title": "Budget-Adaptive Adapter Tuning in Orthogonal Subspaces for Continual Learning in LLMs",
    "authors": [
      "Zhiyi Wan",
      "Wanrou Du",
      "Liang Li",
      "Miao Pan",
      "Xiaoqi Qin"
    ],
    "abstract": "Large language models (LLMs) often suffer from catastrophic forgetting in\ncontinual learning (CL) scenarios, where performance on previously learned\ntasks degrades severely while training on sequentially arriving tasks. Although\npioneering CL approaches using orthogonal subspaces can mitigate task\ninterference, they typically employ fixed budget allocation, neglecting the\nvarying complexity across tasks and layers. Besides, recent budget-adaptive\ntuning methods for LLMs often adopt multi-stage paradigms that decouple\noptimization and budget allocation. Such decoupling results in potential\nmisalignment, which hinders those approaches' practical application in CL\nscenarios. To address these limitations, we propose OA-Adapter, a novel\nparameter-efficient approach for continual learning in LLMs that unifies\ndynamic budget adaptation with orthogonal subspace learning in a single\nend-to-end training stage. Specifically, OA-Adapter introduces a dynamic\nbottleneck dimension adaptation mechanism that simultaneously allocates an\nefficient parameter budget and optimizes task objectives without misalignment.\nTo effectively preserve previously acquired knowledge while coordinating with\nthe dynamic budget allocation, orthogonal constraints are applied specifically\nbetween the parameter subspace of the current task and the dynamically\nallocated parameter subspaces of historical tasks. Experimental results on\ncontinual learning benchmarks demonstrate that OA-Adapter outperforms\nstate-of-the-art methods in both accuracy and parameter efficiency, achieving\nhigher average accuracy while using 58.5% fewer parameters on the standard CL\nbenchmark.",
    "pdf_url": "http://arxiv.org/pdf/2505.22358v1",
    "published": "2025-05-28T13:38:21+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.22357v1",
    "title": "On the Local Converse Theorem for Depth $\\frac{1}{N}$ Supercuspidal Representations of $\\text{GL}(2N, F)$",
    "authors": [
      "David C. Luo",
      "Shaun Stevens"
    ],
    "abstract": "In this paper, we use type theory to construct a family of depth\n$\\frac{1}{N}$ minimax supercuspidal representations of $\\text{GL}(2N, F)$ which\nwe call middle supercuspidal representations. These supercuspidals may be\nviewed as a natural generalization of simple supercuspidal representations,\ni.e. those supercuspidals of minimal positive depth. Via explicit computations\nof twisted gamma factors, we show that middle supercuspidal representations may\nbe uniquely determined through twisting by quasi-characters of $F^{\\times}$ and\nsimple supercuspidal representations of $\\text{GL}(N, F)$.",
    "pdf_url": "http://arxiv.org/pdf/2505.22357v1",
    "published": "2025-05-28T13:37:56+00:00",
    "categories": [
      "math.RT",
      "math.NT",
      "22E50, 11F70"
    ],
    "primary_category": "math.RT"
  },
  {
    "id": "http://arxiv.org/abs/2505.22356v1",
    "title": "Suitability Filter: A Statistical Framework for Classifier Evaluation in Real-World Deployment Settings",
    "authors": [
      "Ang√©line Pouget",
      "Mohammad Yaghini",
      "Stephan Rabanser",
      "Nicolas Papernot"
    ],
    "abstract": "Deploying machine learning models in safety-critical domains poses a key\nchallenge: ensuring reliable model performance on downstream user data without\naccess to ground truth labels for direct validation. We propose the suitability\nfilter, a novel framework designed to detect performance deterioration by\nutilizing suitability signals -- model output features that are sensitive to\ncovariate shifts and indicative of potential prediction errors. The suitability\nfilter evaluates whether classifier accuracy on unlabeled user data shows\nsignificant degradation compared to the accuracy measured on the labeled test\ndataset. Specifically, it ensures that this degradation does not exceed a\npre-specified margin, which represents the maximum acceptable drop in accuracy.\nTo achieve reliable performance evaluation, we aggregate suitability signals\nfor both test and user data and compare these empirical distributions using\nstatistical hypothesis testing, thus providing insights into decision\nuncertainty. Our modular method adapts to various models and domains. Empirical\nevaluations across different classification tasks demonstrate that the\nsuitability filter reliably detects performance deviations due to covariate\nshift. This enables proactive mitigation of potential failures in high-stakes\napplications.",
    "pdf_url": "http://arxiv.org/pdf/2505.22356v1",
    "published": "2025-05-28T13:37:04+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.22355v1",
    "title": "Look Within or Look Beyond? A Theoretical Comparison Between Parameter-Efficient and Full Fine-Tuning",
    "authors": [
      "Yongkang Liu",
      "Xingle Xu",
      "Ercong Nie",
      "Zijing Wang",
      "Shi Feng",
      "Daling Wang",
      "Qian Li",
      "Hinrich Sch√ºtze"
    ],
    "abstract": "Parameter-Efficient Fine-Tuning (PEFT) methods achieve performance comparable\nto Full Fine-Tuning (FFT) while requiring significantly fewer computing\nresources, making it the go-to choice for researchers. We find that although\nPEFT can achieve competitive results on some benchmarks, its performance falls\nshort of FFT in complex tasks, such as reasoning and instruction-based\nfine-tuning. In this paper, we compare the characteristics of PEFT and FFT in\nterms of representational capacity and robustness based on optimization theory.\nWe theoretically demonstrate that PEFT is a strict subset of FFT. By providing\ntheoretical upper bounds for PEFT, we show that the limited parameter space\nconstrains the model's representational ability, making it more susceptible to\nperturbations. Experiments on 15 datasets encompassing classification,\ngeneration, reasoning, instruction fine-tuning tasks and 11 adversarial test\nsets validate our theories. We hope that these results spark further research\nbeyond the realms of well established PEFT. The source code is in the anonymous\nGithub repository\\footnote{https://github.com/misonsky/PEFTEval}.",
    "pdf_url": "http://arxiv.org/pdf/2505.22355v1",
    "published": "2025-05-28T13:35:12+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.22354v1",
    "title": "LLMs Struggle to Reject False Presuppositions when Misinformation Stakes are High",
    "authors": [
      "Judith Sieker",
      "Clara Lachenmaier",
      "Sina Zarrie√ü"
    ],
    "abstract": "This paper examines how LLMs handle false presuppositions and whether certain\nlinguistic factors influence their responses to falsely presupposed content.\nPresuppositions subtly introduce information as given, making them highly\neffective at embedding disputable or false information. This raises concerns\nabout whether LLMs, like humans, may fail to detect and correct misleading\nassumptions introduced as false presuppositions, even when the stakes of\nmisinformation are high. Using a systematic approach based on linguistic\npresupposition analysis, we investigate the conditions under which LLMs are\nmore or less sensitive to adopt or reject false presuppositions. Focusing on\npolitical contexts, we examine how factors like linguistic construction,\npolitical party, and scenario probability impact the recognition of false\npresuppositions. We conduct experiments with a newly created dataset and\nexamine three LLMs: OpenAI's GPT-4-o, Meta's LLama-3-8B, and MistralAI's\nMistral-7B-v03. Our results show that the models struggle to recognize false\npresuppositions, with performance varying by condition. This study highlights\nthat linguistic presupposition analysis is a valuable tool for uncovering the\nreinforcement of political misinformation in LLM responses.",
    "pdf_url": "http://arxiv.org/pdf/2505.22354v1",
    "published": "2025-05-28T13:35:07+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.22353v1",
    "title": "VME: A Satellite Imagery Dataset and Benchmark for Detecting Vehicles in the Middle East and Beyond",
    "authors": [
      "Noora Al-Emadi",
      "Ingmar Weber",
      "Yin Yang",
      "Ferda Ofli"
    ],
    "abstract": "Detecting vehicles in satellite images is crucial for traffic management,\nurban planning, and disaster response. However, current models struggle with\nreal-world diversity, particularly across different regions. This challenge is\namplified by geographic bias in existing datasets, which often focus on\nspecific areas and overlook regions like the Middle East. To address this gap,\nwe present the Vehicles in the Middle East (VME) dataset, designed explicitly\nfor vehicle detection in high-resolution satellite images from Middle Eastern\ncountries. Sourced from Maxar, the VME dataset spans 54 cities across 12\ncountries, comprising over 4,000 image tiles and more than 100,000 vehicles,\nannotated using both manual and semi-automated methods. Additionally, we\nintroduce the largest benchmark dataset for Car Detection in Satellite Imagery\n(CDSI), combining images from multiple sources to enhance global car detection.\nOur experiments demonstrate that models trained on existing datasets perform\npoorly on Middle Eastern images, while the VME dataset significantly improves\ndetection accuracy in this region. Moreover, state-of-the-art models trained on\nCDSI achieve substantial improvements in global car detection.",
    "pdf_url": "http://arxiv.org/pdf/2505.22353v1",
    "published": "2025-05-28T13:34:05+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.22352v1",
    "title": "State and Input Constrained Adaptive Tracking Control of Uncertain Euler-Lagrange Systems with Robustness and Feasibility Analysis",
    "authors": [
      "Poulomee Ghosh",
      "Shubhendu Bhasin"
    ],
    "abstract": "This paper proposes an adaptive tracking controller for uncertain\nEuler-Lagrange (E-L) systems with user-defined state and input constraints in\npresence of bounded external disturbances. A barrier Lyapunov function (BLF) is\nemployed for state constraint satisfaction, integrated with a saturated\ncontroller that ensures the control input remains within pre-specified bounds.\nTo the best of the authors' knowledge, this is the first result on tracking\ncontrol of state and input-constrained uncertain E-L systems that provides\nverifiable conditions for the existence of a feasible control policy. The\nefficacy of the proposed controller in terms of constraint satisfaction and\ntracking performance is demonstrated through simulation on a robotic\nmanipulator system.",
    "pdf_url": "http://arxiv.org/pdf/2505.22352v1",
    "published": "2025-05-28T13:33:14+00:00",
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2505.22351v1",
    "title": "Finding $d$-Cuts in Probe $H$-Free Graphs",
    "authors": [
      "Konrad K. Dabrowski",
      "Tala Eagling-Vose",
      "Matthew Johnson",
      "Giacomo Paesani",
      "Dani√´l Paulusma"
    ],
    "abstract": "For an integer $d\\geq 1$, the $d$-Cut problem is that of deciding whether a\ngraph has an edge cut in which each vertex is adjacent to at most $d$ vertices\non the opposite side of the cut. The $1$-Cut problem is the well-known Matching\nCut problem. The $d$-Cut problem has been extensively studied for $H$-free\ngraphs. We extend these results to the probe graph model, where we do not know\nall the edges of the input graph. For a graph $H$, a partitioned probe $H$-free\ngraph $(G,P,N)$ consists of a graph $G=(V,E)$, together with a set $P\\subseteq\nV$ of probes and an independent set $N=V\\setminus P$ of non-probes such that we\ncan change $G$ into an $H$-free graph by adding zero or more edges between\nvertices in $N$. For every graph $H$ and every integer $d\\geq 1$, we completely\ndetermine the complexity of $d$-Cut on partitioned probe $H$-free graphs.",
    "pdf_url": "http://arxiv.org/pdf/2505.22351v1",
    "published": "2025-05-28T13:32:59+00:00",
    "categories": [
      "cs.DS",
      "cs.CC",
      "cs.DM",
      "math.CO"
    ],
    "primary_category": "cs.DS"
  },
  {
    "id": "http://arxiv.org/abs/2505.22350v2",
    "title": "New chaos decomposition of Gaussian nodal volumes",
    "authors": [
      "Michele Stecconi",
      "Anna Paola Todino"
    ],
    "abstract": "We investigate the random variable defined by the volume of the zero set of a\nsmooth Gaussian field, on a general Riemannian manifold possibly with boundary,\na fundamental object in probability and geometry. We prove a new explicit\nformula for its Wiener-It\\^o chaos decomposition that is notably simpler than\nexisting alternatives and which holds in greater generality, without requiring\nthe field to be compatible with the geometry of the manifold. A key advantage\nof our formulation is a significant reduction in the complexity of computing\nthe variance of the nodal volume. Unlike the standard Hermite expansion, which\nrequires evaluating the expectation of products of $2+2n$ Hermite polynomials,\nour approach reduces this task--in any dimension $n$--to computing the\nexpectation of a product of just four Hermite polynomials. As a consequence, we\nestablish a new exact formula for the variance, together with lower and upper\nbounds. Importantly, in contrast to previous results, our approach applies to\nhighly non-isotropic situations, allowing the study of Riemannian random waves\non arbitrary manifolds. By introducing two parameters associated to any\nGaussian field: the frequency and the eccentricity, we quantify the deviation\nfrom the standard settings (e.g., spheres) and establish a quantitative version\nof Berry's cancellation phenomenon valid on all manifolds.",
    "pdf_url": "http://arxiv.org/pdf/2505.22350v2",
    "published": "2025-05-28T13:32:19+00:00",
    "categories": [
      "math.PR",
      "math.DG",
      "60G15 (Primary) 60D05, 58C35, 60G57 (Secondary)"
    ],
    "primary_category": "math.PR"
  },
  {
    "id": "http://arxiv.org/abs/2506.02022v1",
    "title": "Do You See Me : A Multidimensional Benchmark for Evaluating Visual Perception in Multimodal LLMs",
    "authors": [
      "Aditya Kanade",
      "Tanuja Ganu"
    ],
    "abstract": "Multimodal Large Language Models (MLLMs) show reasoning promise, yet their\nvisual perception is a critical bottleneck. Strikingly, MLLMs can produce\ncorrect answers even while misinterpreting crucial visual elements, masking\nthese underlying failures. Our preliminary study on a joint\nperception-reasoning dataset revealed that for one leading MLLM, 29% of its\ncorrect answers to reasoning questions still exhibited visual perception\nerrors. To systematically address this, we introduce \"Do You See Me\", a\nscalable benchmark with 1,758 images and 2,612 questions. It spans seven\nhuman-psychology inspired subtasks in 2D and 3D, featuring controllable\ncomplexity to rigorously evaluate MLLM visual skills. Our findings on 3 leading\nclosed-source and 5 major open-source models reveal a stark deficit: humans\nachieve 96.49% accuracy, while top MLLMs average below 50%. This performance\ngap widens rapidly with increased task complexity (e.g., from 12% to 45% in the\nvisual form constancy subtask). Further analysis into the root causes suggests\nthat failures stem from challenges like misallocated visual attention and the\ninstability of internal representations for fine-grained details, especially at\nor below encoder patch resolution. This underscores an urgent need for MLLMs\nwith truly robust visual perception. The benchmark dataset, source code and\nevaluation scripts are available at https://github.com/microsoft/Do-You-See-Me.",
    "pdf_url": "http://arxiv.org/pdf/2506.02022v1",
    "published": "2025-05-28T13:31:32+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.22349v1",
    "title": "ChatPD: An LLM-driven Paper-Dataset Networking System",
    "authors": [
      "Anjie Xu",
      "Ruiqing Ding",
      "Leye Wang"
    ],
    "abstract": "Scientific research heavily depends on suitable datasets for method\nvalidation, but existing academic platforms with dataset management like\nPapersWithCode suffer from inefficiencies in their manual workflow. To overcome\nthis bottleneck, we present a system, called ChatPD, that utilizes Large\nLanguage Models (LLMs) to automate dataset information extraction from academic\npapers and construct a structured paper-dataset network. Our system consists of\nthree key modules: \\textit{paper collection}, \\textit{dataset information\nextraction}, and \\textit{dataset entity resolution} to construct paper-dataset\nnetworks. Specifically, we propose a \\textit{Graph Completion and Inference}\nstrategy to map dataset descriptions to their corresponding entities. Through\nextensive experiments, we demonstrate that ChatPD not only outperforms the\nexisting platform PapersWithCode in dataset usage extraction but also achieves\nabout 90\\% precision and recall in entity resolution tasks. Moreover, we have\ndeployed ChatPD to continuously extract which datasets are used in papers, and\nprovide a dataset discovery service, such as task-specific dataset queries and\nsimilar dataset recommendations. We open source ChatPD and the current\npaper-dataset network on this [GitHub\nrepository]{https://github.com/ChatPD-web/ChatPD}.",
    "pdf_url": "http://arxiv.org/pdf/2505.22349v1",
    "published": "2025-05-28T13:31:08+00:00",
    "categories": [
      "cs.DB",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.DB"
  },
  {
    "id": "http://arxiv.org/abs/2505.22348v1",
    "title": "Emergence of Diverse Topological States in Ge Doped MnBi2Te4",
    "authors": [
      "Zhijian Shi",
      "Shengjie Xu",
      "Jianfeng Wang",
      "Yi Du",
      "Weichang Hao"
    ],
    "abstract": "As an ideal platform for studying interplays between symmetry, topology and\nmagnetism, the magnetic topological insulator (MTI) MnBi2Te4 has attracted\nextensive attentions. However, its strong n-type intrinsic defects hinder the\nrealizations of exotic phenomena. Stimulated by recent discoveries that Ge\ndoping can efficiently tune the position of Fermi level, here we systematically\ninvestigate the band evolution and topological phase diagram with doping\nconcentration from MTI MnBi2Te4 to strong topological insulator GeBi2Te4.\nDifferent from magnetically doped Bi2Se3, the topology here is determined by\ncompetition of two band inversions arising from band folding of two\ntime-reversal invariant momenta between antiferromagnetic and\nnonmagnetic/ferromagnetic unit cells. By employing a band momentum mapping\nmethod, besides the known MTI phase, remarkably, we find two classes of\nmagnetic Dirac semimetal phases at antiferromagnetic state, two classes of Weyl\nsemimetal phases at ferromagnetic state, and an intermediate trivial state at\ndifferent doping regions. Interestingly, the trivial state can be tuned into a\nWeyl phase with two coexisting band inversions and extraordinarily long Fermi\narcs by a small strain. Our work reveals diverse topological states with\nintrinsic quantum phenomena can be achieved with great potential for designing\nfuture electronic devices.",
    "pdf_url": "http://arxiv.org/pdf/2505.22348v1",
    "published": "2025-05-28T13:30:31+00:00",
    "categories": [
      "cond-mat.mtrl-sci",
      "cond-mat.other",
      "physics.comp-ph",
      "quant-ph"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2505.22347v2",
    "title": "Bruhat operads",
    "authors": [
      "Gleb Koshevoy",
      "Vadim Schechtman"
    ],
    "abstract": "We describe some planar operads build from the higher Bruhat orders.",
    "pdf_url": "http://arxiv.org/pdf/2505.22347v2",
    "published": "2025-05-28T13:30:28+00:00",
    "categories": [
      "math.CO",
      "math.CT"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.22346v1",
    "title": "State Constrained Model Reference Adaptive Control with Input Amplitude and Rate Limits",
    "authors": [
      "Poulomee Ghosh",
      "Shubhendu Bhasin"
    ],
    "abstract": "This paper proposes a robust model reference adaptive controller (MRAC) for\nuncertain multi-input multi-output (MIMO) linear time-invariant (LTI) plants\nwith user-defined constraints on the plant states, input amplitude, and input\nrate. The proposed two-layer barrier Lyapunov function (BLF)-based control\ndesign considers the input and the input rate as states that are constrained\nusing two BLFs in the first layer, while another BLF in the second layer\nconstrains the plant states. The adaptive control law ensures that the plant\nstates, input amplitude, and input rate remain within the user-defined safe\nsets despite unmatched bounded disturbances. Sufficient conditions for the\nexistence of a feasible control policy are also provided. To the best of the\nauthors' knowledge, this is the first optimization-free method that imposes\nuser-defined constraints on the state, input, and input rate and also provides\nverifiable feasibility conditions in the presence of parametric uncertainties\nand disturbances. Simulation results demonstrate the effectiveness of the\nproposed algorithm.",
    "pdf_url": "http://arxiv.org/pdf/2505.22346v1",
    "published": "2025-05-28T13:28:39+00:00",
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2505.22345v1",
    "title": "A Systematic Approach for Studying How Topological Measurements Respond to Complex Networks Modifications",
    "authors": [
      "Alexandre Benatti",
      "Roberto M. Cesar Jr.",
      "Luciano da F. Costa"
    ],
    "abstract": "Different types of graphs and complex networks have been characterized,\nanalyzed, and modeled based on measurements of their respective topology.\nHowever, the available networks may constitute approximations of the original\nstructure as a consequence of sampling incompleteness, noise, and/or error in\nthe representation of that structure. Therefore, it becomes of particular\ninterest to quantify how successive modifications may impact a set of adopted\ntopological measurements, and how respectively undergone changes can be\ninterrelated, which has been addressed in this paper by considering similarity\nnetworks and hierarchical clustering approaches. These studies are developed\nrespectively to several topological measurements (accessibility, degree,\nhierarchical degree, clustering coefficient, betweenness centrality,\nassortativity, and average shortest path) calculated from complex networks of\nthree main types (Erd\\H{o}s-R\\'enyi, Barab\\'asi-Albert, and geographical) with\nvarying sizes or subjected to progressive edge removal or rewiring. The\ncoincidence similarity index, which can implement particularly strict\ncomparisons, is adopted for two main purposes: to quantify and visualize how\nthe considered topological measurements respond to the considered network\nalterations and to represent hierarchically the relationships between the\nobserved changes undergone by the considered topological measurements. Several\nresults are reported and discussed, including the identification of three types\nof topological changes taking place as a consequence of the modifications. In\naddition, the changes observed for the Erd\\H{o}s-R\\'enyi and Barab\\'asi-Albert\nnetworks resulted mutually more similarly affected by topological changes than\nfor the geometrical networks. The latter type of network has been identified to\nhave more heterogeneous topological features than the other two types of\nnetworks.",
    "pdf_url": "http://arxiv.org/pdf/2505.22345v1",
    "published": "2025-05-28T13:27:49+00:00",
    "categories": [
      "cs.SI",
      "physics.soc-ph"
    ],
    "primary_category": "cs.SI"
  },
  {
    "id": "http://arxiv.org/abs/2505.22344v1",
    "title": "Task-Driven Implicit Representations for Automated Design of LiDAR Systems",
    "authors": [
      "Nikhil Behari",
      "Aaron Young",
      "Akshat Dave",
      "Ramesh Raskar"
    ],
    "abstract": "Imaging system design is a complex, time-consuming, and largely manual\nprocess; LiDAR design, ubiquitous in mobile devices, autonomous vehicles, and\naerial imaging platforms, adds further complexity through unique spatial and\ntemporal sampling requirements. In this work, we propose a framework for\nautomated, task-driven LiDAR system design under arbitrary constraints. To\nachieve this, we represent LiDAR configurations in a continuous six-dimensional\ndesign space and learn task-specific implicit densities in this space via\nflow-based generative modeling. We then synthesize new LiDAR systems by\nmodeling sensors as parametric distributions in 6D space and fitting these\ndistributions to our learned implicit density using expectation-maximization,\nenabling efficient, constraint-aware LiDAR system design. We validate our\nmethod on diverse tasks in 3D vision, enabling automated LiDAR system design\nacross real-world-inspired applications in face scanning, robotic tracking, and\nobject detection.",
    "pdf_url": "http://arxiv.org/pdf/2505.22344v1",
    "published": "2025-05-28T13:27:42+00:00",
    "categories": [
      "cs.CV",
      "cs.RO"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.22343v2",
    "title": "Empowering Intelligent Low-altitude Economy with Large AI Model Deployment",
    "authors": [
      "Zhonghao Lyu",
      "Yulan Gao",
      "Junting Chen",
      "Hongyang Du",
      "Jie Xu",
      "Kaibin Huang",
      "Dong In Kim"
    ],
    "abstract": "Low-altitude economy (LAE) represents an emerging economic paradigm that\nredefines commercial and social aerial activities. Large artificial\nintelligence models (LAIMs) offer transformative potential to further enhance\nthe intelligence of LAE services. However, deploying LAIMs in LAE poses several\nchallenges, including the significant gap between their computational/storage\ndemands and the limited onboard resources of LAE entities, the mismatch between\nlab-trained LAIMs and dynamic physical environments, and the inefficiencies of\ntraditional decoupled designs for sensing, communication, and computation. To\naddress these issues, we first propose a hierarchical system architecture\ntailored for LAIM deployment and present representative LAE application\nscenarios. Next, we explore key enabling techniques that facilitate the mutual\nco-evolution of LAIMs and low-altitude systems, and introduce a task-oriented\nexecution pipeline for scalable and adaptive service delivery. Then, the\nproposed framework is validated through real-world case studies. Finally, we\noutline open challenges to inspire future research.",
    "pdf_url": "http://arxiv.org/pdf/2505.22343v2",
    "published": "2025-05-28T13:27:07+00:00",
    "categories": [
      "eess.SP",
      "cs.AI"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2505.22342v2",
    "title": "Progressive Data Dropout: An Embarrassingly Simple Approach to Faster Training",
    "authors": [
      "Shriram M S",
      "Xinyue Hao",
      "Shihao Hou",
      "Yang Lu",
      "Laura Sevilla-Lara",
      "Anurag Arnab",
      "Shreyank N Gowda"
    ],
    "abstract": "The success of the machine learning field has reliably depended on training\non large datasets. While effective, this trend comes at an extraordinary cost.\nThis is due to two deeply intertwined factors: the size of models and the size\nof datasets. While promising research efforts focus on reducing the size of\nmodels, the other half of the equation remains fairly mysterious. Indeed, it is\nsurprising that the standard approach to training remains to iterate over and\nover, uniformly sampling the training dataset. In this paper we explore a\nseries of alternative training paradigms that leverage insights from\nhard-data-mining and dropout, simple enough to implement and use that can\nbecome the new training standard. The proposed Progressive Data Dropout reduces\nthe number of effective epochs to as little as 12.4% of the baseline. This\nsavings actually do not come at any cost for accuracy. Surprisingly, the\nproposed method improves accuracy by up to 4.82%. Our approach requires no\nchanges to model architecture or optimizer, and can be applied across standard\ntraining pipelines, thus posing an excellent opportunity for wide adoption.\nCode can be found here: https://github.com/bazyagami/LearningWithRevision",
    "pdf_url": "http://arxiv.org/pdf/2505.22342v2",
    "published": "2025-05-28T13:26:52+00:00",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.22341v1",
    "title": "Black Bounces in $f(Q)$ Gravity with Magnetic Source",
    "authors": [
      "Pƒ±nar Kirezli",
      "Doƒüukan Ta≈üer"
    ],
    "abstract": "In this study, the source of the black bounce is discussed in the context of\n$f(Q)$ theory. A body of research has been dedicated to the study of symmetric\nblack bounce solutions that are generated by a combination of a scalar field\nwith a non-zero potential and a magnetic charge within the framework of\nnon-linear electrodynamics. As exact solutions are not obtained, the metric\nfunctions of Simpson-Visser and Bardeen type of black bounce are studied in the\nfield equations. black bounce solutions are obtained by violating at least one\nenergy condition for the Simpson-Visser and Bardeen type for an ordinary scalar\nfield in $f(Q)$ gravity, which is only achieved by a phantom scalar field in\ngeneral relativity.",
    "pdf_url": "http://arxiv.org/pdf/2505.22341v1",
    "published": "2025-05-28T13:26:10+00:00",
    "categories": [
      "gr-qc"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2505.22340v1",
    "title": "The Huang-Yang conjecture for the low-density Fermi gas",
    "authors": [
      "Emanuela L. Giacomelli",
      "Christian Hainzl",
      "Phan Th√†nh Nam",
      "Robert Seiringer"
    ],
    "abstract": "Our work establishes a three-term asymptotic expansion of the ground state\nenergy of a dilute gas of spin $1/2$ fermions with repulsive short-range\ninteractions, validating a formula predicted by Huang and Yang in 1957. The\nformula is universal in the sense that it holds for a large class of\ninteraction potentials and depends on those only via their scattering length.\nWe have recently proved an upper bound on the ground state energy of the\ndesired form, and the present work completes the program by proving the\nmatching lower bound.",
    "pdf_url": "http://arxiv.org/pdf/2505.22340v1",
    "published": "2025-05-28T13:25:07+00:00",
    "categories": [
      "math-ph",
      "math.MP"
    ],
    "primary_category": "math-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.22339v1",
    "title": "The Dirichlet problem for Hessian quotient type curvature equations in Minkowski space",
    "authors": [
      "Mengru Guo",
      "Yang Jiao"
    ],
    "abstract": "In this paper, we consider the Dirichlet problem for a class of prescribed\nHessian quotient type curvature equations in Minkowski space. By establishing\nthe a priori C2 estimates, we prove the existence of smooth spacelike\nhypersurfaces with a class of prescribed Hessian quotient type curvature and\nhomogeneous boundary data in the non-degenerate case.",
    "pdf_url": "http://arxiv.org/pdf/2505.22339v1",
    "published": "2025-05-28T13:24:03+00:00",
    "categories": [
      "math.AP",
      "math.DG"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2505.22338v1",
    "title": "Text2Grad: Reinforcement Learning from Natural Language Feedback",
    "authors": [
      "Hanyang Wang",
      "Lu Wang",
      "Chaoyun Zhang",
      "Tianjun Mao",
      "Si Qin",
      "Qingwei Lin",
      "Saravan Rajmohan",
      "Dongmei Zhang"
    ],
    "abstract": "Traditional RLHF optimizes language models with coarse, scalar rewards that\nmask the fine-grained reasons behind success or failure, leading to slow and\nopaque learning. Recent work augments RL with textual critiques through\nprompting or reflection, improving interpretability but leaving model\nparameters untouched. We introduce Text2Grad, a reinforcement-learning paradigm\nthat turns free-form textual feedback into span-level gradients. Given human\n(or programmatic) critiques, Text2Grad aligns each feedback phrase with the\nrelevant token spans, converts these alignments into differentiable reward\nsignals, and performs gradient updates that directly refine the offending\nportions of the model's policy. This yields precise, feedback-conditioned\nadjustments instead of global nudges. Text2Grad is realized through three\ncomponents: (1) a high-quality feedback-annotation pipeline that pairs\ncritiques with token spans; (2) a fine-grained reward model that predicts\nspan-level reward on answer while generating explanatory critiques; and (3) a\nspan-level policy optimizer that back-propagates natural-language gradients.\nAcross summarization, code generation, and question answering, Text2Grad\nconsistently surpasses scalar-reward RL and prompt-only baselines, providing\nboth higher task metrics and richer interpretability. Our results demonstrate\nthat natural-language feedback, when converted to gradients, is a powerful\nsignal for fine-grained policy optimization. The code for our method is\navailable at https://github.com/microsoft/Text2Grad",
    "pdf_url": "http://arxiv.org/pdf/2505.22338v1",
    "published": "2025-05-28T13:23:49+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.22337v1",
    "title": "Learning to Infer Parameterized Representations of Plants from 3D Scans",
    "authors": [
      "Samara Ghrer",
      "Christophe Godin",
      "Stefanie Wuhrer"
    ],
    "abstract": "Reconstructing faithfully the 3D architecture of plants from unstructured\nobservations is a challenging task. Plants frequently contain numerous organs,\norganized in branching systems in more or less complex spatial networks,\nleading to specific computational issues due to self-occlusion or spatial\nproximity between organs. Existing works either consider inverse modeling where\nthe aim is to recover the procedural rules that allow to simulate virtual\nplants, or focus on specific tasks such as segmentation or skeletonization. We\npropose a unified approach that, given a 3D scan of a plant, allows to infer a\nparameterized representation of the plant. This representation describes the\nplant's branching structure, contains parametric information for each plant\norgan, and can therefore be used directly in a variety of tasks. In this\ndata-driven approach, we train a recursive neural network with virtual plants\ngenerated using an L-systems-based procedural model. After training, the\nnetwork allows to infer a parametric tree-like representation based on an input\n3D point cloud. Our method is applicable to any plant that can be represented\nas binary axial tree. We evaluate our approach on Chenopodium Album plants,\nusing experiments on synthetic plants to show that our unified framework allows\nfor different tasks including reconstruction, segmentation and skeletonization,\nwhile achieving results on-par with state-of-the-art for each task.",
    "pdf_url": "http://arxiv.org/pdf/2505.22337v1",
    "published": "2025-05-28T13:23:48+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.23838v1",
    "title": "Exploring the Landscape of Text-to-SQL with Large Language Models: Progresses, Challenges and Opportunities",
    "authors": [
      "Yiming Huang",
      "Jiyu Guo",
      "Wenxin Mao",
      "Cuiyun Gao",
      "Peiyi Han",
      "Chuanyi Liu",
      "Qing Ling"
    ],
    "abstract": "Converting natural language (NL) questions into SQL queries, referred to as\nText-to-SQL, has emerged as a pivotal technology for facilitating access to\nrelational databases, especially for users without SQL knowledge. Recent\nprogress in large language models (LLMs) has markedly propelled the field of\nnatural language processing (NLP), opening new avenues to improve text-to-SQL\nsystems. This study presents a systematic review of LLM-based text-to-SQL,\nfocusing on four key aspects: (1) an analysis of the research trends in\nLLM-based text-to-SQL; (2) an in-depth analysis of existing LLM-based\ntext-to-SQL techniques from diverse perspectives; (3) summarization of existing\ntext-to-SQL datasets and evaluation metrics; and (4) discussion on potential\nobstacles and avenues for future exploration in this domain. This survey seeks\nto furnish researchers with an in-depth understanding of LLM-based text-to-SQL,\nsparking new innovations and advancements in this field.",
    "pdf_url": "http://arxiv.org/pdf/2505.23838v1",
    "published": "2025-05-28T13:23:38+00:00",
    "categories": [
      "cs.CL",
      "cs.IR"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.22336v1",
    "title": "Spiderwebs on the Sphere and an Isoperimetric Theorem",
    "authors": [
      "Robert Connelly",
      "Zhen Zhang"
    ],
    "abstract": "Here we present a rigidity result in a global (semi-global, homotopy) setting\nfor a restrictive class of polytopes, those that can be inscribed in a unit\nsphere, with some additional conditions. The proof of the rigidity result for\ncabled frameworks on the surface of the sphere uses classical isoperimetric\nideas.",
    "pdf_url": "http://arxiv.org/pdf/2505.22336v1",
    "published": "2025-05-28T13:23:32+00:00",
    "categories": [
      "math.MG",
      "52C25, 52C07, 51FXX"
    ],
    "primary_category": "math.MG"
  },
  {
    "id": "http://arxiv.org/abs/2505.22335v1",
    "title": "UP-SLAM: Adaptively Structured Gaussian SLAM with Uncertainty Prediction in Dynamic Environments",
    "authors": [
      "Wancai Zheng",
      "Linlin Ou",
      "Jiajie He",
      "Libo Zhou",
      "Xinyi Yu",
      "Yan Wei"
    ],
    "abstract": "Recent 3D Gaussian Splatting (3DGS) techniques for Visual Simultaneous\nLocalization and Mapping (SLAM) have significantly progressed in tracking and\nhigh-fidelity mapping. However, their sequential optimization framework and\nsensitivity to dynamic objects limit real-time performance and robustness in\nreal-world scenarios. We present UP-SLAM, a real-time RGB-D SLAM system for\ndynamic environments that decouples tracking and mapping through a parallelized\nframework. A probabilistic octree is employed to manage Gaussian primitives\nadaptively, enabling efficient initialization and pruning without hand-crafted\nthresholds. To robustly filter dynamic regions during tracking, we propose a\ntraining-free uncertainty estimator that fuses multi-modal residuals to\nestimate per-pixel motion uncertainty, achieving open-set dynamic object\nhandling without reliance on semantic labels. Furthermore, a temporal encoder\nis designed to enhance rendering quality. Concurrently, low-dimensional\nfeatures are efficiently transformed via a shallow multilayer perceptron to\nconstruct DINO features, which are then employed to enrich the Gaussian field\nand improve the robustness of uncertainty prediction. Extensive experiments on\nmultiple challenging datasets suggest that UP-SLAM outperforms state-of-the-art\nmethods in both localization accuracy (by 59.8%) and rendering quality (by 4.57\ndB PSNR), while maintaining real-time performance and producing reusable,\nartifact-free static maps in dynamic environments.The project:\nhttps://aczheng-cai.github.io/up_slam.github.io/",
    "pdf_url": "http://arxiv.org/pdf/2505.22335v1",
    "published": "2025-05-28T13:23:16+00:00",
    "categories": [
      "cs.RO",
      "cs.CV"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.22334v2",
    "title": "Advancing Multimodal Reasoning via Reinforcement Learning with Cold Start",
    "authors": [
      "Lai Wei",
      "Yuting Li",
      "Kaipeng Zheng",
      "Chen Wang",
      "Yue Wang",
      "Linghe Kong",
      "Lichao Sun",
      "Weiran Huang"
    ],
    "abstract": "Recent advancements in large language models (LLMs) have demonstrated\nimpressive chain-of-thought reasoning capabilities, with reinforcement learning\n(RL) playing a crucial role in this progress. While \"aha moment\"\npatterns--where models exhibit self-correction through reflection--are often\nattributed to emergent properties from RL, we first demonstrate that these\npatterns exist in multimodal LLMs (MLLMs) prior to RL training but may not\nnecessarily correlate with improved reasoning performance. Building on these\ninsights, we present a comprehensive study on enhancing multimodal reasoning\nthrough a two-stage approach: (1) supervised fine-tuning (SFT) as a cold start\nwith structured chain-of-thought reasoning patterns, followed by (2)\nreinforcement learning via GRPO to further refine these capabilities. Our\nextensive experiments show that this combined approach consistently outperforms\nboth SFT-only and RL-only methods across challenging multimodal reasoning\nbenchmarks. The resulting models achieve state-of-the-art performance among\nopen-source MLLMs at both 3B and 7B scales, with our 7B model showing\nsubstantial improvements over base models (e.g., 66.3 %$\\rightarrow$73.4 % on\nMathVista, 62.9 %$\\rightarrow$70.4 % on We-Math) and our 3B model achieving\nperformance competitive with several 7B models. Overall, this work provides\npractical guidance for building advanced multimodal reasoning models. Our code\nis available at https://github.com/waltonfuture/RL-with-Cold-Start.",
    "pdf_url": "http://arxiv.org/pdf/2505.22334v2",
    "published": "2025-05-28T13:21:38+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.22333v1",
    "title": "Acyclic toric sheaves",
    "authors": [
      "Klaus Altmann",
      "Andreas Hochenegger",
      "Frederik Witt"
    ],
    "abstract": "Let $\\mathcal E$ be a torus-linearised reflexive sheaf over a smooth\nprojective toric variety. Based on a theorem of Perlman-Smith, we prove an\nexplicit sufficient condition for $\\mathcal E$ to be acyclic via Weil\ndecorations.",
    "pdf_url": "http://arxiv.org/pdf/2505.22333v1",
    "published": "2025-05-28T13:20:31+00:00",
    "categories": [
      "math.AG",
      "14C20, 14F06, 14M25"
    ],
    "primary_category": "math.AG"
  },
  {
    "id": "http://arxiv.org/abs/2505.22332v1",
    "title": "Credal Prediction based on Relative Likelihood",
    "authors": [
      "Timo L√∂hr",
      "Paul Hofman",
      "Felix Mohr",
      "Eyke H√ºllermeier"
    ],
    "abstract": "Predictions in the form of sets of probability distributions, so-called\ncredal sets, provide a suitable means to represent a learner's epistemic\nuncertainty. In this paper, we propose a theoretically grounded approach to\ncredal prediction based on the statistical notion of relative likelihood: The\ntarget of prediction is the set of all (conditional) probability distributions\nproduced by the collection of plausible models, namely those models whose\nrelative likelihood exceeds a specified threshold. This threshold has an\nintuitive interpretation and allows for controlling the trade-off between\ncorrectness and precision of credal predictions. We tackle the problem of\napproximating credal sets defined in this way by means of suitably modified\nensemble learning techniques. To validate our approach, we illustrate its\neffectiveness by experiments on benchmark datasets demonstrating superior\nuncertainty representation without compromising predictive performance. We also\ncompare our method against several state-of-the-art baselines in credal\nprediction.",
    "pdf_url": "http://arxiv.org/pdf/2505.22332v1",
    "published": "2025-05-28T13:20:20+00:00",
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2505.22331v1",
    "title": "A Multi-output Gaussian Process Regression with Negative Transfer Mitigation for Generating Boundary Test Scenarios of Multi-UAV Systems",
    "authors": [
      "Hanxu Jiang",
      "Haiyue Yu",
      "Xiaotong Xie",
      "Qi Gao",
      "Jiang Jiang",
      "Jianbin Sun"
    ],
    "abstract": "Adaptive sampling based on Gaussian process regression (GPR) has already been\napplied with considerable success to generate boundary test scenarios for\nmulti-UAV systems (MUS). One of the key techniques in such researches is\nleveraging the accurate prediction of the MUS performance through GPR in\ndifferent test scenarios. Due to the potential correlations among the multiple\nMUS performance metrics, current researches commonly utilize a multi-output GPR\n(MOGPR) to model the multiple performance metrics simultaneously. This approach\ncan achieve a more accurate prediction, rather than modeling each metric\nindividually. However, MOGPR still suffers from negative transfer. When the\nfeature of one output variable is incorrectly learned by another, the models\ntraining process will be negatively affected, leading to a decline in\nprediction performance. To solve this problem, this paper proposes a novel\nadaptive regularization approach into the conventional MOGPR training process.\nUnlike existing regularization approaches for mitigating negative transfer in\nMOGPR, our method penalizes the inconsistencies among output-specific\ncharacteristic parameters using adaptively adjustable regularization weights.\nThis mechanism helps each set of output parameters avoid local optima.\nConsequently, it yields simultaneous improvements in predictive accuracy across\nall outputs. Finally, we validate our approach on a numerical case and on a\nboundary test scenario generation case for a MUS multi-objectives search task.",
    "pdf_url": "http://arxiv.org/pdf/2505.22331v1",
    "published": "2025-05-28T13:17:59+00:00",
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2505.22330v1",
    "title": "Model-free estimation of the Cram√©r-Rao bound for deep-learning microscopy in complex media",
    "authors": [
      "Ilya Starshynov",
      "Maximilian Weimar",
      "Lukas M. Rachbauer",
      "G√ºnther Hackl",
      "Daniele Faccio",
      "Stefan Rotter",
      "Dorian Bouchet"
    ],
    "abstract": "Artificial neural networks have become important tools to harness the\ncomplexity of disordered or random photonic systems. Recent applications\ninclude the recovery of information from light that has been scrambled during\npropagation through a complex scattering medium, especially in the challenging\ncase where the deterministic input-output transmission matrix cannot be\nmeasured. This naturally raises the question of what the limit is that\ninformation theory imposes on this recovery process, and whether neural\nnetworks can actually reach this limit. To answer these questions, we introduce\na model-free approach to calculate the Cram\\'er-Rao bound, which sets the\nultimate precision limit at which artificial neural networks can operate. As an\nexample, we apply this approach in a proof-of-principle experiment using laser\nlight propagating through a disordered medium, evidencing that a convolutional\nnetwork approaches the ultimate precision limit in the challenging task of\nlocalizing a reflective target hidden behind a dynamically-fluctuating\nscattering medium. The model-free method introduced here is generally\napplicable to benchmark the performance of any deep-learning microscope, to\ndrive algorithmic developments and to push the precision of metrology and\nimaging techniques to their ultimate limit.",
    "pdf_url": "http://arxiv.org/pdf/2505.22330v1",
    "published": "2025-05-28T13:17:52+00:00",
    "categories": [
      "physics.optics"
    ],
    "primary_category": "physics.optics"
  },
  {
    "id": "http://arxiv.org/abs/2505.22329v1",
    "title": "Finsler $p$-Laplacian in domains becoming unbounded",
    "authors": [
      "Luca Esposito",
      "Lorenzo Lamberti",
      "Dattatreya N. N.",
      "Prosenjit Roy"
    ],
    "abstract": "We study the asymptotic behavior of sequences of solutions, energies\nfunctionals, and the first eigenvalues associated with the Finsler $p$-Laplace\noperator, also known as the anisotropic $p$-Laplace operator on a sequence of\nbounded cylinders whose length tends to infinity. We prove that the solutions\non the bounded cylinders converge to the solution on the cross-section, with a\npolynomial rate of convergence in the general case and exponential convergence\nin some special cases. We show that energies on finite cylinders, with the\nmultiplication of a scaling factor, converge to the energy on the\ncross-section. Finally, we investigate the convergence of the first eigenvalue\nand, for a specific subclass, we provide the optimal convergence rate.",
    "pdf_url": "http://arxiv.org/pdf/2505.22329v1",
    "published": "2025-05-28T13:16:53+00:00",
    "categories": [
      "math.AP"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2505.22696v1",
    "title": "When Does Neuroevolution Outcompete Reinforcement Learning in Transfer Learning Tasks?",
    "authors": [
      "Eleni Nisioti",
      "Joachim Winther Pedersen",
      "Erwan Plantec",
      "Milton L. Montero",
      "Sebastian Risi"
    ],
    "abstract": "The ability to continuously and efficiently transfer skills across tasks is a\nhallmark of biological intelligence and a long-standing goal in artificial\nsystems. Reinforcement learning (RL), a dominant paradigm for learning in\nhigh-dimensional control tasks, is known to suffer from brittleness to task\nvariations and catastrophic forgetting. Neuroevolution (NE) has recently gained\nattention for its robustness, scalability, and capacity to escape local optima.\nIn this paper, we investigate an understudied dimension of NE: its transfer\nlearning capabilities. To this end, we introduce two benchmarks: a) in stepping\ngates, neural networks are tasked with emulating logic circuits, with designs\nthat emphasize modular repetition and variation b) ecorobot extends the Brax\nphysics engine with objects such as walls and obstacles and the ability to\neasily switch between different robotic morphologies. Crucial in both\nbenchmarks is the presence of a curriculum that enables evaluating skill\ntransfer across tasks of increasing complexity. Our empirical analysis shows\nthat NE methods vary in their transfer abilities and frequently outperform RL\nbaselines. Our findings support the potential of NE as a foundation for\nbuilding more adaptable agents and highlight future challenges for scaling NE\nto complex, real-world problems.",
    "pdf_url": "http://arxiv.org/pdf/2505.22696v1",
    "published": "2025-05-28T13:15:18+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.22328v1",
    "title": "Observation of resistive switching and diode effect in the conductivity of TiTe2 point contacts",
    "authors": [
      "O. E. Kvitnitskaya",
      "L. Harnagea",
      "O. D. Feia",
      "D. V. Efremov",
      "B. B√ºchner",
      "Yu. G. Naidyuk"
    ],
    "abstract": "We measured the I(V) and dV/dI(V) characteristics of TiTe2-based point\ncontacts (PCs) from room to helium temperatures. Features indicating the\nemergence of a charge density wave (CDW) were detected. They represent\nsymmetrical relatively V=0 maxima in dV/dI(V) around 150 mV at liquid helium\ntemperatures, which disappear above 150 K, similar to the case of sister CDW\ncompound TiSe2. Applying higher voltages above 200 mV, we observed resistive\nswitching in TiTe2 PCs from a metallic-like low-resistance state to\nnon-metallic type high-resistance state with a change of resistance by an order\nof magnitude. A unique diode-like effect was registered in \"soft\" TiTe2 PCs\nwith hysteretic I(V) at negative voltage on TiTe2. Discovering the resistive\nswitching and diode effect adds TiTe2 to the transition-metal dichalcogenides,\nwhich could be useful in developing non-volatile ReRAM and other upcoming\nnanotechnologies.",
    "pdf_url": "http://arxiv.org/pdf/2505.22328v1",
    "published": "2025-05-28T13:15:00+00:00",
    "categories": [
      "cond-mat.mes-hall"
    ],
    "primary_category": "cond-mat.mes-hall"
  },
  {
    "id": "http://arxiv.org/abs/2505.22695v1",
    "title": "LLM-ODDR: A Large Language Model Framework for Joint Order Dispatching and Driver Repositioning",
    "authors": [
      "Tengfei Lyu",
      "Siyuan Feng",
      "Hao Liu",
      "Hai Yang"
    ],
    "abstract": "Ride-hailing platforms face significant challenges in optimizing order\ndispatching and driver repositioning operations in dynamic urban environments.\nTraditional approaches based on combinatorial optimization, rule-based\nheuristics, and reinforcement learning often overlook driver income fairness,\ninterpretability, and adaptability to real-world dynamics. To address these\ngaps, we propose LLM-ODDR, a novel framework leveraging Large Language Models\n(LLMs) for joint Order Dispatching and Driver Repositioning (ODDR) in\nride-hailing services. LLM-ODDR framework comprises three key components: (1)\nMulti-objective-guided Order Value Refinement, which evaluates orders by\nconsidering multiple objectives to determine their overall value; (2)\nFairness-aware Order Dispatching, which balances platform revenue with driver\nincome fairness; and (3) Spatiotemporal Demand-Aware Driver Repositioning,\nwhich optimizes idle vehicle placement based on historical patterns and\nprojected supply. We also develop JointDR-GPT, a fine-tuned model optimized for\nODDR tasks with domain knowledge. Extensive experiments on real-world datasets\nfrom Manhattan taxi operations demonstrate that our framework significantly\noutperforms traditional methods in terms of effectiveness, adaptability to\nanomalous conditions, and decision interpretability. To our knowledge, this is\nthe first exploration of LLMs as decision-making agents in ride-hailing ODDR\ntasks, establishing foundational insights for integrating advanced language\nmodels within intelligent transportation systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.22695v1",
    "published": "2025-05-28T13:14:55+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.22327v1",
    "title": "NLP for Social Good: A Survey of Challenges, Opportunities, and Responsible Deployment",
    "authors": [
      "Antonia Karamolegkou",
      "Angana Borah",
      "Eunjung Cho",
      "Sagnik Ray Choudhury",
      "Martina Galletti",
      "Rajarshi Ghosh",
      "Pranav Gupta",
      "Oana Ignat",
      "Priyanka Kargupta",
      "Neema Kotonya",
      "Hemank Lamba",
      "Sun-Joo Lee",
      "Arushi Mangla",
      "Ishani Mondal",
      "Deniz Nazarova",
      "Poli Nemkova",
      "Dina Pisarevskaya",
      "Naquee Rizwan",
      "Nazanin Sabri",
      "Dominik Stammbach",
      "Anna Steinberg",
      "David Tom√°s",
      "Steven R Wilson",
      "Bowen Yi",
      "Jessica H Zhu",
      "Arkaitz Zubiaga",
      "Anders S√∏gaard",
      "Alexander Fraser",
      "Zhijing Jin",
      "Rada Mihalcea",
      "Joel R. Tetreault",
      "Daryna Dementieva"
    ],
    "abstract": "Recent advancements in large language models (LLMs) have unlocked\nunprecedented possibilities across a range of applications. However, as a\ncommunity, we believe that the field of Natural Language Processing (NLP) has a\ngrowing need to approach deployment with greater intentionality and\nresponsibility. In alignment with the broader vision of AI for Social Good\n(Toma\\v{s}ev et al., 2020), this paper examines the role of NLP in addressing\npressing societal challenges. Through a cross-disciplinary analysis of social\ngoals and emerging risks, we highlight promising research directions and\noutline challenges that must be addressed to ensure responsible and equitable\nprogress in NLP4SG research.",
    "pdf_url": "http://arxiv.org/pdf/2505.22327v1",
    "published": "2025-05-28T13:14:44+00:00",
    "categories": [
      "cs.CL",
      "cs.CY"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.22326v1",
    "title": "Individualised Counterfactual Examples Using Conformal Prediction Intervals",
    "authors": [
      "James M. Adams",
      "Gesine Reinert",
      "Lukasz Szpruch",
      "Carsten Maple",
      "Andrew Elliott"
    ],
    "abstract": "Counterfactual explanations for black-box models aim to pr ovide insight into\nan algorithmic decision to its recipient. For a binary classification problem\nan individual counterfactual details which features might be changed for the\nmodel to infer the opposite class. High-dimensional feature spaces that are\ntypical of machine learning classification models admit many possible\ncounterfactual examples to a decision, and so it is important to identify\nadditional criteria to select the most useful counterfactuals. In this paper,\nwe explore the idea that the counterfactuals should be maximally informative\nwhen considering the knowledge of a specific individual about the underlying\nclassifier. To quantify this information gain we explicitly model the knowledge\nof the individual, and assess the uncertainty of predictions which the\nindividual makes by the width of a conformal prediction interval. Regions of\nfeature space where the prediction interval is wide correspond to areas where\nthe confidence in decision making is low, and an additional counterfactual\nexample might be more informative to an individual. To explore and evaluate our\nindividualised conformal prediction interval counterfactuals (CPICFs), first we\npresent a synthetic data set on a hypercube which allows us to fully visualise\nthe decision boundary, conformal intervals via three different methods, and\nresultant CPICFs. Second, in this synthetic data set we explore the impact of a\nsingle CPICF on the knowledge of an individual locally around the original\nquery. Finally, in both our synthetic data set and a complex real world dataset\nwith a combination of continuous and discrete variables, we measure the utility\nof these counterfactuals via data augmentation, testing the performance on a\nheld out set.",
    "pdf_url": "http://arxiv.org/pdf/2505.22326v1",
    "published": "2025-05-28T13:13:52+00:00",
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2505.22325v1",
    "title": "Vector-valued Graph Signal Processing",
    "authors": [
      "Antonio Caputo"
    ],
    "abstract": "Classical graph signal processing (GSP) introduces methodologies for\nanalyzing real or complex signals defined on graph domains, moving beyond\nclassical uniform sampling techniques, such as the graph discrete Fourier\ntransform (GDFT), employed as a pivotal tool for transforming graph signals\ninto their spectral representation, enabling effective signal processing\ntechniques such as filtering and denoising. In this paper, we propose a\npossible generalization of the set of signals and we study some properties of\nthe more general set of vector-valued signals, which take values into any\nBanach space, and some properties of the fundamental operators of\nvertex-frequency analysis acting on these signals, such as the Fourier\ntransform, the convolution operator and the translation operator. In\nparticular, we show some estimates involving their operator norm as linear\noperators between Banach spaces and we establish a graph version of the\nclassical primary uncertainty principle. We also show how these estimates\ndepend on the choice of an orthonormal basis of $\\mathbb{K}^N$. The importance\nof considering this general set of signals derives from the possibility to\nstudy multiple signals at the same time and the correlation existing between\nthem, since multiple scalar signals can be modelled as a unique vector-valued\nsignal.",
    "pdf_url": "http://arxiv.org/pdf/2505.22325v1",
    "published": "2025-05-28T13:13:33+00:00",
    "categories": [
      "math.CA"
    ],
    "primary_category": "math.CA"
  },
  {
    "id": "http://arxiv.org/abs/2505.22324v1",
    "title": "Indirect Magnetoelectric Coupling via Skew Scattering by Orbital Angular Momentum",
    "authors": [
      "Adam B. Cahaya"
    ],
    "abstract": "Recent experimental observations of exchange bias in the\nLa$_{0.67}$Sr$_{0.33}$MnO$_{3}$/LaAlO$_{3}$/SrTiO$_{3}$ heterostructure, which\nlacks an intrinsic antiferromagnetic layer, have sparked theoretical\ninvestigations into the underlying mechanisms. While traditional theories\nsuggest that exchange bias in spin valve structures is mediated by conduction\nelectrons in metallic spacers, the transport properties of LaAlO$3$ are\ndominated by its valence electrons, raising new questions about the origin of\nthis phenomenon. In this work, we propose a theoretical model where the\nelectronic band structure of LaAlO$_3$ is treated as a valence band perturbed\nby skew scattering, which is sensitive to orbital angular momentum. Our\nanalysis reveals a significant magnetoelectric effect at the\nLa$_{0.67}$Sr$_{0.33}$MnO$_3$/LaAlO$_3$ interface, which induces a coupling\nbetween the interface magnetization and the electric field from two dimensional\nelectron gas at LaAlO$_{3}$/SrTiO$_{3}$ interface. This magnetoelectric\ncoupling is found to drive the observed exchange bias, highlighting the role of\nelectric polarization in influencing the magnetic properties of the\nheterostructure.",
    "pdf_url": "http://arxiv.org/pdf/2505.22324v1",
    "published": "2025-05-28T13:11:29+00:00",
    "categories": [
      "cond-mat.mtrl-sci",
      "cond-mat.mes-hall"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2505.22323v1",
    "title": "Advancing Expert Specialization for Better MoE",
    "authors": [
      "Hongcan Guo",
      "Haolang Lu",
      "Guoshun Nan",
      "Bolun Chu",
      "Jialin Zhuang",
      "Yuan Yang",
      "Wenhao Che",
      "Sicong Leng",
      "Qimei Cui",
      "Xudong Jiang"
    ],
    "abstract": "Mixture-of-Experts (MoE) models enable efficient scaling of large language\nmodels (LLMs) by activating only a subset of experts per input. However, we\nobserve that the commonly used auxiliary load balancing loss often leads to\nexpert overlap and overly uniform routing, which hinders expert specialization\nand degrades overall performance during post-training. To address this, we\npropose a simple yet effective solution that introduces two complementary\nobjectives: (1) an orthogonality loss to encourage experts to process distinct\ntypes of tokens, and (2) a variance loss to encourage more discriminative\nrouting decisions. Gradient-level analysis demonstrates that these objectives\nare compatible with the existing auxiliary loss and contribute to optimizing\nthe training process. Experimental results over various model architectures and\nacross multiple benchmarks show that our method significantly enhances expert\nspecialization. Notably, our method improves classic MoE baselines with\nauxiliary loss by up to 23.79%, while also maintaining load balancing in\ndownstream tasks, without any architectural modifications or additional\ncomponents. We will release our code to contribute to the community.",
    "pdf_url": "http://arxiv.org/pdf/2505.22323v1",
    "published": "2025-05-28T13:09:47+00:00",
    "categories": [
      "cs.CL",
      "cs.SE",
      "68T07",
      "I.2.7"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.22322v2",
    "title": "A Closer Look on Memorization in Tabular Diffusion Model: A Data-Centric Perspective",
    "authors": [
      "Zhengyu Fang",
      "Zhimeng Jiang",
      "Huiyuan Chen",
      "Xiaoge Zhang",
      "Kaiyu Tang",
      "Xiao Li",
      "Jing Li"
    ],
    "abstract": "Diffusion models have shown strong performance in generating high-quality\ntabular data, but they carry privacy risks by reproducing exact training\nsamples. While prior work focuses on dataset-level augmentation to reduce\nmemorization, little is known about which individual samples contribute most.\nWe present the first data-centric study of memorization dynamics in tabular\ndiffusion models. We quantify memorization for each real sample based on how\nmany generated samples are flagged as replicas, using a relative distance\nratio. Our empirical analysis reveals a heavy-tailed distribution of\nmemorization counts: a small subset of samples contributes disproportionately\nto leakage, confirmed via sample-removal experiments. To understand this, we\ndivide real samples into top- and non-top-memorized groups and analyze their\ntraining-time behaviors. We track when each sample is first memorized and\nmonitor per-epoch memorization intensity (AUC). Memorized samples are memorized\nslightly earlier and show stronger signals in early training. Based on these\ninsights, we propose DynamicCut, a two-stage, model-agnostic mitigation method:\n(a) rank samples by epoch-wise intensity, (b) prune a tunable top fraction, and\n(c) retrain on the filtered dataset. Across multiple tabular datasets and\nmodels, DynamicCut reduces memorization with minimal impact on data diversity\nand downstream performance. It also complements augmentation-based defenses.\nFurthermore, DynamicCut enables cross-model transferability: high-ranked\nsamples identified from one model (e.g., a diffusion model) are also effective\nfor reducing memorization when removed from others, such as GANs and VAEs.",
    "pdf_url": "http://arxiv.org/pdf/2505.22322v2",
    "published": "2025-05-28T13:06:00+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.22321v1",
    "title": "Generalized boundary triples for adjoint pairs with applications to non-self-adjoint Schr√∂dinger operators",
    "authors": [
      "Antonio Arnal",
      "Jussi Behrndt",
      "Markus Holzmann",
      "Petr Siegl"
    ],
    "abstract": "We extend the notion of generalized boundary triples and their Weyl functions\nfrom extension theory of symmetric operators to adjoint pairs of operators, and\nwe provide criteria on the boundary parameters to induce closed operators with\na nonempty resolvent set. The abstract results are applied to Schr\\\"odinger\noperators with complex $L^p$-potentials on bounded and unbounded Lipschitz\ndomains with compact boundaries.",
    "pdf_url": "http://arxiv.org/pdf/2505.22321v1",
    "published": "2025-05-28T13:05:28+00:00",
    "categories": [
      "math.SP",
      "math.AP",
      "math.FA"
    ],
    "primary_category": "math.SP"
  },
  {
    "id": "http://arxiv.org/abs/2505.22320v1",
    "title": "Chain-of-Thought for Large Language Model-empowered Wireless Communications",
    "authors": [
      "Xudong Wang",
      "Jian Zhu",
      "Ruichen Zhang",
      "Lei Feng",
      "Dusit Niyato",
      "Jiacheng Wang",
      "Hongyang Du",
      "Shiwen Mao",
      "Zhu Han"
    ],
    "abstract": "Recent advances in large language models (LLMs) have opened new possibilities\nfor automated reasoning and decision-making in wireless networks. However,\napplying LLMs to wireless communications presents challenges such as limited\ncapability in handling complex logic, generalization, and reasoning.\nChain-of-Thought (CoT) prompting, which guides LLMs to generate explicit\nintermediate reasoning steps, has been shown to significantly improve LLM\nperformance on complex tasks. Inspired by this, this paper explores the\napplication potential of CoT-enhanced LLMs in wireless communications.\nSpecifically, we first review the fundamental theory of CoT and summarize\nvarious types of CoT. We then survey key CoT and LLM techniques relevant to\nwireless communication and networking. Moreover, we introduce a multi-layer\nintent-driven CoT framework that bridges high-level user intent expressed in\nnatural language with concrete wireless control actions. Our proposed framework\nsequentially parses and clusters intent, selects appropriate CoT reasoning\nmodules via reinforcement learning, then generates interpretable control\npolicies for system configuration. Using the unmanned aerial vehicle (UAV)\nnetwork as a case study, we demonstrate that the proposed framework\nsignificantly outperforms a non-CoT baseline in both communication performance\nand quality of generated reasoning.",
    "pdf_url": "http://arxiv.org/pdf/2505.22320v1",
    "published": "2025-05-28T13:04:48+00:00",
    "categories": [
      "cs.NI"
    ],
    "primary_category": "cs.NI"
  },
  {
    "id": "http://arxiv.org/abs/2505.22319v1",
    "title": "Localization behavior in a Hermitian and non-Hermitian Raman lattice",
    "authors": [
      "Entong Zhao",
      "Yu-Jun Liu",
      "Ka Kwan Pak",
      "Peng Ren",
      "Mengbo Guo",
      "Chengdong He",
      "Gyu-Boong Jo"
    ],
    "abstract": "We introduce a flexible Raman lattice system for alakaline-earth like atoms\nto investigate localization behaviors in a quasi-periodic lattice with\ncontrollable non-Hermiticity. We demonstrate that critical phases and mobility\nedges can arise by adjusting spin-dependence of the incommensurate potentials\nin the Hermitian regime. With non-Hermiticity introduced by spin-selective atom\nloss, we find the localization behaviour in this system can be suppressed by\ndissipation. Our work provides insights into interplay between\nquasi-periodicity and non-Hermitian physics, offering a new perspective on\nlocalization phenomena.",
    "pdf_url": "http://arxiv.org/pdf/2505.22319v1",
    "published": "2025-05-28T13:04:00+00:00",
    "categories": [
      "cond-mat.quant-gas",
      "quant-ph"
    ],
    "primary_category": "cond-mat.quant-gas"
  },
  {
    "id": "http://arxiv.org/abs/2505.22318v1",
    "title": "If Pigs Could Fly... Can LLMs Logically Reason Through Counterfactuals?",
    "authors": [
      "Ishwar B Balappanawar",
      "Vamshi Krishna Bonagiri",
      "Anish R Joishy",
      "Manas Gaur",
      "Krishnaprasad Thirunarayan",
      "Ponnurangam Kumaraguru"
    ],
    "abstract": "Large Language Models (LLMs) demonstrate impressive reasoning capabilities in\nfamiliar contexts, but struggle when the context conflicts with their\nparametric knowledge. To investigate this phenomenon, we introduce\nCounterLogic, a dataset containing 1,800 examples across 9 logical schemas,\nexplicitly designed to evaluate logical reasoning through counterfactual\n(hypothetical knowledge-conflicting) scenarios. Our systematic evaluation of 11\nLLMs across 6 different datasets reveals a consistent performance degradation,\nwith accuracies dropping by 27% on average when reasoning through\ncounterfactual information. We propose Self-Segregate, a prompting method\nenabling metacognitive awareness (explicitly identifying knowledge conflicts)\nbefore reasoning. Our method dramatically narrows the average performance gaps\nfrom 27% to just 11%, while significantly increasing the overall accuracy\n(+7.5%). We discuss the implications of these findings and draw parallels to\nhuman cognitive processes, particularly on how humans disambiguate conflicting\ninformation during reasoning tasks. Our findings offer practical insights for\nunderstanding and enhancing LLMs reasoning capabilities in real-world\napplications, especially where models must logically reason independently of\ntheir factual knowledge.",
    "pdf_url": "http://arxiv.org/pdf/2505.22318v1",
    "published": "2025-05-28T13:03:18+00:00",
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.22317v1",
    "title": "Magnon thermal Hall effect in insulating antiferromagnets",
    "authors": [
      "Vladimir A. Zyuzin"
    ],
    "abstract": "In this paper we theoretically discuss thermal Hall effect of magnons in\ninsulating N\\'{e}el ordered antiferromagnets at zero external magnetic field.\nWe show that non-zero thermal Hall effect requires absence of any symmetry\nbetween the two sublattices. The thermal Hall effect of magnons will be\nnon-zero by a virtue of the spin-momentum splitting of the magnon spectrum due\nto the Dzyaloshinskii-Moriya interaction as well as anisotropic second-nearest\nexchange interaction different in the two sublattices, both corresponding to\nthe broken symmetry. We construct a theoretical model in which an external\nelectric field may change the symmetry of the antiferromagnetic system thus\naltering the thermal Hall effect of magnons.",
    "pdf_url": "http://arxiv.org/pdf/2505.22317v1",
    "published": "2025-05-28T13:01:18+00:00",
    "categories": [
      "cond-mat.mes-hall",
      "cond-mat.str-el"
    ],
    "primary_category": "cond-mat.mes-hall"
  },
  {
    "id": "http://arxiv.org/abs/2505.22316v1",
    "title": "Rethinking BPS: A Utility-Based Evaluation Framework",
    "authors": [
      "Konrad √ñzdemir",
      "Lukas Kirchdorfer",
      "Keyvan Amiri Elyasi",
      "Han van der Aa",
      "Heiner Stuckenschmidt"
    ],
    "abstract": "Business process simulation (BPS) is a key tool for analyzing and optimizing\norganizational workflows, supporting decision-making by estimating the impact\nof process changes. The reliability of such estimates depends on the ability of\na BPS model to accurately mimic the process under analysis, making rigorous\naccuracy evaluation essential. However, the state-of-the-art approach to\nevaluating BPS models has two key limitations. First, it treats simulation as a\nforecasting problem, testing whether models can predict unseen future events.\nThis fails to assess how well a model captures the as-is process, particularly\nwhen process behavior changes from train to test period. Thus, it becomes\ndifficult to determine whether poor results stem from an inaccurate model or\nthe inherent complexity of the data, such as unpredictable drift. Second, the\nevaluation approach strongly relies on Earth Mover's Distance-based metrics,\nwhich can obscure temporal patterns and thus yield misleading conclusions about\nsimulation quality. To address these issues, we propose a novel framework that\nevaluates simulation quality based on its ability to generate representative\nprocess behavior. Instead of comparing simulated logs to future real-world\nexecutions, we evaluate whether predictive process monitoring models trained on\nsimulated data perform comparably to those trained on real data for downstream\nanalysis tasks. Empirical results show that our framework not only helps\nidentify sources of discrepancies but also distinguishes between model accuracy\nand data complexity, offering a more meaningful way to assess BPS quality.",
    "pdf_url": "http://arxiv.org/pdf/2505.22316v1",
    "published": "2025-05-28T13:00:52+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.22315v2",
    "title": "Spin current compensation from competing magnon modes in ferrimagnets",
    "authors": [
      "Adam B. Cahaya"
    ],
    "abstract": "We investigate thermal spin pumping in gadolinium iron garnet (GdIG),\nfocusing on the mode-resolved dynamics of antiferromagnetic magnons and their\nimpact on spin and heat transport. Antiferromagnets support both right-handed\nand left-handed magnon modes, which we treat as positive and negative frequency\nbranches, analogous to electrons and holes in semiconductors. Using a\ntwo-sublattice model with a minimal exchange interaction scheme, we derive the\ntemperature-dependent spin-wave spectrum and evaluate the associated thermal\nspin pumping coefficients. Our analysis reveals that the competition between\nleft- and right-handed modes gives rise to a compensation temperature, where\nthe net thermally generated spin current vanishes. Importantly, we show that\nthis compensation point does not necessarily coincide with the crossing of\nmagnon dispersion branches. While previous research considers a detailed\nmicroscopic model including all magnetic sublattices and exchange couplings,\nour approach demonstrates that key features of mode-resolved spin transport can\nbe captured by a simplified and analytically transparent model. These findings\nadvance the understanding of spin-caloritronic phenomena in ferrimagnets and\noffer new perspectives for the design of chiral magnon-based spintronic\ndevices.",
    "pdf_url": "http://arxiv.org/pdf/2505.22315v2",
    "published": "2025-05-28T12:59:37+00:00",
    "categories": [
      "cond-mat.mes-hall",
      "cond-mat.stat-mech",
      "quant-ph"
    ],
    "primary_category": "cond-mat.mes-hall"
  },
  {
    "id": "http://arxiv.org/abs/2505.22314v1",
    "title": "Solar C/O ratio in planet-forming gas at 1 au in a highly irradiated disk",
    "authors": [
      "Ilane Schroetter",
      "Olivier Bern√©",
      "Emeric Bron",
      "Felipe Alarcon",
      "Paul Amiot",
      "Edwin A. Bergin",
      "Christiaan Boersma",
      "Jan Cami",
      "Gavin A. L. Coleman",
      "Emmanuel Dartois",
      "Asuncion Fuente",
      "Javier R. Goicoechea",
      "Emilie Habart",
      "Thomas J. Haworth",
      "Christine Joblin",
      "Franck Le Petit",
      "Takashi Onaka",
      "Els Peeters",
      "Markus R√∂lling",
      "Alexander G. G. M. Tielens",
      "Marion Zannese"
    ],
    "abstract": "The chemical composition of exoplanets is thought to be influenced by the\ncomposition of the disks in which they form. JWST observations have unveiled a\nvariety of species in numerous nearby disks, showing significant variations in\nthe C/O abundance ratio. However, little is known about the composition and C/O\nratio of disks around young stars in clusters exposed to strong ultraviolet\n(UV) radiation from nearby massive stars, which are representative of the\nenvironments where most planetary systems form, including ours. We present JWST\nspectroscopy of d203-504, a young 0.7 $\\rm M_{\\odot}$ star in the Orion Nebula\nwith a 30 au disk irradiated by nearby massive stars. These observations reveal\nspectroscopic signatures of CO, H$_2$O, CH$_3^+$, and PAHs. Water and CO are\ndetected in absorption in the inner disk ($r\\lesssim 1$ au), where the\nestimated gas-phase C/O ratio is 0.48, consistent with the Solar value and that\nof the Orion Nebula. In contrast, \\ch{CH3+} and PAHs are found in the extended\nsurface layers of the disk. These results suggest that gas in the inner disk is\nchemically shielded from UV radiation while the surface layers of the disk\nexperience UV-induced chemistry, potentially depleting their carbon content.",
    "pdf_url": "http://arxiv.org/pdf/2505.22314v1",
    "published": "2025-05-28T12:58:00+00:00",
    "categories": [
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2505.22313v1",
    "title": "Large-Area Fabrication-aware Computational Diffractive Optics",
    "authors": [
      "Kaixuan Wei",
      "Hector A. Jimenez-Romero",
      "Hadi Amata",
      "Jipeng Sun",
      "Qiang Fu",
      "Felix Heide",
      "Wolfgang Heidrich"
    ],
    "abstract": "Differentiable optics, as an emerging paradigm that jointly optimizes optics\nand (optional) image processing algorithms, has made innovative optical designs\npossible across a broad range of applications. Many of these systems utilize\ndiffractive optical components (DOEs) for holography, PSF engineering, or\nwavefront shaping. Existing approaches have, however, mostly remained limited\nto laboratory prototypes, owing to a large quality gap between simulation and\nmanufactured devices. We aim at lifting the fundamental technical barriers to\nthe practical use of learned diffractive optical systems. To this end, we\npropose a fabrication-aware design pipeline for diffractive optics fabricated\nby direct-write grayscale lithography followed by nano-imprinting replication,\nwhich is directly suited for inexpensive mass production of large area designs.\nWe propose a super-resolved neural lithography model that can accurately\npredict the 3D geometry generated by the fabrication process. This model can be\nseamlessly integrated into existing differentiable optics frameworks, enabling\nfabrication-aware, end-to-end optimization of computational optical systems. To\ntackle the computational challenges, we also devise tensor-parallel compute\nframework centered on distributing large-scale FFT computation across many\nGPUs. As such, we demonstrate large scale diffractive optics designs up to\n32.16 mm $\\times$ 21.44 mm, simulated on grids of up to 128,640 by 85,760\nfeature points. We find adequate agreement between simulation and fabricated\nprototypes for applications such as holography and PSF engineering. We also\nachieve high image quality from an imaging system comprised only of a single\nDOE, with images processed only by a Wiener filter utilizing the simulation\nPSF. We believe our findings lift the fabrication limitations for real-world\napplications of diffractive optics and differentiable optical design.",
    "pdf_url": "http://arxiv.org/pdf/2505.22313v1",
    "published": "2025-05-28T12:56:46+00:00",
    "categories": [
      "physics.optics",
      "cs.CV",
      "cs.ET",
      "cs.GR"
    ],
    "primary_category": "physics.optics"
  },
  {
    "id": "http://arxiv.org/abs/2505.22312v2",
    "title": "Skywork Open Reasoner 1 Technical Report",
    "authors": [
      "Jujie He",
      "Jiacai Liu",
      "Chris Yuhao Liu",
      "Rui Yan",
      "Chaojie Wang",
      "Peng Cheng",
      "Xiaoyu Zhang",
      "Fuxiang Zhang",
      "Jiacheng Xu",
      "Wei Shen",
      "Siyuan Li",
      "Liang Zeng",
      "Tianwen Wei",
      "Cheng Cheng",
      "Bo An",
      "Yang Liu",
      "Yahui Zhou"
    ],
    "abstract": "The success of DeepSeek-R1 underscores the significant role of reinforcement\nlearning (RL) in enhancing the reasoning capabilities of large language models\n(LLMs). In this work, we present Skywork-OR1, an effective and scalable RL\nimplementation for long Chain-of-Thought (CoT) models. Building on the\nDeepSeek-R1-Distill model series, our RL approach achieves notable performance\ngains, increasing average accuracy across AIME24, AIME25, and LiveCodeBench\nfrom 57.8% to 72.8% (+15.0%) for the 32B model and from 43.6% to 57.5% (+13.9%)\nfor the 7B model. Our Skywork-OR1-32B model surpasses both DeepSeek-R1 and\nQwen3-32B on the AIME24 and AIME25 benchmarks, while achieving comparable\nresults on LiveCodeBench. The Skywork-OR1-7B and Skywork-OR1-Math-7B models\ndemonstrate competitive reasoning capabilities among models of similar size. We\nperform comprehensive ablation studies on the core components of our training\npipeline to validate their effectiveness. Additionally, we thoroughly\ninvestigate the phenomenon of entropy collapse, identify key factors affecting\nentropy dynamics, and demonstrate that mitigating premature entropy collapse is\ncritical for improved test performance. To support community research, we fully\nopen-source our model weights, training code, and training datasets.",
    "pdf_url": "http://arxiv.org/pdf/2505.22312v2",
    "published": "2025-05-28T12:56:04+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.22311v1",
    "title": "From Large AI Models to Agentic AI: A Tutorial on Future Intelligent Communications",
    "authors": [
      "Feibo Jiang",
      "Cunhua Pan",
      "Li Dong",
      "Kezhi Wang",
      "Octavia A. Dobre",
      "Merouane Debbah"
    ],
    "abstract": "With the advent of 6G communications, intelligent communication systems face\nmultiple challenges, including constrained perception and response\ncapabilities, limited scalability, and low adaptability in dynamic\nenvironments. This tutorial provides a systematic introduction to the\nprinciples, design, and applications of Large Artificial Intelligence Models\n(LAMs) and Agentic AI technologies in intelligent communication systems, aiming\nto offer researchers a comprehensive overview of cutting-edge technologies and\npractical guidance. First, we outline the background of 6G communications,\nreview the technological evolution from LAMs to Agentic AI, and clarify the\ntutorial's motivation and main contributions. Subsequently, we present a\ncomprehensive review of the key components required for constructing LAMs. We\nfurther categorize LAMs and analyze their applicability, covering Large\nLanguage Models (LLMs), Large Vision Models (LVMs), Large Multimodal Models\n(LMMs), Large Reasoning Models (LRMs), and lightweight LAMs. Next, we propose a\nLAM-centric design paradigm tailored for communications, encompassing dataset\nconstruction and both internal and external learning approaches. Building upon\nthis, we develop an LAM-based Agentic AI system for intelligent communications,\nclarifying its core components such as planners, knowledge bases, tools, and\nmemory modules, as well as its interaction mechanisms. We also introduce a\nmulti-agent framework with data retrieval, collaborative planning, and\nreflective evaluation for 6G. Subsequently, we provide a detailed overview of\nthe applications of LAMs and Agentic AI in communication scenarios. Finally, we\nsummarize the research challenges and future directions in current studies,\naiming to support the development of efficient, secure, and sustainable\nnext-generation intelligent communication systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.22311v1",
    "published": "2025-05-28T12:54:07+00:00",
    "categories": [
      "cs.AI",
      "cs.CY",
      "cs.NI",
      "eess.SP"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.22310v1",
    "title": "From Dormant to Deleted: Tamper-Resistant Unlearning Through Weight-Space Regularization",
    "authors": [
      "Shoaib Ahmed Siddiqui",
      "Adrian Weller",
      "David Krueger",
      "Gintare Karolina Dziugaite",
      "Michael Curtis Mozer",
      "Eleni Triantafillou"
    ],
    "abstract": "Recent unlearning methods for LLMs are vulnerable to relearning attacks:\nknowledge believed-to-be-unlearned re-emerges by fine-tuning on a small set of\n(even seemingly-unrelated) examples. We study this phenomenon in a controlled\nsetting for example-level unlearning in vision classifiers. We make the\nsurprising discovery that forget-set accuracy can recover from around 50%\npost-unlearning to nearly 100% with fine-tuning on just the retain set -- i.e.,\nzero examples of the forget set. We observe this effect across a wide variety\nof unlearning methods, whereas for a model retrained from scratch excluding the\nforget set (gold standard), the accuracy remains at 50%. We observe that\nresistance to relearning attacks can be predicted by weight-space properties,\nspecifically, $L_2$-distance and linear mode connectivity between the original\nand the unlearned model. Leveraging this insight, we propose a new class of\nmethods that achieve state-of-the-art resistance to relearning attacks.",
    "pdf_url": "http://arxiv.org/pdf/2505.22310v1",
    "published": "2025-05-28T12:53:08+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.22309v1",
    "title": "Quantitative Tsirelson's Theorems via Approximate Schur's Lemma and Probabilistic Stampfli's Theorems",
    "authors": [
      "Xiangling Xu",
      "Marc-Olivier Renou",
      "Igor Klep"
    ],
    "abstract": "Tsirelson showed that, in finite dimensions, quantum correlations generated\nby commuting observables--measurements associated with distinct parties whose\noperators mutually commute--are equivalent to those obtainable from\nmeasurements on separate tensor product factors. We generalize this\nfoundational result to the setting of $\\epsilon$-almost commuting observables,\nestablishing two distinct quantitative approximate Tsirelson's theorems. Both\ntheorems show that if a $d$-dimensional bipartite quantum strategy's\nobservables $\\epsilon$-almost commute, then they are within $O(\\mathrm{poly}(d)\n\\epsilon)$ (in operator norm) of observables from a genuine tensor product\nstrategy. This provides a quantitative counterpart to the asymptotic result of\n[N. Ozawa, J. Math. Phys. 54, 032202 (2013)] and justifies the tensor product\nmodel as an effective model even when subsystem independence is only\napproximately satisfied.\n  Our theorems arise from two different but complementary formulations of\nalmost commutation: (i) The first approach utilizes deterministic operator norm\nbounds relative to specific matrix generators (such as clock and shift\nmatrices), leading to an approximate Schur's Lemma from which the first theorem\ndirectly follows. (ii) The second approach employs probabilistic bounds,\nrequiring small commutators only on average against Haar-random single-qubit\nunitaries. This method yields two novel probabilistic Stampfli's theorems,\nquantifying distance to scalars based on probabilistic commutation, a result\nwhich may be of independent interest. These theorems set the basis for the\nsecond approximate Tsirelson's theorem.",
    "pdf_url": "http://arxiv.org/pdf/2505.22309v1",
    "published": "2025-05-28T12:51:27+00:00",
    "categories": [
      "quant-ph",
      "math-ph",
      "math.MP"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.22308v1",
    "title": "Transformers Pretrained on Procedural Data Contain Modular Structures for Algorithmic Reasoning",
    "authors": [
      "Zachary Shinnick",
      "Liangze Jiang",
      "Hemanth Saratchandran",
      "Anton van den Hengel",
      "Damien Teney"
    ],
    "abstract": "Pretraining on large, semantically rich datasets is key for developing\nlanguage models. Surprisingly, recent studies have shown that even synthetic\ndata, generated procedurally through simple semantic-free algorithms, can yield\nsome of the same benefits as natural language pretraining. It is unclear what\nspecific capabilities such simple synthetic data instils in a model, where\nthese capabilities reside in the architecture, and how they manifest within its\nweights. In this short paper, we identify several beneficial forms of\nprocedural data, together with specific algorithmic reasoning skills that\nimprove in small transformers. Our core finding is that different procedural\nrules instil distinct but complementary inductive structures in the model. With\nextensive ablations and partial-transfer experiments, we discover that these\nstructures reside in different parts of the model. Attention layers often carry\nthe most transferable information, but some pretraining rules impart useful\nstructure to MLP blocks instead. Most interestingly, the structures induced by\nmultiple rules can be composed to jointly reinforce multiple capabilities.\nThese results suggest an exciting possibility of disentangling the acquisition\nof knowledge from reasoning in language models, with the goal of improving\ntheir robustness and data efficiency.",
    "pdf_url": "http://arxiv.org/pdf/2505.22308v1",
    "published": "2025-05-28T12:50:09+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.22307v2",
    "title": "On data usage and predictive behavior of data-driven predictive control with 1-norm regularization",
    "authors": [
      "Manuel Kl√§dtke",
      "Moritz Schulze Darup"
    ],
    "abstract": "We investigate the data usage and predictive behavior of data-driven\npredictive control (DPC) with 1-norm regularization. Our analysis enables the\noffline removal of unused data and facilitates a comparison between the\nidentified symmetric structure and data usage against prior knowledge of the\ntrue system. This comparison helps assess the suitability of the DPC scheme for\neffective control.",
    "pdf_url": "http://arxiv.org/pdf/2505.22307v2",
    "published": "2025-05-28T12:46:22+00:00",
    "categories": [
      "eess.SY",
      "cs.SY",
      "math.OC"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2505.22306v2",
    "title": "Versatile Cardiovascular Signal Generation with a Unified Diffusion Transformer",
    "authors": [
      "Zehua Chen",
      "Yuyang Miao",
      "Liyuan Wang",
      "Luyun Fan",
      "Danilo P. Mandic",
      "Jun Zhu"
    ],
    "abstract": "Cardiovascular signals such as photoplethysmography (PPG),\nelectrocardiography (ECG), and blood pressure (BP) are inherently correlated\nand complementary, together reflecting the health of cardiovascular system.\nHowever, their joint utilization in real-time monitoring is severely limited by\ndiverse acquisition challenges from noisy wearable recordings to burdened\ninvasive procedures. Here we propose UniCardio, a multi-modal diffusion\ntransformer that reconstructs low-quality signals and synthesizes unrecorded\nsignals in a unified generative framework. Its key innovations include a\nspecialized model architecture to manage the signal modalities involved in\ngeneration tasks and a continual learning paradigm to incorporate varying\nmodality combinations. By exploiting the complementary nature of cardiovascular\nsignals, UniCardio clearly outperforms recent task-specific baselines in signal\ndenoising, imputation, and translation. The generated signals match the\nperformance of ground-truth signals in detecting abnormal health conditions and\nestimating vital signs, even in unseen domains, while ensuring interpretability\nfor human experts. These advantages position UniCardio as a promising avenue\nfor advancing AI-assisted healthcare.",
    "pdf_url": "http://arxiv.org/pdf/2505.22306v2",
    "published": "2025-05-28T12:45:39+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.22305v1",
    "title": "IKIWISI: An Interactive Visual Pattern Generator for Evaluating the Reliability of Vision-Language Models Without Ground Truth",
    "authors": [
      "Md Touhidul Islam",
      "Imran Kabir",
      "Md Alimoor Reza",
      "Syed Masum Billah"
    ],
    "abstract": "We present IKIWISI (\"I Know It When I See It\"), an interactive visual pattern\ngenerator for assessing vision-language models in video object recognition when\nground truth is unavailable. IKIWISI transforms model outputs into a binary\nheatmap where green cells indicate object presence and red cells indicate\nobject absence. This visualization leverages humans' innate pattern recognition\nabilities to evaluate model reliability. IKIWISI introduces \"spy objects\":\nadversarial instances users know are absent, to discern models hallucinating on\nnonexistent items. The tool functions as a cognitive audit mechanism, surfacing\nmismatches between human and machine perception by visualizing where models\ndiverge from human understanding.\n  Our study with 15 participants found that users considered IKIWISI easy to\nuse, made assessments that correlated with objective metrics when available,\nand reached informed conclusions by examining only a small fraction of heatmap\ncells. This approach not only complements traditional evaluation methods\nthrough visual assessment of model behavior with custom object sets, but also\nreveals opportunities for improving alignment between human perception and\nmachine understanding in vision-language systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.22305v1",
    "published": "2025-05-28T12:41:08+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.22304v1",
    "title": "CADReview: Automatically Reviewing CAD Programs with Error Detection and Correction",
    "authors": [
      "Jiali Chen",
      "Xusen Hei",
      "HongFei Liu",
      "Yuancheng Wei",
      "Zikun Deng",
      "Jiayuan Xie",
      "Yi Cai",
      "Li Qing"
    ],
    "abstract": "Computer-aided design (CAD) is crucial in prototyping 3D objects through\ngeometric instructions (i.e., CAD programs). In practical design workflows,\ndesigners often engage in time-consuming reviews and refinements of these\nprototypes by comparing them with reference images. To bridge this gap, we\nintroduce the CAD review task to automatically detect and correct potential\nerrors, ensuring consistency between the constructed 3D objects and reference\nimages. However, recent advanced multimodal large language models (MLLMs)\nstruggle to recognize multiple geometric components and perform spatial\ngeometric operations within the CAD program, leading to inaccurate reviews. In\nthis paper, we propose the CAD program repairer (ReCAD) framework to\neffectively detect program errors and provide helpful feedback on error\ncorrection. Additionally, we create a dataset, CADReview, consisting of over\n20K program-image pairs, with diverse errors for the CAD review task. Extensive\nexperiments demonstrate that our ReCAD significantly outperforms existing\nMLLMs, which shows great potential in design applications.",
    "pdf_url": "http://arxiv.org/pdf/2505.22304v1",
    "published": "2025-05-28T12:41:00+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.22303v1",
    "title": "Voice CMS: updating the knowledge base of a digital assistant through conversation",
    "authors": [
      "Grzegorz Wolny",
      "Micha≈Ç Szczerbak"
    ],
    "abstract": "In this study, we propose a solution based on a multi-agent LLM architecture\nand a voice user interface (VUI) designed to update the knowledge base of a\ndigital assistant. Its usability is evaluated in comparison to a more\ntraditional graphical content management system (CMS), with a focus on\nunderstanding the relationship between user preferences and the complexity of\nthe information being provided. The findings demonstrate that, while the\noverall usability of the VUI is rated lower than the graphical interface, it is\nalready preferred by users for less complex tasks. Furthermore, the quality of\ncontent entered through the VUI is comparable to that achieved with the\ngraphical interface, even for highly complex tasks. Obtained qualitative\nresults suggest that a hybrid interface combining the strengths of both\napproaches could address the key challenges identified during the experiment,\nsuch as reducing cognitive load through graphical feedback while maintaining\nthe intuitive nature of voice-based interactions. This work highlights the\npotential of conversational interfaces as a viable and effective method for\nknowledge management in specific business contexts.",
    "pdf_url": "http://arxiv.org/pdf/2505.22303v1",
    "published": "2025-05-28T12:40:37+00:00",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2505.22302v1",
    "title": "Connecting the m-dots: accretion rates and thermonuclear burst recurrence times on neutron stars and white dwarfs",
    "authors": [
      "Triantafyllos Kormpakis",
      "Manuel Linares",
      "Jordi Jos√©"
    ],
    "abstract": "We present a compilation of observed recurrence times ($t_{\\rm rec}$) and\ninfer the corresponding local mass-accretion rates ($\\dot m$) for type I X-ray\nbursts, milliHertz quasi-periodic oscillating sources and recurrent novae\neruptions. We construct models of the $t_{\\rm rec}-\\dot m$ relation for\naccreting white dwarfs and neutron stars and find that both are roughly\nconsistent with a global inverse linear relation, connecting for the first time\nthermonuclear runaways on neutron stars and white dwarfs. We find that\ntheoretical models of pure He bursts are in agreement with the best $t_{\\rm\nrec}$ measurements in ultra-compact X-ray binaries at low $\\dot m$\n(4U~$0614+09$ and 2S~0918-549).\n  We suggest that the transient Z source XTE~J1701-462 is a slow rotator, based\non its mHz QPO properties. Finally, we discuss the implications for\nthermonuclear ignition and point out that the difference in eruption/burst\nenergy ($E_{b_{WD}}/E_{b_{NS}}=2\\times 10^4$) is consistent with the difference\nin area between neutron stars and white dwarfs $\\left((R_{WD}/R_{NS})^2=4\\times\n10^4\\right)$. We conclude that ignitions of thermonuclear shell flashes on\nneutron stars and white dwarfs depend primarily on the specific mass accretion\nrate and do not depend on the nature of the underlying compact object.",
    "pdf_url": "http://arxiv.org/pdf/2505.22302v1",
    "published": "2025-05-28T12:38:43+00:00",
    "categories": [
      "astro-ph.HE"
    ],
    "primary_category": "astro-ph.HE"
  },
  {
    "id": "http://arxiv.org/abs/2505.22301v1",
    "title": "Ageing correlators from local scale-invariance",
    "authors": [
      "Malte Henkel",
      "Stoimen Stoimenov"
    ],
    "abstract": "For ageing systems with dynamical exponent $\\mathpzc{z}=2$ and with the\ndominant noise coming from the thermal bath, the form of the two-time\nautocorrelator as well as the time-space form of the single-time correlator are\nderived from Schr\\\"odinger-invariance, generalised to non-equilibrium ageing.\nThese findings reproduce the exact results in the $1D$ Glauber-Ising model at\n$T=0$ and the critical spherical model in $d>2$ dimensions.",
    "pdf_url": "http://arxiv.org/pdf/2505.22301v1",
    "published": "2025-05-28T12:38:01+00:00",
    "categories": [
      "cond-mat.stat-mech",
      "hep-th",
      "math-ph",
      "math.MP"
    ],
    "primary_category": "cond-mat.stat-mech"
  },
  {
    "id": "http://arxiv.org/abs/2505.22300v1",
    "title": "Counting Small Induced Subgraphs: Scorpions Are Easy but Not Trivial",
    "authors": [
      "Radu Curticapean",
      "Simon D√∂ring",
      "Daniel Neuen"
    ],
    "abstract": "We consider the parameterized problem $\\#$IndSub$(\\Phi)$ for fixed graph\nproperties $\\Phi$: Given a graph $G$ and an integer $k$, this problem asks to\ncount the number of induced $k$-vertex subgraphs satisfying $\\Phi$. D\\\"orfler\net al. [Algorithmica 2022] and Roth et al. [SICOMP 2024] conjectured that\n$\\#$IndSub$(\\Phi)$ is $\\#$W[1]-hard for all non-meager properties $\\Phi$, i.e.,\nproperties that are nontrivial for infinitely many $k$. This conjecture has\nbeen confirmed for several restricted types of properties, including all\nhereditary properties [STOC 2022] and all edge-monotone properties [STOC 2024].\n  In this work, we refute this conjecture by showing that scorpion graphs,\ncertain $k$-vertex graphs which were introduced more than 50 years ago in the\ncontext of the evasiveness conjecture, can be counted in time $O(n^4)$ for all\n$k$. A simple variant of this construction results in graph properties that\nachieve arbitrary intermediate complexity assuming ETH.\n  We formulate an updated conjecture on the complexity of $\\#$IndSub$(\\Phi)$\nthat correctly captures the complexity status of scorpions and related\nconstructions.",
    "pdf_url": "http://arxiv.org/pdf/2505.22300v1",
    "published": "2025-05-28T12:37:30+00:00",
    "categories": [
      "cs.CC",
      "cs.DS"
    ],
    "primary_category": "cs.CC"
  },
  {
    "id": "http://arxiv.org/abs/2505.22299v2",
    "title": "Logical Consistency is Vital: Neural-Symbolic Information Retrieval for Negative-Constraint Queries",
    "authors": [
      "Ganlin Xu",
      "Zhoujia Zhang",
      "Wangyi Mei",
      "Jiaqing Liang",
      "Weijia Lu",
      "Xiaodong Zhang",
      "Zhifei Yang",
      "Xiaofeng Ma",
      "Yanghua Xiao",
      "Deqing Yang"
    ],
    "abstract": "Information retrieval plays a crucial role in resource localization. Current\ndense retrievers retrieve the relevant documents within a corpus via embedding\nsimilarities, which compute similarities between dense vectors mainly depending\non word co-occurrence between queries and documents, but overlook the real\nquery intents.\n  Thus, they often retrieve numerous irrelevant documents. Particularly in the\nscenarios of complex queries such as \\emph{negative-constraint queries}, their\nretrieval performance could be catastrophic. To address the issue, we propose a\nneuro-symbolic information retrieval method, namely \\textbf{NS-IR}, that\nleverages first-order logic (FOL) to optimize the embeddings of naive natural\nlanguage by considering the \\emph{logical consistency} between queries and\ndocuments. Specifically, we introduce two novel techniques, \\emph{logic\nalignment} and \\emph{connective constraint}, to rerank candidate documents,\nthereby enhancing retrieval relevance.\n  Furthermore, we construct a new dataset \\textbf{NegConstraint} including\nnegative-constraint queries to evaluate our NS-IR's performance on such complex\nIR scenarios.\n  Our extensive experiments demonstrate that NS-IR not only achieves superior\nzero-shot retrieval performance on web search and low-resource retrieval tasks,\nbut also performs better on negative-constraint queries. Our scource code and\ndataset are available at https://github.com/xgl-git/NS-IR-main.",
    "pdf_url": "http://arxiv.org/pdf/2505.22299v2",
    "published": "2025-05-28T12:37:09+00:00",
    "categories": [
      "cs.IR"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2505.22298v1",
    "title": "Adaptive Detoxification: Safeguarding General Capabilities of LLMs through Toxicity-Aware Knowledge Editing",
    "authors": [
      "Yifan Lu",
      "Jing Li",
      "Yigeng Zhou",
      "Yihui Zhang",
      "Wenya Wang",
      "Xiucheng Li",
      "Meishan Zhang",
      "Fangming Liu",
      "Jun Yu",
      "Min Zhang"
    ],
    "abstract": "Large language models (LLMs) exhibit impressive language capabilities but\nremain vulnerable to malicious prompts and jailbreaking attacks. Existing\nknowledge editing methods for LLM detoxification face two major challenges.\nFirst, they often rely on entity-specific localization, making them ineffective\nagainst adversarial inputs without explicit entities. Second, these methods\nsuffer from over-editing, where detoxified models reject legitimate queries,\ncompromising overall performance. In this paper, we propose ToxEdit, a\ntoxicity-aware knowledge editing approach that dynamically detects toxic\nactivation patterns during forward propagation. It then routes computations\nthrough adaptive inter-layer pathways to mitigate toxicity effectively. This\ndesign ensures precise toxicity mitigation while preserving LLMs' general\ncapabilities. To more accurately assess over-editing, we also enhance the\nSafeEdit benchmark by incorporating instruction-following evaluation tasks.\nExperimental results on multiple LLMs demonstrate that our ToxEdit outperforms\nprevious state-of-the-art methods in both detoxification performance and\nsafeguarding general capabilities of LLMs.",
    "pdf_url": "http://arxiv.org/pdf/2505.22298v1",
    "published": "2025-05-28T12:37:06+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.22297v1",
    "title": "Revealing the terahertz-laser velocity effect during air filamentation via travelling-wave-antenna model",
    "authors": [
      "Jiajun Yang",
      "Xiaofeng Li",
      "Linlin Yuan",
      "Li Lao",
      "Jiayu Zhao"
    ],
    "abstract": "During femtosecond laser filamentation in air, the velocity ratio (K) between\nthe terahertz (THz) phase velocity and the laser group velocity plays a crucial\nrole in THz waves generation. However, K is typically assumed to be unity and\nits impact has been long overlooked due to the more attention paid to the more\neasily controlled filament length. Here, we investigate the obscured\ncontribution of K to the THz radiation characteristics by using the improved\ntravelling-wave-antenna (TWA) model. It has been found that, under both single-\nand two-color laser pumping schemes, K significantly determines the far-field\nspatial distribution of forward or backward THz radiation, as well as a\ntransition from Bessel- to Cherenkov-type THz emission patterns. These results\nestablish the TWA model as a reliable theoretical tool for studying the\nmechanisms of THz beam shaping via the designed K. Moreover, for cases of K not\nbeing controlled, its value can also be inferred by the proposed TWA model,\nwhich could be an effective method to confirm whether the laser ionization\nfront is superluminal or subluminal compared with the generated THz waves.",
    "pdf_url": "http://arxiv.org/pdf/2505.22297v1",
    "published": "2025-05-28T12:36:05+00:00",
    "categories": [
      "physics.optics"
    ],
    "primary_category": "physics.optics"
  },
  {
    "id": "http://arxiv.org/abs/2505.22296v1",
    "title": "360-LLaMA-Factory: Plug & Play Sequence Parallelism for Long Post-Training",
    "authors": [
      "Haosheng Zou",
      "Xiaowei Lv",
      "Shousheng Jia",
      "Xiangzheng Zhang"
    ],
    "abstract": "Adding sequence parallelism into LLaMA-Factory, we open-sourced\n360-LLaMA-Factory at https://github.com/Qihoo360/360-LLaMA-Factory.\n360-LLaMA-Factory has received wide recognition and used in models such as\nLight-R1 arXiv:2503.10460, TinyR1 arXiv:2503.04872, Kaggle AIMO math models and\nalso in large companies' training frameworks. This technical report delves\ndeeper into the different sequence parallel modes behind 360-LLaMA-Factory and\ndiscusses our implementation insights.",
    "pdf_url": "http://arxiv.org/pdf/2505.22296v1",
    "published": "2025-05-28T12:33:46+00:00",
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.22295v1",
    "title": "Engineering Ge profiles in Si/SiGe heterostructures for increased valley splitting",
    "authors": [
      "Lucas E. A. Stehouwer",
      "Merrit P. Losert",
      "Maia Rigot",
      "Davide Degli Esposti",
      "Sara Mart√≠-S√°nchez",
      "Maximillian Rimbach-Russ",
      "Jordi Arbiol",
      "Mark Friesen",
      "Giordano Scappucci"
    ],
    "abstract": "Electron spin qubits in Si/SiGe quantum wells are limited by the small and\nvariable energy separation of the conduction band valleys. While sharp quantum\nwell interfaces are pursued to increase the valley splitting energy\ndeterministically, here we explore an alternative approach to enhance the\nvalley splitting on average. We grow increasingly thinner quantum wells with\nbroad interfaces to controllably increase the overlap of the electron wave\nfunction with Ge atoms. In these quantum wells, comprehensive quantum Hall\nmeasurements of two-dimensional electron gases reveal a linear correlation\nbetween valley splitting and disorder. Benchmarked against quantum wells with\nsharp interfaces, we demonstrate enhanced valley splitting while maintaining a\nlow-disorder potential environment. Simulations using the experimental Ge\nconcentration profiles predict an average valley splitting in quantum dots that\nmatches the enhancement observed in two-dimensional systems. Our results\nmotivate the experimental realization of quantum dot spin qubits in these\nheterostructures.",
    "pdf_url": "http://arxiv.org/pdf/2505.22295v1",
    "published": "2025-05-28T12:33:20+00:00",
    "categories": [
      "cond-mat.mes-hall"
    ],
    "primary_category": "cond-mat.mes-hall"
  },
  {
    "id": "http://arxiv.org/abs/2505.22294v1",
    "title": "Novel pathways in $k$-contact geometry",
    "authors": [
      "Tomasz Sobczak",
      "Tymon Frelik"
    ],
    "abstract": "Our study of Goursat distributions originates new types of $k$-contact\ndistributions and Lie systems with applications. In particular, families of\ngenerators for Goursat distributions on $\\mathbb{R}^4, \\mathbb{R}^5$ and\n$\\mathbb{R}^6$ give rise to Lie systems and we characterise Goursat structures\nthat are $k$-contact distributions. Our results are used to study the\nzero-trailer and other systems via Lie systems and $k$-contact manifolds. New\nideas for the development of superposition rules via geometric structures and\nthe characterisation of $k$-contact distributions are given and applied. Some\nrelations of $k$-contact geometry with parabolic Cartan geometries are\ninspected.",
    "pdf_url": "http://arxiv.org/pdf/2505.22294v1",
    "published": "2025-05-28T12:32:29+00:00",
    "categories": [
      "math.DG",
      "nlin.SI"
    ],
    "primary_category": "math.DG"
  },
  {
    "id": "http://arxiv.org/abs/2505.22694v1",
    "title": "MoRE: A Mixture of Low-Rank Experts for Adaptive Multi-Task Learning",
    "authors": [
      "Dacao Zhang",
      "Kun Zhang",
      "Shimao Chu",
      "Le Wu",
      "Xin Li",
      "Si Wei"
    ],
    "abstract": "With the rapid development of Large Language Models (LLMs),\nParameter-Efficient Fine-Tuning (PEFT) methods have gained significant\nattention, which aims to achieve efficient fine-tuning of LLMs with fewer\nparameters. As a representative PEFT method, Low-Rank Adaptation (LoRA)\nintroduces low-rank matrices to approximate the incremental tuning parameters\nand achieves impressive performance over multiple scenarios. After that, plenty\nof improvements have been proposed for further improvement. However, these\nmethods either focus on single-task scenarios or separately train multiple LoRA\nmodules for multi-task scenarios, limiting the efficiency and effectiveness of\nLoRA in multi-task scenarios. To better adapt to multi-task fine-tuning, in\nthis paper, we propose a novel Mixture of Low-Rank Experts (MoRE) for\nmulti-task PEFT. Specifically, instead of using an individual LoRA for each\ntask, we align different ranks of LoRA module with different tasks, which we\nnamed low-rank experts. Moreover, we design a novel adaptive rank selector to\nselect the appropriate expert for each task. By jointly training low-rank\nexperts, MoRE can enhance the adaptability and efficiency of LoRA in multi-task\nscenarios. Finally, we conduct extensive experiments over multiple multi-task\nbenchmarks along with different LLMs to verify model performance. Experimental\nresults demonstrate that compared to traditional LoRA and its variants, MoRE\nsignificantly improves the performance of LLMs in multi-task scenarios and\nincurs no additional inference cost. We also release the model and code to\nfacilitate the community.",
    "pdf_url": "http://arxiv.org/pdf/2505.22694v1",
    "published": "2025-05-28T12:32:09+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.23837v1",
    "title": "CoMaPOI: A Collaborative Multi-Agent Framework for Next POI Prediction Bridging the Gap Between Trajectory and Language",
    "authors": [
      "Lin Zhong",
      "Lingzhi Wang",
      "Xu Yang",
      "Qing Liao"
    ],
    "abstract": "Large Language Models (LLMs) offer new opportunities for the next\nPoint-Of-Interest (POI) prediction task, leveraging their capabilities in\nsemantic understanding of POI trajectories. However, previous LLM-based\nmethods, which are superficially adapted to next POI prediction, largely\noverlook critical challenges associated with applying LLMs to this task.\nSpecifically, LLMs encounter two critical challenges: (1) a lack of intrinsic\nunderstanding of numeric spatiotemporal data, which hinders accurate modeling\nof users' spatiotemporal distributions and preferences; and (2) an excessively\nlarge and unconstrained candidate POI space, which often results in random or\nirrelevant predictions. To address these issues, we propose a Collaborative\nMulti Agent Framework for Next POI Prediction, named CoMaPOI. Through the close\ninteraction of three specialized agents (Profiler, Forecaster, and Predictor),\nCoMaPOI collaboratively addresses the two critical challenges. The Profiler\nagent is responsible for converting numeric data into language descriptions,\nenhancing semantic understanding. The Forecaster agent focuses on dynamically\nconstraining and refining the candidate POI space. The Predictor agent\nintegrates this information to generate high-precision predictions. Extensive\nexperiments on three benchmark datasets (NYC, TKY, and CA) demonstrate that\nCoMaPOI achieves state of the art performance, improving all metrics by 5% to\n10% compared to SOTA baselines. This work pioneers the investigation of\nchallenges associated with applying LLMs to complex spatiotemporal tasks by\nleveraging tailored collaborative agents.",
    "pdf_url": "http://arxiv.org/pdf/2505.23837v1",
    "published": "2025-05-28T12:32:01+00:00",
    "categories": [
      "cs.CL",
      "cs.IR",
      "I.2.0"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.24548v1",
    "title": "Asymptotic version of the parametrix method for Markov chains converging to diffusions",
    "authors": [
      "I. Bitter",
      "V. Konakov"
    ],
    "abstract": "The paper presents a generalization of the local limit theorem on the\nconvergence of inhomogeneous Markov chains to the diffusion limit for the case\nwhere the corresponding process coefficients satisfy weak regularity conditions\nand coincide only asymptotically. In particular, the drift coefficients\nconsidered by us can be unbounded with at most linear growth, and the estimates\nreflect the transfer of the terminal state by an unbounded trend through the\ncorresponding deterministic flow. Our approach is based on the study of the\nuniform distance between the transition densities of a given inhomogeneous\nMarkov chain and the limit diffusion process, and the convergence rate estimate\nis obtained using the classical local limit theorem and parametrix-type\nstability estimates.",
    "pdf_url": "http://arxiv.org/pdf/2505.24548v1",
    "published": "2025-05-28T12:30:39+00:00",
    "categories": [
      "math.PR"
    ],
    "primary_category": "math.PR"
  },
  {
    "id": "http://arxiv.org/abs/2505.22293v1",
    "title": "Compensating for Data with Reasoning: Low-Resource Machine Translation with LLMs",
    "authors": [
      "Samuel Frontull",
      "Thomas Str√∂hle"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated strong capabilities in\nmultilingual machine translation, sometimes even outperforming traditional\nneural systems. However, previous research has highlighted the challenges of\nusing LLMs, particularly with prompt engineering, for low-resource languages.\nIn this work, we introduce Fragment-Shot Prompting, a novel in-context learning\nmethod that segments input and retrieves translation examples based on\nsyntactic coverage, along with Pivoted Fragment-Shot, an extension that enables\ntranslation without direct parallel data. We evaluate these methods using\nGPT-3.5, GPT-4o, o1-mini, LLaMA-3.3, and DeepSeek-R1 for translation between\nItalian and two Ladin variants, revealing three key findings: (1) Fragment-Shot\nPrompting is effective for translating into and between the studied\nlow-resource languages, with syntactic coverage positively correlating with\ntranslation quality; (2) Models with stronger reasoning abilities make more\neffective use of retrieved knowledge, generally produce better translations,\nand enable Pivoted Fragment-Shot to significantly improve translation quality\nbetween the Ladin variants; and (3) prompt engineering offers limited, if any,\nimprovements when translating from a low-resource to a high-resource language,\nwhere zero-shot prompting already yields satisfactory results. We publicly\nrelease our code and the retrieval corpora.",
    "pdf_url": "http://arxiv.org/pdf/2505.22293v1",
    "published": "2025-05-28T12:29:05+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.22292v1",
    "title": "A topological invariant in the context of the loop representation of the massive Kalb-Ramond-Klein-Gordon model",
    "authors": [
      "E. I√±iguez",
      "M. Freire",
      "L. Leal",
      "E. Contreras"
    ],
    "abstract": "We employ the Dirac procedure to quantize the self-dual massive\nKalb-Ramond-Klein-Gordon model in $2+1$ dimensional spacetimes. The canonical\nfields are expressed in terms of $2$-surfaces and signed points, ensuring the\nautomatic realization of the quantum algebra. As the duality rotation\npreserving the action can be implemented infinitesimally, we derive the\nconserved quantity that generates the transformation. Given that such a\ngenerator is a two dimensional topological quantity, its representation in\nterms of geometrical operators yields a two dimensional invariant (reminiscent\nof a projection of Gauss's law in electrodynamics), which encodes the same\ninformation of the well-known winding number.",
    "pdf_url": "http://arxiv.org/pdf/2505.22292v1",
    "published": "2025-05-28T12:28:53+00:00",
    "categories": [
      "hep-th"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2505.22291v2",
    "title": "Neural Restoration of Greening Defects in Historical Autochrome Photographs Based on Purely Synthetic Data",
    "authors": [
      "Saptarshi Neil Sinha",
      "P. Julius Kuehn",
      "Johannes Koppe",
      "Arjan Kuijper",
      "Michael Weinmann"
    ],
    "abstract": "The preservation of early visual arts, particularly color photographs, is\nchallenged by deterioration caused by aging and improper storage, leading to\nissues like blurring, scratches, color bleeding, and fading defects. Despite\ngreat advances in image restoration and enhancement in recent years, such\nsystematic defects often cannot be restored by current state-of-the-art\nsoftware features as available e.g. in Adobe Photoshop, but would require the\nincorporation of defect-aware priors into the underlying machine learning\ntechniques. However, there are no publicly available datasets of autochromes\nwith defect annotations. In this paper, we address these limitations and\npresent the first approach that allows the automatic removal of greening color\ndefects in digitized autochrome photographs. For this purpose, we introduce an\napproach for accurately simulating respective defects and use the respectively\nobtained synthesized data with its ground truth defect annotations to train a\ngenerative AI model with a carefully designed loss function that accounts for\ncolor imbalances between defected and non-defected areas. As demonstrated in\nour evaluation, our approach allows for the efficient and effective restoration\nof the considered defects, thereby overcoming limitations of alternative\ntechniques that struggle with accurately reproducing original colors and may\nrequire significant manual effort.",
    "pdf_url": "http://arxiv.org/pdf/2505.22291v2",
    "published": "2025-05-28T12:28:35+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.22290v1",
    "title": "Rethinking the Unsolvable: When In-Context Search Meets Test-Time Scaling",
    "authors": [
      "Fanzeng Xia",
      "Yidong Luo",
      "Tinko Sebastian Bartels",
      "Yaqi Xu",
      "Tongxin Li"
    ],
    "abstract": "Recent research has highlighted that Large Language Models (LLMs), even when\ntrained to generate extended long reasoning steps, still face significant\nchallenges on hard reasoning problems. However, much of the existing literature\nrelies on direct prompting with simple in-context learning examples for\nevaluation, which largely overlooks advanced techniques to elicit LLMs'\ndeliberate reasoning before drawing conclusions that LLMs hit a performance\nceiling. In this paper, we systematically explore the combined potential of\nin-context search and test-time scaling on super hard reasoning tasks. We find\nthat by employing advanced in-context search prompting to LLMs augmented with\ninternal scaling, one can achieve transformative performance breakthroughs on\ntasks previously deemed \"unsolvable\" (e.g., reported success rates below 5%).\nWe provide both empirical results and theoretical analysis of how this\ncombination can unleash LLM reasoning capabilities: i) Empirically, on\ncontrolled NP-hard tasks and complex real-world planning benchmarks, our\napproach achieves up to a 30x improvement in success rates compared to\npreviously reported results without any external mechanisms; ii) Theoretically,\nwe show that in-context search prompting, when combined with internal scaling,\nsignificantly extends the complexity class of solvable reasoning problems.\nThese findings challenge prevailing assumptions about the limitations of LLMs\non complex tasks, indicating that current evaluation paradigms systematically\nunderestimate their true potential. Our work calls for a critical reassessment\nof how LLM reasoning is benchmarked and a more robust evaluation strategy that\nfully captures the true capabilities of contemporary LLMs, which can lead to a\nbetter understanding of their operational reasoning boundaries in real-world\ndeployments.",
    "pdf_url": "http://arxiv.org/pdf/2505.22290v1",
    "published": "2025-05-28T12:28:18+00:00",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.22289v1",
    "title": "Network Model Averaging Prediction for Latent Space Models by K-Fold Edge Cross-Validation",
    "authors": [
      "Yan Zhang",
      "Jun Liao",
      "Xinyan Fan",
      "Kuangnan Fang",
      "Yuhong Yang"
    ],
    "abstract": "In complex systems, networks represent connectivity relationships between\nnodes through edges. Latent space models are crucial in analyzing network data\nfor tasks like community detection and link prediction due to their\ninterpretability and visualization capabilities. However, when the network size\nis relatively small, and the true latent space dimension is considerable, the\nparameters in latent space models may not be estimated very well. To address\nthis issue, we propose a Network Model Averaging (NetMA) method tailored for\nlatent space models with varying dimensions, specifically focusing on link\nprediction in networks. For both single-layer and multi-layer networks, we\nfirst establish the asymptotic optimality of the proposed averaging prediction\nin the sense of achieving the lowest possible prediction loss. Then we show\nthat when the candidate models contain some correct models, our method assigns\nall weights to the correct models. Furthermore, we demonstrate the consistency\nof the NetMA-based weight estimator tending to the optimal weight vector.\nExtensive simulation studies show that NetMA performs better than simple\naveraging and model selection methods, and even outperforms the \"oracle\" method\nwhen the real latent space dimension is relatively large. Evaluation on\ncollaboration and virtual event networks further emphasizes the competitiveness\nof NetMA in link prediction performance.",
    "pdf_url": "http://arxiv.org/pdf/2505.22289v1",
    "published": "2025-05-28T12:27:39+00:00",
    "categories": [
      "stat.ME"
    ],
    "primary_category": "stat.ME"
  },
  {
    "id": "http://arxiv.org/abs/2505.22288v2",
    "title": "Compression versus Accuracy: A Hierarchy of Lifted Models",
    "authors": [
      "Jan Speller",
      "Malte Luttermann",
      "Marcel Gehrke",
      "Tanya Braun"
    ],
    "abstract": "Probabilistic graphical models that encode indistinguishable objects and\nrelations among them use first-order logic constructs to compress a\npropositional factorised model for more efficient (lifted) inference. To obtain\na lifted representation, the state-of-the-art algorithm Advanced Colour Passing\n(ACP) groups factors that represent matching distributions. In an approximate\nversion using $\\varepsilon$ as a hyperparameter, factors are grouped that\ndiffer by a factor of at most $(1\\pm \\varepsilon)$. However, finding a suitable\n$\\varepsilon$ is not obvious and may need a lot of exploration, possibly\nrequiring many ACP runs with different $\\varepsilon$ values. Additionally,\nvarying $\\varepsilon$ can yield wildly different models, leading to decreased\ninterpretability. Therefore, this paper presents a hierarchical approach to\nlifted model construction that is hyperparameter-free. It efficiently computes\na hierarchy of $\\varepsilon$ values that ensures a hierarchy of models, meaning\nthat once factors are grouped together given some $\\varepsilon$, these factors\nwill be grouped together for larger $\\varepsilon$ as well. The hierarchy of\n$\\varepsilon$ values also leads to a hierarchy of error bounds. This allows for\nexplicitly weighing compression versus accuracy when choosing specific\n$\\varepsilon$ values to run ACP with and enables interpretability between the\ndifferent models.",
    "pdf_url": "http://arxiv.org/pdf/2505.22288v2",
    "published": "2025-05-28T12:27:32+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.22287v1",
    "title": "New Tools are Needed for Tracking Adherence to AI Model Behavioral Use Clauses",
    "authors": [
      "Daniel McDuff",
      "Tim Korjakow",
      "Kevin Klyman",
      "Danish Contractor"
    ],
    "abstract": "Foundation models have had a transformative impact on AI. A combination of\nlarge investments in research and development, growing sources of digital data\nfor training, and architectures that scale with data and compute has led to\nmodels with powerful capabilities. Releasing assets is fundamental to\nscientific advancement and commercial enterprise. However, concerns over\nnegligent or malicious uses of AI have led to the design of mechanisms to limit\nthe risks of the technology. The result has been a proliferation of licenses\nwith behavioral-use clauses and acceptable-use-policies that are increasingly\nbeing adopted by commonly used families of models (Llama, Gemma, Deepseek) and\na myriad of smaller projects. We created and deployed a custom AI licenses\ngenerator to facilitate license creation and have quantitatively and\nqualitatively analyzed over 300 customized licenses created with this tool.\nAlongside this we analyzed 1.7 million models licenses on the HuggingFace model\nhub. Our results show increasing adoption of these licenses, interest in tools\nthat support their creation and a convergence on common clause configurations.\nIn this paper we take the position that tools for tracking adoption of, and\nadherence to, these licenses is the natural next step and urgently needed in\norder to ensure they have the desired impact of ensuring responsible use.",
    "pdf_url": "http://arxiv.org/pdf/2505.22287v1",
    "published": "2025-05-28T12:26:55+00:00",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY"
  },
  {
    "id": "http://arxiv.org/abs/2506.00045v1",
    "title": "ACE-Step: A Step Towards Music Generation Foundation Model",
    "authors": [
      "Junmin Gong",
      "Sean Zhao",
      "Sen Wang",
      "Shengyuan Xu",
      "Joe Guo"
    ],
    "abstract": "We introduce ACE-Step, a novel open-source foundation model for music\ngeneration that overcomes key limitations of existing approaches and achieves\nstate-of-the-art performance through a holistic architectural design. Current\nmethods face inherent trade-offs between generation speed, musical coherence,\nand controllability. For example, LLM-based models (e.g. Yue, SongGen) excel at\nlyric alignment but suffer from slow inference and structural artifacts.\nDiffusion models (e.g. DiffRhythm), on the other hand, enable faster synthesis\nbut often lack long-range structural coherence. ACE-Step bridges this gap by\nintegrating diffusion-based generation with Sana's Deep Compression AutoEncoder\n(DCAE) and a lightweight linear transformer. It also leverages MERT and\nm-hubert to align semantic representations (REPA) during training, allowing\nrapid convergence. As a result, our model synthesizes up to 4 minutes of music\nin just 20 seconds on an A100 GPU-15x faster than LLM-based baselines-while\nachieving superior musical coherence and lyric alignment across melody,\nharmony, and rhythm metrics. Moreover, ACE-Step preserves fine-grained acoustic\ndetails, enabling advanced control mechanisms such as voice cloning, lyric\nediting, remixing, and track generation (e.g. lyric2vocal,\nsinging2accompaniment). Rather than building yet another end-to-end\ntext-to-music pipeline, our vision is to establish a foundation model for music\nAI: a fast, general-purpose, efficient yet flexible architecture that makes it\neasy to train subtasks on top of it. This paves the way for the development of\npowerful tools that seamlessly integrate into the creative workflows of music\nartists, producers, and content creators. In short, our goal is to build a\nstable diffusion moment for music. The code, the model weights and the demo are\navailable at: https://ace-step.github.io/.",
    "pdf_url": "http://arxiv.org/pdf/2506.00045v1",
    "published": "2025-05-28T12:23:09+00:00",
    "categories": [
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.SD"
  },
  {
    "id": "http://arxiv.org/abs/2505.22286v1",
    "title": "Wireless Communication for Low-Altitude Economy with UAV Swarm Enabled Two-Level Movable Antenna System",
    "authors": [
      "Haiquan Lu",
      "Yong Zeng",
      "Shaodan Ma",
      "Bin Li",
      "Shi Jin",
      "Rui Zhang"
    ],
    "abstract": "Unmanned aerial vehicle (UAV) is regarded as a key enabling platform for\nlow-altitude economy, due to its advantages such as 3D maneuverability,\nflexible deployment, and LoS air-to-air/ground communication links. In\nparticular, the intrinsic high mobility renders UAV especially suitable for\noperating as a movable antenna (MA) from the sky. In this paper, by exploiting\nthe flexible mobility of UAV swarm and antenna position adjustment of MA, we\npropose a novel UAV swarm enabled two-level MA system, where UAVs not only\nindividually deploy a local MA array, but also form a larger-scale MA system\nwith their individual MA arrays via swarm coordination. We formulate a general\noptimization problem to maximize the minimum achievable rate over all ground\nUEs, by jointly optimizing the 3D UAV swarm placement positions, their\nindividual MAs' positions, and receive beamforming for different UEs. We first\nconsider the special case where each UAV has only one antenna, under different\nscenarios of one single UE, two UEs, and arbitrary number of UEs. In\nparticular, for the two-UE case, we derive the optimal UAV swarm placement\npositions in closed-form that achieves IUI-free communication, where the UAV\nswarm forms a uniform sparse array (USA) satisfying collision avoidance\nconstraint. While for the general case with arbitrary number of UEs, we propose\nan efficient alternating optimization algorithm to solve the formulated\nnon-convex optimization problem. Then, we extend the results to the case where\neach UAV is equipped with multiple antennas. Numerical results verify that the\nproposed low-altitude UAV swarm enabled MA system significantly outperforms\nvarious benchmark schemes, thanks to the exploitation of two-level mobility to\ncreate more favorable channel conditions for multi-UE communications.",
    "pdf_url": "http://arxiv.org/pdf/2505.22286v1",
    "published": "2025-05-28T12:22:09+00:00",
    "categories": [
      "cs.IT",
      "eess.SP",
      "math.IT"
    ],
    "primary_category": "cs.IT"
  },
  {
    "id": "http://arxiv.org/abs/2505.22285v1",
    "title": "Sub-arcsecond-resolution LOFAR observations of bright sub-millimetre galaxies in the North Ecliptic Pole field",
    "authors": [
      "M. Bondi",
      "I. Prandoni",
      "M. Magliocchetti",
      "L. Bisigello",
      "M. Bonato",
      "M. Giulietti",
      "R. Scaramella",
      "G. Brunetti",
      "F. Vitello"
    ],
    "abstract": "Bright SMGs contribute significantly to the star formation rate (SFR) density\n(20-50\\%) and stellar mass density ($\\sim$ 30-50\\%) at $z=$ 2-4 with SFRs$\\ge\n1000$ M$_\\odot$,yr$^{-1}$ and stellar masses of $\\sim 10^{11}$-$10^{12}$\nM$_\\odot$. The number of bright SMGs with such high SFRs is hard to reconcile\nwith the standard models of galaxy formation and evolution. In this paper we\nprovide evidence that, in a small sample of 12 bright SMGs, the SFRs derived\nfrom spectral energy distribution (SED) fitting are significantly higher than\nthose obtained using low-frequency radio emission as a proxy for star\nformation. Using the International LOFAR Telescope (ILT), which allows imaging\nat 144 MHz with sub-arcsecond angular resolution, we have produced deep images\nof a small sample of bright SMGs in the North Ecliptic Pole (NEP) field\nextracted from the NEPSC2 survey. For all 12 SMGs, we find radio-emitting\nmid-infrared galaxies at distances from a few arcseconds down to sub-arcsecond\nscales from the SMG and/or the presence of a radio-emitting AGN. The SFRs\nderived from the radio emission of the SMG, disentangled from the AGN-related\nradio emission, are systematically lower by a factor of $\\sim 5$ (median value)\nthan those derived from the multi-band SED fitting. We discuss whether our\nassumptions might be, at least in part, responsible for the observed\ndiscrepancy. We argue that the radio-derived SFRs are not systematically\nunderestimated but can be affected by a significant dispersion ($0.3-0.5$ dex).\nConsidering these new SFR estimates, the offset of the specific SFR of the 12\nbright SMGs from the star-forming galaxy main sequence\n($\\Delta\\mathrm{(SSFR)}$) is significantly reduced, with all 12 bright SMGs\nwhich are only a factor of 2 more star-forming than the main sequence galaxies.",
    "pdf_url": "http://arxiv.org/pdf/2505.22285v1",
    "published": "2025-05-28T12:22:04+00:00",
    "categories": [
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2505.22284v1",
    "title": "From Controlled Scenarios to Real-World: Cross-Domain Degradation Pattern Matching for All-in-One Image Restoration",
    "authors": [
      "Junyu Fan",
      "Chuanlin Liao",
      "Yi Lin"
    ],
    "abstract": "As a fundamental imaging task, All-in-One Image Restoration (AiOIR) aims to\nachieve image restoration caused by multiple degradation patterns via a single\nmodel with unified parameters. Although existing AiOIR approaches obtain\npromising performance in closed and controlled scenarios, they still suffered\nfrom considerable performance reduction in real-world scenarios since the gap\nof data distributions between the training samples (source domain) and\nreal-world test samples (target domain) can lead inferior degradation awareness\nability. To address this issue, a Unified Domain-Adaptive Image Restoration\n(UDAIR) framework is proposed to effectively achieve AiOIR by leveraging the\nlearned knowledge from source domain to target domain. To improve the\ndegradation identification, a codebook is designed to learn a group of discrete\nembeddings to denote the degradation patterns, and the cross-sample contrastive\nlearning mechanism is further proposed to capture shared features from\ndifferent samples of certain degradation. To bridge the data gap, a domain\nadaptation strategy is proposed to build the feature projection between the\nsource and target domains by dynamically aligning their codebook embeddings,\nand a correlation alignment-based test-time adaptation mechanism is designed to\nfine-tune the alignment discrepancies by tightening the degradation embeddings\nto the corresponding cluster center in the source domain. Experimental results\non 10 open-source datasets demonstrate that UDAIR achieves new state-of-the-art\nperformance for the AiOIR task. Most importantly, the feature cluster validate\nthe degradation identification under unknown conditions, and qualitative\ncomparisons showcase robust generalization to real-world scenarios.",
    "pdf_url": "http://arxiv.org/pdf/2505.22284v1",
    "published": "2025-05-28T12:22:00+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.22283v1",
    "title": "Intermittency in Interplanetary Coronal Mass Ejections Observed by Parker Solar Probe and Solar Orbiter",
    "authors": [
      "Julia Ruohotie",
      "Simon Good",
      "Christian M√∂stl",
      "Emilia Kilpua"
    ],
    "abstract": "Intermittency has been studied extensively in the fast and slow solar winds\nbut to a far lesser extent in interplanetary coronal mass ejections (ICMEs).\nWhile ICMEs are often characterized by their relatively smooth, large-scale\nmagnetic flux rope structures, a spectrum of fluctuations is nonetheless\npresent at smaller scales. We have examined kurtosis and its scaling exponents\nat magnetohydrodynamic inertial scales in 49 ICMEs observed between 0.25 and 1\nau by Parker Solar Probe and Solar Orbiter, and compared the results to those\nobtained for the ICME sheath regions and ambient solar wind intervals. Kurtosis\nbehaves similarly in all intervals studied and presents a universal behavior\ntypical of intermittent time series. The ICMEs displayed a radially invariant\nlevel of intermittency, suggesting that they are relatively static,\nwell-developed turbulent environments. In the sheath regions, the level of\nintermittency increased with distance, indicating that the turbulence is not\nyet fully developed at small heliocentric distances. In addition to\nintermittent fluctuations related to turbulence, the sheath regions may possess\na population of non-turbulent structures that increase the absolute value of\nkurtosis.",
    "pdf_url": "http://arxiv.org/pdf/2505.22283v1",
    "published": "2025-05-28T12:19:50+00:00",
    "categories": [
      "astro-ph.SR",
      "physics.plasm-ph",
      "physics.space-ph"
    ],
    "primary_category": "astro-ph.SR"
  },
  {
    "id": "http://arxiv.org/abs/2505.22282v1",
    "title": "Uniqueness of free 2-periodicities of links",
    "authors": [
      "Ken'ichi Yoshida"
    ],
    "abstract": "We show that if two links in the real projective 3-space $\\mathbb{RP}^{3}$\nhave isotopic preimages in the 3-sphere $S^{3}$ by the double covering map,\nthen they are themselves isotopic in $\\mathbb{RP}^{3}$.",
    "pdf_url": "http://arxiv.org/pdf/2505.22282v1",
    "published": "2025-05-28T12:17:32+00:00",
    "categories": [
      "math.GT",
      "57K10, 57K32, 57K35, 57M10"
    ],
    "primary_category": "math.GT"
  },
  {
    "id": "http://arxiv.org/abs/2505.22281v1",
    "title": "Community input to the European Strategy on particle physics: Searches for Permanent Electric Dipole Moments",
    "authors": [
      "M. Athanasakis-Kaklamanakis",
      "M. Au",
      "R. Berger",
      "S. Degenkolb",
      "J. De Vries",
      "S. Hoekstra",
      "A. Keshavarzi",
      "N. Neri",
      "D. Ries",
      "P. Schmidt-Wellenburg",
      "M. Tarbutt"
    ],
    "abstract": "Searches for electric dipole moments (EDMs) in fundamental particles and\nquantum systems with spin are pivotal experiments at the intersection of\nlow-energy and high-precision particle physics. These investigations offer a\ncomplementary pathway to uncovering new physics beyond the Standard Model,\nparallel to high-energy collider searches. EDM experiments are among the most\nsensitive probes for detecting non-standard time-reversal (T) symmetry\nviolations and, via the CPT theorem, CP-violation (CPV). Current EDM\nmeasurements test new physics at mass scales in or above the 10TeV to 100TeV\nrange. This community input to the European Particle Physics Strategy Update\nhighlights the status of the field, and describes challenges and opportunities\nin Europe.",
    "pdf_url": "http://arxiv.org/pdf/2505.22281v1",
    "published": "2025-05-28T12:17:15+00:00",
    "categories": [
      "hep-ex",
      "nucl-ex"
    ],
    "primary_category": "hep-ex"
  },
  {
    "id": "http://arxiv.org/abs/2505.22280v1",
    "title": "Natural Language Processing in Support of Evidence-based Medicine: A Scoping Review",
    "authors": [
      "Zihan Xu",
      "Haotian Ma",
      "Gongbo Zhang",
      "Yihao Ding",
      "Chunhua Weng",
      "Yifan Peng"
    ],
    "abstract": "Evidence-based medicine (EBM) is at the forefront of modern healthcare,\nemphasizing the use of the best available scientific evidence to guide clinical\ndecisions. Due to the sheer volume and rapid growth of medical literature and\nthe high cost of curation, there is a critical need to investigate Natural\nLanguage Processing (NLP) methods to identify, appraise, synthesize, summarize,\nand disseminate evidence in EBM. This survey presents an in-depth review of 129\nresearch studies on leveraging NLP for EBM, illustrating its pivotal role in\nenhancing clinical decision-making processes. The paper systematically explores\nhow NLP supports the five fundamental steps of EBM -- Ask, Acquire, Appraise,\nApply, and Assess. The review not only identifies current limitations within\nthe field but also proposes directions for future research, emphasizing the\npotential for NLP to revolutionize EBM by refining evidence extraction,\nevidence synthesis, appraisal, summarization, enhancing data comprehensibility,\nand facilitating a more efficient clinical workflow.",
    "pdf_url": "http://arxiv.org/pdf/2505.22280v1",
    "published": "2025-05-28T12:17:01+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.22279v1",
    "title": "Learning Fine-Grained Geometry for Sparse-View Splatting via Cascade Depth Loss",
    "authors": [
      "Wenjun Lu",
      "Haodong Chen",
      "Anqi Yi",
      "Yuk Ying Chung",
      "Zhiyong Wang",
      "Kun Hu"
    ],
    "abstract": "Novel view synthesis is a fundamental task in 3D computer vision that aims to\nreconstruct realistic images from a set of posed input views. However,\nreconstruction quality degrades significantly under sparse-view conditions due\nto limited geometric cues. Existing methods, such as Neural Radiance Fields\n(NeRF) and the more recent 3D Gaussian Splatting (3DGS), often suffer from\nblurred details and structural artifacts when trained with insufficient views.\nRecent works have identified the quality of rendered depth as a key factor in\nmitigating these artifacts, as it directly affects geometric accuracy and view\nconsistency. In this paper, we address these challenges by introducing\nHierarchical Depth-Guided Splatting (HDGS), a depth supervision framework that\nprogressively refines geometry from coarse to fine levels. Central to HDGS is a\nnovel Cascade Pearson Correlation Loss (CPCL), which aligns rendered and\nestimated monocular depths across multiple spatial scales. By enforcing\nmulti-scale depth consistency, our method substantially improves structural\nfidelity in sparse-view scenarios. Extensive experiments on the LLFF and DTU\nbenchmarks demonstrate that HDGS achieves state-of-the-art performance under\nsparse-view settings while maintaining efficient and high-quality rendering",
    "pdf_url": "http://arxiv.org/pdf/2505.22279v1",
    "published": "2025-05-28T12:16:42+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.22278v1",
    "title": "A Coupled Hydro-Morphodynamic Model for Sediment Transport using the Moment Approach",
    "authors": [
      "Afroja Parvin",
      "Giovanni Samaey",
      "Julian Koellermeier"
    ],
    "abstract": "Sediment transport is crucial in the hydro-morphodynamic evolution of free\nsurface flows in shallow water environments, which is typically modeled under\nthe shallow water assumption. In classical shallow water modeling for sediment\ntransport, the vertical structure of the flow is collapsed into a\ndepth-averaged and near-bed velocity, usually reconstructed empirically, e.g.,\nusing a parameterized logarithmic profile. In practice, large variations from\nsuch empirical profiles can occur. It is therefore essential to resolve the\nvertical structure of the velocity profile within the shallow water framework\nto better approximate near-bed velocity. This study introduces a model and\nsimulations that incorporate vertical velocity variations and bottom\nerosion-deposition effects in sediment transport, providing a computationally\nefficient framework for predicting sediment dynamics in shallow water\nenvironments. We employ the so-called moment model approach for the velocity\nvariation, which considers a polynomial expansion of the horizontal velocity in\nthe scaled vertical direction. This allows the use of a complex velocity\nprofile with an extended set of variables determined by the polynomial basis\ncoefficients, resolving the vertical structure as part of the solution. The\nextended model comprises four components: (1) the standard shallow water\nequations; (2) moment equations governing evolution of the basis coefficients;\n(3) an evolution equation for sediment concentration; and (4) a transport\nequation for the bed. This enables a coupled model for bedload and suspended\nload transport. We use a hyperbolic regularization technique to ensure model\nstability and realistic eigenvalues. Several numerical tests, including\ndam-break cases with and without wet/dry fronts, validate our results against\nlaboratory data.",
    "pdf_url": "http://arxiv.org/pdf/2505.22278v1",
    "published": "2025-05-28T12:13:43+00:00",
    "categories": [
      "math.NA",
      "cs.NA",
      "physics.geo-ph"
    ],
    "primary_category": "math.NA"
  },
  {
    "id": "http://arxiv.org/abs/2505.22277v1",
    "title": "The complexity of deciding characteristic formulae modulo nested simulation",
    "authors": [
      "Luca Aceto",
      "Antonis Achilleos",
      "Aggeliki Chalki",
      "Anna Ingolfsdottir"
    ],
    "abstract": "This paper studies the complexity of determining whether a formula in the\nmodal logics characterizing the nested-simulation semantics is characteristic\nfor some process, which is equivalent to determining whether the formula is\nsatisfiable and prime. The main results are that the problem of determining\nwhether a formula is prime in the modal logic characterizing the\n2-nested-simulation preorder is CoNP-complete and is PSPACE-complete in the\ncase of the n-nested-simulation preorder, when n>= 3. This establishes that\ndeciding characteristic formulae for the n-nested simulation semantics, n>= 3,\nis PSPACE-complete. In the case of the 2-nested simulation semantics, that\nproblem lies in the complexity class DP, which consists of languages that can\nbe expressed as the intersection of one language in NP and of one in CoNP.",
    "pdf_url": "http://arxiv.org/pdf/2505.22277v1",
    "published": "2025-05-28T12:11:33+00:00",
    "categories": [
      "cs.LO"
    ],
    "primary_category": "cs.LO"
  },
  {
    "id": "http://arxiv.org/abs/2505.22276v1",
    "title": "Low Crosstalk in a Scalable Superconducting Quantum Lattice",
    "authors": [
      "Mohammed Alghadeer",
      "Shuxiang Cao",
      "Simone D Fasciati",
      "Michele Piscitelli",
      "Paul C. Gow",
      "James C. Gates",
      "Mustafa Bakr",
      "Peter J. Leek"
    ],
    "abstract": "Superconducting quantum circuits are a key platform for advancing quantum\ninformation processing and simulation. Scaling efforts currently encounter\nchallenges such as Josephson-junction fabrication yield, design frequency\ntargeting, and crosstalk arising both from spurious microwave modes and\nintrinsic interactions between qubits. We demonstrate a scalable 4x4 square\nlattice with low crosstalk, comprising 16 fixed-frequency transmon qubits with\nnearest-neighbor capacitive coupling that is implemented in a tileable,\n3D-integrated circuit architecture with off-chip inductive shunting to mitigate\nspurious enclosure modes. We report on the design and comprehensive\ncharacterization, and show that our implementation achieves targeted device\nparameters with very low frequency spreads and simultaneous single-qubit gate\nerrors across the device. Our results provide a promising pathway toward a\nscalable, low-crosstalk superconducting lattice topology with high qubit\nconnectivity for quantum error correction and simulation.",
    "pdf_url": "http://arxiv.org/pdf/2505.22276v1",
    "published": "2025-05-28T12:07:51+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.22275v1",
    "title": "Full Domain Analysis in Fluid Dynamics",
    "authors": [
      "Alexander Hagg",
      "Adam Gaier",
      "Dominik Wilde",
      "Alexander Asteroth",
      "Holger Foysi",
      "Dirk Reith"
    ],
    "abstract": "Novel techniques in evolutionary optimization, simulation and machine\nlearning allow for a broad analysis of domains like fluid dynamics, in which\ncomputation is expensive and flow behavior is complex. Under the term of full\ndomain analysis we understand the ability to efficiently determine the full\nspace of solutions in a problem domain, and analyze the behavior of those\nsolutions in an accessible and interactive manner. The goal of full domain\nanalysis is to deepen our understanding of domains by generating many examples\nof flow, their diversification, optimization and analysis. We define a formal\nmodel for full domain analysis, its current state of the art, and requirements\nof subcomponents. Finally, an example is given to show what we can learn by\nusing full domain analysis. Full domain analysis, rooted in optimization and\nmachine learning, can be a helpful tool in understanding complex systems in\ncomputational physics and beyond.",
    "pdf_url": "http://arxiv.org/pdf/2505.22275v1",
    "published": "2025-05-28T12:06:48+00:00",
    "categories": [
      "cs.LG",
      "cs.NE",
      "68U01",
      "I.2.1; I.2.6"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.22274v1",
    "title": "Dimensionality-Driven Anomalous Metallic State with Zero-field Nonreciprocal Transport in Layered Ising Superconductors",
    "authors": [
      "Yanwei Cui",
      "Zenglin Liu",
      "Qin Liu",
      "Junlin Xiong",
      "Yongqin Xie",
      "Yudi Dai",
      "Ji Zhou",
      "Lizheng Wang",
      "Hanyan Fang",
      "Haiwen Liu",
      "Shi-Jun Liang",
      "Bin Cheng",
      "Feng Miao"
    ],
    "abstract": "The anomalous metal state (AMS), observed in failed superconductors, provides\ninsights into superconductivity and quantum criticality, with studies revealing\nunconventional quantum phases like the Bose metal. Recently, layered transition\nmetal dichalcogenide (TMD) superconductors approaching the two-dimensional\nlimit have garnered significant attention for the enhanced phase fluctuations\nand electronic correlations. Investigating AMS in these systems, particularly\nin the absence of an external magnetic field, could offer valuable insights\ninto the dimensionality-driven emergence of exotic quantum phenomena, including\ntriplet Cooper pairing, phase fluctuation dynamics, and especially the recently\ndiscovered field-free superconducting diode effects. However, the field-free\nAMS has yet to be observed in TMD superconductors. Here, we report the\ndimensionality-tunable AMS near the superconducting quantum phase transitions\nin a layered TMD superconductor 2H-Ta2S3Se. In samples with thicknesses below\n10 nm, we demonstrate magnetic field-driven AMS under external magnetic field,\ncharacterized by the vanishing of the Hall resistance and the presence of\nfinite longitudinal resistance. Remarkably, an unexpected zero-field AMS\nemerges as the sample thickness is reduced to 3 nm. This AMS aligns well with\nthe quantum vortex creep model and exhibits non-reciprocal transport behaviors,\nsuggesting the onset of spontaneous time-reversal symmetry breaking accompanied\nby vortex motion as the system approaches the two-dimensional limit. Our\nfindings open new avenues for exploring dimensionality-driven exotic\nsuperconducting quantum critical phases, and pave the way for a deeper\nunderstanding of zero-field superconducting diode effects.",
    "pdf_url": "http://arxiv.org/pdf/2505.22274v1",
    "published": "2025-05-28T12:04:59+00:00",
    "categories": [
      "cond-mat.supr-con",
      "cond-mat.mes-hall"
    ],
    "primary_category": "cond-mat.supr-con"
  },
  {
    "id": "http://arxiv.org/abs/2505.23836v3",
    "title": "Large Language Models Often Know When They Are Being Evaluated",
    "authors": [
      "Joe Needham",
      "Giles Edkins",
      "Govind Pimpale",
      "Henning Bartsch",
      "Marius Hobbhahn"
    ],
    "abstract": "If AI models can detect when they are being evaluated, the effectiveness of\nevaluations might be compromised. For example, models could have systematically\ndifferent behavior during evaluations, leading to less reliable benchmarks for\ndeployment and governance decisions. We investigate whether frontier language\nmodels can accurately classify transcripts based on whether they originate from\nevaluations or real-world deployment, a capability we call evaluation\nawareness. To achieve this, we construct a diverse benchmark of 1,000 prompts\nand transcripts from 61 distinct datasets. These span public benchmarks (e.g.,\nMMLU, SWEBench), real-world deployment interactions, and agent trajectories\nfrom scaffolding frameworks (e.g., web-browsing agents). Frontier models\nclearly demonstrate above-random evaluation awareness (Gemini-2.5-Pro reaches\nan AUC of $0.83$), but do not yet surpass our simple human baseline (AUC of\n$0.92$). Furthermore, both AI models and humans are better at identifying\nevaluations in agentic settings compared to chat settings. Additionally, we\ntest whether models can identify the purpose of the evaluation. Under\nmultiple-choice and open-ended questioning, AI models far outperform random\nchance in identifying what an evaluation is testing for. Our results indicate\nthat frontier models already exhibit a substantial, though not yet superhuman,\nlevel of evaluation-awareness. We recommend tracking this capability in future\nmodels.",
    "pdf_url": "http://arxiv.org/pdf/2505.23836v3",
    "published": "2025-05-28T12:03:09+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.22273v1",
    "title": "Comprehensive Evaluation on Lexical Normalization: Boundary-Aware Approaches for Unsegmented Languages",
    "authors": [
      "Shohei Higashiyama",
      "Masao Utiyama"
    ],
    "abstract": "Lexical normalization research has sought to tackle the challenge of\nprocessing informal expressions in user-generated text, yet the absence of\ncomprehensive evaluations leaves it unclear which methods excel across multiple\nperspectives. Focusing on unsegmented languages, we make three key\ncontributions: (1) creating a large-scale, multi-domain Japanese normalization\ndataset, (2) developing normalization methods based on state-of-the-art\npretrained models, and (3) conducting experiments across multiple evaluation\nperspectives. Our experiments show that both encoder-only and decoder-only\napproaches achieve promising results in both accuracy and efficiency.",
    "pdf_url": "http://arxiv.org/pdf/2505.22273v1",
    "published": "2025-05-28T12:02:45+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.04241v1",
    "title": "Improving Out-of-Distribution Detection with Markov Logic Networks",
    "authors": [
      "Konstantin Kirchheim",
      "Frank Ortmeier"
    ],
    "abstract": "Out-of-distribution (OOD) detection is essential for ensuring the reliability\nof deep learning models operating in open-world scenarios. Current OOD\ndetectors mainly rely on statistical models to identify unusual patterns in the\nlatent representations of a deep neural network. This work proposes to augment\nexisting OOD detectors with probabilistic reasoning, utilizing Markov logic\nnetworks (MLNs). MLNs connect first-order logic with probabilistic reasoning to\nassign probabilities to inputs based on weighted logical constraints defined\nover human-understandable concepts, which offers improved explainability.\nThrough extensive experiments on multiple datasets, we demonstrate that MLNs\ncan significantly enhance the performance of a wide range of existing OOD\ndetectors while maintaining computational efficiency. Furthermore, we introduce\na simple algorithm for learning logical constraints for OOD detection from a\ndataset and showcase its effectiveness.",
    "pdf_url": "http://arxiv.org/pdf/2506.04241v1",
    "published": "2025-05-28T12:00:37+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.22272v1",
    "title": "Addendum to \"Measured foliations and Hilbert 12th problem\"",
    "authors": [
      "Igor V. Nikolaev"
    ],
    "abstract": "We study numerical examples of the abelian extensions of the real quadratic\nnumber fields based on the results in Acta Mathematica Vietnamica 48 (2023),\n271-281 (arXiv:0804.0057)",
    "pdf_url": "http://arxiv.org/pdf/2505.22272v1",
    "published": "2025-05-28T11:58:32+00:00",
    "categories": [
      "math.NT",
      "math.OA",
      "11G45, 46L85"
    ],
    "primary_category": "math.NT"
  },
  {
    "id": "http://arxiv.org/abs/2505.22271v1",
    "title": "Test-Time Immunization: A Universal Defense Framework Against Jailbreaks for (Multimodal) Large Language Models",
    "authors": [
      "Yongcan Yu",
      "Yanbo Wang",
      "Ran He",
      "Jian Liang"
    ],
    "abstract": "While (multimodal) large language models (LLMs) have attracted widespread\nattention due to their exceptional capabilities, they remain vulnerable to\njailbreak attacks. Various defense methods are proposed to defend against\njailbreak attacks, however, they are often tailored to specific types of\njailbreak attacks, limiting their effectiveness against diverse adversarial\nstrategies. For instance, rephrasing-based defenses are effective against text\nadversarial jailbreaks but fail to counteract image-based attacks. To overcome\nthese limitations, we propose a universal defense framework, termed Test-time\nIMmunization (TIM), which can adaptively defend against various jailbreak\nattacks in a self-evolving way. Specifically, TIM initially trains a gist token\nfor efficient detection, which it subsequently applies to detect jailbreak\nactivities during inference. When jailbreak attempts are identified, TIM\nimplements safety fine-tuning using the detected jailbreak instructions paired\nwith refusal answers. Furthermore, to mitigate potential performance\ndegradation in the detector caused by parameter updates during safety\nfine-tuning, we decouple the fine-tuning process from the detection module.\nExtensive experiments on both LLMs and multimodal LLMs demonstrate the efficacy\nof TIM.",
    "pdf_url": "http://arxiv.org/pdf/2505.22271v1",
    "published": "2025-05-28T11:57:46+00:00",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.22270v3",
    "title": "Zitterbewegung, momentum and spin dynamics of electromagnetic wave in linear dielectric medium",
    "authors": [
      "Adam B. Cahaya"
    ],
    "abstract": "The momentum of light in dielectric media has been a century-long controversy\nthat continues to attract significant interest. In a linear dielectric medium\nwith refractive index $n$, the momentum is predicted to be smaller by a factor\nof $n$ according to Max Abraham, and larger by the same factor according to\nHermann Minkowski. By studying the coupled dynamics of electromagnetic waves\nand dipoles in a dielectric medium, we show that the change in momentum of the\ndipole, expressed by the Lorentz force, corresponds to the Abraham momentum and\nis given by the expectation value of the spin-projected momentum vector. On the\nother hand, the Minkowski momentum is obtained as the magnitude of the\nspin-projected momentum vector from the energy-momentum dispersion relation\nderived by diagonalizing the coupled Hamiltonian and determines the direction\nof refraction in accordance with Snell's law. Our model also predicts a\nzitterbewegung-like oscillation due to helicity mixing between left- and\nright-handed wave components, mediated by dipole oscillation. These internal\nwave dynamics may be observable via wavepacket motion or polarization-sensitive\nmeasurements.",
    "pdf_url": "http://arxiv.org/pdf/2505.22270v3",
    "published": "2025-05-28T11:57:10+00:00",
    "categories": [
      "physics.optics",
      "quant-ph"
    ],
    "primary_category": "physics.optics"
  },
  {
    "id": "http://arxiv.org/abs/2505.22269v1",
    "title": "A memristive model of spatio-temporal excitability",
    "authors": [
      "Thomas SJ Burger",
      "Amir Shahhosseini",
      "Rodolphe Sepulchre"
    ],
    "abstract": "This paper introduces a model of excitability that unifies the mechanism of\nan important neuronal property both in time and in space. As a starting point,\nwe revisit both a key model of temporal excitability, proposed by Hodgkin and\nHuxley, and a key model of spatial excitability, proposed by Amari. We then\npropose a novel model that captures the temporal and spatial properties of both\nmodels. Our aim is to regard neuronal excitability as a property across scales,\nand to explore the benefits of modeling excitability with one and the same\nmechanism, whether at the cellular or the population level.",
    "pdf_url": "http://arxiv.org/pdf/2505.22269v1",
    "published": "2025-05-28T11:55:48+00:00",
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2505.22268v1",
    "title": "Thermophysical Properties and Phase Behavior of CO2 with Impurities: Insight from Molecular Simulations",
    "authors": [
      "Darshan Raju",
      "Mahinder Ramdin",
      "Thijs J. H. Vlugt"
    ],
    "abstract": "Experimentally determining thermophysical properties for various compositions\ncommonly found in CO2 transportation systems is extremely challenging. To\novercome this challenge, we performed Monte Carlo (MC) and molecular dynamics\n(MD) simulations of CO2 rich mixtures to compute thermophysical properties such\nas densities, thermal expansion coefficients, isothermal compressibilities,\nheat capacities, Joule-Thomson coefficients, speed of sound, and viscosities at\ntemperatures (235-313) K and pressures (20-200) bar. We computed thermophysical\nproperties of pure CO2 and CO2 rich mixtures with N2, Ar, H2, and CH4 as\nimpurities (1-10) mol% and showed good agreement with available equations of\nstate (EoS). We showed that impurities decrease the values of thermal expansion\ncoefficients, isothermal compressibilities, heat capacities, and Joule-Thomson\ncoefficients in the gas phase, while these values increase in the liquid and\nsupercritical phases. In contrast, impurities increase the value of speed of\nsound in the gas phase and decrease it in the liquid and supercritical phases.\nWe present an extensive data set of thermophysical properties for CO2 rich\nmixtures with various impurities, which will help to design the safe and\nefficient operation of CO2 transportation systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.22268v1",
    "published": "2025-05-28T11:54:55+00:00",
    "categories": [
      "physics.chem-ph"
    ],
    "primary_category": "physics.chem-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.22267v1",
    "title": "Simulation of single hole spin qubit in strained triangular FinFET quantum devices",
    "authors": [
      "Ilan Bouquet",
      "Jiang Cao",
      "Mathieu Luisier"
    ],
    "abstract": "Using an in-house Schroedinger-Poisson (SP) solver, we investigate the\ncreation of a single hole spin qubit inside a triple-gate triangular silicon\nfin field effect transistor (Si FinFET) quantum device similar to experimental\nstructures. The gate induced formation of the required quantum dot (QD) is\nmonitored based on the Luttinger-Kohn 6x6 kp method accounting for magnetic\nfields and strain to determine the qubit ground state. Strain arises from the\ninhomogeneous contraction of the different FinFET components when they are\ncooled down to cryogenic temperatures. It leads to a renormalization of the\nqubit energy levels, thus impacting both the heavy-hole (HH) and light-hole\n(LH) populations as well as their mixing. The dot length, band mixing,\ng-factor, and Larmor/Rabi frequencies of the considered device are extracted.\nIn particular, we show that these metrics exhibit strong strain-dependent\nvariations of their magnitude, thus underlying the importance of including\nrealistic thermal contraction scenarios when modeling hole spin qubits.",
    "pdf_url": "http://arxiv.org/pdf/2505.22267v1",
    "published": "2025-05-28T11:54:20+00:00",
    "categories": [
      "quant-ph",
      "cond-mat.mes-hall"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.22266v2",
    "title": "FGAS: Fixed Decoder Network-Based Audio Steganography with Adversarial Perturbation Generation",
    "authors": [
      "Jialin Yan",
      "Yu Cheng",
      "Zhaoxia Yin",
      "Xinpeng Zhang",
      "Shilin Wang",
      "Tanfeng Sun",
      "Xinghao Jiang"
    ],
    "abstract": "The rapid development of Artificial Intelligence Generated Content (AIGC) has\nmade high-fidelity generated audio widely available across the Internet,\nproviding diverse cover signals for covert communication. Driven by advances in\ndeep learning, current audio steganography schemes are mainly based on\nencoding-decoding network architectures. While these methods greatly improve\nthe security of audio steganography, they typically require complex training\nand large pre-trained models. To address the aforementioned issues, this paper\npioneers a Fixed Decoder Network-Based Audio Steganography with Adversarial\nPerturbation Generation (FGAS). Adversarial perturbations carrying secret\nmessage are embedded into the cover audio to generate stego audio. The receiver\nonly needs to share the structure and weights of the fixed decoder network to\naccurately extract the secret message from the stego audio, this eliminates the\nreliance on large pre-trained models. In FGAS, we propose an audio Adversarial\nPerturbation Generation (APG) strategy and design a lightweight fixed decoder.\nThe fixed decoder guarantees reliable extraction of the hidden message, while\nthe adversarial perturbations are optimized to keep the stego audio\nperceptually and statistically close to the cover audio, thereby improving\nresistance to steganalysis. The experimental results show that FGAS\nsignificantly improves the quality of stego audio, achieving an average PSNR\ngain of over 10 dB compared to SOTA methods. Moreover, FGAS exhibits superior\nanti-steganalysis performance under different relative payloads; under\nhigh-capacity embedding, it achieves a classification error rate about 2%\nhigher, indicating stronger anti-steganalysis performance compared to current\nSOTA methods.",
    "pdf_url": "http://arxiv.org/pdf/2505.22266v2",
    "published": "2025-05-28T11:54:09+00:00",
    "categories": [
      "cs.SD",
      "cs.MM",
      "eess.AS"
    ],
    "primary_category": "cs.SD"
  },
  {
    "id": "http://arxiv.org/abs/2505.22693v1",
    "title": "Derivation of Fokker-Planck equation from Schrodinger dynamics",
    "authors": [
      "Irfan Lone"
    ],
    "abstract": "The Fokker_Planck equation can be derived in a consistent manner through a\nmicroscopic approach based on a unified scheme of classical and quantum\nmechanics. Here we shall derive it through a purely quantum mechanical approach\nbased on the reversible Schrodinger dynamics. We also give a brief discussion\nof the path integral representation of the Fokker_Planck equation in light of\nour derivation. We conclude that, because of the use of the representation of\neigenstates of the time-independent Hamiltonian in our derivation, the\nthermodynamical entropy in this case must correspond to a coarse-graining of\nthe quantum entropy.",
    "pdf_url": "http://arxiv.org/pdf/2505.22693v1",
    "published": "2025-05-28T11:51:30+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.22265v1",
    "title": "Advances in Position-Momentum Entanglement: A Versatile Tool for Quantum Technologies",
    "authors": [
      "Satyajeet Patil",
      "Sebastian T√∂pfer",
      "Rajshree Swarnkar",
      "Sergio Tovar-Perez",
      "Jonas Moos",
      "Jorge Fuenzalida",
      "Markus Gr√§fe"
    ],
    "abstract": "Position-momentum entanglement is a versatile high-dimensional resource in\nquantum optics. From fundamental tests of reality, to application in quantum\ntechnologies, spatial entanglement has had an increasing growth in recent\nyears. In this review, we explore these advances, starting from the generation\nof spatial entanglement, followed by the different types of measurements for\nquantifying the entanglement, and finishing with different quantum-based\napplications. We conclude the review with a discussion and future perspectives\non the field.",
    "pdf_url": "http://arxiv.org/pdf/2505.22265v1",
    "published": "2025-05-28T11:51:21+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.22264v1",
    "title": "MRT at SemEval-2025 Task 8: Maximizing Recovery from Tables with Multiple Steps",
    "authors": [
      "Maximiliano Hormaz√°bal Lagos",
      "√Ålvaro Bueno Saez",
      "H√©ctor Cerezo-Costas",
      "Pedro Alonso Doval",
      "Jorge Alcalde Vesteiro"
    ],
    "abstract": "In this paper we expose our approach to solve the \\textit{SemEval 2025 Task\n8: Question-Answering over Tabular Data} challenge. Our strategy leverages\nPython code generation with LLMs to interact with the table and get the answer\nto the questions. The process is composed of multiple steps: understanding the\ncontent of the table, generating natural language instructions in the form of\nsteps to follow in order to get the answer, translating these instructions to\ncode, running it and handling potential errors or exceptions. These steps use\nopen source LLMs and fine grained optimized prompts for each task (step). With\nthis approach, we achieved a score of $70.50\\%$ for subtask 1.",
    "pdf_url": "http://arxiv.org/pdf/2505.22264v1",
    "published": "2025-05-28T11:50:22+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.22263v1",
    "title": "Ultrasonic spin pumping in the antiferromagnetic acoustic resonator $Œ±-\\text{Fe}_2\\text{O}_3$",
    "authors": [
      "David A. Gabrielyan",
      "Dmitry A. Volkov",
      "Tatyana V. Bogdanova",
      "Kristina D. Samoylenko",
      "Anton V. Matasov",
      "Ansar R. Safin",
      "Dmitry V. Kalyabin",
      "Alexey A. Klimov",
      "Leonid M. Krutyansky",
      "Vladimir L. Preobrazhensky",
      "Sergey A. Nikitov"
    ],
    "abstract": "Recent advances in magnon spintronics have ignited interest in the\ninteractions between the spin and elastic subsystems of magnetic materials.\nThese interactions suggest a dynamic connection between collective excitations\nof spins, quantized as magnons, and elastic waves generated by perturbations in\nthe crystal lattice, quantized as phonons. Both magnons and their associated\nmagnon-phonon excitations can act as sources of spin pumping from magnetic\nmaterials into non-magnetic metals. Although a considerable body of research\nhas focused on spin pumping via elastic waves in ferromagnets, similar\ninvestigations involving antiferromagnets have yet to be undertaken. In this\nwork, we experimentally demonstrate for the first time the feasibility of\ngenerating spin currents at ultrasonic frequencies of acoustic resonance in\nantiferromagnetic crystal hematite $\\alpha-\\text{Fe}_2\\text{O}_3$ at room\ntemperature. We provide both theoretical and experimental evidence that, due to\nstrong magnetoelastic coupling, acoustic vibrations in hematite induce\nsignificant variable deviations in magnetization, resulting in spin\naccumulation at the antiferromagnet-normal metal interface, which in turn leads\nto the generation of spin and charge currents in the metal. Charge currents\narising from the inverse spin Hall effect can be measured using the same\nmethodology employed under high-frequency spin pumping conditions at the\nresonances of the magnetic subsystem itself. Moreover, the acoustic resonance\nin hematite is significantly more pronounced (by hundreds or even thousands of\ntimes) than in other quasiferromagnetic or antiferromagnetic systems, enabling\nthe attainment of extremely large amplitudes of magnetic oscillations for spin\npumping. This research highlights the new approach of utilizing acoustic spin\npumping to manipulate spin currents in magnetic materials, particularly\nantiferromagnets.",
    "pdf_url": "http://arxiv.org/pdf/2505.22263v1",
    "published": "2025-05-28T11:50:18+00:00",
    "categories": [
      "cond-mat.other",
      "physics.app-ph"
    ],
    "primary_category": "cond-mat.other"
  },
  {
    "id": "http://arxiv.org/abs/2505.22262v1",
    "title": "Forager with Inertia : Better for Survival?",
    "authors": [
      "Md Aquib Molla",
      "Sanchari Goswami",
      "Parongama Sen"
    ],
    "abstract": "We study the fate of a forager who searches for food performing simple random\nwalk on lattices. The forager consumes the available food on the site it visits\nand leaves it depleted but can survive up to $S$ steps without food. We\nintroduce the concept of inertia in the dynamics which allows the forager to\nrest with probability $p$ upon consumption of food. The parameter $p$\nsignificantly affects the lifetime of the forager, showing that the inertia can\nbe beneficial for the forager for chosen parameter values. The study of various\nother quantities reveals interesting scaling behavior with $p$ and also\ndeparture from usual diffusive behavior for $0.5 < p < 1$. In addition to\nnumerical approach, the problem has also been studied with analytical approach\nin one dimension and the results agree reasonably well.",
    "pdf_url": "http://arxiv.org/pdf/2505.22262v1",
    "published": "2025-05-28T11:50:01+00:00",
    "categories": [
      "cond-mat.stat-mech",
      "physics.bio-ph",
      "physics.soc-ph"
    ],
    "primary_category": "cond-mat.stat-mech"
  },
  {
    "id": "http://arxiv.org/abs/2505.22261v1",
    "title": "Subsystem Symmetry-Protected Topological Phases from Subsystem SymTFT of 2-Foliated Exotic Tensor Gauge Theory",
    "authors": [
      "Qiang Jia",
      "Zhian Jia"
    ],
    "abstract": "Symmetry topological field theory (SymTFT), or topological holography, posits\na correspondence between symmetries in a $d$-dimensional theory and topological\norder in a $(d+1)$-dimensional theory. In this work, we extend this framework\nto subsystem symmetries and develop subsystem SymTFT as a systematic tool to\ncharacterize and classify subsystem symmetry-protected topological (SSPT)\nphases. For $(2+1)$D gapped phases, we introduce a 2-foliated $(3+1)$D exotic\ntensor gauge theory (which is equivalent to 2-foliated $(3+1)$D BF theory via\nexotic duality) as the subsystem SymTFT and systematically analyze its\ntopological boundary conditions and linearly rigid subsystem symmetries. Taking\nsubsystem symmetry groups $G = \\mathbb{Z}_N$ and $G=\\mathbb{Z}_N \\times\n\\mathbb{Z}_M$ as examples, we demonstrate how to recover the classification\nscheme $\\mathcal{C}[G] = H^{2}(G^{\\times 2}, U(1)) / \\left( H^2(G, U(1))\n\\right)^3$, which was previously derived by examining topological invariant\nunder linear subsystem-symmetric local unitary transformations in the lattice\nHamiltonian formalism. To illustrate the correspondence between field-theoretic\nand lattice descriptions, we further analyze $\\mathbb{Z}_2 \\times \\mathbb{Z}_2$\nand $\\mathbb{Z}_N \\times \\mathbb{Z}_M$ cluster state models as concrete\nexamples.",
    "pdf_url": "http://arxiv.org/pdf/2505.22261v1",
    "published": "2025-05-28T11:47:22+00:00",
    "categories": [
      "cond-mat.str-el",
      "hep-th",
      "math-ph",
      "math.MP",
      "quant-ph"
    ],
    "primary_category": "cond-mat.str-el"
  },
  {
    "id": "http://arxiv.org/abs/2505.22260v1",
    "title": "Cluster sizes, particle displacements and currents in transport mediated by solitary cluster waves",
    "authors": [
      "Alexander P. Antonov",
      "Annika Vonhusen",
      "Artem Ryabov",
      "Philipp Maass"
    ],
    "abstract": "In overdamped particle motion across periodic landscapes, solitary cluster\nwaves can occur at high particle densities and lead to particle transport even\nin the absence of thermal noise. Here we show that for driven motion under a\nconstant drag, the sum of all particle displacements per soliton equals one\nwavelength of the periodic potential. This unit displacement law is used to\ndetermine particle currents mediated by the solitons. We furthermore derive\nproperties of clusters involved in the wave propagation as well as relations\nbetween cluster sizes and soliton numbers.",
    "pdf_url": "http://arxiv.org/pdf/2505.22260v1",
    "published": "2025-05-28T11:46:43+00:00",
    "categories": [
      "cond-mat.stat-mech",
      "nlin.PS"
    ],
    "primary_category": "cond-mat.stat-mech"
  },
  {
    "id": "http://arxiv.org/abs/2505.22259v1",
    "title": "Domain Adaptation of Attention Heads for Zero-shot Anomaly Detection",
    "authors": [
      "Kiyoon Jeong",
      "Jaehyuk Heo",
      "Junyeong Son",
      "Pilsung Kang"
    ],
    "abstract": "Zero-shot anomaly detection (ZSAD) in images is an approach that can detect\nanomalies without access to normal samples, which can be beneficial in various\nrealistic scenarios where model training is not possible. However, existing\nZSAD research has shown limitations by either not considering domain adaptation\nof general-purpose backbone models to anomaly detection domains or by\nimplementing only partial adaptation to some model components. In this paper,\nwe propose HeadCLIP to overcome these limitations by effectively adapting both\ntext and image encoders to the domain. HeadCLIP generalizes the concepts of\nnormality and abnormality through learnable prompts in the text encoder, and\nintroduces learnable head weights to the image encoder to dynamically adjust\nthe features held by each attention head according to domain characteristics.\nAdditionally, we maximize the effect of domain adaptation by introducing a\njoint anomaly score that utilizes domain-adapted pixel-level information for\nimage-level anomaly detection. Experimental results using multiple real\ndatasets in both industrial and medical domains show that HeadCLIP outperforms\nexisting ZSAD techniques at both pixel and image levels. In the industrial\ndomain, improvements of up to 4.9%p in pixel-level mean anomaly detection score\n(mAD) and up to 3.0%p in image-level mAD were achieved, with similar\nimprovements (3.2%p, 3.1%p) in the medical domain.",
    "pdf_url": "http://arxiv.org/pdf/2505.22259v1",
    "published": "2025-05-28T11:45:51+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.22258v1",
    "title": "LiDAR Based Semantic Perception for Forklifts in Outdoor Environments",
    "authors": [
      "Benjamin Serfling",
      "Hannes Reichert",
      "Lorenzo Bayerlein",
      "Konrad Doll",
      "Kati Radkhah-Lens"
    ],
    "abstract": "In this study, we present a novel LiDAR-based semantic segmentation framework\ntailored for autonomous forklifts operating in complex outdoor environments.\nCentral to our approach is the integration of a dual LiDAR system, which\ncombines forward-facing and downward-angled LiDAR sensors to enable\ncomprehensive scene understanding, specifically tailored for industrial\nmaterial handling tasks. The dual configuration improves the detection and\nsegmentation of dynamic and static obstacles with high spatial precision. Using\nhigh-resolution 3D point clouds captured from two sensors, our method employs a\nlightweight yet robust approach that segments the point clouds into\nsafety-critical instance classes such as pedestrians, vehicles, and forklifts,\nas well as environmental classes such as driveable ground, lanes, and\nbuildings. Experimental validation demonstrates that our approach achieves high\nsegmentation accuracy while satisfying strict runtime requirements,\nestablishing its viability for safety-aware, fully autonomous forklift\nnavigation in dynamic warehouse and yard environments.",
    "pdf_url": "http://arxiv.org/pdf/2505.22258v1",
    "published": "2025-05-28T11:45:14+00:00",
    "categories": [
      "cs.RO",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2506.02021v1",
    "title": "Dynamic-Aware Video Distillation: Optimizing Temporal Resolution Based on Video Semantics",
    "authors": [
      "Yinjie Zhao",
      "Heng Zhao",
      "Bihan Wen",
      "Yew-Soon Ong",
      "Joey Tianyi Zhou"
    ],
    "abstract": "With the rapid development of vision tasks and the scaling on datasets and\nmodels, redundancy reduction in vision datasets has become a key area of\nresearch. To address this issue, dataset distillation (DD) has emerged as a\npromising approach to generating highly compact synthetic datasets with\nsignificantly less redundancy while preserving essential information. However,\nwhile DD has been extensively studied for image datasets, DD on video datasets\nremains underexplored. Video datasets present unique challenges due to the\npresence of temporal information and varying levels of redundancy across\ndifferent classes. Existing DD approaches assume a uniform level of temporal\nredundancy across all different video semantics, which limits their\neffectiveness on video datasets. In this work, we propose Dynamic-Aware Video\nDistillation (DAViD), a Reinforcement Learning (RL) approach to predict the\noptimal Temporal Resolution of the synthetic videos. A teacher-in-the-loop\nreward function is proposed to update the RL agent policy. To the best of our\nknowledge, this is the first study to introduce adaptive temporal resolution\nbased on video semantics in video dataset distillation. Our approach\nsignificantly outperforms existing DD methods, demonstrating substantial\nimprovements in performance. This work paves the way for future research on\nmore efficient and semantic-adaptive video dataset distillation research.",
    "pdf_url": "http://arxiv.org/pdf/2506.02021v1",
    "published": "2025-05-28T11:43:58+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.22257v2",
    "title": "Revisiting Group Relative Policy Optimization: Insights into On-Policy and Off-Policy Training",
    "authors": [
      "Youssef Mroueh",
      "Nicolas Dupuis",
      "Brian Belgodere",
      "Apoorva Nitsure",
      "Mattia Rigotti",
      "Kristjan Greenewald",
      "Jiri Navratil",
      "Jerret Ross",
      "Jesus Rios"
    ],
    "abstract": "We revisit Group Relative Policy Optimization (GRPO) in both on-policy and\noff-policy optimization regimes. Our motivation comes from recent work on\noff-policy Proximal Policy Optimization (PPO), which improves training\nstability, sampling efficiency, and memory usage. In addition, a recent\nanalysis of GRPO suggests that estimating the advantage function with\noff-policy samples could be beneficial. Building on these observations, we\nadapt GRPO to the off-policy setting. We show that both on-policy and\noff-policy GRPO objectives yield an improvement in the reward. This result\nmotivates the use of clipped surrogate objectives in the off-policy version of\nGRPO. We then compare the empirical performance of reinforcement learning with\nverifiable rewards in post-training using both GRPO variants. Our results show\nthat off-policy GRPO either significantly outperforms or performs on par with\nits on-policy counterpart.",
    "pdf_url": "http://arxiv.org/pdf/2505.22257v2",
    "published": "2025-05-28T11:42:33+00:00",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.22256v5",
    "title": "Improvement of Solid-Fluid Interaction Scheme in Lattice Boltzmann Immiscible Pseudopotential Models",
    "authors": [
      "Yizhong Chen",
      "Zhibin Wang"
    ],
    "abstract": "The pseudopotential model within the Lattice Boltzmann Method (LBM) framework\nhas emerged as a prominent approach in computational fluid dynamics due to its\ndual strengths in physical intuitiveness and computational tractability.\nHowever, when modeling wettability phenomenon, existing solid-fluid interaction\nschemes exhibit persistent challenges in multi-component immiscible fluid\nsystems, notably manifested through spurious velocity artifacts and unphysical\nmass-transfer boundary layers. This study presents an improved interaction\nscheme that preserves implementation simplicity while effectively mitigating\nthese numerical artifacts. Furthermore, leveraging the enhanced isotropy\ncharacteristics of eighth-order discrete schemes, we develop a novel boundary\ntreatment methodology addressing second-layer lattice data reconstruction at\ncomplex interfaces. To verify the universality of the proposed optimization\nscheme, four benchmark scenarios, including static contact angle measurement on\ncylindrical surface, droplet dynamics through confined geometries, immiscible\ndisplacement processes, and co-current flow in microchannels, are simulated to\ndemonstrate the proposed scheme's capability. The results show that the\nimproved scheme can well simulate various complex immiscible multiphase flows.",
    "pdf_url": "http://arxiv.org/pdf/2505.22256v5",
    "published": "2025-05-28T11:42:05+00:00",
    "categories": [
      "physics.flu-dyn"
    ],
    "primary_category": "physics.flu-dyn"
  },
  {
    "id": "http://arxiv.org/abs/2506.00044v1",
    "title": "Probabilistic intraday electricity price forecasting using generative machine learning",
    "authors": [
      "Jieyu Chen",
      "Sebastian Lerch",
      "Melanie Schienle",
      "Tomasz Serafin",
      "Rafa≈Ç Weron"
    ],
    "abstract": "The growing importance of intraday electricity trading in Europe calls for\nimproved price forecasting and tailored decision-support tools. In this paper,\nwe propose a novel generative neural network model to generate probabilistic\npath forecasts for intraday electricity prices and use them to construct\neffective trading strategies for Germany's continuous-time intraday market. Our\nmethod demonstrates competitive performance in terms of statistical evaluation\nmetrics compared to two state-of-the-art statistical benchmark approaches. To\nfurther assess its economic value, we consider a realistic fixed-volume trading\nscenario and propose various strategies for placing market sell orders based on\nthe path forecasts. Among the different trading strategies, the price paths\ngenerated by our generative model lead to higher profit gains than the\nbenchmark methods. Our findings highlight the potential of generative machine\nlearning tools in electricity price forecasting and underscore the importance\nof economic evaluation.",
    "pdf_url": "http://arxiv.org/pdf/2506.00044v1",
    "published": "2025-05-28T11:41:46+00:00",
    "categories": [
      "stat.AP",
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "stat.AP"
  },
  {
    "id": "http://arxiv.org/abs/2505.22255v1",
    "title": "Train Sparse Autoencoders Efficiently by Utilizing Features Correlation",
    "authors": [
      "Vadim Kurochkin",
      "Yaroslav Aksenov",
      "Daniil Laptev",
      "Daniil Gavrilov",
      "Nikita Balagansky"
    ],
    "abstract": "Sparse Autoencoders (SAEs) have demonstrated significant promise in\ninterpreting the hidden states of language models by decomposing them into\ninterpretable latent directions. However, training SAEs at scale remains\nchallenging, especially when large dictionary sizes are used. While decoders\ncan leverage sparse-aware kernels for efficiency, encoders still require\ncomputationally intensive linear operations with large output dimensions. To\naddress this, we propose KronSAE, a novel architecture that factorizes the\nlatent representation via Kronecker product decomposition, drastically reducing\nmemory and computational overhead. Furthermore, we introduce mAND, a\ndifferentiable activation function approximating the binary AND operation,\nwhich improves interpretability and performance in our factorized framework.",
    "pdf_url": "http://arxiv.org/pdf/2505.22255v1",
    "published": "2025-05-28T11:41:11+00:00",
    "categories": [
      "cs.LG",
      "cs.CL"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.22253v1",
    "title": "Surface plasmons in metamaterial cavities: Scattering by obstacles with negative wave speed",
    "authors": [
      "Yan-Long Fang",
      "Jeffrey Galkowski"
    ],
    "abstract": "We study scattering by metamaterials with negative indices of refraction,\nwhich are known to support \\emph{surface plasmons} -- long-lived states that\nare highly localized at the boundary of the cavity. This type of states has\nfound uses in a variety of modern technologies. In this article, we study\nsurface plasmons in the setting of non-trapping cavities; i.e. when all\nbilliard trajectories outside the cavity escape to infinity. We characterize\nthe indices of refraction which support surface plasmons, show that the\ncorresponding resonances lie super-polynomially close to the real axis,\ndescribe the localization properties of the corresponding resonant states, and\ngive an asymptotic formula for their number.",
    "pdf_url": "http://arxiv.org/pdf/2505.22253v1",
    "published": "2025-05-28T11:41:07+00:00",
    "categories": [
      "math.SP",
      "math-ph",
      "math.AP",
      "math.MP",
      "physics.optics"
    ],
    "primary_category": "math.SP"
  },
  {
    "id": "http://arxiv.org/abs/2505.22254v1",
    "title": "A Unified Online-Offline Framework for Co-Branding Campaign Recommendations",
    "authors": [
      "Xiangxiang Dai",
      "Xiaowei Sun",
      "Jinhang Zuo",
      "Xutong Liu",
      "John C. S. Lui"
    ],
    "abstract": "Co-branding has become a vital strategy for businesses aiming to expand\nmarket reach within recommendation systems. However, identifying effective\ncross-industry partnerships remains challenging due to resource imbalances,\nuncertain brand willingness, and ever-changing market conditions. In this\npaper, we provide the first systematic study of this problem and propose a\nunified online-offline framework to enable co-branding recommendations. Our\napproach begins by constructing a bipartite graph linking ``initiating'' and\n``target'' brands to quantify co-branding probabilities and assess market\nbenefits. During the online learning phase, we dynamically update the graph in\nresponse to market feedback, while striking a balance between exploring new\ncollaborations for long-term gains and exploiting established partnerships for\nimmediate benefits. To address the high initial co-branding costs, our\nframework mitigates redundant exploration, thereby enhancing short-term\nperformance while ensuring sustainable strategic growth. In the offline\noptimization phase, our framework consolidates the interests of multiple\nsub-brands under the same parent brand to maximize overall returns, avoid\nexcessive investment in single sub-brands, and reduce unnecessary costs\nassociated with over-prioritizing a single sub-brand. We present a theoretical\nanalysis of our approach, establishing a highly nontrivial sublinear regret\nbound for online learning in the complex co-branding problem, and enhancing the\napproximation guarantee for the NP-hard offline budget allocation optimization.\nExperiments on both synthetic and real-world co-branding datasets demonstrate\nthe practical effectiveness of our framework, with at least 12\\% improvement.",
    "pdf_url": "http://arxiv.org/pdf/2505.22254v1",
    "published": "2025-05-28T11:41:07+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.22252v1",
    "title": "B-XAIC Dataset: Benchmarking Explainable AI for Graph Neural Networks Using Chemical Data",
    "authors": [
      "Magdalena Proszewska",
      "Tomasz Danel",
      "Dawid Rymarczyk"
    ],
    "abstract": "Understanding the reasoning behind deep learning model predictions is crucial\nin cheminformatics and drug discovery, where molecular design determines their\nproperties. However, current evaluation frameworks for Explainable AI (XAI) in\nthis domain often rely on artificial datasets or simplified tasks, employing\ndata-derived metrics that fail to capture the complexity of real-world\nscenarios and lack a direct link to explanation faithfulness. To address this,\nwe introduce B-XAIC, a novel benchmark constructed from real-world molecular\ndata and diverse tasks with known ground-truth rationales for assigned labels.\nThrough a comprehensive evaluation using B-XAIC, we reveal limitations of\nexisting XAI methods for Graph Neural Networks (GNNs) in the molecular domain.\nThis benchmark provides a valuable resource for gaining deeper insights into\nthe faithfulness of XAI, facilitating the development of more reliable and\ninterpretable models.",
    "pdf_url": "http://arxiv.org/pdf/2505.22252v1",
    "published": "2025-05-28T11:40:48+00:00",
    "categories": [
      "cs.LG",
      "cs.CE"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.22251v2",
    "title": "Evaluation of LLMs in Speech is Often Flawed: Test Set Contamination in Large Language Models for Speech Recognition",
    "authors": [
      "Yuan Tseng",
      "Titouan Parcollet",
      "Rogier van Dalen",
      "Shucong Zhang",
      "Sourav Bhattacharya"
    ],
    "abstract": "Recent work suggests that large language models (LLMs) can improve\nperformance of speech tasks compared to existing systems. To support their\nclaims, results on LibriSpeech and Common Voice are often quoted. However, this\nwork finds that a substantial amount of the LibriSpeech and Common Voice\nevaluation sets appear in public LLM pretraining corpora. This calls into\nquestion the reliability of findings drawn from these two datasets. To measure\ncontamination impact, LLMs trained with/without contamination are compared. A\ncontaminated LLM is more likely to generate test sentences it has seen during\ntraining. Then, speech recognisers based on LLMs are compared. They show only\nsubtle error rate differences if the LLM is contaminated, but assign\nsignificantly higher probabilities to transcriptions seen during LLM training.\nResults show that LLM outputs can be biased by tiny amounts of data\ncontamination, highlighting the importance of evaluating LLM-based speech\nsystems with held-out data.",
    "pdf_url": "http://arxiv.org/pdf/2505.22251v2",
    "published": "2025-05-28T11:39:59+00:00",
    "categories": [
      "eess.AS",
      "cs.CL"
    ],
    "primary_category": "eess.AS"
  },
  {
    "id": "http://arxiv.org/abs/2505.22250v2",
    "title": "YH-MINER: Multimodal Intelligent System for Natural Ecological Reef Metric Extraction",
    "authors": [
      "Mingzhuang Wang",
      "Yvyang Li",
      "Xiyang Zhang",
      "Fei Tan",
      "Qi Shi",
      "Guotao Zhang",
      "Siqi Chen",
      "Yufei Liu",
      "Lei Lei",
      "Ming Zhou",
      "Qiang Lin",
      "Hongqiang Yang"
    ],
    "abstract": "Coral reefs, crucial for sustaining marine biodiversity and ecological\nprocesses (e.g., nutrient cycling, habitat provision), face escalating threats,\nunderscoring the need for efficient monitoring. Coral reef ecological\nmonitoring faces dual challenges of low efficiency in manual analysis and\ninsufficient segmentation accuracy in complex underwater scenarios. This study\ndevelops the YH-MINER system, establishing an intelligent framework centered on\nthe Multimodal Large Model (MLLM) for \"object detection-semantic\nsegmentation-prior input\". The system uses the object detection module\n(mAP@0.5=0.78) to generate spatial prior boxes for coral instances, driving the\nsegment module to complete pixel-level segmentation in low-light and densely\noccluded scenarios. The segmentation masks and finetuned classification\ninstructions are fed into the Qwen2-VL-based multimodal model as prior inputs,\nachieving a genus-level classification accuracy of 88% and simultaneously\nextracting core ecological metrics. Meanwhile, the system retains the\nscalability of the multimodal model through standardized interfaces, laying a\nfoundation for future integration into multimodal agent-based underwater robots\nand supporting the full-process automation of \"image acquisition-prior\ngeneration-real-time analysis\".",
    "pdf_url": "http://arxiv.org/pdf/2505.22250v2",
    "published": "2025-05-28T11:36:18+00:00",
    "categories": [
      "cs.CV",
      "q-bio.QM"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.22249v1",
    "title": "Optimizing Server Locations for Stochastic Emergency Service Systems",
    "authors": [
      "Cheng Hua",
      "Arthur J. Swersey",
      "Wenqian Xing",
      "Yi Zhang"
    ],
    "abstract": "This paper presents a new model for solving the optimal server location\nproblem in a stochastic system that accounts for unit availability,\nheterogeneity, and interdependencies. We show that this problem is NP-hard and\nderive both lower and upper bounds for the optimal solution by leveraging a\nspecial case of the classic $p$-Median problem. To overcome the computational\nchallenges, we propose two Bayesian optimization approaches: (i) a parametric\nmethod that employs a sparse Bayesian linear model with a horseshoe prior\n(SparBL), and (ii) a non-parametric method based on a Gaussian process\nsurrogate model with $p$-Median as mean prior (GP-$p$M). We prove that both\nalgorithms achieve sublinear regret rates and converge to the optimal solution,\nwith the parametric approach demonstrating particular effectiveness in\nhigh-dimensional settings. Numerical experiments and a case study using\nreal-world data from St. Paul, Minnesota emergency response system show that\nour approaches consistently and efficiently identify optimal solutions,\nsignificantly outperforming the $p$-Median solution and other baselines.",
    "pdf_url": "http://arxiv.org/pdf/2505.22249v1",
    "published": "2025-05-28T11:32:36+00:00",
    "categories": [
      "math.OC"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2505.22248v1",
    "title": "Dynamic State-Feedback Control for LPV Systems: Ensuring Stability and LQR Performance",
    "authors": [
      "Armin Gie√üler",
      "Felix Strehle",
      "Jochen Illerhaus",
      "S√∂ren Hohmann"
    ],
    "abstract": "In this paper, we propose a novel dynamic state-feedback controller for\npolytopic linear parameter-varying (LPV) systems with constant input matrix.\nThe controller employs a projected gradient flow method to continuously improve\nits control law and, under established conditions, converges to the optimal\nfeedback gain of the corresponding linear quadratic regulator (LQR) problem\nassociated with constant parameter trajectories. We derive conditions for\nquadratic stability, which can be verified via convex optimization, to ensure\nexponential stability of the LPV system even under arbitrarily fast parameter\nvariations. Additionally, we provide sufficient conditions to guarantee the\nboundedness of the trajectories of the dynamic controller for any parameter\ntrajectory and the convergence of its feedback gains to the optimal LQR gains\nfor constant parameter trajectories. Furthermore, we show that the closed-loop\nsystem is asymptotically stable for constant parameter trajectories under these\nconditions. Simulation results demonstrate that the controller maintains\nstability and improves transient performance.",
    "pdf_url": "http://arxiv.org/pdf/2505.22248v1",
    "published": "2025-05-28T11:30:09+00:00",
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2505.22247v1",
    "title": "Quantum Walk Comb in a Dual Waveguide Quantum Cascade Laser",
    "authors": [
      "Alessio Cargioli",
      "Miguel Montesinos Ballester",
      "Sonja Gantner",
      "Emilio Gini",
      "Mattias Beck",
      "Jerome Faist"
    ],
    "abstract": "Ring quantum cascade lasers (QCLs) proved to be a versatile tool for\ngenerating tunable and stable frequency combs in the mid infrared range in the\nform of quantum walk combs. By homogeneously integrating a racetrack QCL with a\npassive waveguide, which lays on top of the active region plane and therefore\ncan be designed to be fully independent from the laser geometry, we improve the\nlight outcoupling from the ring by more than 2 orders of magnitude reaching a\nmaximum output power of 120 mW. In addition, we show that it is possible to\nachieve quantum walk comb operation in the devices under analysis. Finally, we\nprove that we can change the light dispersion by tuning the parameters of the\npassive waveguide, with a direct impact on the behavior of the generated comb.",
    "pdf_url": "http://arxiv.org/pdf/2505.22247v1",
    "published": "2025-05-28T11:28:29+00:00",
    "categories": [
      "quant-ph",
      "physics.app-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.22246v2",
    "title": "StateSpaceDiffuser: Bringing Long Context to Diffusion World Models",
    "authors": [
      "Nedko Savov",
      "Naser Kazemi",
      "Deheng Zhang",
      "Danda Pani Paudel",
      "Xi Wang",
      "Luc Van Gool"
    ],
    "abstract": "World models have recently become promising tools for predicting realistic\nvisuals based on actions in complex environments. However, their reliance on\nonly a few recent observations leads them to lose track of the long-term\ncontext. Consequently, in just a few steps the generated scenes drift from what\nwas previously observed, undermining the temporal coherence of the sequence.\nThis limitation of the state-of-the-art world models, most of which rely on\ndiffusion, comes from their lack of a lasting environment state. To address\nthis problem, we introduce StateSpaceDiffuser, where a diffusion model is\nenabled to perform long-context tasks by integrating features from a\nstate-space model, representing the entire interaction history. This design\nrestores long-term memory while preserving the high-fidelity synthesis of\ndiffusion models. To rigorously measure temporal consistency, we develop an\nevaluation protocol that probes a model's ability to reinstantiate seen content\nin extended rollouts. Comprehensive experiments show that StateSpaceDiffuser\nsignificantly outperforms a strong diffusion-only baseline, maintaining a\ncoherent visual context for an order of magnitude more steps. It delivers\nconsistent views in both a 2D maze navigation and a complex 3D environment.\nThese results establish that bringing state-space representations into\ndiffusion models is highly effective in demonstrating both visual details and\nlong-term memory.",
    "pdf_url": "http://arxiv.org/pdf/2505.22246v2",
    "published": "2025-05-28T11:27:54+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.22245v1",
    "title": "Direct Algorithms for Reconstructing Small Conductivity Inclusions in Subdiffusion",
    "authors": [
      "Jiho Hong",
      "Bangti Jin",
      "Zhizhang Wu"
    ],
    "abstract": "The subdiffusion model that involves a Caputo fractional derivative in time\nis widely used to describe anomalously slow diffusion processes. In this work\nwe aim at recovering the locations of small conductivity inclusions in the\nmodel from boundary measurement, and develop novel direct algorithms based on\nthe asymptotic expansion of the boundary measurement with respect to the size\nof the inclusions and approximate fundamental solutions. These algorithms\ninvolve only algebraic manipulations and are computationally cheap. To the best\nof our knowledge, they are first direct algorithms for the inverse conductivity\nproblem in the context of the subdiffusion model. Moreover, we provide relevant\ntheoretical underpinnings for the algorithms. Also we present numerical results\nto illustrate their performance under various scenarios, e.g., the size of\ninclusions, noise level of the data, and the number of inclusions, showing that\nthe algorithms are efficient and robust.",
    "pdf_url": "http://arxiv.org/pdf/2505.22245v1",
    "published": "2025-05-28T11:27:48+00:00",
    "categories": [
      "math.NA",
      "cs.NA"
    ],
    "primary_category": "math.NA"
  },
  {
    "id": "http://arxiv.org/abs/2505.22244v1",
    "title": "A Preprocessing Framework for Efficient Approximate Bi-Objective Shortest-Path Computation in the Presence of Correlated Objectives",
    "authors": [
      "Yaron Halle",
      "Ariel Felner",
      "Sven Koenig",
      "Oren Salzman"
    ],
    "abstract": "The bi-objective shortest-path (BOSP) problem seeks to find paths between\nstart and target vertices of a graph while optimizing two conflicting objective\nfunctions. We consider the BOSP problem in the presence of correlated\nobjectives. Such correlations often occur in real-world settings such as road\nnetworks, where optimizing two positively correlated objectives, such as travel\ntime and fuel consumption, is common. BOSP is generally computationally\nchallenging as the size of the search space is exponential in the number of\nobjective functions and the graph size. Bounded sub-optimal BOSP solvers such\nas A*pex alleviate this complexity by approximating the Pareto-optimal solution\nset rather than computing it exactly (given a user-provided approximation\nfactor). As the correlation between objective functions increases, smaller\napproximation factors are sufficient for collapsing the entire Pareto-optimal\nset into a single solution. We leverage this insight to propose an efficient\nalgorithm that reduces the search effort in the presence of correlated\nobjectives. Our approach for computing approximations of the entire\nPareto-optimal set is inspired by graph-clustering algorithms. It uses a\npreprocessing phase to identify correlated clusters within a graph and to\ngenerate a new graph representation. This allows a natural generalization of\nA*pex to run up to five times faster on DIMACS dataset instances, a standard\nbenchmark in the field. To the best of our knowledge, this is the first\nalgorithm proposed that efficiently and effectively exploits correlations in\nthe context of bi-objective search while providing theoretical guarantees on\nsolution quality.",
    "pdf_url": "http://arxiv.org/pdf/2505.22244v1",
    "published": "2025-05-28T11:26:14+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.22243v1",
    "title": "UDuo: Universal Dual Optimization Framework for Online Matching",
    "authors": [
      "Bin Li",
      "Diwei Liu",
      "Zehong Hu",
      "Jia Jia"
    ],
    "abstract": "Online resource allocation under budget constraints critically depends on\nproper modeling of user arrival dynamics. Classical approaches employ\nstochastic user arrival models to derive near-optimal solutions through\nfractional matching formulations of exposed users for downstream allocation\ntasks. However, this is no longer a reasonable assumption when the environment\nchanges dynamically. In this work, We propose the Universal Dual optimization\nframework UDuo, a novel paradigm that fundamentally rethinks online allocation\nthrough three key innovations: (i) a temporal user arrival representation\nvector that explicitly captures distribution shifts in user arrival patterns\nand resource consumption dynamics, (ii) a resource pacing learner with adaptive\nallocation policies that generalize to heterogeneous constraint scenarios, and\n(iii) an online time-series forecasting approach for future user arrival\ndistributions that achieves asymptotically optimal solutions with constraint\nfeasibility guarantees in dynamic environments. Experimental results show that\nUDuo achieves higher efficiency and faster convergence than the traditional\nstochastic arrival model in real-world pricing while maintaining rigorous\ntheoretical validity for general online allocation problems.",
    "pdf_url": "http://arxiv.org/pdf/2505.22243v1",
    "published": "2025-05-28T11:25:50+00:00",
    "categories": [
      "cs.IR",
      "cs.LG"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2505.22242v1",
    "title": "Ito calculus meets the Hubble tension: Effects of small-scale electron density fluctuations on the CMB anisotropies",
    "authors": [
      "Jens Chluba",
      "Geoffrey Vasil",
      "Richard Battye"
    ],
    "abstract": "In this work, we develop a novel formalism to include the effect of electron\ndensity fluctuations at ultra small scales (well below the sound horizon at\nlast scattering) on the observed anisotropies of the Cosmic Microwave\nBackground (CMB). We treat the electron field as an independent stochastic\nvariable and obtain the required ensemble-averaged photon Boltzmann equations\nusing Ito calculus. Beyond changes to the average recombination history (which\ncan be incorporated in the standard approach) our work identifies two new\neffects caused by the clumpiness of the medium. The first is a correction to\nthe Thomson visibility function caused by correlations of the electron\nfluctuations along the line of sight, leading to an additional broadening of\nthe visibility towards higher redshifts which causes extra damping and smearing\nof the CMB anisotropies. The second effect is a reduction of the effective\nscattering rate in the (pre-)recombination era that affects the photon transfer\nfunctions in a non-trivial manner. These new effects are subdominant in LCDM\nbut can be significant in cosmologies with an early onset of structure\nformation (e.g., due to generation of enhanced small-scale power) as suggested\nby a number of indicators (e.g., the abundance of high redshift galaxies\nobserved by JWST). We discuss the relevance of these new effects to the Hubble\ntension, finding that corrections which cannot be captured by simple\nmodifications to the average recombination history arise. This highlights how\nimportant an understanding of the recombination process is in cosmological\ninference, and that a coordinated simulation and analysis campaign is required\nas part of the search for the origin of the various tensions in cosmology.",
    "pdf_url": "http://arxiv.org/pdf/2505.22242v1",
    "published": "2025-05-28T11:22:45+00:00",
    "categories": [
      "astro-ph.CO",
      "astro-ph.GA",
      "hep-th"
    ],
    "primary_category": "astro-ph.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.22241v1",
    "title": "An Exact System Optimum Assignment Model for Transit Demand Management",
    "authors": [
      "Xia Zhou",
      "Mark Wallace",
      "Daniel D. Harabor",
      "Zhenliang Ma"
    ],
    "abstract": "Mass transit systems are experiencing increasing congestion in many cities.\nThe schedule-based transit assignment problem (STAP) involves a joint choice\nmodel for departure times and routes, defining a space-time path in which\npassengers decide when to depart and which route to take. User equilibrium (UE)\nmodels for the STAP indicates the current congestion cost, while a system\noptimum (SO) models can provide insights for congestion relief directions.\nHowever, current STAP methods rely on approximate SO (Approx. SO) models, which\nunderestimate the potential for congestion reduction in the system. The few\nstudies in STAP that compute exact SO solutions ignore realistic constraints\nsuch as hard capacity, multi-line networks, or spatial-temporal competing\ndemand flows. The paper proposes an exact SO method for the STAP that overcomes\nthese limitations. We apply our approach to a case study involving part of the\nHong Kong Mass Transit Railway network, which includes 5 lines, 12 interacting\norigin-destination pairs and 52,717 passengers. Computing an Approx. SO\nsolution for this system indicates a modest potential for congestion reduction\nmeasures, with a cost reduction of 17.39% from the UE solution. Our exact SO\nsolution is 36.35% lower than the UE solution, which is more than double the\npotential for congestion reduction. We then show how the exact SO solution can\nbe used to identify opportunities for congestion reduction: (i) which\norigin-destination pairs have the most potential to reduce congestion; (ii) how\nmany passengers can be reasonably shifted; (iii) future system potential with\nincreasing demand and expanding network capacity.",
    "pdf_url": "http://arxiv.org/pdf/2505.22241v1",
    "published": "2025-05-28T11:22:41+00:00",
    "categories": [
      "math.OC"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2506.00043v1",
    "title": "From Motion to Behavior: Hierarchical Modeling of Humanoid Generative Behavior Control",
    "authors": [
      "Jusheng Zhang",
      "Jinzhou Tang",
      "Sidi Liu",
      "Mingyan Li",
      "Sheng Zhang",
      "Jian Wang",
      "Keze Wang"
    ],
    "abstract": "Human motion generative modeling or synthesis aims to characterize\ncomplicated human motions of daily activities in diverse real-world\nenvironments. However, current research predominantly focuses on either\nlow-level, short-period motions or high-level action planning, without taking\ninto account the hierarchical goal-oriented nature of human activities. In this\nwork, we take a step forward from human motion generation to human behavior\nmodeling, which is inspired by cognitive science. We present a unified\nframework, dubbed Generative Behavior Control (GBC), to model diverse human\nmotions driven by various high-level intentions by aligning motions with\nhierarchical behavior plans generated by large language models (LLMs). Our\ninsight is that human motions can be jointly controlled by task and motion\nplanning in robotics, but guided by LLMs to achieve improved motion diversity\nand physical fidelity. Meanwhile, to overcome the limitations of existing\nbenchmarks, i.e., lack of behavioral plans, we propose GBC-100K dataset\nannotated with a hierarchical granularity of semantic and motion plans driven\nby target goals. Our experiments demonstrate that GBC can generate more diverse\nand purposeful high-quality human motions with 10* longer horizons compared\nwith existing methods when trained on GBC-100K, laying a foundation for future\nresearch on behavioral modeling of human motions. Our dataset and source code\nwill be made publicly available.",
    "pdf_url": "http://arxiv.org/pdf/2506.00043v1",
    "published": "2025-05-28T11:21:33+00:00",
    "categories": [
      "cs.RO",
      "cs.CV"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.22240v2",
    "title": "BioHopR: A Benchmark for Multi-Hop, Multi-Answer Reasoning in Biomedical Domain",
    "authors": [
      "Yunsoo Kim",
      "Yusuf Abdulle",
      "Honghan Wu"
    ],
    "abstract": "Biomedical reasoning often requires traversing interconnected relationships\nacross entities such as drugs, diseases, and proteins. Despite the increasing\nprominence of large language models (LLMs), existing benchmarks lack the\nability to evaluate multi-hop reasoning in the biomedical domain, particularly\nfor queries involving one-to-many and many-to-many relationships. This gap\nleaves the critical challenges of biomedical multi-hop reasoning underexplored.\nTo address this, we introduce BioHopR, a novel benchmark designed to evaluate\nmulti-hop, multi-answer reasoning in structured biomedical knowledge graphs.\nBuilt from the comprehensive PrimeKG, BioHopR includes 1-hop and 2-hop\nreasoning tasks that reflect real-world biomedical complexities.\n  Evaluations of state-of-the-art models reveal that O3-mini, a proprietary\nreasoning-focused model, achieves 37.93% precision on 1-hop tasks and 14.57% on\n2-hop tasks, outperforming proprietary models such as GPT4O and open-source\nbiomedical models including HuatuoGPT-o1-70B and Llama-3.3-70B. However, all\nmodels exhibit significant declines in multi-hop performance, underscoring the\nchallenges of resolving implicit reasoning steps in the biomedical domain. By\naddressing the lack of benchmarks for multi-hop reasoning in biomedical domain,\nBioHopR sets a new standard for evaluating reasoning capabilities and\nhighlights critical gaps between proprietary and open-source models while\npaving the way for future advancements in biomedical LLMs.",
    "pdf_url": "http://arxiv.org/pdf/2505.22240v2",
    "published": "2025-05-28T11:19:01+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.02020v1",
    "title": "Improve Multi-Modal Embedding Learning via Explicit Hard Negative Gradient Amplifying",
    "authors": [
      "Youze Xue",
      "Dian Li",
      "Gang Liu"
    ],
    "abstract": "With the rapid advancement of multi-modal large language models (MLLMs) in\nrecent years, the foundational Contrastive Language-Image Pretraining (CLIP)\nframework has been successfully extended to MLLMs, enabling more powerful and\nuniversal multi-modal embeddings for a wide range of retrieval tasks. Despite\nthese developments, the core contrastive learning paradigm remains largely\nunchanged from CLIP-style models to MLLMs. Within this framework, the effective\nmining of hard negative samples continues to be a critical factor for enhancing\nperformance. Prior works have introduced both offline and online strategies for\nhard negative mining to improve the efficiency of contrastive learning. While\nthese approaches have led to improved multi-modal embeddings, the specific\ncontribution of each hard negative sample to the learning process has not been\nthoroughly investigated. In this work, we conduct a detailed analysis of the\ngradients of the info-NCE loss with respect to the query, positive, and\nnegative samples, elucidating the role of hard negatives in updating model\nparameters. Building upon this analysis, we propose to explicitly amplify the\ngradients associated with hard negative samples, thereby encouraging the model\nto learn more discriminative embeddings. Our multi-modal embedding model,\ntrained with the proposed Explicit Gradient Amplifier and based on the\nLLaVA-OneVision-7B architecture, achieves state-of-the-art performance on the\nMMEB benchmark compared to previous methods utilizing the same MLLM backbone.\nFurthermore, when integrated with our self-developed MLLM, QQMM, our approach\nattains the top rank on the MMEB leaderboard. Code and models are released on\nhttps://github.com/QQ-MM/QQMM-embed.",
    "pdf_url": "http://arxiv.org/pdf/2506.02020v1",
    "published": "2025-05-28T11:18:19+00:00",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.22239v1",
    "title": "Finite-size effects of the excess entropy computed from integrating the radial distribution function",
    "authors": [
      "Darshan Raju",
      "Mahinder Ramdin",
      "Jean-Marc Simon",
      "Peter Kruger",
      "Thijs J. H. Vlugt"
    ],
    "abstract": "Computation of the excess entropy from the second-order density expansion of\nthe entropy holds strictly for infinite systems in the limit of small\ndensities. For the reliable and efficient computation of excess entropy, it is\nimportant to understand finite-size effects. Here, expressions to compute\nexcess entropy and Kirkwood-Buff (KB) integrals by integrating the Radial\nDistribution Function (RDF) in a finite volume are derived, from which Sex and\nKB integrals in the thermodynamic limit are obtained. The scaling of these\nintegrals with system size is studied. We show that the integrals of excess\nentropy converge faster than KB integrals. We compute excess entropy from Monte\nCarlo simulations using the Wang-Ramirez-Dobnikar-Frenkel pair interaction\npotential by thermodynamic integration and by integration of the RDF. We show\nthat excess entropy computed by integrating the RDF is identical to that of\nexcess entropy computed from thermodynamic integration at low densities,\nprovided the RDF is extrapolated to the thermodynamic limit. At higher\ndensities, differences up to 20% are observed.",
    "pdf_url": "http://arxiv.org/pdf/2505.22239v1",
    "published": "2025-05-28T11:17:02+00:00",
    "categories": [
      "cond-mat.stat-mech",
      "physics.chem-ph"
    ],
    "primary_category": "cond-mat.stat-mech"
  },
  {
    "id": "http://arxiv.org/abs/2505.22238v2",
    "title": "Yambda-5B -- A Large-Scale Multi-modal Dataset for Ranking And Retrieval",
    "authors": [
      "A. Ploshkin",
      "V. Tytskiy",
      "A. Pismenny",
      "V. Baikalov",
      "E. Taychinov",
      "A. Permiakov",
      "D. Burlakov",
      "E. Krofto",
      "N. Savushkin"
    ],
    "abstract": "We present Yambda-5B, a large-scale open dataset sourced from the Yandex\nMusic streaming platform. Yambda-5B contains 4.79 billion user-item\ninteractions from 1 million users across 9.39 million tracks. The dataset\nincludes two primary types of interactions: implicit feedback (listening\nevents) and explicit feedback (likes, dislikes, unlikes and undislikes). In\naddition, we provide audio embeddings for most tracks, generated by a\nconvolutional neural network trained on audio spectrograms. A key\ndistinguishing feature of Yambda-5B is the inclusion of the is_organic flag,\nwhich separates organic user actions from recommendation-driven events. This\ndistinction is critical for developing and evaluating machine learning\nalgorithms, as Yandex Music relies on recommender systems to personalize track\nselection for users. To support rigorous benchmarking, we introduce an\nevaluation protocol based on a Global Temporal Split, allowing recommendation\nalgorithms to be assessed in conditions that closely mirror real-world use. We\nreport benchmark results for standard baselines (ItemKNN, iALS) and advanced\nmodels (SANSA, SASRec) using a variety of evaluation metrics. By releasing\nYambda-5B to the community, we aim to provide a readily accessible,\nindustrial-scale resource to advance research, foster innovation, and promote\nreproducible results in recommender systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.22238v2",
    "published": "2025-05-28T11:12:57+00:00",
    "categories": [
      "cs.IR",
      "cs.LG"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2505.22237v1",
    "title": "Essential dimension of sequences of quaternion algebras",
    "authors": [
      "Fatma Kader Bing√∂l",
      "Adam Chapman",
      "Ahmed Laghribi"
    ],
    "abstract": "We study the essential dimension of the set of isometry classes of $m$-tuples\n$(\\varphi_1,...,\\varphi_m)$ of quadratic $n$-fold Pfister forms over a field\n$F$ such that the Witt class of $\\varphi_1 \\perp \\ldots \\perp \\varphi_m$ lies\nin $I_q^{n+1}F$. We show that the essential dimension is equal to $n+1$, when\n$m=3$, and is either $4$ or $5$, when $n=\\text{char} F=2$, $m=4$.",
    "pdf_url": "http://arxiv.org/pdf/2505.22237v1",
    "published": "2025-05-28T11:12:23+00:00",
    "categories": [
      "math.NT",
      "11E04, 16K20"
    ],
    "primary_category": "math.NT"
  },
  {
    "id": "http://arxiv.org/abs/2505.22236v1",
    "title": "A Linguistically Motivated Analysis of Intonational Phrasing in Text-to-Speech Systems: Revealing Gaps in Syntactic Sensitivity",
    "authors": [
      "Charlotte Pouw",
      "Afra Alishahi",
      "Willem Zuidema"
    ],
    "abstract": "We analyze the syntactic sensitivity of Text-to-Speech (TTS) systems using\nmethods inspired by psycholinguistic research. Specifically, we focus on the\ngeneration of intonational phrase boundaries, which can often be predicted by\nidentifying syntactic boundaries within a sentence. We find that TTS systems\nstruggle to accurately generate intonational phrase boundaries in sentences\nwhere syntactic boundaries are ambiguous (e.g., garden path sentences or\nsentences with attachment ambiguity). In these cases, systems need superficial\ncues such as commas to place boundaries at the correct positions. In contrast,\nfor sentences with simpler syntactic structures, we find that systems do\nincorporate syntactic cues beyond surface markers. Finally, we finetune models\non sentences without commas at the syntactic boundary positions, encouraging\nthem to focus on more subtle linguistic cues. Our findings indicate that this\nleads to more distinct intonation patterns that better reflect the underlying\nstructure.",
    "pdf_url": "http://arxiv.org/pdf/2505.22236v1",
    "published": "2025-05-28T11:11:29+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.22235v1",
    "title": "Optimal kernel regression bounds under energy-bounded noise",
    "authors": [
      "Amon Lahr",
      "Johannes K√∂hler",
      "Anna Scampicchio",
      "Melanie N. Zeilinger"
    ],
    "abstract": "Non-conservative uncertainty bounds are key for both assessing an estimation\nalgorithm's accuracy and in view of downstream tasks, such as its deployment in\nsafety-critical contexts. In this paper, we derive a tight, non-asymptotic\nuncertainty bound for kernel-based estimation, which can also handle correlated\nnoise sequences. Its computation relies on a mild norm-boundedness assumption\non the unknown function and the noise, returning the worst-case function\nrealization within the hypothesis class at an arbitrary query input location.\nThe value of this function is shown to be given in terms of the posterior mean\nand covariance of a Gaussian process for an optimal choice of the measurement\nnoise covariance. By rigorously analyzing the proposed approach and comparing\nit with other results in the literature, we show its effectiveness in returning\ntight and easy-to-compute bounds for kernel-based estimates.",
    "pdf_url": "http://arxiv.org/pdf/2505.22235v1",
    "published": "2025-05-28T11:11:24+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.22234v1",
    "title": "Evolution of repositories and privacy laws: commit activities in the GDPR and CCPA era",
    "authors": [
      "Georgia M. Kapitsaki",
      "Maria Papoutsoglou"
    ],
    "abstract": "Free and open source software has gained a lot of momentum in the industry\nand the research community. The latest advances in privacy legislation,\nincluding the EU General Data Protection Regulation (GDPR) and the California\nConsumer Privacy Act (CCPA), have forced the community to pay special attention\nto users' data privacy. The main aim of this work is to examine software\nrepositories that are acting on privacy laws. We have collected commit data\nfrom GitHub repositories in order to understand indications on main data\nprivacy laws (GDPR, CCPA, CPRA, UK DPA) in the last years. Via an automated\nprocess, we analyzed 37,213 commits from 12,391 repositories since 2016,\nwhereas 594 commits from the 70 most popular repositories of the dataset were\nmanually analyzed. We observe that most commits were performed on the year the\nlaw came into effect and privacy relevant terms appear in the commit messages,\nwhereas reference to specific data privacy user rights is scarce. The study\nshowed that more educational activities on data privacy user rights are needed,\nas well as tools for privacy recommendations, whereas verifying actual\ncompliance via source code execution is a useful direction for software\nengineering researchers.",
    "pdf_url": "http://arxiv.org/pdf/2505.22234v1",
    "published": "2025-05-28T11:10:58+00:00",
    "categories": [
      "cs.SE"
    ],
    "primary_category": "cs.SE"
  },
  {
    "id": "http://arxiv.org/abs/2505.22233v1",
    "title": "Moduli of stable supermaps",
    "authors": [
      "Ugo Bruzzo",
      "Daniel Hern√°ndez Ruip√©rez"
    ],
    "abstract": "We review the notion of stable supermap from SUSY curves to a fixed target\nsuperscheme, and prove that when the target is (super)projective, stable\nsupermaps are parameterized by an algebraic superstack with superschematic and\nseparated diagonal. We characterize the bosonic reduction of this moduli\nsuperstack and see that it has a surjective morphism onto the moduli stack of\nstable maps from spin curves to the bosonic reduction of the target, whose\nfibers are linear schemes; for this reason, the moduli superstack of stable\nsupermaps is not proper unless such linear schemes reduce to a point. Using\nManin-Penkov-Voronov's super Grothendieck-Riemann-Roch theorem we also make a\nformal computation of the virtual dimension of the moduli superstack, which\nagrees with the characterization of the bosonic reduction just mentioned and\nwith the dimension formula for the case of bosonic target existing in the\nliterature.",
    "pdf_url": "http://arxiv.org/pdf/2505.22233v1",
    "published": "2025-05-28T11:08:49+00:00",
    "categories": [
      "math.AG",
      "hep-th",
      "math-ph",
      "math.MP",
      "Primary: 14D23, Secondary: 14A20, 14H10, 14M30, 81T30, 83E30"
    ],
    "primary_category": "math.AG"
  },
  {
    "id": "http://arxiv.org/abs/2505.22232v2",
    "title": "Judging Quality Across Languages: A Multilingual Approach to Pretraining Data Filtering with Language Models",
    "authors": [
      "Mehdi Ali",
      "Manuel Brack",
      "Max L√ºbbering",
      "Elias Wendt",
      "Abbas Goher Khan",
      "Richard Rutmann",
      "Alex Jude",
      "Maurice Kraus",
      "Alexander Arno Weber",
      "David Kacz√©r",
      "Florian Mai",
      "Lucie Flek",
      "Rafet Sifa",
      "Nicolas Flores-Herr",
      "Joachim K√∂hler",
      "Patrick Schramowski",
      "Michael Fromm",
      "Kristian Kersting"
    ],
    "abstract": "High-quality multilingual training data is essential for effectively\npretraining large language models (LLMs). Yet, the availability of suitable\nopen-source multilingual datasets remains limited. Existing state-of-the-art\ndatasets mostly rely on heuristic filtering methods, restricting both their\ncross-lingual transferability and scalability. Here, we introduce JQL, a\nsystematic approach that efficiently curates diverse and high-quality\nmultilingual data at scale while significantly reducing computational demands.\nJQL distills LLMs' annotation capabilities into lightweight annotators based on\npretrained multilingual embeddings. These models exhibit robust multilingual\nand cross-lingual performance, even for languages and scripts unseen during\ntraining. Evaluated empirically across 35 languages, the resulting annotation\npipeline substantially outperforms current heuristic filtering methods like\nFineweb2. JQL notably enhances downstream model training quality and increases\ndata retention rates. Our research provides practical insights and valuable\nresources for multilingual data curation, raising the standards of multilingual\ndataset development.",
    "pdf_url": "http://arxiv.org/pdf/2505.22232v2",
    "published": "2025-05-28T11:06:54+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.22231v1",
    "title": "Advancing Hearing Assessment: An ASR-Based Frequency-Specific Speech Test for Diagnosing Presbycusis",
    "authors": [
      "Stefan Bleeck"
    ],
    "abstract": "Traditional audiometry often fails to fully characterize the functional\nimpact of hearing loss on speech understanding, particularly supra-threshold\ndeficits and frequency-specific perception challenges in conditions like\npresbycusis. This paper presents the development and simulated evaluation of a\nnovel Automatic Speech Recognition (ASR)-based frequency-specific speech test\ndesigned to provide granular diagnostic insights. Our approach leverages ASR to\nsimulate the perceptual effects of moderate sloping hearing loss by processing\nspeech stimuli under controlled acoustic degradation and subsequently analyzing\nphoneme-level confusion patterns. Key findings indicate that simulated hearing\nloss introduces specific phoneme confusions, predominantly affecting\nhigh-frequency consonants (e.g., alveolar/palatal to labiodental substitutions)\nand leading to significant phoneme deletions, consistent with the acoustic cues\ndegraded in presbycusis. A test battery curated from these ASR-derived\nconfusions demonstrated diagnostic value, effectively differentiating between\nsimulated normal-hearing and hearing-impaired listeners in a comprehensive\nsimulation. This ASR-driven methodology offers a promising avenue for\ndeveloping objective, granular, and frequency-specific hearing assessment tools\nthat complement traditional audiometry. Future work will focus on validating\nthese findings with human participants and exploring the integration of\nadvanced AI models for enhanced diagnostic precision.",
    "pdf_url": "http://arxiv.org/pdf/2505.22231v1",
    "published": "2025-05-28T11:06:22+00:00",
    "categories": [
      "cs.SD",
      "cs.CL",
      "eess.AS"
    ],
    "primary_category": "cs.SD"
  },
  {
    "id": "http://arxiv.org/abs/2505.22230v1",
    "title": "Enjoying Information Dividend: Gaze Track-based Medical Weakly Supervised Segmentation",
    "authors": [
      "Zhisong Wang",
      "Yiwen Ye",
      "Ziyang Chen",
      "Yong Xia"
    ],
    "abstract": "Weakly supervised semantic segmentation (WSSS) in medical imaging struggles\nwith effectively using sparse annotations. One promising direction for WSSS\nleverages gaze annotations, captured via eye trackers that record regions of\ninterest during diagnostic procedures. However, existing gaze-based methods,\nsuch as GazeMedSeg, do not fully exploit the rich information embedded in gaze\ndata. In this paper, we propose GradTrack, a framework that utilizes\nphysicians' gaze track, including fixation points, durations, and temporal\norder, to enhance WSSS performance. GradTrack comprises two key components:\nGaze Track Map Generation and Track Attention, which collaboratively enable\nprogressive feature refinement through multi-level gaze supervision during the\ndecoding process. Experiments on the Kvasir-SEG and NCI-ISBI datasets\ndemonstrate that GradTrack consistently outperforms existing gaze-based\nmethods, achieving Dice score improvements of 3.21\\% and 2.61\\%, respectively.\nMoreover, GradTrack significantly narrows the performance gap with fully\nsupervised models such as nnUNet.",
    "pdf_url": "http://arxiv.org/pdf/2505.22230v1",
    "published": "2025-05-28T11:05:50+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.22229v1",
    "title": "Two-stage Audio-Visual Target Speaker Extraction System for Real-Time Processing On Edge Device",
    "authors": [
      "Zixuan Li",
      "Xueliang Zhang",
      "Lei Miao",
      "Zhipeng Yan"
    ],
    "abstract": "Audio-Visual Target Speaker Extraction (AVTSE) aims to isolate a target\nspeaker's voice in a multi-speaker environment with visual cues as auxiliary.\nMost of the existing AVTSE methods encode visual and audio features\nsimultaneously, resulting in extremely high computational complexity and making\nit impractical for real-time processing on edge devices. To tackle this issue,\nwe proposed a two-stage ultra-compact AVTSE system. Specifically, in the first\nstage, a compact network is employed for voice activity detection (VAD) using\nvisual information. In the second stage, the VAD results are combined with\naudio inputs to isolate the target speaker's voice. Experiments show that the\nproposed system effectively suppresses background noise and interfering voices\nwhile spending little computational resources.",
    "pdf_url": "http://arxiv.org/pdf/2505.22229v1",
    "published": "2025-05-28T11:05:24+00:00",
    "categories": [
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.SD"
  },
  {
    "id": "http://arxiv.org/abs/2505.22228v1",
    "title": "GoMatching++: Parameter- and Data-Efficient Arbitrary-Shaped Video Text Spotting and Benchmarking",
    "authors": [
      "Haibin He",
      "Jing Zhang",
      "Maoyuan Ye",
      "Juhua Liu",
      "Bo Du",
      "Dacheng Tao"
    ],
    "abstract": "Video text spotting (VTS) extends image text spotting (ITS) by adding text\ntracking, significantly increasing task complexity. Despite progress in VTS,\nexisting methods still fall short of the performance seen in ITS. This paper\nidentifies a key limitation in current video text spotters: limited recognition\ncapability, even after extensive end-to-end training. To address this, we\npropose GoMatching++, a parameter- and data-efficient method that transforms an\noff-the-shelf image text spotter into a video specialist. The core idea lies in\nfreezing the image text spotter and introducing a lightweight, trainable\ntracker, which can be optimized efficiently with minimal training data. Our\napproach includes two key components: (1) a rescoring mechanism to bridge the\ndomain gap between image and video data, and (2) the LST-Matcher, which\nenhances the frozen image text spotter's ability to handle video text. We\nexplore various architectures for LST-Matcher to ensure efficiency in both\nparameters and training data. As a result, GoMatching++ sets new performance\nrecords on challenging benchmarks such as ICDAR15-video, DSText, and BOVText,\nwhile significantly reducing training costs. To address the lack of curved text\ndatasets in VTS, we introduce ArTVideo, a new benchmark featuring over 30%\ncurved text with detailed annotations. We also provide a comprehensive\nstatistical analysis and experimental results for ArTVideo. We believe that\nGoMatching++ and the ArTVideo benchmark will drive future advancements in video\ntext spotting. The source code, models and dataset are publicly available at\nhttps://github.com/Hxyz-123/GoMatching.",
    "pdf_url": "http://arxiv.org/pdf/2505.22228v1",
    "published": "2025-05-28T11:02:45+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.22227v3",
    "title": "Unified Magnetoelectric Mechanism for Spin Splitting in Magnets",
    "authors": [
      "Carlos Mera Acosta"
    ],
    "abstract": "We identify a magnetoelectric correction that completes the theoretical\ndescription of spin splitting (SS) in magnetic systems. Derived from the Dirac\nequation, this term couples local magnetic moments to the scalar electric\npotential, providing a third fundamental mechanism, alongside Zeeman and\nspin-orbit coupling (SOC), that governs SS in ferromagnets, antiferromagnets,\nand altermagnets. In compensated magnets, the proposed relativistic correction\ndepends on the difference in electric potential between symmetry-inequivalent\nmotifs, $\\mathcal{H}_{\\text{ME}} = -\\mu_{\\text{B}}\\eta_0(\\mathcal{V}_1 -\n\\mathcal{V}_2)\\boldsymbol{\\sigma} \\cdot \\boldsymbol{m}$, which explains how\nfinite SS emerges in the absence of SOC and enables a complete classification\nof momentum dependence and motif connectivity across all 32 point groups.\nThrough illustrative examples, we show that distinct SS behaviors - quadratic\n($d$-wave altermagnets), linear ($p$-wave altermagnets or spin Zeeman effect),\nand $k$-independent (SS at $\\Gamma$ or fully compensated ferrimagnets) - are\nspecific manifestations of the proposed magnetoelectric relativistic mechanism,\neach governed by electric quadrupoles, dipoles, or monopoles, respectively. The\nformalism naturally extends to higher-order multipoles and more complex\nsymmetries. This work establishes a unified framework for SS in magnets and\nprovides a predictive tool for analyzing symmetry-allowed SS in magnetic\nmaterials.",
    "pdf_url": "http://arxiv.org/pdf/2505.22227v3",
    "published": "2025-05-28T11:02:37+00:00",
    "categories": [
      "cond-mat.str-el",
      "cond-mat.other"
    ],
    "primary_category": "cond-mat.str-el"
  },
  {
    "id": "http://arxiv.org/abs/2506.00222v1",
    "title": "Power-Linear Polar Directional Fields",
    "authors": [
      "Jiabao Brad Wang",
      "Amir Vaxman"
    ],
    "abstract": "We introduce a novel method for directional-field design on meshes, enabling\nusers to specify singularities at any location on a mesh. Our method uses a\npiecewise power-linear representation for phase and scale, offering precise\ncontrol over field topology. The resulting fields are smooth and accommodate\nany singularity index and field symmetry. With this representation, we mitigate\nthe artifacts caused by coarse or uneven meshes. We showcase our approach on\nmeshes with diverse topologies and triangle qualities.",
    "pdf_url": "http://arxiv.org/pdf/2506.00222v1",
    "published": "2025-05-28T11:01:06+00:00",
    "categories": [
      "cs.GR"
    ],
    "primary_category": "cs.GR"
  },
  {
    "id": "http://arxiv.org/abs/2505.23835v1",
    "title": "Say What You Mean: Natural Language Access Control with Large Language Models for Internet of Things",
    "authors": [
      "Ye Cheng",
      "Minghui Xu",
      "Yue Zhang",
      "Kun Li",
      "Hao Wu",
      "Yechao Zhang",
      "Shaoyong Guo",
      "Wangjie Qiu",
      "Dongxiao Yu",
      "Xiuzhen Cheng"
    ],
    "abstract": "Access control in the Internet of Things (IoT) is becoming increasingly\ncomplex, as policies must account for dynamic and contextual factors such as\ntime, location, user behavior, and environmental conditions. However, existing\nplatforms either offer only coarse-grained controls or rely on rigid rule\nmatching, making them ill-suited for semantically rich or ambiguous access\nscenarios. Moreover, the policy authoring process remains fragmented: domain\nexperts describe requirements in natural language, but developers must manually\ntranslate them into code, introducing semantic gaps and potential\nmisconfiguration. In this work, we present LACE, the Language-based Access\nControl Engine, a hybrid framework that leverages large language models (LLMs)\nto bridge the gap between human intent and machine-enforceable logic. LACE\ncombines prompt-guided policy generation, retrieval-augmented reasoning, and\nformal validation to support expressive, interpretable, and verifiable access\ncontrol. It enables users to specify policies in natural language,\nautomatically translates them into structured rules, validates semantic\ncorrectness, and makes access decisions using a hybrid LLM-rule-based engine.\nWe evaluate LACE in smart home environments through extensive experiments. LACE\nachieves 100% correctness in verified policy generation and up to 88% decision\naccuracy with 0.79 F1-score using DeepSeek-V3, outperforming baselines such as\nGPT-3.5 and Gemini. The system also demonstrates strong scalability under\nincreasing policy volume and request concurrency. Our results highlight LACE's\npotential to enable secure, flexible, and user-friendly access control across\nreal-world IoT platforms.",
    "pdf_url": "http://arxiv.org/pdf/2505.23835v1",
    "published": "2025-05-28T10:59:00+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.22226v1",
    "title": "Hadaptive-Net: Efficient Vision Models via Adaptive Cross-Hadamard Synergy",
    "authors": [
      "Xuyang Zhang",
      "Xi Zhang",
      "Liang Chen",
      "Hao Shi",
      "Qingshan Guo"
    ],
    "abstract": "Recent studies have revealed the immense potential of Hadamard product in\nenhancing network representational capacity and dimensional compression.\nHowever, despite its theoretical promise, this technique has not been\nsystematically explored or effectively applied in practice, leaving its full\ncapabilities underdeveloped. In this work, we first analyze and identify the\nadvantages of Hadamard product over standard convolutional operations in\ncross-channel interaction and channel expansion. Building upon these insights,\nwe propose a computationally efficient module: Adaptive Cross-Hadamard (ACH),\nwhich leverages adaptive cross-channel Hadamard products for high-dimensional\nchannel expansion. Furthermore, we introduce Hadaptive-Net (Hadamard Adaptive\nNetwork), a lightweight network backbone for visual tasks, which is\ndemonstrated through experiments that it achieves an unprecedented balance\nbetween inference speed and accuracy through our proposed module.",
    "pdf_url": "http://arxiv.org/pdf/2505.22226v1",
    "published": "2025-05-28T10:58:56+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.22225v1",
    "title": "Reflection Spectra of Accretion Disks Illuminated by an Off-Axis Corona",
    "authors": [
      "Yuan Feng",
      "Ye-Fei Yuan",
      "Shuang-Nan Zhang"
    ],
    "abstract": "Relativistic reflection features in the X-ray spectra of accreting black\nholes are considered to be generated by the illumination of the accretion disk\nby the hot corona. In this work, we present a numerical method for the emission\nline profile and the reflection spectrum produced by an off-axis X-ray source.\nThe X-ray source is considered as a point source, as in the lamppost scenario,\nexcept that it is located off-axis and moves at arbitrary velocity. The\nobserved flux for the distant observer is calculated directly without priority\nevaluation of the emissivity on the accretion disk, which allows our model to\nbe applicable to the point source that deviates from the axis of the black hole\nspins and moves with a velocity. To study the impact of the off-axis geometry\non the measurement of source properties, we simulate observations for a black\nhole binary with NuSTAR and eXTP. We compare the simulation with the\nobservation of the phase-resolved spectra of the low-frequency quasiperiodic\noscillation observed by the Insight Hard X-ray Modulation Telescope. Due to the\nnonaxisymmetric illumination on the accretion disk, parameters of the model are\nnot reproduced by the lamppost model, including the corona height, radial\nvelocity, and the reflection fraction. On the other hand, all the model\nparameters are recovered through the off-axis model.",
    "pdf_url": "http://arxiv.org/pdf/2505.22225v1",
    "published": "2025-05-28T10:58:43+00:00",
    "categories": [
      "astro-ph.HE"
    ],
    "primary_category": "astro-ph.HE"
  },
  {
    "id": "http://arxiv.org/abs/2505.23834v1",
    "title": "Patient-Aware Feature Alignment for Robust Lung Sound Classification:Cohesion-Separation and Global Alignment Losses",
    "authors": [
      "Seung Gyu Jeong",
      "Seong Eun Kim"
    ],
    "abstract": "Lung sound classification is vital for early diagnosis of respiratory\ndiseases. However, biomedical signals often exhibit inter-patient variability\neven among patients with the same symptoms, requiring a learning approach that\nconsiders individual differences. We propose a Patient-Aware Feature Alignment\n(PAFA) framework with two novel losses, Patient Cohesion-Separation Loss (PCSL)\nand Global Patient Alignment Loss (GPAL). PCSL clusters features of the same\npatient while separating those from other patients to capture patient\nvariability, whereas GPAL draws each patient's centroid toward a global center,\npreventing feature space fragmentation. Our method achieves outstanding results\non the ICBHI dataset with a score of 64.84\\% for four-class and 72.08\\% for\ntwo-class classification. These findings highlight PAFA's ability to capture\nindividualized patterns and demonstrate performance gains in distinct patient\nclusters, offering broader applications for patient-centered healthcare.",
    "pdf_url": "http://arxiv.org/pdf/2505.23834v1",
    "published": "2025-05-28T10:56:55+00:00",
    "categories": [
      "cs.SD",
      "cs.LG",
      "eess.AS"
    ],
    "primary_category": "cs.SD"
  },
  {
    "id": "http://arxiv.org/abs/2505.22224v1",
    "title": "Solver-Free Decision-Focused Learning for Linear Optimization Problems",
    "authors": [
      "Senne Berden",
      "Ali ƒ∞rfan Mahmutoƒüullarƒ±",
      "Dimos Tsouros",
      "Tias Guns"
    ],
    "abstract": "Mathematical optimization is a fundamental tool for decision-making in a wide\nrange of applications. However, in many real-world scenarios, the parameters of\nthe optimization problem are not known a priori and must be predicted from\ncontextual features. This gives rise to predict-then-optimize problems, where a\nmachine learning model predicts problem parameters that are then used to make\ndecisions via optimization. A growing body of work on decision-focused learning\n(DFL) addresses this setting by training models specifically to produce\npredictions that maximize downstream decision quality, rather than accuracy.\nWhile effective, DFL is computationally expensive, because it requires solving\nthe optimization problem with the predicted parameters at each loss evaluation.\nIn this work, we address this computational bottleneck for linear optimization\nproblems, a common class of problems in both DFL literature and real-world\napplications. We propose a solver-free training method that exploits the\ngeometric structure of linear optimization to enable efficient training with\nminimal degradation in solution quality. Our method is based on the insight\nthat a solution is optimal if and only if it achieves an objective value that\nis at least as good as that of its adjacent vertices on the feasible polytope.\nBuilding on this, our method compares the estimated quality of the ground-truth\noptimal solution with that of its precomputed adjacent vertices, and uses this\nas loss function. Experiments demonstrate that our method significantly reduces\ncomputational cost while maintaining high decision quality.",
    "pdf_url": "http://arxiv.org/pdf/2505.22224v1",
    "published": "2025-05-28T10:55:16+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.22223v2",
    "title": "Bayesian Learning in Structural Dynamics: A Comprehensive Review and Emerging Trends",
    "authors": [
      "Wang-Ji Yan",
      "Lin-Feng Mei",
      "Yuan-Wei Yin",
      "Jiang Mo",
      "Costas Papadimitriou",
      "Ka-Veng Yuen",
      "Michael Beer"
    ],
    "abstract": "Bayesian learning has emerged as a compelling and vital research direction in\nthe field of structural dynamics, offering a probabilistic lens to understand\nand refine the analysis of complex dynamical systems. This review meticulously\ntraces the three-decade evolution of Bayesian learning in structural dynamics,\nilluminating core principles, groundbreaking methodologies, and diverse\napplications that have significantly influenced the field. The narrative\ncommences by delving into the basics of Bayesian theory, clarifying essential\nconcepts, and introducing primary methods for deriving posterior distributions,\nwith an in-depth exploration of three types: Laplace approximation, stochastic\nsampling, and variational inference. Subsequently, the text explores the\nimplementation of two types of Bayesian learning in structural dynamics:\nphysical model learning and data-centric statistical model learning. Physical\nmodel learning emphasizes inferring physical model parameters within a Bayesian\nframework for system identification and prediction, while statistical model\nlearning integrates Bayesian learning methodologies into data-centric\nstatistical modeling within probabilistic machine learning. Both types resonate\nacross various applications, such as modal analysis, model updating, damage\ndetection, and reliability updating, highlighting their pivotal role in\nenhancing comprehension of dynamical systems and decision-making. The paper\nalso navigates obstacles by proposing ways to enhance existing Bayesian\ninference strategies. Distinguished from previous research, this study offers a\nthorough examination of both traditional and cutting-edge Bayesian methods. It\nnot only underscores the transformative influence of Bayesian approaches but\nalso serves as a beacon, guiding researchers in the judicious selection and\nrefinement of suitable methods for various challenges in structural dynamics.",
    "pdf_url": "http://arxiv.org/pdf/2505.22223v2",
    "published": "2025-05-28T10:54:41+00:00",
    "categories": [
      "physics.data-an",
      "physics.comp-ph"
    ],
    "primary_category": "physics.data-an"
  },
  {
    "id": "http://arxiv.org/abs/2505.22222v1",
    "title": "Look & Mark: Leveraging Radiologist Eye Fixations and Bounding boxes in Multimodal Large Language Models for Chest X-ray Report Generation",
    "authors": [
      "Yunsoo Kim",
      "Jinge Wu",
      "Su-Hwan Kim",
      "Pardeep Vasudev",
      "Jiashu Shen",
      "Honghan Wu"
    ],
    "abstract": "Recent advancements in multimodal Large Language Models (LLMs) have\nsignificantly enhanced the automation of medical image analysis, particularly\nin generating radiology reports from chest X-rays (CXR). However, these models\nstill suffer from hallucinations and clinically significant errors, limiting\ntheir reliability in real-world applications. In this study, we propose Look &\nMark (L&M), a novel grounding fixation strategy that integrates radiologist eye\nfixations (Look) and bounding box annotations (Mark) into the LLM prompting\nframework. Unlike conventional fine-tuning, L&M leverages in-context learning\nto achieve substantial performance gains without retraining. When evaluated\nacross multiple domain-specific and general-purpose models, L&M demonstrates\nsignificant gains, including a 1.2% improvement in overall metrics (A.AVG) for\nCXR-LLaVA compared to baseline prompting and a remarkable 9.2% boost for\nLLaVA-Med. General-purpose models also benefit from L&M combined with\nin-context learning, with LLaVA-OV achieving an 87.3% clinical average\nperformance (C.AVG)-the highest among all models, even surpassing those\nexplicitly trained for CXR report generation. Expert evaluations further\nconfirm that L&M reduces clinically significant errors (by 0.43 average errors\nper report), such as false predictions and omissions, enhancing both accuracy\nand reliability. These findings highlight L&M's potential as a scalable and\nefficient solution for AI-assisted radiology, paving the way for improved\ndiagnostic workflows in low-resource clinical settings.",
    "pdf_url": "http://arxiv.org/pdf/2505.22222v1",
    "published": "2025-05-28T10:54:40+00:00",
    "categories": [
      "cs.CV",
      "cs.CL"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.22221v2",
    "title": "Tight qubit uncertainty relations studied through weak values in neutron interferometry",
    "authors": [
      "Andreas Dvorak",
      "Ismaele V. Masiello",
      "Yuji Hasegawa",
      "Hartmut Lemmel",
      "Holger F. Hofmann",
      "Stephan Sponar"
    ],
    "abstract": "In its original formulation, Heisenberg's uncertainty principle describes a\ntrade-off relation between the error of a quantum measurement and the thereby\ninduced disturbance on the measured object. However, this relation is not valid\nin general. An alternative universally valid relation was derived by Ozawa in\n2003, defining error and disturbance in a general concept, experimentally\naccessible via a tomographic method. Later, it was shown by Hall that these\nerrors correspond to the statistical deviation between a physical property and\nits estimate. Recently, it was discovered that these errors can be observed\nexperimentally when weak values are determined through a procedure named\n\"feedback compensation\". Here, we apply this procedure for the complete\nexperimental characterization of the error-disturbance relation between a\nwhich-way observable in an interferometer and another observable associated\nwith the output of the interferometer, confirming the theoretically predicted\nrelation. As expected for pure states, the uncertainty is tightly fulfilled.",
    "pdf_url": "http://arxiv.org/pdf/2505.22221v2",
    "published": "2025-05-28T10:54:31+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.22220v1",
    "title": "Domainator: Detecting and Identifying DNS-Tunneling Malware Using Metadata Sequences",
    "authors": [
      "Denis Petrov",
      "Pascal Ruffing",
      "Sebastian Zillien",
      "Steffen Wendzel"
    ],
    "abstract": "In recent years, malware with tunneling (or: covert channel) capabilities is\non the rise. While malware research led to several methods and innovations, the\ndetection and differentiation of malware solely based on its DNS tunneling\nfeatures is still in its infancy. Moreover, no work so far has used the DNS\ntunneling traffic to gain knowledge over the current actions taken by the\nmalware. In this paper, we present Domainator, an approach to detect and\ndifferentiate state-of-the-art malware and DNS tunneling tools without relying\non trivial (but quickly altered) features such as \"magic bytes\" that are\nembedded into subdomains. Instead, we apply an analysis of sequential patterns\nto identify specific types of malware. We evaluate our approach with 7\ndifferent malware samples and tunneling tools and can identify the particular\nmalware based on its DNS traffic. We further infer the rough behavior of the\nparticular malware through its DNS tunneling artifacts. Finally, we compare our\nDomainator with related methods.",
    "pdf_url": "http://arxiv.org/pdf/2505.22220v1",
    "published": "2025-05-28T10:52:19+00:00",
    "categories": [
      "cs.CR",
      "cs.NI"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.22219v2",
    "title": "Constraining the Hubble parameter with the 21 cm brightness temperature signal in a universe with inhomogeneities",
    "authors": [
      "Subhadeep Mukherjee",
      "Shashank Shekhar Pandey",
      "A. S. Majumdar"
    ],
    "abstract": "We consider the 21\\,cm brightness temperature as a probe of the Hubble\ntension in the framework of an inhomogeneous cosmological model. Employing\nBuchert's averaging formalism to study the effect of inhomogeneities on the\nbackground evolution, we consider scaling laws for the backreaction and\ncurvature consistent with structure formation simulations. We calibrate the\neffective matter density using MCMC analysis using Union 2.1 Supernova Ia data.\nOur results show that a higher Hubble constant ($\\sim73$\\,km/s/Mpc) leads to a\nshallower absorption feature in the brightness temperature versus redshift\ncurve. On the other hand, a lower value ($\\sim67$\\,km/s/Mpc) produces a\nremarkable dip in the brightness temperature $T_{21}$. Such a substantial\ndifference is absent in the standard $\\Lambda$CDM model. Our findings indicate\nthat inhomogeneities could significantly affect the 21\\,cm signal, and may shed\nfurther light on the different measurements of the Hubble constant.",
    "pdf_url": "http://arxiv.org/pdf/2505.22219v2",
    "published": "2025-05-28T10:50:55+00:00",
    "categories": [
      "astro-ph.CO",
      "gr-qc"
    ],
    "primary_category": "astro-ph.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.22218v2",
    "title": "Aspects of density approximation by tensor trains",
    "authors": [
      "Ji≈ô√≠ Ajgl",
      "Ond≈ôej Straka"
    ],
    "abstract": "Point-mass filters solve Bayesian recursive relations by approximating\nprobability density functions of a system state over grids of discrete points.\nThe approach suffers from the curse of dimensionality. The exponential increase\nof the number of the grid points can be mitigated by application of low-rank\napproximations of multidimensional arrays. Tensor train decompositions\nrepresent individual values by the product of matrices. This paper focuses on\nselected issues that are substantial in state estimation. Namely, the\ncontamination of the density approximations by negative values is discussed\nfirst. Functional decompositions of quadratic functions are compared with\ndecompositions of discretised Gaussian densities next. In particular, the\nconnection of correlation with tensor train ranks is explored. Last, the\nconsequences of interpolating the density values from one grid to a new grid\nare analysed.",
    "pdf_url": "http://arxiv.org/pdf/2505.22218v2",
    "published": "2025-05-28T10:50:50+00:00",
    "categories": [
      "eess.SP"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2505.22217v1",
    "title": "Benincasa-Dowker causal set actions by quantum counting",
    "authors": [
      "Sean A. Adamson",
      "Petros Wallden"
    ],
    "abstract": "Causal set theory is an approach to quantum gravity in which spacetime is\nfundamentally discrete while retaining local Lorentz invariance. The\nBenincasa--Dowker action is the causal set equivalent to the Einstein--Hilbert\naction underpinning Einstein's general theory of relativity. We present a\n$\\tilde{O}(n^{2})$ running-time quantum algorithm to compute the\nBenincasa--Dowker action in arbitrary spacetime dimensions for causal sets with\n$n$ elements which is asymptotically optimal and offers a polynomial speed up\ncompared to all known classical or quantum algorithms. To do this, we prepare a\nuniform superposition over an $O(n^{2})$-size arbitrary subset of computational\nbasis states encoding the classical description of a causal set of interest. We\nthen construct $\\tilde{O}(n)$-depth oracle circuits testing for different\ndiscrete volumes between pairs of causal set elements. Repeatedly performing a\ntwo-stage variant of quantum counting using these oracles yields the desired\nalgorithm.",
    "pdf_url": "http://arxiv.org/pdf/2505.22217v1",
    "published": "2025-05-28T10:50:06+00:00",
    "categories": [
      "quant-ph",
      "gr-qc"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.22216v2",
    "title": "Diverse reddening distributions in sight lines to type Ia supernovae",
    "authors": [
      "Lucas Hallgren",
      "Radoslaw Wojtak",
      "Jens Hjorth",
      "Charles L. Steinhardt"
    ],
    "abstract": "Precise cosmological constraints from type Ia supernovae require adequately\naccurate corrections for host-galaxy extinction. Modelling these corrections is\nchallenged by the problem of disentangling supernova intrinsic colours from\nhost-galaxy interstellar reddening. The latter is commonly modelled in a\nprobabilistic way assuming an exponential distribution exp(-E(B-V)/\\tau) as a\nuniversal prior which is applied across all types of supernova host galaxies.\nWe test the robustness of the exponential model and its universality against\npredictions based on simulating dust and type Ia supernova distributions in\nhost galaxies of different morphological types. We find substantial differences\nbetween predicted interstellar reddening in late- and early-type host galaxies,\nprimarily driven by the stellar-to-dust mass ratios. The mean simulated\nreddening in late-type galaxies matches well those derived from type Ia\nsupernova observations, but it is significantly lower for early-type host\ngalaxies. The reddening distributions exhibit an excess of sight lines with\nvanishing reddening with respect to the exponential model, although the\ndifference is quite mild for late-type galaxies. On the other hand, the\ndistribution may peak at E(B-V)>0 when considering a population of young type\nIa supernovae originating from lower heights within the dust disc. We\ndemonstrate that assuming a universal reddening prior distribution for modeling\npeak magnitude-colour relation, which is currently a common practice, gives\nrise to a spurious scatter in the derived extinction properties. It may also\nbias relative distances between supernovae originating from different\nhost-galaxy populations. The discrepancy between the simulated reddening in\naverage early-type host galaxies and the observed occurrence of reddened\nsupernovae suggests that reddening does not originate from interstellar dust\nexpected in these galaxies.",
    "pdf_url": "http://arxiv.org/pdf/2505.22216v2",
    "published": "2025-05-28T10:49:36+00:00",
    "categories": [
      "astro-ph.GA",
      "astro-ph.CO"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2505.22215v1",
    "title": "Solving Boolean Satisfiability Problems Using A Hypergraph-based Probabilistic Computer",
    "authors": [
      "Yihan He",
      "Ming-Chun Hong",
      "Wanli Zheng",
      "Ching Shih",
      "Hsin-Han Lee",
      "Yu-Chen Hsin",
      "Jeng-Hua Wei",
      "Xiao Gong",
      "Tuo-Hung Hou",
      "Gengchiau Liang"
    ],
    "abstract": "Boolean Satisfiability (SAT) problems are critical in fields such as\nartificial intelligence and cryptography, where efficient solutions are\nessential. Conventional probabilistic solvers often encounter scalability\nissues due to complex logic synthesis steps. In this work, we present a novel\napproach for solving the 3-SAT Boolean satisfiability problem using\nhypergraph-based probabilistic computers obtained through direct mapping. This\nmethod directly translates 3-SAT logical expressions into hypergraph\nstructures, thereby circumventing conventional logic decomposition and\nsynthesis procedures, and offering a more streamlined solver architecture. For\na uf20-01 instance, our approach significantly reduces the vertex number from\n112 to 20 with a reduced solution space from 2112 to 220. Numerical simulations\ndemonstrate that the proposed hypergraph-based solver achieves a significantly\nhigher success rate of up to 99%, compared to merely 1% for conventional\nsolvers. Furthermore, the proposed direct mapping method can be extended to\nsolve k-SAT problems, which provides a scalable framework for tackling more\ncomplex satisfiability problems using probabilistic computing in the future.",
    "pdf_url": "http://arxiv.org/pdf/2505.22215v1",
    "published": "2025-05-28T10:48:19+00:00",
    "categories": [
      "physics.comp-ph"
    ],
    "primary_category": "physics.comp-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.22214v2",
    "title": "Thermal Modeling and Optimal Allocation of Avionics Safety-critical Tasks on Heterogeneous MPSoCs",
    "authors": [
      "Ond≈ôej Benedikt",
      "Michal Sojka",
      "P≈ôemysl ≈†≈Øcha",
      "Pavel Zaykov",
      "Zdenƒõk Hanz√°lek"
    ],
    "abstract": "Multi-Processor Systems-on-Chip (MPSoC) can deliver high performance needed\nin many industrial domains, including aerospace. However, their high power\nconsumption, combined with avionics safety standards, brings new thermal\nmanagement challenges. This paper investigates techniques for offline\nthermal-aware allocation of periodic tasks on heterogeneous MPSoCs running at a\nfixed clock frequency, as required in avionics. The goal is to find the\nassignment of tasks to (i) cores and (ii) temporal isolation windows while\nminimizing the MPSoC temperature. To achieve that, we propose and analyze three\npower models, and integrate them within several novel optimization approaches\nbased on heuristics, a black-box optimizer, and Integer Linear Programming\n(ILP). We perform the experimental evaluation on three popular MPSoC platforms\n(NXP i.MX8QM MEK, NXP i.MX8QM Ixora, NVIDIA TX2) and observe a difference of up\nto 5.5{\\deg}C among the tested methods (corresponding to a 22% reduction w.r.t.\nthe ambient temperature). We also show that our method, integrating the\nempirical power model with the ILP, outperforms the other methods on all tested\nplatforms.",
    "pdf_url": "http://arxiv.org/pdf/2505.22214v2",
    "published": "2025-05-28T10:40:47+00:00",
    "categories": [
      "cs.SE"
    ],
    "primary_category": "cs.SE"
  },
  {
    "id": "http://arxiv.org/abs/2505.22213v1",
    "title": "Partial Redundancy in Saturation",
    "authors": [
      "M√°rton Hajdu",
      "Laura Kov√°cs",
      "Andrei Voronkov"
    ],
    "abstract": "Redundancy elimination is one of the crucial ingredients of efficient\nsaturation-based proof search. We improve redundancy elimination by introducing\na new notion of redundancy, based on partial clauses and redundancy formulas,\nwhich is more powerful than the standard notion: there are both clauses and\ninferences that are redundant when we use our notions and not redundant when we\nuse standard notions. In a way, our notion blurs the distinction between\nredundancy at the level of inferences and redundancy at the level of clauses.\nWe present a superposition calculus PaRC on partial clauses. Our calculus is\nrefutationally complete and is strong enough to capture some standard\nrestrictions of the superposition calculus. We discuss the implementation of\nthe calculus in the theorem prover Vampire. Our experiments show the power of\nthe new approach: we were able to solve 24 TPTP problems not previously solved\nby any prover, including previous versions of Vampire.",
    "pdf_url": "http://arxiv.org/pdf/2505.22213v1",
    "published": "2025-05-28T10:40:02+00:00",
    "categories": [
      "cs.LO"
    ],
    "primary_category": "cs.LO"
  },
  {
    "id": "http://arxiv.org/abs/2505.22212v1",
    "title": "(Near)-Optimal Algorithms for Sparse Separable Convex Integer Programs",
    "authors": [
      "Christoph Hunkenschr√∂der",
      "Martin Kouteck√Ω",
      "Asaf Levin",
      "Tung Anh Vu"
    ],
    "abstract": "We study the general integer programming (IP) problem of optimizing a\nseparable convex function over the integer points of a polytope: $\\min\n\\{f(\\mathbf{x}) \\mid A\\mathbf{x} = \\mathbf{b}, \\, \\mathbf{l} \\leq \\mathbf{x}\n\\leq \\mathbf{u}, \\, \\mathbf{x} \\in \\mathbb{Z}^n\\}$. The number of variables $n$\nis a variable part of the input, and we consider the regime where the\nconstraint matrix $A$ has small coefficients $\\|A\\|_\\infty$ and small primal or\ndual treedepth $\\mathrm{td}_P(A)$ or $\\mathrm{td}_D(A)$, respectively.\nEquivalently, we consider block-structured matrices, in particular $n$-fold,\ntree-fold, $2$-stage and multi-stage matrices.\n  We ask about the possibility of near-linear time algorithms in the general\ncase of (non-linear) separable convex functions. The techniques of previous\nworks for the linear case are inherently limited to it; in fact, no\nstrongly-polynomial algorithm may exist due to a simple unconditional\ninformation-theoretic lower bound of $n \\log \\|\\mathbf{u}-\\mathbf{l}\\|_\\infty$,\nwhere $\\mathbf{l}, \\mathbf{u}$ are the vectors of lower and upper bounds. Our\nfirst result is that with parameters $\\mathrm{td}_P(A)$ and $\\|A\\|_\\infty$,\nthis lower bound can be matched (up to dependency on the parameters). Second,\nwith parameters $\\mathrm{td}_D(A)$ and $\\|A\\|_\\infty$, the situation is more\ninvolved, and we design an algorithm with time complexity $g(\\mathrm{td}_D(A),\n\\|A\\|_\\infty) n \\log n \\log \\|\\mathbf{u}-\\mathbf{l}\\|_\\infty$ where $g$ is some\ncomputable function. We conjecture that a stronger lower bound is possible in\nthis regime, and our algorithm is in fact optimal.\n  Our algorithms combine ideas from scaling, proximity, and sensitivity of\ninteger programs, together with a new dynamic data structure.",
    "pdf_url": "http://arxiv.org/pdf/2505.22212v1",
    "published": "2025-05-28T10:39:56+00:00",
    "categories": [
      "cs.DS",
      "math.OC"
    ],
    "primary_category": "cs.DS"
  },
  {
    "id": "http://arxiv.org/abs/2505.22211v1",
    "title": "Handling bounded response in high dimensions: a Horseshoe prior Bayesian Beta regression approach",
    "authors": [
      "The Tien Mai"
    ],
    "abstract": "Bounded continuous responses -- such as proportions -- arise frequently in\ndiverse scientific fields including climatology, biostatistics, and finance.\nBeta regression is a widely adopted framework for modeling such data, due to\nthe flexibility of the Beta distribution over the unit interval. While Bayesian\nextensions of Beta regression have shown promise, existing methods are limited\nto low-dimensional settings and lack theoretical guarantees. In this work, we\npropose a novel Bayesian approach for high-dimensional sparse Beta regression\nframework that employs a tempered posterior. Our method incorporates the\nHorseshoe prior for effective shrinkage and variable selection. Most notable,\nwe propose a novel Gibbs sampling algorithm using P\\'olya-Gamma augmentation\nfor efficient inference in Beta regression model. We also provide the first\ntheoretical results establishing posterior consistency and convergence rates\nfor Bayesian Beta regression. Through extensive simulation studies in both low-\nand high-dimensional scenarios, we demonstrate that our approach outperforms\nexisting alternatives, offering improved estimation accuracy and model\ninterpretability.\n  Our method is implemented in the R package ``betaregbayes\" available on\nGithub.",
    "pdf_url": "http://arxiv.org/pdf/2505.22211v1",
    "published": "2025-05-28T10:39:05+00:00",
    "categories": [
      "stat.ME",
      "math.ST",
      "stat.ML",
      "stat.TH"
    ],
    "primary_category": "stat.ME"
  },
  {
    "id": "http://arxiv.org/abs/2505.22210v1",
    "title": "Soliton resolution for the coupled complex short pulse equation",
    "authors": [
      "Nan Liu",
      "Ran Wang"
    ],
    "abstract": "We address the long-time asymptotics of the solution to the Cauchy problem of\nccSP (coupled complex short pulse) equation on the line for decaying initial\ndata that can support solitons. The ccSP system describes ultra-short pulse\npropagation in optical fibers, which is a completely integrable system and\nposses a $4\\times4$ matrix Wadati--Konno--Ichikawa type Lax pair. Based on the\n$\\bar{\\partial}$-generalization of the Deift--Zhou steepest descent method, we\nobtain the long-time asymptotic approximations of the solution in two kinds of\nspace-time regions under a new scale $(\\zeta,t)$. The solution of the ccSP\nequation decays as a speed of $O(t^{-1})$ in the region $\\zeta/t>\\varepsilon$\nwith any $\\varepsilon>0$; while in the region $\\zeta/t<-\\varepsilon$, the\nsolution is depicted by the form of a multi-self-symmetric soliton/composite\nbreather and $t^{-1/2}$ order term arises from self-symmetric soliton/composite\nbreather-radiation interactions as well as an residual error order $O(t^{-1}\\ln\nt)$.",
    "pdf_url": "http://arxiv.org/pdf/2505.22210v1",
    "published": "2025-05-28T10:38:15+00:00",
    "categories": [
      "nlin.SI",
      "math-ph",
      "math.AP",
      "math.MP"
    ],
    "primary_category": "nlin.SI"
  },
  {
    "id": "http://arxiv.org/abs/2505.22209v1",
    "title": "A Survey on Training-free Open-Vocabulary Semantic Segmentation",
    "authors": [
      "Naomi Kombol",
      "Ivan Martinoviƒá",
      "Sini≈°a ≈†egviƒá"
    ],
    "abstract": "Semantic segmentation is one of the most fundamental tasks in image\nunderstanding with a long history of research, and subsequently a myriad of\ndifferent approaches. Traditional methods strive to train models up from\nscratch, requiring vast amounts of computational resources and training data.\nIn the advent of moving to open-vocabulary semantic segmentation, which asks\nmodels to classify beyond learned categories, large quantities of finely\nannotated data would be prohibitively expensive. Researchers have instead\nturned to training-free methods where they leverage existing models made for\ntasks where data is more easily acquired. Specifically, this survey will cover\nthe history, nuance, idea development and the state-of-the-art in training-free\nopen-vocabulary semantic segmentation that leverages existing multi-modal\nclassification models. We will first give a preliminary on the task definition\nfollowed by an overview of popular model archetypes and then spotlight over 30\napproaches split into broader research branches: purely CLIP-based, those\nleveraging auxiliary visual foundation models and ones relying on generative\nmethods. Subsequently, we will discuss the limitations and potential problems\nof current research, as well as provide some underexplored ideas for future\nstudy. We believe this survey will serve as a good onboarding read to new\nresearchers and spark increased interest in the area.",
    "pdf_url": "http://arxiv.org/pdf/2505.22209v1",
    "published": "2025-05-28T10:37:52+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.22208v1",
    "title": "LaMM: Semi-Supervised Pre-Training of Large-Scale Materials Models",
    "authors": [
      "Yosuke Oyama",
      "Yusuke Majima",
      "Eiji Ohta",
      "Yasufumi Sakai"
    ],
    "abstract": "Neural network potentials (NNPs) are crucial for accelerating computational\nmaterials science by surrogating density functional theory (DFT) calculations.\nImproving their accuracy is possible through pre-training and fine-tuning,\nwhere an NNP model is first pre-trained on a large-scale dataset and then\nfine-tuned on a smaller target dataset. However, this approach is\ncomputationally expensive, mainly due to the cost of DFT-based dataset labeling\nand load imbalances during large-scale pre-training. To address this, we\npropose LaMM, a semi-supervised pre-training method incorporating improved\ndenoising self-supervised learning and a load-balancing algorithm for efficient\nmulti-node training. We demonstrate that our approach effectively leverages a\nlarge-scale dataset of $\\sim$300 million semi-labeled samples to train a single\nNNP model, resulting in improved fine-tuning performance in terms of both speed\nand accuracy.",
    "pdf_url": "http://arxiv.org/pdf/2505.22208v1",
    "published": "2025-05-28T10:36:49+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.22207v1",
    "title": "Modulation of Polarization and Metallicity in Janus Sliding Ferroelectrics",
    "authors": [
      "Akshay Mahajan",
      "Awadhesh Narayan"
    ],
    "abstract": "Sliding ferroelectricity is emerging as a distinct and promising mechanism\nfor realizing ferroelectricity in low-dimensional systems, offering new design\nprinciples beyond the conventional ferroelectric mechanism. Further, the\ncoexistence of the out-of-plane polarization with in-plane conductivity induced\nby electrostatic charge doping makes these systems strong candidates for\nrealizing ferroelectric metals. Using density functional theory calculations,\nwe analyze the transition metal dichalcogenides (TMDs) based Janus sliding\nferroelectric bilayers XMY (M = Mo, W; X, Y = S, Se, Te; X $\\neq$ Y). In\naddition to exhibiting switchable interlayer polarization, Janus sliding\nferroelectrics possess an intrinsic electric field within each monolayer,\narising from the electronegativity difference between the chalcogen atoms. We\ndiscover that the intrinsic electric field of the monolayers can be used to\nmodulate the interlayer ferroelectric polarization and the electronic band\nstructure. We identify the decrease in the interlayer distance due to a\nparticular stacking of the Janus bilayers as a major contributor to increasing\npolarization and reducing the bandgap. The direction of the intrinsic electric\nfield within the Janus monolayers plays a significant role in the modulation of\nlayer-wise contribution in the valence and conduction bands, which influences\nthe polarization reduction due to extrinsic charge dopants. Extending this\nconcept to Janus trilayers, we observe further enhancement in polarization and\nadditional bandgap reduction compared to their bilayer counterparts. These\nresults highlight the tunability of TMD-based Janus sliding ferroelectrics and\nsuggest a pathway for designing low bandgap ferroelectrics and potential\nferroelectric metals.",
    "pdf_url": "http://arxiv.org/pdf/2505.22207v1",
    "published": "2025-05-28T10:34:16+00:00",
    "categories": [
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2505.22206v1",
    "title": "Directional $œÅ$-coefficients",
    "authors": [
      "Enrique de Amo",
      "David Garc√≠a-Fern√°ndez",
      "Manuel √öbeda-Flores"
    ],
    "abstract": "In this paper we obtain advances for the concept of directional\n$\\rho$-coefficients, originally defined for the trivariate case in [Nelsen,\nR.B., \\'Ubeda-Flores, M. (2011). Directional dependence in multivariate\ndistributions. Ann. Inst. Stat. Math 64, 677-685] by extending it to encompass\narbitrary dimensions and directions in multivariate space. We provide a\ngeneralized definition and establish its fundamental properties. Moreover, we\nresolve a conjecture from the aforementioned work by proving a more general\nresult applicable to any dimension, correcting a result in [Garc\\'ia, J.E.,\nGonz\\'alez-L\\'opez, V.A., Nelsen, R.B. (2013). A new index to measure positive\ndependence in trivariate distributions. J. Multivariate Anal. 115, 481-495] an\nerratum in the current literature. Our findings contribute to a deeper\nunderstanding of multivariate dependence and association, offering novel tools\nfor detecting directional dependencies in high-dimensional settings. Finally,\nwe introduce nonparametric estimators, based on ranks, for estimating\ndirectional $\\rho$-coefficients from a sample.",
    "pdf_url": "http://arxiv.org/pdf/2505.22206v1",
    "published": "2025-05-28T10:33:22+00:00",
    "categories": [
      "math.ST",
      "stat.TH",
      "62H05, 62H12"
    ],
    "primary_category": "math.ST"
  },
  {
    "id": "http://arxiv.org/abs/2505.22205v2",
    "title": "The Gaia spectroscopic catalogue of exoplanets and host stars",
    "authors": [
      "Patrick de Laverny",
      "Roxanne Ligi",
      "Aur√©lien Crida",
      "Alejandra Recio-Blanco",
      "Pedro A. Palicio"
    ],
    "abstract": "Complete, accurate, and precise catalogues of exoplanet host star (EHS)\nproperties are essential to deriving high-quality exoplanet parameters. This\npaper aims at homogeneously parameterising EHS and their exoplanets, using Gaia\nand GSP-spec data. For 2573 EHS, we computed their L*, R*, and M*, with no\nprior assumption from stellar evolution models. Their Galactic positions,\nkinematic and orbital properties were derived. We re-scaled Mp and Rp of 3556\nexoplanets, fully consistently with the stellar data. These new stellar Teff,\nL*, and R* are in rather good agreement with literature values but are more\nprecise. In particular, R* are derived with typically less than 3% uncertainty;\nthis reduces the uncertainty on Rp significantly and allows for a finer\nanalysis of the decrease in the number of planets around the evaporation\nvalley. Larger differences, however, were found for M*. We note that the EHS\npopulation is rather diverse in terms of the chemical and Galactic properties,\nalthough they are all found in the Solar vicinity, close to the Local spiral\narm. Most EHS belong to the thin disc, but some older thick disc and halo\nmembers have also been identified. For the less massive planets, the average Rp\nincreases with the metallicity of the host star. For giant planets, a dichotomy\nbetween dense and inflated planets is found. Denser planets tend to be more\nmassive as the metallicity of the host star increases, while inflated planets\nare more massive for less metallic hosts. If confirmed, this bimodality implies\nthat the diversity of giant exoplanets depends on their Galactic birth locus,\nwith dense giant planets being more numerous than inflated ones when [M/H]>~1.5\ntimes Solar, as in the central Milky Way regions. The Gaia spectroscopic\ncatalogue of exoplanets and their host stars is large, homogeneous, and\nprecise. It would be a useful added-value for planetary studies.",
    "pdf_url": "http://arxiv.org/pdf/2505.22205v2",
    "published": "2025-05-28T10:33:09+00:00",
    "categories": [
      "astro-ph.EP",
      "astro-ph.IM",
      "astro-ph.SR"
    ],
    "primary_category": "astro-ph.EP"
  },
  {
    "id": "http://arxiv.org/abs/2505.22204v1",
    "title": "IceCube PeV neutrinos from heavy dark matter decay with 12 years HESE data",
    "authors": [
      "Diptarko Mukherjee",
      "Ashadul Halder",
      "Debasish Majumdar",
      "Abhijit Bandyopadhyay"
    ],
    "abstract": "The decay of superheavy dark matter from the early universe may undergo decay\nvia QCD cascades and electroweak cascade to produce neutrinos as one of the\ndecay products. We consider the neutrino events in and around PeV region\nreported by IceCube collaboration are due to the decay of such heavy dark\nmatter. The neutrino spectrum could be from the decay processes via hadronic\ndecay modes and/or leptonic decay modes. Using the numerical evolution of QCD\ncascades as well as electroweak corrections where use has been made of DGLAP\nequations, the neutrino fluxes from the heavy dark matter decay have been\ncomputed. The mass of the decaying superheavy dark matter and its decay\nlifetime have then been estimated from a $\\chi^2$ analysis of the IceCube\n12-year data. The fractional contribution ($f_{\\rm lep}$) of the leptonic decay\nchannel in such a decay process is also estimated from the same $\\chi^2$\nanalyses. It is seen that to explain the IceCube 12-year ultrahigh energy (UHE)\nevents the mass of a decaying superheavy dark matter would be $\\sim9.4\\times\n10^6$ GeV and decay time $\\tau \\simeq 4.2 \\times 10^{28}$ second. It is also\nfound that the lepton channel contribution is very small, $f_{\\rm lep} \\sim\n0.001$.",
    "pdf_url": "http://arxiv.org/pdf/2505.22204v1",
    "published": "2025-05-28T10:30:48+00:00",
    "categories": [
      "hep-ph",
      "astro-ph.HE"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.22203v1",
    "title": "Pitfalls of Rule- and Model-based Verifiers -- A Case Study on Mathematical Reasoning",
    "authors": [
      "Yuzhen Huang",
      "Weihao Zeng",
      "Xingshan Zeng",
      "Qi Zhu",
      "Junxian He"
    ],
    "abstract": "Trustworthy verifiers are essential for the success of reinforcement learning\nwith verifiable reward (RLVR), which is the core methodology behind various\nlarge reasoning models such as DeepSeek-R1. In complex domains like\nmathematical reasoning, rule-based verifiers have been widely adopted in\nprevious works to train strong reasoning models. However, the reliability of\nthese verifiers and their impact on the RL training process remain poorly\nunderstood. In this work, we take mathematical reasoning as a case study and\nconduct a comprehensive analysis of various verifiers in both static evaluation\nand RL training scenarios. First, we find that current open-source rule-based\nverifiers often fail to recognize equivalent answers presented in different\nformats across multiple commonly used mathematical datasets, resulting in\nnon-negligible false negative rates. This limitation adversely affects RL\ntraining performance and becomes more pronounced as the policy model gets\nstronger. Subsequently, we investigate model-based verifiers as a potential\nsolution to address these limitations. While the static evaluation shows that\nmodel-based verifiers achieve significantly higher verification accuracy,\nfurther analysis and RL training results imply that they are highly susceptible\nto hacking, where they misclassify certain patterns in responses as correct\n(i.e., false positives). This vulnerability is exploited during policy model\noptimization, leading to artificially inflated rewards. Our findings underscore\nthe unique risks inherent to both rule-based and model-based verifiers, aiming\nto offer valuable insights to develop more robust reward systems in\nreinforcement learning.",
    "pdf_url": "http://arxiv.org/pdf/2505.22203v1",
    "published": "2025-05-28T10:28:41+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.22202v1",
    "title": "Let's Predict Sentence by Sentence",
    "authors": [
      "Hyeonbin Hwang",
      "Byeongguk Jeon",
      "Seungone Kim",
      "Jiyeon Kim",
      "Hoyeon Chang",
      "Sohee Yang",
      "Seungpil Won",
      "Dohaeng Lee",
      "Youbin Ahn",
      "Minjoon Seo"
    ],
    "abstract": "Autoregressive language models (LMs) generate one token at a time, yet human\nreasoning operates over higher-level abstractions - sentences, propositions,\nand concepts. This contrast raises a central question- Can LMs likewise learn\nto reason over structured semantic units rather than raw token sequences? In\nthis work, we investigate whether pretrained LMs can be lifted into such\nabstract reasoning spaces by building on their learned representations. We\npresent a framework that adapts a pretrained token-level LM to operate in\nsentence space by autoregressively predicting continuous embeddings of next\nsentences. We explore two embedding paradigms inspired by classical\nrepresentation learning: 1) semantic embeddings, learned via autoencoding to\npreserve surface meaning; and 2) contextual embeddings, trained via\nnext-sentence prediction to encode anticipatory structure. We evaluate both\nunder two inference regimes: Discretized, which decodes each predicted\nembedding into text before re-encoding; and Continuous, which reasons entirely\nin embedding space for improved efficiency. Across four domains - mathematics,\nlogic, commonsense, and planning - contextual embeddings under continuous\ninference show competitive performance with Chain-of-Thought (CoT) while\nreducing inference-time FLOPs on average by half. We also present early signs\nof scalability and modular adaptation. Finally, to visualize latent\ntrajectories, we introduce SentenceLens, a diagnostic tool that decodes\nintermediate model states into interpretable sentences. Together, our results\nindicate that pretrained LMs can effectively transition to abstract, structured\nreasoning within latent embedding spaces.",
    "pdf_url": "http://arxiv.org/pdf/2505.22202v1",
    "published": "2025-05-28T10:28:35+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.22201v1",
    "title": "Modeling the progenitors of low-mass post-accretion binaries",
    "authors": [
      "A. J. Dimoff",
      "R. J. Stancliffe",
      "C. J. Hansen",
      "R. M. Seeburger",
      "H. Taylor"
    ],
    "abstract": "About half of the mass of all heavy elements with mass number A > 90 is\nformed through the slow neutron capture process (s-process), occurring in\nevolved asymptotic giant branch (AGB) stars with masses ~1-6 $\\rm{M_{\\odot}}$.\nThe s-process can be studied by modeling the accretion of material from AGB\nstars onto binary barium (Ba), CH, and carbon-enhanced metal-poor (CEMP)-s\nstars. Comparing observationally derived surface parameters and 1D-LTE\nabundance patterns of s-process elements to theoretical binary accretion\nmodels, we aim to understand the formation of post-accretion systems. We\nexplore the extent of dilution of the accreted material and describe the impact\nof convective mixing on the observed surface abundances. We compute a new grid\nof 2700 accretion models for low-mass post-accretion systems. A\nmaximum-likelihood comparison determines the best fit models for observational\nsamples of Ba, CH, and CEMP-s stars. We find consistent AGB donor masses in the\nmass range of 2-3 $\\rm{M_{\\odot}}$ across our sample of post-accretion\nbinaries. We find the formation scenario for weak Ba stars is an AGB star\ntransferring a moderate amount of mass ($\\leq$0.5 $\\rm{M_{\\odot}}$) resulting\nin a ~2.0-2.5 $\\rm{M_{\\odot}}$ star. The strong Ba stars are best fit with\nlower final masses ~1.0-2.0 $\\rm{M_{\\odot}}$, and significant accreted mass\n($\\geq$0.5 $\\rm{M_{\\odot}}$). The CH and CEMP-s stars display lower final\nmasses (~1.0 $\\rm{M_{\\odot}}$) and small amounts of transferred material (~0.1\n$\\rm{M_{\\odot}}$). We find that Ba stars generally accrete more material than\nCEMP-s and CH stars. We also find that strong Ba stars must accrete more than\n0.50 $\\rm{M_{\\odot}}$ to explain their abundance patterns, and in this limit we\nare unable to reproduce the observed mass distribution of strong Ba stars. The\nmass distributions of the weak Ba stars, CEMP-s, and CH stars are well\nreproduced in our modeling.",
    "pdf_url": "http://arxiv.org/pdf/2505.22201v1",
    "published": "2025-05-28T10:27:54+00:00",
    "categories": [
      "astro-ph.SR"
    ],
    "primary_category": "astro-ph.SR"
  },
  {
    "id": "http://arxiv.org/abs/2505.22200v1",
    "title": "Investigating Mechanisms for In-Context Vision Language Binding",
    "authors": [
      "Darshana Saravanan",
      "Makarand Tapaswi",
      "Vineet Gandhi"
    ],
    "abstract": "To understand a prompt, Vision-Language models (VLMs) must perceive the\nimage, comprehend the text, and build associations within and across both\nmodalities. For instance, given an 'image of a red toy car', the model should\nassociate this image to phrases like 'car', 'red toy', 'red object', etc. Feng\nand Steinhardt propose the Binding ID mechanism in LLMs, suggesting that the\nentity and its corresponding attribute tokens share a Binding ID in the model\nactivations. We investigate this for image-text binding in VLMs using a\nsynthetic dataset and task that requires models to associate 3D objects in an\nimage with their descriptions in the text. Our experiments demonstrate that\nVLMs assign a distinct Binding ID to an object's image tokens and its textual\nreferences, enabling in-context association.",
    "pdf_url": "http://arxiv.org/pdf/2505.22200v1",
    "published": "2025-05-28T10:25:43+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.22199v1",
    "title": "Enhancing Uncertainty Estimation and Interpretability via Bayesian Non-negative Decision Layer",
    "authors": [
      "Xinyue Hu",
      "Zhibin Duan",
      "Bo Chen",
      "Mingyuan Zhou"
    ],
    "abstract": "Although deep neural networks have demonstrated significant success due to\ntheir powerful expressiveness, most models struggle to meet practical\nrequirements for uncertainty estimation. Concurrently, the entangled nature of\ndeep neural networks leads to a multifaceted problem, where various localized\nexplanation techniques reveal that multiple unrelated features influence the\ndecisions, thereby undermining interpretability. To address these challenges,\nwe develop a Bayesian Non-negative Decision Layer (BNDL), which reformulates\ndeep neural networks as a conditional Bayesian non-negative factor analysis. By\nleveraging stochastic latent variables, the BNDL can model complex dependencies\nand provide robust uncertainty estimation. Moreover, the sparsity and\nnon-negativity of the latent variables encourage the model to learn\ndisentangled representations and decision layers, thereby improving\ninterpretability. We also offer theoretical guarantees that BNDL can achieve\neffective disentangled learning. In addition, we developed a corresponding\nvariational inference method utilizing a Weibull variational inference network\nto approximate the posterior distribution of the latent variables. Our\nexperimental results demonstrate that with enhanced disentanglement\ncapabilities, BNDL not only improves the model's accuracy but also provides\nreliable uncertainty estimation and improved interpretability.",
    "pdf_url": "http://arxiv.org/pdf/2505.22199v1",
    "published": "2025-05-28T10:23:34+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.22198v1",
    "title": "Solvated electrons in polar liquids as epsilon-near-zero materials tunable in the terahertz frequency range",
    "authors": [
      "Matthias Runge",
      "Michael Woerner",
      "Denys I. Bondar",
      "Thomas Elsaesser"
    ],
    "abstract": "Electrons in polar liquids give rise to a polaron resonance at a terahertz\n(THz) frequency \\nu_0 depending on electron concentration. The impact of this\nresonance on light propagation is studied in experiments, where a femtosecond\npump pulse generates electrons via multiphoton ionization and a THz probe pulse\npropagated through the excited sample is detected in a phase-resolved way. We\nobserve a behavior characteristic for epsilon-near-zero (ENZ) materials with\nstrongly modified phase and group velocities around \\nu_0, and a broadening of\nthe THz pulse envelope below \\nu_0. Calculations based on a local-field\napproach reproduce the ENZ behavior.",
    "pdf_url": "http://arxiv.org/pdf/2505.22198v1",
    "published": "2025-05-28T10:22:06+00:00",
    "categories": [
      "physics.chem-ph",
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "physics.chem-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.22197v1",
    "title": "Effective flows across diffusio-phoretic membranes",
    "authors": [
      "Kevin Wittkowski",
      "Pier Giuseppe Ledda",
      "Edoardo Carlo Giordano",
      "Fran√ßois Gallaire",
      "Giuseppe Antonio Zampogna"
    ],
    "abstract": "Flows enabled by phoretic mechanisms are of significant interest in several\nbiological and biomedical processes, such as bacterial motion and targeted drug\ndelivery. Here, we develop a homogenization-based macroscopic boundary\ncondition which describes the effective flow across a diffusiophoretic\nmicrostructured membrane, where the interaction between the membrane walls and\nthe solute particles is modeled via a potential-approach. We consider two cases\nwhere potential variations occur (i) at the pore scale and (ii) only in the\nclose vicinity of the boundary, enabling a simplified version of the\nmacroscopic flow description, in the latter case. Chemical interactions at the\nmicroscale are rigorously upscaled to macroscopic phoretic solvent velocity and\nsolute flux contributions, and added to the classical permeability and\ndiffusivity properties of the membrane. These properties stem from the solution\nof Stokes-advection-diffusion problems at the microscale, some of them forced\nby an interaction potential term. Eventually, we show an application of the\nmacroscopic model to develop minimal phoretic pumps, showcasing its suitability\nfor efficient design and optimization procedures.",
    "pdf_url": "http://arxiv.org/pdf/2505.22197v1",
    "published": "2025-05-28T10:18:46+00:00",
    "categories": [
      "physics.flu-dyn"
    ],
    "primary_category": "physics.flu-dyn"
  },
  {
    "id": "http://arxiv.org/abs/2505.22196v1",
    "title": "An Augmentation-Aware Theory for Self-Supervised Contrastive Learning",
    "authors": [
      "Jingyi Cui",
      "Hongwei Wen",
      "Yisen Wang"
    ],
    "abstract": "Self-supervised contrastive learning has emerged as a powerful tool in\nmachine learning and computer vision to learn meaningful representations from\nunlabeled data. Meanwhile, its empirical success has encouraged many\ntheoretical studies to reveal the learning mechanisms. However, in the existing\ntheoretical research, the role of data augmentation is still under-exploited,\nespecially the effects of specific augmentation types. To fill in the blank, we\nfor the first time propose an augmentation-aware error bound for\nself-supervised contrastive learning, showing that the supervised risk is\nbounded not only by the unsupervised risk, but also explicitly by a trade-off\ninduced by data augmentation. Then, under a novel semantic label assumption, we\ndiscuss how certain augmentation methods affect the error bound. Lastly, we\nconduct both pixel- and representation-level experiments to verify our proposed\ntheoretical results.",
    "pdf_url": "http://arxiv.org/pdf/2505.22196v1",
    "published": "2025-05-28T10:18:20+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.22195v1",
    "title": "S2AFormer: Strip Self-Attention for Efficient Vision Transformer",
    "authors": [
      "Guoan Xu",
      "Wenfeng Huang",
      "Wenjing Jia",
      "Jiamao Li",
      "Guangwei Gao",
      "Guo-Jun Qi"
    ],
    "abstract": "Vision Transformer (ViT) has made significant advancements in computer\nvision, thanks to its token mixer's sophisticated ability to capture global\ndependencies between all tokens. However, the quadratic growth in computational\ndemands as the number of tokens increases limits its practical efficiency.\nAlthough recent methods have combined the strengths of convolutions and\nself-attention to achieve better trade-offs, the expensive pairwise token\naffinity and complex matrix operations inherent in self-attention remain a\nbottleneck. To address this challenge, we propose S2AFormer, an efficient\nVision Transformer architecture featuring novel Strip Self-Attention (SSA). We\ndesign simple yet effective Hybrid Perception Blocks (HPBs) to effectively\nintegrate the local perception capabilities of CNNs with the global context\nmodeling of Transformer's attention mechanisms. A key innovation of SSA lies in\nits reducing the spatial dimensions of $K$ and $V$ while compressing the\nchannel dimensions of $Q$ and $K$. This design significantly reduces\ncomputational overhead while preserving accuracy, striking an optimal balance\nbetween efficiency and effectiveness. We evaluate the robustness and efficiency\nof S2AFormer through extensive experiments on multiple vision benchmarks,\nincluding ImageNet-1k for image classification, ADE20k for semantic\nsegmentation, and COCO for object detection and instance segmentation. Results\ndemonstrate that S2AFormer achieves significant accuracy gains with superior\nefficiency in both GPU and non-GPU environments, making it a strong candidate\nfor efficient vision Transformers.",
    "pdf_url": "http://arxiv.org/pdf/2505.22195v1",
    "published": "2025-05-28T10:17:23+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.22194v2",
    "title": "Refining Datapath for Microscaling ViTs",
    "authors": [
      "Can Xiao",
      "Jianyi Cheng",
      "Aaron Zhao"
    ],
    "abstract": "Vision Transformers (ViTs) leverage the transformer architecture to\neffectively capture global context, demonstrating strong performance in\ncomputer vision tasks. A major challenge in ViT hardware acceleration is that\nthe model family contains complex arithmetic operations that are sensitive to\nmodel accuracy, such as the Softmax and LayerNorm operations, which cannot be\nmapped onto efficient hardware with low precision. Existing methods only\nexploit parallelism in the matrix multiplication operations of the model on\nhardware and keep these complex operations on the CPU. This results in\nsuboptimal performance due to the communication overhead between the CPU and\naccelerator. Can new data formats solve this problem?\n  In this work, we present the first ViT accelerator that maps all operations\nof the ViT models onto FPGAs. We exploit a new arithmetic format named\nMicroscaling Integer (MXInt) for datapath designs and evaluate how different\ndesign choices can be made to trade off accuracy, hardware performance, and\nhardware utilization. Our contributions are twofold. First, we quantize ViTs\nusing the MXInt format, achieving both high area efficiency and accuracy.\nSecond, we propose MXInt-specific hardware optimization that map these complex\narithmetic operations into custom hardware. Within 1\\% accuracy loss, our\nmethod achieves at least 93$\\times$ speedup compared to Float16 and at least\n1.9$\\times$ speedup compared to related work.",
    "pdf_url": "http://arxiv.org/pdf/2505.22194v2",
    "published": "2025-05-28T10:15:37+00:00",
    "categories": [
      "cs.AR"
    ],
    "primary_category": "cs.AR"
  },
  {
    "id": "http://arxiv.org/abs/2505.22193v1",
    "title": "Physics-inspired Generative AI models via real hardware-based noisy quantum diffusion",
    "authors": [
      "Marco Parigi",
      "Stefano Martina",
      "Francesco Aldo Venturelli",
      "Filippo Caruso"
    ],
    "abstract": "Quantum Diffusion Models (QDMs) are an emerging paradigm in Generative AI\nthat aims to use quantum properties to improve the performances of their\nclassical counterparts. However, existing algorithms are not easily scalable\ndue to the limitations of near-term quantum devices. Following our previous\nwork on QDMs, here we propose and implement two physics-inspired protocols. In\nthe first, we use the formalism of quantum stochastic walks, showing that a\nspecific interplay of quantum and classical dynamics in the forward process\nproduces statistically more robust models generating sets of MNIST images with\nlower Fr\\'echet Inception Distance (FID) than using totally classical dynamics.\nIn the second approach, we realize an algorithm to generate images by\nexploiting the intrinsic noise of real IBM quantum hardware with only four\nqubits. Our work could be a starting point to pave the way for new scenarios\nfor large-scale algorithms in quantum Generative AI, where quantum noise is\nneither mitigated nor corrected, but instead exploited as a useful resource.",
    "pdf_url": "http://arxiv.org/pdf/2505.22193v1",
    "published": "2025-05-28T10:11:48+00:00",
    "categories": [
      "quant-ph",
      "cond-mat.dis-nn",
      "cs.AI",
      "cs.CV",
      "cs.LG",
      "81P68, 81P40, 81P47, 68Q12, 68T07,",
      "I.2.6; I.3.3; J.2"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.22192v1",
    "title": "Efficient Leave-one-out Approximation in LLM Multi-agent Debate Based on Introspection",
    "authors": [
      "Yue Cui",
      "Liuyi Yao",
      "Zitao Li",
      "Yaliang Li",
      "Bolin Ding",
      "Xiaofang Zhou"
    ],
    "abstract": "Multi-agent systems based on large language models (LLMs) advance automatic\ntask completion in various fields, where debate is a common cooperation form\nfor agents to solve complicated problems with reasoning and cross-review to\nsolidify answers. Assessing the individual contributions of agents within these\ndebates is crucial for system refinement and outcome reliability. Traditional\nleave-one-out (LOO) method offers a clear framework for evaluating each agent's\nrole but face challenges in LLM-based systems due to high computational costs\nand associated financial implications. This paper presents\nintrospective-leave-one-out (IntrospecLOO), a simple yet effective prompting\nfor approximation of LOO in LLM-powered multi-agent debates. IntrospecLOO\nintroduces an additional querying round after standard debates, prompting\nagents to update their answers while ignoring responses from a designated\nagent. This strategy effectively isolates and gauges each participant's\ninfluence at a reduced query complexity compared to the original LOO\napproaches. Validation through experiments on three benchmark datasets confirms\nthe effectiveness of IntrospecLOO.",
    "pdf_url": "http://arxiv.org/pdf/2505.22192v1",
    "published": "2025-05-28T10:08:31+00:00",
    "categories": [
      "cs.MA"
    ],
    "primary_category": "cs.MA"
  },
  {
    "id": "http://arxiv.org/abs/2505.22191v1",
    "title": "Approximation of Dirac operators with confining electrostatic and Lorentz scalar $Œ¥$-shell potentials",
    "authors": [
      "Christian Stelzer-Landauer"
    ],
    "abstract": "In this paper we study the approximation of Dirac operators with\n$\\delta$-shell potentials in the norm resolvent sense. In particular, we\nconsider the approximation of Dirac operators with confining electrostatic and\nLorentz scalar $\\delta$-shell potentials, where the support of the\n$\\delta$-shell potentials is impermeable to particles modelled by such Dirac\noperators.",
    "pdf_url": "http://arxiv.org/pdf/2505.22191v1",
    "published": "2025-05-28T10:05:38+00:00",
    "categories": [
      "math.SP",
      "81Q10, 35P05, 35Q40"
    ],
    "primary_category": "math.SP"
  },
  {
    "id": "http://arxiv.org/abs/2505.22190v1",
    "title": "Convergence of the $ppp$ correlation function within the hyperspherical adiabatic basis",
    "authors": [
      "E. Garrido",
      "A. Kievsky",
      "R. Del Grande",
      "L. Serksnyte",
      "M. Viviani",
      "L. E. Marcucci"
    ],
    "abstract": "The computation of the three-particle correlation function involving three\nhadrons started just recently after the first publications of ALICE\nmeasurements. Key elements to be considered are the correct description of the\nasymptotics, antisymmetrization issues and, in most cases, the treatment of the\nCoulomb interaction. In the case of the $ppp$ correlation function, a first\nanalysis was done where the hyperspherical adiabatic method was used to\ndetermine the $ppp$ wave function at different energies. Although the\nasymptotic behavior, antisymmetrization issues and the treatment of the Coulomb\ninteraction were discussed in detail, the convergence properties of the\nadiabatic basis were studied at low energies around the formation of the\ncorrelation peak determined mainly by the $J^\\pi=1/2^-$ and $3/2^-$ three-body\nstates. Since many and very precise data have been taken or are planned to be\nmeasured at energies beyond the peak, we present an analysis of the convergence\ncharacteristics of the basis as the energy of the process increases. We show\nthat in order to describe correctly the correlation tail it is necessary to\nconsider three-body states up to $J^\\pi=21/2^-$ whereas higher states can be\nconsidered as free. Once those states are incorporated solving the associate\ndynamical equations, the agreement with the experimental data is found to be\nexcellent.",
    "pdf_url": "http://arxiv.org/pdf/2505.22190v1",
    "published": "2025-05-28T10:02:38+00:00",
    "categories": [
      "nucl-th",
      "nucl-ex"
    ],
    "primary_category": "nucl-th"
  },
  {
    "id": "http://arxiv.org/abs/2505.22189v1",
    "title": "Generalized Tur√°n problem for directed cycles",
    "authors": [
      "Andrzej Grzesik",
      "Justyna Jaworska",
      "Bart≈Çomiej Kielak",
      "Piotr Kuc",
      "Tomasz ≈ölusarczyk"
    ],
    "abstract": "For integers $k, \\ell \\geq 3$, let $\\mathrm{ex}(n, \\overrightarrow{C_k},\n\\overrightarrow{C_\\ell})$ denote the maximum number of directed cycles of\nlength $k$ in any oriented graph on $n$ vertices which does not contain a\ndirected cycle of length $\\ell$. We establish the order of magnitude of\n$\\mathrm{ex}(n, \\overrightarrow{C_k}, \\overrightarrow{C_\\ell})$ for every $k$\nand $\\ell$ and determine its value up to a lower error term when $k \\nmid \\ell$\nand $\\ell$ is large enough. Additionally, we calculate the value of\n$\\mathrm{ex}(n, \\overrightarrow{C_k}, \\overrightarrow{C_\\ell})$ for some other\nspecific pairs $(k, \\ell)$ showing that a diverse class of extremal\nconstructions can appear for small values of $\\ell$.",
    "pdf_url": "http://arxiv.org/pdf/2505.22189v1",
    "published": "2025-05-28T10:02:29+00:00",
    "categories": [
      "math.CO"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.22188v1",
    "title": "Dispersion of electromagnetic waves in a coaxial line filled with ferrite",
    "authors": [
      "V. A. Balakirev",
      "I. N. Onishchenko"
    ],
    "abstract": "By solving Maxwell's equations the exact dispersion equation for\nelectromagnetic waves propagating in a layered coaxial ferrite line is\nobtained. In particular the analytical consideration is carried out for a\nsimpler case of complete filling of the coaxial line with ferrite (i.e.\nhomogeneous ferrite line). The behavior of dispersion curves of TEM -\nelectromagnetic waves, as well as E - and H - waveguide electromagnetic waves,\nis investigated.",
    "pdf_url": "http://arxiv.org/pdf/2505.22188v1",
    "published": "2025-05-28T10:00:31+00:00",
    "categories": [
      "physics.acc-ph"
    ],
    "primary_category": "physics.acc-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.22187v1",
    "title": "MONSTR: Model-Oriented Neutron Strain Tomographic Reconstruction",
    "authors": [
      "Mohammad Samin Nur Chowdhury",
      "Shimin Tang",
      "Singanallur V. Venkatakrishnan",
      "Hassina Z. Bilheux",
      "Gregery T. Buzzard",
      "Charles A. Bouman"
    ],
    "abstract": "Residual strain, a tensor quantity, is a critical material property that\nimpacts the overall performance of metal parts. Neutron Bragg edge strain\ntomography is a technique for imaging residual strain that works by making\nconventional hyperspectral computed tomography measurements, extracting the\naverage projected strain at each detector pixel, and processing the resulting\nstrain sinogram using a reconstruction algorithm. However, the reconstruction\nis severely ill-posed as the underlying inverse problem involves inferring a\ntensor at each voxel from scalar sinogram data.\n  In this paper, we introduce the model-oriented neutron strain tomographic\nreconstruction (MONSTR) algorithm that reconstructs the 2D residual strain\ntensor from the neutron Bragg edge strain measurements. MONSTR is based on\nusing the multi-agent consensus equilibrium framework for the tensor\ntomographic reconstruction. Specifically, we formulate the reconstruction as a\nconsensus solution of a collection of agents representing detector physics, the\ntomographic reconstruction process, and physics-based constraints from\ncontinuum mechanics. Using simulated data, we demonstrate high-quality\nreconstruction of the strain tensor even when using very few measurements.",
    "pdf_url": "http://arxiv.org/pdf/2505.22187v1",
    "published": "2025-05-28T09:59:37+00:00",
    "categories": [
      "eess.IV",
      "eess.SP"
    ],
    "primary_category": "eess.IV"
  },
  {
    "id": "http://arxiv.org/abs/2505.22186v2",
    "title": "Hot Rocks Survey III: A deep eclipse for LHS 1140c and a new Gaussian process method to account for correlated noise in individual pixels",
    "authors": [
      "Mark Fortune",
      "Neale P. Gibson",
      "Hannah Diamond-Lowe",
      "Jo√£o M. Mendon√ßa",
      "Am√©lie Gressier",
      "Daniel Kitzmann",
      "Natalie H. Allen",
      "Prune C. August",
      "Jegug Ih",
      "Erik Meier Vald√©s",
      "Merlin Zgraggen",
      "Lars A. Buchhave",
      "Brice-Olivier Demory",
      "N√©stor Espinoza",
      "Kevin Heng",
      "Kathryn Jones",
      "Alexander D. Rathcke"
    ],
    "abstract": "Time-series photometry at mid-infrared wavelengths is becoming a common\ntechnique to search for atmospheres around rocky exoplanets. This method\nconstrains the brightness temperature of the planet to determine whether heat\nredistribution is taking place - indicative of an atmosphere - or whether the\nheat is reradiated from a low albedo bare rock. By observing at 15$\\mu$m we are\nalso highly sensitive to CO$_2$ absorption. We observed three eclipses of the\nrocky super-Earth LHS 1140c using MIRI/Imaging with the F1500W filter. We found\nsignificant variation in the initial settling ramp for these observations and\nidentify a potential trend between detector settling and the previous filter\nused by MIRI. We analysed our data using aperture photometry but also developed\na novel approach which joint-fits pixel light curves directly using a shared\neclipse model and a flexible multi-dimensional Gaussian process which models\nchanges in the PSF over time. We demonstrate using simulated data that our\nmethod has the ability to weight away from particular pixels which show\nincreased systematics, allowing for the recovery of eclipse depths in a more\nrobust and precise way. Both methods and an independent analysis detect the\neclipse at $>5\\sigma$ and are highly consistent with a low albedo bare rock. We\nrecover a dayside brightness temperature of $T_\\mathrm{day} = 561\\pm44$ K,\nclose to the theoretical maximum of $T_\\text{day; max} = 537\\pm9$ K. We rule\nout a wide range of atmospheric forward models to $>3\\sigma$ including pure\nCO$_2$ atmospheres with surface pressure $\\ge10$ mbar and pure H$_2$O\natmospheres with surface pressure $\\ge1$ bar. Our strict constraints on\npotential atmospheric composition, in combination with future observations of\nthe exciting outer planet LHS 1140b, could provide a powerful benchmark to\nunderstand atmospheric escape around M dwarfs.",
    "pdf_url": "http://arxiv.org/pdf/2505.22186v2",
    "published": "2025-05-28T09:59:03+00:00",
    "categories": [
      "astro-ph.EP",
      "astro-ph.IM"
    ],
    "primary_category": "astro-ph.EP"
  },
  {
    "id": "http://arxiv.org/abs/2505.22185v1",
    "title": "Quantum Effects at a Spin-Flop Transition in the Antiferromagnetic Topological Insulator MnBi$_2$Te$_4$",
    "authors": [
      "V. V. Val'kov",
      "A. O. Zlotnikov",
      "A. Gamov",
      "N. A. Fedorova",
      "F. N. Tomilin"
    ],
    "abstract": "It is shown that the experimentally detected features in the low-temperature\nbehavior of the magnetization in an external magnetic field perpendicular to\nthe layers of manganese ions of the topological antiferromagnet MnBi$_2$Te$_4$\nare due to quantum effects induced by the off-diagonal nature of the trigonal\ncomponent of the crystal field. In this case, the anomalous increase in the\nmagnetization of the material before the spin-flop transition, as well as after\nit in the phase of \"collapsed\" sublattices, is explained by the suppression of\ncontributions from quantum effects. The comparison of the results of the\ntheoretical analysis with experimental data has made it possible to refine the\nparameters of the effective spin model of MnBi$_2$Te$_4$ and to establish the\nimportant role of the noted trigonal component.",
    "pdf_url": "http://arxiv.org/pdf/2505.22185v1",
    "published": "2025-05-28T09:58:38+00:00",
    "categories": [
      "cond-mat.str-el"
    ],
    "primary_category": "cond-mat.str-el"
  },
  {
    "id": "http://arxiv.org/abs/2505.22184v2",
    "title": "Breaking the Cloak! Unveiling Chinese Cloaked Toxicity with Homophone Graph and Toxic Lexicon",
    "authors": [
      "Xuchen Ma",
      "Jianxiang Yu",
      "Wenming Shao",
      "Bo Pang",
      "Xiang Li"
    ],
    "abstract": "Social media platforms have experienced a significant rise in toxic content,\nincluding abusive language and discriminatory remarks, presenting growing\nchallenges for content moderation. Some users evade censorship by deliberately\ndisguising toxic words through homophonic cloak, which necessitates the task of\nunveiling cloaked toxicity. Existing methods are mostly designed for English\ntexts, while Chinese cloaked toxicity unveiling has not been solved yet. To\ntackle the issue, we propose C$^2$TU, a novel training-free and prompt-free\nmethod for Chinese cloaked toxic content unveiling. It first employs substring\nmatching to identify candidate toxic words based on Chinese homo-graph and\ntoxic lexicon. Then it filters those candidates that are non-toxic and corrects\ncloaks to be their corresponding toxicities. Specifically, we develop two model\nvariants for filtering, which are based on BERT and LLMs, respectively. For\nLLMs, we address the auto-regressive limitation in computing word occurrence\nprobability and utilize the full semantic contexts of a text sequence to reveal\ncloaked toxic words. Extensive experiments demonstrate that C$^2$TU can achieve\nsuperior performance on two Chinese toxic datasets. In particular, our method\noutperforms the best competitor by up to 71% on the F1 score and 35% on\naccuracy, respectively. Our code and data are available at\nhttps://github.com/XDxc-cuber/C2TU-Chinese-cloaked-toxicity-unveiling.",
    "pdf_url": "http://arxiv.org/pdf/2505.22184v2",
    "published": "2025-05-28T09:58:15+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.22183v2",
    "title": "Anomalous Hall Effect in Thick Co$_3$Sn$_2$S$_2$ Weyl Semimetal Crystals",
    "authors": [
      "Eddy Divin Kenvo Songwa",
      "Shaday Jesus Nobosse Nguemeta",
      "Hodaya Gabber",
      "Renana Aharonof",
      "Dima Cheskis"
    ],
    "abstract": "Ferromagnetic Weyl semimetals with Kagome lattice structures exhibit a strong\ncoupling between magnetism and topological band features. Co3Sn2S2 is a prime\nexample, showing a giant anomalous Hall effect (AHE) driven by Berry curvature\nfrom the Weyl nodes. We investigated the temperature and angular dependence of\nHall conductivity in thick Co3Sn2S2 crystals, aiming to distinguish between\ntopological and conventional magnetic contributions. Our measurements reveal a\nrobust Hall response even at low magnetic fields and temperatures above 77 K,\nsuggesting a dominant topological origin and weak sensitivity to external\nconditions.",
    "pdf_url": "http://arxiv.org/pdf/2505.22183v2",
    "published": "2025-05-28T09:57:27+00:00",
    "categories": [
      "cond-mat.mes-hall",
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mes-hall"
  },
  {
    "id": "http://arxiv.org/abs/2505.22182v1",
    "title": "Post-processing of wind gusts from COSMO-REA6 with a spatial Bayesian hierarchical extreme value model",
    "authors": [
      "Philipp Ertz",
      "Petra Friederichs"
    ],
    "abstract": "The aim of this study is to provide a probabilistic gust analysis for the\nregion of Germany that is calibrated with station observations and with an\ninterpolation to unobserved locations. To this end, we develop a spatial\nBayesian hierarchical model (BHM) for the post-processing of surface maximum\nwind gusts from the COSMO-REA6 reanalysis. Our approach uses a non-stationary\nextreme value distribution for the gust observations, with parameters that vary\naccording to a linear model using COSMO-REA6 predictor variables. To capture\nspatial patterns in surface wind gust behavior, the regression coefficients are\nmodeled as 2-dimensional Gaussian random fields with a constant mean and an\nisotropic covariance function that depends on the distance between locations.\nIn addition, we include an elevation offset in the distance metric for the\ncovariance function to account for the topography. This allows us to include\ndata from mountaintop stations in the training process. The training of the BHM\nis carried out with an independent data set from which the data at the station\nto be predicted are excluded. We evaluate the spatial prediction performance at\nthe withheld station using Brier score and quantile score, including their\ndecomposition, and compare the performance of our BHM to climatological\nforecasts and a non-hierarchical, spatially constant baseline model. This is\ndone for 109 weather stations in Germany. Compared to the spatially constant\nbaseline model, the spatial BHM significantly improves the estimation of local\ngust parameters. It shows up to 5 % higher skill for prediction quantiles and\nprovides a particularly improved skill for extreme wind gusts. In addition, the\nBHM improves the prediction of threshold levels at most of the stations.\nAlthough a spatially constant approach already provides high skill, our BHM\nfurther improves predictions and improves spatial consistency.",
    "pdf_url": "http://arxiv.org/pdf/2505.22182v1",
    "published": "2025-05-28T09:56:58+00:00",
    "categories": [
      "physics.ao-ph",
      "stat.AP"
    ],
    "primary_category": "physics.ao-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.22181v1",
    "title": "Term Ordering Diagrams",
    "authors": [
      "M√°rton Hajdu",
      "Robin Coutelier",
      "Laura Kov√°cs",
      "Andrei Voronkov"
    ],
    "abstract": "The superposition calculus for reasoning in first-order logic with equality\nrelies on simplification orderings on terms. Modern saturation provers use the\nKnuth-Bendix order (KBO) and the lexicographic path order (LPO) for discovering\nredundant clauses and inferences. Implementing term orderings is however\nchallenging. While KBO comparisons can be performed in linear time and LPO\nchecks in quadratic time, using the best known algorithms for these orders is\nnot enough. Indeed, our experiments show that for some examples term ordering\nchecks may use about 98% of the overall proving time. The reason for this is\nthat some equalities that cannot be ordered can become ordered after applying a\nsubstitution (post-ordered), and we have to check for post-ordering repeatedly\nfor the same equalities. In this paper, we show how to improve post-ordering\nchecks by introducing a new data structure called term ordering diagrams, in\nshort TODs, which creates an index for these checks. We achieve efficiency by\nlazy modifications of the index and by storing and reusing information from\npreviously performed checks to speed up subsequent checks. Our experiments\ndemonstrate efficiency of TODs.",
    "pdf_url": "http://arxiv.org/pdf/2505.22181v1",
    "published": "2025-05-28T09:56:55+00:00",
    "categories": [
      "cs.LO"
    ],
    "primary_category": "cs.LO"
  },
  {
    "id": "http://arxiv.org/abs/2505.22180v1",
    "title": "Some iterative algorithms on Riemannian manifolds and Banach spaces with good global convergence guarantee",
    "authors": [
      "Tuyen Trung Truong"
    ],
    "abstract": "In this paper, we introduce some new iterative optimisation algorithms on\nRiemannian manifolds and Hilbert spaces which have good global convergence\nguarantees to local minima. More precisely, these algorithms have the following\nproperties: If $\\{x_n\\}$ is a sequence constructed by one such algorithm then:\n  - Finding critical points: Any cluster point of $\\{x_n\\}$ is a critical point\nof the cost function $f$.\n  - Convergence guarantee: Under suitable assumptions, the sequence $\\{x_n\\}$\neither converges to a point $x^*$, or diverges to $\\infty$.\n  - Avoidance of saddle points: If $x_0$ is randomly chosen, then the sequence\n$\\{x_n\\}$ cannot converge to a saddle point.\n  Our results apply for quite general situations: the cost function $f$ is\nassumed to be only $C^2$ or $C^3$, and either $f$ has at most countably many\ncritical points (which is a generic situation) or satisfies certain Lojasiewicz\ngradient inequalities. To illustrate the results, we provide a nice application\nwith optimisation over the unit sphere in a Euclidean space.\n  As for tools needed for the results, in the Riemannian manifold case we\nintroduce a notion of \"strong local retraction\" and (to deal with Newton's\nmethod type) a notion of \"real analytic-like strong local retraction\". In the\ncase of Banach spaces, we introduce a slight generalisation of the notion of\n\"shyness\", and design a new variant of Backtracking New Q-Newton's method which\nis more suitable to the infinite dimensional setting (and in the Euclidean\nsetting is simpler than the current versions).",
    "pdf_url": "http://arxiv.org/pdf/2505.22180v1",
    "published": "2025-05-28T09:56:18+00:00",
    "categories": [
      "math.OC",
      "math.DS"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2505.22179v2",
    "title": "Speculative Decoding Meets Quantization: Compatibility Evaluation and Hierarchical Framework Design",
    "authors": [
      "Yudi Zhang",
      "Weilin Zhao",
      "Xu Han",
      "Tiejun Zhao",
      "Wang Xu",
      "Hailong Cao",
      "Conghui Zhu"
    ],
    "abstract": "Speculative decoding and quantization effectively accelerate memory-bound\ninference of large language models. Speculative decoding mitigates the memory\nbandwidth bottleneck by verifying multiple tokens within a single forward pass,\nwhich increases computational effort. Quantization achieves this optimization\nby compressing weights and activations into lower bit-widths and also reduces\ncomputations via low-bit matrix multiplications. To further leverage their\nstrengths, we investigate the integration of these two techniques.\nSurprisingly, experiments applying the advanced speculative decoding method\nEAGLE-2 to various quantized models reveal that the memory benefits from 4-bit\nweight quantization are diminished by the computational load from speculative\ndecoding. Specifically, verifying a tree-style draft incurs significantly more\ntime overhead than a single-token forward pass on 4-bit weight quantized\nmodels. This finding led to our new speculative decoding design: a hierarchical\nframework that employs a small model as an intermediate stage to turn\ntree-style drafts into sequence drafts, leveraging the memory access benefits\nof the target quantized model. Experimental results show that our hierarchical\napproach achieves a 2.78$\\times$ speedup across various tasks for the 4-bit\nweight Llama-3-70B model on an A100 GPU, outperforming EAGLE-2 by 1.31$\\times$.\nCode available at https://github.com/AI9Stars/SpecMQuant.",
    "pdf_url": "http://arxiv.org/pdf/2505.22179v2",
    "published": "2025-05-28T09:55:08+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.22178v1",
    "title": "Signature maps from positive cones on algebras with involution",
    "authors": [
      "Vincent Astier",
      "Thomas Unger"
    ],
    "abstract": "We introduced positive cones in an earlier paper as a notion of ordering on\ncentral simple algebras with involution that corresponds to signatures of\nhermitian forms. In the current paper we describe signatures of hermitian forms\ndirectly out of positive cones, and also use this approach to rectify a problem\nthat affected some results in the previously mentioned paper.",
    "pdf_url": "http://arxiv.org/pdf/2505.22178v1",
    "published": "2025-05-28T09:53:56+00:00",
    "categories": [
      "math.RA",
      "13J30, 16W10, 06F25, 16K20, 11E39"
    ],
    "primary_category": "math.RA"
  },
  {
    "id": "http://arxiv.org/abs/2505.22177v1",
    "title": "Hydrogen-like structures in the strong interaction",
    "authors": [
      "Lei Liu",
      "Yanmei Xiao",
      "Tao Guo"
    ],
    "abstract": "Heavy flavor hadrons, especially doubly heavy baryons and doubly heavy\ntetraquarks, have always received extensive attention in theoretical and\nexperimental research. Given the separation of quark masses $m_Q \\gg m_q$ ($Q =\nc, b$ and $q = u, d, s$), this type of heavy flavor hadrons can be well\nregarded as hydrogen-like structures in the strong interaction. In the\ntheoretical framework of Born-Oppenheimer approximation, we derive the\nSchr{\\\"o}dinger equation for the motion of light quarks in the effective\npotential field of heavy quarks. Taking proper account of the color-spin\nhyperfine interaction, we carry out a systematic study on the mass spectra of\n$S$-wave doubly heavy baryons and doubly heavy tetraquarks. The model\nparameters required for the calculation are obtained by fitting conventional\nhadrons. The investigation on the doubly heavy baryon systems indicates the\nreliability of our theoretical approach. Our calculation results show that the\nexperimentally discovered $T_{cc}^+$ is most likely a compact tetraquark\n$|(cc)_0^{6}(\\bar{u}\\bar{d})_1^{\\bar{6}}\\rangle$ state with quantum numbers\n$(I,J^P)=(0, 1^+)$. Forthermore, for different quantum number assignments, some\nstable tetraquark states are found and may be very narrow peaks. The\npredictions for other heavy flavor hadrons are expected to be confirmed in new\ntheories and future experiments.",
    "pdf_url": "http://arxiv.org/pdf/2505.22177v1",
    "published": "2025-05-28T09:52:04+00:00",
    "categories": [
      "hep-ph"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.22176v2",
    "title": "TabXEval: Why this is a Bad Table? An eXhaustive Rubric for Table Evaluation",
    "authors": [
      "Vihang Pancholi",
      "Jainit Bafna",
      "Tejas Anvekar",
      "Manish Shrivastava",
      "Vivek Gupta"
    ],
    "abstract": "Evaluating tables qualitatively and quantitatively poses a significant\nchallenge, as standard metrics often overlook subtle structural and\ncontent-level discrepancies. To address this, we propose a rubric-based\nevaluation framework that integrates multi-level structural descriptors with\nfine-grained contextual signals, enabling more precise and consistent table\ncomparison. Building on this, we introduce TabXEval, an eXhaustive and\neXplainable two-phase evaluation framework. TabXEval first aligns reference and\npredicted tables structurally via TabAlign, then performs semantic and\nsyntactic comparison using TabCompare, offering interpretable and granular\nfeedback. We evaluate TabXEval on TabXBench, a diverse, multi-domain benchmark\nfeaturing realistic table perturbations and human annotations. A\nsensitivity-specificity analysis further demonstrates the robustness and\nexplainability of TabXEval across varied table tasks. Code and data are\navailable at https://coral-lab-asu.github.io/tabxeval/",
    "pdf_url": "http://arxiv.org/pdf/2505.22176v2",
    "published": "2025-05-28T09:50:29+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.22175v1",
    "title": "Algorithm Unrolling-based Denoising of Multimodal Graph Signals",
    "authors": [
      "Hayate Kojima",
      "Keigo Takanami",
      "Junya Hara",
      "Yukihiro Bandoh",
      "Seishi Takamura",
      "Hiroshi Higashi",
      "Yuichi Tanaka"
    ],
    "abstract": "We propose a denoising method of multimodal graph signals by iteratively\nsolving signal restoration and graph learning problems. Many complex-structured\ndata, i.e., those on sensor networks, can capture multiple modalities at each\nmeasurement point, referred to as modalities. They are also assumed to have an\nunderlying structure or correlations in modality as well as space. Such\nmultimodal data are regarded as graph signals on a twofold graph and they are\noften corrupted by noise. Furthermore, their spatial/modality relationships are\nnot always given a priori: We need to estimate twofold graphs during a\ndenoising algorithm. In this paper, we consider a signal denoising method on\ntwofold graphs, where graphs are learned simultaneously. We formulate an\noptimization problem for that and parameters in an iterative algorithm are\nlearned from training data by unrolling the iteration with deep algorithm\nunrolling. Experimental results on synthetic and real-world data demonstrate\nthat the proposed method outperforms existing model- and deep learning-based\ngraph signal denoising methods.",
    "pdf_url": "http://arxiv.org/pdf/2505.22175v1",
    "published": "2025-05-28T09:49:52+00:00",
    "categories": [
      "eess.SP"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2505.22174v1",
    "title": "Online Fair Division for Personalized $2$-Value Instances",
    "authors": [
      "Georgios Amanatidis",
      "Alexandros Lolos",
      "Evangelos Markakis",
      "Victor Turmel"
    ],
    "abstract": "We study an online fair division setting, where goods arrive one at a time\nand there is a fixed set of $n$ agents, each of whom has an additive valuation\nfunction over the goods. Once a good appears, the value each agent has for it\nis revealed and it must be allocated immediately and irrevocably to one of the\nagents. It is known that without any assumptions about the values being\nseverely restricted or coming from a distribution, very strong impossibility\nresults hold in this setting. To bypass the latter, we turn our attention to\ninstances where the valuation functions are restricted. In particular, we study\npersonalized $2$-value instances, where there are only two possible values each\nagent may have for each good, possibly different across agents, and we show how\nto obtain worst case guarantees with respect to well-known fairness notions,\nsuch as maximin share fairness and envy-freeness up to one (or two) good(s). We\nsuggest a deterministic algorithm that maintains a $1/(2n-1)$-MMS allocation at\nevery time step and show that this is the best possible any deterministic\nalgorithm can achieve if one cares about every single time step; nevertheless,\neventually the allocation constructed by our algorithm becomes a $1/4$-MMS\nallocation. To achieve this, the algorithm implicitly maintains a fragile\nsystem of priority levels for all agents. Further, we show that, by allowing\nsome limited access to future information, it is possible to have stronger\nresults with less involved approaches. By knowing the values of goods for $n-1$\ntime steps into the future, we design a matching-based algorithm that achieves\nan EF$1$ allocation every $n$ time steps, while always maintaining an EF$2$\nallocation. Finally, we show that our results allow us to get the first\nnontrivial guarantees for additive instances in which the ratio of the maximum\nover the minimum value an agent has for a good is bounded.",
    "pdf_url": "http://arxiv.org/pdf/2505.22174v1",
    "published": "2025-05-28T09:48:16+00:00",
    "categories": [
      "cs.GT",
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.GT"
  },
  {
    "id": "http://arxiv.org/abs/2505.22173v1",
    "title": "Charting circumstellar chemistry of carbon-rich asymptotic giant branch stars. II. Abundances and spatial distributions of CS",
    "authors": [
      "R. Unnikrishnan",
      "M. Andriantsaralaza",
      "E. De Beck",
      "L. -√Ö. Nyman",
      "H. Olofsson",
      "W. H. T. Vlemmings",
      "M. Maercker",
      "M. Van de Sande",
      "T. Danilovich",
      "T. J. Millar",
      "S. B. Charnley",
      "M. G. Rawlings"
    ],
    "abstract": "The circumstellar envelopes (CSEs) of asymptotic giant branch (AGB) stars\nharbour a rich variety of molecules and are sites of complex chemistry. Our\ncurrent understanding of the circumstellar chemical processes of carbon-rich\nAGB stars is predominantly based on observations of a single star, IRC+10216,\noften regarded as an archetypical carbon star. We aim to estimate stellar and\ncircumstellar properties for five carbon stars, and constrain their\ncircumstellar CS abundances. This study compares the CS abundances among the\nsources, informs circumstellar chemical models, and helps to assess if\nIRC+10216 is a good representative of the physics and chemistry of carbon star\nCSEs. We modelled the spectral energy distributions (SEDs) and CO line emission\nto derive the stellar and outflow properties. Using these, we then retrieved CS\nabundance profiles with detailed radiative transfer modelling, imposing spatial\nand excitation constraints from ALMA and single-dish observations. We obtain\ngood fits to the SEDs and CO lines for all sources and reproduce the CS line\nemission across various transitions and apertures, yielding robust estimates of\nthe CS abundance profiles. Peak CS fractional abundances range from\n1$\\times$10$^{-6}$ - 4$\\times$10$^{-6}$, with e-folding radii of\n1.8$\\times$10$^{16}$ - 6.8$\\times$10$^{16}$ cm. We also derive reliable\n$^{12}$C/$^{13}$C and $^{32}$S/$^{34}$S ratios from CS isotopologue modelling.\nOur results refine previous single-dish CS abundance estimates and improve the\nrelative uncertainty on the CS e-folding radius for IRAS 07454$-$7112 by a\nfactor of $\\sim$2.5. Chemical models reproduce our estimates of the CS radial\nextent, corroborating the CS photodissociation framework used therein. We find\nno significant differences between the derived CS abundance profiles for\nIRC+10216 and the rest of the sample, apart from the expected density-driven\nvariations.",
    "pdf_url": "http://arxiv.org/pdf/2505.22173v1",
    "published": "2025-05-28T09:45:58+00:00",
    "categories": [
      "astro-ph.SR",
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.SR"
  },
  {
    "id": "http://arxiv.org/abs/2505.22172v1",
    "title": "Reverse Preference Optimization for Complex Instruction Following",
    "authors": [
      "Xiang Huang",
      "Ting-En Lin",
      "Feiteng Fang",
      "Yuchuan Wu",
      "Hangyu Li",
      "Yuzhong Qu",
      "Fei Huang",
      "Yongbin Li"
    ],
    "abstract": "Instruction following (IF) is a critical capability for large language models\n(LLMs). However, handling complex instructions with multiple constraints\nremains challenging. Previous methods typically select preference pairs based\non the number of constraints they satisfy, introducing noise where chosen\nexamples may fail to follow some constraints and rejected examples may excel in\ncertain respects over the chosen ones. To address the challenge of aligning\nwith multiple preferences, we propose a simple yet effective method called\nReverse Preference Optimization (RPO). It mitigates noise in preference pairs\nby dynamically reversing the constraints within the instruction to ensure the\nchosen response is perfect, alleviating the burden of extensive sampling and\nfiltering to collect perfect responses. Besides, reversal also enlarges the gap\nbetween chosen and rejected responses, thereby clarifying the optimization\ndirection and making it more robust to noise. We evaluate RPO on two multi-turn\nIF benchmarks, Sysbench and Multi-IF, demonstrating average improvements over\nthe DPO baseline of 4.6 and 2.5 points (on Llama-3.1 8B), respectively.\nMoreover, RPO scales effectively across model sizes (8B to 70B parameters),\nwith the 70B RPO model surpassing GPT-4o.",
    "pdf_url": "http://arxiv.org/pdf/2505.22172v1",
    "published": "2025-05-28T09:44:27+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.22171v2",
    "title": "The 2-Category of Topological Quantum Computation",
    "authors": [
      "Fatimah Rita Ahmadi"
    ],
    "abstract": "Unitary Ribbon Fusion Categories (URFC) formalize anyonic theories. It has\nbeen widely assumed that the same category formalizes a topological quantum\ncomputing model. However, in previous work, we addressed and resolved this\nconfusion and demonstrated while the former could be any fusion category, the\nlatter is always a subcategory of Hilb. In this paper, we argue that a\ncategorical formalism that captures and unifies both anyonic theories (the\nHardware of quantum computing) and a model of topological quantum computing is\na braided (fusion) 2-category. In this 2-category, 0-morphisms describe anyonic\ntypes and Hom-categories describe different models of quantum computing. This\npicture provides an insightful perspective on superselection rules. It presents\nfurthermore a clear distinction between fusion of anyons versus tensor products\nas defined in linear algebra, between vector spaces of 1-morphisms. The former\nrepresents a monoidal product and sum between 0-morphisms and the latter a\ntensor product and direct sum between 1-morphisms.",
    "pdf_url": "http://arxiv.org/pdf/2505.22171v2",
    "published": "2025-05-28T09:41:17+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.22170v1",
    "title": "Attention-Enhanced Prompt Decision Transformers for UAV-Assisted Communications with AoI",
    "authors": [
      "Chi Lu",
      "Yiyang Ni",
      "Zhe Wang",
      "Xiaoli Shi",
      "Jun Li",
      "Shi Jin"
    ],
    "abstract": "Decision Transformer (DT) has recently demonstrated strong generalizability\nin dynamic resource allocation within unmanned aerial vehicle (UAV) networks,\ncompared to conventional deep reinforcement learning (DRL). However, its\nperformance is hindered due to zero-padding for varying state dimensions,\ninability to manage long-term energy constraint, and challenges in acquiring\nexpert samples for few-shot fine-tuning in new scenarios. To overcome these\nlimitations, we propose an attention-enhanced prompt Decision Transformer\n(APDT) framework to optimize trajectory planning and user scheduling, aiming to\nminimize the average age of information (AoI) under long-term energy constraint\nin UAV-assisted Internet of Things (IoT) networks. Specifically, we enhance the\nconvenional DT framework by incorporating an attention mechanism to accommodate\nvarying numbers of terrestrial users, introducing a prompt mechanism based on\nshort trajectory demonstrations for rapid adaptation to new scenarios, and\ndesigning a token-assisted method to address the UAV's long-term energy\nconstraint. The APDT framework is first pre-trained on offline datasets and\nthen efficiently generalized to new scenarios. Simulations demonstrate that\nAPDT achieves twice faster in terms of convergence rate and reduces average AoI\nby $8\\%$ compared to conventional DT.",
    "pdf_url": "http://arxiv.org/pdf/2505.22170v1",
    "published": "2025-05-28T09:41:10+00:00",
    "categories": [
      "eess.SP",
      "cs.IT",
      "math.IT"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2505.22169v1",
    "title": "ReliableEval: A Recipe for Stochastic LLM Evaluation via Method of Moments",
    "authors": [
      "Gili Lior",
      "Eliya Habba",
      "Shahar Levy",
      "Avi Caciularu",
      "Gabriel Stanovsky"
    ],
    "abstract": "LLMs are highly sensitive to prompt phrasing, yet standard benchmarks\ntypically report performance using a single prompt, raising concerns about the\nreliability of such evaluations. In this work, we argue for a stochastic method\nof moments evaluation over the space of meaning-preserving prompt\nperturbations. We introduce a formal definition of reliable evaluation that\naccounts for prompt sensitivity, and suggest ReliableEval - a method for\nestimating the number of prompt resamplings needed to obtain meaningful\nresults. Using our framework, we stochastically evaluate five frontier LLMs and\nfind that even top-performing models like GPT-4o and Claude-3.7-Sonnet exhibit\nsubstantial prompt sensitivity. Our approach is model-, task-, and\nmetric-agnostic, offering a recipe for meaningful and robust LLM evaluation.",
    "pdf_url": "http://arxiv.org/pdf/2505.22169v1",
    "published": "2025-05-28T09:40:48+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.22168v2",
    "title": "Apax: A Flexible and Performant Framework For The Development of Machine-Learned Interatomic Potentials",
    "authors": [
      "Moritz Ren√© Sch√§fer",
      "Nico Segreto",
      "Fabian Zills",
      "Christian Holm",
      "Johannes K√§stner"
    ],
    "abstract": "We introduce Atomistic learned potentials in JAX (apax), a flexible and\nefficient open source software package for training and inference of\nmachine-learned interatomic potentials. Built on the JAX framework, apax\nsupports GPU acceleration and implements flexible model abstractions for fast\ndevelopment. With features such as kernel-based data selection, well-calibrated\nuncertainty estimation, and enhanced sampling, it is tailored to active\nlearning applications and ease of use. The features and design decisions made\nin apax are discussed before demonstrating some of its capabilities. First, a\ndata set for the room-temperature ionic liquid EMIM+BF4- is created using\nactive learning. It is highlighted how continuously learning models between\niterations can reduce training times up to 85 % with only a minor reduction of\nthe models' accuracy. Second, we show good scalability in a data-parallel\ntraining setting. We report that a Gaussian Moment Neural Network model, as\nimplemented in apax, achieves higher accuracy and up to 10 times faster\ninference times than a performance-optimized Allegro model. A recently\npublished Li3PO4 dataset, reported with comparable accuracy and inference\nperformance metrics, is used as a point of comparison. Moreover, the inference\nspeeds of the available simulation engines are compared. Finally, to highlight\nthe modularity of apax, an equivariant message-passing model is trained as a\nshallow ensemble and used to perform uncertainty-driven dynamics.",
    "pdf_url": "http://arxiv.org/pdf/2505.22168v2",
    "published": "2025-05-28T09:34:03+00:00",
    "categories": [
      "physics.chem-ph"
    ],
    "primary_category": "physics.chem-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.22167v1",
    "title": "Q-VDiT: Towards Accurate Quantization and Distillation of Video-Generation Diffusion Transformers",
    "authors": [
      "Weilun Feng",
      "Chuanguang Yang",
      "Haotong Qin",
      "Xiangqi Li",
      "Yu Wang",
      "Zhulin An",
      "Libo Huang",
      "Boyu Diao",
      "Zixiang Zhao",
      "Yongjun Xu",
      "Michele Magno"
    ],
    "abstract": "Diffusion transformers (DiT) have demonstrated exceptional performance in\nvideo generation. However, their large number of parameters and high\ncomputational complexity limit their deployment on edge devices. Quantization\ncan reduce storage requirements and accelerate inference by lowering the\nbit-width of model parameters. Yet, existing quantization methods for image\ngeneration models do not generalize well to video generation tasks. We identify\ntwo primary challenges: the loss of information during quantization and the\nmisalignment between optimization objectives and the unique requirements of\nvideo generation. To address these challenges, we present Q-VDiT, a\nquantization framework specifically designed for video DiT models. From the\nquantization perspective, we propose the Token-aware Quantization Estimator\n(TQE), which compensates for quantization errors in both the token and feature\ndimensions. From the optimization perspective, we introduce Temporal\nMaintenance Distillation (TMD), which preserves the spatiotemporal correlations\nbetween frames and enables the optimization of each frame with respect to the\noverall video context. Our W3A6 Q-VDiT achieves a scene consistency of 23.40,\nsetting a new benchmark and outperforming current state-of-the-art quantization\nmethods by 1.9$\\times$. Code will be available at\nhttps://github.com/cantbebetter2/Q-VDiT.",
    "pdf_url": "http://arxiv.org/pdf/2505.22167v1",
    "published": "2025-05-28T09:33:52+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.22166v3",
    "title": "Critical and Nonpercolating Phases in Bond Percolation on the Song-Havlin-Makse Network",
    "authors": [
      "Kazuki Wataya",
      "Takehisa Hasegawa"
    ],
    "abstract": "We investigate bond percolation on the Song-Havlin-Makse (SHM) network, a\nscale-free tree with a tunable degree exponent and dimensionality. Using a\ngenerating function approach, we analytically derive the average size and the\nfractal exponent of the root cluster for deterministic cases. Our analysis\nreveals that bond percolation on the SHM network remains in a nonpercolating\nphase for all $p < 1$ when the network is fractal (i.e., finite-dimensional),\nwhereas it exhibits a critical phase, where the cluster size distribution\nfollows a power-law with a $p$-dependent exponent, throughout the entire range\nof $p$ when the network is small-world (i.e., infinite-dimensional), regardless\nof the specific dimensionality or degree exponent. The analytical results are\nin excellent agreement with Monte Carlo simulations.",
    "pdf_url": "http://arxiv.org/pdf/2505.22166v3",
    "published": "2025-05-28T09:33:11+00:00",
    "categories": [
      "cond-mat.stat-mech",
      "cond-mat.dis-nn"
    ],
    "primary_category": "cond-mat.stat-mech"
  },
  {
    "id": "http://arxiv.org/abs/2505.22165v1",
    "title": "Unifying Continuous and Discrete Text Diffusion with Non-simultaneous Diffusion Processes",
    "authors": [
      "Bocheng Li",
      "Zhujin Gao",
      "Linli Xu"
    ],
    "abstract": "Diffusion models have emerged as a promising approach for text generation,\nwith recent works falling into two main categories: discrete and continuous\ndiffusion models. Discrete diffusion models apply token corruption\nindependently using categorical distributions, allowing for different diffusion\nprogress across tokens but lacking fine-grained control. Continuous diffusion\nmodels map tokens to continuous spaces and apply fine-grained noise, but the\ndiffusion progress is uniform across tokens, limiting their ability to capture\nsemantic nuances. To address these limitations, we propose\n\\textbf{\\underline{N}}on-simultan\\textbf{\\underline{e}}ous\nC\\textbf{\\underline{o}}ntinuous \\textbf{\\underline{Diff}}usion Models\n(NeoDiff), a novel diffusion model that integrates the strengths of both\ndiscrete and continuous approaches. NeoDiff introduces a Poisson diffusion\nprocess for the forward process, enabling a flexible and fine-grained noising\nparadigm, and employs a time predictor for the reverse process to adaptively\nmodulate the denoising progress based on token semantics. Furthermore, NeoDiff\nutilizes an optimized schedule for inference to ensure more precise noise\ncontrol and improved performance. Our approach unifies the theories of discrete\nand continuous diffusion models, offering a more principled and effective\nframework for text generation. Experimental results on several text generation\ntasks demonstrate NeoDiff's superior performance compared to baselines of\nnon-autoregressive continuous and discrete diffusion models, iterative-based\nmethods and autoregressive diffusion-based methods. These results highlight\nNeoDiff's potential as a powerful tool for generating high-quality text and\nadvancing the field of diffusion-based text generation.",
    "pdf_url": "http://arxiv.org/pdf/2505.22165v1",
    "published": "2025-05-28T09:28:52+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.15697v1",
    "title": "DeepRTL2: A Versatile Model for RTL-Related Tasks",
    "authors": [
      "Yi Liu",
      "Hongji Zhang",
      "Yunhao Zhou",
      "Zhengyuan Shi",
      "Changran Xu",
      "Qiang Xu"
    ],
    "abstract": "The integration of large language models (LLMs) into electronic design\nautomation (EDA) has significantly advanced the field, offering transformative\nbenefits, particularly in register transfer level (RTL) code generation and\nunderstanding. While previous studies have demonstrated the efficacy of\nfine-tuning LLMs for these generation-based tasks, embedding-based tasks, which\nare equally critical to EDA workflows, have been largely overlooked. These\ntasks, including natural language code search, RTL code functionality\nequivalence checking, and performance prediction, are essential for\naccelerating and optimizing the hardware design process. To address this gap,\nwe present DeepRTL2, a family of versatile LLMs that unifies both generation-\nand embedding-based tasks related to RTL. By simultaneously tackling a broad\nrange of tasks, DeepRTL2 represents the first model to provide a comprehensive\nsolution to the diverse challenges in EDA. Through extensive experiments, we\nshow that DeepRTL2 achieves state-of-the-art performance across all evaluated\ntasks.",
    "pdf_url": "http://arxiv.org/pdf/2506.15697v1",
    "published": "2025-05-28T09:28:39+00:00",
    "categories": [
      "cs.AR",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AR"
  },
  {
    "id": "http://arxiv.org/abs/2505.22164v1",
    "title": "The dynamics of spontaneous emission",
    "authors": [
      "Marcello Baldo"
    ],
    "abstract": "The spontaneous decay of an excited atom by photon emission is one of the\nmost common and elementary physical process present in nature and in\nlaboratories. The decay is random in time with constant probability density, as\nit can be inferred by the exponential law observed experimentally. Despite the\nsimplicity of the process, in Quantum Mechanics the decay itself is considered\na law of nature which is not further analyzed or explained. However it is\nlegitimate to ask for the reason of its randomness and for the dynamics of the\natom around the decay. The decay process of an isolated atom is usually assumed\nto be instantaneous, the so called Quantum jumps. Particular experimental\narrangements can widen the duration of the transition from an excited state to\nthe ground state to a finite time. In general this is due to the quantum back\naction of the detector. The development of Quantum Optics has enormously\nenriched the possibilities to study in detail the process, and new illuminating\ninsights have been obtained, but the question is still valid and its answer is\nstill elusive. In this paper we analyze the spontaneous decay within the new\nprospect introduced by a recent model that complete standard Quantum Mechanics\nin a formalism which is able to describe the dynamics of measurement and of\nspontaneous decay. Comparison is made with more phenomenological theories, the\nQuantum Mechanics of open system and the Stochastic wave function model. In the\nnew model the stochastic photon emission by an excited atom is triggered by the\nvacuum fluctuations. It is suggested how to re-analyze three types of\nexperiments, already realized in many laboratories, in order to reveal the\npresence and the effect of these fluctuations.",
    "pdf_url": "http://arxiv.org/pdf/2505.22164v1",
    "published": "2025-05-28T09:27:03+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.22163v1",
    "title": "Condensation of a spinor field at the event horizon",
    "authors": [
      "Vladimir Dzhunushaliev",
      "Vladimir Folomeev"
    ],
    "abstract": "The physical effect of condensation of a classical spinor field at the event\nhorizon is under consideration. The corresponding solution is sought for the\nset of the Einstein-Dirac equations. It is shown that in this case there arises\na black hole with a $\\delta$-like classical spinor field concentrated at the\nevent horizon.",
    "pdf_url": "http://arxiv.org/pdf/2505.22163v1",
    "published": "2025-05-28T09:26:34+00:00",
    "categories": [
      "gr-qc"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2505.22162v1",
    "title": "Accountable, Scalable and DoS-resilient Secure Vehicular Communication",
    "authors": [
      "Hongyu Jin",
      "Panos Papadimitratos"
    ],
    "abstract": "Paramount to vehicle safety, broadcasted Cooperative Awareness Messages\n(CAMs) and Decentralized Environmental Notification Messages (DENMs) are\npseudonymously authenticated for security and privacy protection, with each\nnode needing to have all incoming messages validated within an expiration\ndeadline. This creates an asymmetry that can be easily exploited by external\nadversaries to launch a clogging Denial of Service (DoS) attack: each forged VC\nmessage forces all neighboring nodes to cryptographically validate it; at\nincreasing rates, easy to generate forged messages gradually exhaust processing\nresources and severely degrade or deny timely validation of benign CAMs/DENMs.\nThe result can be catastrophic when awareness of neighbor vehicle positions or\ncritical reports are missed. We address this problem making the standardized VC\npseudonymous authentication DoS-resilient. We propose efficient cryptographic\nconstructs, which we term message verification facilitators, to prioritize\nprocessing resources for verification of potentially valid messages among bogus\nmessages and verify multiple messages based on one signature verification. Any\nmessage acceptance is strictly based on public-key based message\nauthentication/verification for accountability, i.e., non-repudiation is not\nsacrificed, unlike symmetric key based approaches. This further enables drastic\nmisbehavior detection, also exploiting the newly introduced facilitators, based\non probabilistic signature verification and cross-checking over multiple\nfacilitators verifying the same message; while maintaining verification latency\nlow even when under attack, trading off modest communication overhead. Our\nfacilitators can also be used for efficient discovery and verification of DENM\nor any event-driven message, including misbehavior evidence used for our\nscheme.",
    "pdf_url": "http://arxiv.org/pdf/2505.22162v1",
    "published": "2025-05-28T09:25:34+00:00",
    "categories": [
      "cs.CR"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.22161v1",
    "title": "Spectral indices in active galactic nuclei as seen by Apertif and LOFAR",
    "authors": [
      "A. M. Kutkin",
      "R. Morganti",
      "T. A. Oosterloo",
      "E. A. K. Adams",
      "H. D√©nes",
      "J. van Leeuwen",
      "M. J. Norden",
      "E. Orru"
    ],
    "abstract": "We present two new radio continuum images obtained with Apertif at 1.4 GHz.\nThe images, produced with a direction-dependent calibration pipeline, cover 136\nsquare degrees of the Lockman Hole and 24 square degrees of the ELAIS-N fields,\nwith an average resolution of 17x12\" and residual noise of 33 uJy/beam. With\nthe improved depth of the images we found in total 63692 radio sources, many of\nwhich are detected for the first time at this frequency. With the addition of\nthe previously published Apertif catalog for the Bootes field, we cross-match\nwith the LOFAR deep-fields value-added catalogs at 150 MHz, resulting in a\nhomogeneous sample of 10196 common sources with spectral index estimates, one\nof the largest to date. We analyze and discuss the correlations between\nspectral index, redshift, linear sources size, and radio luminosity, taking\ninto account biases of flux-density-limited surveys. Our results suggest that\nthe observed correlation between spectral index and redshift of active galactic\nnuclei can be attributed to the Malmquist bias reflecting an intrinsic relation\nbetween radio luminosity and the spectral index. We also find a correlation\nbetween spectral index and linear source size with more compact sources having\nsteeper spectra.",
    "pdf_url": "http://arxiv.org/pdf/2505.22161v1",
    "published": "2025-05-28T09:24:58+00:00",
    "categories": [
      "astro-ph.GA",
      "astro-ph.CO"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2505.22160v1",
    "title": "Eternalism and Everettian Quantum Mechanics",
    "authors": [
      "Matias Slavov"
    ],
    "abstract": "This paper shall explore the conjunction of eternalism and Everettian quantum\nmechanics. It shall be argued that there is a strong analogy between these two\nviews. In case there is an indefinite number of worlds and observers that are\nall equally real, there should be an indefinite number of local times which are\nall also equally real. Whereas Everettianism, specifically the diverging\nversion, treats actuality indexically, relativistic eternalism treats tense\nindexically. All times exist analogously to all isolated Everettian worlds.\nThere is no unique 'now' that cuts throughout all that physically exists.\nInstead, as eternalism propounds, all times exist. The paper concludes that\neternalism and the many-worlds interpretation are not only compatible but\ncomplement each other, providing a coherent framework for understanding the\nnature of temporal reality.",
    "pdf_url": "http://arxiv.org/pdf/2505.22160v1",
    "published": "2025-05-28T09:24:50+00:00",
    "categories": [
      "physics.hist-ph"
    ],
    "primary_category": "physics.hist-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.22159v1",
    "title": "ForceVLA: Enhancing VLA Models with a Force-aware MoE for Contact-rich Manipulation",
    "authors": [
      "Jiawen Yu",
      "Hairuo Liu",
      "Qiaojun Yu",
      "Jieji Ren",
      "Ce Hao",
      "Haitong Ding",
      "Guangyu Huang",
      "Guofan Huang",
      "Yan Song",
      "Panpan Cai",
      "Cewu Lu",
      "Wenqiang Zhang"
    ],
    "abstract": "Vision-Language-Action (VLA) models have advanced general-purpose robotic\nmanipulation by leveraging pretrained visual and linguistic representations.\nHowever, they struggle with contact-rich tasks that require fine-grained\ncontrol involving force, especially under visual occlusion or dynamic\nuncertainty. To address these limitations, we propose \\textbf{ForceVLA}, a\nnovel end-to-end manipulation framework that treats external force sensing as a\nfirst-class modality within VLA systems. ForceVLA introduces \\textbf{FVLMoE}, a\nforce-aware Mixture-of-Experts fusion module that dynamically integrates\npretrained visual-language embeddings with real-time 6-axis force feedback\nduring action decoding. This enables context-aware routing across\nmodality-specific experts, enhancing the robot's ability to adapt to subtle\ncontact dynamics. We also introduce \\textbf{ForceVLA-Data}, a new dataset\ncomprising synchronized vision, proprioception, and force-torque signals across\nfive contact-rich manipulation tasks. ForceVLA improves average task success by\n23.2\\% over strong $\\pi_0$-based baselines, achieving up to 80\\% success in\ntasks such as plug insertion. Our approach highlights the importance of\nmultimodal integration for dexterous manipulation and sets a new benchmark for\nphysically intelligent robotic control. Code and data will be released at\nhttps://sites.google.com/view/forcevla2025.",
    "pdf_url": "http://arxiv.org/pdf/2505.22159v1",
    "published": "2025-05-28T09:24:25+00:00",
    "categories": [
      "cs.RO",
      "cs.CV"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.22158v1",
    "title": "The informativeness of the gradient revisited",
    "authors": [
      "Rustem Takhanov"
    ],
    "abstract": "In the past decade gradient-based deep learning has revolutionized several\napplications. However, this rapid advancement has highlighted the need for a\ndeeper theoretical understanding of its limitations. Research has shown that,\nin many practical learning tasks, the information contained in the gradient is\nso minimal that gradient-based methods require an exceedingly large number of\niterations to achieve success. The informativeness of the gradient is typically\nmeasured by its variance with respect to the random selection of a target\nfunction from a hypothesis class.\n  We use this framework and give a general bound on the variance in terms of a\nparameter related to the pairwise independence of the target function class and\nthe collision entropy of the input distribution. Our bound scales as $\n\\tilde{\\mathcal{O}}(\\varepsilon+e^{-\\frac{1}{2}\\mathcal{E}_c}) $, where $\n\\tilde{\\mathcal{O}} $ hides factors related to the regularity of the learning\nmodel and the loss function, $ \\varepsilon $ measures the pairwise independence\nof the target function class and $\\mathcal{E}_c$ is the collision entropy of\nthe input distribution.\n  To demonstrate the practical utility of our bound, we apply it to the class\nof Learning with Errors (LWE) mappings and high-frequency functions. In\naddition to the theoretical analysis, we present experiments to understand\nbetter the nature of recent deep learning-based attacks on LWE.",
    "pdf_url": "http://arxiv.org/pdf/2505.22158v1",
    "published": "2025-05-28T09:23:37+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.22157v1",
    "title": "Stratified Selective Sampling for Instruction Tuning with Dedicated Scoring Strategy",
    "authors": [
      "Paramita Mirza",
      "Lucas Weber",
      "Fabian K√ºch"
    ],
    "abstract": "Recent work shows that post-training datasets for LLMs can be substantially\ndownsampled without noticeably deteriorating performance. However, data\nselection often incurs high computational costs or is limited to narrow\ndomains. In this paper, we demonstrate that data selection can be both --\nefficient and universal -- by using a multi-step pipeline in which we\nefficiently bin data points into groups, estimate quality using specialized\nmodels, and score difficulty with a robust, lightweight method. Task-based\ncategorization allows us to control the composition of our final data --\ncrucial for finetuning multi-purpose models. To guarantee diversity, we improve\nupon previous work using embedding models and a clustering algorithm. This\nintegrated strategy enables high-performance fine-tuning with minimal overhead.",
    "pdf_url": "http://arxiv.org/pdf/2505.22157v1",
    "published": "2025-05-28T09:22:25+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.22156v1",
    "title": "InComeS: Integrating Compression and Selection Mechanisms into LLMs for Efficient Model Editing",
    "authors": [
      "Shuaiyi Li",
      "Zhisong Zhang",
      "Yang Deng",
      "Chenlong Deng",
      "Tianqing Fang",
      "Hongming Zhang",
      "Haitao Mi",
      "Dong Yu",
      "Wai Lam"
    ],
    "abstract": "Although existing model editing methods perform well in recalling exact edit\nfacts, they often struggle in complex scenarios that require deeper semantic\nunderstanding rather than mere knowledge regurgitation. Leveraging the strong\ncontextual reasoning abilities of large language models (LLMs), in-context\nlearning (ICL) becomes a promising editing method by comprehending edit\ninformation through context encoding. However, this method is constrained by\nthe limited context window of LLMs, leading to degraded performance and\nefficiency as the number of edits increases. To overcome this limitation, we\npropose InComeS, a flexible framework that enhances LLMs' ability to process\nediting contexts through explicit compression and selection mechanisms.\nSpecifically, InComeS compresses each editing context into the key-value (KV)\ncache of a special gist token, enabling efficient handling of multiple edits\nwithout being restricted by the model's context window. Furthermore,\nspecialized cross-attention modules are added to dynamically select the most\nrelevant information from the gist pools, enabling adaptive and effective\nutilization of edit information. We conduct experiments on diverse model\nediting benchmarks with various editing formats, and the results demonstrate\nthe effectiveness and efficiency of our method.",
    "pdf_url": "http://arxiv.org/pdf/2505.22156v1",
    "published": "2025-05-28T09:20:18+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.22155v1",
    "title": "An instance of FreeCHR with refined operational semantics",
    "authors": [
      "Sascha Rechenberger",
      "Thom Fr√ºhwirth"
    ],
    "abstract": "Constraint Handling Rules (CHR) is a rule-based programming language which is\ntypically embedded into a general-purpose language. There exists a plethora of\nimplementations of CHR for numerous host languages. However, the existing\nimplementations often reinvent the way to embed CHR, which impedes maintenance\nand weakens assertions of correctness. To formalize and thereby unify the\nembedding of CHR into arbitrary host languages, we introduced the framework\nFreeCHR and proved it to be a valid representation of classical CHR. Until now,\nthis framework only includes a translation of the very abstract operational\nsemantics of CHR which, due to its abstract nature, introduces several\npractical issues. In this paper, we introduce an execution algorithm for\nFreeCHR. We derive it from the refined operational semantics of CHR, which\nresolve the issues introduced by the very abstract semantics. We also prove\nsoundness of the algorithm with respect to the very abstract semantics of\nFreeCHR. Hereby we provide a unified and an easy to implement guideline for new\nCHR implementations, as well as an algorithmic definition of the refined\noperational semantics.",
    "pdf_url": "http://arxiv.org/pdf/2505.22155v1",
    "published": "2025-05-28T09:19:33+00:00",
    "categories": [
      "cs.PL"
    ],
    "primary_category": "cs.PL"
  },
  {
    "id": "http://arxiv.org/abs/2505.22154v1",
    "title": "Learning A Robust RGB-Thermal Detector for Extreme Modality Imbalance",
    "authors": [
      "Chao Tian",
      "Chao Yang",
      "Guoqing Zhu",
      "Qiang Wang",
      "Zhenyu He"
    ],
    "abstract": "RGB-Thermal (RGB-T) object detection utilizes thermal infrared (TIR) images\nto complement RGB data, improving robustness in challenging conditions.\nTraditional RGB-T detectors assume balanced training data, where both\nmodalities contribute equally. However, in real-world scenarios, modality\ndegradation-due to environmental factors or technical issues-can lead to\nextreme modality imbalance, causing out-of-distribution (OOD) issues during\ntesting and disrupting model convergence during training. This paper addresses\nthese challenges by proposing a novel base-and-auxiliary detector architecture.\nWe introduce a modality interaction module to adaptively weigh modalities based\non their quality and handle imbalanced samples effectively. Additionally, we\nleverage modality pseudo-degradation to simulate real-world imbalances in\ntraining data. The base detector, trained on high-quality pairs, provides a\nconsistency constraint for the auxiliary detector, which receives degraded\nsamples. This framework enhances model robustness, ensuring reliable\nperformance even under severe modality degradation. Experimental results\ndemonstrate the effectiveness of our method in handling extreme modality\nimbalances~(decreasing the Missing Rate by 55%) and improving performance\nacross various baseline detectors.",
    "pdf_url": "http://arxiv.org/pdf/2505.22154v1",
    "published": "2025-05-28T09:18:55+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.22153v2",
    "title": "Personalized Tree-Based Progressive Regression Model for Watch-Time Prediction in Short Video Recommendation",
    "authors": [
      "Xiaokai Chen",
      "Xiao Lin",
      "Changcheng Li",
      "Peng Jiang"
    ],
    "abstract": "In online video platforms, accurate watch time prediction has become a\nfundamental and challenging problem in video recommendation. Previous research\nhas revealed that the accuracy of watch time prediction highly depends on both\nthe transformation of watch-time labels and the decomposition of the estimation\nprocess. TPM (Tree based Progressive Regression Model) achieves\nState-of-the-Art performance with a carefully designed and effective\ndecomposition paradigm. TPM discretizes the watch time into several ordinal\nintervals and organizes them into a binary decision tree, where each node\ncorresponds to a specific interval. At each non-leaf node, a binary classifier\nis used to determine the specific interval in which the watch time variable\nmost likely falls, based on the prediction outcome at its parent node.\n  The tree structure is central to TPM, as it defines the decomposition of\nwatch time estimation and how ordinal intervals are discretized. However, TPM\nuses a predefined full binary tree, which may be sub-optimal for two reasons.\nFirst, full binary trees imply equal partitioning of the watch time space,\nwhich may fail to capture the complexity of real-world distributions. Second,\nrather than relying on a fixed global structure, we advocate for a\npersonalized, data-driven tree that can be learned end-to-end. Thus, we propose\nPTPM to enable highly personalized decomposition of watch estimation with\nbetter efficacy and efficiency. Moreover, we show that TPM suffers from\nselection bias due to conditional modeling and propose a simple solution. We\nconduct extensive experiments on offline datasets and online environments.\nOffline results show improved watch time accuracy, and online A/B tests further\nvalidate the effectiveness of our framework. PTPM has been fully deployed in\ncore traffic scenarios and now serves over 400 million users daily.",
    "pdf_url": "http://arxiv.org/pdf/2505.22153v2",
    "published": "2025-05-28T09:18:48+00:00",
    "categories": [
      "cs.IR"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2505.22152v1",
    "title": "Uncertainty Estimation for Heterophilic Graphs Through the Lens of Information Theory",
    "authors": [
      "Dominik Fuchsgruber",
      "Tom Wollschl√§ger",
      "Johannes Bordne",
      "Stephan G√ºnnemann"
    ],
    "abstract": "While uncertainty estimation for graphs recently gained traction, most\nmethods rely on homophily and deteriorate in heterophilic settings. We address\nthis by analyzing message passing neural networks from an information-theoretic\nperspective and developing a suitable analog to data processing inequality to\nquantify information throughout the model's layers. In contrast to non-graph\ndomains, information about the node-level prediction target can increase with\nmodel depth if a node's features are semantically different from its neighbors.\nTherefore, on heterophilic graphs, the latent embeddings of an MPNN each\nprovide different information about the data distribution - different from\nhomophilic settings. This reveals that considering all node representations\nsimultaneously is a key design principle for epistemic uncertainty estimation\non graphs beyond homophily. We empirically confirm this with a simple post-hoc\ndensity estimator on the joint node embedding space that provides\nstate-of-the-art uncertainty on heterophilic graphs. At the same time, it\nmatches prior work on homophilic graphs without explicitly exploiting homophily\nthrough post-processing.",
    "pdf_url": "http://arxiv.org/pdf/2505.22152v1",
    "published": "2025-05-28T09:18:01+00:00",
    "categories": [
      "cs.LG",
      "cs.SI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.22151v1",
    "title": "Oryx: a Performant and Scalable Algorithm for Many-Agent Coordination in Offline MARL",
    "authors": [
      "Claude Formanek",
      "Omayma Mahjoub",
      "Louay Ben Nessir",
      "Sasha Abramowitz",
      "Ruan de Kock",
      "Wiem Khlifi",
      "Simon Du Toit",
      "Felix Chalumeau",
      "Daniel Rajaonarivonivelomanantsoa",
      "Arnol Fokam",
      "Siddarth Singh",
      "Ulrich Mbou Sob",
      "Arnu Pretorius"
    ],
    "abstract": "A key challenge in offline multi-agent reinforcement learning (MARL) is\nachieving effective many-agent multi-step coordination in complex environments.\nIn this work, we propose Oryx, a novel algorithm for offline cooperative MARL\nto directly address this challenge. Oryx adapts the recently proposed\nretention-based architecture Sable and combines it with a sequential form of\nimplicit constraint Q-learning (ICQ), to develop a novel offline\nauto-regressive policy update scheme. This allows Oryx to solve complex\ncoordination challenges while maintaining temporal coherence over lengthy\ntrajectories. We evaluate Oryx across a diverse set of benchmarks from prior\nworks (SMAC, RWARE, and Multi-Agent MuJoCo) covering tasks of both discrete and\ncontinuous control, varying in scale and difficulty. Oryx achieves\nstate-of-the-art performance on more than 80% of the 65 tested datasets,\noutperforming prior offline MARL methods and demonstrating robust\ngeneralisation across domains with many agents and long horizons. Finally, we\nintroduce new datasets to push the limits of many-agent coordination in offline\nMARL, and demonstrate Oryx's superior ability to scale effectively in such\nsettings. We will make all of our datasets, experimental data, and code\navailable upon publication.",
    "pdf_url": "http://arxiv.org/pdf/2505.22151v1",
    "published": "2025-05-28T09:17:44+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.22150v2",
    "title": "Improving Brain-to-Image Reconstruction via Fine-Grained Text Bridging",
    "authors": [
      "Runze Xia",
      "Shuo Feng",
      "Renzhi Wang",
      "Congchi Yin",
      "Xuyun Wen",
      "Piji Li"
    ],
    "abstract": "Brain-to-Image reconstruction aims to recover visual stimuli perceived by\nhumans from brain activity. However, the reconstructed visual stimuli often\nmissing details and semantic inconsistencies, which may be attributed to\ninsufficient semantic information. To address this issue, we propose an\napproach named Fine-grained Brain-to-Image reconstruction (FgB2I), which\nemploys fine-grained text as bridge to improve image reconstruction. FgB2I\ncomprises three key stages: detail enhancement, decoding fine-grained text\ndescriptions, and text-bridged brain-to-image reconstruction. In the\ndetail-enhancement stage, we leverage large vision-language models to generate\nfine-grained captions for visual stimuli and experimentally validate its\nimportance. We propose three reward metrics (object accuracy, text-image\nsemantic similarity, and image-image semantic similarity) to guide the language\nmodel in decoding fine-grained text descriptions from fMRI signals. The\nfine-grained text descriptions can be integrated into existing reconstruction\nmethods to achieve fine-grained Brain-to-Image reconstruction.",
    "pdf_url": "http://arxiv.org/pdf/2505.22150v2",
    "published": "2025-05-28T09:16:44+00:00",
    "categories": [
      "cs.CV",
      "cs.CL"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.22149v1",
    "title": "Real-World Modeling of Computation Offloading for Neural Networks with Early Exits and Splits",
    "authors": [
      "Jan Danek",
      "Zdenek Becvar",
      "Adam Janes"
    ],
    "abstract": "We focus on computation offloading of applications based on convolutional\nneural network (CNN) from moving devices, such as mobile robots or autonomous\nvehicles, to MultiAccess Edge Computing (MEC) servers via a mobile network. In\norder to reduce overall CNN inference time, we design and implement CNN with\nearly exits and splits, allowing a flexible partial or full offloading of CNN\ninference. Through real-world experiments, we analyze an impact of the CNN\ninference offloading on the total CNN processing delay, energy consumption, and\nclassification accuracy in a practical road sign recognition task. The results\nconfirm that offloading of CNN with early exits and splits can significantly\nreduce both total processing delay and energy consumption compared to full\nlocal processing while not impairing classification accuracy. Based on the\nresults of real-world experiments, we derive practical models for energy\nconsumption and total processing delay related to offloading of CNN with early\nexits and splits.",
    "pdf_url": "http://arxiv.org/pdf/2505.22149v1",
    "published": "2025-05-28T09:16:13+00:00",
    "categories": [
      "cs.NI",
      "eess.SP"
    ],
    "primary_category": "cs.NI"
  },
  {
    "id": "http://arxiv.org/abs/2506.05368v1",
    "title": "Speaking images. A novel framework for the automated self-description of artworks",
    "authors": [
      "Valentine Bernasconi",
      "Gustavo Marfia"
    ],
    "abstract": "Recent breakthroughs in generative AI have opened the door to new research\nperspectives in the domain of art and cultural heritage, where a large number\nof artifacts have been digitized. There is a need for innovation to ease the\naccess and highlight the content of digital collections. Such innovations\ndevelop into creative explorations of the digital image in relation to its\nmalleability and contemporary interpretation, in confrontation to the original\nhistorical object. Based on the concept of the autonomous image, we propose a\nnew framework towards the production of self-explaining cultural artifacts\nusing open-source large-language, face detection, text-to-speech and\naudio-to-animation models. The goal is to start from a digitized artwork and to\nautomatically assemble a short video of the latter where the main character\nanimates to explain its content. The whole process questions cultural biases\nencapsulated in large-language models, the potential of digital images and\ndeepfakes of artworks for educational purposes, along with concerns of the\nfield of art history regarding such creative diversions.",
    "pdf_url": "http://arxiv.org/pdf/2506.05368v1",
    "published": "2025-05-28T09:13:41+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.22148v1",
    "title": "What Makes a Good Reasoning Chain? Uncovering Structural Patterns in Long Chain-of-Thought Reasoning",
    "authors": [
      "Gangwei Jiang",
      "Yahui Liu",
      "Zhaoyi Li",
      "Qi Wang",
      "Fuzheng Zhang",
      "Linqi Song",
      "Ying Wei",
      "Defu Lian"
    ],
    "abstract": "Recent advances in reasoning with large language models (LLMs) have\npopularized Long Chain-of-Thought (LCoT), a strategy that encourages deliberate\nand step-by-step reasoning before producing a final answer. While LCoTs have\nenabled expert-level performance in complex tasks, how the internal structures\nof their reasoning chains drive, or even predict, the correctness of final\nanswers remains a critical yet underexplored question. In this work, we present\nLCoT2Tree, an automated framework that converts sequential LCoTs into\nhierarchical tree structures and thus enables deeper structural analysis of LLM\nreasoning. Using graph neural networks (GNNs), we reveal that structural\npatterns extracted by LCoT2Tree, including exploration, backtracking, and\nverification, serve as stronger predictors of final performance across a wide\nrange of tasks and models. Leveraging an explainability technique, we further\nidentify critical thought patterns such as over-branching that account for\nfailures. Beyond diagnostic insights, the structural patterns by LCoT2Tree\nsupport practical applications, including improving Best-of-N decoding\neffectiveness. Overall, our results underscore the critical role of internal\nstructures of reasoning chains, positioning LCoT2Tree as a powerful tool for\ndiagnosing, interpreting, and improving reasoning in LLMs.",
    "pdf_url": "http://arxiv.org/pdf/2505.22148v1",
    "published": "2025-05-28T09:12:31+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.22147v1",
    "title": "Lifted Forward Planning in Relational Factored Markov Decision Processes with Concurrent Actions",
    "authors": [
      "Florian Andreas Marwitz",
      "Tanya Braun",
      "Ralf M√∂ller",
      "Marcel Gehrke"
    ],
    "abstract": "Decision making is a central problem in AI that can be formalized using a\nMarkov Decision Process. A problem is that, with increasing numbers of\n(indistinguishable) objects, the state space grows exponentially. To compute\npolicies, the state space has to be enumerated. Even more possibilities have to\nbe enumerated if the size of the action space depends on the size of the state\nspace, especially if we allow concurrent actions. To tackle the exponential\nblow-up in the action and state space, we present a first-order representation\nto store the spaces in polynomial instead of exponential size in the number of\nobjects and introduce Foreplan, a relational forward planner, which uses this\nrepresentation to efficiently compute policies for numerous indistinguishable\nobjects and actions. Additionally, we introduce an even faster approximate\nversion of Foreplan. Moreover, Foreplan identifies how many objects an agent\nshould act on to achieve a certain task given restrictions. Further, we provide\na theoretical analysis and an empirical evaluation of Foreplan, demonstrating a\nspeedup of at least four orders of magnitude.",
    "pdf_url": "http://arxiv.org/pdf/2505.22147v1",
    "published": "2025-05-28T09:08:27+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.22146v4",
    "title": "Flexible Tool Selection through Low-dimensional Attribute Alignment of Vision and Language",
    "authors": [
      "Guangfu Hao",
      "Haojie Wen",
      "Liangxuan Guo",
      "Yang Chen",
      "Yanchao Bi",
      "Shan Yu"
    ],
    "abstract": "Flexible tool selection reflects a complex cognitive ability that\ndistinguishes humans from other species, yet computational models that capture\nthis ability remain underdeveloped. We developed a framework using\nlow-dimensional attribute representations to bridge visual tool perception and\nlinguistic task understanding. We constructed a comprehensive dataset (ToolNet)\ncontaining 115 common tools labeled with 13 carefully designed attributes\nspanning physical, functional, and psychological properties, paired with\nnatural language scenarios describing tool usage. Visual encoders (ResNet or\nViT) extract attributes from tool images while fine-tuned language models\n(GPT-2, LLaMA, DeepSeek) derive required attributes from task descriptions. Our\napproach achieves 74% accuracy in tool selection tasks-significantly\noutperforming direct tool matching (20%) and smaller multimodal models\n(21%-58%), while approaching performance of much larger models like GPT-4o\n(73%) with substantially fewer parameters. Human evaluation studies validate\nour framework's alignment with human decision-making patterns, and\ngeneralization experiments demonstrate effective performance on novel tool\ncategories. Ablation studies revealed that manipulation-related attributes\n(graspability, elongation, hand-relatedness) consistently prove most critical\nacross modalities. This work provides a parameter-efficient, interpretable\nsolution that mimics human-like tool cognition, advancing both cognitive\nscience understanding and practical applications in tool selection tasks.",
    "pdf_url": "http://arxiv.org/pdf/2505.22146v4",
    "published": "2025-05-28T09:06:04+00:00",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "q-bio.NC"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.22145v1",
    "title": "Discrete stochastic maximal regularity",
    "authors": [
      "Foivos Evangelopoulos-Ntemiris",
      "Mark Veraar"
    ],
    "abstract": "In this paper, we investigate discrete regularity estimates for a broad class\nof temporal numerical schemes for parabolic stochastic evolution equations. We\nprovide a characterization of discrete stochastic maximal $\\ell^p$-regularity\nin terms of its continuous counterpart, thereby establishing a unified\nframework that yields numerous new discrete regularity results. Moreover, as a\nconsequence of the continuous-time theory, we establish several important\nproperties of discrete stochastic maximal regularity such as extrapolation in\nthe exponent $p$ and with respect to a power weight. Furthermore, employing the\n$H^\\infty$-functional calculus, we derive a powerful discrete maximal estimate\nin the trace space norm $D_A(1-\\frac1p,p)$ for $p \\in [2,\\infty)$.",
    "pdf_url": "http://arxiv.org/pdf/2505.22145v1",
    "published": "2025-05-28T09:05:15+00:00",
    "categories": [
      "math.AP",
      "cs.NA",
      "math.FA",
      "math.NA",
      "math.PR",
      "Primary: 46N40, 60H15, Secondary: 35B65, 42B37, 47D06, 60H35, 65J10,\n  65M12"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2505.22144v2",
    "title": "Fractional Quantum Hall Anyons via the Algebraic Topology of Exotic Flux Quanta",
    "authors": [
      "Hisham Sati",
      "Urs Schreiber"
    ],
    "abstract": "Fractional quantum Hall systems (FQH), due to their experimentally observed\nanyonic topological order, are a main contender for future\nhardware-implementation of error-protected quantum registers (\"topological\nqbits\") subject to error-protected quantum operations (\"topological quantum\ngates\"), both plausibly necessary for future quantum computing at useful scale,\nbut both remaining insufficiently understood. Here we present a novel\nnon-Lagrangian effective description of FQH anyons, based on previously elusive\nproper global quantization of effective topological flux in extraordinary\nnon-abelian cohomology theories. This directly translates the system's quantum\n-observables, -states, -symmetries, and -measurement channels into purely\nalgebro-topological analysis of local systems of Hilbert spaces over the\nquantized flux moduli spaces. Under the hypothesis -- for which we provide a\nfair bit of evidence -- that the appropriate effective flux quantization of FQH\nsystems is in 2-Cohomotopy theory (a cousin of Hypothesis H in high-energy\nphysics), the results here are rigorously derived and as such might usefully\ninform laboratory searches for novel anyonic phenomena in FQH systems and hence\nfor topological quantum hardware.",
    "pdf_url": "http://arxiv.org/pdf/2505.22144v2",
    "published": "2025-05-28T09:05:14+00:00",
    "categories": [
      "cond-mat.mes-hall",
      "cond-mat.str-el",
      "hep-th",
      "math-ph",
      "math.AT",
      "math.MP"
    ],
    "primary_category": "cond-mat.mes-hall"
  },
  {
    "id": "http://arxiv.org/abs/2505.22143v1",
    "title": "3D Question Answering via only 2D Vision-Language Models",
    "authors": [
      "Fengyun Wang",
      "Sicheng Yu",
      "Jiawei Wu",
      "Jinhui Tang",
      "Hanwang Zhang",
      "Qianru Sun"
    ],
    "abstract": "Large vision-language models (LVLMs) have significantly advanced numerous\nfields. In this work, we explore how to harness their potential to address 3D\nscene understanding tasks, using 3D question answering (3D-QA) as a\nrepresentative example. Due to the limited training data in 3D, we do not train\nLVLMs but infer in a zero-shot manner. Specifically, we sample 2D views from a\n3D point cloud and feed them into 2D models to answer a given question. When\nthe 2D model is chosen, e.g., LLAVA-OV, the quality of sampled views matters\nthe most. We propose cdViews, a novel approach to automatically selecting\ncritical and diverse Views for 3D-QA. cdViews consists of two key components:\nviewSelector prioritizing critical views based on their potential to provide\nanswer-specific information, and viewNMS enhancing diversity by removing\nredundant views based on spatial overlap. We evaluate cdViews on the\nwidely-used ScanQA and SQA benchmarks, demonstrating that it achieves\nstate-of-the-art performance in 3D-QA while relying solely on 2D models without\nfine-tuning. These findings support our belief that 2D LVLMs are currently the\nmost effective alternative (of the resource-intensive 3D LVLMs) for addressing\n3D tasks.",
    "pdf_url": "http://arxiv.org/pdf/2505.22143v1",
    "published": "2025-05-28T09:04:39+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.22142v2",
    "title": "Interpolation of Quantum Polar Codes and Quantum Reed-Muller Codes",
    "authors": [
      "Keita Hidaka",
      "Dina Abdelhadi",
      "Ruediger Urbanke"
    ],
    "abstract": "Good quantum error-correcting codes that fulfill practical considerations,\nsuch as simple encoding circuits and efficient decoders, are essential for\nfunctional quantum information processing systems. Quantum polar codes satisfy\nsome of these requirements but lack certain critical features, thereby\nhindering their widespread use. Existing constructions either require\nentanglement assistance to produce valid quantum codes, suffer from poor\nfinite-size performance, or fail to tailor polar codes to the underlying\nchannel properties. Meanwhile, quantum Reed-Muller (RM) codes demonstrate\nstrong performance, though no known efficient decoding algorithm exists for\nthem. In this work, we propose strategies to interpolate between quantum polar\ncodes and quantum RM codes, thus addressing the challenges of designing valid\nquantum polar codes without entanglement assistance and improving finite-size\ncode performance.",
    "pdf_url": "http://arxiv.org/pdf/2505.22142v2",
    "published": "2025-05-28T09:04:02+00:00",
    "categories": [
      "quant-ph",
      "cs.IT",
      "math.IT"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.22141v2",
    "title": "FaceEditTalker: Controllable Talking Head Generation with Facial Attribute Editing",
    "authors": [
      "Guanwen Feng",
      "Zhiyuan Ma",
      "Yunan Li",
      "Jiahao Yang",
      "Junwei Jing",
      "Qiguang Miao"
    ],
    "abstract": "Recent advances in audio-driven talking head generation have achieved\nimpressive results in lip synchronization and emotional expression. However,\nthey largely overlook the crucial task of facial attribute editing. This\ncapability is indispensable for achieving deep personalization and expanding\nthe range of practical applications, including user-tailored digital avatars,\nengaging online education content, and brand-specific digital customer service.\nIn these key domains, flexible adjustment of visual attributes, such as\nhairstyle, accessories, and subtle facial features, is essential for aligning\nwith user preferences, reflecting diverse brand identities and adapting to\nvarying contextual demands. In this paper, we present FaceEditTalker, a unified\nframework that enables controllable facial attribute manipulation while\ngenerating high-quality, audio-synchronized talking head videos. Our method\nconsists of two key components: an image feature space editing module, which\nextracts semantic and detail features and allows flexible control over\nattributes like expression, hairstyle, and accessories; and an audio-driven\nvideo generation module, which fuses these edited features with audio-guided\nfacial landmarks to drive a diffusion-based generator. This design ensures\ntemporal coherence, visual fidelity, and identity preservation across frames.\nExtensive experiments on public datasets demonstrate that our method achieves\ncomparable or superior performance to representative baseline methods in\nlip-sync accuracy, video quality, and attribute controllability. Project page:\nhttps://peterfanfan.github.io/FaceEditTalker/",
    "pdf_url": "http://arxiv.org/pdf/2505.22141v2",
    "published": "2025-05-28T09:04:00+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.22140v1",
    "title": "Search for a dark baryon in the $Œû^-\\rightarrowœÄ^-+{\\rm invisible}$ decay",
    "authors": [
      "BESIII Collaboration",
      "M. Ablikim",
      "M. N. Achasov",
      "P. Adlarson",
      "X. C. Ai",
      "R. Aliberti",
      "A. Amoroso",
      "Q. An",
      "Y. Bai",
      "O. Bakina",
      "Y. Ban",
      "H. -R. Bao",
      "V. Batozskaya",
      "K. Begzsuren",
      "N. Berger",
      "M. Berlowski",
      "M. Bertani",
      "D. Bettoni",
      "F. Bianchi",
      "E. Bianco",
      "A. Bortone",
      "I. Boyko",
      "R. A. Briere",
      "A. Brueggemann",
      "H. Cai",
      "M. H. Cai",
      "X. Cai",
      "A. Calcaterra",
      "G. F. Cao",
      "N. Cao",
      "S. A. Cetin",
      "X. Y. Chai",
      "J. F. Chang",
      "G. R. Che",
      "Y. Z. Che",
      "C. H. Chen",
      "Chao Chen",
      "G. Chen",
      "H. S. Chen",
      "H. Y. Chen",
      "M. L. Chen",
      "S. J. Chen",
      "S. L. Chen",
      "S. M. Chen",
      "T. Chen",
      "X. R. Chen",
      "X. T. Chen",
      "X. Y. Chen",
      "Y. B. Chen",
      "Y. Q. Chen",
      "Y. Q. Chen",
      "Z. Chen",
      "Z. J. Chen",
      "Z. K. Chen",
      "S. K. Choi",
      "X. Chu",
      "G. Cibinetto",
      "F. Cossio",
      "J. Cottee-Meldrum",
      "J. J. Cui",
      "H. L. Dai",
      "J. P. Dai",
      "A. Dbeyssi",
      "R. E. de Boer",
      "D. Dedovich",
      "C. Q. Deng",
      "Z. Y. Deng",
      "A. Denig",
      "I. Denysenko",
      "M. Destefanis",
      "F. De Mori",
      "B. Ding",
      "X. X. Ding",
      "Y. Ding",
      "Y. Ding",
      "Y. X. Ding",
      "J. Dong",
      "L. Y. Dong",
      "M. Y. Dong",
      "X. Dong",
      "M. C. Du",
      "S. X. Du",
      "S. X. Du",
      "Y. Y. Duan",
      "P. Egorov",
      "G. F. Fan",
      "J. J. Fan",
      "Y. H. Fan",
      "J. Fang",
      "J. Fang",
      "S. S. Fang",
      "W. X. Fang",
      "Y. Q. Fang",
      "R. Farinelli",
      "L. Fava",
      "F. Feldbauer",
      "G. Felici",
      "C. Q. Feng",
      "J. H. Feng",
      "L. Feng",
      "Q. X. Feng",
      "Y. T. Feng",
      "M. Fritsch",
      "C. D. Fu",
      "J. L. Fu",
      "Y. W. Fu",
      "H. Gao",
      "X. B. Gao",
      "Y. Gao",
      "Y. N. Gao",
      "Y. N. Gao",
      "Y. Y. Gao",
      "S. Garbolino",
      "I. Garzia",
      "P. T. Ge",
      "Z. W. Ge",
      "C. Geng",
      "E. M. Gersabeck",
      "A. Gilman",
      "K. Goetzen",
      "J. D. Gong",
      "L. Gong",
      "W. X. Gong",
      "W. Gradl",
      "S. Gramigna",
      "M. Greco",
      "M. H. Gu",
      "Y. T. Gu",
      "C. Y. Guan",
      "A. Q. Guo",
      "L. B. Guo",
      "M. J. Guo",
      "R. P. Guo",
      "Y. P. Guo",
      "A. Guskov",
      "J. Gutierrez",
      "K. L. Han",
      "T. T. Han",
      "F. Hanisch",
      "K. D. Hao",
      "X. Q. Hao",
      "F. A. Harris",
      "K. K. He",
      "K. L. He",
      "F. H. Heinsius",
      "C. H. Heinz",
      "Y. K. Heng",
      "C. Herold",
      "P. C. Hong",
      "G. Y. Hou",
      "X. T. Hou",
      "Y. R. Hou",
      "Z. L. Hou",
      "H. M. Hu",
      "J. F. Hu",
      "Q. P. Hu",
      "S. L. Hu",
      "T. Hu",
      "Y. Hu",
      "Z. M. Hu",
      "G. S. Huang",
      "K. X. Huang",
      "L. Q. Huang",
      "P. Huang",
      "X. T. Huang",
      "Y. P. Huang",
      "Y. S. Huang",
      "T. Hussain",
      "N. H√ºsken",
      "N. in der Wiesche",
      "J. Jackson",
      "Q. Ji",
      "Q. P. Ji",
      "W. Ji",
      "X. B. Ji",
      "X. L. Ji",
      "Y. Y. Ji",
      "Z. K. Jia",
      "D. Jiang",
      "H. B. Jiang",
      "P. C. Jiang",
      "S. J. Jiang",
      "T. J. Jiang",
      "X. S. Jiang",
      "Y. Jiang",
      "J. B. Jiao",
      "J. K. Jiao",
      "Z. Jiao",
      "S. Jin",
      "Y. Jin",
      "M. Q. Jing",
      "X. M. Jing",
      "T. Johansson",
      "S. Kabana",
      "N. Kalantar-Nayestanaki",
      "X. L. Kang",
      "X. S. Kang",
      "M. Kavatsyuk",
      "B. C. Ke",
      "V. Khachatryan",
      "A. Khoukaz",
      "R. Kiuchi",
      "O. B. Kolcu",
      "B. Kopf",
      "M. Kuessner",
      "X. Kui",
      "N. Kumar",
      "A. Kupsc",
      "W. K√ºhn",
      "Q. Lan",
      "W. N. Lan",
      "T. T. Lei",
      "M. Lellmann",
      "T. Lenz",
      "C. Li",
      "C. Li",
      "C. Li",
      "C. H. Li",
      "C. K. Li",
      "D. M. Li",
      "F. Li",
      "G. Li",
      "H. B. Li",
      "H. J. Li",
      "H. N. Li",
      "Hui Li",
      "J. R. Li",
      "J. S. Li",
      "K. Li",
      "K. L. Li",
      "K. L. Li",
      "L. J. Li",
      "Lei Li",
      "M. H. Li",
      "M. R. Li",
      "P. L. Li",
      "P. R. Li",
      "Q. M. Li",
      "Q. X. Li",
      "R. Li",
      "S. X. Li",
      "T. Li",
      "T. Y. Li",
      "W. D. Li",
      "W. G. Li",
      "X. Li",
      "X. H. Li",
      "X. L. Li",
      "X. Y. Li",
      "X. Z. Li",
      "Y. Li",
      "Y. G. Li",
      "Y. P. Li",
      "Z. J. Li",
      "Z. Y. Li",
      "H. Liang",
      "Y. F. Liang",
      "Y. T. Liang",
      "G. R. Liao",
      "L. B. Liao",
      "M. H. Liao",
      "Y. P. Liao",
      "J. Libby",
      "A. Limphirat",
      "C. C. Lin",
      "D. X. Lin",
      "L. Q. Lin",
      "T. Lin",
      "B. J. Liu",
      "B. X. Liu",
      "C. Liu",
      "C. X. Liu",
      "F. Liu",
      "F. H. Liu",
      "Feng Liu",
      "G. M. Liu",
      "H. Liu",
      "H. B. Liu",
      "H. H. Liu",
      "H. M. Liu",
      "Huihui Liu",
      "J. B. Liu",
      "J. J. Liu",
      "K. Liu",
      "K. Liu",
      "K. Y. Liu",
      "Ke Liu",
      "L. C. Liu",
      "Lu Liu",
      "M. H. Liu",
      "P. L. Liu",
      "Q. Liu",
      "S. B. Liu",
      "T. Liu",
      "W. K. Liu",
      "W. M. Liu",
      "W. T. Liu",
      "X. Liu",
      "X. Liu",
      "X. K. Liu",
      "X. Y. Liu",
      "Y. Liu",
      "Y. Liu",
      "Y. Liu",
      "Y. B. Liu",
      "Z. A. Liu",
      "Z. D. Liu",
      "Z. Q. Liu",
      "X. C. Lou",
      "F. X. Lu",
      "H. J. Lu",
      "J. G. Lu",
      "X. L. Lu",
      "Y. Lu",
      "Y. H. Lu",
      "Y. P. Lu",
      "Z. H. Lu",
      "C. L. Luo",
      "J. R. Luo",
      "J. S. Luo",
      "M. X. Luo",
      "T. Luo",
      "X. L. Luo",
      "Z. Y. Lv",
      "X. R. Lyu",
      "Y. F. Lyu",
      "Y. H. Lyu",
      "F. C. Ma",
      "H. L. Ma",
      "J. L. Ma",
      "L. L. Ma",
      "L. R. Ma",
      "Q. M. Ma",
      "R. Q. Ma",
      "R. Y. Ma",
      "T. Ma",
      "X. T. Ma",
      "X. Y. Ma",
      "Y. M. Ma",
      "F. E. Maas",
      "I. MacKay",
      "M. Maggiora",
      "S. Malde",
      "Q. A. Malik",
      "H. X. Mao",
      "Y. J. Mao",
      "Z. P. Mao",
      "S. Marcello",
      "A. Marshall",
      "F. M. Melendi",
      "Y. H. Meng",
      "Z. X. Meng",
      "G. Mezzadri",
      "H. Miao",
      "T. J. Min",
      "R. E. Mitchell",
      "X. H. Mo",
      "B. Moses",
      "N. Yu. Muchnoi",
      "J. Muskalla",
      "Y. Nefedov",
      "F. Nerling",
      "L. S. Nie",
      "I. B. Nikolaev",
      "Z. Ning",
      "S. Nisar",
      "Q. L. Niu",
      "W. D. Niu",
      "C. Normand",
      "S. L. Olsen",
      "Q. Ouyang",
      "S. Pacetti",
      "X. Pan",
      "Y. Pan",
      "A. Pathak",
      "Y. P. Pei",
      "M. Pelizaeus",
      "H. P. Peng",
      "X. J. Peng",
      "Y. Y. Peng",
      "K. Peters",
      "K. Petridis",
      "J. L. Ping",
      "R. G. Ping",
      "S. Plura",
      "V. Prasad",
      "F. Z. Qi",
      "H. R. Qi",
      "M. Qi",
      "S. Qian",
      "W. B. Qian",
      "C. F. Qiao",
      "J. H. Qiao",
      "J. J. Qin",
      "J. L. Qin",
      "L. Q. Qin",
      "L. Y. Qin",
      "P. B. Qin",
      "X. P. Qin",
      "X. S. Qin",
      "Z. H. Qin",
      "J. F. Qiu",
      "Z. H. Qu",
      "J. Rademacker",
      "C. F. Redmer",
      "A. Rivetti",
      "M. Rolo",
      "G. Rong",
      "S. S. Rong",
      "F. Rosini",
      "Ch. Rosner",
      "M. Q. Ruan",
      "N. Salone",
      "A. Sarantsev",
      "Y. Schelhaas",
      "K. Schoenning",
      "M. Scodeggio",
      "K. Y. Shan",
      "W. Shan",
      "X. Y. Shan",
      "Z. J. Shang",
      "J. F. Shangguan",
      "L. G. Shao",
      "M. Shao",
      "C. P. Shen",
      "H. F. Shen",
      "W. H. Shen",
      "X. Y. Shen",
      "B. A. Shi",
      "H. Shi",
      "J. L. Shi",
      "J. Y. Shi",
      "S. Y. Shi",
      "X. Shi",
      "H. L. Song",
      "J. J. Song",
      "T. Z. Song",
      "W. M. Song",
      "Y. J. Song",
      "Y. X. Song",
      "S. Sosio",
      "S. Spataro",
      "F. Stieler",
      "S. S Su",
      "Y. J. Su",
      "G. B. Sun",
      "G. X. Sun",
      "H. Sun",
      "H. K. Sun",
      "J. F. Sun",
      "K. Sun",
      "L. Sun",
      "S. S. Sun",
      "T. Sun",
      "Y. C. Sun",
      "Y. H. Sun",
      "Y. J. Sun",
      "Y. Z. Sun",
      "Z. Q. Sun",
      "Z. T. Sun",
      "C. J. Tang",
      "G. Y. Tang",
      "J. Tang",
      "J. J. Tang",
      "L. F. Tang",
      "Y. A. Tang",
      "L. Y. Tao",
      "M. Tat",
      "J. X. Teng",
      "J. Y. Tian",
      "W. H. Tian",
      "Y. Tian",
      "Z. F. Tian",
      "I. Uman",
      "B. Wang",
      "B. Wang",
      "Bo Wang",
      "C. Wang",
      "C. Wang",
      "Cong Wang",
      "D. Y. Wang",
      "H. J. Wang",
      "J. J. Wang",
      "K. Wang",
      "L. L. Wang",
      "L. W. Wang",
      "M. Wang",
      "M. Wang",
      "N. Y. Wang",
      "S. Wang",
      "T. Wang",
      "T. J. Wang",
      "W. Wang",
      "W. Wang",
      "W. P. Wang",
      "X. Wang",
      "X. F. Wang",
      "X. J. Wang",
      "X. L. Wang",
      "X. N. Wang",
      "Y. Wang",
      "Y. D. Wang",
      "Y. F. Wang",
      "Y. H. Wang",
      "Y. J. Wang",
      "Y. L. Wang",
      "Y. N. Wang",
      "Y. Q. Wang",
      "Yaqian Wang",
      "Yi Wang",
      "Yuan Wang",
      "Z. Wang",
      "Z. L. Wang",
      "Z. L. Wang",
      "Z. Q. Wang",
      "Z. Y. Wang",
      "D. H. Wei",
      "H. R. Wei",
      "F. Weidner",
      "S. P. Wen",
      "Y. R. Wen",
      "U. Wiedner",
      "G. Wilkinson",
      "M. Wolke",
      "C. Wu",
      "J. F. Wu",
      "L. H. Wu",
      "L. J. Wu",
      "L. J. Wu",
      "Lianjie Wu",
      "S. G. Wu",
      "S. M. Wu",
      "X. Wu",
      "X. H. Wu",
      "Y. J. Wu",
      "Z. Wu",
      "L. Xia",
      "X. M. Xian",
      "B. H. Xiang",
      "D. Xiao",
      "G. Y. Xiao",
      "H. Xiao",
      "Y. L. Xiao",
      "Z. J. Xiao",
      "C. Xie",
      "K. J. Xie",
      "X. H. Xie",
      "Y. Xie",
      "Y. G. Xie",
      "Y. H. Xie",
      "Z. P. Xie",
      "T. Y. Xing",
      "C. F. Xu",
      "C. J. Xu",
      "G. F. Xu",
      "H. Y. Xu",
      "H. Y. Xu",
      "M. Xu",
      "Q. J. Xu",
      "Q. N. Xu",
      "T. D. Xu",
      "W. Xu",
      "W. L. Xu",
      "X. P. Xu",
      "Y. Xu",
      "Y. Xu",
      "Y. C. Xu",
      "Z. S. Xu",
      "F. Yan",
      "H. Y. Yan",
      "L. Yan",
      "W. B. Yan",
      "W. C. Yan",
      "W. H. Yan",
      "W. P. Yan",
      "X. Q. Yan",
      "H. J. Yang",
      "H. L. Yang",
      "H. X. Yang",
      "J. H. Yang",
      "R. J. Yang",
      "T. Yang",
      "Y. Yang",
      "Y. F. Yang",
      "Y. H. Yang",
      "Y. Q. Yang",
      "Y. X. Yang",
      "Y. Z. Yang",
      "M. Ye",
      "M. H. Ye",
      "Z. J. Ye",
      "Junhao Yin",
      "Z. Y. You",
      "B. X. Yu",
      "C. X. Yu",
      "G. Yu",
      "J. S. Yu",
      "L. Q. Yu",
      "M. C. Yu",
      "T. Yu",
      "X. D. Yu",
      "Y. C. Yu",
      "C. Z. Yuan",
      "H. Yuan",
      "J. Yuan",
      "J. Yuan",
      "L. Yuan",
      "S. C. Yuan",
      "X. Q. Yuan",
      "Y. Yuan",
      "Z. Y. Yuan",
      "C. X. Yue",
      "Ying Yue",
      "A. A. Zafar",
      "S. H. Zeng",
      "X. Zeng",
      "Y. Zeng",
      "Y. J. Zeng",
      "Y. J. Zeng",
      "X. Y. Zhai",
      "Y. H. Zhan",
      "A. Q. Zhang",
      "B. L. Zhang",
      "B. X. Zhang",
      "D. H. Zhang",
      "G. Y. Zhang",
      "G. Y. Zhang",
      "H. Zhang",
      "H. Zhang",
      "H. C. Zhang",
      "H. H. Zhang",
      "H. Q. Zhang",
      "H. R. Zhang",
      "H. Y. Zhang",
      "J. Zhang",
      "J. Zhang",
      "J. J. Zhang",
      "J. L. Zhang",
      "J. Q. Zhang",
      "J. S. Zhang",
      "J. W. Zhang",
      "J. X. Zhang",
      "J. Y. Zhang",
      "J. Z. Zhang",
      "Jianyu Zhang",
      "L. M. Zhang",
      "Lei Zhang",
      "N. Zhang",
      "P. Zhang",
      "Q. Zhang",
      "Q. Y. Zhang",
      "R. Y. Zhang",
      "S. H. Zhang",
      "Shulei Zhang",
      "X. M. Zhang",
      "X. Y Zhang",
      "X. Y. Zhang",
      "Y. Zhang",
      "Y. Zhang",
      "Y. T. Zhang",
      "Y. H. Zhang",
      "Y. M. Zhang",
      "Y. P. Zhang",
      "Z. D. Zhang",
      "Z. H. Zhang",
      "Z. L. Zhang",
      "Z. L. Zhang",
      "Z. X. Zhang",
      "Z. Y. Zhang",
      "Z. Y. Zhang",
      "Z. Z. Zhang",
      "Zh. Zh. Zhang",
      "G. Zhao",
      "J. Y. Zhao",
      "J. Z. Zhao",
      "L. Zhao",
      "L. Zhao",
      "M. G. Zhao",
      "N. Zhao",
      "R. P. Zhao",
      "S. J. Zhao",
      "Y. B. Zhao",
      "Y. L. Zhao",
      "Y. X. Zhao",
      "Z. G. Zhao",
      "A. Zhemchugov",
      "B. Zheng",
      "B. M. Zheng",
      "J. P. Zheng",
      "W. J. Zheng",
      "X. R. Zheng",
      "Y. H. Zheng",
      "B. Zhong",
      "C. Zhong",
      "H. Zhou",
      "J. Q. Zhou",
      "J. Y. Zhou",
      "S. Zhou",
      "X. Zhou",
      "X. K. Zhou",
      "X. R. Zhou",
      "X. Y. Zhou",
      "Y. X. Zhou",
      "Y. Z. Zhou",
      "A. N. Zhu",
      "J. Zhu",
      "K. Zhu",
      "K. J. Zhu",
      "K. S. Zhu",
      "L. Zhu",
      "L. X. Zhu",
      "S. H. Zhu",
      "T. J. Zhu",
      "W. D. Zhu",
      "W. D. Zhu",
      "W. J. Zhu",
      "W. Z. Zhu",
      "Y. C. Zhu",
      "Z. A. Zhu",
      "X. Y. Zhuang",
      "J. H. Zou",
      "J. Zu"
    ],
    "abstract": "A search for a dark baryon is performed for the first time in the two-body\ndecay $\\Xi^-\\rightarrow\\pi^-+{\\rm invisible}$ using\n$(10.087\\pm0.044)\\times10^{9}$ $J/\\psi$ events collected at a center-of-mass\nenergy of $\\sqrt{s}=3.097\\,\\mbox{GeV}$ with the BESIII detector at the BEPCII\ncollider. No significant signal is observed, and the 90% (95%) confidence level\nupper limits on the branching fraction $B(\\Xi^-\\rightarrow\\pi^-+{\\rm\ninvisible})$ are determined to be $4.2\\times10^{-5}$ ($5.2\\times10^{-5}$),\n$6.9\\times10^{-5}$ ($8.4\\times10^{-5}$), $6.5\\times10^{-4}$\n($7.6\\times10^{-4}$), $1.1\\times10^{-4}$ ($1.3\\times10^{-4}$) and\n$4.5\\times10^{-5}$ ($5.5\\times10^{-5}$), under the dark baryon mass hypotheses\nof 1.07$\\,\\mbox{GeV}/c^2$, 1.10$\\,\\mbox{GeV}/c^2$, $m_\\Lambda$\n(1.116$\\,\\mbox{GeV}/c^2$), 1.13$\\,\\mbox{GeV}/c^2$, and 1.16$\\,\\mbox{GeV}/c^2$,\nrespectively. The constraints obtained on the Wilson coefficients $C_{u s,\ns}^L$ and $C_{u s, s}^R$ are more stringent than the previous limits derived\nfrom the LHC searches for the colored mediators.",
    "pdf_url": "http://arxiv.org/pdf/2505.22140v1",
    "published": "2025-05-28T09:03:38+00:00",
    "categories": [
      "hep-ex"
    ],
    "primary_category": "hep-ex"
  },
  {
    "id": "http://arxiv.org/abs/2505.23833v1",
    "title": "Benchmarking Abstract and Reasoning Abilities Through A Theoretical Perspective",
    "authors": [
      "Qingchuan Ma",
      "Yuhang Wu",
      "Xiawu Zheng",
      "Rongrong Ji"
    ],
    "abstract": "In this paper, we aim to establish a simple, effective, and theoretically\ngrounded benchmark for rigorously probing abstract reasoning in Large Language\nModels (LLMs). To achieve this, we first develop a mathematic framework that\ndefines abstract reasoning as the ability to: (i) extract essential patterns\nindependent of surface representations, and (ii) apply consistent rules to\nthese abstract patterns. Based on this framework, we introduce two novel\ncomplementary metrics: \\(\\scoreGamma\\) measures basic reasoning accuracy, while\n\\(\\scoreDelta\\) quantifies a model's reliance on specific symbols rather than\nunderlying patterns - a key indicator of true abstraction versus mere\nmemorization. To implement this measurement, we design a benchmark: systematic\nsymbol remapping in rule-based tasks, which forces models to demonstrate\ngenuine pattern recognition beyond superficial token matching. Extensive LLM\nevaluations using this benchmark (commercial API models, 7B-70B, multi-agent)\nreveal:1) critical limitations in non-decimal arithmetic and symbolic\nreasoning; 2) persistent abstraction gaps despite chain-of-thought prompting;\nand 3) \\(\\scoreDelta\\)'s effectiveness in robustly measuring memory dependence\nby quantifying performance degradation under symbol remapping, particularly\nhighlighting operand-specific memorization. These findings underscore that\ncurrent LLMs, despite domain-specific strengths, still lack robust abstract\nreasoning, highlighting key areas for future improvement.",
    "pdf_url": "http://arxiv.org/pdf/2505.23833v1",
    "published": "2025-05-28T09:02:45+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.23832v1",
    "title": "LegalSearchLM: Rethinking Legal Case Retrieval as Legal Elements Generation",
    "authors": [
      "Chaeeun Kim",
      "Jinu Lee",
      "Wonseok Hwang"
    ],
    "abstract": "Legal Case Retrieval (LCR), which retrieves relevant cases from a query case,\nis a fundamental task for legal professionals in research and decision-making.\nHowever, existing studies on LCR face two major limitations. First, they are\nevaluated on relatively small-scale retrieval corpora (e.g., 100-55K cases) and\nuse a narrow range of criminal query types, which cannot sufficiently reflect\nthe complexity of real-world legal retrieval scenarios. Second, their reliance\non embedding-based or lexical matching methods often results in limited\nrepresentations and legally irrelevant matches. To address these issues, we\npresent: (1) LEGAR BENCH, the first large-scale Korean LCR benchmark, covering\n411 diverse crime types in queries over 1.2M legal cases; and (2)\nLegalSearchLM, a retrieval model that performs legal element reasoning over the\nquery case and directly generates content grounded in the target cases through\nconstrained decoding. Experimental results show that LegalSearchLM outperforms\nbaselines by 6-20% on LEGAR BENCH, achieving state-of-the-art performance. It\nalso demonstrates strong generalization to out-of-domain cases, outperforming\nnaive generative models trained on in-domain data by 15%.",
    "pdf_url": "http://arxiv.org/pdf/2505.23832v1",
    "published": "2025-05-28T09:02:41+00:00",
    "categories": [
      "cs.CL",
      "cs.IR"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.22139v1",
    "title": "The stellar population in the SARAO MeerKAT Galactic Plane Survey",
    "authors": [
      "Okwudili D. Egbo",
      "David A. H. Buckley",
      "Paul J. Groot",
      "Francesco Cavallaro",
      "Patrick A. Woudt",
      "Mark A. Thompson",
      "Mubela Mutale",
      "Michael Bietenholz"
    ],
    "abstract": "We report on optically selected stellar candidates of SARAO MeerKAT 1.3 GHz\nradio continuum survey sources of the Galactic plane. Stellar counterparts to\nradio sources are selected by cross-matching the MeerKAT source positions with\n\\textit{Gaia} DR3, using two approaches. The first approach evaluated the\nprobability of chance alignments between the radio survey and \\textit{Gaia}\nsources and used AllWISE infrared colour-colour information to select potential\nstellar candidates. The second approach utilized a Monte Carlo method to\nevaluate the cross-matching reliability probability, based on populations of\nknown radio-emitting stars. From the combined approaches, we found 629\npotential stellar counterparts, of which 169 have existing SIMBAD\nclassifications, making it the largest Galactic plane radio-optical crossmatch\nsample to date. A colour-magnitude analysis of the sample revealed a diverse\npopulation of stellar objects, ranging from massive OB stars, main-sequence\nstars, giants, young stellar objects, emission line stars, red dwarfs and white\ndwarfs. Some of the proposed optical counterparts include\nchromospherically/coronally active stars, for example RS CVn binaries, BY Dra\nsystems, YSOs and flare stars, which typically exhibit radio emission. Based on\nGaia's low-resolution spectroscopy, some of the stars show strong H$\\alpha$\nemission, indicating they are magnetically active, consistent with them being\nradio emitters. While MeerKAT's sensitivity and survey speed make it ideal for\ndetecting faint radio sources, its angular resolution limits accurate\ncounterpart identification for crowded fields such as the Galactic Plane.\nHigher frequency, and, thereby, better spatial resolution, radio observations\nplus circular polarization would be required to strengthen the associations.",
    "pdf_url": "http://arxiv.org/pdf/2505.22139v1",
    "published": "2025-05-28T09:02:15+00:00",
    "categories": [
      "astro-ph.SR"
    ],
    "primary_category": "astro-ph.SR"
  },
  {
    "id": "http://arxiv.org/abs/2505.23831v1",
    "title": "ICH-Qwen: A Large Language Model Towards Chinese Intangible Cultural Heritage",
    "authors": [
      "Wenhao Ye",
      "Tiansheng Zheng",
      "Yue Qi",
      "Wenhua Zhao",
      "Xiyu Wang",
      "Xue Zhao",
      "Jiacheng He",
      "Yaya Zheng",
      "Dongbo Wang"
    ],
    "abstract": "The intangible cultural heritage (ICH) of China, a cultural asset transmitted\nacross generations by various ethnic groups, serves as a significant testament\nto the evolution of human civilization and holds irreplaceable value for the\npreservation of historical lineage and the enhancement of cultural\nself-confidence. However, the rapid pace of modernization poses formidable\nchallenges to ICH, including threats damage, disappearance and discontinuity of\ninheritance. China has the highest number of items on the UNESCO Intangible\nCultural Heritage List, which is indicative of the nation's abundant cultural\nresources and emphasises the pressing need for ICH preservation. In recent\nyears, the rapid advancements in large language modelling have provided a novel\ntechnological approach for the preservation and dissemination of ICH. This\nstudy utilises a substantial corpus of open-source Chinese ICH data to develop\na large language model, ICH-Qwen, for the ICH domain. The model employs natural\nlanguage understanding and knowledge reasoning capabilities of large language\nmodels, augmented with synthetic data and fine-tuning techniques. The\nexperimental results demonstrate the efficacy of ICH-Qwen in executing tasks\nspecific to the ICH domain. It is anticipated that the model will provide\nintelligent solutions for the protection, inheritance and dissemination of\nintangible cultural heritage, as well as new theoretical and practical\nreferences for the sustainable development of intangible cultural heritage.\nFurthermore, it is expected that the study will open up new paths for digital\nhumanities research.",
    "pdf_url": "http://arxiv.org/pdf/2505.23831v1",
    "published": "2025-05-28T09:02:13+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.22138v1",
    "title": "On the inverse problem of the two-velocity tree-like graph",
    "authors": [
      "S. A. Avdonin",
      "A. Choque Rivero",
      "G. Leugering",
      "V. S. Mikhaylov"
    ],
    "abstract": "In this article the authors continue the discussion in \\cite{ALM}\n  about inverse problems for second order elliptic and hyperbolic equations\n  on metric trees from boundary measurements. In the present paper we prove\n  the identifiability of varying densities of a planar tree-like network of\n  strings along with the complete information on the graph, i.e. the lengths\n  of the edges, the edge degrees and the angles between neighbouring edges.\n  The results are achieved using the Titchmarch-Weyl function for the spectral\n  problem and the Steklov-Poincar{\\'e} operator for the dynamic wave equation\n  on the tree. The general result is obtained by a peeling argument which\nreduces\n  the inverse problem layer-by-layer from the leaves to the clamped\n  root of the tree.",
    "pdf_url": "http://arxiv.org/pdf/2505.22138v1",
    "published": "2025-05-28T09:01:25+00:00",
    "categories": [
      "math.AP",
      "math.SP"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2505.22137v1",
    "title": "Limited Generalizability in Argument Mining: State-Of-The-Art Models Learn Datasets, Not Arguments",
    "authors": [
      "Marc Feger",
      "Katarina Boland",
      "Stefan Dietze"
    ],
    "abstract": "Identifying arguments is a necessary prerequisite for various tasks in\nautomated discourse analysis, particularly within contexts such as political\ndebates, online discussions, and scientific reasoning. In addition to\ntheoretical advances in understanding the constitution of arguments, a\nsignificant body of research has emerged around practical argument mining,\nsupported by a growing number of publicly available datasets. On these\nbenchmarks, BERT-like transformers have consistently performed best,\nreinforcing the belief that such models are broadly applicable across diverse\ncontexts of debate. This study offers the first large-scale re-evaluation of\nsuch state-of-the-art models, with a specific focus on their ability to\ngeneralize in identifying arguments. We evaluate four transformers, three\nstandard and one enhanced with contrastive pre-training for better\ngeneralization, on 17 English sentence-level datasets as most relevant to the\ntask. Our findings show that, to varying degrees, these models tend to rely on\nlexical shortcuts tied to content words, suggesting that apparent progress may\noften be driven by dataset-specific cues rather than true task alignment. While\nthe models achieve strong results on familiar benchmarks, their performance\ndrops markedly when applied to unseen datasets. Nonetheless, incorporating both\ntask-specific pre-training and joint benchmark training proves effective in\nenhancing both robustness and generalization.",
    "pdf_url": "http://arxiv.org/pdf/2505.22137v1",
    "published": "2025-05-28T09:00:56+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.22136v1",
    "title": "Frame bound, spectral gap and Plus space",
    "authors": [
      "Zheng-Yi Lu"
    ],
    "abstract": "In this paper, we investigate the relationship between frame bounds and\nspectral gaps. By introducing the notion of \\emph{essential minimum(maximal)\nspectral gap}, we provide a local characterization of Landau's theorem\n\\cite{Lan67}. As an application, we resolve the spectrality additive measures\nof Lebesgue type, conclusively answering an open question on the spectrality of\nPlus spaces originally raised by Lai, Liu, Prince \\cite{LLP21} and further\nstudied by Ai, Lu, Zhou \\cite{ALZ23} and Kolountzakis, Wu \\cite{KW25}.",
    "pdf_url": "http://arxiv.org/pdf/2505.22136v1",
    "published": "2025-05-28T09:00:01+00:00",
    "categories": [
      "math.FA"
    ],
    "primary_category": "math.FA"
  },
  {
    "id": "http://arxiv.org/abs/2505.22135v1",
    "title": "RAD: Redundancy-Aware Distillation for Hybrid Models via Self-Speculative Decoding",
    "authors": [
      "Yuichiro Hoshino",
      "Hideyuki Tachibana",
      "Muneyoshi Inahara",
      "Hiroto Takegawa"
    ],
    "abstract": "Hybrid models combining Transformers and State Space Models (SSMs) are\npromising for balancing performance and efficiency. However, optimizing these\nhybrid models, particularly by addressing the potential redundancy inherent\nwithin the Transformer components, remains a significant challenge. In this\npaper, we propose RAD (Redundancy-Aware Distillation), a novel framework that\nuses self-speculative decoding as a diagnostic tool to identify redundant\nattention layers within the model. These identified layers are then selectively\nreplaced with SSM components, followed by targeted (self-)distillation.\nSpecifically, RAD focuses knowledge transfer on the components identified as\nredundant, considering architectural changes and specific weight initialization\nstrategies. We experimentally demonstrate that self-distillation using RAD\nsignificantly surpasses the performance of the original base model on\nmathematical and coding tasks. Furthermore, RAD is also effective in standard\nknowledge distillation settings, achieving up to approximately 2x faster\nconvergence compared to baseline methods. Notably, while a baseline model\ndistilled from a Llama-3.1 70B teacher achieves scores of 46.17 on GSM8K and\n22.75 on CRUX, RAD achieves significantly higher scores of 71.27 on GSM8K and\n28.25 on CRUX, even when using a much smaller Llama-3.1 8B teacher. RAD offers\na new pathway for efficient optimization and performance enhancement in the\ndistillation of hybrid models.",
    "pdf_url": "http://arxiv.org/pdf/2505.22135v1",
    "published": "2025-05-28T08:59:02+00:00",
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.22134v1",
    "title": "Infection dynamics for fluctuating infection or removal rates regarding the number of infected and susceptible individuals",
    "authors": [
      "Seong Jun Park",
      "M. Y. Choi"
    ],
    "abstract": "In general, the rates of infection and removal (whether through recovery or\ndeath) are nonlinear functions of the number of infected and susceptible\nindividuals. One of the simplest models for the spread of infectious diseases\nis the SIR model, which categorizes individuals as susceptible, infectious,\nrecovered or deceased. In this model, the infection rate, governing the\ntransition from susceptible to infected individuals, is given by a linear\nfunction of both susceptible and infected populations. Similarly, the removal\nrate, representing the transition from infected to removed individuals, is a\nlinear function of the number of infected individuals. However, existing\nresearch often overlooks the impact of nonlinear infection and removal rates in\ninfection dynamics. This work presents an analytic expression for the number of\ninfected individuals considering nonlinear infection and removal rates. In\nparticular, we examine how the number of infected individuals varies as cases\nemerge and obtain the expression accounting for the number of infected\nindividuals at each moment. This work paves the way for new quantitative\napproaches to understanding infection dynamics.",
    "pdf_url": "http://arxiv.org/pdf/2505.22134v1",
    "published": "2025-05-28T08:58:37+00:00",
    "categories": [
      "q-bio.PE"
    ],
    "primary_category": "q-bio.PE"
  },
  {
    "id": "http://arxiv.org/abs/2505.22133v2",
    "title": "Developing a Top-tier Framework in Naturalistic Conditions Challenge for Categorized Emotion Prediction: From Speech Foundation Models and Learning Objective to Data Augmentation and Engineering Choices",
    "authors": [
      "Tiantian Feng",
      "Thanathai Lertpetchpun",
      "Dani Byrd",
      "Shrikanth Narayanan"
    ],
    "abstract": "Speech emotion recognition (SER), particularly for naturally expressed\nemotions, remains a challenging computational task. Key challenges include the\ninherent subjectivity in emotion annotation and the imbalanced distribution of\nemotion labels in datasets. This paper introduces the \\texttt{SAILER} system\ndeveloped for participation in the INTERSPEECH 2025 Emotion Recognition\nChallenge (Task 1). The challenge dataset, which contains natural emotional\nspeech from podcasts, serves as a valuable resource for studying imbalanced and\nsubjective emotion annotations. Our system is designed to be simple,\nreproducible, and effective, highlighting critical choices in modeling,\nlearning objectives, data augmentation, and engineering choices. Results show\nthat even a single system (without ensembling) can outperform more than 95\\% of\nthe submissions, with a Macro-F1 score exceeding 0.4. Moreover, an ensemble of\nthree systems further improves performance, achieving a competitively ranked\nscore (top-3 performing team). Our model is at:\nhttps://github.com/tiantiaf0627/vox-profile-release.",
    "pdf_url": "http://arxiv.org/pdf/2505.22133v2",
    "published": "2025-05-28T08:58:22+00:00",
    "categories": [
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.SD"
  },
  {
    "id": "http://arxiv.org/abs/2505.22132v1",
    "title": "Streaming Remote rendering services: Comparison of QUIC-based and WebRTC Protocols",
    "authors": [
      "Daniel Mej√≠as",
      "Inhar Yeregui",
      "√Ångel Mart√≠n",
      "Roberto Viola",
      "Pablo Angueira",
      "Jon Montalb√°n"
    ],
    "abstract": "The proliferation of Extended Reality (XR) applications, requiring\nhigh-quality, low-latency media streaming, has driven the demand for efficient\nremote rendering solutions. This paper focuses on holographic conferencing in\nvirtual environments and their required uplink and downlink media transmission\ncapabilities. By examining Media over QUIC (MoQ), Real-time Transport Protocol\n(RTP) over QUIC (RoQ), and Web Real-Time Communication (WebRTC), we assess\ntheir latency performance over Wi-Fi and 5G networks. Improvements of\napproximately 30% in latency and 60% in connection startup are expected in\nQUIC-based protocols compared to WebRTC. The experimental setup transmits a\nremote-rendered virtual experience using real-time video streaming protocols to\nprovide the content to the participant. Our findings contribute to\nunderstanding the maturity of streaming protocols, particularly within\nopen-source frameworks, and evaluate their suitability in supporting\nlatency-sensitive XR applications. The study highlights specific protocol\nadvantages across varied remote rendering scenarios, informing the design of\nfuture XR communication solutions.",
    "pdf_url": "http://arxiv.org/pdf/2505.22132v1",
    "published": "2025-05-28T08:57:44+00:00",
    "categories": [
      "cs.NI"
    ],
    "primary_category": "cs.NI"
  },
  {
    "id": "http://arxiv.org/abs/2505.22131v1",
    "title": "EULER: Enhancing the Reasoning Ability of Large Language Models through Error-Induced Learning",
    "authors": [
      "Zhuoyang Wu",
      "Xinze Li",
      "Zhenghao Liu",
      "Yukun Yan",
      "Zhiyuan Liu",
      "Minghe Yu",
      "Cheng Yang",
      "Yu Gu",
      "Ge Yu",
      "Maosong Sun"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated strong reasoning capabilities\nand achieved promising results in mathematical problem-solving tasks. Learning\nfrom errors offers the potential to further enhance the performance of LLMs\nduring Supervised Fine-Tuning (SFT). However, the errors in synthesized\nsolutions are typically gathered from sampling trails, making it challenging to\ngenerate solution errors for each mathematical problem. This paper introduces\nthe Error-IndUced LEaRning (EULER) model, which aims to develop an error\nexposure model that generates high-quality solution errors to enhance the\nmathematical reasoning capabilities of LLMs. Specifically, EULER optimizes the\nerror exposure model to increase the generation probability of self-made\nsolution errors while utilizing solutions produced by a superior LLM to\nregularize the generation quality. Our experiments across various mathematical\nproblem datasets demonstrate the effectiveness of the EULER model, achieving an\nimprovement of over 4% compared to all baseline models. Further analysis\nreveals that EULER is capable of synthesizing more challenging and educational\nsolution errors, which facilitate both the training and inference processes of\nLLMs. All codes are available at https://github.com/NEUIR/EULER.",
    "pdf_url": "http://arxiv.org/pdf/2505.22131v1",
    "published": "2025-05-28T08:57:03+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.22130v1",
    "title": "ConsRec: Denoising Sequential Recommendation through User-Consistent Preference Modeling",
    "authors": [
      "Haidong Xin",
      "Qiushi Xiong",
      "Zhenghao Liu",
      "Sen Mei",
      "Yukun Yan",
      "Shi Yu",
      "Shuo Wang",
      "Yu Gu",
      "Ge Yu",
      "Chenyan Xiong"
    ],
    "abstract": "User-item interaction histories are pivotal for sequential recommendation\nsystems but often include noise, such as unintended clicks or actions that fail\nto reflect genuine user preferences. To address this issue, we propose the\nUser-Consistent Preference-based Sequential Recommendation System (ConsRec),\ndesigned to capture stable user preferences and filter noisy items from\ninteraction histories. Specifically, ConsRec constructs a user-interacted item\ngraph, learns item similarities from their text representations, and then\nextracts the maximum connected subgraph from the user-interacted item graph for\ndenoising items. Experimental results on the Yelp and Amazon Product datasets\nillustrate that ConsRec achieves a 13% improvement over baseline recommendation\nmodels, showing its effectiveness in denoising user-interacted items. Further\nanalysis reveals that the denoised interaction histories form semantically\ntighter clusters of user-preferred items, leading to higher relevance scores\nfor ground-truth targets and more accurate recommendations. All codes are\navailable at https://github.com/NEUIR/ConsRec.",
    "pdf_url": "http://arxiv.org/pdf/2505.22130v1",
    "published": "2025-05-28T08:55:13+00:00",
    "categories": [
      "cs.IR"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2505.22129v1",
    "title": "What Makes for Text to 360-degree Panorama Generation with Stable Diffusion?",
    "authors": [
      "Jinhong Ni",
      "Chang-Bin Zhang",
      "Qiang Zhang",
      "Jing Zhang"
    ],
    "abstract": "Recent prosperity of text-to-image diffusion models, e.g. Stable Diffusion,\nhas stimulated research to adapt them to 360-degree panorama generation. Prior\nwork has demonstrated the feasibility of using conventional low-rank adaptation\ntechniques on pre-trained diffusion models to generate panoramic images.\nHowever, the substantial domain gap between perspective and panoramic images\nraises questions about the underlying mechanisms enabling this empirical\nsuccess. We hypothesize and examine that the trainable counterparts exhibit\ndistinct behaviors when fine-tuned on panoramic data, and such an adaptation\nconceals some intrinsic mechanism to leverage the prior knowledge within the\npre-trained diffusion models. Our analysis reveals the following: 1) the query\nand key matrices in the attention modules are responsible for common\ninformation that can be shared between the panoramic and perspective domains,\nthus are less relevant to panorama generation; and 2) the value and output\nweight matrices specialize in adapting pre-trained knowledge to the panoramic\ndomain, playing a more critical role during fine-tuning for panorama\ngeneration. We empirically verify these insights by introducing a simple\nframework called UniPano, with the objective of establishing an elegant\nbaseline for future research. UniPano not only outperforms existing methods but\nalso significantly reduces memory usage and training time compared to prior\ndual-branch approaches, making it scalable for end-to-end panorama generation\nwith higher resolution. The code will be released.",
    "pdf_url": "http://arxiv.org/pdf/2505.22129v1",
    "published": "2025-05-28T08:54:04+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.22128v2",
    "title": "Real-Time Blind Defocus Deblurring for Earth Observation: The IMAGIN-e Mission Approach",
    "authors": [
      "Alejandro D. Mousist"
    ],
    "abstract": "This work addresses mechanical defocus in Earth observation images from the\nIMAGIN-e mission aboard the ISS, proposing a blind deblurring approach adapted\nto space-based edge computing constraints. Leveraging Sentinel-2 data, our\nmethod estimates the defocus kernel and trains a restoration model within a GAN\nframework, effectively operating without reference images.\n  On Sentinel-2 images with synthetic degradation, SSIM improved by 72.47% and\nPSNR by 25.00%, confirming the model's ability to recover lost details when the\noriginal clean image is known. On IMAGIN-e, where no reference images exist,\nperceptual quality metrics indicate a substantial enhancement, with NIQE\nimproving by 60.66% and BRISQUE by 48.38%, validating real-world onboard\nrestoration. The approach is currently deployed aboard the IMAGIN-e mission,\ndemonstrating its practical application in an operational space environment.\n  By efficiently handling high-resolution images under edge computing\nconstraints, the method enables applications such as water body segmentation\nand contour detection while maintaining processing viability despite resource\nlimitations.",
    "pdf_url": "http://arxiv.org/pdf/2505.22128v2",
    "published": "2025-05-28T08:52:38+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.22127v1",
    "title": "Unveiling Crystal Embeddings: New Perspectives on String Polytopes and Atomic Decompositions",
    "authors": [
      "Lara Bossinger",
      "Jacinta Torres"
    ],
    "abstract": "We present n-1 different embeddings of string polytopes of type A. We\ncharacterize their compatibility with the crystal structure on the string\npolytopes, and formulate a conjecture describing how to obtain n-1 different\natomic decompositions of the crystal with highest weight a multiple of the\nhighest root.",
    "pdf_url": "http://arxiv.org/pdf/2505.22127v1",
    "published": "2025-05-28T08:51:32+00:00",
    "categories": [
      "math.RT",
      "math.CO"
    ],
    "primary_category": "math.RT"
  },
  {
    "id": "http://arxiv.org/abs/2505.22126v1",
    "title": "SridBench: Benchmark of Scientific Research Illustration Drawing of Image Generation Model",
    "authors": [
      "Yifan Chang",
      "Yukang Feng",
      "Jianwen Sun",
      "Jiaxin Ai",
      "Chuanhao Li",
      "S. Kevin Zhou",
      "Kaipeng Zhang"
    ],
    "abstract": "Recent years have seen rapid advances in AI-driven image generation. Early\ndiffusion models emphasized perceptual quality, while newer multimodal models\nlike GPT-4o-image integrate high-level reasoning, improving semantic\nunderstanding and structural composition. Scientific illustration generation\nexemplifies this evolution: unlike general image synthesis, it demands accurate\ninterpretation of technical content and transformation of abstract ideas into\nclear, standardized visuals. This task is significantly more\nknowledge-intensive and laborious, often requiring hours of manual work and\nspecialized tools. Automating it in a controllable, intelligent manner would\nprovide substantial practical value. Yet, no benchmark currently exists to\nevaluate AI on this front. To fill this gap, we introduce SridBench, the first\nbenchmark for scientific figure generation. It comprises 1,120 instances\ncurated from leading scientific papers across 13 natural and computer science\ndisciplines, collected via human experts and MLLMs. Each sample is evaluated\nalong six dimensions, including semantic fidelity and structural accuracy.\nExperimental results reveal that even top-tier models like GPT-4o-image lag\nbehind human performance, with common issues in text/visual clarity and\nscientific correctness. These findings highlight the need for more advanced\nreasoning-driven visual generation capabilities.",
    "pdf_url": "http://arxiv.org/pdf/2505.22126v1",
    "published": "2025-05-28T08:51:01+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.22125v1",
    "title": "Sentiment Simulation using Generative AI Agents",
    "authors": [
      "Melrose Tia",
      "Jezreel Sophia Lanuzo",
      "Lei Rigi Baltazar",
      "Marie Joy Lopez-Relente",
      "Diwa Malaya Qui√±ones",
      "Jason Albia"
    ],
    "abstract": "Traditional sentiment analysis relies on surface-level linguistic patterns\nand retrospective data, limiting its ability to capture the psychological and\ncontextual drivers of human sentiment. These limitations constrain its\neffectiveness in applications that require predictive insight, such as policy\ntesting, narrative framing, and behavioral forecasting. We present a robust\nframework for sentiment simulation using generative AI agents embedded with\npsychologically rich profiles. Agents are instantiated from a nationally\nrepresentative survey of 2,485 Filipino respondents, combining sociodemographic\ninformation with validated constructs of personality traits, values, beliefs,\nand socio-political attitudes. The framework includes three stages: (1) agent\nembodiment via categorical or contextualized encodings, (2) exposure to\nreal-world political and economic scenarios, and (3) generation of sentiment\nratings accompanied by explanatory rationales. Using Quadratic Weighted\nAccuracy (QWA), we evaluated alignment between agent-generated and human\nresponses. Contextualized encoding achieved 92% alignment in replicating\noriginal survey responses. In sentiment simulation tasks, agents reached\n81%--86% accuracy against ground truth sentiment, with contextualized profile\nencodings significantly outperforming categorical (p < 0.0001, Cohen's d =\n0.70). Simulation results remained consistent across repeated trials\n(+/-0.2--0.5% SD) and resilient to variation in scenario framing (p = 0.9676,\nCohen's d = 0.02). Our findings establish a scalable framework for sentiment\nmodeling through psychographically grounded AI agents. This work signals a\nparadigm shift in sentiment analysis from retrospective classification to\nprospective and dynamic simulation grounded in psychology of sentiment\nformation.",
    "pdf_url": "http://arxiv.org/pdf/2505.22125v1",
    "published": "2025-05-28T08:50:56+00:00",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.CY",
      "I.2; I.6; J.4"
    ],
    "primary_category": "cs.MA"
  },
  {
    "id": "http://arxiv.org/abs/2505.22124v2",
    "title": "A Nurse Staffing and Scheduling Problem with Bounded Flexibility and Demand Uncertainty",
    "authors": [
      "Si Zhang",
      "Paul Mingzheng Tang",
      "Hoong Chuin Lau"
    ],
    "abstract": "Nurse staffing and scheduling are persistent challenges in healthcare due to\ndemand fluctuations and individual nurse preferences. This study introduces the\nconcept of bounded flexibility, balancing nurse satisfaction with strict\nrostering rules, particularly a real-world time regularity policy from a major\nhospital in Singapore. We model the problem as a multi-stage stochastic program\nto address evolving demand, optimizing both aggregate staffing and detailed\nscheduling decisions. A reformulation into a two-stage structure using\nblock-separable recourse reduces computational burden without loss of accuracy.\nTo solve the problem efficiently, we develop a Generative AI-guided algorithm.\nNumerical experiments with real hospital data show substantial cost savings and\nimproved nurse flexibility with minimal compromise to schedule regularity.\nNumerical experiments based on real-world nurse profiles, nurse preferences,\nand patient demand data are conducted to evaluate the performance of the\nproposed methods. Our results demonstrate that the stochastic model achieves\nsignificant cost savings compared to the deterministic model. Notably, a slight\nreduction in the regularity level can remarkably enhance nurse flexibility.",
    "pdf_url": "http://arxiv.org/pdf/2505.22124v2",
    "published": "2025-05-28T08:50:09+00:00",
    "categories": [
      "math.OC"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2505.22123v1",
    "title": "Leveraging 5G Physical Layer Monitoring for Adaptive Remote Rendering in XR Applications",
    "authors": [
      "Inhar Yeregui",
      "Daniel Mej√≠as",
      "Mikel Zorrilla",
      "Roberto Viola",
      "Jasone Astorga",
      "Eduardo Jacob"
    ],
    "abstract": "As immersive eXtended Reality (XR) applications demand substantial network\nresources, understanding their interaction with 5G networks becomes crucial to\nimprove them. This paper investigates the role of 5G physical-layer monitoring\nto manage and enhance the remote rendering of XR content dynamically. By\nobserving network metrics directly from the physical layer, we propose a system\nto adapt streaming parameters such as bitrate, framerate, and resolution in\nreal time based on available network capacity. Using theoretical formulas to\nestimate maximum data rate, our approach evaluates network resource\navailability, enabling the renderer to self-adjust media content\nrepresentation. This is critical for providing consistent and smooth XR\nexperiences to users, especially as network conditions fluctuate. Our findings\nsuggest that physical-layer monitoring offers valuable insights to increase the\nQuality of Service (QoS) and has the potential to elevate user experience in\nremote-rendered XR applications.",
    "pdf_url": "http://arxiv.org/pdf/2505.22123v1",
    "published": "2025-05-28T08:50:08+00:00",
    "categories": [
      "cs.NI"
    ],
    "primary_category": "cs.NI"
  },
  {
    "id": "http://arxiv.org/abs/2505.22122v1",
    "title": "Effective potential and scattering length of shielding polar molecules",
    "authors": [
      "Peng Xu",
      "Gang Chen"
    ],
    "abstract": "We investigate the effective potential and scattering length of ultracold\npolar molecules under different shielding techniques. First, we derive the\neffective potential for two polar molecules in the presence of an elliptical\npolarization field, combined elliptical and linear polarization fields, and\ncombined elliptical polarization and static fields. The effective potential is\nthen expressed as a sum of a zero-range contact interaction and a long-range\ndipole-dipole interaction under the Born approximation. We find that the first\ntwo shielding methods only partially suppress attractive interactions, while\nthe second method allows for the construction of bound states with different\npolarization shapes. The last shielding method can achieve complete\ncancellation of residual attractive forces, which is particularly significant\nfor maintaining quantum degeneracy in ultracold dipolar systems. Our results\nprovide a comprehensive understanding of the effective potential and scattering\nlength of shielding polar molecules, which is crucial for studying many-body\nphysics in ultracold dipolar systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.22122v1",
    "published": "2025-05-28T08:48:26+00:00",
    "categories": [
      "cond-mat.quant-gas"
    ],
    "primary_category": "cond-mat.quant-gas"
  },
  {
    "id": "http://arxiv.org/abs/2505.22121v2",
    "title": "Multi-period Mean-Buffered Probability of Exceedance in Defined Contribution Portfolio Optimization",
    "authors": [
      "Duy-Minh Dang",
      "Chang Chen"
    ],
    "abstract": "We investigate multi-period mean-risk portfolio optimization for long-horizon\nDefined Contribution plans, focusing on buffered Probability of Exceedance\n(bPoE), a more intuitive, dollar-based alternative to Conditional Value-at-Risk\n(CVaR). We formulate both pre-commitment and time-consistent Mean-bPoE and\nMean-CVaR portfolio optimization problems under realistic investment\nconstraints (e.g., no leverage, no short selling) and jump-diffusion dynamics.\nThese formulations are naturally framed as bilevel optimization problems, with\nan outer search over the shortfall threshold and an inner optimization over\nrebalancing decisions. We establish an equivalence between the pre-commitment\nformulations through a one-to-one correspondence of their scalarization optimal\nsets, while showing that no such equivalence holds in the time-consistent\nsetting. We develop provably convergent numerical schemes for the value\nfunctions associated with both pre-commitment and time-consistent formulations\nof these mean-risk control problems.\n  Using nearly a century of market data, we find that time-consistent Mean-bPoE\nstrategies closely resemble their pre-commitment counterparts. In particular,\nthey maintain alignment with investors' preferences for a minimum acceptable\nterminal wealth level-unlike time-consistent Mean-CVaR, which often leads to\ncounterintuitive control behavior. We further show that bPoE, as a strictly\ntail-oriented measure, prioritizes guarding against catastrophic shortfalls\nwhile allowing meaningful upside exposure, making it especially appealing for\nlong-horizon wealth security. These findings highlight bPoE's practical\nadvantages for Defined Contribution investment planning.",
    "pdf_url": "http://arxiv.org/pdf/2505.22121v2",
    "published": "2025-05-28T08:47:54+00:00",
    "categories": [
      "q-fin.PM",
      "q-fin.CP",
      "91G, 65R20, 93E20, 49M25"
    ],
    "primary_category": "q-fin.PM"
  },
  {
    "id": "http://arxiv.org/abs/2505.22120v1",
    "title": "LoKI: Low-damage Knowledge Implanting of Large Language Models",
    "authors": [
      "Runyu Wang",
      "Peng Ping",
      "Zhengyu Guo",
      "Xiaoye Zhang",
      "Quan Shi",
      "Liting Zhou",
      "Tianbo Ji"
    ],
    "abstract": "Fine-tuning adapts pretrained models for specific tasks but poses the risk of\ncatastrophic forgetting (CF), where critical knowledge from pre-training is\noverwritten. Current Parameter-Efficient Fine-Tuning (PEFT) methods for Large\nLanguage Models (LLMs), while efficient, often sacrifice general capabilities.\nTo address the issue of CF in a general-purpose PEFT framework, we propose\n\\textbf{Lo}w-damage \\textbf{K}nowledge \\textbf{I}mplanting (\\textbf{LoKI}), a\nPEFT technique that is based on a mechanistic understanding of how knowledge is\nstored in transformer architectures. In two real-world scenarios, LoKI\ndemonstrates task-specific performance that is comparable to or even surpasses\nthat of full fine-tuning and LoRA-based methods across various model types,\nwhile significantly better preserving general capabilities. Our work connects\nmechanistic insights into LLM knowledge storage with practical fine-tuning\nobjectives, achieving state-of-the-art trade-offs between task specialization\nand the preservation of general capabilities. Our implementation is publicly\navailable as ready-to-use code\\footnote{https://github.com/Nexround/LoKI}.",
    "pdf_url": "http://arxiv.org/pdf/2505.22120v1",
    "published": "2025-05-28T08:47:26+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.22119v3",
    "title": "Massless limit of massive self-interacting vector fields",
    "authors": [
      "Nabamita Banerjee",
      "Jitesh Singh"
    ],
    "abstract": "We study massive self-interacting vector field theories with mass added ``by\nhand\".\n  We show that the massless limit of the quartic self-interacting vector field\ntheory is not smooth. Pathological behavior of the theory is not limited only\nat the classical level, even at the quantum level unitarity is violated at the\ntwo-loop. Using the Vainshtein mechanism, we show that it fails beyond the\nstrong-coupling scale and hence a massless limit is not smooth even in quantum\ntheory.",
    "pdf_url": "http://arxiv.org/pdf/2505.22119v3",
    "published": "2025-05-28T08:47:13+00:00",
    "categories": [
      "hep-th"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2505.22118v1",
    "title": "Multilingual vs Crosslingual Retrieval of Fact-Checked Claims: A Tale of Two Approaches",
    "authors": [
      "Alan Ramponi",
      "Marco Rovera",
      "Robert Moro",
      "Sara Tonelli"
    ],
    "abstract": "Retrieval of previously fact-checked claims is a well-established task, whose\nautomation can assist professional fact-checkers in the initial steps of\ninformation verification. Previous works have mostly tackled the task\nmonolingually, i.e., having both the input and the retrieved claims in the same\nlanguage. However, especially for languages with a limited availability of\nfact-checks and in case of global narratives, such as pandemics, wars, or\ninternational politics, it is crucial to be able to retrieve claims across\nlanguages. In this work, we examine strategies to improve the multilingual and\ncrosslingual performance, namely selection of negative examples (in the\nsupervised) and re-ranking (in the unsupervised setting). We evaluate all\napproaches on a dataset containing posts and claims in 47 languages (283\nlanguage combinations). We observe that the best results are obtained by using\nLLM-based re-ranking, followed by fine-tuning with negative examples sampled\nusing a sentence similarity-based strategy. Most importantly, we show that\ncrosslinguality is a setup with its own unique characteristics compared to the\nmultilingual setup.",
    "pdf_url": "http://arxiv.org/pdf/2505.22118v1",
    "published": "2025-05-28T08:47:10+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.22117v1",
    "title": "The sulfur plume in the Horsehead nebula: New detections of S$_2$H, SH$^+$, and CO$^+$",
    "authors": [
      "Asunci√≥n Fuente",
      "Gisela Esplugues",
      "Pablo Rivi√®re-Marichalar",
      "David Navarro-Almaida",
      "Rafael Mart√≠n-Dom√©nech",
      "Guillermo M. Mu√±oz-Caro",
      "√Ålvaro S√°nchez-Monge",
      "Ang√®le Taillard",
      "H√©ctor Carrascosa",
      "Juli√°n J. Miranzo-Pastor",
      "Aitana Tasa-Chaveli",
      "Patricia Fern√°ndez-Ruiz",
      "Viviana V. Guzm√°n",
      "Javier R. Goicoechea",
      "Maryvonne Gerin",
      "Jerome Pety"
    ],
    "abstract": "Sulfur is essential for life, but its abundance and distribution in the\ninterstellar medium remain uncertain, with over 90% of sulfur undetected in\ncold molecular clouds. Sulfur allotropes (S$_{\\rm n}$) have been proposed as\npossible reservoirs, but the only detected interstellar molecule with a\ndisulfide bond is S$_2$H in the Horsehead Nebula, making the estimation of\nsulfur chains abundances difficult. Here we present total-power ALMA images of\nH$_2$S, S$_2$H, SO$_2$, CO$^+$, and SH$^+$ towards the Horsehead nebula. These\nobservations, with unprecedented sensitivity (rms $\\sim$ 1.5 mK), provide the\nfirst detections of SH$^+$ and CO$^+$ in this region, together with the\nidentification of a new S$_2$H line. The comparison of the spectroscopic images\nof H$_2$S, S$_2$H, SO$_2$, CO$^+$ and SH$^+$ shows that the S$_2$H emission\noriginates from a warm gas layer adjacent to the photodissociation front. The\nemission peak of S$_2$H is offset from those of reactive ions such as SH$^+$,\nCO$^+$, and SO$^+$, suggesting that gas-phase reactions involving SH$^+$ and\nH$_2$S are not the dominant formation pathway of S$_2$H. Instead, we propose\nthat S$_2$H is desorbed from irradiated grain surfaces by non-thermal\nprocesses. The SH$^+$ detection indicates that sulfur is not significantly\ndepleted at the UV-irradiated edge of the molecular cloud, arguing against a\nmajor refractory sulfur reservoir in the interior of molecular clouds.",
    "pdf_url": "http://arxiv.org/pdf/2505.22117v1",
    "published": "2025-05-28T08:46:08+00:00",
    "categories": [
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2505.22116v3",
    "title": "Multimodal Forecasting of Sparse Intraoperative Hypotension Events Powered by Language Model",
    "authors": [
      "Jintao Zhang",
      "Zirui Liu",
      "Mingyue Cheng",
      "Shilong Zhang",
      "Tingyue Pan",
      "Yitong zhou",
      "Qi Liu",
      "Yanhu Xie"
    ],
    "abstract": "Intraoperative hypotension (IOH) frequently occurs under general anesthesia\nand is strongly linked to adverse outcomes such as myocardial injury and\nincreased mortality. Despite its significance, IOH prediction is hindered by\nevent sparsity and the challenge of integrating static and dynamic data across\ndiverse patients. In this paper, we propose \\textbf{IOHFuseLM}, a multimodal\nlanguage model framework. To accurately identify and differentiate sparse\nhypotensive events, we leverage a two-stage training strategy. The first stage\ninvolves domain adaptive pretraining on IOH physiological time series augmented\nthrough diffusion methods, thereby enhancing the model sensitivity to patterns\nassociated with hypotension. Subsequently, task fine-tuning is performed on the\noriginal clinical dataset to further enhance the ability to distinguish\nnormotensive from hypotensive states. To enable multimodal fusion for each\npatient, we align structured clinical descriptions with the corresponding\nphysiological time series at the token level. Such alignment enables the model\nto capture individualized temporal patterns alongside their corresponding\nclinical semantics. In addition, we convert static patient attributes into\nstructured text to enrich personalized information. Experimental evaluations on\ntwo intraoperative datasets demonstrate that IOHFuseLM outperforms established\nbaselines in accurately identifying IOH events, highlighting its applicability\nin clinical decision support scenarios. Our code is publicly available to\npromote reproducibility at https://github.com/zjt-gpu/IOHFuseLM.",
    "pdf_url": "http://arxiv.org/pdf/2505.22116v3",
    "published": "2025-05-28T08:44:55+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.02019v2",
    "title": "ChatCFD: An LLM-Driven Agent for End-to-End CFD Automation with Domain-Specific Structured Reasoning",
    "authors": [
      "E Fan",
      "Kang Hu",
      "Zhuowen Wu",
      "Jiangyang Ge",
      "Jiawei Miao",
      "Yuzhi Zhang",
      "He Sun",
      "Weizong Wang",
      "Tianhan Zhang"
    ],
    "abstract": "Computational Fluid Dynamics (CFD) is essential for advancing scientific and\nengineering fields but is hindered by operational complexity, high expertise\nrequirements, and limited accessibility. This paper introduces ChatCFD, an\nautomated agent system for OpenFOAM simulations that processes multi-modal\ninputs (e.g., research papers, meshes) via an interactive interface, leveraging\nDeepSeek-R1 and DeepSeek-V3 large language models, a multi-agent architecture,\nand OpenFOAM knowledge. Its four-stage pipeline (Knowledge Base Construction,\nUser Input Processing, Case File Generation, and Execution and Error\nReflection) enables iterative trial-reflection-refinement for intricate setups,\nsupporting diverse physical models and external meshes. Validation on 205\nbenchmark tutorial cases, 110 perturbed variants, and 2 literature-derived\ncases shows ChatCFD's 82.1 percent operational success rate on basic cases,\noutperforming MetaOpenFOAM (6.2 percent) and Foam-Agent (42.3 percent), and\n60-80 percent on literature-derived complex cases. Turbulence model studies\nshow a 40 percent success rate for common models versus 10 percent for rare\nones like RNG k-epsilon. Physics coupling analyses reveal higher resource\ndemands for multi-physics-coupled cases, while LLM bias toward simpler setups\nintroduces persistent errors, such as dimensional inconsistency. Ablation\nstudies highlight the efficacy of RAG-based modules and reflection mechanisms.\nBy automating hypothesis testing and parameter exploration, ChatCFD accelerates\nscientific discovery in fluid mechanics and engineering, addressing LLM\nlimitations through structured design and showing strong potential as a modular\ncomponent in MCP-based agent networks for collaborative multi-agent systems,\npaving the way for scalable AI-driven CFD innovation. The code for ChatCFD is\navailable at https://github.com/ConMoo/ChatCFD.",
    "pdf_url": "http://arxiv.org/pdf/2506.02019v2",
    "published": "2025-05-28T08:43:49+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.22115v1",
    "title": "On an inverse problem for tree-like networks of elastic strings",
    "authors": [
      "S. A. Avdonin",
      "G. Leugering",
      "V. S. Mikhaylov"
    ],
    "abstract": "We consider the in-plane motion of elastic strings on tree-like network,\nobserved from the 'leaves'. We investigate the inverse problem of recovering\nnot only the physical properties i.e. the 'optical lengths' of each string, but\nalso the topology of the tree which is represented by the edge degrees and the\nangles between branching edges. To this end use the boundary control method for\nwave equations established in~\\cite{AK,B}. It is shown that under generic\nassumptions the inverse problem can be solved by applying measurements at all\nleaves, the root of the tree being fixed.",
    "pdf_url": "http://arxiv.org/pdf/2505.22115v1",
    "published": "2025-05-28T08:43:19+00:00",
    "categories": [
      "math.AP",
      "math.SP"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2505.22114v1",
    "title": "BiMi Sheets: Infosheets for bias mitigation methods",
    "authors": [
      "MaryBeth Defrance",
      "Guillaume Bied",
      "Maarten Buyl",
      "Jefrey Lijffijt",
      "Tijl De Bie"
    ],
    "abstract": "Over the past 15 years, hundreds of bias mitigation methods have been\nproposed in the pursuit of fairness in machine learning (ML). However,\nalgorithmic biases are domain-, task-, and model-specific, leading to a\n`portability trap': bias mitigation solutions in one context may not be\nappropriate in another. Thus, a myriad of design choices have to be made when\ncreating a bias mitigation method, such as the formalization of fairness it\npursues, and where and how it intervenes in the ML pipeline. This creates\nchallenges in benchmarking and comparing the relative merits of different bias\nmitigation methods, and limits their uptake by practitioners.\n  We propose BiMi Sheets as a portable, uniform guide to document the design\nchoices of any bias mitigation method. This enables researchers and\npractitioners to quickly learn its main characteristics and to compare with\ntheir desiderata. Furthermore, the sheets' structure allow for the creation of\na structured database of bias mitigation methods. In order to foster the\nsheets' adoption, we provide a platform for finding and creating BiMi Sheets at\nbimisheet.com.",
    "pdf_url": "http://arxiv.org/pdf/2505.22114v1",
    "published": "2025-05-28T08:41:35+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.22113v1",
    "title": "THINK-Bench: Evaluating Thinking Efficiency and Chain-of-Thought Quality of Large Reasoning Models",
    "authors": [
      "Zhiyuan Li",
      "Yi Chang",
      "Yuan Wu"
    ],
    "abstract": "Large reasoning models (LRMs) have achieved impressive performance in complex\ntasks, often outperforming conventional large language models (LLMs). However,\nthe prevalent issue of overthinking severely limits their computational\nefficiency. Overthinking occurs when models generate excessive and redundant\ntokens that contribute little to accurate outcomes, especially in simple tasks,\nresulting in a significant waste of computational resources. To systematically\ninvestigate this issue, we introduce Think-Bench, a benchmark designed to\nevaluate the reasoning efficiency of LRMs. We also propose novel efficiency\nmetrics and conduct a comprehensive evaluation of various LRMs across multiple\ndimensions, including the reasoning process, outcome quality, and\nchain-of-thought (CoT) characteristics. Our analysis reveals that most LRMs\nexhibit overthinking in handling easy questions, generating unnecessarily\nlengthy reasoning chains. While many LRMs demonstrate high CoT quality, several\nsuffer from low efficiency. We hope that Think-Bench can serve as a robust\nfoundation for advancing research into LRMs.",
    "pdf_url": "http://arxiv.org/pdf/2505.22113v1",
    "published": "2025-05-28T08:41:14+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.22112v1",
    "title": "Visual Large Language Models Exhibit Human-Level Cognitive Flexibility in the Wisconsin Card Sorting Test",
    "authors": [
      "Guangfu Hao",
      "Frederic Alexandre",
      "Shan Yu"
    ],
    "abstract": "Cognitive flexibility has been extensively studied in human cognition but\nremains relatively unexplored in the context of Visual Large Language Models\n(VLLMs). This study assesses the cognitive flexibility of state-of-the-art\nVLLMs (GPT-4o, Gemini-1.5 Pro, and Claude-3.5 Sonnet) using the Wisconsin Card\nSorting Test (WCST), a classic measure of set-shifting ability. Our results\nreveal that VLLMs achieve or surpass human-level set-shifting capabilities\nunder chain-of-thought prompting with text-based inputs. However, their\nabilities are highly influenced by both input modality and prompting strategy.\nIn addition, we find that through role-playing, VLLMs can simulate various\nfunctional deficits aligned with patients having impairments in cognitive\nflexibility, suggesting that VLLMs may possess a cognitive architecture, at\nleast regarding the ability of set-shifting, similar to the brain. This study\nreveals the fact that VLLMs have already approached the human level on a key\ncomponent underlying our higher cognition, and highlights the potential to use\nthem to emulate complex brain processes.",
    "pdf_url": "http://arxiv.org/pdf/2505.22112v1",
    "published": "2025-05-28T08:40:55+00:00",
    "categories": [
      "cs.AI",
      "q-bio.NC"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.22111v2",
    "title": "Autoregression-free video prediction using diffusion model for mitigating error propagation",
    "authors": [
      "Woonho Ko",
      "Jin Bok Park",
      "Il Yong Chun"
    ],
    "abstract": "Existing long-term video prediction methods often rely on an autoregressive\nvideo prediction mechanism. However, this approach suffers from error\npropagation, particularly in distant future frames. To address this limitation,\nthis paper proposes the first AutoRegression-Free (ARFree) video prediction\nframework using diffusion models. Different from an autoregressive video\nprediction mechanism, ARFree directly predicts any future frame tuples from the\ncontext frame tuple. The proposed ARFree consists of two key components: 1) a\nmotion prediction module that predicts a future motion using motion feature\nextracted from the context frame tuple; 2) a training method that improves\nmotion continuity and contextual consistency between adjacent future frame\ntuples. Our experiments with two benchmark datasets show that the proposed\nARFree video prediction framework outperforms several state-of-the-art video\nprediction methods.",
    "pdf_url": "http://arxiv.org/pdf/2505.22111v2",
    "published": "2025-05-28T08:40:38+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.00042v1",
    "title": "Enhancing Tool Learning in Large Language Models with Hierarchical Error Checklists",
    "authors": [
      "Yue Cui",
      "Liuyi Yao",
      "Shuchang Tao",
      "Weijie Shi",
      "Yaliang Li",
      "Bolin Ding",
      "Xiaofang Zhou"
    ],
    "abstract": "Large language models (LLMs) have significantly advanced natural language\nprocessing, particularly through the integration of external tools and APIs.\nHowever, their effectiveness is frequently hampered by parameter mis-filling\nduring tool calling. In this paper, we propose the Hierarchical Tool Error\nChecklist (HiTEC) framework to systematically diagnose and mitigate\ntool-calling errors without relying on extensive real-world interactions. HiTEC\nintroduces a two-tiered approach: a global error checklist that identifies\ncommon, cross-tool issues, and a local error checklist that targets\ntool-specific and contextual failures. Building on this structure, we propose\ntwo deployments: HiTEC-In Context Learning (HiTEC-ICL) and\nHiTEC-Kahneman-Tversky Optimization (HiTEC-KTO). HiTEC-ICL embeds the global\nchecklist in the initial prompts and leverages a two-round conversational\ninteraction to dynamically refine parameter handling, while HiTEC-KTO generates\nhigh-quality negative examples to drive fine-tuning via preference-based\noptimization. Extensive experiments across five public datasets demonstrate\nthat our framework significantly improves parameter-filling accuracy and\ntool-calling success rates compared to baseline methods.",
    "pdf_url": "http://arxiv.org/pdf/2506.00042v1",
    "published": "2025-05-28T08:39:35+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.23830v1",
    "title": "EvoMoE: Expert Evolution in Mixture of Experts for Multimodal Large Language Models",
    "authors": [
      "Linglin Jing",
      "Yuting Gao",
      "Zhigang Wang",
      "Wang Lan",
      "Yiwen Tang",
      "Wenhai Wang",
      "Kaipeng Zhang",
      "Qingpei Guo"
    ],
    "abstract": "Recent advancements have shown that the Mixture of Experts (MoE) approach\nsignificantly enhances the capacity of large language models (LLMs) and\nimproves performance on downstream tasks. Building on these promising results,\nmulti-modal large language models (MLLMs) have increasingly adopted MoE\ntechniques. However, existing multi-modal MoE tuning methods typically face two\nkey challenges: expert uniformity and router rigidity. Expert uniformity occurs\nbecause MoE experts are often initialized by simply replicating the FFN\nparameters from LLMs, leading to homogenized expert functions and weakening the\nintended diversification of the MoE architecture. Meanwhile, router rigidity\nstems from the prevalent use of static linear routers for expert selection,\nwhich fail to distinguish between visual and textual tokens, resulting in\nsimilar expert distributions for image and text. To address these limitations,\nwe propose EvoMoE, an innovative MoE tuning framework. EvoMoE introduces a\nmeticulously designed expert initialization strategy that progressively evolves\nmultiple robust experts from a single trainable expert, a process termed expert\nevolution that specifically targets severe expert homogenization. Furthermore,\nwe introduce the Dynamic Token-aware Router (DTR), a novel routing mechanism\nthat allocates input tokens to appropriate experts based on their modality and\nintrinsic token values. This dynamic routing is facilitated by hypernetworks,\nwhich dynamically generate routing weights tailored for each individual token.\nExtensive experiments demonstrate that EvoMoE significantly outperforms other\nsparse MLLMs across a variety of multi-modal benchmarks, including MME,\nMMBench, TextVQA, and POPE. Our results highlight the effectiveness of EvoMoE\nin enhancing the performance of MLLMs by addressing the critical issues of\nexpert uniformity and router rigidity.",
    "pdf_url": "http://arxiv.org/pdf/2505.23830v1",
    "published": "2025-05-28T08:38:39+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.22110v1",
    "title": "Some questions about the regularity and the uniqueness of solutions of parabolic partial differential equations",
    "authors": [
      "Inmaculada Gayte Delgado",
      "Irene Mar√≠n Gayte"
    ],
    "abstract": "This work obtains a fixed-point equation for the solution of linear parabolic\npartial differential problems based on solutions to heat problems. This is a\npointwise equality, so we have required non-standard techniques that involve\nthe study of the sign of certain solutions to linear parabolic problems. This\nfixed-point equation implies regularity properties of solutions to parabolic\nproblems, not necessarily linear, and this allows us to prove the uniqueness of\nthe solution in three dimensions for the Navier-Stokes problem.",
    "pdf_url": "http://arxiv.org/pdf/2505.22110v1",
    "published": "2025-05-28T08:38:14+00:00",
    "categories": [
      "math.AP",
      "35Q30, 49K20, 76D05, 93C95"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2505.22109v1",
    "title": "The quest for the GRAph Level autoEncoder (GRALE)",
    "authors": [
      "Paul Krzakala",
      "Gabriel Melo",
      "Charlotte Laclau",
      "Florence d'Alch√©-Buc",
      "R√©mi Flamary"
    ],
    "abstract": "Although graph-based learning has attracted a lot of attention, graph\nrepresentation learning is still a challenging task whose resolution may impact\nkey application fields such as chemistry or biology. To this end, we introduce\nGRALE, a novel graph autoencoder that encodes and decodes graphs of varying\nsizes into a shared embedding space. GRALE is trained using an Optimal\nTransport-inspired loss that compares the original and reconstructed graphs and\nleverages a differentiable node matching module, which is trained jointly with\nthe encoder and decoder. The proposed attention-based architecture relies on\nEvoformer, the core component of AlphaFold, which we extend to support both\ngraph encoding and decoding. We show, in numerical experiments on simulated and\nmolecular data, that GRALE enables a highly general form of pre-training,\napplicable to a wide range of downstream tasks, from classification and\nregression to more complex tasks such as graph interpolation, editing,\nmatching, and prediction.",
    "pdf_url": "http://arxiv.org/pdf/2505.22109v1",
    "published": "2025-05-28T08:37:33+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.22108v2",
    "title": "Inclusive, Differentially Private Federated Learning for Clinical Data",
    "authors": [
      "Santhosh Parampottupadam",
      "Melih Co≈üƒüun",
      "Sarthak Pati",
      "Maximilian Zenk",
      "Saikat Roy",
      "Dimitrios Bounias",
      "Benjamin Hamm",
      "Sinem Sav",
      "Ralf Floca",
      "Klaus Maier-Hein"
    ],
    "abstract": "Federated Learning (FL) offers a promising approach for training clinical AI\nmodels without centralizing sensitive patient data. However, its real-world\nadoption is hindered by challenges related to privacy, resource constraints,\nand compliance. Existing Differential Privacy (DP) approaches often apply\nuniform noise, which disproportionately degrades model performance, even among\nwell-compliant institutions. In this work, we propose a novel compliance-aware\nFL framework that enhances DP by adaptively adjusting noise based on\nquantifiable client compliance scores. Additionally, we introduce a compliance\nscoring tool based on key healthcare and security standards to promote secure,\ninclusive, and equitable participation across diverse clinical settings.\nExtensive experiments on public datasets demonstrate that integrating\nunder-resourced, less compliant clinics with highly regulated institutions\nyields accuracy improvements of up to 15% over traditional FL. This work\nadvances FL by balancing privacy, compliance, and performance, making it a\nviable solution for real-world clinical workflows in global healthcare.",
    "pdf_url": "http://arxiv.org/pdf/2505.22108v2",
    "published": "2025-05-28T08:36:21+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR",
      "cs.DC"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.22107v4",
    "title": "Curse of High Dimensionality Issue in Transformer for Long-context Modeling",
    "authors": [
      "Shuhai Zhang",
      "Zeng You",
      "Yaofo Chen",
      "Zhiquan Wen",
      "Qianyue Wang",
      "Zhijie Qiu",
      "Yuanqing Li",
      "Mingkui Tan"
    ],
    "abstract": "Transformer-based large language models (LLMs) excel in natural language\nprocessing tasks by capturing long-range dependencies through self-attention\nmechanisms. However, long-context modeling faces significant computational\ninefficiencies due to \\textit{redundant} attention computations: while\nattention weights are often \\textit{sparse}, all tokens consume \\textit{equal}\ncomputational resources. In this paper, we reformulate traditional\nprobabilistic sequence modeling as a \\textit{supervised learning task},\nenabling the separation of relevant and irrelevant tokens and providing a\nclearer understanding of redundancy. Based on this reformulation, we\ntheoretically analyze attention sparsity, revealing that only a few tokens\nsignificantly contribute to predictions. Building on this, we formulate\nattention optimization as a linear coding problem and propose a \\textit{group\ncoding strategy}, theoretically showing its ability to improve robustness\nagainst random noise and enhance learning efficiency. Motivated by this, we\npropose \\textit{Dynamic Group Attention} (DGA), which leverages the group\ncoding to explicitly reduce redundancy by aggregating less important tokens\nduring attention computation. Empirical results show that our DGA significantly\nreduces computational costs while maintaining competitive performance.Code is\navailable at https://github.com/bolixinyu/DynamicGroupAttention.",
    "pdf_url": "http://arxiv.org/pdf/2505.22107v4",
    "published": "2025-05-28T08:34:46+00:00",
    "categories": [
      "cs.CL",
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.22106v1",
    "title": "AudioTurbo: Fast Text-to-Audio Generation with Rectified Diffusion",
    "authors": [
      "Junqi Zhao",
      "Jinzheng Zhao",
      "Haohe Liu",
      "Yun Chen",
      "Lu Han",
      "Xubo Liu",
      "Mark Plumbley",
      "Wenwu Wang"
    ],
    "abstract": "Diffusion models have significantly improved the quality and diversity of\naudio generation but are hindered by slow inference speed. Rectified flow\nenhances inference speed by learning straight-line ordinary differential\nequation (ODE) paths. However, this approach requires training a flow-matching\nmodel from scratch and tends to perform suboptimally, or even poorly, at low\nstep counts. To address the limitations of rectified flow while leveraging the\nadvantages of advanced pre-trained diffusion models, this study integrates\npre-trained models with the rectified diffusion method to improve the\nefficiency of text-to-audio (TTA) generation. Specifically, we propose\nAudioTurbo, which learns first-order ODE paths from deterministic noise sample\npairs generated by a pre-trained TTA model. Experiments on the AudioCaps\ndataset demonstrate that our model, with only 10 sampling steps, outperforms\nprior models and reduces inference to 3 steps compared to a flow-matching-based\nacceleration model.",
    "pdf_url": "http://arxiv.org/pdf/2505.22106v1",
    "published": "2025-05-28T08:33:58+00:00",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD"
  },
  {
    "id": "http://arxiv.org/abs/2505.22105v1",
    "title": "Adapting Segment Anything Model for Power Transmission Corridor Hazard Segmentation",
    "authors": [
      "Hang Chen",
      "Maoyuan Ye",
      "Peng Yang",
      "Haibin He",
      "Juhua Liu",
      "Bo Du"
    ],
    "abstract": "Power transmission corridor hazard segmentation (PTCHS) aims to separate\ntransmission equipment and surrounding hazards from complex background,\nconveying great significance to maintaining electric power transmission safety.\nRecently, the Segment Anything Model (SAM) has emerged as a foundational vision\nmodel and pushed the boundaries of segmentation tasks. However, SAM struggles\nto deal with the target objects in complex transmission corridor scenario,\nespecially those with fine structure. In this paper, we propose ELE-SAM,\nadapting SAM for the PTCHS task. Technically, we develop a Context-Aware Prompt\nAdapter to achieve better prompt tokens via incorporating global-local features\nand focusing more on key regions. Subsequently, to tackle the hazard objects\nwith fine structure in complex background, we design a High-Fidelity Mask\nDecoder by leveraging multi-granularity mask features and then scaling them to\na higher resolution. Moreover, to train ELE-SAM and advance this field, we\nconstruct the ELE-40K benchmark, the first large-scale and real-world dataset\nfor PTCHS including 44,094 image-mask pairs. Experimental results for ELE-40K\ndemonstrate the superior performance that ELE-SAM outperforms the baseline\nmodel with the average 16.8% mIoU and 20.6% mBIoU performance improvement.\nMoreover, compared with the state-of-the-art method on HQSeg-44K, the average\n2.9% mIoU and 3.8% mBIoU absolute improvements further validate the\neffectiveness of our method on high-quality generic object segmentation. The\nsource code and dataset are available at https://github.com/Hhaizee/ELE-SAM.",
    "pdf_url": "http://arxiv.org/pdf/2505.22105v1",
    "published": "2025-05-28T08:32:55+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.22104v1",
    "title": "Efficient Dynamic Shielding for Parametric Safety Specifications",
    "authors": [
      "Davide Corsi",
      "Kaushik Mallik",
      "Andoni Rodriguez",
      "Cesar Sanchez"
    ],
    "abstract": "Shielding has emerged as a promising approach for ensuring safety of\nAI-controlled autonomous systems. The algorithmic goal is to compute a shield,\nwhich is a runtime safety enforcement tool that needs to monitor and intervene\nthe AI controller's actions if safety could be compromised otherwise.\nTraditional shields are designed statically for a specific safety requirement.\nTherefore, if the safety requirement changes at runtime due to changing\noperating conditions, the shield needs to be recomputed from scratch, causing\ndelays that could be fatal. We introduce dynamic shields for parametric safety\nspecifications, which are succinctly represented sets of all possible safety\nspecifications that may be encountered at runtime. Our dynamic shields are\nstatically designed for a given safety parameter set, and are able to\ndynamically adapt as the true safety specification (permissible by the\nparameters) is revealed at runtime. The main algorithmic novelty lies in the\ndynamic adaptation procedure, which is a simple and fast algorithm that\nutilizes known features of standard safety shields, like maximal\npermissiveness. We report experimental results for a robot navigation problem\nin unknown territories, where the safety specification evolves as new obstacles\nare discovered at runtime. In our experiments, the dynamic shields took a few\nminutes for their offline design, and took between a fraction of a second and a\nfew seconds for online adaptation at each step, whereas the brute-force online\nrecomputation approach was up to 5 times slower.",
    "pdf_url": "http://arxiv.org/pdf/2505.22104v1",
    "published": "2025-05-28T08:30:03+00:00",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.LO",
      "cs.RO",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.22103v1",
    "title": "Optimized Schwarz methods for heterogeneous heat transfer problems",
    "authors": [
      "Martin J. Gander",
      "Liu-Di Lu",
      "Tingting Wu"
    ],
    "abstract": "We present here nonoverlapping optimized Schwarz methods applied to heat\ntransfer problems with heterogeneous diffusion coefficients. After a Laplace\ntransform in time, we derive the error equation and obtain the convergence\nfactor. The optimal transmission operators are nonlocal, and thus inconvenient\nto use in practice. We introduce three versions of local approximations for the\ntransmission parameter, and provide a detailed analysis at the continuous level\nin each case to identify the best local transmission conditions. Numerical\nexperiments are presented to illustrate the performance of each local\ntransmission condition. As shown in our analysis, local transmission\nconditions, which are scaled appropriately with respect to the heterogeneous\ndiffusion coefficients, are more efficient and robust especially when the\ndiscontinuity of the diffusion coefficient is large.",
    "pdf_url": "http://arxiv.org/pdf/2505.22103v1",
    "published": "2025-05-28T08:29:08+00:00",
    "categories": [
      "math.NA",
      "cs.NA"
    ],
    "primary_category": "math.NA"
  },
  {
    "id": "http://arxiv.org/abs/2505.22102v2",
    "title": "The Kick Velocity Distribution of Isolated Neutron Stars",
    "authors": [
      "Paul Disberg",
      "Ilya Mandel"
    ],
    "abstract": "Neutron stars (NSs) are thought to receive natal kicks at their formation in\nsupernovae. In order to investigate the magnitude of these kicks, we analyze\nthe proper motions and distance estimates -- either through parallax or\ndispersion measures -- of young isolated pulsars and infer their\nthree-dimensional velocities relative to their local standard of rest. We find\nthat the velocities based on parallax distances of pulsars younger than 10 Myr\nfollow a log-normal distribution with $\\mu=5.60\\pm0.12$ and\n$\\sigma=0.68\\pm0.10$, peaking at ${\\sim}$150--200 km/s, which we adopt as our\nfiducial kick distribution. Using a previously established method that infers\nkick magnitudes through the eccentricity of Galactic trajectories, we also\nestimate the kick velocities of older pulsars, which we find to be consistent\nwith our fiducial kick distribution. A log-normal fit to all pulsars with ages\nbelow 40 Myr yields a more constraining (but possibly more prone to systematic\nerrors) fit with $\\mu=5.67\\pm0.10$ and $\\sigma=0.59\\pm0.08$, respectively.\nMoreover, we (1) resolve the tension between our results and the Maxwellian\ndistribution found by Hobbs et al. (2005), which has a ${\\sim}50\\%$ higher\nmedian velocity, by showing that their analysis is missing a Jacobian needed to\ncorrect for its logarithmic histogram bin sizes, and (2) argue that the\nbimodality found by others is not statistically significant and that previous\nresults are consistent with our inferred kick distribution, effectively\nreconciling the literature on observed NS kicks.",
    "pdf_url": "http://arxiv.org/pdf/2505.22102v2",
    "published": "2025-05-28T08:27:35+00:00",
    "categories": [
      "astro-ph.HE",
      "astro-ph.GA",
      "astro-ph.SR"
    ],
    "primary_category": "astro-ph.HE"
  },
  {
    "id": "http://arxiv.org/abs/2505.22101v1",
    "title": "MemOS: An Operating System for Memory-Augmented Generation (MAG) in Large Language Models",
    "authors": [
      "Zhiyu Li",
      "Shichao Song",
      "Hanyu Wang",
      "Simin Niu",
      "Ding Chen",
      "Jiawei Yang",
      "Chenyang Xi",
      "Huayi Lai",
      "Jihao Zhao",
      "Yezhaohui Wang",
      "Junpeng Ren",
      "Zehao Lin",
      "Jiahao Huo",
      "Tianyi Chen",
      "Kai Chen",
      "Kehang Li",
      "Zhiqiang Yin",
      "Qingchen Yu",
      "Bo Tang",
      "Hongkang Yang",
      "Zhi-Qin John Xu",
      "Feiyu Xiong"
    ],
    "abstract": "Large Language Models (LLMs) have emerged as foundational infrastructure in\nthe pursuit of Artificial General Intelligence (AGI). Despite their remarkable\ncapabilities in language perception and generation, current LLMs fundamentally\nlack a unified and structured architecture for handling memory. They primarily\nrely on parametric memory (knowledge encoded in model weights) and ephemeral\nactivation memory (context-limited runtime states). While emerging methods like\nRetrieval-Augmented Generation (RAG) incorporate plaintext memory, they lack\nlifecycle management and multi-modal integration, limiting their capacity for\nlong-term knowledge evolution. To address this, we introduce MemOS, a memory\noperating system designed for LLMs that, for the first time, elevates memory to\na first-class operational resource. It builds unified mechanisms for\nrepresentation, organization, and governance across three core memory types:\nparametric, activation, and plaintext. At its core is the MemCube, a\nstandardized memory abstraction that enables tracking, fusion, and migration of\nheterogeneous memory, while offering structured, traceable access across tasks\nand contexts. MemOS establishes a memory-centric execution framework with\nstrong controllability, adaptability, and evolvability. It fills a critical gap\nin current LLM infrastructure and lays the groundwork for continual adaptation,\npersonalized intelligence, and cross-platform coordination in next-generation\nintelligent systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.22101v1",
    "published": "2025-05-28T08:27:12+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.22100v1",
    "title": "Symmetry reduction for testing $k$-block-positivity via extendibility",
    "authors": [
      "Qian Chen",
      "Beno√Æt Collins",
      "Omar Fawzi"
    ],
    "abstract": "We study the problem of testing $k$-block-positivity via symmetric\n$N$-extendibility by taking the tensor product with a $k$-dimensional maximally\nentangled state. We exploit the unitary symmetry of the maximally entangled\nstate to reduce the size of the corresponding semidefinite programs (SDP). For\nexample, for $k=2$, the SDP is reduced from one block of size $2^{N+1} d^{N+1}$\nto $\\lfloor \\frac{N+1}{2} \\rfloor$ blocks of size $\\approx O( (N-1)^{-1}\n2^{N+1} d^{N+1} )$.",
    "pdf_url": "http://arxiv.org/pdf/2505.22100v1",
    "published": "2025-05-28T08:26:34+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.22099v1",
    "title": "On the Transferability and Discriminability of Repersentation Learning in Unsupervised Domain Adaptation",
    "authors": [
      "Wenwen Qiang",
      "Ziyin Gu",
      "Lingyu Si",
      "Jiangmeng Li",
      "Changwen Zheng",
      "Fuchun Sun",
      "Hui Xiong"
    ],
    "abstract": "In this paper, we addressed the limitation of relying solely on distribution\nalignment and source-domain empirical risk minimization in Unsupervised Domain\nAdaptation (UDA). Our information-theoretic analysis showed that this standard\nadversarial-based framework neglects the discriminability of target-domain\nfeatures, leading to suboptimal performance. To bridge this\ntheoretical-practical gap, we defined \"good representation learning\" as\nguaranteeing both transferability and discriminability, and proved that an\nadditional loss term targeting target-domain discriminability is necessary.\nBuilding on these insights, we proposed a novel adversarial-based UDA framework\nthat explicitly integrates a domain alignment objective with a\ndiscriminability-enhancing constraint. Instantiated as Domain-Invariant\nRepresentation Learning with Global and Local Consistency (RLGLC), our method\nleverages Asymmetrically-Relaxed Wasserstein of Wasserstein Distance (AR-WWD)\nto address class imbalance and semantic dimension weighting, and employs a\nlocal consistency mechanism to preserve fine-grained target-domain\ndiscriminative information. Extensive experiments across multiple benchmark\ndatasets demonstrate that RLGLC consistently surpasses state-of-the-art\nmethods, confirming the value of our theoretical perspective and underscoring\nthe necessity of enforcing both transferability and discriminability in\nadversarial-based UDA.",
    "pdf_url": "http://arxiv.org/pdf/2505.22099v1",
    "published": "2025-05-28T08:24:43+00:00",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.09055v1",
    "title": "Learn Like Feynman: Developing and Testing an AI-Driven Feynman Bot",
    "authors": [
      "Akshaya Rajesh",
      "Sumbul Khan"
    ],
    "abstract": "The Feynman learning technique is an active learning strategy that helps\nlearners simplify complex information through student-led teaching and\ndiscussion. In this paper, we present the development and usability testing of\nthe Feynman Bot, which uses the Feynman technique to assist self-regulated\nlearners who lack peer or instructor support. The Bot embodies the Feynman\nlearning technique by encouraging learners to discuss their lecture material in\na question-answer-driven discussion format. The Feynman Bot was developed using\na large language model with Langchain in a Retrieval-Augmented-Generation\nframework to leverage the reasoning capability required to generate effective\ndiscussion-oriented questions. To test the Feynman bot, a controlled experiment\nwas conducted over three days with fourteen participants. Formative and\nsummative assessments were conducted, followed by a self-efficacy survey. We\nfound that participants who used the Feynman Bot experienced higher learning\ngains than the Passive Learners' group. Moreover, Feynman Bot Learners' had a\nhigher level of comfort with the subject after using the bot. We also found\ntyping to be the preferred input modality method over speech, when interacting\nwith the bot. The high learning gains and improved confidence with study\nmaterial brought about by the Feynman Bot makes it a promising tool for\nself-regulated learners.",
    "pdf_url": "http://arxiv.org/pdf/2506.09055v1",
    "published": "2025-05-28T08:22:19+00:00",
    "categories": [
      "physics.ed-ph",
      "J.4"
    ],
    "primary_category": "physics.ed-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.22098v1",
    "title": "UAVPairs: A Challenging Benchmark for Match Pair Retrieval of Large-scale UAV Images",
    "authors": [
      "Junhuan Liu",
      "San Jiang",
      "Wei Ge",
      "Wei Huang",
      "Bingxuan Guo",
      "Qingquan Li"
    ],
    "abstract": "The primary contribution of this paper is a challenging benchmark dataset,\nUAVPairs, and a training pipeline designed for match pair retrieval of\nlarge-scale UAV images. First, the UAVPairs dataset, comprising 21,622\nhigh-resolution images across 30 diverse scenes, is constructed; the 3D points\nand tracks generated by SfM-based 3D reconstruction are employed to define the\ngeometric similarity of image pairs, ensuring genuinely matchable image pairs\nare used for training. Second, to solve the problem of expensive mining cost\nfor global hard negative mining, a batched nontrivial sample mining strategy is\nproposed, leveraging the geometric similarity and multi-scene structure of the\nUAVPairs to generate training samples as to accelerate training. Third,\nrecognizing the limitation of pair-based losses, the ranked list loss is\ndesigned to improve the discrimination of image retrieval models, which\noptimizes the global similarity structure constructed from the positive set and\nnegative set. Finally, the effectiveness of the UAVPairs dataset and training\npipeline is validated through comprehensive experiments on three distinct\nlarge-scale UAV datasets. The experiment results demonstrate that models\ntrained with the UAVPairs dataset and the ranked list loss achieve\nsignificantly improved retrieval accuracy compared to models trained on\nexisting datasets or with conventional losses. Furthermore, these improvements\ntranslate to enhanced view graph connectivity and higher quality of\nreconstructed 3D models. The models trained by the proposed approach perform\nmore robustly compared with hand-crafted global features, particularly in\nchallenging repetitively textured scenes and weakly textured scenes. For match\npair retrieval of large-scale UAV images, the trained image retrieval models\noffer an effective solution. The dataset would be made publicly available at\nhttps://github.com/json87/UAVPairs.",
    "pdf_url": "http://arxiv.org/pdf/2505.22098v1",
    "published": "2025-05-28T08:21:05+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.22097v2",
    "title": "From the Rose-DuBois Ansatz of Hot Spot Fields to the Instanton Solution: a Pedestrian Presentation",
    "authors": [
      "Philippe Mounaix"
    ],
    "abstract": "This paper gives a pedestrian presentation of some technical results recently\npublished in mathematical physics with non-trivial implications for\nlaser-plasma interaction. The aim is to get across the main results without\ngoing into the details of the calculations, nor offering a specialist's user\nguide, but by focusing conceptually on how these results modify the\ncommonly-held description -- in terms of laser hot spot fields -- of\nbackscattering instabilities with a spatially smoothed laser beam. The intended\nreaders are plasma physicists as well as graduate students interested in\nlaser-plasma interaction. No prior knowledge of scattering instabilities is\nrequired. Step by step, we explain how the laser hot spots are gradually\nreplaced with other structures, called instantons, as the amplification of the\nscattered light increases. In the amplification range of interest for\nlaser-plasma interaction, instanton--hot spot complexes tend to appear in the\nlaser field (in addition to the expected hot spots), with a non-negligible\nprobability. For even larger amplifications and systems longer than a hot spot\nlength, the hot spot field description is clearly invalidated by the instanton\ntakeover.",
    "pdf_url": "http://arxiv.org/pdf/2505.22097v2",
    "published": "2025-05-28T08:18:42+00:00",
    "categories": [
      "physics.plasm-ph"
    ],
    "primary_category": "physics.plasm-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.22096v1",
    "title": "Knowledge Base Construction for Knowledge-Augmented Text-to-SQL",
    "authors": [
      "Jinheon Baek",
      "Horst Samulowitz",
      "Oktie Hassanzadeh",
      "Dharmashankar Subramanian",
      "Sola Shirai",
      "Alfio Gliozzo",
      "Debarun Bhattacharjya"
    ],
    "abstract": "Text-to-SQL aims to translate natural language queries into SQL statements,\nwhich is practical as it enables anyone to easily retrieve the desired\ninformation from databases. Recently, many existing approaches tackle this\nproblem with Large Language Models (LLMs), leveraging their strong capability\nin understanding user queries and generating corresponding SQL code. Yet, the\nparametric knowledge in LLMs might be limited to covering all the diverse and\ndomain-specific queries that require grounding in various database schemas,\nwhich makes generated SQLs less accurate oftentimes. To tackle this, we propose\nconstructing the knowledge base for text-to-SQL, a foundational source of\nknowledge, from which we retrieve and generate the necessary knowledge for\ngiven queries. In particular, unlike existing approaches that either manually\nannotate knowledge or generate only a few pieces of knowledge for each query,\nour knowledge base is comprehensive, which is constructed based on a\ncombination of all the available questions and their associated database\nschemas along with their relevant knowledge, and can be reused for unseen\ndatabases from different datasets and domains. We validate our approach on\nmultiple text-to-SQL datasets, considering both the overlapping and\nnon-overlapping database scenarios, where it outperforms relevant baselines\nsubstantially.",
    "pdf_url": "http://arxiv.org/pdf/2505.22096v1",
    "published": "2025-05-28T08:17:58+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.22095v1",
    "title": "Learning to Route Queries Across Knowledge Bases for Step-wise Retrieval-Augmented Reasoning",
    "authors": [
      "Chunyi Peng",
      "Zhipeng Xu",
      "Zhenghao Liu",
      "Yishan Li",
      "Yukun Yan",
      "Shuo Wang",
      "Zhiyuan Liu",
      "Yu Gu",
      "Minghe Yu",
      "Ge Yu",
      "Maosong Sun"
    ],
    "abstract": "Multimodal Retrieval-Augmented Generation (MRAG) has shown promise in\nmitigating hallucinations in Multimodal Large Language Models (MLLMs) by\nincorporating external knowledge during generation. Existing MRAG methods\ntypically adopt a static retrieval pipeline that fetches relevant information\nfrom multiple Knowledge Bases (KBs), followed by a refinement step. However,\nthese approaches overlook the reasoning and planning capabilities of MLLMs to\ndynamically determine how to interact with different KBs during the reasoning\nprocess. To address this limitation, we propose R1-Router, a novel MRAG\nframework that learns to decide when and where to retrieve knowledge based on\nthe evolving reasoning state. Specifically, R1-Router can generate follow-up\nqueries according to the current reasoning step, routing these intermediate\nqueries to the most suitable KB, and integrating external knowledge into a\ncoherent reasoning trajectory to answer the original query. Furthermore, we\nintroduce Step-wise Group Relative Policy Optimization (Step-GRPO), a tailored\nreinforcement learning algorithm that assigns step-specific rewards to optimize\nthe reasoning behavior of MLLMs. Experimental results on various open-domain QA\nbenchmarks across multiple modalities demonstrate that R1-Router outperforms\nbaseline models by over 7%. Further analysis shows that R1-Router can\nadaptively and effectively leverage diverse KBs, reducing unnecessary\nretrievals and improving both efficiency and accuracy.",
    "pdf_url": "http://arxiv.org/pdf/2505.22095v1",
    "published": "2025-05-28T08:17:57+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.22094v5",
    "title": "ReinFlow: Fine-tuning Flow Matching Policy with Online Reinforcement Learning",
    "authors": [
      "Tonghe Zhang",
      "Chao Yu",
      "Sichang Su",
      "Yu Wang"
    ],
    "abstract": "We propose ReinFlow, a simple yet effective online reinforcement learning\n(RL) framework that fine-tunes a family of flow matching policies for\ncontinuous robotic control. Derived from rigorous RL theory, ReinFlow injects\nlearnable noise into a flow policy's deterministic path, converting the flow\ninto a discrete-time Markov Process for exact and straightforward likelihood\ncomputation. This conversion facilitates exploration and ensures training\nstability, enabling ReinFlow to fine-tune diverse flow model variants,\nincluding Rectified Flow [35] and Shortcut Models [19], particularly at very\nfew or even one denoising step. We benchmark ReinFlow in representative\nlocomotion and manipulation tasks, including long-horizon planning with visual\ninput and sparse reward. The episode reward of Rectified Flow policies obtained\nan average net growth of 135.36% after fine-tuning in challenging legged\nlocomotion tasks while saving denoising steps and 82.63% of wall time compared\nto state-of-the-art diffusion RL fine-tuning method DPPO [43]. The success rate\nof the Shortcut Model policies in state and visual manipulation tasks achieved\nan average net increase of 40.34% after fine-tuning with ReinFlow at four or\neven one denoising step, whose performance is comparable to fine-tuned DDIM\npolicies while saving computation time for an average of 23.20%. Project\nwebpage: https://reinflow.github.io/",
    "pdf_url": "http://arxiv.org/pdf/2505.22094v5",
    "published": "2025-05-28T08:17:16+00:00",
    "categories": [
      "cs.RO",
      "cs.LG"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.22093v1",
    "title": "From Coders to Critics: Empowering Students through Peer Assessment in the Age of AI Copilots",
    "authors": [
      "Santiago Berrezueta-Guzman",
      "Stephan Krusche",
      "Stefan Wagner"
    ],
    "abstract": "The rapid adoption of AI powered coding assistants like ChatGPT and other\ncoding copilots is transforming programming education, raising questions about\nassessment practices, academic integrity, and skill development. As educators\nseek alternatives to traditional grading methods susceptible to AI enabled\nplagiarism, structured peer assessment could be a promising strategy. This\npaper presents an empirical study of a rubric based, anonymized peer review\nprocess implemented in a large introductory programming course.\n  Students evaluated each other's final projects (2D game), and their\nassessments were compared to instructor grades using correlation, mean absolute\nerror, and root mean square error (RMSE). Additionally, reflective surveys from\n47 teams captured student perceptions of fairness, grading behavior, and\npreferences regarding grade aggregation. Results show that peer review can\napproximate instructor evaluation with moderate accuracy and foster student\nengagement, evaluative thinking, and interest in providing good feedback to\ntheir peers. We discuss these findings for designing scalable, trustworthy peer\nassessment systems to face the age of AI assisted coding.",
    "pdf_url": "http://arxiv.org/pdf/2505.22093v1",
    "published": "2025-05-28T08:17:05+00:00",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CY"
  },
  {
    "id": "http://arxiv.org/abs/2505.22092v2",
    "title": "VIRAL: Vision-grounded Integration for Reward design And Learning",
    "authors": [
      "Valentin Cuzin-Rambaud",
      "Emilien Komlenovic",
      "Alexandre Faure",
      "Bruno Yun"
    ],
    "abstract": "The alignment between humans and machines is a critical challenge in\nartificial intelligence today. Reinforcement learning, which aims to maximize a\nreward function, is particularly vulnerable to the risks associated with poorly\ndesigned reward functions. Recent advancements has shown that Large Language\nModels (LLMs) for reward generation can outperform human performance in this\ncontext. We introduce VIRAL, a pipeline for generating and refining reward\nfunctions through the use of multi-modal LLMs. VIRAL autonomously creates and\ninteractively improves reward functions based on a given environment and a goal\nprompt or annotated image. The refinement process can incorporate human\nfeedback or be guided by a description generated by a video LLM, which explains\nthe agent's policy in video form. We evaluated VIRAL in five Gymnasium\nenvironments, demonstrating that it accelerates the learning of new behaviors\nwhile ensuring improved alignment with user intent. The source-code and demo\nvideo are available at: https://github.com/VIRAL-UCBL1/VIRAL and\nhttps://youtu.be/Hqo82CxVT38.",
    "pdf_url": "http://arxiv.org/pdf/2505.22092v2",
    "published": "2025-05-28T08:16:09+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.22091v2",
    "title": "A simulation framework for autonomous lunar construction work",
    "authors": [
      "Mattias Linde",
      "Daniel Lindmark",
      "Sandra √Ölstig",
      "Martin Servin"
    ],
    "abstract": "We present a simulation framework for lunar construction work involving\nmultiple autonomous machines. The framework supports modelling of construction\nscenarios and autonomy solutions, execution of the scenarios in simulation, and\nanalysis of work time and energy consumption throughout the construction\nproject. The simulations are based on physics-based models for contacting\nmultibody dynamics and deformable terrain, including vehicle-soil interaction\nforces and soil flow in real time. A behaviour tree manages the operational\nlogic and error handling, which enables the representation of complex\nbehaviours through a discrete set of simpler tasks in a modular hierarchical\nstructure. High-level decision-making is separated from lower-level control\nalgorithms, with the two connected via ROS2. Excavation movements are\ncontrolled through inverse kinematics and tracking controllers. The framework\nis tested and demonstrated on two different lunar construction scenarios that\ninvolve an excavator and dump truck with actively controlled articulated\ncrawlers.",
    "pdf_url": "http://arxiv.org/pdf/2505.22091v2",
    "published": "2025-05-28T08:16:05+00:00",
    "categories": [
      "cs.RO"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.22090v1",
    "title": "High Volume Rate 3D Ultrasound Reconstruction with Diffusion Models",
    "authors": [
      "Tristan S. W. Stevens",
      "Ois√≠n Nolan",
      "Oudom Somphone",
      "Jean-Luc Robert",
      "Ruud J. G. van Sloun"
    ],
    "abstract": "Three-dimensional ultrasound enables real-time volumetric visualization of\nanatomical structures. Unlike traditional 2D ultrasound, 3D imaging reduces the\nreliance on precise probe orientation, potentially making ultrasound more\naccessible to clinicians with varying levels of experience and improving\nautomated measurements and post-exam analysis. However, achieving both high\nvolume rates and high image quality remains a significant challenge. While 3D\ndiverging waves can provide high volume rates, they suffer from limited tissue\nharmonic generation and increased multipath effects, which degrade image\nquality. One compromise is to retain the focusing in elevation while leveraging\nunfocused diverging waves in the lateral direction to reduce the number of\ntransmissions per elevation plane. Reaching the volume rates achieved by full\n3D diverging waves, however, requires dramatically undersampling the number of\nelevation planes. Subsequently, to render the full volume, simple interpolation\ntechniques are applied. This paper introduces a novel approach to 3D ultrasound\nreconstruction from a reduced set of elevation planes by employing diffusion\nmodels (DMs) to achieve increased spatial and temporal resolution. We compare\nboth traditional and supervised deep learning-based interpolation methods on a\n3D cardiac ultrasound dataset. Our results show that DM-based reconstruction\nconsistently outperforms the baselines in image quality and downstream task\nperformance. Additionally, we accelerate inference by leveraging the temporal\nconsistency inherent to ultrasound sequences. Finally, we explore the\nrobustness of the proposed method by exploiting the probabilistic nature of\ndiffusion posterior sampling to quantify reconstruction uncertainty and\ndemonstrate improved recall on out-of-distribution data with synthetic\nanomalies under strong subsampling.",
    "pdf_url": "http://arxiv.org/pdf/2505.22090v1",
    "published": "2025-05-28T08:14:12+00:00",
    "categories": [
      "eess.IV",
      "cs.LG"
    ],
    "primary_category": "eess.IV"
  },
  {
    "id": "http://arxiv.org/abs/2505.22089v1",
    "title": "Fast Feature Matching of UAV Images via Matrix Band Reduction-based GPU Data Schedule",
    "authors": [
      "San Jiang",
      "Kan You",
      "Wanshou Jiang",
      "Qingquan Li"
    ],
    "abstract": "Feature matching dominats the time costs in structure from motion (SfM). The\nprimary contribution of this study is a GPU data schedule algorithm for\nefficient feature matching of Unmanned aerial vehicle (UAV) images. The core\nidea is to divide the whole dataset into blocks based on the matrix band\nreduction (MBR) and achieve efficient feature matching via GPU-accelerated\ncascade hashing. First, match pairs are selected by using an image retrieval\ntechnique, which converts images into global descriptors and searches\nhigh-dimension nearest neighbors with graph indexing. Second, compact image\nblocks are iteratively generated from a MBR-based data schedule strategy, which\nexploits image connections to avoid redundant data IO (input/output) burden and\nincreases the usage of GPU computing power. Third, guided by the generated\nimage blocks, feature matching is executed sequentially within the framework of\nGPU-accelerated cascade hashing, and initial candidate matches are refined by\ncombining a local geometric constraint and RANSAC-based global verification.\nFor further performance improvement, these two seps are designed to execute\nparallelly in GPU and CPU. Finally, the performance of the proposed solution is\nevaluated by using large-scale UAV datasets. The results demonstrate that it\nincreases the efficiency of feature matching with speedup ratios ranging from\n77.0 to 100.0 compared with KD-Tree based matching methods, and achieves\ncomparable accuracy in relative and absolute bundle adjustment (BA). The\nproposed algorithm is an efficient solution for feature matching of UAV images.",
    "pdf_url": "http://arxiv.org/pdf/2505.22089v1",
    "published": "2025-05-28T08:12:12+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.22088v1",
    "title": "Visual Cues Support Robust Turn-taking Prediction in Noise",
    "authors": [
      "Sam O'Connor Russell",
      "Naomi Harte"
    ],
    "abstract": "Accurate predictive turn-taking models (PTTMs) are essential for naturalistic\nhuman-robot interaction. However, little is known about their performance in\nnoise. This study therefore explores PTTM performance in types of noise likely\nto be encountered once deployed. Our analyses reveal PTTMs are highly sensitive\nto noise. Hold/shift accuracy drops from 84% in clean speech to just 52% in 10\ndB music noise. Training with noisy data enables a multimodal PTTM, which\nincludes visual features to better exploit visual cues, with 72% accuracy in 10\ndB music noise. The multimodal PTTM outperforms the audio-only PTTM across all\nnoise types and SNRs, highlighting its ability to exploit visual cues; however,\nthis does not always generalise to new types of noise. Analysis also reveals\nthat successful training relies on accurate transcription, limiting the use of\nASR-derived transcriptions to clean conditions. We make code publicly available\nfor future research.",
    "pdf_url": "http://arxiv.org/pdf/2505.22088v1",
    "published": "2025-05-28T08:11:13+00:00",
    "categories": [
      "cs.SD",
      "cs.CL",
      "eess.AS"
    ],
    "primary_category": "cs.SD"
  },
  {
    "id": "http://arxiv.org/abs/2505.23829v1",
    "title": "BiasFilter: An Inference-Time Debiasing Framework for Large Language Models",
    "authors": [
      "Xiaoqing Cheng",
      "Ruizhe Chen",
      "Hongying Zan",
      "Yuxiang Jia",
      "Min Peng"
    ],
    "abstract": "Mitigating social bias in large language models (LLMs) has become an\nincreasingly important research objective. However, existing debiasing methods\noften incur high human and computational costs, exhibit limited effectiveness,\nand struggle to scale to larger models and open-ended generation tasks. To\naddress these limitations, this paper proposes BiasFilter, a model-agnostic,\ninference-time debiasing framework that integrates seamlessly with both\nopen-source and API-based LLMs. Instead of relying on retraining with balanced\ndata or modifying model parameters, BiasFilter enforces fairness by filtering\ngeneration outputs in real time. Specifically, it periodically evaluates\nintermediate outputs every few tokens, maintains an active set of candidate\ncontinuations, and incrementally completes generation by discarding low-reward\nsegments based on a fairness reward signal. To support this process, we\nconstruct a fairness preference dataset and train an implicit reward model to\nassess token-level fairness in generated responses. Extensive experiments\ndemonstrate that BiasFilter effectively mitigates social bias across a range of\nLLMs while preserving overall generation quality.",
    "pdf_url": "http://arxiv.org/pdf/2505.23829v1",
    "published": "2025-05-28T08:09:10+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.22087v1",
    "title": "Cognitively-Inspired Emergent Communication via Knowledge Graphs for Assisting the Visually Impaired",
    "authors": [
      "Ruxiao Chen",
      "Dezheng Han",
      "Wenjie Han",
      "Shuaishuai Guo"
    ],
    "abstract": "Assistive systems for visually impaired individuals must deliver rapid,\ninterpretable, and adaptive feedback to facilitate real-time navigation.\nCurrent approaches face a trade-off between latency and semantic richness:\nnatural language-based systems provide detailed guidance but are too slow for\ndynamic scenarios, while emergent communication frameworks offer low-latency\nsymbolic languages but lack semantic depth, limiting their utility in tactile\nmodalities like vibration. To address these limitations, we introduce a novel\nframework, Cognitively-Inspired Emergent Communication via Knowledge Graphs\n(VAG-EC), which emulates human visual perception and cognitive mapping. Our\nmethod constructs knowledge graphs to represent objects and their\nrelationships, incorporating attention mechanisms to prioritize task-relevant\nentities, thereby mirroring human selective attention. This structured approach\nenables the emergence of compact, interpretable, and context-sensitive symbolic\nlanguages. Extensive experiments across varying vocabulary sizes and message\nlengths demonstrate that VAG-EC outperforms traditional emergent communication\nmethods in Topographic Similarity (TopSim) and Context Independence (CI). These\nfindings underscore the potential of cognitively grounded emergent\ncommunication as a fast, adaptive, and human-aligned solution for real-time\nassistive technologies. Code is available at\nhttps://github.com/Anonymous-NLPcode/Anonymous_submission/tree/main.",
    "pdf_url": "http://arxiv.org/pdf/2505.22087v1",
    "published": "2025-05-28T08:09:06+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.22086v2",
    "title": "iDSE: Navigating Design Space Exploration in High-Level Synthesis Using LLMs",
    "authors": [
      "Runkai Li",
      "Jia Xiong",
      "Xi Wang"
    ],
    "abstract": "High-Level Synthesis (HLS) serves as an agile hardware development tool that\nstreamlines the circuit design by abstracting the register transfer level into\nbehavioral descriptions, while allowing designers to customize the generated\nmicroarchitectures through optimization directives. However, the combinatorial\nexplosion of possible directive configurations yields an intractable design\nspace. Traditional design space exploration (DSE) methods, despite adopting\nheuristics or constructing predictive models to accelerate Pareto-optimal\ndesign acquisition, still suffer from prohibitive exploration costs and\nsuboptimal results. Addressing these concerns, we introduce iDSE, the first\nLLM-aided DSE framework that leverages HLS design quality perception to\neffectively navigate the design space. iDSE intelligently pruns the design\nspace to guide LLMs in calibrating representative initial sampling designs,\nexpediting convergence toward the Pareto front. By exploiting the convergent\nand divergent thinking patterns inherent in LLMs for hardware optimization,\niDSE achieves multi-path refinement of the design quality and diversity.\nExtensive experiments demonstrate that iDSE outperforms heuristic-based DSE\nmethods by 5.1$\\times$$\\sim$16.6$\\times$ in proximity to the reference Pareto\nfront, matching NSGA-II with only 4.6% of the explored designs. Our work\ndemonstrates the transformative potential of LLMs in scalable and efficient HLS\ndesign optimization, offering new insights into multiobjective optimization\nchallenges.",
    "pdf_url": "http://arxiv.org/pdf/2505.22086v2",
    "published": "2025-05-28T08:08:57+00:00",
    "categories": [
      "cs.AR",
      "cs.AI"
    ],
    "primary_category": "cs.AR"
  },
  {
    "id": "http://arxiv.org/abs/2505.22085v1",
    "title": "PADAM: Parallel averaged Adam reduces the error for stochastic optimization in scientific machine learning",
    "authors": [
      "Arnulf Jentzen",
      "Julian Kranz",
      "Adrian Riekert"
    ],
    "abstract": "Averaging techniques such as Ruppert--Polyak averaging and exponential\nmovering averaging (EMA) are powerful approaches to accelerate optimization\nprocedures of stochastic gradient descent (SGD) optimization methods such as\nthe popular ADAM optimizer. However, depending on the specific optimization\nproblem under consideration, the type and the parameters for the averaging need\nto be adjusted to achieve the smallest optimization error. In this work we\npropose an averaging approach, which we refer to as parallel averaged ADAM\n(PADAM), in which we compute parallely different averaged variants of ADAM and\nduring the training process dynamically select the variant with the smallest\noptimization error. A central feature of this approach is that this procedure\nrequires no more gradient evaluations than the usual ADAM optimizer as each of\nthe averaged trajectories relies on the same underlying ADAM trajectory and\nthus on the same underlying gradients. We test the proposed PADAM optimizer in\n13 stochastic optimization and deep neural network (DNN) learning problems and\ncompare its performance with known optimizers from the literature such as\nstandard SGD, momentum SGD, Adam with and without EMA, and ADAMW. In\nparticular, we apply the compared optimizers to physics-informed neural\nnetwork, deep Galerkin, deep backward stochastic differential equation and deep\nKolmogorov approximations for boundary value partial differential equation\nproblems from scientific machine learning, as well as to DNN approximations for\noptimal control and optimal stopping problems. In nearly all of the considered\nexamples PADAM achieves, sometimes among others and sometimes exclusively,\nessentially the smallest optimization error. This work thus strongly suggest to\nconsider PADAM for scientific machine learning problems and also motivates\nfurther research for adaptive averaging procedures within the training of DNNs.",
    "pdf_url": "http://arxiv.org/pdf/2505.22085v1",
    "published": "2025-05-28T08:07:34+00:00",
    "categories": [
      "math.OC",
      "cs.LG",
      "cs.NA",
      "math.NA"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2505.22084v1",
    "title": "MObyGaze: a film dataset of multimodal objectification densely annotated by experts",
    "authors": [
      "Julie Tores",
      "Elisa Ancarani",
      "Lucile Sassatelli",
      "Hui-Yin Wu",
      "Clement Bergman",
      "Lea Andolfi",
      "Victor Ecrement",
      "Remy Sun",
      "Frederic Precioso",
      "Thierry Devars",
      "Magali Guaresi",
      "Virginie Julliard",
      "Sarah Lecossais"
    ],
    "abstract": "Characterizing and quantifying gender representation disparities in\naudiovisual storytelling contents is necessary to grasp how stereotypes may\nperpetuate on screen. In this article, we consider the high-level construct of\nobjectification and introduce a new AI task to the ML community: characterize\nand quantify complex multimodal (visual, speech, audio) temporal patterns\nproducing objectification in films. Building on film studies and psychology, we\ndefine the construct of objectification in a structured thesaurus involving 5\nsub-constructs manifesting through 11 concepts spanning 3 modalities. We\nintroduce the Multimodal Objectifying Gaze (MObyGaze) dataset, made of 20\nmovies annotated densely by experts for objectification levels and concepts\nover freely delimited segments: it amounts to 6072 segments over 43 hours of\nvideo with fine-grained localization and categorization. We formulate different\nlearning tasks, propose and investigate best ways to learn from the diversity\nof labels among a low number of annotators, and benchmark recent vision, text\nand audio models, showing the feasibility of the task. We make our code and our\ndataset available to the community and described in the Croissant format:\nhttps://anonymous.4open.science/r/MObyGaze-F600/.",
    "pdf_url": "http://arxiv.org/pdf/2505.22084v1",
    "published": "2025-05-28T08:07:28+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.22083v2",
    "title": "Hyperbolic recurrent neural network as the first type of non-Euclidean neural quantum state ansatz",
    "authors": [
      "H. L. Dao"
    ],
    "abstract": "In this work, we introduce the first type of non-Euclidean neural quantum\nstate (NQS) ansatz, in the form of the hyperbolic GRU (a variant of recurrent\nneural networks (RNNs)), to be used in the Variational Monte Carlo method of\napproximating the ground state energy for quantum many-body systems. In\nparticular, we examine the performances of NQS ansatzes constructed from both\nconventional or Euclidean RNN/GRU and from hyperbolic GRU in the prototypical\nsettings of the one- and two-dimensional transverse field Ising models (TFIM)\nand the one-dimensional Heisenberg $J_1J_2$ and $J_1J_2J_3$ systems. By virtue\nof the fact that, for all of the experiments performed in this work, hyperbolic\nGRU can yield performances comparable to or better than Euclidean RNNs, which\nhave been extensively studied in these settings in the literature, our work is\na proof-of-concept for the viability of hyperbolic GRU as the first type of\nnon-Euclidean NQS ansatz for quantum many-body systems. Furthermore, in\nsettings where the Hamiltonian displays a clear hierarchical interaction\nstructure, such as the 1D Heisenberg $J_1J_2$ & $J_1J_2J_3$ systems with the\n1st, 2nd and even 3rd nearest neighbor interactions, our results show that\nhyperbolic GRU definitively outperforms its Euclidean version in all instances.\nThe fact that these results are reminiscent of the established ones from\nnatural language processing where hyperbolic GRU almost always outperforms\nEuclidean RNNs when the training data exhibit a tree-like or hierarchical\nstructure leads us to hypothesize that hyperbolic GRU NQS ansatz would likely\noutperform Euclidean RNN/GRU NQS ansatz in quantum spin systems that involve\ndifferent degrees of nearest neighbor interactions. Finally, with this work, we\nhope to initiate future studies of other types of non-Euclidean NQS beyond\nhyperbolic GRU.",
    "pdf_url": "http://arxiv.org/pdf/2505.22083v2",
    "published": "2025-05-28T08:06:25+00:00",
    "categories": [
      "quant-ph",
      "cond-mat.dis-nn",
      "cs.LG",
      "physics.comp-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.22082v2",
    "title": "Galaxy Superclusters and Their Complexes in the Cosmic Web",
    "authors": [
      "Maret Einasto"
    ],
    "abstract": "The richest and largest structures in the cosmic web are galaxy\nsuperclusters, their complexes (associations of several almost connected very\nrich superclusters), and planes. Superclusters represent a special environment\nwhere the evolution of galaxies and galaxy groups and clusters differs from the\nevolution of these systems in a low-density environment. The richest galaxy\nclusters reside in superclusters. The richest superclusters in the nearby\nUniverse form a quasiregular pattern with the characteristic distance between\nsuperclusters 120 - 140 $h^{-1}$Mpc. Moreover, superclusters in the nearby\nUniverse lie in two huge perpendicular planes with the extent of several\nhundreds of megaparsecs, the Local Supercluster plane and the Dominant\nsupercluster plane. The origin of these patterns in the supercluster\ndistribution is not yet clear, and it is an open question whether the presence\nof such structures can be explained within the $\\Lambda$CDM cosmological model.\nThis review presents a brief story of superclusters, their discovery,\ndefinitions, main properties, and large-scale distribution.",
    "pdf_url": "http://arxiv.org/pdf/2505.22082v2",
    "published": "2025-05-28T08:04:49+00:00",
    "categories": [
      "astro-ph.CO"
    ],
    "primary_category": "astro-ph.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.22081v1",
    "title": "Can Test-time Computation Mitigate Memorization Bias in Neural Symbolic Regression?",
    "authors": [
      "Shun Sato",
      "Issei Sato"
    ],
    "abstract": "Symbolic regression aims to discover mathematical equations that fit given\nnumerical data. It has been applied in various fields of scientific research,\nsuch as producing human-readable expressions that explain physical phenomena.\nRecently, Neural symbolic regression (NSR) methods that involve Transformers\npre-trained on large-scale synthetic datasets have gained attention. While\nthese methods offer advantages such as short inference time, they suffer from\nlow performance, particularly when the number of input variables is large. In\nthis study, we hypothesized that this limitation stems from the memorization\nbias of Transformers in symbolic regression. We conducted a quantitative\nevaluation of this bias in Transformers using a synthetic dataset and found\nthat Transformers rarely generate expressions not present in the training data.\nAdditional theoretical analysis reveals that this bias arises from the\nTransformer's inability to construct expressions compositionally while\nverifying their numerical validity. We finally examined if tailoring test-time\nstrategies can lead to reduced memorization bias and better performance. We\nempirically demonstrate that providing additional information to the model at\ntest time can significantly mitigate memorization bias. On the other hand, we\nalso find that reducing memorization bias does not necessarily correlate with\nimproved performance. These findings contribute to a deeper understanding of\nthe limitations of NSR approaches and offer a foundation for designing more\nrobust, generalizable symbolic regression methods. Code is available at\nhttps://github.com/Shun-0922/Mem-Bias-NSR .",
    "pdf_url": "http://arxiv.org/pdf/2505.22081v1",
    "published": "2025-05-28T08:01:25+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.22080v2",
    "title": "Trade Networks and the Rise of a Dominant Currency",
    "authors": [
      "Tomoo Kikuchi",
      "Lien Pham"
    ],
    "abstract": "We develop a model where currency issuers provide liquidity, while users in a\ntrade network choose currency usage for trade settlement. We identify a\nfeedback mechanism where a user's currency preference spillovers to others and\nincreases the issuer's commitment to liquidity provision, which in turn\nincreases the adoption of the currency. Our findings highlight not only the\nadvantage of the incumbent issuer in maintaining dominance, but also the\nconditions that lead to the rise and fall of dominant currencies. Our framework\noffers testable implications for the share of global settlement currencies, the\nnetwork structure, and the strategy of issuers.",
    "pdf_url": "http://arxiv.org/pdf/2505.22080v2",
    "published": "2025-05-28T08:00:55+00:00",
    "categories": [
      "econ.TH"
    ],
    "primary_category": "econ.TH"
  },
  {
    "id": "http://arxiv.org/abs/2505.22079v1",
    "title": "Bringing CLIP to the Clinic: Dynamic Soft Labels and Negation-Aware Learning for Medical Analysis",
    "authors": [
      "Hanbin Ko",
      "Chang-Min Park"
    ],
    "abstract": "The development of large-scale image-text pair datasets has significantly\nadvanced self-supervised learning in Vision-Language Processing (VLP). However,\ndirectly applying general-domain architectures such as CLIP to medical data\npresents challenges, particularly in handling negations and addressing the\ninherent data imbalance of medical datasets. To address these issues, we\npropose a novel approach that integrates clinically-enhanced dynamic soft\nlabels and medical graphical alignment, thereby improving clinical\ncomprehension and the applicability of contrastive loss in medical contexts.\nFurthermore, we introduce negation-based hard negatives to deepen the model's\nunderstanding of the complexities of clinical language. Our approach is easily\nintegrated into the medical CLIP training pipeline and achieves\nstate-of-the-art performance across multiple tasks, including zero-shot,\nfine-tuned classification, and report retrieval. To comprehensively evaluate\nour model's capacity for understanding clinical language, we introduce\nCXR-Align, a benchmark uniquely designed to evaluate the understanding of\nnegation and clinical information within chest X-ray (CXR) datasets.\nExperimental results demonstrate that our proposed methods are straightforward\nto implement and generalize effectively across contrastive learning frameworks,\nenhancing medical VLP capabilities and advancing clinical language\nunderstanding in medical imaging.",
    "pdf_url": "http://arxiv.org/pdf/2505.22079v1",
    "published": "2025-05-28T08:00:18+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.22078v1",
    "title": "Local cubic spline interpolation for Vlasov-type equations on a multi-patch geometry",
    "authors": [
      "Pauline Vidal",
      "Emily Bourne",
      "Virginie Grandgirard",
      "Michel Mehrenberger",
      "Eric Sonnendr√ºcker"
    ],
    "abstract": "We present a semi-Lagrangian method for the numerical resolution of\nVlasov-type equations on multi-patch meshes. We employ a local cubic spline\ninterpolation with Hermite boundary conditions between the patches. The\nderivative reconstruction is adapted to cope with non-uniform meshes as well as\nnon-conforming situations. In the conforming case, there are no longer any\nconstraints on the number of points for each patch; however, a small global\nsystem must now be solved. In that case, the local spline representations\ncoincide with the corresponding global spline reconstruction. Alternatively, we\ncan choose not to apply the global system and the derivatives can be\napproximated. The influence of the most distant points diminishes as the number\nof points per patch increases. For uniform per patch configurations, a study of\nthe explicit and asymptotic behavior of this influence has been led. The method\nis validated using a two-dimensional guiding-center model with an O-point. All\nthe numerical results are carried out in the Gyselalib++ library.",
    "pdf_url": "http://arxiv.org/pdf/2505.22078v1",
    "published": "2025-05-28T08:00:15+00:00",
    "categories": [
      "math.NA",
      "cs.NA",
      "65M25, 65D07"
    ],
    "primary_category": "math.NA"
  },
  {
    "id": "http://arxiv.org/abs/2505.22077v1",
    "title": "Influence of thickness on magnetic properties of RF-sputtered amorphous CoNbZr thin films",
    "authors": [
      "Indujan Sivanesarajaha",
      "Leon Abelmann",
      "Uwe Hartmann"
    ],
    "abstract": "Amorphous sputtered Co-based thin films are widely used as soft magnetic\nmaterials in applications such as sensors, inductors and magnetic flux\nconcentrators. The magnetic properties of these films can be controlled by\ndeposition parameters like film thickness, argon pressure, deposition rate and\nothers. In this study, we present a detailed investigation of the magnetic\nproperties of RF-sputtered Co$_{91}$Nb$_7$Zr$_2$ films with thicknesses ranging\nfrom 52 nm to 1040 nm. These amorphous films exhibit an average saturation\nmagnetisation of 1.01(4) MA/m. As the film thickness increases, there is a\nsignificant decrease in coercivity, remanent-to-saturation magnetisation ratio\nM$_r$/M$_s$, and maximum permeability. The change in macroscopic magnetic\nproperties is also reflected by the domain structure. At a thickness of 52 nm,\nthe remanent domain state shows irregular domains, while films thicknesses\nabove 208 nm exhibit flux-closure domain structures instead. The\nthickness-dependent modifications are attributed to the transition between\nN\\'eel and Bloch type domain walls, which is expected to occur at approximately\n84 nm.",
    "pdf_url": "http://arxiv.org/pdf/2505.22077v1",
    "published": "2025-05-28T07:58:36+00:00",
    "categories": [
      "cond-mat.mtrl-sci",
      "physics.app-ph"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2505.22076v1",
    "title": "ArgInstruct: Specialized Instruction Fine-Tuning for Computational Argumentation",
    "authors": [
      "Maja Stahl",
      "Timon Ziegenbein",
      "Joonsuk Park",
      "Henning Wachsmuth"
    ],
    "abstract": "Training large language models (LLMs) to follow instructions has\nsignificantly enhanced their ability to tackle unseen tasks. However, despite\ntheir strong generalization capabilities, instruction-following LLMs encounter\ndifficulties when dealing with tasks that require domain knowledge. This work\nintroduces a specialized instruction fine-tuning for the domain of\ncomputational argumentation (CA). The goal is to enable an LLM to effectively\ntackle any unseen CA tasks while preserving its generalization capabilities.\nReviewing existing CA research, we crafted natural language instructions for\n105 CA tasks to this end. On this basis, we developed a CA-specific benchmark\nfor LLMs that allows for a comprehensive evaluation of LLMs' capabilities in\nsolving various CA tasks. We synthesized 52k CA-related instructions, adapting\nthe self-instruct process to train a CA-specialized instruction-following LLM.\nOur experiments suggest that CA-specialized instruction fine-tuning\nsignificantly enhances the LLM on both seen and unseen CA tasks. At the same\ntime, performance on the general NLP tasks of the SuperNI benchmark remains\nstable.",
    "pdf_url": "http://arxiv.org/pdf/2505.22076v1",
    "published": "2025-05-28T07:58:29+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.22075v1",
    "title": "Data-Driven Adjustable Robust Optimization",
    "authors": [
      "Xiaoxing Ren",
      "Alessio Moreschini",
      "Zhongda Chu",
      "Yulong Gao",
      "Thomas Parisini"
    ],
    "abstract": "In this paper, we develop a two-stage data-driven approach to address the\nadjustable robust optimization problem, where the uncertainty set is adjustable\nto manage infeasibility caused by significant or poorly quantified\nuncertainties. In the first stage, we synthesize an uncertainty set to ensure\nthe feasibility of the problem as much as possible using the collected\nuncertainty samples. In the second stage, we find the optimal solution while\nensuring that the constraints are satisfied under the new uncertainty set. This\napproach enlarges the feasible state set, at the expense of the risk of\npossible constraint violation. We analyze two scenarios: one where the\nuncertainty is non-stochastic, and another where the uncertainty is stochastic\nbut with unknown probability distribution, leading to a distributionally robust\noptimization problem. In the first case, we scale the uncertainty set and find\nthe best subset that fits the uncertainty samples. In the second case, we\nemploy the Wasserstein metric to quantify uncertainty based on training data,\nand for polytope uncertainty sets, we further provide a finite program\nreformulation of the problem. The effectiveness of the proposed methods is\ndemonstrated through an optimal power flow problem.",
    "pdf_url": "http://arxiv.org/pdf/2505.22075v1",
    "published": "2025-05-28T07:56:08+00:00",
    "categories": [
      "math.OC"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2505.22074v1",
    "title": "The Resurrection of the ReLU",
    "authors": [
      "Co≈üku Can Horuz",
      "Geoffrey Kasenbacher",
      "Saya Higuchi",
      "Sebastian Kairat",
      "Jendrik Stoltz",
      "Moritz Pesl",
      "Bernhard A. Moser",
      "Christoph Linse",
      "Thomas Martinetz",
      "Sebastian Otte"
    ],
    "abstract": "Modeling sophisticated activation functions within deep learning\narchitectures has evolved into a distinct research direction. Functions such as\nGELU, SELU, and SiLU offer smooth gradients and improved convergence\nproperties, making them popular choices in state-of-the-art models. Despite\nthis trend, the classical ReLU remains appealing due to its simplicity,\ninherent sparsity, and other advantageous topological characteristics. However,\nReLU units are prone to becoming irreversibly inactive - a phenomenon known as\nthe dying ReLU problem - which limits their overall effectiveness. In this\nwork, we introduce surrogate gradient learning for ReLU (SUGAR) as a novel,\nplug-and-play regularizer for deep architectures. SUGAR preserves the standard\nReLU function during the forward pass but replaces its derivative in the\nbackward pass with a smooth surrogate that avoids zeroing out gradients. We\ndemonstrate that SUGAR, when paired with a well-chosen surrogate function,\nsubstantially enhances generalization performance over convolutional network\narchitectures such as VGG-16 and ResNet-18, providing sparser activations while\neffectively resurrecting dead ReLUs. Moreover, we show that even in modern\narchitectures like Conv2NeXt and Swin Transformer - which typically employ GELU\n- substituting these with SUGAR yields competitive and even slightly superior\nperformance. These findings challenge the prevailing notion that advanced\nactivation functions are necessary for optimal performance. Instead, they\nsuggest that the conventional ReLU, particularly with appropriate gradient\nhandling, can serve as a strong, versatile revived classic across a broad range\nof deep learning vision models.",
    "pdf_url": "http://arxiv.org/pdf/2505.22074v1",
    "published": "2025-05-28T07:55:51+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.22073v2",
    "title": "A Closer Look at the Existing Risks of Generative AI: Mapping the Who, What, and How of Real-World Incidents",
    "authors": [
      "Megan Li",
      "Wendy Bickersteth",
      "Ningjing Tang",
      "Jason Hong",
      "Lorrie Cranor",
      "Hong Shen",
      "Hoda Heidari"
    ],
    "abstract": "Due to its general-purpose nature, Generative AI is applied in an\never-growing set of domains and tasks, leading to an expanding set of risks of\nharm impacting people, communities, society, and the environment. These risks\nmay arise due to failures during the design and development of the technology,\nas well as during its release, deployment, or downstream usages and\nappropriations of its outputs. In this paper, building on prior taxonomies of\nAI risks, harms, and failures, we construct a taxonomy specifically for\nGenerative AI failures and map them to the harms they precipitate. Through a\nsystematic analysis of 499 publicly reported incidents, we describe what harms\nare reported, how they arose, and who they impact. We report the prevalence of\neach type of harm, underlying failure mode, and harmed stakeholder, as well as\ntheir common co-occurrences. We find that most reported incidents are caused by\nuse-related issues but bring harm to parties beyond the end user(s) of the\nGenerative AI system at fault, and that the landscape of Generative AI harms is\ndistinct from that of traditional AI. Our work offers actionable insights to\npolicymakers, developers, and Generative AI users. In particular, we call for\nthe prioritization of non-technical risk and harm mitigation strategies,\nincluding public disclosures and education and careful regulatory stances.",
    "pdf_url": "http://arxiv.org/pdf/2505.22073v2",
    "published": "2025-05-28T07:54:06+00:00",
    "categories": [
      "cs.CY"
    ],
    "primary_category": "cs.CY"
  },
  {
    "id": "http://arxiv.org/abs/2505.22072v1",
    "title": "On-the-fly Routing for Zero-shot MoE Speaker Adaptation of Speech Foundation Models for Dysarthric Speech Recognition",
    "authors": [
      "Shujie HU",
      "Xurong Xie",
      "Mengzhe Geng",
      "Jiajun Deng",
      "Huimeng Wang",
      "Guinan Li",
      "Chengxi Deng",
      "Tianzi Wang",
      "Mingyu Cui",
      "Helen Meng",
      "Xunying Liu"
    ],
    "abstract": "This paper proposes a novel MoE-based speaker adaptation framework for\nfoundation models based dysarthric speech recognition. This approach enables\nzero-shot adaptation and real-time processing while incorporating domain\nknowledge. Speech impairment severity and gender conditioned adapter experts\nare dynamically combined using on-the-fly predicted speaker-dependent routing\nparameters. KL-divergence is used to further enforce diversity among experts\nand their generalization to unseen speakers. Experimental results on the\nUASpeech corpus suggest that on-the-fly MoE-based adaptation produces\nstatistically significant WER reductions of up to 1.34% absolute (6.36%\nrelative) over the unadapted baseline HuBERT/WavLM models. Consistent WER\nreductions of up to 2.55% absolute (11.44% relative) and RTF speedups of up to\n7 times are obtained over batch-mode adaptation across varying speaker-level\ndata quantities. The lowest published WER of 16.35% (46.77% on very low\nintelligibility) is obtained.",
    "pdf_url": "http://arxiv.org/pdf/2505.22072v1",
    "published": "2025-05-28T07:52:58+00:00",
    "categories": [
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.SD"
  },
  {
    "id": "http://arxiv.org/abs/2505.22071v3",
    "title": "Ocean-E2E: Hybrid Physics-Based and Data-Driven Global Forecasting of Extreme Marine Heatwaves with End-to-End Neural Assimilation",
    "authors": [
      "Ruiqi Shu",
      "Yuan Gao",
      "Hao Wu",
      "Ruijian Gou",
      "Kun Wang",
      "Yanfei Xiang",
      "Fan Xu",
      "Qingsong Wen",
      "Xiaomeng Huang"
    ],
    "abstract": "This work focuses on the end-to-end forecast of global extreme marine\nheatwaves (MHWs), which are unusually warm sea surface temperature events with\nprofound impacts on marine ecosystems. Accurate prediction of extreme MHWs has\nsignificant scientific and financial worth. However, existing methods still\nhave certain limitations in forecasting general patterns and extreme events. In\nthis study, to address these issues, based on the physical nature of MHWs, we\ncreated a novel hybrid data-driven and numerical MHWs forecast framework\nOcean-E2E, which is capable of 40-day accurate MHW forecasting with end-to-end\ndata assimilation. Our framework significantly improves the forecast ability of\nMHWs by explicitly modeling the effect of oceanic mesoscale advection and\nair-sea interaction based on a dynamic kernel. Furthermore, Ocean-E2E is\ncapable of end-to-end MHWs forecast and regional high-resolution prediction,\nallowing our framework to operate completely independently of numerical models\nwhile outperforming the current state-of-the-art ocean numerical/AI\nforecasting-assimilation models. Experimental results show that the proposed\nframework performs excellently on global-to-regional scales and\nshort-to-long-term forecasts, especially in those most extreme MHWs. Overall,\nour model provides a framework for forecasting and understanding MHWs and other\nclimate extremes. Our codes are available at\nhttps://github.com/ChiyodaMomo01/Ocean-E2E.",
    "pdf_url": "http://arxiv.org/pdf/2505.22071v3",
    "published": "2025-05-28T07:52:41+00:00",
    "categories": [
      "physics.geo-ph"
    ],
    "primary_category": "physics.geo-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.22070v2",
    "title": "Physical Reduced Stochastic Equations for Continuously Monitored Non-Markovian Quantum Systems with a Markovian Embedding",
    "authors": [
      "Hendra I. Nurdin"
    ],
    "abstract": "An effective approach to modeling non-Markovian quantum systems is to embed a\nprincipal (quantum) system of interest into a larger quantum system. A widely\nemployed embedding is one that uses another quantum system, referred to as the\nauxiliary system, which is coupled to the principal system, and both the\nprincipal and auxiliary can be coupled to quantum white noise processes. The\nprincipal and auxiliary together form a quantum Markov system and the quantum\nwhite noises act as a bath (environment) for this system. Recently it was shown\nthat the conditional evolution of the principal system in this embedding under\ncontinuous monitoring by a travelling quantum probe can be expressed as a\nsystem of coupled stochastic differential equations (SDEs) that involve only\noperators of the principal system. The reduced conditional state of the\nprincipal only (conditioned on the measurement outcomes) is determined by the\n``diagonal\" blocks of this coupled systems of SDEs. It is shown here that the\n``off-diagonal\" blocks can be exactly eliminated up to their initial\nconditions, leaving a reduced closed system of SDEs for the diagonal blocks\nonly. Under additional conditions the off-diagonal initial conditions can be\nmade to vanish. This new closed system of equations, which includes an\nintegration term involving a two-time stochastic kernel, represents the\nnon-Markovian stochastic dynamics of the principal system under\ncontinuous-measurement. The system of equations determine the reduced\nconditional state of the principal only and may be viewed as a stochastic\nNakajima-Zwanzig type of equation for continuously monitored non-Markovian\nquantum systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.22070v2",
    "published": "2025-05-28T07:52:37+00:00",
    "categories": [
      "quant-ph",
      "cs.SY",
      "eess.SY",
      "math-ph",
      "math.MP",
      "math.OC"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.02018v1",
    "title": "Enhancing Paraphrase Type Generation: The Impact of DPO and RLHF Evaluated with Human-Ranked Data",
    "authors": [
      "Christopher Lee L√ºbbers"
    ],
    "abstract": "Paraphrasing re-expresses meaning to enhance applications like text\nsimplification, machine translation, and question-answering. Specific\nparaphrase types facilitate accurate semantic analysis and robust language\nmodels. However, existing paraphrase-type generation methods often misalign\nwith human preferences due to reliance on automated metrics and limited\nhuman-annotated training data, obscuring crucial aspects of semantic fidelity\nand linguistic transformations.\n  This study addresses this gap by leveraging a human-ranked paraphrase-type\ndataset and integrating Direct Preference Optimization (DPO) to align model\noutputs directly with human judgments. DPO-based training increases\nparaphrase-type generation accuracy by 3 percentage points over a supervised\nbaseline and raises human preference ratings by 7 percentage points. A newly\ncreated human-annotated dataset supports more rigorous future evaluations.\nAdditionally, a paraphrase-type detection model achieves F1 scores of 0.91 for\naddition/deletion, 0.78 for same polarity substitution, and 0.70 for\npunctuation changes.\n  These findings demonstrate that preference data and DPO training produce more\nreliable, semantically accurate paraphrases, enabling downstream applications\nsuch as improved summarization and more robust question-answering. The PTD\nmodel surpasses automated metrics and provides a more reliable framework for\nevaluating paraphrase quality, advancing paraphrase-type research toward\nricher, user-aligned language generation and establishing a stronger foundation\nfor future evaluations grounded in human-centric criteria.",
    "pdf_url": "http://arxiv.org/pdf/2506.02018v1",
    "published": "2025-05-28T07:52:18+00:00",
    "categories": [
      "cs.CL",
      "I.2.7"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.22069v1",
    "title": "Delayed-KD: Delayed Knowledge Distillation based CTC for Low-Latency Streaming ASR",
    "authors": [
      "Longhao Li",
      "Yangze Li",
      "Hongfei Xue",
      "Jie Liu",
      "Shuai Fang",
      "Kai Wang",
      "Lei Xie"
    ],
    "abstract": "CTC-based streaming ASR has gained significant attention in real-world\napplications but faces two main challenges: accuracy degradation in small\nchunks and token emission latency. To mitigate these challenges, we propose\nDelayed-KD, which applies delayed knowledge distillation on CTC posterior\nprobabilities from a non-streaming to a streaming model. Specifically, with a\ntiny chunk size, we introduce a Temporal Alignment Buffer (TAB) that defines a\nrelative delay range compared to the non-streaming teacher model to align CTC\noutputs and mitigate non-blank token mismatches. Additionally, TAB enables\nfine-grained control over token emission delay. Experiments on 178-hour\nAISHELL-1 and 10,000-hour WenetSpeech Mandarin datasets show consistent\nsuperiority of Delayed-KD. Impressively, Delayed-KD at 40 ms latency achieves a\nlower character error rate (CER) of 5.42% on AISHELL-1, comparable to the\ncompetitive U2++ model running at 320 ms latency.",
    "pdf_url": "http://arxiv.org/pdf/2505.22069v1",
    "published": "2025-05-28T07:51:21+00:00",
    "categories": [
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.SD"
  },
  {
    "id": "http://arxiv.org/abs/2506.02017v1",
    "title": "Fairness through Feedback: Addressing Algorithmic Misgendering in Automatic Gender Recognition",
    "authors": [
      "Camilla Quaresmini",
      "Giacomo Zanotti"
    ],
    "abstract": "Automatic Gender Recognition (AGR) systems are an increasingly widespread\napplication in the Machine Learning (ML) landscape. While these systems are\ntypically understood as detecting gender, they often classify datapoints based\non observable features correlated at best with either male or female sex. In\naddition to questionable binary assumptions, from an epistemological point of\nview, this is problematic for two reasons. First, there exists a gap between\nthe categories the system is meant to predict (woman versus man) and those onto\nwhich their output reasonably maps (female versus male). What is more, gender\ncannot be inferred on the basis of such observable features. This makes AGR\ntools often unreliable, especially in the case of non-binary and gender\nnon-conforming people. We suggest a theoretical and practical rethinking of AGR\nsystems. To begin, distinctions are made between sex, gender, and gender\nexpression. Then, we build upon the observation that, unlike algorithmic\nmisgendering, human-human misgendering is open to the possibility of\nre-evaluation and correction. We suggest that analogous dynamics should be\nrecreated in AGR, giving users the possibility to correct the system's output.\nWhile implementing such a feedback mechanism could be regarded as diminishing\nthe system's autonomy, it represents a way to significantly increase fairness\nlevels in AGR. This is consistent with the conceptual change of paradigm that\nwe advocate for AGR systems, which should be understood as tools respecting\nindividuals' rights and capabilities of self-expression and determination.",
    "pdf_url": "http://arxiv.org/pdf/2506.02017v1",
    "published": "2025-05-28T07:49:05+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.22068v1",
    "title": "Beyond path selection: Better LLMs for Scientific Information Extraction with MimicSFT and Relevance and Rule-induced(R$^2$)GRPO",
    "authors": [
      "Ran Li",
      "Shimin Di",
      "Yuchen Liu",
      "Chen Jing",
      "Yu Qiu",
      "Lei Chen"
    ],
    "abstract": "Previous study suggest that powerful Large Language Models (LLMs) trained\nwith Reinforcement Learning with Verifiable Rewards (RLVR) only refines\nreasoning path without improving the reasoning capacity in math tasks while\nsupervised-finetuning(SFT) with distillation can. We study this from the view\nof Scientific information extraction (SciIE) where LLMs and reasoning LLMs\nunderperforms small Bert-based models. SciIE require both the reasoning and\nmemorization. We argue that both SFT and RLVR can refine the reasoning path and\nimprove reasoning capacity in a simple way based on SciIE. We propose two-stage\ntraining with 1. MimicSFT, using structured reasoning templates without needing\nhigh-quality chain-of-thought data, 2. R$^2$GRPO with relevance and\nrule-induced rewards. Experiments on scientific IE benchmarks show that both\nmethods can improve the reasoning capacity. R$^2$GRPO with mimicSFT surpasses\nbaseline LLMs and specialized supervised models in relation extraction. Our\ncode is available at https://github.com/ranlislz/R2GRPO.",
    "pdf_url": "http://arxiv.org/pdf/2505.22068v1",
    "published": "2025-05-28T07:47:46+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.22067v1",
    "title": "From Failures to Fixes: LLM-Driven Scenario Repair for Self-Evolving Autonomous Driving",
    "authors": [
      "Xinyu Xia",
      "Xingjun Ma",
      "Yunfeng Hu",
      "Ting Qu",
      "Hong Chen",
      "Xun Gong"
    ],
    "abstract": "Ensuring robust and generalizable autonomous driving requires not only broad\nscenario coverage but also efficient repair of failure cases, particularly\nthose related to challenging and safety-critical scenarios. However, existing\nscenario generation and selection methods often lack adaptivity and semantic\nrelevance, limiting their impact on performance improvement. In this paper, we\npropose \\textbf{SERA}, an LLM-powered framework that enables autonomous driving\nsystems to self-evolve by repairing failure cases through targeted scenario\nrecommendation. By analyzing performance logs, SERA identifies failure patterns\nand dynamically retrieves semantically aligned scenarios from a structured\nbank. An LLM-based reflection mechanism further refines these recommendations\nto maximize relevance and diversity. The selected scenarios are used for\nfew-shot fine-tuning, enabling targeted adaptation with minimal data.\nExperiments on the benchmark show that SERA consistently improves key metrics\nacross multiple autonomous driving baselines, demonstrating its effectiveness\nand generalizability under safety-critical conditions.",
    "pdf_url": "http://arxiv.org/pdf/2505.22067v1",
    "published": "2025-05-28T07:46:19+00:00",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.22066v1",
    "title": "Cosmic Strings as Dynamical Dark Energy: Novel Constraints",
    "authors": [
      "Hanyu Cheng",
      "Eleonora Di Valentino",
      "Luca Visinelli"
    ],
    "abstract": "Cosmic strings, topological defects predicted by high-energy theories, may\ncontribute to the late-time expansion of the Universe, effectively mimicking\ndynamical dark energy. We investigate four phenomenological extensions of the\n$\\Lambda$CDM model involving a residual string network: (i) a non-relativistic\ncomponent with positive energy density (Model~1), (ii) a velocity-dependent\nextension (Model~2), (iii) a non-relativistic string network with energy\ndensity allowed to take both positive and negative values (Model~3), and (iv) a\ngeneral scenario with free energy and velocity parameters (Model~4). These\nmodels are constrained using \\textit{Planck} CMB data, SDSS or DESI baryon\nacoustic oscillations, and Type Ia supernovae observations. Models~1 and~2\nyield strong upper bounds on the string density, for example,\n$\\Omega_{\\mathrm{s}} < 0.00901$ at 95\\% CL from the CMB+DESI+DESY5 combination\nfor Model~2, and mildly shift the inferred value of $H_0$ upward, though they\nare not favored by Bayesian evidence. For the same combination, the bulk\nvelocity is bound as $v_{\\mathrm{s}} < 0.569$. Models~3 and~4 exhibit a\nconsistent preference for slightly negative values of $\\Omega_{\\mathrm{s}}$,\nwith CMB-only data yielding $\\Omega_{\\mathrm{s}} = -0.038^{+0.029}_{-0.022}$\nand $v_{\\mathrm{s}}< 0.574$ in Model~4, and a best-fit improvement of $\\Delta\n\\chi^2 = -6.07$. However, these improvements are not sufficient to overcome the\nOccam penalty, and the Bayesian evidence continues to favor $\\Lambda$CDM. These\nfindings demonstrate the power of current data to constrain exotic energy\ncomponents and encourage further exploration of string-inspired extensions to\n$\\Lambda$CDM, particularly those involving negative-tension networks.",
    "pdf_url": "http://arxiv.org/pdf/2505.22066v1",
    "published": "2025-05-28T07:45:53+00:00",
    "categories": [
      "astro-ph.CO",
      "hep-ph"
    ],
    "primary_category": "astro-ph.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.22065v1",
    "title": "AquaMonitor: A multimodal multi-view image sequence dataset for real-life aquatic invertebrate biodiversity monitoring",
    "authors": [
      "Mikko Impi√∂",
      "Philipp M. Rehsen",
      "Tiina Laamanen",
      "Arne J. Beermann",
      "Florian Leese",
      "Jenni Raitoharju"
    ],
    "abstract": "This paper presents the AquaMonitor dataset, the first large computer vision\ndataset of aquatic invertebrates collected during routine environmental\nmonitoring. While several large species identification datasets exist, they are\nrarely collected using standardized collection protocols, and none focus on\naquatic invertebrates, which are particularly laborious to collect. For\nAquaMonitor, we imaged all specimens from two years of monitoring whenever\nimaging was possible given practical limitations. The dataset enables the\nevaluation of automated identification methods for real-life monitoring\npurposes using a realistically challenging and unbiased setup. The dataset has\n2.7M images from 43,189 specimens, DNA sequences for 1358 specimens, and dry\nmass and size measurements for 1494 specimens, making it also one of the\nlargest biological multi-view and multimodal datasets to date. We define three\nbenchmark tasks and provide strong baselines for these: 1) Monitoring\nbenchmark, reflecting real-life deployment challenges such as open-set\nrecognition, distribution shift, and extreme class imbalance, 2) Classification\nbenchmark, which follows a standard fine-grained visual categorization setup,\nand 3) Few-shot benchmark, which targets classes with only few training\nexamples from very fine-grained categories. Advancements on the Monitoring\nbenchmark can directly translate to improvement of aquatic biodiversity\nmonitoring, which is an important component of regular legislative water\nquality assessment in many countries.",
    "pdf_url": "http://arxiv.org/pdf/2505.22065v1",
    "published": "2025-05-28T07:45:20+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.22064v1",
    "title": "Generic weights for finite reductive groups",
    "authors": [
      "Zhicheng Feng",
      "Gunter Malle",
      "Jiping Zhang"
    ],
    "abstract": "This paper is motivated by the study of Alperin's weight conjecture in the\nrepresentation theory of finite groups. We generalize the notion of\n$e$-cuspidality in the $e$-Harish-Chandra theory of finite reductive groups,\nand define generic weights in non-defining characteristic. We show that the\ngeneric weights play an analogous role as the weights defined by Alperin in the\ninvestigation of the inductive Alperin weight condition for simple groups of\nLie type at most good primes. We hope that our approach will constitute a step\ntowards an eventual proof of Alperin's weight conjecture.",
    "pdf_url": "http://arxiv.org/pdf/2505.22064v1",
    "published": "2025-05-28T07:44:16+00:00",
    "categories": [
      "math.RT",
      "math.GR",
      "20C33, 20C20, 20G40"
    ],
    "primary_category": "math.RT"
  },
  {
    "id": "http://arxiv.org/abs/2505.23828v1",
    "title": "Spa-VLM: Stealthy Poisoning Attacks on RAG-based VLM",
    "authors": [
      "Lei Yu",
      "Yechao Zhang",
      "Ziqi Zhou",
      "Yang Wu",
      "Wei Wan",
      "Minghui Li",
      "Shengshan Hu",
      "Pei Xiaobing",
      "Jing Wang"
    ],
    "abstract": "With the rapid development of the Vision-Language Model (VLM), significant\nprogress has been made in Visual Question Answering (VQA) tasks. However,\nexisting VLM often generate inaccurate answers due to a lack of up-to-date\nknowledge. To address this issue, recent research has introduced\nRetrieval-Augmented Generation (RAG) techniques, commonly used in Large\nLanguage Models (LLM), into VLM, incorporating external multi-modal knowledge\nto enhance the accuracy and practicality of VLM systems. Nevertheless, the RAG\nin LLM may be susceptible to data poisoning attacks. RAG-based VLM may also\nface the threat of this attack. This paper first reveals the vulnerabilities of\nthe RAG-based large model under poisoning attack, showing that existing\nsingle-modal RAG poisoning attacks have a 100\\% failure rate in multi-modal RAG\nscenarios. To address this gap, we propose Spa-VLM (Stealthy Poisoning Attack\non RAG-based VLM), a new paradigm for poisoning attacks on large models. We\ncarefully craft malicious multi-modal knowledge entries, including adversarial\nimages and misleading text, which are then injected into the RAG's knowledge\nbase. When users access the VLM service, the system may generate misleading\noutputs. We evaluate Spa-VLM on two Wikipedia datasets and across two different\nRAGs. Results demonstrate that our method achieves highly stealthy poisoning,\nwith the attack success rate exceeding 0.8 after injecting just 5 malicious\nentries into knowledge bases with 100K and 2M entries, outperforming\nstate-of-the-art poisoning attacks designed for RAG-based LLMs. Additionally,\nwe evaluated several defense mechanisms, all of which ultimately proved\nineffective against Spa-VLM, underscoring the effectiveness and robustness of\nour attack.",
    "pdf_url": "http://arxiv.org/pdf/2505.23828v1",
    "published": "2025-05-28T07:44:10+00:00",
    "categories": [
      "cs.CR"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.22063v1",
    "title": "Weakly Supervised Data Refinement and Flexible Sequence Compression for Efficient Thai LLM-based ASR",
    "authors": [
      "Mingchen Shao",
      "Xinfa Zhu",
      "Chengyou Wang",
      "Bingshen Mu",
      "Hai Li",
      "Ying Yan",
      "Junhui Liu",
      "Danming Xie",
      "Lei Xie"
    ],
    "abstract": "Despite remarkable achievements, automatic speech recognition (ASR) in\nlow-resource scenarios still faces two challenges: high-quality data scarcity\nand high computational demands. This paper proposes EThai-ASR, the first to\napply large language models (LLMs) to Thai ASR and create an efficient\nLLM-based ASR system. EThai-ASR comprises a speech encoder, a connection module\nand a Thai LLM decoder. To address the data scarcity and obtain a powerful\nspeech encoder, EThai-ASR introduces a self-evolving data refinement strategy\nto refine weak labels, yielding an enhanced speech encoder. Moreover, we\npropose a pluggable sequence compression module used in the connection module\nwith three modes designed to reduce the sequence length, thus decreasing\ncomputational demands while maintaining decent performance. Extensive\nexperiments demonstrate that EThai-ASR has achieved state-of-the-art accuracy\nin multiple datasets. We release our refined text transcripts to promote\nfurther research.",
    "pdf_url": "http://arxiv.org/pdf/2505.22063v1",
    "published": "2025-05-28T07:39:25+00:00",
    "categories": [
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.SD"
  },
  {
    "id": "http://arxiv.org/abs/2505.22062v2",
    "title": "Further Characterization of the JadePix-3 CMOS Pixel Sensor for the CEPC Vertex Detector",
    "authors": [
      "Jiahao Hu",
      "Ruiyang Zhang",
      "Zhiliang Chen",
      "Yunpeng Lu",
      "Qun Ouyang",
      "Lailin Xu"
    ],
    "abstract": "The Circular Electron-Positron Collider (CEPC), a proposed next-generation\n$e^+e^-$ collider to enable high-precision studies of the Higgs boson and\npotential new physics, imposes rigorous demands on detector technologies,\nparticularly the vertex detector. JadePix-3 is a prototype Monolithic Active\nPixel Sensor (MAPS) designed for the CEPC vertex detector. This paper presents\na detailed laboratory-based characterization of the JadePix-3 sensor, focusing\non the previously under-explored effects of substrate reverse bias voltage on\nkey performance metrics: charge collection efficiency, average cluster size,\nand detection efficiency. Systematic testing demonstrated that JadePix-3\noperates reliably under reverse bias, exhibiting a reduced input capacitance,\nan expanded depletion region, enhanced charge collection efficiency, and a\nlower fake-hit rate. These findings confirm the sensor's potential for\nhigh-precision particle tracking and vertexing at the CEPC while offering\nvaluable references for future iterational R\\&D of the JadePix series.",
    "pdf_url": "http://arxiv.org/pdf/2505.22062v2",
    "published": "2025-05-28T07:37:35+00:00",
    "categories": [
      "physics.ins-det",
      "hep-ex"
    ],
    "primary_category": "physics.ins-det"
  },
  {
    "id": "http://arxiv.org/abs/2505.22061v1",
    "title": "Safeguarding Privacy of Retrieval Data against Membership Inference Attacks: Is This Query Too Close to Home?",
    "authors": [
      "Yujin Choi",
      "Youngjoo Park",
      "Junyoung Byun",
      "Jaewook Lee",
      "Jinseong Park"
    ],
    "abstract": "Retrieval-augmented generation (RAG) mitigates the hallucination problem in\nlarge language models (LLMs) and has proven effective for specific,\npersonalized applications. However, passing private retrieved documents\ndirectly to LLMs introduces vulnerability to membership inference attacks\n(MIAs), which try to determine whether the target datum exists in the private\nexternal database or not. Based on the insight that MIA queries typically\nexhibit high similarity to only one target document, we introduce Mirabel, a\nsimilarity-based MIA detection framework designed for the RAG system. With the\nproposed Mirabel, we show that simple detect-and-hide strategies can\nsuccessfully obfuscate attackers, maintain data utility, and remain\nsystem-agnostic. We experimentally prove its detection and defense against\nvarious state-of-the-art MIA methods and its adaptability to existing private\nRAG systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.22061v1",
    "published": "2025-05-28T07:35:07+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.22060v1",
    "title": "SAT Strikes Back: Parameter and Path Relations in Quantum Toolchains",
    "authors": [
      "Lukas Schmidbauer",
      "Wolfgang Mauerer"
    ],
    "abstract": "In the foreseeable future, toolchains for quantum computing should offer\nautomatic means of transforming a high level problem formulation down to a\nhardware executable form. Thereby, it is crucial to find (multiple)\ntransformation paths that are optimised for (hardware specific) metrics. We\nzoom into this pictured tree of transformations by focussing on k-SAT instances\nas input and their transformation to QUBO, while considering structure and\ncharacteristic metrics of input, intermediate and output representations. Our\nresults can be used to rate valid paths of transformation in advance -- also in\nautomated (quantum) toolchains. We support the automation aspect by considering\nstability and therefore predictability of free parameters and transformation\npaths. Moreover, our findings can be used in the manifesting era of error\ncorrection (since considering structure in a high abstraction layer can benefit\nerror correcting codes in layers below). We also show that current research is\nclosely linked to quadratisation techniques and their mathematical foundation.",
    "pdf_url": "http://arxiv.org/pdf/2505.22060v1",
    "published": "2025-05-28T07:32:37+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.22059v2",
    "title": "Wasserstein metrics and quantitative equidistribution of exponential sums over finite fields",
    "authors": [
      "Emmanuel Kowalski",
      "Th√©o Untrau"
    ],
    "abstract": "The Wasserstein distance between probability measures on compact spaces\nprovides a natural invariant quantitative measure of equidistribution, which is\npartly similar to the classical discrepancy appearing in Erd\\\"os-Tur\\'an type\ninequalities in the case of tori, but is a more intrinsic quantity. We recall\nthe basic properties of Wasserstein distances and present applications to\nquantitative forms of equidistribution of exponential sums in two examples, one\nrelated to our previous work on the equidistribution of ultra-short exponential\nsums, and the second a quantitative form of the equidistribution theorems of\nDeligne and Katz.",
    "pdf_url": "http://arxiv.org/pdf/2505.22059v2",
    "published": "2025-05-28T07:29:40+00:00",
    "categories": [
      "math.NT",
      "11K38, 11L03, 11T23, 49Q22"
    ],
    "primary_category": "math.NT"
  },
  {
    "id": "http://arxiv.org/abs/2505.22058v1",
    "title": "The experimental determination of exchange mass terms in surface states on both terminations of MnBi4Te7",
    "authors": [
      "Dezhi Song",
      "Fuyang Hang",
      "Gang Yao",
      "Jun Zhang",
      "Ye-Ping Jiang",
      "Jin-Feng Jia"
    ],
    "abstract": "The intrinsic antiferromagnetic topological insulators in the Mn-Bi-Te\nfamily, composed of superlattice-like MnBi2Te4/(Bi2Te3)n (n = 0, 1, 2, 3...)\nlayered structure, present intriguing states of matter such as quantum\nanomalous Hall effect and the axion insulator. However, the surface state gap,\nwhich is the prerequisite for the observation of these states, remains elusive.\nHere by molecular beam epitaxy, we obtain two types of MnBi4Te7 films with the\nexclusive Bi2Te3 (BT) or MnBi2Te4 (MBT) terminations. By scanning tunneling\nspectroscopy, the mass terms in the surface states are identified on both\nsurface terminations. Experimental results reveal the existence of a\nhybridization gap of approximately 23 meV in surface states on the BT\ntermination. This gap comes from the hybridization between the surface states\nand the spin-split states in the adjacent MBT layer. On the MBT termination, an\nexchange mass term of about 30 meV in surface states is identified by taking\nmagnetic-field-dependent Landau level spectra as well as theoretical\nsimulations. In addition, the mass term varies with the field in the film with\na heavy BiMn doping level in the Mn layers. These findings demonstrate the\nexistence of mass terms in surface states on both types of terminations in our\nepitaxial MnBi4Te7 films investigated by local probes.",
    "pdf_url": "http://arxiv.org/pdf/2505.22058v1",
    "published": "2025-05-28T07:28:58+00:00",
    "categories": [
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2505.22057v1",
    "title": "Shapley Value-driven Data Pruning for Recommender Systems",
    "authors": [
      "Yansen Zhang",
      "Xiaokun Zhang",
      "Ziqiang Cui",
      "Chen Ma"
    ],
    "abstract": "Recommender systems often suffer from noisy interactions like accidental\nclicks or popularity bias. Existing denoising methods typically identify users'\nintent in their interactions, and filter out noisy interactions that deviate\nfrom the assumed intent. However, they ignore that interactions deemed noisy\ncould still aid model training, while some ``clean'' interactions offer little\nlearning value. To bridge this gap, we propose Shapley Value-driven Valuation\n(SVV), a framework that evaluates interactions based on their objective impact\non model training rather than subjective intent assumptions. In SVV, a\nreal-time Shapley value estimation method is devised to quantify each\ninteraction's value based on its contribution to reducing training loss.\nAfterward, SVV highlights the interactions with high values while downplaying\nlow ones to achieve effective data pruning for recommender systems. In\naddition, we develop a simulated noise protocol to examine the performance of\nvarious denoising approaches systematically. Experiments on four real-world\ndatasets show that SVV outperforms existing denoising methods in both accuracy\nand robustness. Further analysis also demonstrates that our SVV can preserve\ntraining-critical interactions and offer interpretable noise assessment. This\nwork shifts denoising from heuristic filtering to principled, model-driven\ninteraction valuation.",
    "pdf_url": "http://arxiv.org/pdf/2505.22057v1",
    "published": "2025-05-28T07:27:59+00:00",
    "categories": [
      "cs.IR"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2505.22056v1",
    "title": "Systematic generation of electron models for Second-Principles Density Functional Theory Methods",
    "authors": [
      "Nayara Carral-Sainz",
      "Toraya Fern√°ndez-Ruiz",
      "Jorge √ç√±iguez",
      "Javier Junquera",
      "Pablo Garcia-Fernandez"
    ],
    "abstract": "We present a systematic, quasi-automated methodology for generating\nelectronic models in the framework of second-principles density functional\ntheory (SPDFT). This approach enables the construction of accurate and\ncomputationally efficient models by deriving all necessary parameters from\nfirst-principles calculations on a carefully designed training set. A key\nfeature of our method is the enforcement of space group symmetries, which\nreduces both the number of independent parameters and the required\ncomputational effort. The formalism includes improved treatments of\none-electron Hamiltonians, electron-lattice coupling-through both linear and\nquadratic terms-and electron-electron interactions, enabling accurate modeling\nof structural and electronic responses. We apply the methodology to SrTiO$_{3}$\nand LiF, materials representative of transition-metal perovskites and\nwide-band-gap insulators, respectively. In both cases, the resulting models\nreproduce DFT reference data with high fidelity across various atomic\nconfigurations and charge states. Our results validate the robustness of the\napproach and highlight its potential for simulating complex phenomena such as\npolarons and excitons. This work lays the foundation for extending SPDFT to\nreal-time simulations of optoelectronic properties and further integration with\nmachine-learning methods.",
    "pdf_url": "http://arxiv.org/pdf/2505.22056v1",
    "published": "2025-05-28T07:27:04+00:00",
    "categories": [
      "cond-mat.mtrl-sci",
      "cond-mat.other"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2505.22055v1",
    "title": "On the Chromatic Number of Grassmann Graphs",
    "authors": [
      "Jozefien D'haeseleer",
      "Vladislav Taranchuk"
    ],
    "abstract": "In this paper we study the chromatic number of the Grassmann graphs $J_q(n,\nm)$. We show that $\\binom{n-m+1}{1}_q \\leq \\chi(J_q(n, m)) \\leq\n\\binom{n}{1}_q$, which is analogous to the best-known bounds for the chromatic\nnumber of the Johnson graphs $J(n, m)$. When $m = 2$, determining $\\chi(J_q(n,\n2))$ is equivalent to determining the smallest number of partial line\nparallelisms that one can partition the lines of PG$(n-1, q)$ into. We survey\nknown results about line parallelisms and their implications for $\\chi(J_q(n,\n2))$. Finally, we prove that when $q$ is any power of two, and $n$ is any even\ninteger, then $\\chi(J_q(n, 2)) < 2\\binom{n-1}{1}_q$.",
    "pdf_url": "http://arxiv.org/pdf/2505.22055v1",
    "published": "2025-05-28T07:24:56+00:00",
    "categories": [
      "math.CO",
      "05B25 (Primary) 05B40, 52C17 (Secondary)"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.22054v1",
    "title": "Voice Adaptation for Swiss German",
    "authors": [
      "Samuel Stucki",
      "Jan Deriu",
      "Mark Cieliebak"
    ],
    "abstract": "This work investigates the performance of Voice Adaptation models for Swiss\nGerman dialects, i.e., translating Standard German text to Swiss German dialect\nspeech. For this, we preprocess a large dataset of Swiss podcasts, which we\nautomatically transcribe and annotate with dialect classes, yielding\napproximately 5000 hours of weakly labeled training material. We fine-tune the\nXTTSv2 model on this dataset and show that it achieves good scores in human and\nautomated evaluations and can correctly render the desired dialect. Our work\nshows a step towards adapting Voice Cloning technology to underrepresented\nlanguages. The resulting model achieves CMOS scores of up to -0.28 and SMOS\nscores of 3.8.",
    "pdf_url": "http://arxiv.org/pdf/2505.22054v1",
    "published": "2025-05-28T07:24:40+00:00",
    "categories": [
      "cs.CL",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.22053v2",
    "title": "AudioGenie: A Training-Free Multi-Agent Framework for Diverse Multimodality-to-Multiaudio Generation",
    "authors": [
      "Yan Rong",
      "Jinting Wang",
      "Guangzhi Lei",
      "Shan Yang",
      "Li Liu"
    ],
    "abstract": "Multimodality-to-Multiaudio (MM2MA) generation faces significant challenges\nin synthesizing diverse and contextually aligned audio types (e.g., sound\neffects, speech, music, and songs) from multimodal inputs (e.g., video, text,\nimages), owing to the scarcity of high-quality paired datasets and the lack of\nrobust multi-task learning frameworks. Recently, multi-agent system shows great\npotential in tackling the above issues. However, directly applying it to MM2MA\ntask presents three critical challenges: (1) inadequate fine-grained\nunderstanding of multimodal inputs (especially for video), (2) the inability of\nsingle models to handle diverse audio events, and (3) the absence of\nself-correction mechanisms for reliable outputs. To this end, we propose\nAudioGenie, a novel training-free multi-agent system featuring a dual-layer\narchitecture with a generation team and a supervisor team. For the generation\nteam, a fine-grained task decomposition and an adaptive Mixture-of-Experts\n(MoE) collaborative entity are designed for detailed comprehensive multimodal\nunderstanding and dynamic model selection, and a trial-and-error iterative\nrefinement module is designed for self-correction. The supervisor team ensures\ntemporal-spatial consistency and verifies outputs through feedback loops.\nMoreover, we build MA-Bench, the first benchmark for MM2MA tasks, comprising\n198 annotated videos with multi-type audios. Experiments demonstrate that our\nAudioGenie achieves state-of-the-art (SOTA) or comparable performance across 9\nmetrics in 8 tasks. User study further validates the effectiveness of our\nmethod in terms of quality, accuracy, alignment, and aesthetic. The project\nwebsite with audio samples can be found at https://audiogenie.github.io/.",
    "pdf_url": "http://arxiv.org/pdf/2505.22053v2",
    "published": "2025-05-28T07:23:53+00:00",
    "categories": [
      "cs.SD",
      "cs.MA",
      "cs.MM",
      "eess.AS"
    ],
    "primary_category": "cs.SD"
  },
  {
    "id": "http://arxiv.org/abs/2505.22052v1",
    "title": "A Comparative Study of Fuzzers and Static Analysis Tools for Finding Memory Unsafety in C and C++",
    "authors": [
      "Keno Hassler",
      "Philipp G√∂rz",
      "Stephan Lipp",
      "Thorsten Holz",
      "Marcel B√∂hme"
    ],
    "abstract": "Even today, over 70% of security vulnerabilities in critical software systems\nresult from memory safety violations. To address this challenge, fuzzing and\nstatic analysis are widely used automated methods to discover such\nvulnerabilities. Fuzzing generates random program inputs to identify faults,\nwhile static analysis examines source code to detect potential vulnerabilities.\nAlthough these techniques share a common goal, they take fundamentally\ndifferent approaches and have evolved largely independently.\n  In this paper, we present an empirical analysis of five static analyzers and\n13 fuzzers, applied to over 100 known security vulnerabilities in C/C++\nprograms. We measure the number of bug reports generated for each vulnerability\nto evaluate how the approaches differ and complement each other. Moreover, we\nrandomly sample eight bug-containing functions, manually analyze all bug\nreports therein, and quantify false-positive rates. We also assess limits to\nbug discovery, ease of use, resource requirements, and integration into the\ndevelopment process. We find that both techniques discover different types of\nbugs, but there are clear winners for each. Developers should consider these\ntools depending on their specific workflow and usability requirements. Based on\nour findings, we propose future directions to foster collaboration between\nthese research domains.",
    "pdf_url": "http://arxiv.org/pdf/2505.22052v1",
    "published": "2025-05-28T07:22:29+00:00",
    "categories": [
      "cs.CR"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.22051v2",
    "title": "ARiSE: Auto-Regressive Multi-Channel Speech Enhancement",
    "authors": [
      "Pengjie Shen",
      "Xueliang Zhang",
      "Zhong-Qiu Wang"
    ],
    "abstract": "We propose ARiSE, an auto-regressive algorithm for multi-channel speech\nenhancement. ARiSE improves existing deep neural network (DNN) based\nframe-online multi-channel speech enhancement models by introducing\nauto-regressive connections, where the estimated target speech at previous\nframes is leveraged as extra input features to help the DNN estimate the target\nspeech at the current frame. The extra input features can be derived from (a)\nthe estimated target speech in previous frames; and (b) a beamformed mixture\nwith the beamformer computed based on the previous estimated target speech. On\nthe other hand, naively training the DNN in an auto-regressive manner is very\nslow. To deal with this, we propose a parallel training mechanism to speed up\nthe training. Evaluation results in noisy-reverberant conditions show the\neffectiveness and potential of the proposed algorithms.",
    "pdf_url": "http://arxiv.org/pdf/2505.22051v2",
    "published": "2025-05-28T07:22:28+00:00",
    "categories": [
      "eess.AS"
    ],
    "primary_category": "eess.AS"
  },
  {
    "id": "http://arxiv.org/abs/2505.22050v2",
    "title": "Reinforced Reasoning for Embodied Planning",
    "authors": [
      "Di Wu",
      "Jiaxin Fan",
      "Junzhe Zang",
      "Guanbo Wang",
      "Wei Yin",
      "Wenhao Li",
      "Bo Jin"
    ],
    "abstract": "Embodied planning requires agents to make coherent multi-step decisions based\non dynamic visual observations and natural language goals. While recent\nvision-language models (VLMs) excel at static perception tasks, they struggle\nwith the temporal reasoning, spatial understanding, and commonsense grounding\nneeded for planning in interactive environments. In this work, we introduce a\nreinforcement fine-tuning framework that brings R1-style reasoning enhancement\ninto embodied planning. We first distill a high-quality dataset from a powerful\nclosed-source model and perform supervised fine-tuning (SFT) to equip the model\nwith structured decision-making priors. We then design a rule-based reward\nfunction tailored to multi-step action quality and optimize the policy via\nGeneralized Reinforced Preference Optimization (GRPO). Our approach is\nevaluated on Embench, a recent benchmark for interactive embodied tasks,\ncovering both in-domain and out-of-domain scenarios. Experimental results show\nthat our method significantly outperforms models of similar or larger scale,\nincluding GPT-4o-mini and 70B+ open-source baselines, and exhibits strong\ngeneralization to unseen environments. This work highlights the potential of\nreinforcement-driven reasoning to advance long-horizon planning in embodied AI.",
    "pdf_url": "http://arxiv.org/pdf/2505.22050v2",
    "published": "2025-05-28T07:21:37+00:00",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.22049v1",
    "title": "Differentiable Generalized Sliced Wasserstein Plans",
    "authors": [
      "Laetitia Chapel",
      "Romain Tavenard",
      "Samuel Vaiter"
    ],
    "abstract": "Optimal Transport (OT) has attracted significant interest in the machine\nlearning community, not only for its ability to define meaningful distances\nbetween probability distributions -- such as the Wasserstein distance -- but\nalso for its formulation of OT plans. Its computational complexity remains a\nbottleneck, though, and slicing techniques have been developed to scale OT to\nlarge datasets. Recently, a novel slicing scheme, dubbed min-SWGG, lifts a\nsingle one-dimensional plan back to the original multidimensional space,\nfinally selecting the slice that yields the lowest Wasserstein distance as an\napproximation of the full OT plan. Despite its computational and theoretical\nadvantages, min-SWGG inherits typical limitations of slicing methods: (i) the\nnumber of required slices grows exponentially with the data dimension, and (ii)\nit is constrained to linear projections. Here, we reformulate min-SWGG as a\nbilevel optimization problem and propose a differentiable approximation scheme\nto efficiently identify the optimal slice, even in high-dimensional settings.\nWe furthermore define its generalized extension for accommodating to data\nliving on manifolds. Finally, we demonstrate the practical value of our\napproach in various applications, including gradient flows on manifolds and\nhigh-dimensional spaces, as well as a novel sliced OT-based conditional flow\nmatching for image generation -- where fast computation of transport plans is\nessential.",
    "pdf_url": "http://arxiv.org/pdf/2505.22049v1",
    "published": "2025-05-28T07:18:08+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.22048v1",
    "title": "Learning Curves of Stochastic Gradient Descent in Kernel Regression",
    "authors": [
      "Haihan Zhang",
      "Weicheng Lin",
      "Yuanshi Liu",
      "Cong Fang"
    ],
    "abstract": "This paper considers a canonical problem in kernel regression: how good are\nthe model performances when it is trained by the popular online first-order\nalgorithms, compared to the offline ones, such as ridge and ridgeless\nregression? In this paper, we analyze the foundational single-pass Stochastic\nGradient Descent (SGD) in kernel regression under source condition where the\noptimal predictor can even not belong to the RKHS, i.e. the model is\nmisspecified. Specifically, we focus on the inner product kernel over the\nsphere and characterize the exact orders of the excess risk curves under\ndifferent scales of sample sizes $n$ concerning the input dimension $d$.\nSurprisingly, we show that SGD achieves min-max optimal rates up to constants\namong all the scales, without suffering the saturation, a prevalent phenomenon\nobserved in (ridge) regression, except when the model is highly misspecified\nand the learning is in a final stage where $n\\gg d^{\\gamma}$ with any constant\n$\\gamma >0$. The main reason for SGD to overcome the curse of saturation is the\nexponentially decaying step size schedule, a common practice in deep neural\nnetwork training. As a byproduct, we provide the \\emph{first} provable\nadvantage of the scheme over the iterative averaging method in the common\nsetting.",
    "pdf_url": "http://arxiv.org/pdf/2505.22048v1",
    "published": "2025-05-28T07:16:11+00:00",
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2505.22047v1",
    "title": "Organizational Regularities in Recurrent Neural Networks",
    "authors": [
      "Claus Metzner",
      "Achim Schilling",
      "Andreas Maier",
      "Patrick Krauss"
    ],
    "abstract": "Previous work has shown that the dynamical regime of Recurrent Neural\nNetworks (RNNs) - ranging from oscillatory to chaotic and fixpoint behavior -\ncan be controlled by the global distribution of weights in connection matrices\nwith statistically independent elements. However, it remains unclear how\nnetwork dynamics respond to organizational regularities in the weight matrix,\nas often observed in biological neural networks. Here, we investigate three\nsuch regularities: (1) monopolar output weights per neuron, in accordance with\nDale's principle, (2) reciprocal symmetry between neuron pairs, as in Hopfield\nnetworks, and (3) modular structure, where strongly connected blocks are\nembedded in a background of weaker connectivity. We construct weight matrices\nin which the strength of each regularity can be continuously tuned via control\nparameters, and analyze how key dynamical signatures of the RNN evolve as a\nfunction of these parameters. Moreover, using the RNN for actual information\nprocessing in a reservoir computing framework, we study how each regularity\naffects performance. We find that Dale monopolarity and modularity\nsignificantly enhance task accuracy, while Hopfield reciprocity tends to reduce\nit by promoting early saturation, limiting reservoir flexibility.",
    "pdf_url": "http://arxiv.org/pdf/2505.22047v1",
    "published": "2025-05-28T07:13:43+00:00",
    "categories": [
      "q-bio.NC"
    ],
    "primary_category": "q-bio.NC"
  },
  {
    "id": "http://arxiv.org/abs/2506.15696v1",
    "title": "CoC: Chain-of-Cancer based on Cross-Modal Autoregressive Traction for Survival Prediction",
    "authors": [
      "Haipeng Zhou",
      "Sicheng Yang",
      "Sihan Yang",
      "Jing Qin",
      "Lei Chen",
      "Lei Zhu"
    ],
    "abstract": "Survival prediction aims to evaluate the risk level of cancer patients.\nExisting methods primarily rely on pathology and genomics data, either\nindividually or in combination. From the perspective of cancer pathogenesis,\nepigenetic changes, such as methylation data, could also be crucial for this\ntask. Furthermore, no previous endeavors have utilized textual descriptions to\nguide the prediction. To this end, we are the first to explore the use of four\nmodalities, including three clinical modalities and language, for conducting\nsurvival prediction. In detail, we are motivated by the Chain-of-Thought (CoT)\nto propose the Chain-of-Cancer (CoC) framework, focusing on intra-learning and\ninter-learning. We encode the clinical data as the raw features, which remain\ndomain-specific knowledge for intra-learning. In terms of inter-learning, we\nuse language to prompt the raw features and introduce an Autoregressive Mutual\nTraction module for synergistic representation. This tailored framework\nfacilitates joint learning among multiple modalities. Our approach is evaluated\nacross five public cancer datasets, and extensive experiments validate the\neffectiveness of our methods and proposed designs, leading to producing \\sota\nresults. Codes will be released.",
    "pdf_url": "http://arxiv.org/pdf/2506.15696v1",
    "published": "2025-05-28T07:11:49+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.22046v2",
    "title": "LatentMove: Towards Complex Human Movement Video Generation",
    "authors": [
      "Ashkan Taghipour",
      "Morteza Ghahremani",
      "Mohammed Bennamoun",
      "Farid Boussaid",
      "Aref Miri Rekavandi",
      "Zinuo Li",
      "Qiuhong Ke",
      "Hamid Laga"
    ],
    "abstract": "Image-to-video (I2V) generation seeks to produce realistic motion sequences\nfrom a single reference image. Although recent methods exhibit strong temporal\nconsistency, they often struggle when dealing with complex, non-repetitive\nhuman movements, leading to unnatural deformations. To tackle this issue, we\npresent LatentMove, a DiT-based framework specifically tailored for highly\ndynamic human animation. Our architecture incorporates a conditional control\nbranch and learnable face/body tokens to preserve consistency as well as\nfine-grained details across frames. We introduce Complex-Human-Videos (CHV), a\ndataset featuring diverse, challenging human motions designed to benchmark the\nrobustness of I2V systems. We also introduce two metrics to assess the flow and\nsilhouette consistency of generated videos with their ground truth.\nExperimental results indicate that LatentMove substantially improves human\nanimation quality--particularly when handling rapid, intricate\nmovements--thereby pushing the boundaries of I2V generation. The code, the CHV\ndataset, and the evaluation metrics will be available at https://github.com/\n--.",
    "pdf_url": "http://arxiv.org/pdf/2505.22046v2",
    "published": "2025-05-28T07:10:49+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.22045v1",
    "title": "Mitigating Audiovisual Mismatch in Visual-Guide Audio Captioning",
    "authors": [
      "Le Xu",
      "Chenxing Li",
      "Yong Ren",
      "Yujie Chen",
      "Yu Gu",
      "Ruibo Fu",
      "Shan Yang",
      "Dong Yu"
    ],
    "abstract": "Current vision-guided audio captioning systems frequently fail to address\naudiovisual misalignment in real-world scenarios, such as dubbed content or\noff-screen sounds. To bridge this critical gap, we present an entropy-aware\ngated fusion framework that dynamically modulates visual information flow\nthrough cross-modal uncertainty quantification. Our novel approach employs\nattention entropy analysis in cross-attention layers to automatically identify\nand suppress misleading visual cues during modal fusion. Complementing this\narchitecture, we develop a batch-wise audiovisual shuffling technique that\ngenerates synthetic mismatched training pairs, greatly enhancing model\nresilience against alignment noise. Evaluations on the AudioCaps benchmark\ndemonstrate our system's superior performance over existing baselines,\nespecially in mismatched modality scenarios. Furthermore, our solution\ndemonstrates an approximately 6x improvement in inference speed compared to the\nbaseline.",
    "pdf_url": "http://arxiv.org/pdf/2505.22045v1",
    "published": "2025-05-28T07:08:17+00:00",
    "categories": [
      "cs.MM",
      "cs.CV",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.MM"
  },
  {
    "id": "http://arxiv.org/abs/2505.22044v1",
    "title": "Design and implementation of the constant fraction discriminator for glass MRPC timing",
    "authors": [
      "L. L. Kurchaninov",
      "E. A. Ladygin",
      "V. P. Ladygin",
      "A. A. Semak"
    ],
    "abstract": "The analog front-end electronics based on the constant fraction\ndiscrimination method is designed and optimized for the Multigap Resistive\nPlate Chamber (MRPC) timing measurements. The total time resolution of 40 ps\nhas been obtained for 10 and 12 gaps MRPCs using cosmic setup and a muon beam\nat the IHEP U-70 accelerator in Protvino, which complies with the conditions of\nthe SPD experiment at NICA.",
    "pdf_url": "http://arxiv.org/pdf/2505.22044v1",
    "published": "2025-05-28T07:07:34+00:00",
    "categories": [
      "physics.ins-det"
    ],
    "primary_category": "physics.ins-det"
  },
  {
    "id": "http://arxiv.org/abs/2505.22043v1",
    "title": "Perfect fluid equations with N=1,2 Schrodinger supersymmetry",
    "authors": [
      "Timofei Snegirev"
    ],
    "abstract": "Superconformal extensions of the perfect fluid equations, which realize\n$N=1,2$ Schrodinger superalgebra, are constructed within the Hamiltonian\nformalism. They are built by introducing real (for $N=1$) or complex (for\n$N=2$) anticommuting field variables as superpartners for the density and\nvelocity of a fluid. The full set of conserved charges associated with the\n$N=1,2$ Schrodinger superalgebra is constructed. Within the Lagrangian\nformalism, when the Clebsch decomposition for the velocity vector field is\nused, the anticommuting variables can be interpreted as potentials\nparameterizing fluid's vorticity.",
    "pdf_url": "http://arxiv.org/pdf/2505.22043v1",
    "published": "2025-05-28T07:07:06+00:00",
    "categories": [
      "hep-th"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2505.22042v1",
    "title": "Estimating the Effects of Sample Training Orders for Large Language Models without Retraining",
    "authors": [
      "Hao Yang",
      "Haoxuan Li",
      "Mengyue Yang",
      "Xu Chen",
      "Mingming Gong"
    ],
    "abstract": "The order of training samples plays a crucial role in large language models\n(LLMs), significantly impacting both their external performance and internal\nlearning dynamics. Traditional methods for investigating this effect generally\nrequire retraining the model with various sample orders, which is\ncomputationally infeasible for LLMs. In this work, we improve traditional\nmethods by designing a retraining-free framework. By approximating Adam\noptimizer updates with first- and second-order Taylor expansions and utilizing\nrandom projection methods to store intermediate checkpoints, our framework can\nefficiently estimate model parameters for arbitrary training sample orders.\nNext, we apply our framework to two downstream research problems: (1) Training\ncurriculum design for LLMs -- we base our retraining-free framework to propose\na novel curriculum learning strategy that augments curriculum proposals with\nestimated model performances, enabling more informed sample scheduling. (2)\nLLMs' memorization and generalization effect analysis -- we use our\nretraining-free framework to estimate how the positions of training samples\ninfluence LLMs' capacity for memorization and generalization. We conduct\nextensive experiments to validate the effectiveness of our retraining-free\nframework in reproducing the true model performances, and further demonstrate\nits potential in optimizing LLM training curricula and analyzing the\nmemorization and generalization effects of LLMs.",
    "pdf_url": "http://arxiv.org/pdf/2505.22042v1",
    "published": "2025-05-28T07:07:02+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.22041v1",
    "title": "Detecting Undesired Process Behavior by Means of Retrieval Augmented Generation",
    "authors": [
      "Michael Grohs",
      "Adrian Rebmann",
      "Jana-Rebecca Rehse"
    ],
    "abstract": "Conformance checking techniques detect undesired process behavior by\ncomparing process executions that are recorded in event logs to desired\nbehavior that is captured in a dedicated process model. If such models are not\navailable, conformance checking techniques are not applicable, but\norganizations might still be interested in detecting undesired behavior in\ntheir processes. To enable this, existing approaches use Large Language Models\n(LLMs), assuming that they can learn to distinguish desired from undesired\nbehavior through fine-tuning. However, fine-tuning is highly resource-intensive\nand the fine-tuned LLMs often do not generalize well. To address these\nlimitations, we propose an approach that requires neither a dedicated process\nmodel nor resource-intensive fine-tuning to detect undesired process behavior.\nInstead, we use Retrieval Augmented Generation (RAG) to provide an LLM with\ndirect access to a knowledge base that contains both desired and undesired\nprocess behavior from other processes, assuming that the LLM can transfer this\nknowledge to the process at hand. Our evaluation shows that our approach\noutperforms fine-tuned LLMs in detecting undesired behavior, demonstrating that\nRAG is a viable alternative to resource-intensive fine-tuning, particularly\nwhen enriched with relevant context from the event log, such as frequent traces\nand activities.",
    "pdf_url": "http://arxiv.org/pdf/2505.22041v1",
    "published": "2025-05-28T07:03:46+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.22040v1",
    "title": "A Hybrid Subgradient Method for Nonsmooth Nonconvex Bilevel Optimization",
    "authors": [
      "Nachuan Xiao",
      "Xiaoyin Hu",
      "Xin Liu",
      "Kim-Chuan Toh"
    ],
    "abstract": "In this paper, we focus on the nonconvex-nonconvex bilevel optimization\nproblem (BLO), where both upper-level and lower-level objectives are nonconvex,\nwith the upper-level problem potentially being nonsmooth. We develop a\ntwo-timescale momentum-accelerated subgradient method (TMG) that employs\ntwo-timescale stepsizes, and establish its local convergence when initialized\nwithin a sufficiently small neighborhood of the feasible region. To develop a\nglobally convergent algorithm for (BLO), we introduce a feasibility restoration\nscheme (FRG) that drives iterates toward the feasible region. Both (TMG) and\n(FRG) only require the first-order derivatives of the upper-level and\nlower-level objective functions, ensuring efficient computations in practice.\nWe then develop a novel hybrid method that alternates between (TMG) and (FRG)\nand adaptively estimates its hyperparameters. Under mild conditions, we\nestablish the global convergence properties of our proposed algorithm.\nPreliminary numerical experiments demonstrate the high efficiency and promising\npotential of our proposed algorithm.",
    "pdf_url": "http://arxiv.org/pdf/2505.22040v1",
    "published": "2025-05-28T07:02:26+00:00",
    "categories": [
      "math.OC"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2505.22039v1",
    "title": "OmniAD: Detect and Understand Industrial Anomaly via Multimodal Reasoning",
    "authors": [
      "Shifang Zhao",
      "Yiheng Lin",
      "Lu Han",
      "Yao Zhao",
      "Yunchao Wei"
    ],
    "abstract": "While anomaly detection has made significant progress, generating detailed\nanalyses that incorporate industrial knowledge remains a challenge. To address\nthis gap, we introduce OmniAD, a novel framework that unifies anomaly detection\nand understanding for fine-grained analysis. OmniAD is a multimodal reasoner\nthat combines visual and textual reasoning processes. The visual reasoning\nprovides detailed inspection by leveraging Text-as-Mask Encoding to perform\nanomaly detection through text generation without manually selected thresholds.\nFollowing this, Visual Guided Textual Reasoning conducts comprehensive analysis\nby integrating visual perception. To enhance few-shot generalization, we employ\nan integrated training strategy that combines supervised fine-tuning (SFT) with\nreinforcement learning (GRPO), incorporating three sophisticated reward\nfunctions. Experimental results demonstrate that OmniAD achieves a performance\nof 79.1 on the MMAD benchmark, surpassing models such as Qwen2.5-VL-7B and\nGPT-4o. It also shows strong results across multiple anomaly detection\nbenchmarks. These results highlight the importance of enhancing visual\nperception for effective reasoning in anomaly understanding. All codes and\nmodels will be publicly available.",
    "pdf_url": "http://arxiv.org/pdf/2505.22039v1",
    "published": "2025-05-28T07:02:15+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.22038v1",
    "title": "Balanced Token Pruning: Accelerating Vision Language Models Beyond Local Optimization",
    "authors": [
      "Kaiyuan Li",
      "Xiaoyue Chen",
      "Chen Gao",
      "Yong Li",
      "Xinlei Chen"
    ],
    "abstract": "Large Vision-Language Models (LVLMs) have shown impressive performance across\nmulti-modal tasks by encoding images into thousands of tokens. However, the\nlarge number of image tokens results in significant computational overhead, and\nthe use of dynamic high-resolution inputs further increases this burden.\nPrevious approaches have attempted to reduce the number of image tokens through\ntoken pruning, typically by selecting tokens based on attention scores or image\ntoken diversity. Through empirical studies, we observe that existing methods\noften overlook the joint impact of pruning on both the current layer's output\n(local) and the outputs of subsequent layers (global), leading to suboptimal\npruning decisions. To address this challenge, we propose Balanced Token Pruning\n(BTP), a plug-and-play method for pruning vision tokens. Specifically, our\nmethod utilizes a small calibration set to divide the pruning process into\nmultiple stages. In the early stages, our method emphasizes the impact of\npruning on subsequent layers, whereas in the deeper stages, the focus shifts\ntoward preserving the consistency of local outputs. Extensive experiments\nacross various LVLMs demonstrate the broad effectiveness of our approach on\nmultiple benchmarks. Our method achieves a 78% compression rate while\npreserving 96.7% of the original models' performance on average.",
    "pdf_url": "http://arxiv.org/pdf/2505.22038v1",
    "published": "2025-05-28T07:00:50+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.22037v1",
    "title": "Jailbreak Distillation: Renewable Safety Benchmarking",
    "authors": [
      "Jingyu Zhang",
      "Ahmed Elgohary",
      "Xiawei Wang",
      "A S M Iftekhar",
      "Ahmed Magooda",
      "Benjamin Van Durme",
      "Daniel Khashabi",
      "Kyle Jackson"
    ],
    "abstract": "Large language models (LLMs) are rapidly deployed in critical applications,\nraising urgent needs for robust safety benchmarking. We propose Jailbreak\nDistillation (JBDistill), a novel benchmark construction framework that\n\"distills\" jailbreak attacks into high-quality and easily-updatable safety\nbenchmarks. JBDistill utilizes a small set of development models and existing\njailbreak attack algorithms to create a candidate prompt pool, then employs\nprompt selection algorithms to identify an effective subset of prompts as\nsafety benchmarks. JBDistill addresses challenges in existing safety\nevaluation: the use of consistent evaluation prompts across models ensures fair\ncomparisons and reproducibility. It requires minimal human effort to rerun the\nJBDistill pipeline and produce updated benchmarks, alleviating concerns on\nsaturation and contamination. Extensive experiments demonstrate our benchmarks\ngeneralize robustly to 13 diverse evaluation models held out from benchmark\nconstruction, including proprietary, specialized, and newer-generation LLMs,\nsignificantly outperforming existing safety benchmarks in effectiveness while\nmaintaining high separability and diversity. Our framework thus provides an\neffective, sustainable, and adaptable solution for streamlining safety\nevaluation.",
    "pdf_url": "http://arxiv.org/pdf/2505.22037v1",
    "published": "2025-05-28T06:59:46+00:00",
    "categories": [
      "cs.CL",
      "cs.CR",
      "cs.SE"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.22036v1",
    "title": "The $L$-polynomials of van der Geer--van der Vlugt curves in characteristic $2$",
    "authors": [
      "Tetsushi Ito",
      "Daichi Takeuchi",
      "Takahiro Tsushima"
    ],
    "abstract": "The van der Geer--van der Vlugt curves form a class of Artin--Schreier\ncoverings of the projective line over finite fields. We provide an explicit\nformula for their $L$-polynomials in characteristic $2$, expressed in terms of\ncharacters of maximal abelian subgroups of associated Heisenberg groups. For\nthis purpose, we develop new methods specific to characteristic $2$ that\nexploit the structure of the Heisenberg groups and the geometry of Lang torsors\nfor $W_2$. As an application, we construct examples of curves in this family\nattaining the Hasse--Weil bound.",
    "pdf_url": "http://arxiv.org/pdf/2505.22036v1",
    "published": "2025-05-28T06:59:05+00:00",
    "categories": [
      "math.NT",
      "math.AG"
    ],
    "primary_category": "math.NT"
  },
  {
    "id": "http://arxiv.org/abs/2506.02016v1",
    "title": "Are classical deep neural networks weakly adversarially robust?",
    "authors": [
      "Nuolin Sun",
      "Linyuan Wang",
      "Dongyang Li",
      "Bin Yan",
      "Lei Li"
    ],
    "abstract": "Adversarial attacks have received increasing attention and it has been widely\nrecognized that classical DNNs have weak adversarial robustness. The most\ncommonly used adversarial defense method, adversarial training, improves the\nadversarial accuracy of DNNs by generating adversarial examples and retraining\nthe model. However, adversarial training requires a significant computational\noverhead. In this paper, inspired by existing studies focusing on the\nclustering properties of DNN output features at each layer and the Progressive\nFeedforward Collapse phenomenon, we propose a method for adversarial example\ndetection and image recognition that uses layer-wise features to construct\nfeature paths and computes the correlation between the examples feature paths\nand the class-centered feature paths. Experimental results show that the\nrecognition method achieves 82.77% clean accuracy and 44.17% adversarial\naccuracy on the ResNet-20 with PFC. Compared to the adversarial training method\nwith 77.64% clean accuracy and 52.94% adversarial accuracy, our method exhibits\na trade-off without relying on computationally expensive defense strategies.\nFurthermore, on the standard ResNet-18, our method maintains this advantage\nwith respective metrics of 80.01% and 46.1%. This result reveals inherent\nadversarial robustness in DNNs, challenging the conventional understanding of\nthe weak adversarial robustness in DNNs.",
    "pdf_url": "http://arxiv.org/pdf/2506.02016v1",
    "published": "2025-05-28T06:58:05+00:00",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.22035v1",
    "title": "Neuromorphic Sequential Arena: A Benchmark for Neuromorphic Temporal Processing",
    "authors": [
      "Xinyi Chen",
      "Chenxiang Ma",
      "Yujie Wu",
      "Kay Chen Tan",
      "Jibin Wu"
    ],
    "abstract": "Temporal processing is vital for extracting meaningful information from\ntime-varying signals. Recent advancements in Spiking Neural Networks (SNNs)\nhave shown immense promise in efficiently processing these signals. However,\nprogress in this field has been impeded by the lack of effective and\nstandardized benchmarks, which complicates the consistent measurement of\ntechnological advancements and limits the practical applicability of SNNs. To\nbridge this gap, we introduce the Neuromorphic Sequential Arena (NSA), a\ncomprehensive benchmark that offers an effective, versatile, and\napplication-oriented evaluation framework for neuromorphic temporal processing.\nThe NSA includes seven real-world temporal processing tasks from a diverse\nrange of application scenarios, each capturing rich temporal dynamics across\nmultiple timescales. Utilizing NSA, we conduct extensive comparisons of\nrecently introduced spiking neuron models and neural architectures, presenting\ncomprehensive baselines in terms of task performance, training speed, memory\nusage, and energy efficiency. Our findings emphasize an urgent need for\nefficient SNN designs that can consistently deliver high performance across\ntasks with varying temporal complexities while maintaining low computational\ncosts. NSA enables systematic tracking of advancements in neuromorphic\nalgorithm research and paves the way for developing effective and efficient\nneuromorphic temporal processing systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.22035v1",
    "published": "2025-05-28T06:57:40+00:00",
    "categories": [
      "cs.NE"
    ],
    "primary_category": "cs.NE"
  },
  {
    "id": "http://arxiv.org/abs/2505.22034v2",
    "title": "Random irregular histograms",
    "authors": [
      "Oskar H√∏gberg Simensen",
      "Dennis Christensen",
      "Nils Lid Hjort"
    ],
    "abstract": "We propose a new method of histogram construction, providing a fully Bayesian\napproach to irregular histograms. Our procedure applies Bayesian model\nselection to a piecewise constant model of the underlying distribution,\nresulting in a method that selects both the number of bins as well as their\nlocation based on the data in a fully automatic fashion. We show that the\nhistogram estimate is consistent with respect to the Hellinger metric under\nmild regularity conditions, and that it attains a convergence rate equal to the\nminimax rate (up to a logarithmic factor) for H\\\"{o}lder continuous densities.\nSimulation studies indicate that the new method performs comparably to other\nhistogram procedures, both for minimizing the estimation error and for\nidentifying modes. A software implementation is included as supplementary\nmaterial.",
    "pdf_url": "http://arxiv.org/pdf/2505.22034v2",
    "published": "2025-05-28T06:55:58+00:00",
    "categories": [
      "stat.ME",
      "math.ST",
      "stat.TH"
    ],
    "primary_category": "stat.ME"
  },
  {
    "id": "http://arxiv.org/abs/2505.22033v1",
    "title": "Phase Transition and Critical Phenomena of Charged Einstein-Maxwell-Scalar Black Holes",
    "authors": [
      "Zeming Zhuang",
      "Kun Meng",
      "Hongsheng Zhang"
    ],
    "abstract": "We study the phase transition and critical phenomenon of charged black holes\nin Einstein-Maxwell-scalar (EMs) theory. Through comprehensive analysis of\nthermodynamic behaviors manifested in P-V diagrams, G(T,P) surfaces, and C_P\ncurves, we establish that these black holes exhibit van der Waals-type phase\ntransition behavior. The derived critical exponents governing the phase\ntransition show precise correspondence with both van der Waals gas-liquid\nsystems, reinforcing the connection between black hole thermodynamics and mean\nfield theory statistics. The findings reveal a crucial dependence of phase\ntransition properties on the scalar charge parameter. A critical threshold\nemerges where phase transitions become prohibited when scalar charge exceeds a\nspecific magnitude. However, the transition persists asymptotically as scalar\ncharge approaches zero. The analysis further demonstrates nonlinear\nrelationships between scalar charge and critical parameters: while small scalar\ncharges induce increasing critical volume with charge magnitude, larger values\nproduce an inverse trend. Critical temperature displays complementary behavior,\nmaintaining monotonic variation under certain conditions while exhibiting\ninverse correlation with critical volume in others. Significantly, the\ntransition points governing critical volume and temperature trends occur at\ndistinct scalar charge values for different black holes, indicating a\nnon-trivial parameter dependence. These results highlight the scalar charge's\ndual role as both an enabler and suppressor of phase transitions in EMs black\nholes, providing new insights into the interplay between geometric\nconfigurations and thermodynamic properties in modified gravity theories.",
    "pdf_url": "http://arxiv.org/pdf/2505.22033v1",
    "published": "2025-05-28T06:53:51+00:00",
    "categories": [
      "gr-qc"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2505.22032v1",
    "title": "Retweets, Receipts, and Resistance: Discourse, Sentiment, and Credibility in Public Health Crisis Twitter",
    "authors": [
      "Tawfiq Ammari",
      "Anna Gutowska",
      "Jacob Ziff",
      "Casey Randazzo",
      "Harihan Subramonyam"
    ],
    "abstract": "As the COVID-19 pandemic evolved, the Centers for Disease Control and\nPrevention (CDC) used Twitter to disseminate safety guidance and updates,\nreaching millions of users. This study analyzes two years of tweets from, to,\nand about the CDC using a mixed methods approach to examine discourse\ncharacteristics, credibility, and user engagement. We found that the CDCs\ncommunication remained largely one directional and did not foster reciprocal\ninteraction, while discussions around COVID19 were deeply shaped by political\nand ideological polarization. Users frequently cited earlier CDC messages to\ncritique new and sometimes contradictory guidance. Our findings highlight the\nrole of sentiment, media richness, and source credibility in shaping the spread\nof public health messages. We propose design strategies to help the CDC tailor\ncommunications to diverse user groups and manage misinformation more\neffectively during high-stakes health crises.",
    "pdf_url": "http://arxiv.org/pdf/2505.22032v1",
    "published": "2025-05-28T06:53:33+00:00",
    "categories": [
      "cs.SI",
      "cs.HC"
    ],
    "primary_category": "cs.SI"
  },
  {
    "id": "http://arxiv.org/abs/2505.22031v1",
    "title": "Guess the Age of Photos: An Interactive Web Platform for Historical Image Age Estimation",
    "authors": [
      "Hasan Yucedag",
      "Adam Jatowt"
    ],
    "abstract": "This paper introduces Guess the Age of Photos, a web platform engaging users\nin estimating the years of historical photographs through two gamified modes:\nGuess the Year (predicting a single image's year) and Timeline Challenge\n(comparing two images to identify the older). Built with Python, Flask,\nBootstrap, and PostgreSQL, it uses a 10,150-image subset of the Date Estimation\nin the Wild dataset (1930-1999). Features like dynamic scoring and leaderboards\nboost engagement. Evaluated with 113 users and 15,473 gameplays, the platform\nearned a 4.25/5 satisfaction rating. Users excelled in relative comparisons\n(65.9% accuracy) over absolute year guesses (25.6% accuracy), with older\ndecades easier to identify. The platform serves as an educational tool,\nfostering historical awareness and analytical skills via interactive\nexploration of visual heritage. Furthermore, the platform provides a valuable\nresource for studying human perception of temporal cues in images and could be\nused to generate annotated data for training and evaluating computer vision\nmodels.",
    "pdf_url": "http://arxiv.org/pdf/2505.22031v1",
    "published": "2025-05-28T06:52:49+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.22030v1",
    "title": "The chemical yields of stars in the range 9-15 Msun",
    "authors": [
      "Marco Limongi",
      "Lorenzo Roberti",
      "Agnese Falla",
      "Alessandro Chieffi",
      "Ken'ichi Nomoto"
    ],
    "abstract": "In Limongi et al. (2024) we presented and discussed the main evolutionary\nproperties and final fate of stars in the mass range 7-15 Msun. The evolutions\nof those models were computed by means of a medium size nuclear network that\nguaranteed a proper calculation of the nuclear energy generation and hence a\ngood modeling of the physical evolution of these stars. In the present paper,\nwe extend this study by computing the detailed chemical yields of stars in the\nmass range 9-15 Msun, i.e., those stars that explode as core collapse\nsupernovae (CCSNe). The explosive nucleosynthesis is then computed in the\nframework of the thermal bomb induced explosion by means of the HYPERION code\n(Limongi and Chieffi 2020). We find that: (1) the yields of the intermediate\nmass elements (i.e., O to P) show a steep decrease as the inital mass\ndecreases; (2) the yields of s-weak component, i.e., those produced by the slow\nneutron captures from Ga to to the first neutron closure shell, decrease almost\nlinearly as a function of the initial mass with respect to the ones produced by\nthe more massive stars; (3) the global contribution of the stars in the mass\nrange 9.22-13 Msun to the yields of a generation of massive stars averaged over\na standard initial mass function is negligible for essentially all the\nisotopes. In spite of this, however, the models of stars in this mass range can\nbe fundamental to interpret the observations of specific supernovae.",
    "pdf_url": "http://arxiv.org/pdf/2505.22030v1",
    "published": "2025-05-28T06:52:16+00:00",
    "categories": [
      "astro-ph.SR"
    ],
    "primary_category": "astro-ph.SR"
  },
  {
    "id": "http://arxiv.org/abs/2505.22029v2",
    "title": "Analysis and Evaluation of Synthetic Data Generation in Speech Dysfluency Detection",
    "authors": [
      "Jinming Zhang",
      "Xuanru Zhou",
      "Jiachen Lian",
      "Shuhe Li",
      "William Li",
      "Zoe Ezzes",
      "Rian Bogley",
      "Lisa Wauters",
      "Zachary Miller",
      "Jet Vonk",
      "Brittany Morin",
      "Maria Gorno-Tempini",
      "Gopala Anumanchipalli"
    ],
    "abstract": "Speech dysfluency detection is crucial for clinical diagnosis and language\nassessment, but existing methods are limited by the scarcity of high-quality\nannotated data. Although recent advances in TTS model have enabled synthetic\ndysfluency generation, existing synthetic datasets suffer from unnatural\nprosody and limited contextual diversity. To address these limitations, we\npropose LLM-Dys -- the most comprehensive dysfluent speech corpus with\nLLM-enhanced dysfluency simulation. This dataset captures 11 dysfluency\ncategories spanning both word and phoneme levels. Building upon this resource,\nwe improve an end-to-end dysfluency detection framework. Experimental\nvalidation demonstrates state-of-the-art performance. All data, models, and\ncode are open-sourced at https://github.com/Berkeley-Speech-Group/LLM-Dys.",
    "pdf_url": "http://arxiv.org/pdf/2505.22029v2",
    "published": "2025-05-28T06:52:10+00:00",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.SD"
    ],
    "primary_category": "eess.AS"
  },
  {
    "id": "http://arxiv.org/abs/2505.22028v1",
    "title": "Weakly-Supervised Contrastive Learning for Imprecise Class Labels",
    "authors": [
      "Zi-Hao Zhou",
      "Jun-Jie Wang",
      "Tong Wei",
      "Min-Ling Zhang"
    ],
    "abstract": "Contrastive learning has achieved remarkable success in learning effective\nrepresentations, with supervised contrastive learning often outperforming\nself-supervised approaches. However, in real-world scenarios, data annotations\nare often ambiguous or inaccurate, meaning that class labels may not reliably\nindicate whether two examples belong to the same class. This limitation\nrestricts the applicability of supervised contrastive learning. To address this\nchallenge, we introduce the concept of ``continuous semantic similarity'' to\ndefine positive and negative pairs. Instead of directly relying on imprecise\nclass labels, we measure the semantic similarity between example pairs, which\nquantifies how closely they belong to the same category by iteratively refining\nweak supervisory signals. Based on this concept, we propose a graph-theoretic\nframework for weakly-supervised contrastive learning, where semantic similarity\nserves as the graph weights. Our framework is highly versatile and can be\napplied to many weakly-supervised learning scenarios. We demonstrate its\neffectiveness through experiments in two common settings, i.e., noisy label and\npartial label learning, where existing methods can be easily integrated to\nsignificantly improve performance. Theoretically, we establish an error bound\nfor our approach, showing that it can approximate supervised contrastive\nlearning under mild conditions. The implementation code is available at\nhttps://github.com/Speechless-10308/WSC.",
    "pdf_url": "http://arxiv.org/pdf/2505.22028v1",
    "published": "2025-05-28T06:50:40+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.22027v1",
    "title": "Improving Respiratory Sound Classification with Architecture-Agnostic Knowledge Distillation from Ensembles",
    "authors": [
      "Miika Toikkanen",
      "June-Woo Kim"
    ],
    "abstract": "Respiratory sound datasets are limited in size and quality, making high\nperformance difficult to achieve. Ensemble models help but inevitably increase\ncompute cost at inference time. Soft label training distills knowledge\nefficiently with extra cost only at training. In this study, we explore soft\nlabels for respiratory sound classification as an architecture-agnostic\napproach to distill an ensemble of teacher models into a student model. We\nexamine different variations of our approach and find that even a single\nteacher, identical to the student, considerably improves performance beyond its\nown capability, with optimal gains achieved using only a few teachers. We\nachieve the new state-of-the-art Score of 64.39 on ICHBI, surpassing the\nprevious best by 0.85 and improving average Scores across architectures by more\nthan 1.16. Our results highlight the effectiveness of knowledge distillation\nwith soft labels for respiratory sound classification, regardless of size or\narchitecture.",
    "pdf_url": "http://arxiv.org/pdf/2505.22027v1",
    "published": "2025-05-28T06:49:18+00:00",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD"
  },
  {
    "id": "http://arxiv.org/abs/2506.12050v1",
    "title": "Stackification via adjunction",
    "authors": [
      "Zheng Wei"
    ],
    "abstract": "We establish a form of 2-adjunction (tentatively termed the *fundamental\n2-adjunction*), building on the fundamental adjunction proposed by Olivia\nCaramello and Riccardo Zanfa, which provides a constructive method for the\nassociated stack functor. Additionally, we investigate 2-local homeomorphisms\nthrough the lens of indexed fibrations.",
    "pdf_url": "http://arxiv.org/pdf/2506.12050v1",
    "published": "2025-05-28T06:48:57+00:00",
    "categories": [
      "math.CT"
    ],
    "primary_category": "math.CT"
  },
  {
    "id": "http://arxiv.org/abs/2505.22026v1",
    "title": "Two-dimensional equilibrium configurations in Korteweg fluids",
    "authors": [
      "M. Gorgone",
      "F. Oliveri",
      "A. Ricciardello",
      "P. Rogolino"
    ],
    "abstract": "In this paper, after reviewing the form of the constitutive equations for a\nthird grade Korteweg fluid, recently derived by means of an extended Liu\nprocedure, an equilibrium problem is investigated. By considering a\ntwo--dimensional setting, it is derived a single nonlinear elliptic equation\nsuch that the equilibrium conditions are identically satisfied. Such an\nequation is discussed both analytically and numerically. Moreover, by\nconsidering a particular boundary value problem of Dirichlet type, some\npreliminary numerical solutions are presented.",
    "pdf_url": "http://arxiv.org/pdf/2505.22026v1",
    "published": "2025-05-28T06:47:07+00:00",
    "categories": [
      "math-ph",
      "math.MP",
      "76A10 - 76M20"
    ],
    "primary_category": "math-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.22025v1",
    "title": "Learnable Burst-Encodable Time-of-Flight Imaging for High-Fidelity Long-Distance Depth Sensing",
    "authors": [
      "Manchao Bao",
      "Shengjiang Fang",
      "Tao Yue",
      "Xuemei Hu"
    ],
    "abstract": "Long-distance depth imaging holds great promise for applications such as\nautonomous driving and robotics. Direct time-of-flight (dToF) imaging offers\nhigh-precision, long-distance depth sensing, yet demands ultra-short pulse\nlight sources and high-resolution time-to-digital converters. In contrast,\nindirect time-of-flight (iToF) imaging often suffers from phase wrapping and\nlow signal-to-noise ratio (SNR) as the sensing distance increases. In this\npaper, we introduce a novel ToF imaging paradigm, termed Burst-Encodable\nTime-of-Flight (BE-ToF), which facilitates high-fidelity, long-distance depth\nimaging. Specifically, the BE-ToF system emits light pulses in burst mode and\nestimates the phase delay of the reflected signal over the entire burst period,\nthereby effectively avoiding the phase wrapping inherent to conventional iToF\nsystems. Moreover, to address the low SNR caused by light attenuation over\nincreasing distances, we propose an end-to-end learnable framework that jointly\noptimizes the coding functions and the depth reconstruction network. A\nspecialized double well function and first-order difference term are\nincorporated into the framework to ensure the hardware implementability of the\ncoding functions. The proposed approach is rigorously validated through\ncomprehensive simulations and real-world prototype experiments, demonstrating\nits effectiveness and practical applicability.",
    "pdf_url": "http://arxiv.org/pdf/2505.22025v1",
    "published": "2025-05-28T06:46:43+00:00",
    "categories": [
      "cs.CV",
      "eess.IV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.22024v1",
    "title": "RESOUND: Speech Reconstruction from Silent Videos via Acoustic-Semantic Decomposed Modeling",
    "authors": [
      "Long-Khanh Pham",
      "Thanh V. T. Tran",
      "Minh-Tan Pham",
      "Van Nguyen"
    ],
    "abstract": "Lip-to-speech (L2S) synthesis, which reconstructs speech from visual cues,\nfaces challenges in accuracy and naturalness due to limited supervision in\ncapturing linguistic content, accents, and prosody. In this paper, we propose\nRESOUND, a novel L2S system that generates intelligible and expressive speech\nfrom silent talking face videos. Leveraging source-filter theory, our method\ninvolves two components: an acoustic path to predict prosody and a semantic\npath to extract linguistic features. This separation simplifies learning,\nallowing independent optimization of each representation. Additionally, we\nenhance performance by integrating speech units, a proven unsupervised speech\nrepresentation technique, into waveform generation alongside mel-spectrograms.\nThis allows RESOUND to synthesize prosodic speech while preserving content and\nspeaker identity. Experiments conducted on two standard L2S benchmarks confirm\nthe effectiveness of the proposed method across various metrics.",
    "pdf_url": "http://arxiv.org/pdf/2505.22024v1",
    "published": "2025-05-28T06:46:13+00:00",
    "categories": [
      "cs.SD",
      "cs.CV",
      "eess.AS"
    ],
    "primary_category": "cs.SD"
  },
  {
    "id": "http://arxiv.org/abs/2505.23827v2",
    "title": "ValueSim: Generating Backstories to Model Individual Value Systems",
    "authors": [
      "Bangde Du",
      "Ziyi Ye",
      "Zhijing Wu",
      "Jankowska Monika",
      "Shuqi Zhu",
      "Qingyao Ai",
      "Yujia Zhou",
      "Yiqun Liu"
    ],
    "abstract": "As Large Language Models (LLMs) continue to exhibit increasingly human-like\ncapabilities, aligning them with human values has become critically important.\nContemporary advanced techniques, such as prompt learning and reinforcement\nlearning, are being deployed to better align LLMs with human values. However,\nwhile these approaches address broad ethical considerations and helpfulness,\nthey rarely focus on simulating individualized human value systems. To address\nthis gap, we present ValueSim, a framework that simulates individual values\nthrough the generation of personal backstories reflecting past experiences and\ndemographic information. ValueSim converts structured individual data into\nnarrative backstories and employs a multi-module architecture inspired by the\nCognitive-Affective Personality System to simulate individual values based on\nthese narratives. Testing ValueSim on a self-constructed benchmark derived from\nthe World Values Survey demonstrates an improvement in top-1 accuracy by over\n10% compared to retrieval-augmented generation methods. Further analysis\nreveals that performance enhances as additional user interaction history\nbecomes available, indicating the model's ability to refine its persona\nsimulation capabilities over time.",
    "pdf_url": "http://arxiv.org/pdf/2505.23827v2",
    "published": "2025-05-28T06:43:16+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.22023v1",
    "title": "Securing the Software Package Supply Chain for Critical Systems",
    "authors": [
      "Ritwik Murali",
      "Akash Ravi"
    ],
    "abstract": "Software systems have grown as an indispensable commodity used across various\nindustries, and almost all essential services depend on them for effective\noperation. The software is no longer an independent or stand-alone piece of\ncode written by a developer but rather a collection of packages designed by\nmultiple developers across the globe. Ensuring the reliability and resilience\nof these systems is crucial since emerging threats target software supply\nchains, as demonstrated by the widespread SolarWinds hack in late 2020. These\nsupply chains extend beyond patches and updates, involving distribution\nnetworks throughout the software lifecycle. Industries like smart grids,\nmanufacturing, healthcare, and finance rely on interconnected software systems\nand their dependencies for effective functioning. To secure software modules\nand add-ons, robust distribution architectures are essential. The proposed\nchapter enhances the existing delivery frameworks by including a permissioned\nledger with Proof of Authority consensus and multi-party signatures. The\nproposed system aims to prevent attacks while permitting every stakeholder to\nverify the same. Critical systems can interface with the secure pipeline\nwithout disrupting existing functionalities, thus preventing the cascading\neffect of an attack at any point in the supply chain.",
    "pdf_url": "http://arxiv.org/pdf/2505.22023v1",
    "published": "2025-05-28T06:42:37+00:00",
    "categories": [
      "cs.SE",
      "cs.CR"
    ],
    "primary_category": "cs.SE"
  },
  {
    "id": "http://arxiv.org/abs/2505.22022v1",
    "title": "A High Accuracy Symplectic Scheme for Advection Diffusion Reaction Models in Bioseparation",
    "authors": [
      "Farjana Siddiqua",
      "Catalin Trenchea"
    ],
    "abstract": "We analyze an advection-diffusion-reaction problem with non-homogeneous\nboundary conditions that models the chromatography process, a vital stage in\nbioseparation. We prove stability and error estimates for both constant and\naffine adsorption, using the symplectic one-step implicit midpoint method for\ntime discretization and finite elements for spatial discretization. In\naddition, we perform the stability analysis for the nonlinear, explicit\nadsorption in the continuous and semi-discrete cases. For the nonlinear,\nexplicit adsorption, we also complete the error analysis for the semi-discrete\ncase and prove the existence of a solution for the fully discrete case. The\nnumerical tests validate our theoretical results.",
    "pdf_url": "http://arxiv.org/pdf/2505.22022v1",
    "published": "2025-05-28T06:38:20+00:00",
    "categories": [
      "math.NA",
      "cs.NA"
    ],
    "primary_category": "math.NA"
  },
  {
    "id": "http://arxiv.org/abs/2505.23826v1",
    "title": "FinRipple: Aligning Large Language Models with Financial Market for Event Ripple Effect Awareness",
    "authors": [
      "Yuanjian Xu",
      "Jianing Hao",
      "Kunsheng Tang",
      "Jingnan Chen",
      "Anxian Liu",
      "Peng Liu",
      "Guang Zhang"
    ],
    "abstract": "Financial markets exhibit complex dynamics where localized events trigger\nripple effects across entities. Previous event studies, constrained by static\nsingle-company analyses and simplistic assumptions, fail to capture these\nripple effects. While large language models (LLMs) offer emergent reasoning\ncapabilities, their direct application falters due to structural market\nunawareness and limited capacity to analyze ripple effects. We propose\nFinRipple, an elegant framework that empowers LLMs with the ability to analyze\nripple effects through financial theory-guided large-scale reinforcement\nlearning. We begin by relaxing the assumptions of previous methods,\nincorporating a time-varying knowledge graph to accurately represent market\nstructure. By seamlessly integrating classical asset pricing theory, we align\nthe LLM with the market, enabling it to predict ripple effects. To the best of\nour knowledge, we are the first to provide a standardized definition of ripple\neffect prediction, a task that is extremely important yet unexplored in the\nfinancial domain. Extensive experiments demonstrate that FinRipple provides a\npromising solution to this task.",
    "pdf_url": "http://arxiv.org/pdf/2505.23826v1",
    "published": "2025-05-28T06:37:36+00:00",
    "categories": [
      "cs.SI"
    ],
    "primary_category": "cs.SI"
  },
  {
    "id": "http://arxiv.org/abs/2505.22021v1",
    "title": "GL-PGENet: A Parameterized Generation Framework for Robust Document Image Enhancement",
    "authors": [
      "Zhihong Tang",
      "Yang Li"
    ],
    "abstract": "Document Image Enhancement (DIE) serves as a critical component in Document\nAI systems, where its performance substantially determines the effectiveness of\ndownstream tasks. To address the limitations of existing methods confined to\nsingle-degradation restoration or grayscale image processing, we present Global\nwith Local Parametric Generation Enhancement Network (GL-PGENet), a novel\narchitecture designed for multi-degraded color document images, ensuring both\nefficiency and robustness in real-world scenarios. Our solution incorporates\nthree key innovations: First, a hierarchical enhancement framework that\nintegrates global appearance correction with local refinement, enabling\ncoarse-to-fine quality improvement. Second, a Dual-Branch Local-Refine Network\nwith parametric generation mechanisms that replaces conventional direct\nprediction, producing enhanced outputs through learned intermediate parametric\nrepresentations rather than pixel-wise mapping. This approach enhances local\nconsistency while improving model generalization. Finally, a modified NestUNet\narchitecture incorporating dense block to effectively fuse low-level pixel\nfeatures and high-level semantic features, specifically adapted for document\nimage characteristics. In addition, to enhance generalization performance, we\nadopt a two-stage training strategy: large-scale pretraining on a synthetic\ndataset of 500,000+ samples followed by task-specific fine-tuning. Extensive\nexperiments demonstrate the superiority of GL-PGENet, achieving\nstate-of-the-art SSIM scores of 0.7721 on DocUNet and 0.9480 on RealDAE. The\nmodel also exhibits remarkable cross-domain adaptability and maintains\ncomputational efficiency for high-resolution images without performance\ndegradation, confirming its practical utility in real-world scenarios.",
    "pdf_url": "http://arxiv.org/pdf/2505.22021v1",
    "published": "2025-05-28T06:37:06+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.22692v2",
    "title": "BLUE: Bi-layer Heterogeneous Graph Fusion Network for Avian Influenza Forecasting",
    "authors": [
      "Jing Du",
      "Haley Stone",
      "Yang Yang",
      "Ashna Desai",
      "Hao Xue",
      "Andreas Z√ºfle",
      "Chandini Raina MacIntyre",
      "Flora D. Salim"
    ],
    "abstract": "Accurate forecasting of avian influenza outbreaks within wild bird\npopulations requires models that account for complex, multi-scale transmission\npatterns driven by various factors. Spatio-temporal GNN-based models have\nrecently gained traction for infection forecasting due to their ability to\ncapture relations and flow between spatial regions, but most existing\nframeworks rely solely on spatial connections and their connections. This\noverlooks valuable genetic information at the case level, such as cases in one\nregion being genetically descended from strains in another, which is essential\nfor understanding how infectious diseases spread through epidemiological\nlinkages beyond geography. We address this gap with BLUE, a B}i-Layer\nheterogeneous graph fUsion nEtwork designed to integrate genetic, spatial, and\necological data for accurate outbreak forecasting. The framework 1) builds\nheterogeneous graphs from multiple information sources and multiple layers, 2)\nsmooths across relation types, 3) performs fusion while retaining structural\npatterns, and 4) predicts future outbreaks via an autoregressive graph sequence\nmodel that captures transmission dynamics over time. To facilitate further\nresearch, we introduce \\textbf{Avian-US} dataset, the dataset for avian\ninfluenza outbreak forecasting in the United States, incorporating genetic,\nspatial, and ecological data across locations. BLUE achieves superior\nperformance over existing baselines, highlighting the value of incorporating\nmulti-layer information into infectious disease forecasting.",
    "pdf_url": "http://arxiv.org/pdf/2505.22692v2",
    "published": "2025-05-28T06:36:21+00:00",
    "categories": [
      "cs.SI"
    ],
    "primary_category": "cs.SI"
  },
  {
    "id": "http://arxiv.org/abs/2505.22691v1",
    "title": "Early Assessment of Artificial Lower Extremity Sensory Response Times and Proprioceptive Acuity via Sensory Cortex Electrical Stimulation",
    "authors": [
      "Won Joon Sohn",
      "Jeffrey Lim",
      "Po T. Wang",
      "Susan J. Shaw",
      "Michelle Armacost",
      "Hui Gong",
      "Brian Lee",
      "Darrin Lee",
      "Payam Heydari",
      "Richard A. Andersen",
      "Charles Y. Liu",
      "Zoran Nenadic",
      "An H. Do"
    ],
    "abstract": "Bi-directional brain computer interfaces (BD-BCIs) may restore\nbrain-controlled walking and artificial leg sensation after spinal cord injury.\nCurrent BD-BCIs provide only simplistic \"tingling\" feedback, which lacks\nproprioceptive information to perceive critical gait events (leg swing, double\nsupport). This information must also be perceived adequately fast to facilitate\ntimely motor responses. Here, we investigated utilizing primary sensory cortex\n(S1) direct cortical electrical stimulation (DCES) to deliver leg\nproprioceptive information and measured response times to artificial leg\nsensations. Subjects with subdural electrocorticogram electrodes over S1 leg\nareas participated in two tasks: (1) Proprioceptive acuity: subjects identified\nthe difference between DCES-induced percepts emulating various leg swing\nspeeds; (2) Sensory response: measuring subjects' reaction time to DCES-induced\nleg sensations, with DCES-hand, visual and auditory control conditions. Three\nsubjects were recruited. Only one completed the proprioceptive assessment,\nachieving 80%, 70%, 60%, and 53% accuracy in discriminating between fast/slow,\nfast/medium, medium/slow, and same speeds, respectively\n(p-value=1.9x10$^{-5}$). Response times for leg/hand percepts were\n1007$\\pm$413/599$\\pm$171 ms, visual leg/hand responses were\n528$\\pm$137/384$\\pm$84 ms, and auditory leg/hand responses were\n393$\\pm$106/352$\\pm$93 ms, respectively. These results suggest proprioceptive\ninformation can be delivered artificially, but perception may be significantly\ndelayed. Future work should address improving acuity, reducing response times,\nand expanding sensory modalities.",
    "pdf_url": "http://arxiv.org/pdf/2505.22691v1",
    "published": "2025-05-28T06:35:22+00:00",
    "categories": [
      "q-bio.NC",
      "q-bio.OT"
    ],
    "primary_category": "q-bio.NC"
  },
  {
    "id": "http://arxiv.org/abs/2505.22020v1",
    "title": "Falling Threads During Solar Filament Eruptions",
    "authors": [
      "Yidian Wu",
      "Rui Liu",
      "Runbin Luo",
      "Wensi Wang"
    ],
    "abstract": "Mass drainage is frequently observed in solar filaments. During filament\neruptions, falling material most likely flows along magnetic field lines, which\nmay provide important clues for the magnetic structures of filaments. Here we\nstudy three filament eruptions exhibiting significant mass draining, often\nmanifested as falling threads at a constant speed ranging between 30--300 km/s.\nWe found that most of the falling material lands onto the hooked segments of\nflare ribbons, only a small fraction lands inside the hooks, and almost none\nlands onto the straight segments of ribbons. Based on these observations we\nsurmise that before eruptions most of the filament mass is entrained by field\nlines threading the quasi-separatrix layers (QSLs), which wrap around the\nfilament field and whose footpoints are mapped by the hooked ribbons, and that\nthe magnetic reconnection involving these field lines is the major cause of the\nmass drainage during eruptions. Additionally, the light curves of the hooked\nribbons suggest that during eruptions the earlier (later) QSL boundary of\nfilaments is threaded by mass-loaded (depleted) field lines. By assuming that\nthe constant-speed motion is due to a drag force balancing the gravity, we\nproposed a simplified analytical model to estimate the density contrast of the\nfalling material. The estimated density contrast is then fed into a numerical\nmodel, in which filament threads fall along vertical magnetic field lines\nthrough a gravitationally stratified atmosphere. The resultant falling speeds,\nhowever, are short of observed values, which calls for further investigations.",
    "pdf_url": "http://arxiv.org/pdf/2505.22020v1",
    "published": "2025-05-28T06:31:50+00:00",
    "categories": [
      "astro-ph.SR"
    ],
    "primary_category": "astro-ph.SR"
  },
  {
    "id": "http://arxiv.org/abs/2505.22019v2",
    "title": "VRAG-RL: Empower Vision-Perception-Based RAG for Visually Rich Information Understanding via Iterative Reasoning with Reinforcement Learning",
    "authors": [
      "Qiuchen Wang",
      "Ruixue Ding",
      "Yu Zeng",
      "Zehui Chen",
      "Lin Chen",
      "Shihang Wang",
      "Pengjun Xie",
      "Fei Huang",
      "Feng Zhao"
    ],
    "abstract": "Effectively retrieving, reasoning and understanding visually rich information\nremains a challenge for RAG methods. Traditional text-based methods cannot\nhandle visual-related information. On the other hand, current vision-based RAG\napproaches are often limited by fixed pipelines and frequently struggle to\nreason effectively due to the insufficient activation of the fundamental\ncapabilities of models. As RL has been proven to be beneficial for model\nreasoning, we introduce VRAG-RL, a novel RL framework tailored for complex\nreasoning across visually rich information. With this framework, VLMs interact\nwith search engines, autonomously sampling single-turn or multi-turn reasoning\ntrajectories with the help of visual perception tokens and undergoing continual\noptimization based on these samples. Our approach highlights key limitations of\nRL in RAG domains: (i) Prior Multi-modal RAG approaches tend to merely\nincorporate images into the context, leading to insufficient reasoning token\nallocation and neglecting visual-specific perception; and (ii) When models\ninteract with search engines, their queries often fail to retrieve relevant\ninformation due to the inability to articulate requirements, thereby leading to\nsuboptimal performance. To address these challenges, we define an action space\ntailored for visually rich inputs, with actions including cropping and scaling,\nallowing the model to gather information from a coarse-to-fine perspective.\nFurthermore, to bridge the gap between users' original inquiries and the\nretriever, we employ a simple yet effective reward that integrates query\nrewriting and retrieval performance with a model-based reward. Our VRAG-RL\noptimizes VLMs for RAG tasks using specially designed RL strategies, aligning\nthe model with real-world applications. The code is available at\nhttps://github.com/Alibaba-NLP/VRAG.",
    "pdf_url": "http://arxiv.org/pdf/2505.22019v2",
    "published": "2025-05-28T06:30:51+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.22018v2",
    "title": "Improving Continual Pre-training Through Seamless Data Packing",
    "authors": [
      "Ruicheng Yin",
      "Xuan Gao",
      "Changze Lv",
      "Xiaohua Wang",
      "Xiaoqing Zheng",
      "Xuanjing Huang"
    ],
    "abstract": "Continual pre-training has demonstrated significant potential in enhancing\nmodel performance, particularly in domain-specific scenarios. The most common\napproach for packing data before continual pre-training involves concatenating\ninput texts and splitting them into fixed-length sequences. While\nstraightforward and efficient, this method often leads to excessive truncation\nand context discontinuity, which can hinder model performance. To address these\nissues, we explore the potential of data engineering to enhance continual\npre-training, particularly its impact on model performance and efficiency. We\npropose Seamless Packing (SP), a novel data packing strategy aimed at\npreserving contextual information more effectively and enhancing model\nperformance. Our approach employs a sliding window technique in the first stage\nthat synchronizes overlapping tokens across consecutive sequences, ensuring\nbetter continuity and contextual coherence. In the second stage, we adopt a\nFirst-Fit-Decreasing algorithm to pack shorter texts into bins slightly larger\nthan the target sequence length, thereby minimizing padding and truncation.\nEmpirical evaluations across various model architectures and corpus domains\ndemonstrate the effectiveness of our method, outperforming baseline method in\n99% of all settings. Code is available at\nhttps://github.com/Infernus-WIND/Seamless-Packing.",
    "pdf_url": "http://arxiv.org/pdf/2505.22018v2",
    "published": "2025-05-28T06:30:37+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.22017v1",
    "title": "CoThink: Token-Efficient Reasoning via Instruct Models Guiding Reasoning Models",
    "authors": [
      "Siqi Fan",
      "Peng Han",
      "Shuo Shang",
      "Yequan Wang",
      "Aixin Sun"
    ],
    "abstract": "Large language models (LLMs) benefit from increased test-time compute, a\nphenomenon known as test-time scaling. However, reasoning-optimized models\noften overthink even simple problems, producing excessively verbose outputs and\nleading to low token efficiency. By comparing these models with equally sized\ninstruct models, we identify two key causes of this verbosity: (1)\nreinforcement learning reduces the information density of forward reasoning,\nand (2) backward chain-of thought training encourages redundant and often\nunnecessary verification steps. Since LLMs cannot assess the difficulty of a\ngiven problem, they tend to apply the same cautious reasoning strategy across\nall tasks, resulting in inefficient overthinking. To address this, we propose\nCoThink, an embarrassingly simple pipeline: an instruct model first drafts a\nhigh-level solution outline; a reasoning model then works out the solution. We\nobserve that CoThink enables dynamic adjustment of reasoning depth based on\ninput difficulty. Evaluated with three reasoning models DAPO, DeepSeek-R1, and\nQwQ on three datasets GSM8K, MATH500, and AIME24, CoThink reduces total token\ngeneration by 22.3% while maintaining pass@1 accuracy within a 0.42% margin on\naverage. With reference to the instruct model, we formally define reasoning\nefficiency and observe a potential reasoning efficiency scaling law in LLMs.",
    "pdf_url": "http://arxiv.org/pdf/2505.22017v1",
    "published": "2025-05-28T06:24:45+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.23825v1",
    "title": "Privacy-Preserving Inconsistency Measurement",
    "authors": [
      "Carl Corea",
      "Timotheus Kampik",
      "Nico Potyka"
    ],
    "abstract": "We investigate a new form of (privacy-preserving) inconsistency measurement\nfor multi-party communication. Intuitively, for two knowledge bases K_A, K_B\n(of two agents A, B), our results allow to quantitatively assess the degree of\ninconsistency for K_A U K_B without having to reveal the actual contents of the\nknowledge bases. Using secure multi-party computation (SMPC) and cryptographic\nprotocols, we develop two concrete methods for this use-case and show that they\nsatisfy important properties of SMPC protocols -- notably, input privacy, i.e.,\njointly computing the inconsistency degree without revealing the inputs.",
    "pdf_url": "http://arxiv.org/pdf/2505.23825v1",
    "published": "2025-05-28T06:24:33+00:00",
    "categories": [
      "cs.CR"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.22016v2",
    "title": "PanoWan: Lifting Diffusion Video Generation Models to 360¬∞ with Latitude/Longitude-aware Mechanisms",
    "authors": [
      "Yifei Xia",
      "Shuchen Weng",
      "Siqi Yang",
      "Jingqi Liu",
      "Chengxuan Zhu",
      "Minggui Teng",
      "Zijian Jia",
      "Han Jiang",
      "Boxin Shi"
    ],
    "abstract": "Panoramic video generation enables immersive 360{\\deg} content creation,\nvaluable in applications that demand scene-consistent world exploration.\nHowever, existing panoramic video generation models struggle to leverage\npre-trained generative priors from conventional text-to-video models for\nhigh-quality and diverse panoramic videos generation, due to limited dataset\nscale and the gap in spatial feature representations. In this paper, we\nintroduce PanoWan to effectively lift pre-trained text-to-video models to the\npanoramic domain, equipped with minimal modules. PanoWan employs latitude-aware\nsampling to avoid latitudinal distortion, while its rotated semantic denoising\nand padded pixel-wise decoding ensure seamless transitions at longitude\nboundaries. To provide sufficient panoramic videos for learning these lifted\nrepresentations, we contribute PanoVid, a high-quality panoramic video dataset\nwith captions and diverse scenarios. Consequently, PanoWan achieves\nstate-of-the-art performance in panoramic video generation and demonstrates\nrobustness for zero-shot downstream tasks. Our project page is available at\nhttps://panowan.variantconst.com.",
    "pdf_url": "http://arxiv.org/pdf/2505.22016v2",
    "published": "2025-05-28T06:24:21+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.22015v1",
    "title": "Debiased distributed PCA under high dimensional spiked model",
    "authors": [
      "Weiming Li",
      "Zeng Li",
      "Siyu Wang",
      "Yanqing Yin",
      "Junpeng Zhu"
    ],
    "abstract": "We study distributed principal component analysis (PCA) in high-dimensional\nsettings under the spiked model. In such regimes, sample eigenvectors can\ndeviate significantly from population ones, introducing a persistent bias.\nExisting distributed PCA methods are sensitive to this bias, particularly when\nthe number of machines is small. Their consistency typically relies on the\nnumber of machines tending to infinity. We propose a debiased distributed PCA\nalgorithm that corrects the local bias before aggregation and incorporates a\nsparsity-detection step to adaptively handle sparse and non-sparse\neigenvectors. Theoretically, we establish the consistency of our estimator\nunder much weaker conditions compared to existing literature. In particular,\nour approach does not require symmetric innovations and only assumes a finite\nsixth moment. Furthermore, our method generally achieves smaller estimation\nerror, especially when the number of machines is small. Empirically, extensive\nsimulations and real data experiments demonstrate that our method consistently\noutperforms existing distributed PCA approaches. The advantage is especially\nprominent when the leading eigenvectors are sparse or the number of machines is\nlimited. Our method and theoretical analysis are also applicable to the sample\ncorrelation matrix.",
    "pdf_url": "http://arxiv.org/pdf/2505.22015v1",
    "published": "2025-05-28T06:23:33+00:00",
    "categories": [
      "stat.ME"
    ],
    "primary_category": "stat.ME"
  },
  {
    "id": "http://arxiv.org/abs/2505.22014v1",
    "title": "Learning in Compact Spaces with Approximately Normalized Transformers",
    "authors": [
      "J√∂rg K. H. Franke",
      "Urs Spiegelhalter",
      "Marianna Nezhurina",
      "Jenia Jitsev",
      "Frank Hutter",
      "Michael Hefenbrock"
    ],
    "abstract": "In deep learning, regularization and normalization are common solutions for\nchallenges such as overfitting, numerical instabilities, and the increasing\nvariance in the residual stream. An alternative approach is to force all\nparameters and representations to lie on a hypersphere. This removes the need\nfor regularization and increases convergence speed, but comes with additional\ncosts. In this work, we propose a more holistic but approximate normalization\n(anTransformer). Our approach constrains the norm of parameters and normalizes\nall representations via scalar multiplications motivated by the tight\nconcentration of the norms of high-dimensional random vectors. When applied to\nGPT training, we observe a 40% faster convergence compared to models with QK\nnormalization, with less than 3% additional runtime. Deriving scaling laws for\nanGPT, we found our method enables training with larger batch sizes and fewer\nhyperparameters, while matching the favorable scaling characteristics of\nclassic GPT architectures.",
    "pdf_url": "http://arxiv.org/pdf/2505.22014v1",
    "published": "2025-05-28T06:23:19+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.22013v1",
    "title": "Overlap-Adaptive Hybrid Speaker Diarization and ASR-Aware Observation Addition for MISP 2025 Challenge",
    "authors": [
      "Shangkun Huang",
      "Yuxuan Du",
      "Jingwen Yang",
      "Dejun Zhang",
      "Xupeng Jia",
      "Jing Deng",
      "Jintao Kang",
      "Rong Zheng"
    ],
    "abstract": "This paper presents the system developed to address the MISP 2025 Challenge.\nFor the diarization system, we proposed a hybrid approach combining a WavLM\nend-to-end segmentation method with a traditional multi-module clustering\ntechnique to adaptively select the appropriate model for handling varying\ndegrees of overlapping speech. For the automatic speech recognition (ASR)\nsystem, we proposed an ASR-aware observation addition method that compensates\nfor the performance limitations of Guided Source Separation (GSS) under low\nsignal-to-noise ratio conditions. Finally, we integrated the speaker\ndiarization and ASR systems in a cascaded architecture to address Track 3. Our\nsystem achieved character error rates (CER) of 9.48% on Track 2 and\nconcatenated minimum permutation character error rate (cpCER) of 11.56% on\nTrack 3, ultimately securing first place in both tracks and thereby\ndemonstrating the effectiveness of the proposed methods in real-world meeting\nscenarios.",
    "pdf_url": "http://arxiv.org/pdf/2505.22013v1",
    "published": "2025-05-28T06:22:37+00:00",
    "categories": [
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.SD"
  },
  {
    "id": "http://arxiv.org/abs/2505.22012v1",
    "title": "Data-Adaptive Automatic Threshold Calibration for Stability Selection",
    "authors": [
      "Martin Huang",
      "Samuel Muller",
      "Garth Tarr"
    ],
    "abstract": "Stability selection has gained popularity as a method for enhancing the\nperformance of variable selection algorithms while controlling false discovery\nrates. However, achieving these desirable properties depends on correctly\nspecifying the stable threshold parameter, which can be challenging. An\narbitrary choice of this parameter can substantially alter the set of selected\nvariables, as the variables' selection probabilities are inherently\ndata-dependent. To address this issue, we propose Exclusion Automatic Threshold\nSelection (EATS), a data-adaptive algorithm that streamlines stability\nselection by automating the threshold specification process. Additionally, we\nintroduce Automatic Threshold Selection (ATS), the motivation behind EATS. We\nevaluate our approach through an extensive simulation study, benchmarking\nacross commonly used variable selection algorithms and several static stable\nthreshold values.",
    "pdf_url": "http://arxiv.org/pdf/2505.22012v1",
    "published": "2025-05-28T06:21:45+00:00",
    "categories": [
      "stat.ME"
    ],
    "primary_category": "stat.ME"
  },
  {
    "id": "http://arxiv.org/abs/2505.22011v2",
    "title": "Prototype Embedding Optimization for Human-Object Interaction Detection in Livestreaming",
    "authors": [
      "Menghui Zhang",
      "Jing Zhang",
      "Lin Chen",
      "Li Zhuo"
    ],
    "abstract": "Livestreaming often involves interactions between streamers and objects,\nwhich is critical for understanding and regulating web content. While\nhuman-object interaction (HOI) detection has made some progress in\ngeneral-purpose video downstream tasks, when applied to recognize the\ninteraction behaviors between a streamer and different objects in\nlivestreaming, it tends to focuses too much on the objects and neglects their\ninteractions with the streamer, which leads to object bias. To solve this\nissue, we propose a prototype embedding optimization for human-object\ninteraction detection (PeO-HOI). First, the livestreaming is preprocessed using\nobject detection and tracking techniques to extract features of the\nhuman-object (HO) pairs. Then, prototype embedding optimization is adopted to\nmitigate the effect of object bias on HOI. Finally, after modelling the\nspatio-temporal context between HO pairs, the HOI detection results are\nobtained by the prediction head. The experimental results show that the\ndetection accuracy of the proposed PeO-HOI method has detection accuracies of\n37.19%@full, 51.42%@non-rare, 26.20%@rare on the publicly available dataset\nVidHOI, 45.13%@full, 62.78%@non-rare and 30.37%@rare on the self-built dataset\nBJUT-HOI, which effectively improves the HOI detection performance in\nlivestreaming.",
    "pdf_url": "http://arxiv.org/pdf/2505.22011v2",
    "published": "2025-05-28T06:19:37+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.22010v1",
    "title": "VulBinLLM: LLM-powered Vulnerability Detection for Stripped Binaries",
    "authors": [
      "Nasir Hussain",
      "Haohan Chen",
      "Chanh Tran",
      "Philip Huang",
      "Zhuohao Li",
      "Pravir Chugh",
      "William Chen",
      "Ashish Kundu",
      "Yuan Tian"
    ],
    "abstract": "Recognizing vulnerabilities in stripped binary files presents a significant\nchallenge in software security. Although some progress has been made in\ngenerating human-readable information from decompiled binary files with Large\nLanguage Models (LLMs), effectively and scalably detecting vulnerabilities\nwithin these binary files is still an open problem. This paper explores the\nnovel application of LLMs to detect vulnerabilities within these binary files.\nWe demonstrate the feasibility of identifying vulnerable programs through a\ncombined approach of decompilation optimization to make the vulnerabilities\nmore prominent and long-term memory for a larger context window, achieving\nstate-of-the-art performance in binary vulnerability analysis. Our findings\nhighlight the potential for LLMs to overcome the limitations of traditional\nanalysis methods and advance the field of binary vulnerability detection,\npaving the way for more secure software systems. In this paper, we present\nVul-BinLLM , an LLM-based framework for binary vulnerability detection that\nmirrors traditional binary analysis workflows with fine-grained optimizations\nin decompilation and vulnerability reasoning with an extended context. In the\ndecompilation phase, Vul-BinLLM adds vulnerability and weakness comments\nwithout altering the code structure or functionality, providing more contextual\ninformation for vulnerability reasoning later. Then for vulnerability\nreasoning, Vul-BinLLM combines in-context learning and chain-of-thought\nprompting along with a memory management agent to enhance accuracy. Our\nevaluations encompass the commonly used synthetic dataset Juliet to evaluate\nthe potential feasibility for analysis and vulnerability detection in C/C++\nbinaries. Our evaluations show that Vul-BinLLM is highly effective in detecting\nvulnerabilities on the compiled Juliet dataset.",
    "pdf_url": "http://arxiv.org/pdf/2505.22010v1",
    "published": "2025-05-28T06:17:56+00:00",
    "categories": [
      "cs.CR"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.22009v1",
    "title": "Hidden Transits: TOI-2285 b is a Warmer sub-Neptune Likely with a Super-Earth Companion",
    "authors": [
      "Akihiko Fukui"
    ],
    "abstract": "TOI-2285 b is a sub-Neptune-sized planet orbiting a nearby M dwarf,\ndiscovered through the TESS photometric survey and ground-based follow-up\nobservations. The planet was initially reported to have an orbital period of\n27.27 d, making it one of the lowest temperature sub-Neptunes transiting a\nbright M dwarf. However, additional TESS data reveal that its true orbital\nperiod is 13.64 d, half the original value, resulting in a warmer equilibrium\ntemperature (358 K) than previously estimated (284 K). The misidentification\nlikely resulted from the low signal-to-noise ratio of individual transit\nsignals and the limited number of transits observed by TESS at that time. This\ncase highlights the importance of carefully considering harmonic solutions for\nsimilar cases. The additional TESS data also reveal another planetary candidate\nwith an orbital period of 9.67 d and a radius of 1.5 $R_\\oplus$, requiring\nvalidation in future studies.",
    "pdf_url": "http://arxiv.org/pdf/2505.22009v1",
    "published": "2025-05-28T06:17:04+00:00",
    "categories": [
      "astro-ph.EP",
      "astro-ph.IM"
    ],
    "primary_category": "astro-ph.EP"
  },
  {
    "id": "http://arxiv.org/abs/2505.22008v1",
    "title": "Align-DA: Align Score-based Atmospheric Data Assimilation with Multiple Preferences",
    "authors": [
      "Jing-An Sun",
      "Hang Fan",
      "Junchao Gong",
      "Ben Fei",
      "Kun Chen",
      "Fenghua Ling",
      "Wenlong Zhang",
      "Wanghan Xu",
      "Li Yan",
      "Pierre Gentine",
      "Lei Bai"
    ],
    "abstract": "Data assimilation (DA) aims to estimate the full state of a dynamical system\nby combining partial and noisy observations with a prior model forecast,\ncommonly referred to as the background. In atmospheric applications, this\nproblem is fundamentally ill-posed due to the sparsity of observations relative\nto the high-dimensional state space. Traditional methods address this challenge\nby simplifying background priors to regularize the solution, which are\nempirical and require continual tuning for application. Inspired by alignment\ntechniques in text-to-image diffusion models, we propose Align-DA, which\nformulates DA as a generative process and uses reward signals to guide\nbackground priors, replacing manual tuning with data-driven alignment.\nSpecifically, we train a score-based model in the latent space to approximate\nthe background-conditioned prior, and align it using three complementary reward\nsignals for DA: (1) assimilation accuracy, (2) forecast skill initialized from\nthe assimilated state, and (3) physical adherence of the analysis fields.\nExperiments with multiple reward signals demonstrate consistent improvements in\nanalysis quality across different evaluation metrics and observation-guidance\nstrategies. These results show that preference alignment, implemented as a soft\nconstraint, can automatically adapt complex background priors tailored to DA,\noffering a promising new direction for advancing the field.",
    "pdf_url": "http://arxiv.org/pdf/2505.22008v1",
    "published": "2025-05-28T06:15:41+00:00",
    "categories": [
      "physics.ao-ph",
      "cs.LG"
    ],
    "primary_category": "physics.ao-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.23824v2",
    "title": "Reviewing Scientific Papers for Critical Problems With Reasoning LLMs: Baseline Approaches and Automatic Evaluation",
    "authors": [
      "Tianmai M. Zhang",
      "Neil F. Abernethy"
    ],
    "abstract": "Recent advancements in large language models have sparked interest in\nutilizing them to aid the peer review process of scientific publication amid\nthe peer review crisis. However, having AI models generate full reviews in the\nsame way as human reviewers risks exacerbating the irresponsible use of\nLLM-generated reviews. As an alternative, we propose adopting LLMs as\nmanuscript quality checkers. We introduce several baseline approaches and an\nextendable automatic evaluation framework using top reasoning LLMs as judges to\ntackle the difficulty of recruiting domain experts for manual evaluation.\nUtilizing papers withdrawn from arXiv, we validated our proposed methods with\nseveral leading reasoning LLMs from multiple vendors and assessed their\nperformance and API costs for identifying critical errors and unsoundness\nproblems in scientific papers. o3 exhibited the best problem identification\nperformance among all models at a modest cost. This paper provides insights\ninto document-based scientific understanding/reasoning and lays a foundation\nfor future applications. Our dataset, code, and model outputs are publicly\navailable.",
    "pdf_url": "http://arxiv.org/pdf/2505.23824v2",
    "published": "2025-05-28T06:14:30+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.22007v1",
    "title": "Event-based Egocentric Human Pose Estimation in Dynamic Environment",
    "authors": [
      "Wataru Ikeda",
      "Masashi Hatano",
      "Ryosei Hara",
      "Mariko Isogawa"
    ],
    "abstract": "Estimating human pose using a front-facing egocentric camera is essential for\napplications such as sports motion analysis, VR/AR, and AI for wearable\ndevices. However, many existing methods rely on RGB cameras and do not account\nfor low-light environments or motion blur. Event-based cameras have the\npotential to address these challenges. In this work, we introduce a novel task\nof human pose estimation using a front-facing event-based camera mounted on the\nhead and propose D-EventEgo, the first framework for this task. The proposed\nmethod first estimates the head poses, and then these are used as conditions to\ngenerate body poses. However, when estimating head poses, the presence of\ndynamic objects mixed with background events may reduce head pose estimation\naccuracy. Therefore, we introduce the Motion Segmentation Module to remove\ndynamic objects and extract background information. Extensive experiments on\nour synthetic event-based dataset derived from EgoBody, demonstrate that our\napproach outperforms our baseline in four out of five evaluation metrics in\ndynamic environments.",
    "pdf_url": "http://arxiv.org/pdf/2505.22007v1",
    "published": "2025-05-28T06:13:01+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.22006v1",
    "title": "Efficiently Enhancing General Agents With Hierarchical-categorical Memory",
    "authors": [
      "Changze Qiao",
      "Mingming Lu"
    ],
    "abstract": "With large language models (LLMs) demonstrating remarkable capabilities,\nthere has been a surge in research on leveraging LLMs to build general-purpose\nmulti-modal agents. However, existing approaches either rely on computationally\nexpensive end-to-end training using large-scale multi-modal data or adopt\ntool-use methods that lack the ability to continuously learn and adapt to new\nenvironments. In this paper, we introduce EHC, a general agent capable of\nlearning without parameter updates. EHC consists of a Hierarchical Memory\nRetrieval (HMR) module and a Task-Category Oriented Experience Learning (TOEL)\nmodule. The HMR module facilitates rapid retrieval of relevant memories and\ncontinuously stores new information without being constrained by memory\ncapacity. The TOEL module enhances the agent's comprehension of various task\ncharacteristics by classifying experiences and extracting patterns across\ndifferent categories. Extensive experiments conducted on multiple standard\ndatasets demonstrate that EHC outperforms existing methods, achieving\nstate-of-the-art performance and underscoring its effectiveness as a general\nagent for handling complex multi-modal tasks.",
    "pdf_url": "http://arxiv.org/pdf/2505.22006v1",
    "published": "2025-05-28T06:12:51+00:00",
    "categories": [
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.22005v1",
    "title": "Leveraging LLM for Stuttering Speech: A Unified Architecture Bridging Recognition and Event Detection",
    "authors": [
      "Shangkun Huang",
      "Jing Deng",
      "Jintao Kang",
      "Rong Zheng"
    ],
    "abstract": "The performance bottleneck of Automatic Speech Recognition (ASR) in\nstuttering speech scenarios has limited its applicability in domains such as\nspeech rehabilitation. This paper proposed an LLM-driven ASR-SED multi-task\nlearning framework that jointly optimized the ASR and Stuttering Event\nDetection (SED) tasks. We proposed a dynamic interaction mechanism where the\nASR branch leveraged CTC-generated soft prompts to assist LLM context modeling,\nwhile the SED branch output stutter embeddings to enhance LLM comprehension of\nstuttered speech. We incorporated contrastive learning to strengthen the\ndiscriminative power of stuttering acoustic features and applied Focal Loss to\nmitigate the long-tailed distribution in stuttering event categories.\nEvaluations on the AS-70 Mandarin stuttering dataset demonstrated that our\nframework reduced the ASR character error rate (CER) to 5.45% (-37.71% relative\nreduction) and achieved an average SED F1-score of 73.63% (+46.58% relative\nimprovement).",
    "pdf_url": "http://arxiv.org/pdf/2505.22005v1",
    "published": "2025-05-28T06:12:19+00:00",
    "categories": [
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.SD"
  },
  {
    "id": "http://arxiv.org/abs/2505.22004v1",
    "title": "Simplicial properadic homotopy",
    "authors": [
      "Eric Hoffbeck",
      "Johan Leray",
      "Bruno Vallette"
    ],
    "abstract": "In this paper, we settle the homotopy properties of the infinity-morphisms of\nhomotopy (bial)-gebras over properads, i.e. algebraic structures made up of\noperations with several inputs and outputs. We start by providing the\nliterature with characterizations for the various types of infinity-morphisms,\nthe most seminal one being the equivalence between infinity-quasi-isomorphisms\nand zig-zags of quasi-isomorphisms which plays a key role in the study the\nformality property. We establish a simplicial enrichment for the categories of\ngebras over some cofibrant properads together with their infinity-morphisms,\nwhose homotopy category provides us with the localisation with respect to\ninfinity-quasi-isomorphisms. These results extend to the properadic level known\nproperties for operads, but the lack of the rectification procedure in this\nsetting forces us to use different methods.",
    "pdf_url": "http://arxiv.org/pdf/2505.22004v1",
    "published": "2025-05-28T06:11:03+00:00",
    "categories": [
      "math.AT",
      "math.CT",
      "math.QA",
      "18M85, 14D15, 16T10, 17B55, 18M70, 18N40, 18N50"
    ],
    "primary_category": "math.AT"
  },
  {
    "id": "http://arxiv.org/abs/2507.19489v1",
    "title": "MAIA: A Collaborative Medical AI Platform for Integrated Healthcare Innovation",
    "authors": [
      "Simone Bendazzoli",
      "Sanna Persson",
      "Mehdi Astaraki",
      "Sebastian Pettersson",
      "Vitali Grozman",
      "Rodrigo Moreno"
    ],
    "abstract": "The integration of Artificial Intelligence (AI) into clinical workflows\nrequires robust collaborative platforms that are able to bridge the gap between\ntechnical innovation and practical healthcare applications. This paper\nintroduces MAIA (Medical Artificial Intelligence Assistant), an open-source\nplatform designed to facilitate interdisciplinary collaboration among\nclinicians, researchers, and AI developers. Built on Kubernetes, MAIA offers a\nmodular, scalable environment with integrated tools for data management, model\ndevelopment, annotation, deployment, and clinical feedback. Key features\ninclude project isolation, CI/CD automation, integration with high-computing\ninfrastructures and in clinical workflows. MAIA supports real-world use cases\nin medical imaging AI, with deployments in both academic and clinical\nenvironments. By promoting collaborations and interoperability, MAIA aims to\naccelerate the translation of AI research into impactful clinical solutions\nwhile promoting reproducibility, transparency, and user-centered design. We\nshowcase the use of MAIA with different projects, both at KTH Royal Institute\nof Technology and Karolinska University Hospital.",
    "pdf_url": "http://arxiv.org/pdf/2507.19489v1",
    "published": "2025-05-28T06:06:57+00:00",
    "categories": [
      "cs.AI",
      "cs.CV",
      "cs.HC",
      "cs.SE"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.22003v1",
    "title": "Legal Assist AI: Leveraging Transformer-Based Model for Effective Legal Assistance",
    "authors": [
      "Jatin Gupta",
      "Akhil Sharma",
      "Saransh Singhania",
      "Ali Imam Abidi"
    ],
    "abstract": "Pursuit of accessible legal assistance in India faces a critical gap, as many\ncitizens struggle to leverage their legal rights due to limited awareness and\naccess to relevant legal information. This paper introduces Legal Assist AI, a\ntransformer-based model designed to bridge this gap by offering effective legal\nassistance through large language models (LLMs). The system retrieves relevant\nlegal information from a curated database and generates accurate responses,\nenabling effective assistance for diverse users, including legal professionals,\nscholars, and the general public. The model was fine-tuned on extensive\ndatasets from the Indian legal domain, including Indian Constitution, Bharatiya\nNyaya Sanhita (BNS), Bharatiya Nagarik Suraksha Sanhita (BNSS) and so forth,\nproviding a robust understanding of the complexities of Indian law. By\nincorporating domain-specific legal datasets, the proposed model demonstrated\nremarkable efficiency and specialization in legal Question-Answering. The model\nwas evaluated against state-of-the-art models such as GPT-3.5 Turbo and Mistral\n7B, achieving a 60.08% score on the AIBE, outperforming its competitors in\nlegal reasoning and accuracy. Unlike other models, Legal Assist AI avoided\ncommon issues such as hallucinations, making it highly reliable for practical\nlegal applications. It showcases the model's applicability in real-world legal\nscenarios, with future iterations aiming to enhance performance and expand its\ndataset to cover a broader range of multilingual and case-specific queries as\nwell.",
    "pdf_url": "http://arxiv.org/pdf/2505.22003v1",
    "published": "2025-05-28T06:06:53+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.22002v1",
    "title": "D-Fusion: Direct Preference Optimization for Aligning Diffusion Models with Visually Consistent Samples",
    "authors": [
      "Zijing Hu",
      "Fengda Zhang",
      "Kun Kuang"
    ],
    "abstract": "The practical applications of diffusion models have been limited by the\nmisalignment between generated images and corresponding text prompts. Recent\nstudies have introduced direct preference optimization (DPO) to enhance the\nalignment of these models. However, the effectiveness of DPO is constrained by\nthe issue of visual inconsistency, where the significant visual disparity\nbetween well-aligned and poorly-aligned images prevents diffusion models from\nidentifying which factors contribute positively to alignment during\nfine-tuning. To address this issue, this paper introduces D-Fusion, a method to\nconstruct DPO-trainable visually consistent samples. On one hand, by performing\nmask-guided self-attention fusion, the resulting images are not only\nwell-aligned, but also visually consistent with given poorly-aligned images. On\nthe other hand, D-Fusion can retain the denoising trajectories of the resulting\nimages, which are essential for DPO training. Extensive experiments demonstrate\nthe effectiveness of D-Fusion in improving prompt-image alignment when applied\nto different reinforcement learning algorithms.",
    "pdf_url": "http://arxiv.org/pdf/2505.22002v1",
    "published": "2025-05-28T06:03:41+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.22001v2",
    "title": "Evaporation-induced freezing dynamics of droplets levitated in acoustic field",
    "authors": [
      "Misaki Mitsuno",
      "Xiao Ma",
      "Koji Hasegawa"
    ],
    "abstract": "This paper presents the evaporation-induced freezing dynamics of pure\ncyclohexane droplets levitated via acoustic levitation. Acoustic levitation has\nattracted considerable attention across various fields owing to its potential\nto create lab-in-a-drop systems. While droplet evaporation is a fundamental\nphysicochemical process in such a platform, the freezing of droplets induced by\nevaporation has been sparsely explored experimentally. For pure cyclohexane,\nthe rapid evaporation of levitated droplets initiated freezing at the droplet\nsurface. To better understand this evaporation-induced freezing process, the\nevaporation behavior of the levitated cyclohexane droplets was visualized and\nquantified using a high-speed camera and an infrared camera. According to the\nobtained experimental data, the evaporative heat transfer characteristics of\nthe droplets were identified with theoretical models. Using the derived heat\ntransfer coefficient, a mathematical prediction method for the onset of\nfreezing was proposed and validated with the experimental data. These\nexperimental findings offer valuable insights into the phase transition process\nand its potential physicochemical applications in a containerless environment.",
    "pdf_url": "http://arxiv.org/pdf/2505.22001v2",
    "published": "2025-05-28T06:02:11+00:00",
    "categories": [
      "physics.flu-dyn"
    ],
    "primary_category": "physics.flu-dyn"
  },
  {
    "id": "http://arxiv.org/abs/2505.22000v1",
    "title": "Collaborative Learning for Unsupervised Multimodal Remote Sensing Image Registration: Integrating Self-Supervision and MIM-Guided Diffusion-Based Image Translation",
    "authors": [
      "Xiaochen Wei",
      "Weiwei Guo",
      "Wenxian Yu"
    ],
    "abstract": "The substantial modality-induced variations in radiometric, texture, and\nstructural characteristics pose significant challenges for the accurate\nregistration of multimodal images. While supervised deep learning methods have\ndemonstrated strong performance, they often rely on large-scale annotated\ndatasets, limiting their practical application. Traditional unsupervised\nmethods usually optimize registration by minimizing differences in feature\nrepresentations, yet often fail to robustly capture geometric discrepancies,\nparticularly under substantial spatial and radiometric variations, thus\nhindering convergence stability. To address these challenges, we propose a\nCollaborative Learning framework for Unsupervised Multimodal Image\nRegistration, named CoLReg, which reformulates unsupervised registration\nlearning into a collaborative training paradigm comprising three components:\n(1) a cross-modal image translation network, MIMGCD, which employs a learnable\nMaximum Index Map (MIM) guided conditional diffusion model to synthesize\nmodality-consistent image pairs; (2) a self-supervised intermediate\nregistration network which learns to estimate geometric transformations using\naccurate displacement labels derived from MIMGCD outputs; (3) a distilled\ncross-modal registration network trained with pseudo-label predicted by the\nintermediate network. The three networks are jointly optimized through an\nalternating training strategy wherein each network enhances the performance of\nthe others. This mutual collaboration progressively reduces modality\ndiscrepancies, enhances the quality of pseudo-labels, and improves registration\naccuracy. Extensive experimental results on multiple datasets demonstrate that\nour ColReg achieves competitive or superior performance compared to\nstate-of-the-art unsupervised approaches and even surpasses several supervised\nbaselines.",
    "pdf_url": "http://arxiv.org/pdf/2505.22000v1",
    "published": "2025-05-28T06:02:06+00:00",
    "categories": [
      "eess.IV"
    ],
    "primary_category": "eess.IV"
  },
  {
    "id": "http://arxiv.org/abs/2505.21999v1",
    "title": "Found in Translation: Measuring Multilingual LLM Consistency as Simple as Translate then Evaluate",
    "authors": [
      "Ashim Gupta",
      "Maitrey Mehta",
      "Zhichao Xu",
      "Vivek Srikumar"
    ],
    "abstract": "Large language models (LLMs) provide detailed and impressive responses to\nqueries in English. However, are they really consistent at responding to the\nsame query in other languages? The popular way of evaluating for multilingual\nperformance of LLMs requires expensive-to-collect annotated datasets. Further,\nevaluating for tasks like open-ended generation, where multiple correct answers\nmay exist, is nontrivial. Instead, we propose to evaluate the predictability of\nmodel response across different languages. In this work, we propose a framework\nto evaluate LLM's cross-lingual consistency based on a simple Translate then\nEvaluate strategy. We instantiate this evaluation framework along two\ndimensions of consistency: information and empathy. Our results reveal\npronounced inconsistencies in popular LLM responses across thirty languages,\nwith severe performance deficits in certain language families and scripts,\nunderscoring critical weaknesses in their multilingual capabilities. These\nfindings necessitate cross-lingual evaluations that are consistent along\nmultiple dimensions. We invite practitioners to use our framework for future\nmultilingual LLM benchmarking.",
    "pdf_url": "http://arxiv.org/pdf/2505.21999v1",
    "published": "2025-05-28T06:00:21+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.21998v1",
    "title": "Hyperbolic Monge-Amp√®re systems with $S_1=0$",
    "authors": [
      "Yuhao Hu"
    ],
    "abstract": "For hyperbolic Monge-Amp\\`ere systems, a well-known solution of the\nequivalence problem yields two invariant tensors, ${S}_1$ and ${S}_2$, defined\non the underlying $5$-manifold, where ${S}_2=0$ characterizes systems that are\nEuler-Lagrange. In this article, we consider the `opposite' case, ${S}_1 = 0$,\nand show that the local generality of such systems is `$2$ arbitrary functions\nof $3$ variables'. In addition, we classify all $S_1=0$ systems with\ncohomogeneity at most one, which turn out to be linear up to contact\ntransformations.",
    "pdf_url": "http://arxiv.org/pdf/2505.21998v1",
    "published": "2025-05-28T05:58:04+00:00",
    "categories": [
      "math.DG",
      "math.AP",
      "35L10, 58A15, 53C10"
    ],
    "primary_category": "math.DG"
  },
  {
    "id": "http://arxiv.org/abs/2505.21997v1",
    "title": "Leveraging Interview-Informed LLMs to Model Survey Responses: Comparative Insights from AI-Generated and Human Data",
    "authors": [
      "Jihong Zhang",
      "Xinya Liang",
      "Anqi Deng",
      "Nicole Bonge",
      "Lin Tan",
      "Ling Zhang",
      "Nicole Zarrett"
    ],
    "abstract": "Mixed methods research integrates quantitative and qualitative data but faces\nchallenges in aligning their distinct structures, particularly in examining\nmeasurement characteristics and individual response patterns. Advances in large\nlanguage models (LLMs) offer promising solutions by generating synthetic survey\nresponses informed by qualitative data. This study investigates whether LLMs,\nguided by personal interviews, can reliably predict human survey responses,\nusing the Behavioral Regulations in Exercise Questionnaire (BREQ) and\ninterviews from after-school program staff as a case study. Results indicate\nthat LLMs capture overall response patterns but exhibit lower variability than\nhumans. Incorporating interview data improves response diversity for some\nmodels (e.g., Claude, GPT), while well-crafted prompts and low-temperature\nsettings enhance alignment between LLM and human responses. Demographic\ninformation had less impact than interview content on alignment accuracy. These\nfindings underscore the potential of interview-informed LLMs to bridge\nqualitative and quantitative methodologies while revealing limitations in\nresponse variability, emotional interpretation, and psychometric fidelity.\nFuture research should refine prompt design, explore bias mitigation, and\noptimize model settings to enhance the validity of LLM-generated survey data in\nsocial science research.",
    "pdf_url": "http://arxiv.org/pdf/2505.21997v1",
    "published": "2025-05-28T05:57:26+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.21996v1",
    "title": "Learning World Models for Interactive Video Generation",
    "authors": [
      "Taiye Chen",
      "Xun Hu",
      "Zihan Ding",
      "Chi Jin"
    ],
    "abstract": "Foundational world models must be both interactive and preserve\nspatiotemporal coherence for effective future planning with action choices.\nHowever, present models for long video generation have limited inherent world\nmodeling capabilities due to two main challenges: compounding errors and\ninsufficient memory mechanisms. We enhance image-to-video models with\ninteractive capabilities through additional action conditioning and\nautoregressive framework, and reveal that compounding error is inherently\nirreducible in autoregressive video generation, while insufficient memory\nmechanism leads to incoherence of world models. We propose video retrieval\naugmented generation (VRAG) with explicit global state conditioning, which\nsignificantly reduces long-term compounding errors and increases spatiotemporal\nconsistency of world models. In contrast, naive autoregressive generation with\nextended context windows and retrieval-augmented generation prove less\neffective for video generation, primarily due to the limited in-context\nlearning capabilities of current video models. Our work illuminates the\nfundamental challenges in video world models and establishes a comprehensive\nbenchmark for improving video generation models with internal world modeling\ncapabilities.",
    "pdf_url": "http://arxiv.org/pdf/2505.21996v1",
    "published": "2025-05-28T05:55:44+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.21995v2",
    "title": "Sr$_2$NbO$_4$: A $4d$ analogue of the layered perovskite Sr$_2$VO$_4$",
    "authors": [
      "Leonid S. Taran",
      "Anastasia E. Lebedeva",
      "Sergey V. Streltsov"
    ],
    "abstract": "This work focuses on the layered perovskite Sr$_2$NbO$_4$, a 4$d$ analogue of\nSr$_2$VO$_4$, which remains an unsolved puzzle with a possible intriguing\nhidden magnetic order. Using density functional theory (DFT) calculations, we\ndemonstrate the robust thermodynamic stability and exfoliability of\nSr$_2$NbO$_4$, suggesting potential applications as a 2D material. Imperfect\nFermi surface nesting indicates instabilities that may drive symmetry lowering,\ncharge/orbital density waves, or superconductivity. Dynamical mean-field theory\n(DMFT) calculations reveal moderate mass renormalization $(m^*/m\\sim1.3)$ and\nan itinerant character of magnetism with strong longitudinal spin fluctuations.\nThe exchange interaction is dominated by in-plane ferromagnetic coupling with\nmuch weaker interlayer antiferromagnetic exchange.",
    "pdf_url": "http://arxiv.org/pdf/2505.21995v2",
    "published": "2025-05-28T05:54:43+00:00",
    "categories": [
      "cond-mat.str-el"
    ],
    "primary_category": "cond-mat.str-el"
  },
  {
    "id": "http://arxiv.org/abs/2505.21994v1",
    "title": "Locking-Free Training of Physics-Informed Neural Network for Solving Nearly Incompressible Elasticity Equations",
    "authors": [
      "Josef Dick",
      "Seungchan Ko",
      "Kassem Mustapha",
      "Sanghyeon Park"
    ],
    "abstract": "Due to divergence instability, the accuracy of low-order conforming finite\nelement methods for nearly incompressible homogeneous elasticity equations\ndeteriorates as the Lam\\'e coefficient $\\lambda\\to\\infty$, or equivalently as\nthe Poisson ratio $\\nu\\to1/2$. This phenomenon, known as locking or\nnon-robustness, remains not fully understood despite extensive investigation.\nIn this paper, we propose a robust method based on a fundamentally different,\nmachine-learning-driven approach. Leveraging recently developed\nPhysics-Informed Neural Networks (PINNs), we address the numerical solution of\nlinear elasticity equations governing nearly incompressible materials. The core\nidea of our method is to appropriately decompose the given equations to\nalleviate the extreme imbalance in the coefficients, while simultaneously\nsolving both the forward and inverse problems to recover the solutions of the\ndecomposed systems as well as the associated external conditions. Through\nvarious numerical experiments, including constant, variable and parametric\nLam\\'e coefficients, we illustrate the efficiency of the proposed methodology.",
    "pdf_url": "http://arxiv.org/pdf/2505.21994v1",
    "published": "2025-05-28T05:52:03+00:00",
    "categories": [
      "math.NA",
      "cs.LG",
      "cs.NA"
    ],
    "primary_category": "math.NA"
  },
  {
    "id": "http://arxiv.org/abs/2505.23823v1",
    "title": "RAGPPI: RAG Benchmark for Protein-Protein Interactions in Drug Discovery",
    "authors": [
      "Youngseung Jeon",
      "Ziwen Li",
      "Thomas Li",
      "JiaSyuan Chang",
      "Morteza Ziyadi",
      "Xiang 'Anthony' Chen"
    ],
    "abstract": "Retrieving the biological impacts of protein-protein interactions (PPIs) is\nessential for target identification (Target ID) in drug development. Given the\nvast number of proteins involved, this process remains time-consuming and\nchallenging. Large Language Models (LLMs) and Retrieval-Augmented Generation\n(RAG) frameworks have supported Target ID; however, no benchmark currently\nexists for identifying the biological impacts of PPIs. To bridge this gap, we\nintroduce the RAG Benchmark for PPIs (RAGPPI), a factual question-answer\nbenchmark of 4,420 question-answer pairs that focus on the potential biological\nimpacts of PPIs. Through interviews with experts, we identified criteria for a\nbenchmark dataset, such as a type of QA and source. We built a gold-standard\ndataset (500 QA pairs) through expert-driven data annotation. We developed an\nensemble auto-evaluation LLM that reflected expert labeling characteristics,\nwhich facilitates the construction of a silver-standard dataset (3,720 QA\npairs). We are committed to maintaining RAGPPI as a resource to support the\nresearch community in advancing RAG systems for drug discovery QA solutions.",
    "pdf_url": "http://arxiv.org/pdf/2505.23823v1",
    "published": "2025-05-28T05:48:25+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.21993v2",
    "title": "Free Circle Actions on the Product of Three Spheres",
    "authors": [
      "Dimpi",
      "Hemant Kumar Singh"
    ],
    "abstract": "The orbit spaces of free S^0-actions on the mod 2 cohomology product of three\nspheres, S^n x S^m x S^l, 1 <= n <= m <= l have been determined in [6]. In this\npaper, we extend these findings to free S^1-actions on the rational cohomology\nproduct of three spheres. This extension also builds upon the work of Dotzel et\nal. [7], who studied free circle actions on the rational cohomology product of\ntwo spheres. Additionally, we establish Borsuk-Ulam type theorems.",
    "pdf_url": "http://arxiv.org/pdf/2505.21993v2",
    "published": "2025-05-28T05:47:27+00:00",
    "categories": [
      "math.AT",
      "Primary 57S17, Secondary 57S25"
    ],
    "primary_category": "math.AT"
  },
  {
    "id": "http://arxiv.org/abs/2505.21992v1",
    "title": "Soft Electrothermal Meta-Actuator for Robust Multifunctional Control",
    "authors": [
      "Hanseong Jo",
      "Pavel Shafirin",
      "Christopher Le",
      "Caden Chan",
      "Artur Davoyan"
    ],
    "abstract": "Soft electrothermal actuators are of great interest in diverse application\ndomains for their simplicity, compliance, and ease of control. However, the\nvery nature of thermally induced mechanical actuation sets inherent operation\nconstraints: unidirectional motion, environmental sensitivity, and slow\nresponse times limited by passive cooling. To overcome these constraints, we\npropose a meta-actuator architecture, which uses engineered heat transfer in\nthin films to achieve multifunctional operation. We demonstrate electrically\nselectable bidirectional motion with large deflection ($ \\geq $28% of actuator\nlength at 0.75 W), suppressed thermal sensitivity to ambient temperature\nchanges when compared to conventional actuators (>100$ \\times $ lower), and\nactively forced return to the rest state, which is 10 times faster than that\nwith passive cooling. We further show that our meta-actuator approach enables\nextended ranges of motions for manipulating complex objects. Versatile soft\ngripper operations highlight the meta-actuator's potential for soft robotics\nand devices.",
    "pdf_url": "http://arxiv.org/pdf/2505.21992v1",
    "published": "2025-05-28T05:45:10+00:00",
    "categories": [
      "cs.RO"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.21991v1",
    "title": "Bridging Fitness With Search Spaces By Fitness Supremums: A Theoretical Study on LGP",
    "authors": [
      "Zhixing Huang",
      "Yi Mei",
      "Fangfang Zhang",
      "Mengjie Zhang",
      "Wolfgang Banzhaf"
    ],
    "abstract": "Genetic programming has undergone rapid development in recent years. However,\ntheoretical studies of genetic programming are far behind. One of the major\nobstacles to theoretical studies is the challenge of developing a model to\ndescribe the relationship between fitness values and program genotypes. In this\npaper, we take linear genetic programming (LGP) as an example to study the\nfitness-to-genotype relationship. We find that the fitness expectation\nincreases with fitness supremum over instruction editing distance, considering\n1) the fitness supremum linearly increases with the instruction editing\ndistance in LGP, 2) the fitness infimum is fixed, and 3) the fitness\nprobabilities over different instruction editing distances are similar. We then\nextend these findings to explain the bloat effect and the minimum hitting time\nof LGP based on instruction editing distance. The bloat effect happens because\nit is more likely to produce better offspring by adding instructions than by\nremoving them, given an instruction editing distance from the optimal program.\nThe analysis of the minimum hitting time suggests that for a basic LGP genetic\noperator (i.e., freemut), maintaining a necessarily small program size and\nmutating multiple instructions each time can improve LGP performance. The\nreported empirical results verify our hypothesis.",
    "pdf_url": "http://arxiv.org/pdf/2505.21991v1",
    "published": "2025-05-28T05:39:33+00:00",
    "categories": [
      "cs.NE"
    ],
    "primary_category": "cs.NE"
  },
  {
    "id": "http://arxiv.org/abs/2505.21990v1",
    "title": "Polarforming Design with Phase Shifter Based Polarization Reconfigurable Antennas",
    "authors": [
      "Zijian Zhou",
      "Jingze Ding",
      "Rui Zhang"
    ],
    "abstract": "In this paper, we propose a new form of polarization reconfigurable antennas\n(PRAs) that can form linear, circular, and general elliptical polarizations\nassisted by phase shifters (PSs). With PRAs, polarforming is achieved, which\nenables the antenna to shape its polarization into a desired state for aligning\nwith that of the received electromagnetic (EM) wave or reconfiguring that of\nthe transmit EM wave. To demonstrate the benefits of polarforming, we\ninvestigate a PRA-aided single-input single-output (SISO) communication system\nequipped with tunable PSs for polarization adaptation. We characterize the\nachievable signal-to-noise ratio (SNR) at the receiver as a function of the\nphase shifts of PS-based PRAs. Moreover, we develop an alternating optimization\napproach to maximize the SNR by optimizing the phase shifts at both the\ntransmitter and receiver. Finally, comprehensive simulation results are\npresented, which not only validate the effectiveness of polarforming in\nmitigating the channel depolarization effects, but also demonstrate its\nsubstantial performance improvement over conventional systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.21990v1",
    "published": "2025-05-28T05:36:05+00:00",
    "categories": [
      "eess.SP"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2505.21989v1",
    "title": "Extending Recent Congruence Results on $(\\ell,Œº)$-Regular Overpartitions",
    "authors": [
      "Bishnu Paudel",
      "James A. Sellers",
      "Haiyang Wang"
    ],
    "abstract": "Recently, Alanazi, Munagi, and Saikia employed the theory of modular forms to\ninvestigate the arithmetic properties of the function\n$\\overline{R_{\\ell,\\mu}}(n)$, which enumerates the overpartitions of $n$ where\nno part is divisible by either $\\ell$ or $\\mu$, for various integer pairs\n$(\\ell, \\mu)$. In this paper, we substantially extend several of their results\nand establish infinitely many families of new congruences. Our proofs are\nentirely elementary, relying solely on classical $q$-series manipulations and\ndissection formulas.",
    "pdf_url": "http://arxiv.org/pdf/2505.21989v1",
    "published": "2025-05-28T05:33:54+00:00",
    "categories": [
      "math.NT",
      "math.CO",
      "11P83, 05A17"
    ],
    "primary_category": "math.NT"
  },
  {
    "id": "http://arxiv.org/abs/2505.21988v1",
    "title": "Functional Matching of Logic Subgraphs: Beyond Structural Isomorphism",
    "authors": [
      "Ziyang Zheng",
      "Kezhi Li",
      "Zhengyuan Shi",
      "Qiang Xu"
    ],
    "abstract": "Subgraph matching in logic circuits is foundational for numerous Electronic\nDesign Automation (EDA) applications, including datapath optimization,\narithmetic verification, and hardware trojan detection. However, existing\ntechniques rely primarily on structural graph isomorphism and thus fail to\nidentify function-related subgraphs when synthesis transformations\nsubstantially alter circuit topology. To overcome this critical limitation, we\nintroduce the concept of functional subgraph matching, a novel approach that\nidentifies whether a given logic function is implicitly present within a larger\ncircuit, irrespective of structural variations induced by synthesis or\ntechnology mapping. Specifically, we propose a two-stage multi-modal framework:\n(1) learning robust functional embeddings across AIG and post-mapping netlists\nfor functional subgraph detection, and (2) identifying fuzzy boundaries using a\ngraph segmentation approach. Evaluations on standard benchmarks (ITC99,\nOpenABCD, ForgeEDA) demonstrate significant performance improvements over\nexisting structural methods, with average $93.8\\%$ accuracy in functional\nsubgraph detection and a dice score of $91.3\\%$ in fuzzy boundary\nidentification.",
    "pdf_url": "http://arxiv.org/pdf/2505.21988v1",
    "published": "2025-05-28T05:31:49+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.21987v1",
    "title": "ACE: Exploring Activation Cosine Similarity and Variance for Accurate and Calibration-Efficient LLM Pruning",
    "authors": [
      "Zhendong Mi",
      "Zhenglun Kong",
      "Geng Yuan",
      "Shaoyi Huang"
    ],
    "abstract": "With the rapid expansion of large language models (LLMs), the demand for\nmemory and computational resources has grown significantly. Recent advances in\nLLM pruning aim to reduce the size and computational cost of these models.\nHowever, existing methods often suffer from either suboptimal pruning\nperformance or low time efficiency during the pruning process. In this work, we\npropose an efficient and effective pruning method that simultaneously achieves\nhigh pruning performance and fast pruning speed with improved calibration\nefficiency. Our approach introduces two key innovations: (1) An activation\ncosine similarity loss-guided pruning metric, which considers the angular\ndeviation of the output activation between the dense and pruned models. (2) An\nactivation variance-guided pruning metric, which helps preserve semantic\ndistinctions in output activations after pruning, enabling effective pruning\nwith shorter input sequences. These two components can be readily combined to\nenhance LLM pruning in both accuracy and efficiency. Experimental results show\nthat our method achieves up to an 18% reduction in perplexity and up to 63%\ndecrease in pruning time on prevalent LLMs such as LLaMA, LLaMA-2, and OPT.",
    "pdf_url": "http://arxiv.org/pdf/2505.21987v1",
    "published": "2025-05-28T05:25:16+00:00",
    "categories": [
      "cs.LG",
      "I.2.6; I.2.7"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.21986v2",
    "title": "Characterizing Equivalence of Logically Constrained Terms via Existentially Constrained Terms (Full Version)",
    "authors": [
      "Kanta Takahata",
      "Jonas Sch√∂pf",
      "Naoki Nishida",
      "Takahito Aoto"
    ],
    "abstract": "Logically constrained term rewriting is a rewriting framework that supports\nbuilt-in data structures such as integers and bit vectors. Recently,\nconstrained terms play a key role in various analyses and applications of\nlogically constrained term rewriting. A fundamental question on constrained\nterms arising there is how to characterize equivalence between them. However,\nin the current literature only limited progress has been made on this. In this\npaper, we provide several sound and complete solutions to tackle this problem.\nOur key idea is the introduction of a novel concept, namely existentially\nconstrained terms, into which the original form of constrained terms can be\nembedded. We present several syntactic characterizations of equivalence between\nexistentially constrained terms. In particular, we provide two different kinds\nof complete characterizations: one is designed to facilitate equivalence\nchecking, while the other is intended for theoretical analysis.",
    "pdf_url": "http://arxiv.org/pdf/2505.21986v2",
    "published": "2025-05-28T05:23:50+00:00",
    "categories": [
      "cs.LO"
    ],
    "primary_category": "cs.LO"
  },
  {
    "id": "http://arxiv.org/abs/2505.21985v1",
    "title": "Reward-Independent Messaging for Decentralized Multi-Agent Reinforcement Learning",
    "authors": [
      "Naoto Yoshida",
      "Tadahiro Taniguchi"
    ],
    "abstract": "In multi-agent reinforcement learning (MARL), effective communication\nimproves agent performance, particularly under partial observability. We\npropose MARL-CPC, a framework that enables communication among fully\ndecentralized, independent agents without parameter sharing. MARL-CPC\nincorporates a message learning model based on collective predictive coding\n(CPC) from emergent communication research. Unlike conventional methods that\ntreat messages as part of the action space and assume cooperation, MARL-CPC\nlinks messages to state inference, supporting communication in non-cooperative,\nreward-independent settings. We introduce two algorithms -Bandit-CPC and\nIPPO-CPC- and evaluate them in non-cooperative MARL tasks. Benchmarks show that\nboth outperform standard message-as-action approaches, establishing effective\ncommunication even when messages offer no direct benefit to the sender. These\nresults highlight MARL-CPC's potential for enabling coordination in complex,\ndecentralized environments.",
    "pdf_url": "http://arxiv.org/pdf/2505.21985v1",
    "published": "2025-05-28T05:23:47+00:00",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.MA"
  },
  {
    "id": "http://arxiv.org/abs/2508.08256v1",
    "title": "FIER: Fine-Grained and Efficient KV Cache Retrieval for Long-context LLM Inference",
    "authors": [
      "Dongwei Wang",
      "Zijie Liu",
      "Song Wang",
      "Yuxin Ren",
      "Jianing Deng",
      "Jingtong Hu",
      "Tianlong Chen",
      "Huanrui Yang"
    ],
    "abstract": "The Key-Value (KV) cache reading latency increases significantly with context\nlengths, hindering the efficiency of long-context LLM inference. To address\nthis, previous works propose retaining a small fraction of KV cache based on\ntoken importance. For example, KV eviction uses static heuristics to retain\ntokens, while KV retrieval dynamically selects query-relevant tokens for more\nadaptive cache management. However, we observe that important tokens are often\nsparsely distributed across the long context. This sparsity makes existing\npage-level KV retrieval inaccurate, as each page may include irrelevant tokens\nand miss critical ones. In this work, we propose Fier, a\n\\underline{Fi}ne-Grained and \\underline{E}fficient KV cache\n\\underline{R}etrieval method. Fier uses 1-bit quantized keys to estimate the\nimportance of each token, resulting in efficient and precise retrieval.\nExperiments show that Fier matches full KV performance using only 11\\% of the\ncache budget across various long-context tasks, reducing decoding latency by\n1.2$\\times$ to 1.5$\\times$.",
    "pdf_url": "http://arxiv.org/pdf/2508.08256v1",
    "published": "2025-05-28T05:22:44+00:00",
    "categories": [
      "cs.DB"
    ],
    "primary_category": "cs.DB"
  },
  {
    "id": "http://arxiv.org/abs/2505.21984v1",
    "title": "Stress distribution in elastic disks with a hole under uniaxial compression",
    "authors": [
      "Ken Okamura",
      "Yosuke Sato",
      "Satoshi Takada"
    ],
    "abstract": "This paper investigates the stress and displacement distribution in a\ntwo-dimensional elastic hollow disk subjected to distributed diametric loading,\nextending our previous analysis of concentrated loading [Okamura et al.\nStrength Mater. 57, 102-114 (2025)]. The study provides deeper insights into\nthe mechanical behavior of materials such as concrete and rock by examining the\neffects of load distribution on stress localization and displacement patterns.\nUsing elastodynamic theory, we derive the static stress distributions and\nidentify key differences from the concentrated loading case, particularly in\nthe locations and magnitudes of stress extrema. This work contributes to a more\ncomprehensive understanding of stress behavior in elastic disks under realistic\nloading conditions.",
    "pdf_url": "http://arxiv.org/pdf/2505.21984v1",
    "published": "2025-05-28T05:22:38+00:00",
    "categories": [
      "cond-mat.soft",
      "physics.class-ph"
    ],
    "primary_category": "cond-mat.soft"
  },
  {
    "id": "http://arxiv.org/abs/2505.21983v1",
    "title": "Tracing Galaxy Evolution in infalling galaxies of Abell 496: From Starburst to Quenching",
    "authors": [
      "M. M. L√≥pez-Guti√©rrez",
      "H. Bravo-Alfaro",
      "P. T. Rahna",
      "G. A. Mamon",
      "Y. L. Jaff√©",
      "L. F. Madrigal-Ayala",
      "E. Acosta-Espinoza"
    ],
    "abstract": "During the fall of late-type galaxies into clusters, they can experiment a\nvariety of evolutionary mechanisms according their local environment.\nConsequently, studying the UV emission and the cold gas of late-type galaxies\nprovide key insights in the evolution of short-lived starburst and galaxy\nquenching. In this work, we conduted a study of two 28' fields observed with\nUVIT-AstroSat in the central region of the Abell cluster A496 ($z=0.033$),\nincluding HI, data from NRAO VLA. We reported 22 cluster members detected in\nFUV; all of them are detected in HI, or have upper limits for the HI-mass. We\nfind our FUV detected galaxies generally have higher specific star formation\nrates than other star forming galaxies. Most of the FUV galaxies with masses\nabove 10$^9 \\mathrm{M}_{\\odot}$,and showing high sSFR have no close neighbors,\npointing at RPS as the dominant mechanism affecting them. In contrast, most of\nthe low-mass FUV objects present at least one companion, suggesting that tidal\ninteractions also play an important role in the triggering of infalling\ngalaxies. Combining the FUV-SFR with the HI properties of the observed galaxies\nin A496 we identify an evolutionary sequence consisting of five stages: (1)\nPre-triggering, (2) Initial SF-triggering, (3) Peak of star-formation, (4)\nSF-fading, and (5) SF-quenching. During this path, normal gas-rich objects\nreach a gas-deficiency phase with SFR well below the main sequence. This\nprocess, prior to becoming a full passive galaxy, can be accomplished within a\nfew 10$^{8}$ yr.",
    "pdf_url": "http://arxiv.org/pdf/2505.21983v1",
    "published": "2025-05-28T05:22:17+00:00",
    "categories": [
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2505.21982v1",
    "title": "Eye-Tracking and Biometric Feedback in UX Research: Measuring User Engagement and Cognitive Load",
    "authors": [
      "Aaditya Shankar Majumder"
    ],
    "abstract": "User experience research often uses surveys and interviews, which may miss\nsubconscious user interactions. This study explores eye-tracking and biometric\nfeedback as tools to assess user engagement and cognitive load in digital\ninterfaces. These methods measure gaze behavior and bodily responses, providing\nan objective complement to qualitative insights. Using empirical evidence,\npractical applications, and advancements from 2023-2025, we present\nexperimental data, describe our methodology, and place our work within\nfoundational and recent literature. We address challenges like data\ninterpretation, ethical issues, and technological integration. These tools are\nkey for advancing UX design in complex digital environments.",
    "pdf_url": "http://arxiv.org/pdf/2505.21982v1",
    "published": "2025-05-28T05:21:29+00:00",
    "categories": [
      "cs.HC"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2505.21981v1",
    "title": "Learning Compositional Behaviors from Demonstration and Language",
    "authors": [
      "Weiyu Liu",
      "Neil Nie",
      "Ruohan Zhang",
      "Jiayuan Mao",
      "Jiajun Wu"
    ],
    "abstract": "We introduce Behavior from Language and Demonstration (BLADE), a framework\nfor long-horizon robotic manipulation by integrating imitation learning and\nmodel-based planning. BLADE leverages language-annotated demonstrations,\nextracts abstract action knowledge from large language models (LLMs), and\nconstructs a library of structured, high-level action representations. These\nrepresentations include preconditions and effects grounded in visual perception\nfor each high-level action, along with corresponding controllers implemented as\nneural network-based policies. BLADE can recover such structured\nrepresentations automatically, without manually labeled states or symbolic\ndefinitions. BLADE shows significant capabilities in generalizing to novel\nsituations, including novel initial states, external state perturbations, and\nnovel goals. We validate the effectiveness of our approach both in simulation\nand on real robots with a diverse set of objects with articulated parts,\npartial observability, and geometric constraints.",
    "pdf_url": "http://arxiv.org/pdf/2505.21981v1",
    "published": "2025-05-28T05:19:59+00:00",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.21980v2",
    "title": "Understanding gas mixing in the circumgalactic medium",
    "authors": [
      "Hilay Shah",
      "Freeke van de Voort",
      "Amit Seta",
      "Christoph Federrath"
    ],
    "abstract": "We study gas mixing in a simulated Milky Way-mass galaxy's circumgalactic\nmedium (CGM) using cosmological `zoom-in' simulations. We insert tracer dyes in\nthe CGM with different gas flows (shearing, coherent, and static) and diverse\nphysical properties to track gas mixing. We correlate the extent and shape of\nthe dye spread with the local gas properties to understand gas mixing. Velocity\ndispersion and traceless symmetric shear tensors (pure shear deformation) in\nsmall regions (<= 5 kpc) around the dye injection locations best predict the\ndye spread extent after 200 Myr. We use this to determine diffusion calibration\nconstants for subgrid-scale mixing models. While the dye shape after 200 Myr\naligns well with the velocity dispersion and magnetic field dispersion, the\nbest alignment occurs with the dispersion of stretching eigenvectors (traceless\nsymmetric shear tensor) and plane-of-rotation (antisymmetric shear or vorticity\ntensor) in large regions (10 kpc) around the dye injection locations.\nTherefore, shear statistics and velocity dispersion best predict the extent and\nshape of mixed gas. The linear temporal dependence of the dye spread suggests\nsuperdiffusion in the CGM, potentially due to turbulent and large-scale\ncoherent flows or numerical diffusion. Despite significant numerical mixing\nfrom our 1 kpc resolution (insufficient to resolve Reynolds numbers ~10^2-10^3,\nwhich require a few hundred pc resolution), our correlation results are robust\nthanks to fixed spatial resolution throughout the CGM. These results can be\nused to predict diffusion coefficients to model magnetic field diffusion, heat\ntransport, and metal mixing.",
    "pdf_url": "http://arxiv.org/pdf/2505.21980v2",
    "published": "2025-05-28T05:17:59+00:00",
    "categories": [
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2505.21979v2",
    "title": "Pearl: A Multimodal Culturally-Aware Arabic Instruction Dataset",
    "authors": [
      "Fakhraddin Alwajih",
      "Samar Mohamed Magdy",
      "Abdellah El Mekki",
      "Omer Nacar",
      "Youssef Nafea",
      "Safaa Taher Abdelfadil",
      "Abdulfattah Mohammed Yahya",
      "Hamzah Luqman",
      "Nada Almarwani",
      "Samah Aloufi",
      "Baraah Qawasmeh",
      "Houdaifa Atou",
      "Serry Sibaee",
      "Hamzah A. Alsayadi",
      "Walid Al-Dhabyani",
      "Maged S. Al-shaibani",
      "Aya El aatar",
      "Nour Qandos",
      "Rahaf Alhamouri",
      "Samar Ahmad",
      "Razan Khassib",
      "Lina Hamad",
      "Mohammed Anwar AL-Ghrawi",
      "Fatimah Alshamari",
      "Cheikh Malainine",
      "Doaa Qawasmeh",
      "Aminetou Yacoub",
      "Tfeil moilid",
      "Ruwa AbuHweidi",
      "Ahmed Aboeitta",
      "Vatimetou Mohamed Lemin",
      "Reem Abdel-Salam",
      "Ahlam Bashiti",
      "Adel Ammar",
      "Aisha Alansari",
      "Ahmed Ashraf",
      "Nora Alturayeif",
      "Sara Shatnawi",
      "Alcides Alcoba Inciarte",
      "AbdelRahim A. Elmadany",
      "Mohamedou cheikh tourad",
      "Ismail Berrada",
      "Mustafa Jarrar",
      "Shady Shehata",
      "Muhammad Abdul-Mageed"
    ],
    "abstract": "Mainstream large vision-language models (LVLMs) inherently encode cultural\nbiases, highlighting the need for diverse multimodal datasets. To address this\ngap, we introduce Pearl, a large-scale Arabic multimodal dataset and benchmark\nexplicitly designed for cultural understanding. Constructed through advanced\nagentic workflows and extensive human-in-the-loop annotations by 45 annotators\nfrom across the Arab world, Pearl comprises over K multimodal examples spanning\nten culturally significant domains covering all Arab countries. We further\nprovide two robust evaluation benchmarks Pearl and Pearl-Lite along with a\nspecialized subset Pearl-X explicitly developed to assess nuanced cultural\nvariations. Comprehensive evaluations on state-of-the-art open and proprietary\nLVLMs demonstrate that reasoning-centric instruction alignment substantially\nimproves models' cultural grounding compared to conventional scaling methods.\nPearl establishes a foundational resource for advancing culturally-informed\nmultimodal modeling research. All datasets and benchmarks are publicly\navailable.",
    "pdf_url": "http://arxiv.org/pdf/2505.21979v2",
    "published": "2025-05-28T05:14:47+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.21978v1",
    "title": "Two-Stage Feature Generation with Transformer and Reinforcement Learning",
    "authors": [
      "Wanfu Gao",
      "Zengyao Man",
      "Zebin He",
      "Yuhao Tang",
      "Jun Gao",
      "Kunpeng Liu"
    ],
    "abstract": "Feature generation is a critical step in machine learning, aiming to enhance\nmodel performance by capturing complex relationships within the data and\ngenerating meaningful new features. Traditional feature generation methods\nheavily rely on domain expertise and manual intervention, making the process\nlabor-intensive and challenging to adapt to different scenarios. Although\nautomated feature generation techniques address these issues to some extent,\nthey often face challenges such as feature redundancy, inefficiency in feature\nspace exploration, and limited adaptability to diverse datasets and tasks. To\naddress these problems, we propose a Two-Stage Feature Generation (TSFG)\nframework, which integrates a Transformer-based encoder-decoder architecture\nwith Proximal Policy Optimization (PPO). The encoder-decoder model in TSFG\nleverages the Transformer's self-attention mechanism to efficiently represent\nand transform features, capturing complex dependencies within the data. PPO\nfurther enhances TSFG by dynamically adjusting the feature generation strategy\nbased on task-specific feedback, optimizing the process for improved\nperformance and adaptability. TSFG dynamically generates high-quality feature\nsets, significantly improving the predictive performance of machine learning\nmodels. Experimental results demonstrate that TSFG outperforms existing\nstate-of-the-art methods in terms of feature quality and adaptability.",
    "pdf_url": "http://arxiv.org/pdf/2505.21978v1",
    "published": "2025-05-28T05:11:59+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.21977v1",
    "title": "Homology of Rook-Brauer Algebras and Motzkin Algebras",
    "authors": [
      "Khoa Ta"
    ],
    "abstract": "Using the technique of inductive resolution introduced in arXiv:2303.07979,\nwe prove that the homology of Rook-Brauer Algebra, interpreted as appropriate\nTor-group, is isomorphic to that of symmetric group for all degrees under the\nassumption that $\\epsilon$ in $R$ is invertible; furthermore, we also prove the\nhomology of the Motzkin algebras vanishes in positive degrees under the same\nassumption. These results thereby establish homological stability of both\nalgebras.",
    "pdf_url": "http://arxiv.org/pdf/2505.21977v1",
    "published": "2025-05-28T05:09:35+00:00",
    "categories": [
      "math.RA",
      "math.RT"
    ],
    "primary_category": "math.RA"
  },
  {
    "id": "http://arxiv.org/abs/2505.21976v1",
    "title": "High-order virtual gain for optical loss compensation in plasmonic metamaterials",
    "authors": [
      "Fuxin Guan",
      "Zemeng Lin",
      "Sixin Chen",
      "Xinhua Wen",
      "Shuang Zhang"
    ],
    "abstract": "Metamaterials exhibit extraordinary properties yet suffer from pronounced\nwave dissipation, particularly in optical imaging and sensing systems. Recent\nadvances leveraging complex frequency wave excitations with virtual gain\neffect, synthesized by multi-monochromatic waves, offer promising solutions for\noptical loss compensation. However, this approach faces limitations in extreme\nloss scenarios. The complex frequency wave requires sufficient virtual gain,\ni.e., temporal attenuation, to offset material loss, inevitably triggering\nrapid signal decay to zero before reaching a quasi-static state. To address\nthis challenge, we introduce synthetic waves of high-order virtual gain to slow\ndown the decay rate while preserving the loss compensation efficiency. We\nexperimentally demonstrate 20-fold noise suppression in plasmonic resonance\nsystems compared to conventional complex frequency excitations. This approach\nexhibits broad applicability across diverse fields, including imaging,\nbiosensing, and integrated photonic signal processing.",
    "pdf_url": "http://arxiv.org/pdf/2505.21976v1",
    "published": "2025-05-28T05:07:34+00:00",
    "categories": [
      "physics.optics"
    ],
    "primary_category": "physics.optics"
  },
  {
    "id": "http://arxiv.org/abs/2505.21975v1",
    "title": "DvD: Unleashing a Generative Paradigm for Document Dewarping via Coordinates-based Diffusion Model",
    "authors": [
      "Weiguang Zhang",
      "Huangcheng Lu",
      "Maizhen Ning",
      "Xiaowei Huang",
      "Wei Wang",
      "Kaizhu Huang",
      "Qiufeng Wang"
    ],
    "abstract": "Document dewarping aims to rectify deformations in photographic document\nimages, thus improving text readability, which has attracted much attention and\nmade great progress, but it is still challenging to preserve document\nstructures. Given recent advances in diffusion models, it is natural for us to\nconsider their potential applicability to document dewarping. However, it is\nfar from straightforward to adopt diffusion models in document dewarping due to\ntheir unfaithful control on highly complex document images (e.g.,\n2000$\\times$3000 resolution). In this paper, we propose DvD, the first\ngenerative model to tackle document \\textbf{D}ewarping \\textbf{v}ia a\n\\textbf{D}iffusion framework. To be specific, DvD introduces a coordinate-level\ndenoising instead of typical pixel-level denoising, generating a mapping for\ndeformation rectification. In addition, we further propose a time-variant\ncondition refinement mechanism to enhance the preservation of document\nstructures. In experiments, we find that current document dewarping benchmarks\ncan not evaluate dewarping models comprehensively. To this end, we present\nAnyPhotoDoc6300, a rigorously designed large-scale document dewarping benchmark\ncomprising 6,300 real image pairs across three distinct domains, enabling\nfine-grained evaluation of dewarping models. Comprehensive experiments\ndemonstrate that our proposed DvD can achieve state-of-the-art performance with\nacceptable computational efficiency on multiple metrics across various\nbenchmarks including DocUNet, DIR300, and AnyPhotoDoc6300. The new benchmark\nand code will be publicly available.",
    "pdf_url": "http://arxiv.org/pdf/2505.21975v1",
    "published": "2025-05-28T05:05:51+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.21974v2",
    "title": "BOFormer: Learning to Solve Multi-Objective Bayesian Optimization via Non-Markovian RL",
    "authors": [
      "Yu-Heng Hung",
      "Kai-Jie Lin",
      "Yu-Heng Lin",
      "Chien-Yi Wang",
      "Cheng Sun",
      "Ping-Chun Hsieh"
    ],
    "abstract": "Bayesian optimization (BO) offers an efficient pipeline for optimizing\nblack-box functions with the help of a Gaussian process prior and an\nacquisition function (AF). Recently, in the context of single-objective BO,\nlearning-based AFs witnessed promising empirical results given its favorable\nnon-myopic nature. Despite this, the direct extension of these approaches to\nmulti-objective Bayesian optimization (MOBO) suffer from the\n\\textit{hypervolume identifiability issue}, which results from the\nnon-Markovian nature of MOBO problems. To tackle this, inspired by the\nnon-Markovian RL literature and the success of Transformers in language\nmodeling, we present a generalized deep Q-learning framework and propose\n\\textit{BOFormer}, which substantiates this framework for MOBO via sequence\nmodeling. Through extensive evaluation, we demonstrate that BOFormer constantly\noutperforms the benchmark rule-based and learning-based algorithms in various\nsynthetic MOBO and real-world multi-objective hyperparameter optimization\nproblems. We have made the source code publicly available to encourage further\nresearch in this direction.",
    "pdf_url": "http://arxiv.org/pdf/2505.21974v2",
    "published": "2025-05-28T05:00:50+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.21973v1",
    "title": "Towards Structure-aware Model for Multi-modal Knowledge Graph Completion",
    "authors": [
      "Linyu Li",
      "Zhi Jin",
      "Yichi Zhang",
      "Dongming Jin",
      "Chengfeng Dou",
      "Yuanpeng He",
      "Xuan Zhang",
      "Haiyan Zhao"
    ],
    "abstract": "Knowledge graphs (KGs) play a key role in promoting various multimedia and AI\napplications. However, with the explosive growth of multi-modal information,\ntraditional knowledge graph completion (KGC) models cannot be directly applied.\nThis has attracted a large number of researchers to study multi-modal knowledge\ngraph completion (MMKGC). Since MMKG extends KG to the visual and textual\ndomains, MMKGC faces two main challenges: (1) how to deal with the fine-grained\nmodality information interaction and awareness; (2) how to ensure the dominant\nrole of graph structure in multi-modal knowledge fusion and deal with the noise\ngenerated by other modalities during modality fusion. To address these\nchallenges, this paper proposes a novel MMKGC model named TSAM, which\nintegrates fine-grained modality interaction and dominant graph structure to\nform a high-performance MMKGC framework. Specifically, to solve the challenges,\nTSAM proposes the Fine-grained Modality Awareness Fusion method (FgMAF), which\nuses pre-trained language models to better capture fine-grained semantic\ninformation interaction of different modalities and employs an attention\nmechanism to achieve fine-grained modality awareness and fusion. Additionally,\nTSAM presents the Structure-aware Contrastive Learning method (SaCL), which\nutilizes two contrastive learning approaches to align other modalities more\nclosely with the structured modality. Extensive experiments show that the\nproposed TSAM model significantly outperforms existing MMKGC models on widely\nused multi-modal datasets.",
    "pdf_url": "http://arxiv.org/pdf/2505.21973v1",
    "published": "2025-05-28T04:50:58+00:00",
    "categories": [
      "cs.MM"
    ],
    "primary_category": "cs.MM"
  },
  {
    "id": "http://arxiv.org/abs/2505.21972v1",
    "title": "Judging LLMs on a Simplex",
    "authors": [
      "Patrick Vossler",
      "Fan Xia",
      "Yifan Mai",
      "Jean Feng"
    ],
    "abstract": "Automated evaluation of free-form outputs from large language models (LLMs)\nis challenging because many distinct answers can be equally valid. A common\npractice is to use LLMs themselves as judges, but the theoretical properties of\nthis approach are not yet well understood. We show that a geometric framework\nthat represents both judges and candidates as points on a probability simplex\ncan provide helpful insight on what is or is not identifiable using LLM judges.\nOur theoretical analysis uncovers a \"phase transition\" in ranking\nidentifiability: for binary scoring systems, true rankings are identifiable\neven with weak judges under mild assumptions, while rankings become\nnon-identifiable for three or more scoring levels even with infinite data,\nabsent additional prior knowledge. This non-identifiability highlights how\nuncertainty in rankings stems from not only aleatoric uncertainty (i.e.,\ninherent stochasticity in the data) but also epistemic uncertainty regarding\nwhich assumptions hold, an aspect that has received limited attention until\nnow. To integrate both types of uncertainty, we use Bayesian inference to\nencode assumptions as priors and conduct sensitivity analysis of ranking\nestimates and credible intervals. Empirical evaluations across multiple\nbenchmarks demonstrate that Bayesian inference yields more accurate rankings\nand substantially improves coverage rates. These results underscore the\nimportance of taking a more holistic approach to uncertainty quantification\nwhen using LLMs as judges.",
    "pdf_url": "http://arxiv.org/pdf/2505.21972v1",
    "published": "2025-05-28T04:50:41+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.21971v1",
    "title": "The Tri-Hybrid MIMO Architecture",
    "authors": [
      "Robert W. Heath, Jr.",
      "Joseph Carlson",
      "Nitish Vikas Deshpande",
      "Miguel Rodrigo Castellanos",
      "Mohamed Akrout",
      "Chan-Byoung Chae"
    ],
    "abstract": "We present an evolution of multiple-input multiple-output (MIMO) wireless\ncommunications known as the tri-hybrid MIMO architecture. In this framework,\nthe traditional operations of linear precoding at the transmitter are\ndistributed across digital beamforming, analog beamforming, and reconfigurable\nantennas. Compared with the hybrid MIMO architecture, which combines digital\nand analog beamforming, the tri-hybrid approach introduces a third layer of\nelectromagnetic beamforming through antenna reconfigurability. This added layer\noffers a pathway to scale MIMO spatial dimensions, important for 6G systems\noperating in centimeter-wave bands, where the tension between larger bandwidths\nand infrastructure reuse necessitates ultra-large antenna arrays. We introduce\nthe key features of the tri-hybrid architecture by (i)~reviewing the benefits\nand challenges of communicating with reconfigurable antennas, (ii)~examining\ntradeoffs between spectral and energy efficiency enabled by reconfigurability,\nand (iii)~exploring configuration challenges across the three layers. Overall,\nthe tri-hybrid MIMO architecture offers a new approach for integrating emerging\nantenna technologies in the MIMO precoding framework.",
    "pdf_url": "http://arxiv.org/pdf/2505.21971v1",
    "published": "2025-05-28T04:50:03+00:00",
    "categories": [
      "cs.IT",
      "cs.NI",
      "math.IT"
    ],
    "primary_category": "cs.IT"
  },
  {
    "id": "http://arxiv.org/abs/2506.10014v1",
    "title": "NOCL: Node-Oriented Conceptualization LLM for Graph Tasks without Message Passing",
    "authors": [
      "Wei Li",
      "Mengcheng Lan",
      "Jiaxing Xu",
      "Yiping Ke"
    ],
    "abstract": "Graphs are essential for modeling complex interactions across domains such as\nsocial networks, biology, and recommendation systems. Traditional Graph Neural\nNetworks, particularly Message Passing Neural Networks (MPNNs), rely heavily on\nsupervised learning, limiting their generalization and applicability in\nlabel-scarce scenarios. Recent self-supervised approaches still require labeled\nfine-tuning, limiting their effectiveness in zero-shot scenarios. Meanwhile,\nLarge Language Models (LLMs) excel in natural language tasks but face\nsignificant challenges when applied to graphs, including preserving reasoning\nabilities, managing extensive token lengths from rich node attributes, and\nbeing limited to textual-attributed graphs (TAGs) and a single level task. To\novercome these limitations, we propose the Node-Oriented Conceptualization LLM\n(NOCL), a novel framework that leverages two core techniques: 1) node\ndescription, which converts heterogeneous node attributes into structured\nnatural language, extending LLM from TAGs to non-TAGs; 2) node concept, which\nencodes node descriptions into compact semantic embeddings using pretrained\nlanguage models, significantly reducing token lengths by up to 93.9% compared\nto directly using node descriptions. Additionally, our NOCL employs graph\nrepresentation descriptors to unify graph tasks at various levels into a\nshared, language-based query format, paving a new direction for Graph\nFoundation Models. Experimental results validate NOCL's competitive supervised\nperformance relative to traditional MPNNs and hybrid LLM-MPNN methods and\ndemonstrate superior generalization in zero-shot settings.",
    "pdf_url": "http://arxiv.org/pdf/2506.10014v1",
    "published": "2025-05-28T04:48:43+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.21970v2",
    "title": "Constraints on the strength of first-order phase transition and its relation to nucleon mass",
    "authors": [
      "Bikai Gao"
    ],
    "abstract": "We investigate the constraints on the strength of first-order phase\ntransitions in neutron star matter and its relation to the origin of nucleon\nmass. By combining the parity doublet model for the hadronic phase, the\nNambu-Jona-Lasinio model for quark matter, and the integral constraint\nframework for intermediate densities, we construct equation of states spanning\nthe full density range relevant to neutron stars. Our approach systematically\nexplores how the chiral invariant mass $m_0$ affects the allowable properties\nof first-order quark-hadron phase transitions. Through comparison with recent\nneutron star observations, we establish a inverse correlation between the\nallowed phase transition strength and the chiral invariant mass. Our results\ndemonstrate a direct connection between fundamental questions about the\nmicroscopic origin of nucleon mass and macroscopic neutron star observables,\nproviding a novel astrophysical probe of chiral dynamics and QCD physics under\nextreme conditions.",
    "pdf_url": "http://arxiv.org/pdf/2505.21970v2",
    "published": "2025-05-28T04:48:19+00:00",
    "categories": [
      "nucl-th"
    ],
    "primary_category": "nucl-th"
  },
  {
    "id": "http://arxiv.org/abs/2505.21969v3",
    "title": "DORAEMON: Decentralized Ontology-aware Reliable Agent with Enhanced Memory Oriented Navigation",
    "authors": [
      "Tianjun Gu",
      "Linfeng Li",
      "Xuhong Wang",
      "Chenghua Gong",
      "Jingyu Gong",
      "Zhizhong Zhang",
      "Yuan Xie",
      "Lizhuang Ma",
      "Xin Tan"
    ],
    "abstract": "Adaptive navigation in unfamiliar environments is crucial for household\nservice robots but remains challenging due to the need for both low-level path\nplanning and high-level scene understanding. While recent vision-language model\n(VLM) based zero-shot approaches reduce dependence on prior maps and\nscene-specific training data, they face significant limitations: spatiotemporal\ndiscontinuity from discrete observations, unstructured memory representations,\nand insufficient task understanding leading to navigation failures. We propose\nDORAEMON (Decentralized Ontology-aware Reliable Agent with Enhanced Memory\nOriented Navigation), a novel cognitive-inspired framework consisting of\nVentral and Dorsal Streams that mimics human navigation capabilities. The\nDorsal Stream implements the Hierarchical Semantic-Spatial Fusion and Topology\nMap to handle spatiotemporal discontinuities, while the Ventral Stream combines\nRAG-VLM and Policy-VLM to improve decision-making. Our approach also develops\nNav-Ensurance to ensure navigation safety and efficiency. We evaluate DORAEMON\non the HM3D, MP3D, and GOAT datasets, where it achieves state-of-the-art\nperformance on both success rate (SR) and success weighted by path length (SPL)\nmetrics, significantly outperforming existing methods. We also introduce a new\nevaluation metric (AORI) to assess navigation intelligence better.\nComprehensive experiments demonstrate DORAEMON's effectiveness in zero-shot\nautonomous navigation without requiring prior map building or pre-training.",
    "pdf_url": "http://arxiv.org/pdf/2505.21969v3",
    "published": "2025-05-28T04:46:13+00:00",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.21968v1",
    "title": "Enhanced SIRRT*: A Structure-Aware RRT* for 2D Path Planning with Hybrid Smoothing and Bidirectional Rewiring",
    "authors": [
      "Hyejeong Ryu"
    ],
    "abstract": "Sampling-based motion planners such as Rapidly-exploring Random Tree* (RRT*)\nand its informed variant IRRT* are widely used for optimal path planning in\ncomplex environments. However, these methods often suffer from slow convergence\nand high variance due to their reliance on random sampling, particularly when\ninitial solution discovery is delayed. This paper presents Enhanced SIRRT*\n(E-SIRRT*), a structure-aware planner that improves upon the original SIRRT*\nframework by introducing two key enhancements: hybrid path smoothing and\nbidirectional rewiring. Hybrid path smoothing refines the initial path through\nspline fitting and collision-aware correction, while bidirectional rewiring\nlocally optimizes tree connectivity around the smoothed path to improve cost\npropagation. Experimental results demonstrate that E-SIRRT* consistently\noutperforms IRRT* and SIRRT* in terms of initial path quality, convergence\nrate, and robustness across 100 trials. Unlike IRRT*, which exhibits high\nvariability due to stochastic initialization, E-SIRRT* achieves repeatable and\nefficient performance through deterministic skeleton-based initialization and\nstructural refinement.",
    "pdf_url": "http://arxiv.org/pdf/2505.21968v1",
    "published": "2025-05-28T04:45:25+00:00",
    "categories": [
      "cs.RO"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.21967v1",
    "title": "Seeing the Threat: Vulnerabilities in Vision-Language Models to Adversarial Attack",
    "authors": [
      "Juan Ren",
      "Mark Dras",
      "Usman Naseem"
    ],
    "abstract": "Large Vision-Language Models (LVLMs) have shown remarkable capabilities\nacross a wide range of multimodal tasks. However, their integration of visual\ninputs introduces expanded attack surfaces, thereby exposing them to novel\nsecurity vulnerabilities. In this work, we conduct a systematic\nrepresentational analysis to uncover why conventional adversarial attacks can\ncircumvent the safety mechanisms embedded in LVLMs. We further propose a novel\ntwo stage evaluation framework for adversarial attacks on LVLMs. The first\nstage differentiates among instruction non compliance, outright refusal, and\nsuccessful adversarial exploitation. The second stage quantifies the degree to\nwhich the model's output fulfills the harmful intent of the adversarial prompt,\nwhile categorizing refusal behavior into direct refusals, soft refusals, and\npartial refusals that remain inadvertently helpful. Finally, we introduce a\nnormative schema that defines idealized model behavior when confronted with\nharmful prompts, offering a principled target for safety alignment in\nmultimodal systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.21967v1",
    "published": "2025-05-28T04:43:39+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.21966v2",
    "title": "MapStory: Prototyping Editable Map Animations with LLM Agents",
    "authors": [
      "Aditya Gunturu",
      "Ben Pearman",
      "Keiichi Ihara",
      "Morteza Faraji",
      "Bryan Wang",
      "Rubaiat Habib Kazi",
      "Ryo Suzuki"
    ],
    "abstract": "We introduce MapStory, an LLM-powered animation prototyping tool that\ngenerates editable map animation sequences directly from natural language text\nby leveraging a dual-agent LLM architecture. Given a user written script,\nMapStory automatically produces a scene breakdown, which decomposes the text\ninto key map animation primitives such as camera movements, visual highlights,\nand animated elements. Our system includes a researcher agent that accurately\nqueries geospatial information by leveraging an LLM with web search, enabling\nautomatic extraction of relevant regions, paths, and coordinates while allowing\nusers to edit and query for changes or additional information to refine the\nresults. Additionally, users can fine-tune parameters of these primitive blocks\nthrough an interactive timeline editor. We detail the system's design and\narchitecture, informed by formative interviews with professional animators and\nby an analysis of 200 existing map animation videos. Our evaluation, which\nincludes expert interviews (N=5) and a usability study (N=12), demonstrates\nthat MapStory enables users to create map animations with ease, facilitates\nfaster iteration, encourages creative exploration, and lowers barriers to\ncreating map-centric stories.",
    "pdf_url": "http://arxiv.org/pdf/2505.21966v2",
    "published": "2025-05-28T04:36:08+00:00",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CL",
      "cs.MM",
      "H.5.2, H.5.1"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2505.21965v1",
    "title": "Target Localization with Coprime Multistatic MIMO Radar via Coupled Canonical Polyadic Decomposition Based on Joint Eigenvalue Decomposition",
    "authors": [
      "Guo-Zhao Liao",
      "Xiao-Feng Gong",
      "Wei Liu",
      "Hing Cheung So"
    ],
    "abstract": "This paper investigates target localization using a multistatic\nmultiple-input multiple-output (MIMO) radar system with two distinct coprime\narray configurations: coprime L-shaped arrays and coprime planar arrays. The\nobserved signals are modeled as tensors that admit a coupled canonical polyadic\ndecomposition (C-CPD) model. For each configuration, a C-CPD method is\npresented based on joint eigenvalue decomposition (J-EVD). This computational\nframework includes (semi-)algebraic and optimization-based C-CPD algorithms and\ntarget localization that fuses direction-of-arrivals (DOAs) information to\ncalculate the optimal position of each target. Specifically, the proposed\n(semi-)algebraic methods exploit the rotational invariance of the Vandermonde\nstructure in coprime arrays, similar to the multiple invariance property of\n\\added{estimation of signal parameters via rotational invariance techniques}\n(ESPRIT), which transforms the model into a J-EVD problem and reduces\ncomputational complexity. The study also investigates the working conditions of\nthe algorithm to understand model identifiability. Additionally, the proposed\nmethod does not rely on prior knowledge of non-orthogonal probing waveforms and\nis effective in challenging underdetermined scenarios. Experimental results\ndemonstrate that our method outperforms existing tensor-based approaches in\nboth accuracy and computational efficiency.",
    "pdf_url": "http://arxiv.org/pdf/2505.21965v1",
    "published": "2025-05-28T04:34:13+00:00",
    "categories": [
      "eess.SP"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2505.21964v1",
    "title": "UI-Evol: Automatic Knowledge Evolving for Computer Use Agents",
    "authors": [
      "Ziyun Zhang",
      "Xinyi Liu",
      "Xiaoyi Zhang",
      "Jun Wang",
      "Gang Chen",
      "Yan Lu"
    ],
    "abstract": "External knowledge has played a crucial role in the recent development of\ncomputer use agents. We identify a critical knowledge-execution gap: retrieved\nknowledge often fails to translate into effective real-world task execution.\nOur analysis shows even 90\\% correct knowledge yields only 41\\% execution\nsuccess rate. To bridge this gap, we propose UI-Evol, a plug-and-play module\nfor autonomous GUI knowledge evolution. UI-Evol consists of two stages: a\nRetrace Stage that extracts faithful objective action sequences from actual\nagent-environment interactions, and a Critique Stage that refines existing\nknowledge by comparing these sequences against external references. We conduct\ncomprehensive experiments on the OSWorld benchmark with the state-of-the-art\nAgent S2. Our results demonstrate that UI-Evol not only significantly boosts\ntask performance but also addresses a previously overlooked issue of high\nbehavioral standard deviation in computer use agents, leading to superior\nperformance on computer use tasks and substantially improved agent reliability.",
    "pdf_url": "http://arxiv.org/pdf/2505.21964v1",
    "published": "2025-05-28T04:32:05+00:00",
    "categories": [
      "cs.HC",
      "cs.CL"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2505.21963v1",
    "title": "LaMDAgent: An Autonomous Framework for Post-Training Pipeline Optimization via LLM Agents",
    "authors": [
      "Taro Yano",
      "Yoichi Ishibashi",
      "Masafumi Oyamada"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated exceptional performance across\na wide range of tasks. To further tailor LLMs to specific domains or\napplications, post-training techniques such as Supervised Fine-Tuning (SFT),\nPreference Learning, and model merging are commonly employed. While each of\nthese methods has been extensively studied in isolation, the automated\nconstruction of complete post-training pipelines remains an underexplored area.\nExisting approaches typically rely on manual design or focus narrowly on\noptimizing individual components, such as data ordering or merging strategies.\nIn this work, we introduce LaMDAgent (short for Language Model Developing\nAgent), a novel framework that autonomously constructs and optimizes full\npost-training pipelines through the use of LLM-based agents. LaMDAgent\nsystematically explores diverse model generation techniques, datasets, and\nhyperparameter configurations, leveraging task-based feedback to discover\nhigh-performing pipelines with minimal human intervention. Our experiments show\nthat LaMDAgent improves tool-use accuracy by 9.0 points while preserving\ninstruction-following capabilities. Moreover, it uncovers effective\npost-training strategies that are often overlooked by conventional human-driven\nexploration. We further analyze the impact of data and model size scaling to\nreduce computational costs on the exploration, finding that model size scalings\nintroduces new challenges, whereas scaling data size enables cost-effective\npipeline discovery.",
    "pdf_url": "http://arxiv.org/pdf/2505.21963v1",
    "published": "2025-05-28T04:30:51+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.21962v1",
    "title": "A2Seek: Towards Reasoning-Centric Benchmark for Aerial Anomaly Understanding",
    "authors": [
      "Mengjingcheng Mo",
      "Xinyang Tong",
      "Jiaxu Leng",
      "Mingpi Tan",
      "Jiankang Zheng",
      "Yiran Liu",
      "Haosheng Chen",
      "Ji Gan",
      "Weisheng Li",
      "Xinbo Gao"
    ],
    "abstract": "While unmanned aerial vehicles (UAVs) offer wide-area, high-altitude coverage\nfor anomaly detection, they face challenges such as dynamic viewpoints, scale\nvariations, and complex scenes. Existing datasets and methods, mainly designed\nfor fixed ground-level views, struggle to adapt to these conditions, leading to\nsignificant performance drops in drone-view scenarios. To bridge this gap, we\nintroduce A2Seek (Aerial Anomaly Seek), a large-scale, reasoning-centric\nbenchmark dataset for aerial anomaly understanding. This dataset covers various\nscenarios and environmental conditions, providing high-resolution real-world\naerial videos with detailed annotations, including anomaly categories,\nframe-level timestamps, region-level bounding boxes, and natural language\nexplanations for causal reasoning. Building on this dataset, we propose\nA2Seek-R1, a novel reasoning framework that generalizes R1-style strategies to\naerial anomaly understanding, enabling a deeper understanding of \"Where\"\nanomalies occur and \"Why\" they happen in aerial frames. To this end, A2Seek-R1\nfirst employs a graph-of-thought (GoT)-guided supervised fine-tuning approach\nto activate the model's latent reasoning capabilities on A2Seek. Then, we\nintroduce Aerial Group Relative Policy Optimization (A-GRPO) to design\nrule-based reward functions tailored to aerial scenarios. Furthermore, we\npropose a novel \"seeking\" mechanism that simulates UAV flight behavior by\ndirecting the model's attention to informative regions. Extensive experiments\ndemonstrate that A2Seek-R1 achieves up to a 22.04% improvement in AP for\nprediction accuracy and a 13.9% gain in mIoU for anomaly localization,\nexhibiting strong generalization across complex environments and\nout-of-distribution scenarios. Our dataset and code will be released at\nhttps://hayneyday.github.io/A2Seek/.",
    "pdf_url": "http://arxiv.org/pdf/2505.21962v1",
    "published": "2025-05-28T04:28:13+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.21961v1",
    "title": "Tripartite Entanglement dynamics: the influence of intrinsic decoherence and decoherence channels",
    "authors": [
      "S. V. Mousavi"
    ],
    "abstract": "This study examines a system of three coupled qubits, focusing on\nentanglement measures in the presence of decoherence. It utilizes an XXZ\nHeisenberg chain with an external magnetic field and Dzyaloshinskii-Moriya\ninteraction, considering intrinsic decoherence. The results reveal that only\nthe magnetic field strength affects entanglement, while intrinsic decoherence\nsuppresses it, with stronger decoherence leading to greater suppression.\nVarious decoherence channels are analyzed, showing that the $I$-tangle\ntypically decreases with increased decoherence, except for the generalized W\nstate under phase damping channel, where only one qubit is affected.\nInterestingly, dark periods of $I$-tangle occur for the GHZ state under\nnon-Markovian dephasing, and while steady-state entanglement disappears in this\nchannel, it remains nonzero when starting from a mixture of GHZ and fully\nseparable states. Additionally, under generalized amplitude damping channel,\nreduced bipartite states of a W state exhibit entanglement sudden death, while\nthe steady-state $I$-tangle for the spectral decomposed state stays nonzero.",
    "pdf_url": "http://arxiv.org/pdf/2505.21961v1",
    "published": "2025-05-28T04:23:31+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.21960v1",
    "title": "One-Way Ticket:Time-Independent Unified Encoder for Distilling Text-to-Image Diffusion Models",
    "authors": [
      "Senmao Li",
      "Lei Wang",
      "Kai Wang",
      "Tao Liu",
      "Jiehang Xie",
      "Joost van de Weijer",
      "Fahad Shahbaz Khan",
      "Shiqi Yang",
      "Yaxing Wang",
      "Jian Yang"
    ],
    "abstract": "Text-to-Image (T2I) diffusion models have made remarkable advancements in\ngenerative modeling; however, they face a trade-off between inference speed and\nimage quality, posing challenges for efficient deployment. Existing distilled\nT2I models can generate high-fidelity images with fewer sampling steps, but\noften struggle with diversity and quality, especially in one-step models. From\nour analysis, we observe redundant computations in the UNet encoders. Our\nfindings suggest that, for T2I diffusion models, decoders are more adept at\ncapturing richer and more explicit semantic information, while encoders can be\neffectively shared across decoders from diverse time steps. Based on these\nobservations, we introduce the first Time-independent Unified Encoder TiUE for\nthe student model UNet architecture, which is a loop-free image generation\napproach for distilling T2I diffusion models. Using a one-pass scheme, TiUE\nshares encoder features across multiple decoder time steps, enabling parallel\nsampling and significantly reducing inference time complexity. In addition, we\nincorporate a KL divergence term to regularize noise prediction, which enhances\nthe perceptual realism and diversity of the generated images. Experimental\nresults demonstrate that TiUE outperforms state-of-the-art methods, including\nLCM, SD-Turbo, and SwiftBrushv2, producing more diverse and realistic results\nwhile maintaining the computational efficiency.",
    "pdf_url": "http://arxiv.org/pdf/2505.21960v1",
    "published": "2025-05-28T04:23:22+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.21959v2",
    "title": "EnsemW2S: Enhancing Weak-to-Strong Generalization with Large Language Model Ensembles",
    "authors": [
      "Aakriti Agrawal",
      "Mucong Ding",
      "Zora Che",
      "Chenghao Deng",
      "Anirudh Satheesh",
      "Bang An",
      "Bayan Bruss",
      "John Langford",
      "Furong Huang"
    ],
    "abstract": "With Large Language Models (LLMs) rapidly approaching and potentially\nsurpassing human-level performance, it has become imperative to develop\napproaches capable of effectively supervising and enhancing these powerful\nmodels using smaller, human-level models exposed to only human-level data. We\naddress this critical weak-to-strong (W2S) generalization challenge by\nproposing a novel method aimed at improving weak experts, by training on the\nsame limited human-level data, enabling them to generalize to complex,\nsuper-human-level tasks. Our approach, called \\textbf{EnsemW2S}, employs a\ntoken-level ensemble strategy that iteratively combines multiple weak experts,\nsystematically addressing the shortcomings identified in preceding iterations.\nBy continuously refining these weak models, we significantly enhance their\ncollective ability to supervise stronger student models. We extensively\nevaluate the generalization performance of both the ensemble of weak experts\nand the subsequent strong student model across in-distribution (ID) and\nout-of-distribution (OOD) datasets. For OOD, we specifically introduce question\ndifficulty as an additional dimension for defining distributional shifts. Our\nempirical results demonstrate notable improvements, achieving 4\\%, and 3.2\\%\nimprovements on ID datasets and, upto 6\\% and 2.28\\% on OOD datasets for\nexperts and student models respectively, underscoring the effectiveness of our\nproposed method in advancing W2S generalization.",
    "pdf_url": "http://arxiv.org/pdf/2505.21959v2",
    "published": "2025-05-28T04:23:12+00:00",
    "categories": [
      "cs.LG",
      "cs.CL"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.21958v1",
    "title": "Resolving Knowledge Conflicts in Domain-specific Data Selection: A Case Study on Medical Instruction-tuning",
    "authors": [
      "Qihuang Zhong",
      "Liang Ding",
      "Fei Liao",
      "Juhua Liu",
      "Bo Du",
      "Dacheng Tao"
    ],
    "abstract": "Domain-specific instruction-tuning has become the defacto standard for\nimproving the performance of large language models (LLMs) in specialized\napplications, e.g., medical question answering. Since the instruction-tuning\ndataset might contain redundant or low-quality data, data selection (DS) is\nusually required to maximize the data efficiency. Despite the successes in the\ngeneral domain, current DS methods often struggle to select the desired data\nfor domain-specific instruction-tuning. One of the main reasons is that they\nneglect the impact of knowledge conflicts, i.e., the discrepancy between LLMs'\npretrained knowledge and context knowledge of instruction data, which could\ndamage LLMs' prior abilities and lead to hallucination. To this end, we propose\na simple-yet-effective Knowledge-aware Data Selection (namely KDS) framework to\nselect the domain-specific instruction-tuning data that meets LLMs' actual\nneeds. The core of KDS is to leverage two knowledge-aware metrics for\nquantitatively measuring knowledge conflicts from two aspects: context-memory\nknowledge alignment and intra-memory knowledge consistency. By filtering the\ndata with large knowledge conflicts and sampling the high-quality and diverse\ndata, KDS can effectively stimulate the LLMs' abilities and achieve better\ndomain-specific performance. Taking the medical domain as the testbed, we\nconduct extensive experiments and empirically prove that KDS surpasses the\nother baselines and brings significant and consistent performance gains among\nall LLMs. More encouragingly, KDS effectively improves the model generalization\nand alleviates the hallucination problem.",
    "pdf_url": "http://arxiv.org/pdf/2505.21958v1",
    "published": "2025-05-28T04:18:24+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.21957v1",
    "title": "Revisiting the Li abundances of Stars with and without Detected Planets from the High Resolution Spectroscopy",
    "authors": [
      "Jinxiao Qin",
      "Hong-Liang Yan",
      "Wenyuan Cui",
      "Jian-Rong Shi",
      "Subo Dong",
      "Shuai Liu",
      "Zeming Zhou",
      "Miao Tian",
      "Zhenyan Huo",
      "Xiangsong Fang",
      "Jinghua Zhang",
      "Chunqian Li",
      "Mingyi Ding",
      "Song Wang",
      "Henggeng Han"
    ],
    "abstract": "Whether the presence of planets affects the lithium (Li) abundance of their\nhost stars is still an open question. To investigate the difference of the Li\nabundance between planet-host stars (HS) and isolated stars (IS) with no\ndetected planets, we analyze a large sample of stars with temperatures ranging\nfrom 4600 to 6600 K and metallicity ranging from -0.55 to +0.50. The sample\nconsists of 279 HS whose spectra were taken from the California-Kepler Survey\n(CKS), which followed up planets detected by Kepler, and 171 IS whose spectra\nwere taken from the Keck archive. The non-local thermodynamic equilibrium\n(non-LTE) effects were taken into consideration. It is found that the\ndistribution of Li abundances in both the HS and IS groups are generally\nconsistent with each other. This suggests that the presence of Kepler-like\nplanets does not have a significant impact on Li depletion. We also found that\nthe non-LTE corrections can not be neglected for stars with A(Li) over ~ 2.5\ndex.",
    "pdf_url": "http://arxiv.org/pdf/2505.21957v1",
    "published": "2025-05-28T04:13:51+00:00",
    "categories": [
      "astro-ph.SR",
      "astro-ph.EP"
    ],
    "primary_category": "astro-ph.SR"
  },
  {
    "id": "http://arxiv.org/abs/2505.21956v2",
    "title": "Cross-modal RAG: Sub-dimensional Retrieval-Augmented Text-to-Image Generation",
    "authors": [
      "Mengdan Zhu",
      "Senhao Cheng",
      "Guangji Bai",
      "Yifei Zhang",
      "Liang Zhao"
    ],
    "abstract": "Text-to-image generation increasingly demands access to domain-specific,\nfine-grained, and rapidly evolving knowledge that pretrained models cannot\nfully capture. Existing Retrieval-Augmented Generation (RAG) methods attempt to\naddress this by retrieving globally relevant images, but they fail when no\nsingle image contains all desired elements from a complex user query. We\npropose Cross-modal RAG, a novel framework that decomposes both queries and\nimages into sub-dimensional components, enabling subquery-aware retrieval and\ngeneration. Our method introduces a hybrid retrieval strategy - combining a\nsub-dimensional sparse retriever with a dense retriever - to identify a\nPareto-optimal set of images, each contributing complementary aspects of the\nquery. During generation, a multimodal large language model is guided to\nselectively condition on relevant visual features aligned to specific\nsubqueries, ensuring subquery-aware image synthesis. Extensive experiments on\nMS-COCO, Flickr30K, WikiArt, CUB, and ImageNet-LT demonstrate that Cross-modal\nRAG significantly outperforms existing baselines in both retrieval and\ngeneration quality, while maintaining high efficiency.",
    "pdf_url": "http://arxiv.org/pdf/2505.21956v2",
    "published": "2025-05-28T04:09:49+00:00",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.21955v1",
    "title": "Towards Comprehensive Scene Understanding: Integrating First and Third-Person Views for LVLMs",
    "authors": [
      "Insu Lee",
      "Wooje Park",
      "Jaeyun Jang",
      "Minyoung Noh",
      "Kyuhong Shim",
      "Byonghyo Shim"
    ],
    "abstract": "Large vision-language models (LVLMs) are increasingly deployed in interactive\napplications such as virtual and augmented reality, where first-person\n(egocentric) view captured by head-mounted cameras serves as key input. While\nthis view offers fine-grained cues about user attention and hand-object\ninteractions, their narrow field of view and lack of global context often lead\nto failures on spatially or contextually demanding queries. To address this, we\nintroduce a framework that augments egocentric inputs with third-person\n(exocentric) views, providing complementary information such as global scene\nlayout and object visibility to LVLMs. We present E3VQA, the first benchmark\nfor multi-view question answering with 4K high-quality question-answer pairs\ngrounded in synchronized ego-exo image pairs. Additionally, we propose M3CoT, a\ntraining-free prompting technique that constructs a unified scene\nrepresentation by integrating scene graphs from three complementary\nperspectives. M3CoT enables LVLMs to reason more effectively across views,\nyielding consistent performance gains (4.84% for GPT-4o and 5.94% for Gemini\n2.0 Flash) over a recent CoT baseline. Our extensive evaluation reveals key\nstrengths and limitations of LVLMs in multi-view reasoning and highlights the\nvalue of leveraging both egocentric and exocentric inputs.",
    "pdf_url": "http://arxiv.org/pdf/2505.21955v1",
    "published": "2025-05-28T04:09:42+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.21954v1",
    "title": "UniTalk: Towards Universal Active Speaker Detection in Real World Scenarios",
    "authors": [
      "Le Thien Phuc Nguyen",
      "Zhuoran Yu",
      "Khoa Quang Nhat Cao",
      "Yuwei Guo",
      "Tu Ho Manh Pham",
      "Tuan Tai Nguyen",
      "Toan Ngo Duc Vo",
      "Lucas Poon",
      "Soochahn Lee",
      "Yong Jae Lee"
    ],
    "abstract": "We present UniTalk, a novel dataset specifically designed for the task of\nactive speaker detection, emphasizing challenging scenarios to enhance model\ngeneralization. Unlike previously established benchmarks such as AVA, which\npredominantly features old movies and thus exhibits significant domain gaps,\nUniTalk focuses explicitly on diverse and difficult real-world conditions.\nThese include underrepresented languages, noisy backgrounds, and crowded scenes\n- such as multiple visible speakers speaking concurrently or in overlapping\nturns. It contains over 44.5 hours of video with frame-level active speaker\nannotations across 48,693 speaking identities, and spans a broad range of video\ntypes that reflect real-world conditions. Through rigorous evaluation, we show\nthat state-of-the-art models, while achieving nearly perfect scores on AVA,\nfail to reach saturation on UniTalk, suggesting that the ASD task remains far\nfrom solved under realistic conditions. Nevertheless, models trained on UniTalk\ndemonstrate stronger generalization to modern \"in-the-wild\" datasets like\nTalkies and ASW, as well as to AVA. UniTalk thus establishes a new benchmark\nfor active speaker detection, providing researchers with a valuable resource\nfor developing and evaluating versatile and resilient models.\n  Dataset: https://huggingface.co/datasets/plnguyen2908/UniTalk-ASD\n  Code: https://github.com/plnguyen2908/UniTalk-ASD-code",
    "pdf_url": "http://arxiv.org/pdf/2505.21954v1",
    "published": "2025-05-28T04:08:59+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.21953v1",
    "title": "Exploring the Accretion disc/Corona Connection in NGC 6814: Insights from UV and X-ray spectral-timing studies",
    "authors": [
      "Kavita Kumari",
      "I. E. Papadakis",
      "G. C. Dewangan"
    ],
    "abstract": "We conducted a comprehensive spectral and timing analysis of NGC 6814 using\nAstroSat's 2019 and XMM-Newton's 2021 observations. Cross-correlation analysis\nrevealed a significant correlation between FUV (1541 \\AA)/X-ray and UVW1 (2910\n\\AA)/X-ray variations, with delays of $\\sim 15~\\rm{ks}$ and $30~\\rm{ks}$,\nrespectively. We constructed four broadband SEDs after applying aperture\ncorrection (for the UVIT filter), subtracting host galaxy and emission line\ncontributions from UV flux, and using mean X-ray spectra alongside selected UV\ndata points. First, we fitted the SEDs with KYNSED model assuming various\ncombinations of inclination, $\\theta$, color correction factors, $f_{\\rm col}$,\nand BH spins. Best-fit models were achieved for $\\theta=70^{\\circ}$ (consistent\nwith past estimates for this source) and for spin $\\leq 0.5$, while $f_{\\rm\ncol}$ is not constrained. KYNSED provided satisfactory fit to all SEDs in the\ncase when the corona is powered by the accretion process, with $\\sim 10-20$% of\nthe accretion power transferred to the corona, $\\dot{m}/\\dot{m}_{\\rm Edd}\\sim\n0.1$, corona radius of $\\sim 6-10~r_g$, and height of $\\sim7.5-35~r_g$. Model\ntime-lags computed using the SED best-fit results are aligned well with the\nobserved time-lags. Although some of the model parameters are not constrained,\nthe important result of our work is that both the broadband X-ray/UV spectra\nand the X-ray/UV time-lags in NGC 6814 are consistent with the hypothesis of\nX-ray illumination of the disc in a lamp-post geometry framework. Within this\nmodel framework, we do not need to assume an outer or inner truncated disc.",
    "pdf_url": "http://arxiv.org/pdf/2505.21953v1",
    "published": "2025-05-28T04:07:49+00:00",
    "categories": [
      "astro-ph.HE",
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.HE"
  },
  {
    "id": "http://arxiv.org/abs/2505.23822v3",
    "title": "Speech as a Multimodal Digital Phenotype for Multi-Task LLM-based Mental Health Prediction",
    "authors": [
      "Mai Ali",
      "Christopher Lucasius",
      "Tanmay P. Patel",
      "Madison Aitken",
      "Jacob Vorstman",
      "Peter Szatmari",
      "Marco Battaglia",
      "Deepa Kundur"
    ],
    "abstract": "Speech is a noninvasive digital phenotype that can offer valuable insights\ninto mental health conditions, but it is often treated as a single modality. In\ncontrast, we propose the treatment of patient speech data as a trimodal\nmultimedia data source for depression detection. This study explores the\npotential of large language model-based architectures for speech-based\ndepression prediction in a multimodal regime that integrates speech-derived\ntext, acoustic landmarks, and vocal biomarkers. Adolescent depression presents\na significant challenge and is often comorbid with multiple disorders, such as\nsuicidal ideation and sleep disturbances. This presents an additional\nopportunity to integrate multi-task learning (MTL) into our study by\nsimultaneously predicting depression, suicidal ideation, and sleep disturbances\nusing the multimodal formulation. We also propose a longitudinal analysis\nstrategy that models temporal changes across multiple clinical interactions,\nallowing for a comprehensive understanding of the conditions' progression. Our\nproposed approach, featuring trimodal, longitudinal MTL is evaluated on the\nDepression Early Warning dataset. It achieves a balanced accuracy of 70.8%,\nwhich is higher than each of the unimodal, single-task, and non-longitudinal\nmethods.",
    "pdf_url": "http://arxiv.org/pdf/2505.23822v3",
    "published": "2025-05-28T04:07:17+00:00",
    "categories": [
      "cs.CL",
      "cs.MM"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.21952v1",
    "title": "Properties of zero-determinant strategies in multichannel games",
    "authors": [
      "Masahiko Ueda"
    ],
    "abstract": "Controlling payoffs in repeated games is one of the important topics in\ncontrol theory of multi-agent systems. Recently proposed zero-determinant\nstrategies enable players to unilaterally enforce linear relations between\npayoffs. Furthermore, based on the mathematics of zero-determinant strategies,\nregional payoff control, in which payoffs are enforced into some feasible\nregions, has been discovered in social dilemma situations. More recently,\ntheory of payoff control was extended to multichannel games, where players\nparallelly interact with each other in multiple channels. However, properties\nof zero-determinant strategies specific to multichannel games are still not\nclear. In this paper, we elucidate properties of zero-determinant strategies in\nmultichannel games. First, we relate the existence condition of\nzero-determinant strategies in multichannel games to that of zero-determinant\nstrategies in each channel. We then show that the existence of zero-determinant\nstrategies in multichannel games requires the existence of zero-determinant\nstrategies in some channels. This result implies that the existence of\nzero-determinant strategies in multichannel games is tightly restricted by\nstructure of games played in each channel.",
    "pdf_url": "http://arxiv.org/pdf/2505.21952v1",
    "published": "2025-05-28T04:06:04+00:00",
    "categories": [
      "physics.soc-ph",
      "cs.GT",
      "cs.MA",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "physics.soc-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.21951v1",
    "title": "When Feedback Empowers the Uplink: Integrating Adaptive Coding with Wireless Power Transfer",
    "authors": [
      "Zijian Yang",
      "Yulin Shao",
      "Shaodan Ma"
    ],
    "abstract": "Energy consumption and device lifetime are critical concerns for\nbattery-constrained IoT devices. This paper introduces the Feedback-Aided\nCoding and Energy Transfer (FACET) framework, which synergistically combines\nadaptive feedback channel coding with wireless power transfer. FACET leverages\nthe saturation effect of feedback coding, where increasing downlink power\nyields diminishing returns, to design a dual-purpose feedback mechanism that\nsimultaneously guides uplink coding and replenishes device energy. We\ncharacterize the inherent tradeoff between feedback precision and harvested\npower, and formulate a fairness-constrained min-max optimization problem to\nminimize worst-case net energy consumption. An efficient algorithm based on\nalternating optimization and Lagrangian duality is developed, with each\nsubproblem admitting a closed-form solution. Simulations show that FACET nearly\ntriples device lifetime compared to conventional feedback coding architectures,\nand remains robust across a wide range of power regimes. These results suggest\nthat FACET not only improves communication efficiency but also redefines the\nrole of feedback in energy-constrained IoT systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.21951v1",
    "published": "2025-05-28T04:04:24+00:00",
    "categories": [
      "cs.IT",
      "eess.SP",
      "math.IT"
    ],
    "primary_category": "cs.IT"
  },
  {
    "id": "http://arxiv.org/abs/2506.03167v1",
    "title": "Distributionally Robust Wireless Semantic Communication with Large AI Models",
    "authors": [
      "Long Tan Le",
      "Senura Hansaja Wanasekara",
      "Zerun Niu",
      "Yansong Shi",
      "Nguyen H. Tran",
      "Phuong Vo",
      "Walid Saad",
      "Dusit Niyato",
      "Zhu Han",
      "Choong Seon Hong",
      "H. Vincent Poor"
    ],
    "abstract": "6G wireless systems are expected to support massive volumes of data with\nultra-low latency. However, conventional bit-level transmission strategies\ncannot support the efficiency and adaptability required by modern,\ndata-intensive applications. The concept of semantic communication (SemCom)\naddresses this limitation by focusing on transmitting task-relevant semantic\ninformation instead of raw data. While recent efforts incorporating deep\nlearning and large-scale AI models have improved SemCom's performance, existing\nsystems remain vulnerable to both semantic-level and transmission-level noise\nbecause they often rely on domain-specific architectures that hinder\ngeneralizability. In this paper, a novel and generalized semantic communication\nframework called WaSeCom is proposed to systematically address uncertainty and\nenhance robustness. In particular, Wasserstein distributionally robust\noptimization is employed to provide resilience against semantic\nmisinterpretation and channel perturbations. A rigorous theoretical analysis is\nperformed to establish the robust generalization guarantees of the proposed\nframework. Experimental results on image and text transmission demonstrate that\nWaSeCom achieves improved robustness under noise and adversarial perturbations.\nThese results highlight its effectiveness in preserving semantic fidelity\nacross varying wireless conditions.",
    "pdf_url": "http://arxiv.org/pdf/2506.03167v1",
    "published": "2025-05-28T04:03:57+00:00",
    "categories": [
      "cs.NI",
      "cs.ET",
      "cs.IT",
      "cs.LG",
      "math.IT"
    ],
    "primary_category": "cs.NI"
  },
  {
    "id": "http://arxiv.org/abs/2505.21950v1",
    "title": "Winning Probabilities of Balanced and Nontransitive n-tuples of Dice",
    "authors": [
      "Joshua Rooney"
    ],
    "abstract": "For a positive integer $n$, an $n$-tuple of dice $(A_1,A_2,\\dots,A_n)$ is\ncalled balanced if $P(A_1<A_2) = P(A_2<A_3) = \\cdots = P(A_n<A_1)$ and\nnontransitive if $P(A_1<A_2), P(A_2<A_3), \\dots, P(A_n<A_1)$ are each greater\nthan $\\frac{1}{2}$. For a balanced and nontransitive $n$-tuple of dice\n$(A_1,A_2,\\dots,A_n)$, we define the winning probability $w(A_1,A_2,\\dots,A_n)\n:= P(A_1 < A_2)$. The works of Trybula and Kim et al. together show that for a\nbalanced and nontransitve triple of dice $(A_1,A_2,A_3)$, the least upper bound\non the winning probability is $\\frac{-1+\\sqrt{5}}{2}$. Kim et al. then asked\nwhat the least upper bound on the winning probability was for the $n \\geq 4$\ncases. Bogdanov and Komisarski independently have shown that for $n\\geq 3$ and\na balanced and nontransitive $n$-tuple of dice $(A_1,A_2,\\dots,A_n)$, the\nwinning probability is less than $\\pi_n := 1-\\frac{1}{4\\cos^2\\left(\n\\frac{\\pi}{n+2} \\right)}$.\n  In this paper, we will show that for $n \\geq 3$ and every rational $p \\in\n\\left( \\frac{1}{2}, \\pi_n \\right]$, there exists a balanced and nontransitive\n$n$-tuple of dice with winning probability $p$. Paired with Bogdanov and\nKomisarski's results, this fully answers the problem posed by Kim et al. and\nestablishes a complete characterization of the winning probabilities for\nnontransitive and balanced $n$-tuples of dice.",
    "pdf_url": "http://arxiv.org/pdf/2505.21950v1",
    "published": "2025-05-28T04:03:03+00:00",
    "categories": [
      "math.CO"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2505.21949v2",
    "title": "Chemotaxis of branched cells in complex environments",
    "authors": [
      "Jiayi Liu",
      "Jonathan E. Ron",
      "Giulia Rinaldi",
      "Ivanna Williantarra",
      "Antonios Georgantzoglou",
      "Ingrid de Vries",
      "Michael Sixt",
      "Milka Sarris",
      "Nir S. Gov"
    ],
    "abstract": "Cell migration in vivo is often guided by chemical signals. Such chemotaxis,\nsuch as performed by immune cells migrating to a wound site, is complicated by\nthe complex geometry inside living tissues. In this study, we extend our\ntheoretical model of branched-cell migration on a network by introducing\nchemokine sources to explore the cellular response. The model predicts a\nspeed-accuracy tradeoff, whereby slow cells are significantly more accurate and\nable to follow efficiently a weak chemoattractant signal. We then compare the\nmodel's predictions with experimental observations of neutrophils migrating to\nthe site of laser-inflicted wound in a zebrafish larva fin, and migrating\nin-vitro inside a regular lattice of pillars. We find that the model captures\nthe details of the sub-cellular response to the chemokine gradient, as well as\nthe large-scale migration response. This comparison suggests that the\nneutrophils behave as fast cells, compromising their chemotaxis accuracy, which\nexplains the functionality of these immune cells.",
    "pdf_url": "http://arxiv.org/pdf/2505.21949v2",
    "published": "2025-05-28T04:00:43+00:00",
    "categories": [
      "physics.bio-ph",
      "q-bio.CB"
    ],
    "primary_category": "physics.bio-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.21948v1",
    "title": "Deep Extragalactic VIsible Legacy Survey (DEVILS): The sSFR-M$_{\\star}$ plane part II: Starbursts, SFHs and AGN Feedback",
    "authors": [
      "L. J. M. Davies",
      "J. E. Thorne",
      "S. Bellstedt",
      "R. H. W. Cook",
      "M. Bravo",
      "A. S. G. Robotham",
      "C. del P. Lagos",
      "S. Phillipps",
      "M. Siudek",
      "B. W. Holwerda",
      "M. N. Bremer",
      "J. D'Silva",
      "S. P. Driver"
    ],
    "abstract": "In part I of this series we discussed the variation of star-formation\nhistories (SFHs) across the specific star formation rate - stellar mass plane\n(sSFR-M$_{\\star}$) using the Deep Extragalactic VIsible Legacy Survey (DEVILS).\nHere we explore the physical mechanisms that are likely driving these\nobservational trends, by comparing the properties of galaxies with common\nrecent SFH shapes. Overall, we find that the processes shaping the movement of\ngalaxies through the sSFR-M$_{\\star}$ plane can be be largely split into two\nstellar mass regimes, bounded by the minimum SFR dispersion ($\\sigma_{SFR}$)\npoint. At lower stellar masses we find that large $\\sigma_{SFR}$ values are\nlikely observed due to a combination of stochastic star-formation processes and\na large variety in absolute sSFR values, but relatively constant/flat SFHs.\nWhile at higher stellar masses we see strong observational evidence that Active\nGalactic Nuclei (AGN) are associated with rapidly declining SFHs, and that\nthese galaxies reside in the high $\\sigma_{SFR}$ region of the plane. As such,\nwe suggest that AGN feedback, leading to galaxy quenching, is the primary\ndriver of the high $\\sigma_{SFR}$ values. These results are consistent with\nprevious theoretical interpretations of the $\\sigma_{SFR}$-M$_{\\star}$\nrelation.",
    "pdf_url": "http://arxiv.org/pdf/2505.21948v1",
    "published": "2025-05-28T03:57:04+00:00",
    "categories": [
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2505.21947v1",
    "title": "Deep Extragalactic VIsible Legacy Survey (DEVILS): The sSFR-M$_{\\star}$plane part I: The recent SFH of galaxies and movement through the plane",
    "authors": [
      "L. J. M. Davies",
      "J. E. Thorne",
      "S. Bellstedt",
      "R. H. W. Cook",
      "M. Bravo",
      "A. S. G. Robotham",
      "C. del P. Lagos",
      "S. Phillipps",
      "M. Siudek",
      "B. W. Holwerda",
      "M. N. Bremer",
      "J. D'Silva",
      "S. P. Driver"
    ],
    "abstract": "In a recent paper we parameterised the evolution of the star-formation rate\ndispersion ($\\sigma_{SFR}$) across the specific star-formation rate - stellar\nmass plane (sSFR-M$_{\\star}$) using the Deep Extragalactic VIsible Legacy\nSurvey (DEVILS) - suggesting that the point at which the minimum in the\ndispersion occurs (M$^{*}_{\\sigma-min}$) defines a boundary between different\nphysical mechanisms affecting galaxy evolution. Here we expand upon that work\nto determine the movement of galaxies through the sSFR-M$_{\\star}$ plane using\ntheir recent star-formation histories (SFHs) and explore how this leads to the\nobserved $\\sigma_{SFR}$-M$_{\\star}$ relation. We find that galaxies in\nsub-regions of the sSFR-M$_{\\star}$ plane show distinctly different SFHs,\nleading to a complex evolution of the sSFR-M$_{\\star}$ plane and star-forming\nsequence (SFS). However, we find that selecting galaxies based on stellar mass\nand position relative to SFS alone (as is traditionally the case), may not\nidentify sources with common recent SFHs, and therefore propose a new selection\nmethodology. We then use the recent SFH of galaxies to measure the evolution of\nthe SFS, showing that it has varying contributions from galaxies with different\nSFHs that lead to the observed changes in slope, normalisation and turnover\nstellar mass. Finally, we determine the overall evolution of the\nsSFR-M$_{\\star}$ plane from $z\\sim1$ to today. In the second paper in this\nseries we will discuss physical properties of galaxies with common recent SFHs\nand how these lead to the observed $\\sigma_{SFR}$-M$_{\\star}$ relation and\nevolution of the sSFR-M$_{\\star}$ plane.",
    "pdf_url": "http://arxiv.org/pdf/2505.21947v1",
    "published": "2025-05-28T03:56:57+00:00",
    "categories": [
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2505.21946v1",
    "title": "Fluid Simulation on Vortex Particle Flow Maps",
    "authors": [
      "Sinan Wang",
      "Junwei Zhou",
      "Fan Feng",
      "Zhiqi Li",
      "Yuchen Sun",
      "Duowen Chen",
      "Greg Turk",
      "Bo Zhu"
    ],
    "abstract": "We propose the Vortex Particle Flow Map (VPFM) method to simulate\nincompressible flow with complex vortical evolution in the presence of dynamic\nsolid boundaries. The core insight of our approach is that vorticity is an\nideal quantity for evolution on particle flow maps, enabling significantly\nlonger flow map distances compared to other fluid quantities like velocity or\nimpulse. To achieve this goal, we developed a hybrid Eulerian-Lagrangian\nrepresentation that evolves vorticity and flow map quantities on vortex\nparticles, while reconstructing velocity on a background grid. The method\nintegrates three key components: (1) a vorticity-based particle flow map\nframework, (2) an accurate Hessian evolution scheme on particles, and (3) a\nsolid boundary treatment for no-through and no-slip conditions in VPFM. These\ncomponents collectively allow a substantially longer flow map length (3-12\ntimes longer) than the state-of-the-art, enhancing vorticity preservation over\nextended spatiotemporal domains. We validated the performance of VPFM through\ndiverse simulations, demonstrating its effectiveness in capturing complex\nvortex dynamics and turbulence phenomena.",
    "pdf_url": "http://arxiv.org/pdf/2505.21946v1",
    "published": "2025-05-28T03:56:38+00:00",
    "categories": [
      "cs.GR",
      "physics.flu-dyn"
    ],
    "primary_category": "cs.GR"
  },
  {
    "id": "http://arxiv.org/abs/2505.21945v2",
    "title": "Deuterated water abundance in the young hot core RCW 120 S2",
    "authors": [
      "Maria. S. Kirsanova",
      "Anastasiia A. Farafontova"
    ],
    "abstract": "Since the emission of water molecules cannot be observed from Earth, less\nabundant isotopologues, such as H$_2^{18}$O and HDO, are used to trace water in\nstar-forming regions. The main aim of this study is to determine HDO abundance\nin the hot core RCW 120 S2. We performed observations of the hot core in the\n200-255~GHz range using the nFLASH230 receiver on the APEX telescope. Two HDO\nlines were detected toward RCW 120 S2. Their intensities are described by\nexcitation temperature $286\\pm2$~K and gas number density $\\geq\n10^9$~cm$^{-3}$. The emission originates from the hot core rather than the warm\ndense envelope surrounding a central young stellar object. The HDO column\ndensity ranges from $(3.9-7.9)\\times10^{13}$~cm$^{-3}$ with a most probable\nvalue $5.6\\times10^{13}$~cm$^{-3}$. The HDO abundance relative to hydrogen\nnuclei is $1.5\\times10^{-9}$. This HDO abundance value is among the lowest\nreported for hot cores. Combined with the non-detection of the H$_2^{18}$O\nline, we conclude that protostellar heating in RCW 120 S2 is still in its early\nstages.",
    "pdf_url": "http://arxiv.org/pdf/2505.21945v2",
    "published": "2025-05-28T03:55:13+00:00",
    "categories": [
      "astro-ph.SR",
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.SR"
  },
  {
    "id": "http://arxiv.org/abs/2505.21944v1",
    "title": "Stochastic Primal-Dual Double Block-Coordinate for Two-way Partial AUC Maximization",
    "authors": [
      "Linli Zhou",
      "Bokun Wang",
      "My T. Thai",
      "Tianbao Yang"
    ],
    "abstract": "Two-way partial AUC (TPAUC) is a critical performance metric for binary\nclassification with imbalanced data, as it focuses on specific ranges of the\ntrue positive rate (TPR) and false positive rate (FPR). However, stochastic\nalgorithms for TPAUC optimization remain under-explored, with existing methods\neither limited to approximated TPAUC loss functions or burdened by sub-optimal\ncomplexities. To overcome these limitations, we introduce two innovative\nstochastic primal-dual double block-coordinate algorithms for TPAUC\nmaximization. These algorithms utilize stochastic block-coordinate updates for\nboth the primal and dual variables, catering to both convex and non-convex\nsettings. We provide theoretical convergence rate analyses, demonstrating\nsignificant improvements over prior approaches. Our experimental results, based\non multiple benchmark datasets, validate the superior performance of our\nalgorithms, showcasing faster convergence and better generalization. This work\nadvances the state of the art in TPAUC optimization and offers practical tools\nfor real-world machine learning applications.",
    "pdf_url": "http://arxiv.org/pdf/2505.21944v1",
    "published": "2025-05-28T03:55:05+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.21943v1",
    "title": "Point-to-Region Loss for Semi-Supervised Point-Based Crowd Counting",
    "authors": [
      "Wei Lin",
      "Chenyang Zhao",
      "Antoni B. Chan"
    ],
    "abstract": "Point detection has been developed to locate pedestrians in crowded scenes by\ntraining a counter through a point-to-point (P2P) supervision scheme. Despite\nits excellent localization and counting performance, training a point-based\ncounter still faces challenges concerning annotation labor: hundreds to\nthousands of points are required to annotate a single sample capturing a dense\ncrowd. In this paper, we integrate point-based methods into a semi-supervised\ncounting framework based on pseudo-labeling, enabling the training of a counter\nwith only a few annotated samples supplemented by a large volume of\npseudo-labeled data. However, during implementation, the training encounters\nissues as the confidence for pseudo-labels fails to be propagated to background\npixels via the P2P. To tackle this challenge, we devise a point-specific\nactivation map (PSAM) to visually interpret the phenomena occurring during the\nill-posed training. Observations from the PSAM suggest that the feature map is\nexcessively activated by the loss for unlabeled data, causing the decoder to\nmisinterpret these over-activations as pedestrians. To mitigate this issue, we\npropose a point-to-region (P2R) scheme to substitute P2P, which segments out\nlocal regions rather than detects a point corresponding to a pedestrian for\nsupervision. Consequently, pixels in the local region can share the same\nconfidence with the corresponding pseudo points. Experimental results in both\nsemi-supervised counting and unsupervised domain adaptation highlight the\nadvantages of our method, illustrating P2R can resolve issues identified in\nPSAM. The code is available at https://github.com/Elin24/P2RLoss.",
    "pdf_url": "http://arxiv.org/pdf/2505.21943v1",
    "published": "2025-05-28T03:53:08+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.21942v1",
    "title": "Continual Learning Beyond Experience Rehearsal and Full Model Surrogates",
    "authors": [
      "Prashant Bhat",
      "Laurens Niesten",
      "Elahe Arani",
      "Bahram Zonooz"
    ],
    "abstract": "Continual learning (CL) has remained a significant challenge for deep neural\nnetworks as learning new tasks erases previously acquired knowledge, either\npartially or completely. Existing solutions often rely on experience rehearsal\nor full model surrogates to mitigate CF. While effective, these approaches\nintroduce substantial memory and computational overhead, limiting their\nscalability and applicability in real-world scenarios. To address this, we\npropose SPARC, a scalable CL approach that eliminates the need for experience\nrehearsal and full-model surrogates. By effectively combining task-specific\nworking memories and task-agnostic semantic memory for cross-task knowledge\nconsolidation, SPARC results in a remarkable parameter efficiency, using only\n6% of the parameters required by full-model surrogates. Despite its lightweight\ndesign, SPARC achieves superior performance on Seq-TinyImageNet and matches\nrehearsal-based methods on various CL benchmarks. Additionally, weight\nre-normalization in the classification layer mitigates task-specific biases,\nestablishing SPARC as a practical and scalable solution for CL under stringent\nefficiency constraints.",
    "pdf_url": "http://arxiv.org/pdf/2505.21942v1",
    "published": "2025-05-28T03:52:34+00:00",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.22690v1",
    "title": "Phase space analysis of cosmological models on $f(R,G,T)$ gravity",
    "authors": [
      "Elangbam Chingkheinganba Meetei",
      "S. Surendra Singh"
    ],
    "abstract": "In the present article, we developed a dynamical system in the context of\nmodified $f(R,G,T)$ gravity, where $R$, $G$ and $T$ are Ricci scalar,\nGauss-Bonnet term and energy-momentum tensor respectively. Development of the\ndynamical system is done by first defining 9 dimensionless variables and\nformulate a ordinary differential equations by taking derivative of the\nvariables with respect to logarithmic time $N=\\log a(t)$, where $a(t)$ is the\nscale factor. This formulation is applied to the model $f(R,G,T)=\\alpha\nR^{l}+\\beta G^{m} + \\gamma T^{n} $, and its solutions and their corresponding\nstabilities are analysed in details. From the plot of density parameters vs\n$N=-log(1+z)$, we conclude that our Universe is currently dominated by dark\nenergy, which is compatible with current observation. Taking $l=2$, cosmic\nparameters such as deceleration parameter $(q)$, equation of state $(\\omega)$\nand state finder parameters are also discussed by fixing one dimensionless\nvariable, showing our Universe's expansion is accelerating with the present\nvalue of $q=-0.5$. Present value of $\\omega=-0.66$ suggests that our Universe\nis in Quintessence phase. Lastly, the validity of the model with respect to the\n$\\Lambda$CDM model is checked by using 77 Hubble, 15 BAO and 1024 pantheon\ndatasets, which implies that our model is aligned with the $\\Lambda$CDM model's\nbahaviour.",
    "pdf_url": "http://arxiv.org/pdf/2505.22690v1",
    "published": "2025-05-28T03:51:11+00:00",
    "categories": [
      "gr-qc",
      "hep-th"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2505.21941v1",
    "title": "Test-Time Scaling with Repeated Sampling Improves Multilingual Text Generation",
    "authors": [
      "Ashim Gupta",
      "Vivek Srikumar"
    ],
    "abstract": "Inference-time scaling via repeated sampling has shown promise in reasoning\ntasks, but its effectiveness in multilingual generation remains underexplored.\nWe evaluate this approach using perplexity- and reward-based verifiers on two\nmultilingual benchmarks: the Aya Evaluation Suite and m-ArenaHard. Our results\nshow consistent quality improvements, with gains exceeding 35% in some cases.\nWhile perplexity-based scoring is effective for open-ended prompts, only\nreward-based verifiers improve performance on tasks requiring reasoning (e.g.,\nmath, code). Our results demonstrate the broader utility of repeated sampling\nfor multilingual text generation and underscore the importance of selecting\nright verifiers for the task.",
    "pdf_url": "http://arxiv.org/pdf/2505.21941v1",
    "published": "2025-05-28T03:50:19+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.21940v1",
    "title": "RISE: Reasoning Enhancement via Iterative Self-Exploration in Multi-hop Question Answering",
    "authors": [
      "Bolei He",
      "Xinran He",
      "Mengke Chen",
      "Xianwei Xue",
      "Ying Zhu",
      "Zhenhua Ling"
    ],
    "abstract": "Large Language Models (LLMs) excel in many areas but continue to face\nchallenges with complex reasoning tasks, such as Multi-Hop Question Answering\n(MHQA). MHQA requires integrating evidence from diverse sources while managing\nintricate logical dependencies, often leads to errors in reasoning.\nRetrieval-Augmented Generation (RAG), widely employed in MHQA tasks, faces\nchallenges in effectively filtering noisy data and retrieving all necessary\nevidence, thereby limiting its effectiveness in addressing MHQA challenges. To\naddress these challenges, we propose RISE:Reasoning Enhancement via Iterative\nSelf-Exploration, a novel framework designed to enhance models' reasoning\ncapability through iterative self-exploration. Specifically, RISE involves\nthree key steps in addressing MHQA tasks: question decomposition,\nretrieve-then-read, and self-critique. By leveraging continuous\nself-exploration, RISE identifies accurate reasoning paths, iteratively\nself-improving the model's capability to integrate evidence, maintain logical\nconsistency, and enhance performance in MHQA tasks. Extensive experiments on\nmultiple MHQA benchmarks demonstrate that RISE significantly improves reasoning\naccuracy and task performance.",
    "pdf_url": "http://arxiv.org/pdf/2505.21940v1",
    "published": "2025-05-28T03:48:28+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.21939v1",
    "title": "Improved Approximation Algorithms for Chromatic and Pseudometric-Weighted Correlation Clustering",
    "authors": [
      "Dahoon Lee",
      "Chenglin Fan",
      "Euiwoong Lee"
    ],
    "abstract": "Correlation Clustering (CC) is a foundational problem in unsupervised\nlearning that models binary similarity relations using labeled graphs. While\nclassical CC has been widely studied, many real-world applications involve more\nnuanced relationships, either multi-class categorical interactions or varying\nconfidence levels in edge labels. To address these, two natural generalizations\nhave been proposed: Chromatic Correlation Clustering (CCC), which assigns\nsemantic colors to edge labels, and pseudometric-weighted CC, which allows edge\nweights satisfying the triangle inequality. In this paper, we develop improved\napproximation algorithms for both settings. Our approach leverages LP-based\npivoting techniques combined with problem-specific rounding functions. For the\npseudometric-weighted correlation clustering problem, we present a tight\n$10/3$-approximation algorithm, matching the best possible bound achievable\nwithin the framework of standard LP relaxation combined with specialized\nrounding. For the Chromatic Correlation Clustering (CCC) problem, we improve\nthe approximation ratio from the previous best of $2.5$ to $2.15$, and we\nestablish a lower bound of $2.11$ within the same analytical framework,\nhighlighting the near-optimality of our result.",
    "pdf_url": "http://arxiv.org/pdf/2505.21939v1",
    "published": "2025-05-28T03:47:42+00:00",
    "categories": [
      "cs.DS"
    ],
    "primary_category": "cs.DS"
  },
  {
    "id": "http://arxiv.org/abs/2505.21938v2",
    "title": "Practical Adversarial Attacks on Stochastic Bandits via Fake Data Injection",
    "authors": [
      "Qirun Zeng",
      "Eric He",
      "Richard Hoffmann",
      "Xuchuang Wang",
      "Jinhang Zuo"
    ],
    "abstract": "Adversarial attacks on stochastic bandits have traditionally relied on some\nunrealistic assumptions, such as per-round reward manipulation and unbounded\nperturbations, limiting their relevance to real-world systems. We propose a\nmore practical threat model, Fake Data Injection, which reflects realistic\nadversarial constraints: the attacker can inject only a limited number of\nbounded fake feedback samples into the learner's history, simulating legitimate\ninteractions. We design efficient attack strategies under this model,\nexplicitly addressing both magnitude constraints (on reward values) and\ntemporal constraints (on when and how often data can be injected). Our\ntheoretical analysis shows that these attacks can mislead both Upper Confidence\nBound (UCB) and Thompson Sampling algorithms into selecting a target arm in\nnearly all rounds while incurring only sublinear attack cost. Experiments on\nsynthetic and real-world datasets validate the effectiveness of our strategies,\nrevealing significant vulnerabilities in widely used stochastic bandit\nalgorithms under practical adversarial scenarios.",
    "pdf_url": "http://arxiv.org/pdf/2505.21938v2",
    "published": "2025-05-28T03:47:13+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.02015v1",
    "title": "Object-centric Self-improving Preference Optimization for Text-to-Image Generation",
    "authors": [
      "Yoonjin Oh",
      "Yongjin Kim",
      "Hyomin Kim",
      "Donghwan Chi",
      "Sungwoong Kim"
    ],
    "abstract": "Recent advancements in Multimodal Large Language Models (MLLMs) have\nsignificantly improved both image understanding and generation capabilities.\nDespite these improvements, MLLMs still struggle with fine-grained visual\ncomprehension, particularly in text-to-image generation tasks. While preference\noptimization methods have been explored to address these limitations in image\nunderstanding tasks, their application to image generation remains largely\nunderexplored. To address this gap, we propose an Object-centric Self-improving\nPreference Optimization (OSPO) framework designed for text-to-image generation\nby MLLMs. OSPO leverages the intrinsic reasoning abilities of MLLMs without\nrequiring any external datasets or models. OSPO emphasizes the importance of\nhigh-quality preference pair data, which is critical for effective preference\noptimization. To achieve this, it introduces a self-improving mechanism that\nautonomously constructs object-level contrastive preference pairs through\nobject-centric prompt perturbation, densification and VQA scoring. This process\neliminates ambiguous or disproportionate variations commonly found in naively\ngenerated preference pairs, thereby enhancing the effectiveness of preference\noptimization. We validate OSPO on three representative compositional\ntext-to-image benchmarks, demonstrating substantial performance gains over\nbaseline models.",
    "pdf_url": "http://arxiv.org/pdf/2506.02015v1",
    "published": "2025-05-28T03:45:42+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.21937v1",
    "title": "Graph-Assisted Culturally Adaptable Idiomatic Translation for Indic Languages",
    "authors": [
      "Pratik Rakesh Singh",
      "Kritarth Prasad",
      "Mohammadi Zaki",
      "Pankaj Wasnik"
    ],
    "abstract": "Translating multi-word expressions (MWEs) and idioms requires a deep\nunderstanding of the cultural nuances of both the source and target languages.\nThis challenge is further amplified by the one-to-many nature of idiomatic\ntranslations, where a single source idiom can have multiple target-language\nequivalents depending on cultural references and contextual variations.\nTraditional static knowledge graphs (KGs) and prompt-based approaches struggle\nto capture these complex relationships, often leading to suboptimal\ntranslations. To address this, we propose IdiomCE, an adaptive graph neural\nnetwork (GNN) based methodology that learns intricate mappings between\nidiomatic expressions, effectively generalizing to both seen and unseen nodes\nduring training. Our proposed method enhances translation quality even in\nresource-constrained settings, facilitating improved idiomatic translation in\nsmaller models. We evaluate our approach on multiple idiomatic translation\ndatasets using reference-less metrics, demonstrating significant improvements\nin translating idioms from English to various Indian languages.",
    "pdf_url": "http://arxiv.org/pdf/2505.21937v1",
    "published": "2025-05-28T03:42:16+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.21936v2",
    "title": "RedTeamCUA: Realistic Adversarial Testing of Computer-Use Agents in Hybrid Web-OS Environments",
    "authors": [
      "Zeyi Liao",
      "Jaylen Jones",
      "Linxi Jiang",
      "Eric Fosler-Lussier",
      "Yu Su",
      "Zhiqiang Lin",
      "Huan Sun"
    ],
    "abstract": "Computer-use agents (CUAs) promise to automate complex tasks across operating\nsystems (OS) and the web, but remain vulnerable to indirect prompt injection.\nCurrent evaluations of this threat either lack support realistic but controlled\nenvironments or ignore hybrid web-OS attack scenarios involving both\ninterfaces. To address this, we propose RedTeamCUA, an adversarial testing\nframework featuring a novel hybrid sandbox that integrates a VM-based OS\nenvironment with Docker-based web platforms. Our sandbox supports key features\ntailored for red teaming, such as flexible adversarial scenario configuration,\nand a setting that decouples adversarial evaluation from navigational\nlimitations of CUAs by initializing tests directly at the point of an\nadversarial injection. Using RedTeamCUA, we develop RTC-Bench, a comprehensive\nbenchmark with 864 examples that investigate realistic, hybrid web-OS attack\nscenarios and fundamental security vulnerabilities. Benchmarking current\nfrontier CUAs identifies significant vulnerabilities: Claude 3.7 Sonnet | CUA\ndemonstrates an ASR of 42.9%, while Operator, the most secure CUA evaluated,\nstill exhibits an ASR of 7.6%. Notably, CUAs often attempt to execute\nadversarial tasks with an Attempt Rate as high as 92.5%, although failing to\ncomplete them due to capability limitations. Nevertheless, we observe\nconcerning ASRs of up to 50% in realistic end-to-end settings, with the\nrecently released frontier Claude 4 Opus | CUA showing an alarming ASR of 48%,\ndemonstrating that indirect prompt injection presents tangible risks for even\nadvanced CUAs despite their capabilities and safeguards. Overall, RedTeamCUA\nprovides an essential framework for advancing realistic, controlled, and\nsystematic analysis of CUA vulnerabilities, highlighting the urgent need for\nrobust defenses to indirect prompt injection prior to real-world deployment.",
    "pdf_url": "http://arxiv.org/pdf/2505.21936v2",
    "published": "2025-05-28T03:42:09+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.21935v2",
    "title": "From Reasoning to Learning: A Survey on Hypothesis Discovery and Rule Learning with Large Language Models",
    "authors": [
      "Kaiyu He",
      "Zhiyu Chen"
    ],
    "abstract": "Since the advent of Large Language Models (LLMs), efforts have largely\nfocused on improving their instruction-following and deductive reasoning\nabilities, leaving open the question of whether these models can truly discover\nnew knowledge. In pursuit of artificial general intelligence (AGI), there is a\ngrowing need for models that not only execute commands or retrieve information\nbut also learn, reason, and generate new knowledge by formulating novel\nhypotheses and theories that deepen our understanding of the world. Guided by\nPeirce's framework of abduction, deduction, and induction, this survey offers a\nstructured lens to examine LLM-based hypothesis discovery. We synthesize\nexisting work in hypothesis generation, application, and validation,\nidentifying both key achievements and critical gaps. By unifying these threads,\nwe illuminate how LLMs might evolve from mere ``information executors'' into\nengines of genuine innovation, potentially transforming research, science, and\nreal-world problem solving.",
    "pdf_url": "http://arxiv.org/pdf/2505.21935v2",
    "published": "2025-05-28T03:40:02+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.21934v1",
    "title": "Beyond data: leveraging non-empirical information and expert knowledge in Bayesian model calibration",
    "authors": [
      "Sarah A. Vollert",
      "Christopher Drovandi",
      "Cailan Jeynes-Smith",
      "Luz V. Pascal",
      "Matthew P. Adams"
    ],
    "abstract": "Mathematical models connect theory with the real world through data, enabling\nus to interpret, understand, and predict complex phenomena. However, scientific\nknowledge often extends beyond what can be empirically measured, offering\nvaluable insights into complex and uncertain systems. Here, we introduce a\nstatistical framework for calibrating mathematical models using non-empirical\ninformation. Through examples in ecology, biology, and medicine, we demonstrate\nhow expert knowledge, scientific theory, and qualitative observations can\nmeaningfully constrain models. In each case, these non-empirical insights guide\nmodels toward more realistic dynamics and more informed predictions than\nempirical data alone could achieve. Now, our understanding of the systems\nrepresented by mathematical models is not limited by the data that can be\nobtained; they instead sit at the edge of scientific understanding.",
    "pdf_url": "http://arxiv.org/pdf/2505.21934v1",
    "published": "2025-05-28T03:38:59+00:00",
    "categories": [
      "stat.ME",
      "stat.AP"
    ],
    "primary_category": "stat.ME"
  },
  {
    "id": "http://arxiv.org/abs/2505.21933v1",
    "title": "Universal principles for sudden-quench quantum Otto engines",
    "authors": [
      "R. S. Watson",
      "K. V. Kheruntsyan"
    ],
    "abstract": "We apply a simple sudden quench approximation for the unitary work strokes of\na quantum Otto engine in order to provide a general analysis of its\nperformance, applicable to arbitrary quantum models with two-body interactions.\nThis work extends recent results for an interaction-driven Otto cycle to\ngeneric many-body interacting quantum models, providing universal bounds on\ntheir operation efficiency. From this, we demonstrate that the net work of such\nan engine cycle is determined entirely by interparticle correlations.\nApplications are demonstrated for a handful of paradigmatic many-body quantum\nmodels, including a novel engine -- with a spin-1/2 Fermi gas with contact\ntwo-body interactions as its working medium -- in which we leverage control\nover spin polarization to greatly enhance its performance compared to the\nunpolarized case. We then extend the analysis of interaction-driven quantum\nOtto engine cycles to systems where control is exerted over the strength of\narbitrary quantum operators that might be present in the system Hamiltonian\n(such as one-body, or three-body, etc.), finding that the general principles\nderived for the sudden quench with two-body interactions apply universally. As\nan example, this is demonstrated for a conventional volumetric Otto cycle,\nwhere beneficial net work is generated by leveraging the control over the\nfrequency of an external trap, which is a one-body operator. However, we\nemphasize that the results derived here apply universally to all Otto engine\ncycles operating under a sudden quench protocol.",
    "pdf_url": "http://arxiv.org/pdf/2505.21933v1",
    "published": "2025-05-28T03:38:00+00:00",
    "categories": [
      "cond-mat.quant-gas",
      "cond-mat.stat-mech",
      "quant-ph"
    ],
    "primary_category": "cond-mat.quant-gas"
  },
  {
    "id": "http://arxiv.org/abs/2505.21932v2",
    "title": "Higher-Order Group Synchronization",
    "authors": [
      "Adriana L. Duncan",
      "Joe Kileel"
    ],
    "abstract": "Group synchronization is the problem of determining reliable global estimates\nfrom noisy local measurements on networks. The typical task for group\nsynchronization is to assign elements of a group to the nodes of a graph in a\nway that respects group elements given on the edges which encode information\nabout local pairwise relationships between the nodes. In this paper, we\nintroduce a novel higher-order group synchronization problem which operates on\na hypergraph and seeks to synchronize higher-order local measurements on the\nhyperedges to obtain global estimates on the nodes. Higher-order group\nsynchronization is motivated by applications to computer vision and image\nprocessing, among other computational problems. First, we define the problem of\nhigher-order group synchronization and discuss its mathematical foundations.\nSpecifically, we give necessary and sufficient synchronizability conditions\nwhich establish the importance of cycle consistency in higher-order group\nsynchronization. Then, we propose the first computational framework for general\nhigher-order group synchronization; it acts globally and directly on\nhigher-order measurements using a message passing algorithm. We discuss\ntheoretical guarantees for our framework, including convergence analyses under\noutliers and noise. Finally, we show potential advantages of our method through\nnumerical experiments. In particular, we show that in certain cases our\nhigher-order method applied to rotational and angular synchronization\noutperforms standard pairwise synchronization methods and is more robust to\noutliers. We also show that our method has comparable performance on simulated\ncryo-electron microscopy (cryo-EM) data compared to a standard cryo-EM\nreconstruction package.",
    "pdf_url": "http://arxiv.org/pdf/2505.21932v2",
    "published": "2025-05-28T03:37:10+00:00",
    "categories": [
      "stat.ML",
      "cs.CV",
      "cs.LG",
      "math.CO",
      "math.OC"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2505.21931v1",
    "title": "Large Language Models for Solving Economic Dispatch Problem",
    "authors": [
      "Sina Mohammadi",
      "Ali Hassan",
      "Rouzbeh Haghighi",
      "Van-Hai Bui",
      "Wencong Su"
    ],
    "abstract": "This paper investigates the capability of off-the-shelf large language models\n(LLMs) to solve the economic dispatch (ED) problem. ED is a hard-constrained\noptimization problem solved on a day-ahead timescale by grid operators to\nminimize electricity generation costs while accounting for physical and\nengineering constraints. Numerous approaches have been proposed, but these\ntypically require either mathematical formulations, face convergence issues, or\ndepend on extensive labeled data and training time. This work implements LLMs\nenhanced with reasoning capabilities to address the classic lossless ED\nproblem. The proposed approach avoids the need for explicit mathematical\nformulations, does not suffer from convergence challenges, and requires neither\nlabeled data nor extensive training. A few-shot learning technique is utilized\nin two different prompting contexts. The IEEE 118-bus system with 19 generation\nunits serves as the evaluation benchmark. Results demonstrate that various\nprompting strategies enable LLMs to effectively solve the ED problem, offering\na convenient and efficient alternative. Consequently, this approach presents a\npromising future solution for ED tasks, particularly when foundational power\nsystem models are available.",
    "pdf_url": "http://arxiv.org/pdf/2505.21931v1",
    "published": "2025-05-28T03:31:54+00:00",
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2506.14790v1",
    "title": "Continuous Evolution Pool: Taming Recurring Concept Drift in Online Time Series Forecasting",
    "authors": [
      "Tianxiang Zhan",
      "Ming Jin",
      "Yuanpeng He",
      "Yuxuan Liang",
      "Yong Deng",
      "Shirui Pan"
    ],
    "abstract": "Recurring concept drift, a type of concept drift in which previously observed\ndata patterns reappear after some time, is one of the most prevalent types of\nconcept drift in time series. As time progresses, concept drift occurs and\npreviously encountered concepts are forgotten, thereby leading to a decline in\nthe accuracy of online predictions. Existing solutions employ parameter\nupdating techniques to delay forgetting; however, this may result in the loss\nof some previously learned knowledge while neglecting the exploration of\nknowledge retention mechanisms. To retain all conceptual knowledge and fully\nutilize it when the concepts recur, we propose the Continuous Evolution Pool\n(CEP), a pooling mechanism that stores different instances of forecasters for\ndifferent concepts. Our method first selects the forecaster nearest to the test\nsample and then learns the features from its neighboring samples - a process we\nrefer to as the retrieval. If there are insufficient neighboring samples, it\nindicates that a new concept has emerged, and a new model will evolve from the\ncurrent nearest sample to the pool to store the knowledge of the concept.\nSimultaneously, the elimination mechanism will enable outdated knowledge to be\ncleared to ensure the prediction effect of the forecasters. Experiments on\ndifferent architectural models and eight real datasets demonstrate that CEP\neffectively retains the knowledge of different concepts. In the scenario of\nonline forecasting with recurring concepts, CEP significantly enhances the\nprediction results.",
    "pdf_url": "http://arxiv.org/pdf/2506.14790v1",
    "published": "2025-05-28T03:27:49+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.21930v1",
    "title": "Efficient Ensemble for Fine-tuning Language Models on Multiple Datasets",
    "authors": [
      "Dongyue Li",
      "Ziniu Zhang",
      "Lu Wang",
      "Hongyang R. Zhang"
    ],
    "abstract": "This paper develops an ensemble method for fine-tuning a language model to\nmultiple datasets. Existing methods, such as quantized LoRA (QLoRA), are\nefficient when adapting to a single dataset. When training on multiple datasets\nof different tasks, a common setup in practice, it remains unclear how to\ndesign an efficient adaptation for fine-tuning language models. We propose to\nuse an ensemble of multiple smaller adapters instead of a single adapter per\ntask. We design an efficient algorithm that partitions $n$ datasets into $m$\ngroups, where $m$ is typically much smaller than $n$ in practice, and train one\nadapter for each group before taking a weighted combination to form the\nensemble. The algorithm leverages a first-order approximation property of\nlow-rank adaptation to quickly obtain the fine-tuning performances of dataset\ncombinations since methods like LoRA stay close to the base model. Hence, we\nuse the gradients of the base model to estimate its behavior during\nfine-tuning. Empirically, this approximation holds with less than $1\\%$ error\non models with up to $34$ billion parameters, leading to an estimation of true\nfine-tuning performances under $5\\%$ error while speeding up computation\ncompared to base fine-tuning by $105$ times. When applied to fine-tune Llama\nand GPT models on ten text classification tasks, our approach provides up to\n$10\\%$ higher average test accuracy over QLoRA, with only $9\\%$ more FLOPs. On\na Llama model with $34$ billion parameters, an ensemble of QLoRA increases test\naccuracy by $3\\%$ compared to QLoRA, with only $8\\%$ more FLOPs.",
    "pdf_url": "http://arxiv.org/pdf/2505.21930v1",
    "published": "2025-05-28T03:27:08+00:00",
    "categories": [
      "cs.LG",
      "cs.CL"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.21929v1",
    "title": "MWA and VLA Observations of Diffuse Radio Lobes in M 87",
    "authors": [
      "Linhui Wu",
      "Fu-Guo Xie",
      "Qian Zheng",
      "Quan Guo",
      "Huanyuan Shan",
      "Dan Hu",
      "Stefan W. Duchesne",
      "Nicholas Seymour",
      "Jingying Wang",
      "Junhua Gu",
      "Qingwen Wu",
      "Zhenghao Zhu",
      "Melanie Johnston-Hollitt",
      "Chris Riseley",
      "Xu-Liang Fan"
    ],
    "abstract": "This study investigates the projected, quasi-symmetric $\\sim\\rm46\\,kpc$-scale\ndiffuse radio lobes surrounding the giant elliptical galaxy M\\,87, utilizing\nwell-sampled wideband ($\\rm 60\\,MHz-10.55\\,GHz$) observations from MWA and VLA,\nsupplemented by data from LOFAR and Effelsberg. The observed structures feature\nsharp edges and filaments, with nearly uniform and moderately steep spectral\nindices ($\\alpha$, mostly within $-1.2\\leq\\alpha\\leq-0.8$), indicating\nturbulence. Well-sampled radio spectra for the lobes' diffuse region are\nderived using the continuous injection (CI) model (with $\\alpha_{\\rm\ninj}\\simeq-0.86$ and $\\nu_{\\rm b}\\simeq1.72\\rm\\,GHz$), and for its three\nlocalized regions using the impulsive injection model (e.g., JP model). From\nenergy equipartition analysis, we estimate the typical magnetic field strength\nin the lobes' diffuse region to be $B_{\\rm eq}\\simeq10\\,\\mu\\rm G$. The age of\nthe lobes is estimated as $\\sim30-50\\,\\rm~Myr$, based on lifetimes derived from\nthe CI and JP models and sound crossing time. Outflow powers of\n$\\sim(0.2-2)\\times10^{44}\\,\\rm erg\\,s^{-1}$ for the lobes' diffuse components\nand $\\sim(1-11)\\times10^{44}\\,\\rm erg\\,s^{-1}$ for the whole source are\ncalculated. With this power assessment, we conclude that the galactic stellar\nwind has a negligible effect, the active galactic nucleus (AGN)-driven jet can\nprovide the necessary energy for the whole system. Furthermore, we argue that\nwhile the wind driven by current AGN activity is unlikely to power the lobes'\ndiffuse components, an average enhancement of AGN activity by a factor of $\\sim\n10^2$ over the past $\\sim 30-50$ Myr remains plausible.",
    "pdf_url": "http://arxiv.org/pdf/2505.21929v1",
    "published": "2025-05-28T03:23:31+00:00",
    "categories": [
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2505.21928v2",
    "title": "Subspecialty-Specific Foundation Model for Intelligent Gastrointestinal Pathology",
    "authors": [
      "Lianghui Zhu",
      "Xitong Ling",
      "Minxi Ouyang",
      "Xiaoping Liu",
      "Tian Guan",
      "Mingxi Fu",
      "Zhiqiang Cheng",
      "Fanglei Fu",
      "Maomao Zeng",
      "Liming Liu",
      "Song Duan",
      "Qiang Huang",
      "Ying Xiao",
      "Jianming Li",
      "Shanming Lu",
      "Zhenghua Piao",
      "Mingxi Zhu",
      "Yibo Jin",
      "Shan Xu",
      "Qiming He",
      "Yizhi Wang",
      "Junru Cheng",
      "Xuanyu Wang",
      "Luxi Xie",
      "Houqiang Li",
      "Sufang Tian",
      "Yonghong He"
    ],
    "abstract": "Gastrointestinal (GI) diseases represent a clinically significant burden,\nnecessitating precise diagnostic approaches to optimize patient outcomes.\nConventional histopathological diagnosis suffers from limited reproducibility\nand diagnostic variability. To overcome these limitations, we develop Digepath,\na specialized foundation model for GI pathology. Our framework introduces a\ndual-phase iterative optimization strategy combining pretraining with\nfine-screening, specifically designed to address the detection of sparsely\ndistributed lesion areas in whole-slide images. Digepath is pretrained on over\n353 million multi-scale images from 210,043 H&E-stained slides of GI diseases.\nIt attains state-of-the-art performance on 33 out of 34 tasks related to GI\npathology, including pathological diagnosis, protein expression status\nprediction, gene mutation prediction, and prognosis evaluation. We further\ntranslate the intelligent screening module for early GI cancer and achieve\nnear-perfect 99.70% sensitivity across nine independent medical institutions.\nThis work not only advances AI-driven precision pathology for GI diseases but\nalso bridge critical gaps in histopathological practice.",
    "pdf_url": "http://arxiv.org/pdf/2505.21928v2",
    "published": "2025-05-28T03:22:08+00:00",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "eess.IV"
  },
  {
    "id": "http://arxiv.org/abs/2505.21927v2",
    "title": "Giant electro-optic coefficient in single crystal barium titanate on oxide insulator based Mach-Zehnder interferometer",
    "authors": [
      "Hong-Lin Lin",
      "Pragati Aashna",
      "Yu Cao",
      "Aaron Danner"
    ],
    "abstract": "Electro-optic modulators are indispensable components of modern day photonic\nintegrated circuits (PICs). Recently lithium niobate has emerged as a key\nmaterial to realize large-bandwidth high-speed modulation, but next-generation\nmodulators require high-density integration, low cost, low power and high\nperformance simultaneously, which are difficult to achieve with established\nintegrated lithium niobate photonics platforms due to its limited electro-optic\ncoefficient. Leveraging its exceptional Pockels coefficient, barium titanate\n(BTO) in the thin film form has emerged as a promising alternative but the\nelectro-optic coefficients reported in thin-film BTO often fall short of bulk\nvalues due to challenges in film growth and waveguide fabrication. Here, we\nreport, to the best of our knowledge, the largest Pockels coefficient (r42) of\n1268 pm/V in thin film BTO platform, which is very close to the bulk value. We\nmeasure it by using an unbalanced Mach-Zehnder interferometer, fabricated by an\noptimized wet-etching method for realising single-mode waveguides in\nsingle-crystal barium titanate-on-insulator grown by pulsed laser deposition.\nThis giant r42 is extracted from a device in which the optical mode is fully\nconfined within a single-crystal BTO waveguide. This approach contrasts with\nprevious designs where the core material - typically silicon or silicon nitride\n- supports only partial confinement, resulting in an evanescent overlap with a\nmulti-crystalline BTO layer. This highly confined BTO on insulator\nelectro-optic modulation technology may significantly advance the field of\nultra-low-power integrated photonic devices and allows for the realization of\nnext-generation efficient and compact photonic circuits.",
    "pdf_url": "http://arxiv.org/pdf/2505.21927v2",
    "published": "2025-05-28T03:22:01+00:00",
    "categories": [
      "physics.optics",
      "physics.app-ph"
    ],
    "primary_category": "physics.optics"
  },
  {
    "id": "http://arxiv.org/abs/2505.21926v1",
    "title": "Beyond Completion: A Foundation Model for General Knowledge Graph Reasoning",
    "authors": [
      "Yin Hua",
      "Zhiqiang Liu",
      "Mingyang Chen",
      "Zheng Fang",
      "Chi Man Wong",
      "Lingxiao Li",
      "Chi Man Vong",
      "Huajun Chen",
      "Wen Zhang"
    ],
    "abstract": "In natural language processing (NLP) and computer vision (CV), the successful\napplication of foundation models across diverse tasks has demonstrated their\nremarkable potential. However, despite the rich structural and textual\ninformation embedded in knowledge graphs (KGs), existing research of foundation\nmodel for KG has primarily focused on their structural aspects, with most\nefforts restricted to in-KG tasks (e.g., knowledge graph completion, KGC). This\nlimitation has hindered progress in addressing more challenging out-of-KG\ntasks. In this paper, we introduce MERRY, a foundation model for general\nknowledge graph reasoning, and investigate its performance across two task\ncategories: in-KG reasoning tasks (e.g., KGC) and out-of-KG tasks (e.g., KG\nquestion answering, KGQA). We not only utilize the structural information, but\nalso the textual information in KGs. Specifically, we propose a\nmulti-perspective Conditional Message Passing (CMP) encoding architecture to\nbridge the gap between textual and structural modalities, enabling their\nseamless integration. Additionally, we introduce a dynamic residual fusion\nmodule to selectively retain relevant textual information and a flexible edge\nscoring mechanism to adapt to diverse downstream tasks. Comprehensive\nevaluations on 28 datasets demonstrate that MERRY outperforms existing\nbaselines in most scenarios, showcasing strong reasoning capabilities within\nKGs and excellent generalization to out-of-KG tasks such as KGQA.",
    "pdf_url": "http://arxiv.org/pdf/2505.21926v1",
    "published": "2025-05-28T03:21:28+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.21925v1",
    "title": "RenderFormer: Transformer-based Neural Rendering of Triangle Meshes with Global Illumination",
    "authors": [
      "Chong Zeng",
      "Yue Dong",
      "Pieter Peers",
      "Hongzhi Wu",
      "Xin Tong"
    ],
    "abstract": "We present RenderFormer, a neural rendering pipeline that directly renders an\nimage from a triangle-based representation of a scene with full global\nillumination effects and that does not require per-scene training or\nfine-tuning. Instead of taking a physics-centric approach to rendering, we\nformulate rendering as a sequence-to-sequence transformation where a sequence\nof tokens representing triangles with reflectance properties is converted to a\nsequence of output tokens representing small patches of pixels. RenderFormer\nfollows a two stage pipeline: a view-independent stage that models\ntriangle-to-triangle light transport, and a view-dependent stage that\ntransforms a token representing a bundle of rays to the corresponding pixel\nvalues guided by the triangle-sequence from the view-independent stage. Both\nstages are based on the transformer architecture and are learned with minimal\nprior constraints. We demonstrate and evaluate RenderFormer on scenes with\nvarying complexity in shape and light transport.",
    "pdf_url": "http://arxiv.org/pdf/2505.21925v1",
    "published": "2025-05-28T03:20:46+00:00",
    "categories": [
      "cs.GR",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.GR"
  },
  {
    "id": "http://arxiv.org/abs/2505.21924v2",
    "title": "Modified Transfer Matrix Method for the Extraction of Material Properties via Terahertz Time-Domain Spectroscopy",
    "authors": [
      "Kamyar Rashidi",
      "Matthew Y. Sfeir"
    ],
    "abstract": "Terahertz Time-Domain Spectroscopy is a powerful technique for extracting the\nlow-frequency optical properties of materials. However, the optical constants\nare difficult to determine directly from the experimental transfer function,\nsuch that various numerical approximations must be implemented to describe\nspecific conditions. Here, we introduce a modified Transfer Matrix Method that\nuses a genetic algorithm for optimization to determine the refractive index of\nmaterials in the THz regime. We show that this approach is generally applicable\nacross a wide range of refractive indices, structures, and frequency ranges.\nOur method is intuitive and yields accurate results compared to leading methods\nacross a wide spectral range (0.1 - 15 THz).",
    "pdf_url": "http://arxiv.org/pdf/2505.21924v2",
    "published": "2025-05-28T03:19:35+00:00",
    "categories": [
      "physics.optics",
      "cond-mat.mes-hall",
      "cond-mat.mtrl-sci",
      "physics.chem-ph"
    ],
    "primary_category": "physics.optics"
  },
  {
    "id": "http://arxiv.org/abs/2505.21923v1",
    "title": "FALCON: An ML Framework for Fully Automated Layout-Constrained Analog Circuit Design",
    "authors": [
      "Asal Mehradfar",
      "Xuzhe Zhao",
      "Yilun Huang",
      "Emir Ceyani",
      "Yankai Yang",
      "Shihao Han",
      "Hamidreza Aghasi",
      "Salman Avestimehr"
    ],
    "abstract": "Designing analog circuits from performance specifications is a complex,\nmulti-stage process encompassing topology selection, parameter inference, and\nlayout feasibility. We introduce FALCON, a unified machine learning framework\nthat enables fully automated, specification-driven analog circuit synthesis\nthrough topology selection and layout-constrained optimization. Given a target\nperformance, FALCON first selects an appropriate circuit topology using a\nperformance-driven classifier guided by human design heuristics. Next, it\nemploys a custom, edge-centric graph neural network trained to map circuit\ntopology and parameters to performance, enabling gradient-based parameter\ninference through the learned forward model. This inference is guided by a\ndifferentiable layout cost, derived from analytical equations capturing\nparasitic and frequency-dependent effects, and constrained by design rules. We\ntrain and evaluate FALCON on a large-scale custom dataset of 1M analog mm-wave\ncircuits, generated and simulated using Cadence Spectre across 20\nexpert-designed topologies. Through this evaluation, FALCON demonstrates >99\\%\naccuracy in topology inference, <10\\% relative error in performance prediction,\nand efficient layout-aware design that completes in under 1 second per\ninstance. Together, these results position FALCON as a practical and extensible\nfoundation model for end-to-end analog circuit design automation.",
    "pdf_url": "http://arxiv.org/pdf/2505.21923v1",
    "published": "2025-05-28T03:16:08+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.AR",
      "cs.CE"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.21922v1",
    "title": "Dual-Polarization SHG Interferometry for Imaging Antiparallel Domains and Stacking Angles of 2D Heterocrystals",
    "authors": [
      "Juseung Oh",
      "Wontaek Kim",
      "Gyouil Jeong",
      "Yeri Lee",
      "Jihun Kim",
      "Hyeongjoon Kim",
      "Hyeon Suk Shin",
      "Sunmin Ryu"
    ],
    "abstract": "Optical second-harmonic generation (SHG) enables orientational polarimetry\nfor crystallographic analysis and domain imaging of various materials. However,\nconventional intensity polarimetry, which neglects phase information, fails to\nresolve antiparallel domains and to describe two-dimensional heterostructures,\nwhich represent a new class of van der Waals-bound composite crystals. In this\nwork, we report dual-polarization spectral phase interferometry (DP-SPI) and\nestablish a generalized SHG superposition model that incorporates the\nobservables of DP-SPI. Antiparallel domains of monolayer transition metal\ndichalcogenides (TMDs) were successfully imaged with distinction, validating\nthe interferometric polarimetry. From DP interferograms of TMD heterobilayers,\nthe orientation of each layer could be determined, enabling layer-resolved\nprobing. By employing the superposition model, we also demonstrate the photonic\ndesign and fabrication of ternary TMD heterostructures for circularly polarized\nSHG. These methods, providing comprehensive SHG measurements and theoretical\ndescription, can be extended to heterostructures consisting of more than two\nconstituent layers and are not limited to TMDs or 2D materials.",
    "pdf_url": "http://arxiv.org/pdf/2505.21922v1",
    "published": "2025-05-28T03:12:34+00:00",
    "categories": [
      "physics.optics",
      "cond-mat.mes-hall",
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "physics.optics"
  },
  {
    "id": "http://arxiv.org/abs/2505.21921v1",
    "title": "Exact Quantum Many-Body Scars in 2D Quantum Gauge Models",
    "authors": [
      "Yuan Miao",
      "Linhao Li",
      "Hosho Katsura",
      "Masahito Yamazaki"
    ],
    "abstract": "Quantum many-body scars (QMBS) serve as important examples of\nergodicity-breaking phenomena in quantum many-body systems. Despite recent\nextensive studies, exact QMBS are rare in dimensions higher than one. In this\npaper, we study a two-dimensional quantum $\\mathbb{Z}_2$ gauge model that is\ndual to a two-dimensional spin-$1/2$ XY model defined on bipartite graphs. We\nidentify the exact eigenstates of the XY model with a tower structure as exact\nQMBS. Exploiting the duality transformation, we show that the exact QMBS of the\nXY model (and XXZ model) after the transformation are the exact QMBS of the\ndual $\\mathbb{Z}_2$ gauge model. This construction is versatile and has\npotential applications for finding new QMBS in other higher-dimensional models.",
    "pdf_url": "http://arxiv.org/pdf/2505.21921v1",
    "published": "2025-05-28T03:10:22+00:00",
    "categories": [
      "cond-mat.str-el",
      "cond-mat.stat-mech",
      "quant-ph"
    ],
    "primary_category": "cond-mat.str-el"
  },
  {
    "id": "http://arxiv.org/abs/2505.21920v2",
    "title": "InfoSAM: Fine-Tuning the Segment Anything Model from An Information-Theoretic Perspective",
    "authors": [
      "Yuanhong Zhang",
      "Muyao Yuan",
      "Weizhan Zhang",
      "Tieliang Gong",
      "Wen Wen",
      "Jiangyong Ying",
      "Weijie Shi"
    ],
    "abstract": "The Segment Anything Model (SAM), a vision foundation model, exhibits\nimpressive zero-shot capabilities in general tasks but struggles in specialized\ndomains. Parameter-efficient fine-tuning (PEFT) is a promising approach to\nunleash the potential of SAM in novel scenarios. However, existing PEFT methods\nfor SAM neglect the domain-invariant relations encoded in the pre-trained\nmodel. To bridge this gap, we propose InfoSAM, an information-theoretic\napproach that enhances SAM fine-tuning by distilling and preserving its\npre-trained segmentation knowledge. Specifically, we formulate the knowledge\ntransfer process as two novel mutual information-based objectives: (i) to\ncompress the domain-invariant relation extracted from pre-trained SAM,\nexcluding pseudo-invariant information as possible, and (ii) to maximize mutual\ninformation between the relational knowledge learned by the teacher\n(pre-trained SAM) and the student (fine-tuned model). The proposed InfoSAM\nestablishes a robust distillation framework for PEFT of SAM. Extensive\nexperiments across diverse benchmarks validate InfoSAM's effectiveness in\nimproving SAM family's performance on real-world tasks, demonstrating its\nadaptability and superiority in handling specialized scenarios.",
    "pdf_url": "http://arxiv.org/pdf/2505.21920v2",
    "published": "2025-05-28T03:09:22+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.21919v1",
    "title": "Towards Efficient Key-Value Cache Management for Prefix Prefilling in LLM Inference",
    "authors": [
      "Yue Zhu",
      "Hao Yu",
      "Chen Wang",
      "Zhuoran Liu",
      "Eun Kyung Lee"
    ],
    "abstract": "The increasing adoption of large language models (LLMs) with extended context\nwindows necessitates efficient Key-Value Cache (KVC) management to optimize\ninference performance. Inference workloads like Retrieval-Augmented Generation\n(RAG) and agents exhibit high cache reusability, making efficient caching\ncritical to reducing redundancy and improving speed. We analyze real-world KVC\naccess patterns using publicly available traces and evaluate commercial\nkey-value stores like Redis and state-of-the-art RDMA-based systems (CHIME [1]\nand Sherman [2]) for KVC metadata management. Our work demonstrates the lack of\ntailored storage solution for KVC prefilling, underscores the need for an\nefficient distributed caching system with optimized metadata management for LLM\nworkloads, and provides insights into designing improved KVC management systems\nfor scalable, low-latency inference.",
    "pdf_url": "http://arxiv.org/pdf/2505.21919v1",
    "published": "2025-05-28T03:05:55+00:00",
    "categories": [
      "cs.ET",
      "cs.AI",
      "cs.DC"
    ],
    "primary_category": "cs.ET"
  },
  {
    "id": "http://arxiv.org/abs/2505.21918v1",
    "title": "Self-supervised Learning Method Using Transformer for Multi-dimensional Sensor Data Processing",
    "authors": [
      "Haruki Kai",
      "Tsuyoshi Okita"
    ],
    "abstract": "We developed a deep learning algorithm for human activity recognition using\nsensor signals as input. In this study, we built a pretrained language model\nbased on the Transformer architecture, which is widely used in natural language\nprocessing. By leveraging this pretrained model, we aimed to improve\nperformance on the downstream task of human activity recognition. While this\ntask can be addressed using a vanilla Transformer, we propose an enhanced\nn-dimensional numerical processing Transformer that incorporates three key\nfeatures: embedding n-dimensional numerical data through a linear layer,\nbinning-based pre-processing, and a linear transformation in the output layer.\nWe evaluated the effectiveness of our proposed model across five different\ndatasets. Compared to the vanilla Transformer, our model demonstrated 10%-15%\nimprovements in accuracy.",
    "pdf_url": "http://arxiv.org/pdf/2505.21918v1",
    "published": "2025-05-28T03:04:13+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.21917v1",
    "title": "Structured Divide-and-Conquer for the Definite Generalized Eigenvalue Problem",
    "authors": [
      "James Demmel",
      "Ioana Dumitriu",
      "Ryan Schneider"
    ],
    "abstract": "This paper presents a fast, randomized divide-and-conquer algorithm for the\ndefinite generalized eigenvalue problem, which corresponds to pencils $(A,B)$\nin which $A$ and $B$ are Hermitian and the Crawford number $\\gamma(A,B) =\n\\min_{||x||_2 = 1} |x^H(A+iB)x|$ is positive. Adapted from the fastest known\nmethod for diagonalizing arbitrary matrix pencils [Foundations of Computational\nMathematics 2024], the algorithm is both inverse-free and highly parallel. As\nin the general case, randomization takes the form of perturbations applied to\nthe input matrices, which regularize the problem for compatibility with fast,\ndivide-and-conquer eigensolvers -- i.e., the now well-established phenomenon of\npseudospectral shattering. We demonstrate that this high-level approach to\ndiagonalization can be executed in a structure-aware fashion by (1) extending\npseudospectral shattering to definite pencils under structured perturbations\n(either random diagonal or sampled from the Gaussian Unitary Ensemble) and (2)\nformulating the divide-and-conquer procedure in a way that maintains\ndefiniteness. The result is a specialized solver whose complexity, when applied\nto definite pencils, is provably lower than that of general divide-and-conquer.",
    "pdf_url": "http://arxiv.org/pdf/2505.21917v1",
    "published": "2025-05-28T03:04:06+00:00",
    "categories": [
      "math.NA",
      "cs.NA",
      "15A22, 15B57, 65F15"
    ],
    "primary_category": "math.NA"
  },
  {
    "id": "http://arxiv.org/abs/2505.21916v1",
    "title": "Mastering Agile Tasks with Limited Trials",
    "authors": [
      "Yihang Hu",
      "Pingyue Sheng",
      "Shengjie Wang",
      "Yang Gao"
    ],
    "abstract": "Embodied robots nowadays can already handle many real-world manipulation\ntasks. However, certain other real-world tasks (e.g., shooting a basketball\ninto a hoop) are highly agile and require high execution precision, presenting\nadditional challenges for methods primarily designed for quasi-static\nmanipulation tasks. This leads to increased efforts in costly data collection,\nlaborious reward design, or complex motion planning. Such tasks, however, are\nfar less challenging for humans. Say a novice basketball player typically needs\nonly $\\sim$10 attempts to make their first successful shot, by roughly\nimitating a motion prior and then iteratively adjusting their motion based on\nthe past outcomes. Inspired by this human learning paradigm, we propose the\nAdaptive Diffusion Action Plannin (ADAP) algorithm, a simple & scalable\napproach which iteratively refines its action plan by few real-world trials\nwithin a learned prior motion pattern, until reaching a specific goal.\nExperiments demonstrated that ADAP can learn and accomplish a wide range of\ngoal-conditioned agile dynamic tasks with human-level precision and efficiency\ndirectly in real-world, such as throwing a basketball into the hoop in fewer\nthan 10 trials. Project website:https://adap-robotics.github.io/ .",
    "pdf_url": "http://arxiv.org/pdf/2505.21916v1",
    "published": "2025-05-28T03:03:38+00:00",
    "categories": [
      "cs.RO"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.22689v1",
    "title": "SlimLLM: Accurate Structured Pruning for Large Language Models",
    "authors": [
      "Jialong Guo",
      "Xinghao Chen",
      "Yehui Tang",
      "Yunhe Wang"
    ],
    "abstract": "Large language models(LLMs) have garnered significant attention and\ndemonstrated impressive capabilities in a wide range of applications. However,\ndue to their enormous computational costs, the deployment and application of\nLLMs are often severely limited. To address this issue, structured pruning is\nan effective solution to compress the parameters of LLMs. Determining the\nimportance of each sub-module in LLMs and minimizing performance loss are\ncritical issues that need to be carefully addressed in structured pruning. In\nthis paper, we propose an effective and fast structured pruning method named\nSlimLLM for large language models. For channel and attention head pruning, we\nevaluate the importance based on the entire channel or head, rather than merely\naggregating the importance of individual elements within a sub-module. This\napproach enables a more holistic consideration of the interdependence among\nelements within the sub-module. In addition, we design a simple linear\nregression strategy for the output matrix to quickly recover performance. We\nalso propose layer-based importance ratio to determine the pruning ratio for\neach layer. Based on the LLaMA benchmark results, our SlimLLM outperforms other\nmethods and achieves state-of-the-art performance.",
    "pdf_url": "http://arxiv.org/pdf/2505.22689v1",
    "published": "2025-05-28T03:01:28+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.21915v1",
    "title": "BD Open LULC Map: High-resolution land use land cover mapping & benchmarking for urban development in Dhaka, Bangladesh",
    "authors": [
      "Mir Sazzat Hossain",
      "Ovi Paul",
      "Md Akil Raihan Iftee",
      "Rakibul Hasan Rajib",
      "Abu Bakar Siddik Nayem",
      "Anis Sarker",
      "Arshad Momen",
      "Md. Ashraful Amin",
      "Amin Ahsan Ali",
      "AKM Mahbubur Rahman"
    ],
    "abstract": "Land Use Land Cover (LULC) mapping using deep learning significantly enhances\nthe reliability of LULC classification, aiding in understanding geography,\nsocioeconomic conditions, poverty levels, and urban sprawl. However, the\nscarcity of annotated satellite data, especially in South/East Asian developing\ncountries, poses a major challenge due to limited funding, diverse\ninfrastructures, and dense populations. In this work, we introduce the BD Open\nLULC Map (BOLM), providing pixel-wise LULC annotations across eleven classes\n(e.g., Farmland, Water, Forest, Urban Structure, Rural Built-Up) for Dhaka\nmetropolitan city and its surroundings using high-resolution Bing satellite\nimagery (2.22 m/pixel). BOLM spans 4,392 sq km (891 million pixels), with\nground truth validated through a three-stage process involving GIS experts. We\nbenchmark LULC segmentation using DeepLab V3+ across five major classes and\ncompare performance on Bing and Sentinel-2A imagery. BOLM aims to support\nreliable deep models and domain adaptation tasks, addressing critical LULC\ndataset gaps in South/East Asia.",
    "pdf_url": "http://arxiv.org/pdf/2505.21915v1",
    "published": "2025-05-28T03:00:03+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.21914v1",
    "title": "LiDARDustX: A LiDAR Dataset for Dusty Unstructured Road Environments",
    "authors": [
      "Chenfeng Wei",
      "Qi Wu",
      "Si Zuo",
      "Jiahua Xu",
      "Boyang Zhao",
      "Zeyu Yang",
      "Guotao Xie",
      "Shenhong Wang"
    ],
    "abstract": "Autonomous driving datasets are essential for validating the progress of\nintelligent vehicle algorithms, which include localization, perception, and\nprediction. However, existing datasets are predominantly focused on structured\nurban environments, which limits the exploration of unstructured and\nspecialized scenarios, particularly those characterized by significant dust\nlevels. This paper introduces the LiDARDustX dataset, which is specifically\ndesigned for perception tasks under high-dust conditions, such as those\nencountered in mining areas. The LiDARDustX dataset consists of 30,000 LiDAR\nframes captured by six different LiDAR sensors, each accompanied by 3D bounding\nbox annotations and point cloud semantic segmentation. Notably, over 80% of the\ndataset comprises dust-affected scenes. By utilizing this dataset, we have\nestablished a benchmark for evaluating the performance of state-of-the-art 3D\ndetection and segmentation algorithms. Additionally, we have analyzed the\nimpact of dust on perception accuracy and delved into the causes of these\neffects. The data and further information can be accessed at:\nhttps://github.com/vincentweikey/LiDARDustX.",
    "pdf_url": "http://arxiv.org/pdf/2505.21914v1",
    "published": "2025-05-28T02:59:19+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.21913v2",
    "title": "On the intracyclic instability in Stokes layers",
    "authors": [
      "Mengqi Zhang"
    ],
    "abstract": "Time-dependent fluid dynamics plays a crucial role in both natural phenomena\nand industrial applications. Understanding the flow instabilities and\ntransitions within these dynamical systems is essential for predicting and\ncontrolling their unsteady behaviour. A classic example of time-dependent flow\nis the Stokes layer. To study the transition mechanism in this flow, we employ\nthe Finite-Time Lyapunov Exponent (FTLE) to demonstrate that a linear energy\namplification mechanism may explain the intracyclic instability in the\ntransitional Stokes layer, supported by favourable comparisons with\nexperimental measurements of axial turbulence intensity. This complements\nexisting theories applied to the Stokes layer in the literature, including the\nFloquet analysis and the instantaneous/momentary analyses, which have struggled\nto capture this experimental observation accurately. The FTLE analysis is\nclosely related to the transient growth analysis, formulated as an optimisation\nproblem of the disturbance energy growth over time. We found that the energy\namplification weakens as the finite Stokes layer becomes more confined and the\noscillating frequency has a non-monotonic effect on the maximum transient\ngrowth. Based on these results, we recommend future experimental studies to\nvalidate this linear mechanism.",
    "pdf_url": "http://arxiv.org/pdf/2505.21913v2",
    "published": "2025-05-28T02:59:00+00:00",
    "categories": [
      "physics.flu-dyn"
    ],
    "primary_category": "physics.flu-dyn"
  },
  {
    "id": "http://arxiv.org/abs/2505.21912v1",
    "title": "Detecting Cultural Differences in News Video Thumbnails via Computational Aesthetics",
    "authors": [
      "Marvin Limpijankit",
      "John Kender"
    ],
    "abstract": "We propose a two-step approach for detecting differences in the style of\nimages across sources of differing cultural affinity, where images are first\nclustered into finer visual themes based on content before their aesthetic\nfeatures are compared. We test this approach on 2,400 YouTube video thumbnails\ntaken equally from two U.S. and two Chinese YouTube channels, and relating\nequally to COVID-19 and the Ukraine conflict. Our results suggest that while\nChinese thumbnails are less formal and more candid, U.S. channels tend to use\nmore deliberate, proper photographs as thumbnails. In particular, U.S.\nthumbnails are less colorful, more saturated, darker, more finely detailed,\nless symmetric, sparser, less varied, and more up close and personal than\nChinese thumbnails. We suggest that most of these differences reflect cultural\npreferences, and that our methods and observations can serve as a baseline\nagainst which suspected visual propaganda can be computed and compared.",
    "pdf_url": "http://arxiv.org/pdf/2505.21912v1",
    "published": "2025-05-28T02:58:41+00:00",
    "categories": [
      "cs.CY",
      "cs.CV"
    ],
    "primary_category": "cs.CY"
  },
  {
    "id": "http://arxiv.org/abs/2505.21911v1",
    "title": "AlignGen: Boosting Personalized Image Generation with Cross-Modality Prior Alignment",
    "authors": [
      "Yiheng Lin",
      "Shifang Zhao",
      "Ting Liu",
      "Xiaochao Qu",
      "Luoqi Liu",
      "Yao Zhao",
      "Yunchao Wei"
    ],
    "abstract": "Personalized image generation aims to integrate user-provided concepts into\ntext-to-image models, enabling the generation of customized content based on a\ngiven prompt. Recent zero-shot approaches, particularly those leveraging\ndiffusion transformers, incorporate reference image information through\nmulti-modal attention mechanism. This integration allows the generated output\nto be influenced by both the textual prior from the prompt and the visual prior\nfrom the reference image. However, we observe that when the prompt and\nreference image are misaligned, the generated results exhibit a stronger bias\ntoward the textual prior, leading to a significant loss of reference content.\nTo address this issue, we propose AlignGen, a Cross-Modality Prior Alignment\nmechanism that enhances personalized image generation by: 1) introducing a\nlearnable token to bridge the gap between the textual and visual priors, 2)\nincorporating a robust training strategy to ensure proper prior alignment, and\n3) employing a selective cross-modal attention mask within the multi-modal\nattention mechanism to further align the priors. Experimental results\ndemonstrate that AlignGen outperforms existing zero-shot methods and even\nsurpasses popular test-time optimization approaches.",
    "pdf_url": "http://arxiv.org/pdf/2505.21911v1",
    "published": "2025-05-28T02:57:55+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.21910v1",
    "title": "Taming Transformer Without Using Learning Rate Warmup",
    "authors": [
      "Xianbiao Qi",
      "Yelin He",
      "Jiaquan Ye",
      "Chun-Guang Li",
      "Bojia Zi",
      "Xili Dai",
      "Qin Zou",
      "Rong Xiao"
    ],
    "abstract": "Scaling Transformer to a large scale without using some technical tricks such\nas learning rate warump and using an obviously lower learning rate is an\nextremely challenging task, and is increasingly gaining more attention. In this\npaper, we provide a theoretical analysis for the process of training\nTransformer and reveal the rationale behind the model crash phenomenon in the\ntraining process, termed \\textit{spectral energy concentration} of\n${\\bW_q}^{\\top} \\bW_k$, which is the reason for a malignant entropy collapse,\nwhere ${\\bW_q}$ and $\\bW_k$ are the projection matrices for the query and the\nkey in Transformer, respectively. To remedy this problem, motivated by\n\\textit{Weyl's Inequality}, we present a novel optimization strategy, \\ie,\nmaking the weight updating in successive steps smooth -- if the ratio\n$\\frac{\\sigma_{1}(\\nabla \\bW_t)}{\\sigma_{1}(\\bW_{t-1})}$ is larger than a\nthreshold, we will automatically bound the learning rate to a weighted multiple\nof $\\frac{\\sigma_{1}(\\bW_{t-1})}{\\sigma_{1}(\\nabla \\bW_t)}$, where $\\nabla\n\\bW_t$ is the updating quantity in step $t$. Such an optimization strategy can\nprevent spectral energy concentration to only a few directions, and thus can\navoid malignant entropy collapse which will trigger the model crash. We conduct\nextensive experiments using ViT, Swin-Transformer and GPT, showing that our\noptimization strategy can effectively and stably train these Transformers\nwithout using learning rate warmup.",
    "pdf_url": "http://arxiv.org/pdf/2505.21910v1",
    "published": "2025-05-28T02:55:28+00:00",
    "categories": [
      "cs.LG",
      "cs.CV"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.21909v2",
    "title": "Causal Inference for Experiments with Latent Outcomes: Key Results and Their Implications for Design and Analysis",
    "authors": [
      "Jiawei Fu",
      "Donald P. Green"
    ],
    "abstract": "How should researchers analyze randomized experiments in which the main\noutcome is measured in multiple ways but each measure contains some degree of\nerror? We describe modeling approaches that enable researchers to identify\ncausal parameters of interest, suggest ways that experimental designs can be\naugmented so as to make linear latent variable models more credible, and\ndiscuss empirical tests of key modeling assumptions. We show that when\nexperimental researchers invest appropriately in multiple outcome measures, an\noptimally weighted index of the outcome measures enables researchers to obtain\nefficient and interpretable estimates of causal parameters by applying standard\nregression methods, and that weights may be obtained using instrumental\nvariables regression. Maximum likelihood and generalized method of moments\nestimators can be used to obtain estimates and standard errors in a single\nstep. An empirical application illustrates the gains in precision and\nrobustness that multiple outcome measures can provide.",
    "pdf_url": "http://arxiv.org/pdf/2505.21909v2",
    "published": "2025-05-28T02:54:45+00:00",
    "categories": [
      "econ.EM",
      "stat.AP",
      "stat.ME"
    ],
    "primary_category": "econ.EM"
  },
  {
    "id": "http://arxiv.org/abs/2505.21908v1",
    "title": "Reinforcement Learning for Out-of-Distribution Reasoning in LLMs: An Empirical Study on Diagnosis-Related Group Coding",
    "authors": [
      "Hanyin Wang",
      "Zhenbang Wu",
      "Gururaj Kolar",
      "Hariprasad Korsapati",
      "Brian Bartlett",
      "Bryan Hull",
      "Jimeng Sun"
    ],
    "abstract": "Diagnosis-Related Group (DRG) codes are essential for hospital reimbursement\nand operations but require labor-intensive assignment. Large Language Models\n(LLMs) struggle with DRG coding due to the out-of-distribution (OOD) nature of\nthe task: pretraining corpora rarely contain private clinical or billing data.\nWe introduce DRG-Sapphire, which uses large-scale reinforcement learning (RL)\nfor automated DRG coding from clinical notes. Built on Qwen2.5-7B and trained\nwith Group Relative Policy Optimization (GRPO) using rule-based rewards,\nDRG-Sapphire introduces a series of RL enhancements to address domain-specific\nchallenges not seen in previous mathematical tasks. Our model achieves\nstate-of-the-art accuracy on the MIMIC-IV benchmark and generates\nphysician-validated reasoning for DRG assignments, significantly enhancing\nexplainability. Our study further sheds light on broader challenges of applying\nRL to knowledge-intensive, OOD tasks. We observe that RL performance scales\napproximately linearly with the logarithm of the number of supervised\nfine-tuning (SFT) examples, suggesting that RL effectiveness is fundamentally\nconstrained by the domain knowledge encoded in the base model. For OOD tasks\nlike DRG coding, strong RL performance requires sufficient knowledge infusion\nprior to RL. Consequently, scaling SFT may be more effective and\ncomputationally efficient than scaling RL alone for such tasks.",
    "pdf_url": "http://arxiv.org/pdf/2505.21908v1",
    "published": "2025-05-28T02:54:07+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.21907v2",
    "title": "Modeling and Optimizing User Preferences in AI Copilots: A Comprehensive Survey and Taxonomy",
    "authors": [
      "Saleh Afzoon",
      "Zahra Jahanandish",
      "Phuong Thao Huynh",
      "Amin Beheshti",
      "Usman Naseem"
    ],
    "abstract": "AI copilots represent a new generation of AI-powered systems designed to\nassist users, particularly knowledge workers and developers, in complex,\ncontext-rich tasks. As these systems become more embedded in daily workflows,\npersonalization has emerged as a critical factor for improving usability,\neffectiveness, and user satisfaction. Central to this personalization is\npreference optimization: the system's ability to detect, interpret, and align\nwith individual user preferences. While prior work in intelligent assistants\nand optimization algorithms is extensive, their intersection within AI copilots\nremains underexplored. This survey addresses that gap by examining how user\npreferences are operationalized in AI copilots. We investigate how preference\nsignals are sourced, modeled across different interaction stages, and refined\nthrough feedback loops. Building on a comprehensive literature review, we\ndefine the concept of an AI copilot and introduce a taxonomy of preference\noptimization techniques across pre-, mid-, and post-interaction phases. Each\ntechnique is evaluated in terms of advantages, limitations, and design\nimplications. By consolidating fragmented efforts across AI personalization,\nhuman-AI interaction, and language model adaptation, this work offers both a\nunified conceptual foundation and a practical design perspective for building\nuser-aligned, persona-aware AI copilots that support end-to-end adaptability\nand deployment.",
    "pdf_url": "http://arxiv.org/pdf/2505.21907v2",
    "published": "2025-05-28T02:52:39+00:00",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.HC"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2506.00041v2",
    "title": "Decoding Dense Embeddings: Sparse Autoencoders for Interpreting and Discretizing Dense Retrieval",
    "authors": [
      "Seongwan Park",
      "Taeklim Kim",
      "Youngjoong Ko"
    ],
    "abstract": "Despite their strong performance, Dense Passage Retrieval (DPR) models suffer\nfrom a lack of interpretability. In this work, we propose a novel\ninterpretability framework that leverages Sparse Autoencoders (SAEs) to\ndecompose previously uninterpretable dense embeddings from DPR models into\ndistinct, interpretable latent concepts. We generate natural language\ndescriptions for each latent concept, enabling human interpretations of both\nthe dense embeddings and the query-document similarity scores of DPR models. We\nfurther introduce Concept-Level Sparse Retrieval (CL-SR), a retrieval framework\nthat directly utilizes the extracted latent concepts as indexing units. CL-SR\neffectively combines the semantic expressiveness of dense embeddings with the\ntransparency and efficiency of sparse representations. We show that CL-SR\nachieves high index-space and computational efficiency while maintaining robust\nperformance across vocabulary and semantic mismatches.",
    "pdf_url": "http://arxiv.org/pdf/2506.00041v2",
    "published": "2025-05-28T02:50:17+00:00",
    "categories": [
      "cs.IR",
      "cs.LG"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2505.21906v2",
    "title": "ChatVLA-2: Vision-Language-Action Model with Open-World Embodied Reasoning from Pretrained Knowledge",
    "authors": [
      "Zhongyi Zhou",
      "Yichen Zhu",
      "Junjie Wen",
      "Chaomin Shen",
      "Yi Xu"
    ],
    "abstract": "Vision-language-action (VLA) models have emerged as the next generation of\nmodels in robotics. However, despite leveraging powerful pre-trained\nVision-Language Models (VLMs), existing end-to-end VLA systems often lose key\ncapabilities during fine-tuning as the model adapts to specific robotic tasks.\nWe argue that a generalizable VLA model should retain and expand upon the VLM's\ncore competencies: 1) Open-world embodied reasoning - the VLA should inherit\nthe knowledge from VLM, i.e., recognize anything that the VLM can recognize, be\ncapable of solving math problems, and possess visual-spatial intelligence, 2)\nReasoning following - effectively translating the open-world reasoning into\nactionable steps for the robot. In this work, we introduce ChatVLA-2, a novel\nmixture-of-expert VLA model coupled with a specialized two-stage training\npipeline designed to preserve the VLM's original strengths while enabling\nactionable reasoning. To validate our approach, we design a math-matching task\nwherein a robot interprets math problems written on a whiteboard and picks\ncorresponding number cards from a table to solve equations. Remarkably, our\nmethod exhibits exceptional mathematical reasoning and OCR capabilities,\ndespite these abilities not being explicitly trained within the VLA.\nFurthermore, we demonstrate that the VLA possesses strong spatial reasoning\nskills, enabling it to interpret novel directional instructions involving\npreviously unseen objects. Overall, our method showcases reasoning and\ncomprehension abilities that significantly surpass state-of-the-art imitation\nlearning methods such as OpenVLA, DexVLA, and pi-zero. This work represents a\nsubstantial advancement toward developing truly generalizable robotic\nfoundation models endowed with robust reasoning capacities.",
    "pdf_url": "http://arxiv.org/pdf/2505.21906v2",
    "published": "2025-05-28T02:48:42+00:00",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.21905v1",
    "title": "Reference-Guided Identity Preserving Face Restoration",
    "authors": [
      "Mo Zhou",
      "Keren Ye",
      "Viraj Shah",
      "Kangfu Mei",
      "Mauricio Delbracio",
      "Peyman Milanfar",
      "Vishal M. Patel",
      "Hossein Talebi"
    ],
    "abstract": "Preserving face identity is a critical yet persistent challenge in\ndiffusion-based image restoration. While reference faces offer a path forward,\nexisting reference-based methods often fail to fully exploit their potential.\nThis paper introduces a novel approach that maximizes reference face utility\nfor improved face restoration and identity preservation. Our method makes three\nkey contributions: 1) Composite Context, a comprehensive representation that\nfuses multi-level (high- and low-level) information from the reference face,\noffering richer guidance than prior singular representations. 2) Hard Example\nIdentity Loss, a novel loss function that leverages the reference face to\naddress the identity learning inefficiencies found in the existing identity\nloss. 3) A training-free method to adapt the model to multi-reference inputs\nduring inference. The proposed method demonstrably restores high-quality faces\nand achieves state-of-the-art identity preserving restoration on benchmarks\nsuch as FFHQ-Ref and CelebA-Ref-Test, consistently outperforming previous work.",
    "pdf_url": "http://arxiv.org/pdf/2505.21905v1",
    "published": "2025-05-28T02:46:34+00:00",
    "categories": [
      "cs.CV",
      "cs.MM"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.21904v3",
    "title": "CAST: Contrastive Adaptation and Distillation for Semi-Supervised Instance Segmentation",
    "authors": [
      "Pardis Taghavi",
      "Tian Liu",
      "Renjie Li",
      "Reza Langari",
      "Zhengzhong Tu"
    ],
    "abstract": "Instance segmentation demands costly per-pixel annotations and large models.\nWe introduce CAST, a semi-supervised knowledge distillation (SSKD) framework\nthat compresses pretrained vision foundation models (VFM) into compact experts\nusing limited labeled and abundant unlabeled data. CAST unfolds in three\nstages: (1) domain adaptation of the VFM teacher(s) via self-training with\ncontrastive pixel calibration, (2) distillation into a compact student via a\nunified multi-objective loss that couples standard supervision and\npseudo-labels with our instance-aware pixel-wise contrastive term, and (3)\nfine-tuning on labeled data to remove residual pseudo-label bias. Central to\nCAST is an \\emph{instance-aware pixel-wise contrastive loss} that fuses mask\nand class scores to mine informative negatives and enforce clear inter-instance\nmargins. By maintaining this contrastive signal across both adaptation and\ndistillation, we align teacher and student embeddings and fully leverage\nunlabeled images. On Cityscapes and ADE20K, our ~11X smaller student surpasses\nits adapted VFM teacher(s) by +3.4 AP (33.9 vs. 30.5) and +1.5 AP (16.7 vs.\n15.2) and outperforms state-of-the-art semi-supervised approaches.",
    "pdf_url": "http://arxiv.org/pdf/2505.21904v3",
    "published": "2025-05-28T02:45:42+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.21903v1",
    "title": "Enhanced Ideal Objective Vector Estimation for Evolutionary Multi-Objective Optimization",
    "authors": [
      "Ruihao Zheng",
      "Zhenkun Wang",
      "Yin Wu",
      "Maoguo Gong"
    ],
    "abstract": "The ideal objective vector, which comprises the optimal values of the $m$\nobjective functions in an $m$-objective optimization problem, is an important\nconcept in evolutionary multi-objective optimization. Accurate estimation of\nthis vector has consistently been a crucial task, as it is frequently used to\nguide the search process and normalize the objective space. Prevailing\nestimation methods all involve utilizing the best value concerning each\nobjective function achieved by the individuals in the current or accumulated\npopulation. However, this paper reveals that the population-based estimation\nmethod can only work on simple problems but falls short on problems with\nsubstantial bias. The biases in multi-objective optimization problems can be\ndivided into three categories, and an analysis is performed to illustrate how\neach category hinders the estimation of the ideal objective vector.\nSubsequently, a set of test instances is proposed to quantitatively evaluate\nthe impact of various biases on the ideal objective vector estimation method.\nBeyond that, a plug-and-play component called enhanced ideal objective vector\nestimation (EIE) is introduced for multi-objective evolutionary algorithms\n(MOEAs). EIE features adaptive and fine-grained searches over $m$ subproblems\ndefined by the extreme weighted sum method. EIE finally outputs $m$ solutions\nthat can well approximate the ideal objective vector. In the experiments, EIE\nis integrated into three representative MOEAs. To demonstrate the wide\napplicability of EIE, algorithms are tested not only on the newly proposed test\ninstances but also on existing ones. The results consistently show that EIE\nimproves the ideal objective vector estimation and enhances the MOEA's\nperformance.",
    "pdf_url": "http://arxiv.org/pdf/2505.21903v1",
    "published": "2025-05-28T02:36:45+00:00",
    "categories": [
      "cs.NE"
    ],
    "primary_category": "cs.NE"
  },
  {
    "id": "http://arxiv.org/abs/2505.21902v1",
    "title": "Rise Time and Charge Collection Efficiency of Graphene-Optimized 4H-SiC PIN Detector",
    "authors": [
      "Zhenyu Jiang",
      "Xuemei Lu",
      "Congcong Wang",
      "Yingjie Huang",
      "Xiaoshen Kang",
      "Suyu Xiao",
      "Xiyuan Zhang",
      "Xin Shi"
    ],
    "abstract": "Silicon carbide detectors exhibit good detection performance and are being\nconsidered for detection applications. However, the presence of surface\nelectrode of detector limits the application of low-penetration particle\ndetectors, photodetectors and heavy-ion detection. A graphene-optimized 4H-SiC\ndetector has been fabricated to expand the application of SiC detectors.Its\nelectrical properties and the charge collection performance of {\\alpha}\nparticles are reported. The effective doping concentration of lightly doped\n4H-SiC epitaxial layer is about 4.5\\times10^{13}cm^{-3}, approaching the limit\nof the lowest doping level by the SiC epitaxial growth technique. The rise time\nof the graphene-optimized ring electrode detector is reduced by 24% at 200 V,\ncompared to ring electrode detector. The charge collection efficiency (CCE) of\ngraphene-optimized 4H-SiC PIN is 99.22%. When the irradiation dose is\n2\\times10^{11} n_{eq}/cm^2, the irradiation has no significant impact on the\nrise time and uniformity of the rise time for the graphene-optimized 4H-SiC\ndetectors. This study proves that graphene has a certain radiation resistance.\nGraphene-optimized 4H-SiC detectors can not only reduce the signal rise time,\nbut also improve uniformity of signal rise time and stability of charge\ncollection. This research will expand the application of graphene-based 4H-SiC\ndetectors in fields such as low energy ions, X-ray, UV light detection,\nparticle physics, medical dosimetry and heavy-ion detection.",
    "pdf_url": "http://arxiv.org/pdf/2505.21902v1",
    "published": "2025-05-28T02:31:58+00:00",
    "categories": [
      "physics.ins-det"
    ],
    "primary_category": "physics.ins-det"
  },
  {
    "id": "http://arxiv.org/abs/2505.21901v1",
    "title": "Symbolically Regressing Fish Biomass Spectral Data: A Linear Genetic Programming Method with Tunable Primitives",
    "authors": [
      "Zhixing Huang",
      "Bing Xue",
      "Mengjie Zhang",
      "Jeremy S. Ronney",
      "Keith C. Gordon",
      "Daniel P. Killeen"
    ],
    "abstract": "Machine learning techniques play an important role in analyzing spectral\ndata. The spectral data of fish biomass is useful in fish production, as it\ncarries many important chemistry properties of fish meat. However, it is\nchallenging for existing machine learning techniques to comprehensively\ndiscover hidden patterns from fish biomass spectral data since the spectral\ndata often have a lot of noises while the training data are quite limited. To\nbetter analyze fish biomass spectral data, this paper models it as a symbolic\nregression problem and solves it by a linear genetic programming method with\nnewly proposed tunable primitives. In the symbolic regression problem, linear\ngenetic programming automatically synthesizes regression models based on the\ngiven primitives and training data. The tunable primitives further improve the\napproximation ability of the regression models by tuning their inherent\ncoefficients. Our empirical results over ten fish biomass targets show that the\nproposed method improves the overall performance of fish biomass composition\nprediction. The synthesized regression models are compact and have good\ninterpretability, which allow us to highlight useful features over the\nspectrum. Our further investigation also verifies the good generality of the\nproposed method across various spectral data treatments and other symbolic\nregression problems.",
    "pdf_url": "http://arxiv.org/pdf/2505.21901v1",
    "published": "2025-05-28T02:27:49+00:00",
    "categories": [
      "cs.NE"
    ],
    "primary_category": "cs.NE"
  },
  {
    "id": "http://arxiv.org/abs/2505.21900v2",
    "title": "Ubiquitous Asymptotic Robustness in Biochemical Systems",
    "authors": [
      "Hyukpyo Hong",
      "Diego Rojas La Luz",
      "Gheorghe Craciun"
    ],
    "abstract": "Living systems maintain stable internal states despite environmental\nfluctuations. Absolute concentration robustness (ACR) is a striking homeostatic\nphenomenon in which the steady-state concentration of a molecular species\nremains invariant to changes in total molecular supply. Although experimental\nstudies have reported approximate-but not exact-robustness in steady-state\nconcentrations, such behavior has often been attributed to exact ACR motifs\nperturbed by measurement noise or minor side reactions, rather than recognized\nas a structural property of the network itself. In this work, we highlight a\npreviously underappreciated phenomenon, which we term asymptotic ACR (aACR):\napproximate robustness can emerge solely from the architecture of the reaction\nnetwork, without requiring parameters being negligible or the presence of an\nexact ACR motif. We find that aACR is far more common than classical ACR, as\ndemonstrated in systems such as the Escherichia coli EnvZ-OmpR system and MAPK\nsignaling cascade. Furthermore, we mathematically prove that such ubiquity\nstems solely from network structure. Finally, we reveal a counterintuitive\nfeature of aACR in systems with multiple conserved quantities, revealing subtle\ndistinctions in how robustness manifests in complex biochemical networks.",
    "pdf_url": "http://arxiv.org/pdf/2505.21900v2",
    "published": "2025-05-28T02:27:34+00:00",
    "categories": [
      "math.DS",
      "q-bio.QM",
      "37N25 (Primary) 34E18, 92B99 (Secondary)"
    ],
    "primary_category": "math.DS"
  },
  {
    "id": "http://arxiv.org/abs/2505.21899v1",
    "title": "Joint$Œª$: Orchestrating Serverless Workflows on Jointcloud FaaS Systems",
    "authors": [
      "Jianfei Liu",
      "Rui Li",
      "Zhilin Yang",
      "Peichang Shi",
      "Guodong Yi",
      "Huaimin Wang"
    ],
    "abstract": "Existing serverless workflow orchestration systems are predominantly designed\nfor a single-cloud FaaS system, leading to vendor lock-in. This restricts\nperformance optimization, cost reduction, and availability of applications.\nHowever, orchestrating serverless workflows on Jointcloud FaaS systems faces\ntwo main challenges: 1) Additional overhead caused by centralized cross-cloud\norchestration; and 2) A lack of reliable failover and fault-tolerant mechanisms\nfor cross-cloud serverless workflows. To address these challenges, we propose\nJoint$\\lambda$, a distributed runtime system designed to orchestrate serverless\nworkflows on multiple FaaS systems without relying on a centralized\norchestrator. Joint$\\lambda$ introduces a compatibility layer, Backend-Shim,\nleveraging inter-cloud heterogeneity to optimize makespan and reduce costs with\non-demand billing. By using function-side orchestration instead of centralized\nnodes, it enables independent function invocations and data transfers, reducing\ncross-cloud communication overhead. For high availability, it ensures\nexactly-once execution via datastores and failover mechanisms for serverless\nworkflows on Jointcloud FaaS systems. We validate Joint$\\lambda$ on two\nheterogeneous FaaS systems, AWS and ALiYun, with four workflows. Compared to\nthe most advanced commercial orchestration services for single-cloud serverless\nworkflows, Joint$\\lambda$ reduces up to 3.3$\\times$ latency, saving up to 65\\%\ncost. Joint$\\lambda$ is also faster than the state-of-the-art orchestrators for\ncross-cloud serverless workflows up to 4.0$\\times$, reducing up to 4.5$\\times$\ncost and providing strong execution guarantees.",
    "pdf_url": "http://arxiv.org/pdf/2505.21899v1",
    "published": "2025-05-28T02:24:12+00:00",
    "categories": [
      "cs.DC"
    ],
    "primary_category": "cs.DC"
  },
  {
    "id": "http://arxiv.org/abs/2505.21898v1",
    "title": "Co-Saving: Resource Aware Multi-Agent Collaboration for Software Development",
    "authors": [
      "Rennai Qiu",
      "Chen Qian",
      "Ran Li",
      "Yufan Dang",
      "Weize Chen",
      "Cheng Yang",
      "Yingli Zhang",
      "Ye Tian",
      "Xuantang Xiong",
      "Lei Han",
      "Zhiyuan Liu",
      "Maosong Sun"
    ],
    "abstract": "Recent advancements in Large Language Models (LLMs) and autonomous agents\nhave demonstrated remarkable capabilities across various domains. However,\nstandalone agents frequently encounter limitations when handling complex tasks\nthat demand extensive interactions and substantial computational resources.\nAlthough Multi-Agent Systems (MAS) alleviate some of these limitations through\ncollaborative mechanisms like task decomposition, iterative communication, and\nrole specialization, they typically remain resource-unaware, incurring\nsignificant inefficiencies due to high token consumption and excessive\nexecution time. To address these limitations, we propose a resource-aware\nmulti-agent system -- Co-Saving (meaning that multiple agents collaboratively\nengage in resource-saving activities), which leverages experiential knowledge\nto enhance operational efficiency and solution quality. Our key innovation is\nthe introduction of \"shortcuts\" -- instructional transitions learned from\nhistorically successful trajectories -- which allows to bypass redundant\nreasoning agents and expedite the collective problem-solving process.\nExperiments for software development tasks demonstrate significant advantages\nover existing methods. Specifically, compared to the state-of-the-art MAS\nChatDev, our method achieves an average reduction of 50.85% in token usage, and\nimproves the overall code quality by 10.06%.",
    "pdf_url": "http://arxiv.org/pdf/2505.21898v1",
    "published": "2025-05-28T02:23:53+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.MA",
      "cs.SE"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.02014v1",
    "title": "Research on Driving Scenario Technology Based on Multimodal Large Lauguage Model Optimization",
    "authors": [
      "Wang Mengjie",
      "Zhu Huiping",
      "Li Jian",
      "Shi Wenxiu",
      "Zhang Song"
    ],
    "abstract": "With the advancement of autonomous and assisted driving technologies, higher\ndemands are placed on the ability to understand complex driving scenarios.\nMultimodal general large models have emerged as a solution for this challenge.\nHowever, applying these models in vertical domains involves difficulties such\nas data collection, model training, and deployment optimization. This paper\nproposes a comprehensive method for optimizing multimodal models in driving\nscenarios, including cone detection, traffic light recognition, speed limit\nrecommendation, and intersection alerts. The method covers key aspects such as\ndynamic prompt optimization, dataset construction, model training, and\ndeployment. Specifically, the dynamic prompt optimization adjusts the prompts\nbased on the input image content to focus on objects affecting the ego vehicle,\nenhancing the model's task-specific focus and judgment capabilities. The\ndataset is constructed by combining real and synthetic data to create a\nhigh-quality and diverse multimodal training dataset, improving the model's\ngeneralization in complex driving environments. In model training, advanced\ntechniques like knowledge distillation, dynamic fine-tuning, and quantization\nare integrated to reduce storage and computational costs while boosting\nperformance. Experimental results show that this systematic optimization method\nnot only significantly improves the model's accuracy in key tasks but also\nachieves efficient resource utilization, providing strong support for the\npractical application of driving scenario perception technologies.",
    "pdf_url": "http://arxiv.org/pdf/2506.02014v1",
    "published": "2025-05-28T02:22:11+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.21897v1",
    "title": "Concentrate on Weakness: Mining Hard Prototypes for Few-Shot Medical Image Segmentation",
    "authors": [
      "Jianchao Jiang",
      "Haofeng Zhang"
    ],
    "abstract": "Few-Shot Medical Image Segmentation (FSMIS) has been widely used to train a\nmodel that can perform segmentation from only a few annotated images. However,\nmost existing prototype-based FSMIS methods generate multiple prototypes from\nthe support image solely by random sampling or local averaging, which can cause\nparticularly severe boundary blurring due to the tendency for normal features\naccounting for the majority of features of a specific category. Consequently,\nwe propose to focus more attention to those weaker features that are crucial\nfor clear segmentation boundary. Specifically, we design a Support\nSelf-Prediction (SSP) module to identify such weak features by comparing true\nsupport mask with one predicted by global support prototype. Then, a Hard\nPrototypes Generation (HPG) module is employed to generate multiple hard\nprototypes based on these weak features. Subsequently, a Multiple Similarity\nMaps Fusion (MSMF) module is devised to generate final segmenting mask in a\ndual-path fashion to mitigate the imbalance between foreground and background\nin medical images. Furthermore, we introduce a boundary loss to further\nconstraint the edge of segmentation. Extensive experiments on three publicly\navailable medical image datasets demonstrate that our method achieves\nstate-of-the-art performance. Code is available at\nhttps://github.com/jcjiang99/CoW.",
    "pdf_url": "http://arxiv.org/pdf/2505.21897v1",
    "published": "2025-05-28T02:22:05+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.23821v2",
    "title": "SpeechVerifier: Robust Acoustic Fingerprint against Tampering Attacks via Watermarking",
    "authors": [
      "Lingfeng Yao",
      "Chenpei Huang",
      "Shengyao Wang",
      "Junpei Xue",
      "Hanqing Guo",
      "Jiang Liu",
      "Xun Chen",
      "Miao Pan"
    ],
    "abstract": "With the surge of social media, maliciously tampered public speeches,\nespecially those from influential figures, have seriously affected social\nstability and public trust. Existing speech tampering detection methods remain\ninsufficient: they either rely on external reference data or fail to be both\nsensitive to attacks and robust to benign operations, such as compression and\nresampling. To tackle these challenges, we introduce SpeechVerifer to\nproactively verify speech integrity using only the published speech itself,\ni.e., without requiring any external references. Inspired by audio\nfingerprinting and watermarking, SpeechVerifier can (i) effectively detect\ntampering attacks, (ii) be robust to benign operations and (iii) verify the\nintegrity only based on published speeches. Briefly, SpeechVerifier utilizes\nmultiscale feature extraction to capture speech features across different\ntemporal resolutions. Then, it employs contrastive learning to generate\nfingerprints that can detect modifications at varying granularities. These\nfingerprints are designed to be robust to benign operations, but exhibit\nsignificant changes when malicious tampering occurs. To enable speech\nverification in a self-contained manner, the generated fingerprints are then\nembedded into the speech signal by segment-wise watermarking. Without external\nreferences, SpeechVerifier can retrieve the fingerprint from the published\naudio and check it with the embedded watermark to verify the integrity of the\nspeech. Extensive experimental results demonstrate that the proposed\nSpeechVerifier is effective in detecting tampering attacks and robust to benign\noperations.",
    "pdf_url": "http://arxiv.org/pdf/2505.23821v2",
    "published": "2025-05-28T02:20:33+00:00",
    "categories": [
      "cs.CR",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2505.21896v2",
    "title": "Theory of itinerant collisional spin dynamics in nondegenerate molecular gases",
    "authors": [
      "Reuben R. W. Wang",
      "John L. Bohn"
    ],
    "abstract": "We study the fully itinerant dynamics of ultracold but nondegenerate polar\nmolecules with a spin-$1/2$ degree of freedom encoded into two of their\nelectric field dressed rotational states. Center of mass molecular motion is\nconstrained to two-dimensions via tight confinement with a one-dimensional\noptical lattice, but remains mostly unconstrained within the plane. The\npseudospins can become entangled through ultracold dipolar collisions, for\nwhich the locality of interactions is greatly relaxed by free molecular motion.\nAt the level of single-molecule observables, collision-induced entanglement\nmanifests as spin decoherence, for which our theoretical calculations serve\nwell to describe recent Ramsey contrast measurements of quasi-2D confined KRb\nmolecules at JILA [A. Carroll et al., Science 388 6745 (2025)]. In presenting a\nmore detailed theoretical analysis of the KRb experiment, we highlight a key\nfinding that molecular loss enhanced by particle exchange symmetry can lead to\na suppression of collective spin decoherence, a mechanism with refer to as\n``loss-induced quantum autoselection\". We then show that by utilizing bialkali\nspecies with sufficiently large dipole moments, loss can be near completely\nsuppressed in all collision channels via electric field tunable\nconfinement-induced collisional shielding. The afforded collisional stability\npermits fully coherent spin mixing dynamics, natively realizing unitary circuit\ndynamics with random all-to-all connectivity and U(1) charge conservation. This\nwork establishes a bridge between the domains of ultracold molecular collisions\nand many-body spin physics, ultimately proposing the use of nondegenerate bulk\nmolecular gases as a controllable platform for nonequilibrium explorations of\nitinerant quantum matter.",
    "pdf_url": "http://arxiv.org/pdf/2505.21896v2",
    "published": "2025-05-28T02:18:22+00:00",
    "categories": [
      "cond-mat.quant-gas",
      "cond-mat.dis-nn",
      "physics.atom-ph",
      "quant-ph"
    ],
    "primary_category": "cond-mat.quant-gas"
  },
  {
    "id": "http://arxiv.org/abs/2505.21895v1",
    "title": "Compressing Sine-Activated Low-Rank Adapters through Post-Training Quantization",
    "authors": [
      "Cameron Gordon",
      "Yiping Ji",
      "Hemanth Saratchandran",
      "Paul Albert",
      "Simon Lucey"
    ],
    "abstract": "Low-Rank Adaptation (LoRA) has become a standard approach for\nparameter-efficient fine-tuning, offering substantial reductions in trainable\nparameters by modeling updates as the product of two low-rank matrices. While\neffective, the low-rank constraint inherently limits representational capacity,\noften resulting in reduced performance compared to full-rank fine-tuning.\nRecent work by Ji et al. (2025) has addressed this limitation by applying a\nfixed-frequency sinusoidal transformation to low-rank adapters, increasing\ntheir stable rank without introducing additional parameters. This raises a\ncrucial question: can the same sine-activated technique be successfully applied\nwithin the context of Post-Training Quantization to retain benefits even after\nmodel compression? In this paper, we investigate this question by extending the\nsinusoidal transformation framework to quantized LoRA adapters. We develop a\ntheoretical analysis showing that the stable rank of a quantized adapter is\ntightly linked to that of its full-precision counterpart, motivating the use of\nsuch rank-enhancing functions even under quantization. Our results demonstrate\nthat the expressivity gains from a sinusoidal non-linearity persist after\nquantization, yielding highly compressed adapters with negligible loss in\nperformance. We validate our approach across a range of fine-tuning tasks for\nlanguage, vision and text-to-image generation achieving significant memory\nsavings while maintaining competitive accuracy.",
    "pdf_url": "http://arxiv.org/pdf/2505.21895v1",
    "published": "2025-05-28T02:15:15+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.21894v1",
    "title": "Patch-based Reconstruction for Unsupervised Dynamic MRI using Learnable Tensor Function with Implicit Neural Representation",
    "authors": [
      "Yuanyuan Liu",
      "Yuanbiao Yang",
      "Zhuo-Xu Cui",
      "Qingyong Zhu",
      "Jing Cheng",
      "Congcong Liu",
      "Jinwen Xie",
      "Jingran Xu",
      "Hairong Zheng",
      "Dong Liang",
      "Yanjie Zhu"
    ],
    "abstract": "Dynamic MRI plays a vital role in clinical practice by capturing both spatial\ndetails and dynamic motion, but its high spatiotemporal resolution is often\nlimited by long scan times. Deep learning (DL)-based methods have shown\npromising performance in accelerating dynamic MRI. However, most existing\nalgorithms rely on large fully-sampled datasets for training, which are\ndifficult to acquire. Recently, implicit neural representation (INR) has\nemerged as a powerful scan-specific paradigm for accelerated MRI, which models\nsignals as a continuous function over spatiotemporal coordinates. Although this\napproach achieves efficient continuous modeling of dynamic images and robust\nreconstruction, it faces challenges in recovering fine details and increasing\ncomputational demands for high dimensional data representation. To enhance both\nefficiency and reconstruction quality, we propose TenF-INR, a novel patch-based\nunsupervised framework that employs INR to model bases of tensor decomposition,\nenabling efficient and accurate modeling of dynamic MR images with learnable\ntensor functions. By exploiting strong correlations in similar spatial image\npatches and in the temporal direction, TenF-INR enforces multidimensional\nlow-rankness and implements patch-based reconstruction with the benefits of\ncontinuous modeling. We compare TenF-INR with state-of-the-art methods,\nincluding supervised DL methods and unsupervised approaches. Experimental\nresults demonstrate that TenF-INR achieves high acceleration factors up to 21,\noutperforming all comparison methods in image quality, temporal fidelity, and\nquantitative metrics, even surpassing the supervised methods.",
    "pdf_url": "http://arxiv.org/pdf/2505.21894v1",
    "published": "2025-05-28T02:13:09+00:00",
    "categories": [
      "eess.IV"
    ],
    "primary_category": "eess.IV"
  },
  {
    "id": "http://arxiv.org/abs/2505.21893v1",
    "title": "SDPO: Importance-Sampled Direct Preference Optimization for Stable Diffusion Training",
    "authors": [
      "Xiaomeng Yang",
      "Zhiyu Tan",
      "Junyan Wang",
      "Zhijian Zhou",
      "Hao Li"
    ],
    "abstract": "Preference learning has become a central technique for aligning generative\nmodels with human expectations. Recently, it has been extended to diffusion\nmodels through methods like Direct Preference Optimization (DPO). However,\nexisting approaches such as Diffusion-DPO suffer from two key challenges:\ntimestep-dependent instability, caused by a mismatch between the reverse and\nforward diffusion processes and by high gradient variance in early noisy\ntimesteps, and off-policy bias arising from the mismatch between optimization\nand data collection policies. We begin by analyzing the reverse diffusion\ntrajectory and observe that instability primarily occurs at early timesteps\nwith low importance weights. To address these issues, we first propose\nDPO-C\\&M, a practical strategy that improves stability by clipping and masking\nuninformative timesteps while partially mitigating off-policy bias. Building on\nthis, we introduce SDPO (Importance-Sampled Direct Preference Optimization), a\nprincipled framework that incorporates importance sampling into the objective\nto fully correct for off-policy bias and emphasize informative updates during\nthe diffusion process. Experiments on CogVideoX-2B, CogVideoX-5B, and\nWan2.1-1.3B demonstrate that both methods outperform standard Diffusion-DPO,\nwith SDPO achieving superior VBench scores, human preference alignment, and\ntraining robustness. These results highlight the importance of timestep-aware,\ndistribution-corrected optimization in diffusion-based preference learning.",
    "pdf_url": "http://arxiv.org/pdf/2505.21893v1",
    "published": "2025-05-28T02:11:56+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.21892v1",
    "title": "Almost Linear Convergence under Minimal Score Assumptions: Quantized Transition Diffusion",
    "authors": [
      "Xunpeng Huang",
      "Yingyu Lin",
      "Nikki Lijing Kuang",
      "Hanze Dong",
      "Difan Zou",
      "Yian Ma",
      "Tong Zhang"
    ],
    "abstract": "Continuous diffusion models have demonstrated remarkable performance in data\ngeneration across various domains, yet their efficiency remains constrained by\ntwo critical limitations: (1) the local adjacency structure of the forward\nMarkov process, which restricts long-range transitions in the data space, and\n(2) inherent biases introduced during the simulation of time-inhomogeneous\nreverse denoising processes. To address these challenges, we propose Quantized\nTransition Diffusion (QTD), a novel approach that integrates data quantization\nwith discrete diffusion dynamics. Our method first transforms the continuous\ndata distribution $p_*$ into a discrete one $q_*$ via histogram approximation\nand binary encoding, enabling efficient representation in a structured discrete\nlatent space. We then design a continuous-time Markov chain (CTMC) with Hamming\ndistance-based transitions as the forward process, which inherently supports\nlong-range movements in the original data space. For reverse-time sampling, we\nintroduce a \\textit{truncated uniformization} technique to simulate the reverse\nCTMC, which can provably provide unbiased generation from $q_*$ under minimal\nscore assumptions. Through a novel KL dynamic analysis of the reverse CTMC, we\nprove that QTD can generate samples with $O(d\\ln^2(d/\\epsilon))$ score\nevaluations in expectation to approximate the $d$--dimensional target\ndistribution $p_*$ within an $\\epsilon$ error tolerance. Our method not only\nestablishes state-of-the-art inference efficiency but also advances the\ntheoretical foundations of diffusion-based generative modeling by unifying\ndiscrete and continuous diffusion paradigms.",
    "pdf_url": "http://arxiv.org/pdf/2505.21892v1",
    "published": "2025-05-28T02:10:11+00:00",
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2505.21891v1",
    "title": "TIEboard: A Digital Educational Tool for Kids Geometric Learning",
    "authors": [
      "Arooj Zaidi",
      "Giulia Barbareschi",
      "Kai Kunze",
      "Yun Suen Pai",
      "Junichi Yamaoka"
    ],
    "abstract": "Tangible User Interfaces have shown potential in supporting the acquisition\nof key concepts in computing and mathematics while fostering engagement in\nyoung learners, but these approaches are less commonly utilised in the context\nof geometry. In this paper we introduce TIEboard, an interactive device to\npromote early learning of basic geometry concepts. TIEboard draws inspiration\nfrom traditional geoboards and lacing toys to leverage children's familiarity\nwith these traditional tools. It employs instructional lights to guide children\nin creating shapes using colourful threads of optical fiber. The use of\nconductive materials allows the system to detect lacing activity and provide\nfeedback in real-time. TIEboard incorporates six interaction modes of varying\ndifficulty based on an incremental learning framework. The study evaluated\nTIEboard's effectiveness in supporting early geometric learning, facilitating\ncreativity and promoting collaboration among 16 children aged 5-9.",
    "pdf_url": "http://arxiv.org/pdf/2505.21891v1",
    "published": "2025-05-28T02:10:03+00:00",
    "categories": [
      "cs.HC"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2505.21890v1",
    "title": "Hyperspectral Gaussian Splatting",
    "authors": [
      "Sunil Kumar Narayanan",
      "Lingjun Zhao",
      "Lu Gan",
      "Yongsheng Chen"
    ],
    "abstract": "Hyperspectral imaging (HSI) has been widely used in agricultural applications\nfor non-destructive estimation of plant nutrient composition and precise\ndetermination of nutritional elements in samples. Recently, 3D reconstruction\nmethods have been used to create implicit neural representations of HSI scenes,\nwhich can help localize the target object's nutrient composition spatially and\nspectrally. Neural Radiance Field (NeRF) is a cutting-edge implicit\nrepresentation that can render hyperspectral channel compositions of each\nspatial location from any viewing direction. However, it faces limitations in\ntraining time and rendering speed. In this paper, we propose Hyperspectral\nGaussian Splatting (HS-GS), which combines the state-of-the-art 3D Gaussian\nSplatting (3DGS) with a diffusion model to enable 3D explicit reconstruction of\nthe hyperspectral scenes and novel view synthesis for the entire spectral\nrange. To enhance the model's ability to capture fine-grained reflectance\nvariations across the light spectrum and leverage correlations between adjacent\nwavelengths for denoising, we introduce a wavelength encoder to generate\nwavelength-specific spherical harmonics offsets. We also introduce a novel\nKullback--Leibler divergence-based loss to mitigate the spectral distribution\ngap between the rendered image and the ground truth. A diffusion model is\nfurther applied for denoising the rendered images and generating photorealistic\nhyperspectral images. We present extensive evaluations on five diverse\nhyperspectral scenes from the Hyper-NeRF dataset to show the effectiveness of\nour proposed HS-GS framework. The results demonstrate that HS-GS achieves new\nstate-of-the-art performance among all previously published methods. Code will\nbe released upon publication.",
    "pdf_url": "http://arxiv.org/pdf/2505.21890v1",
    "published": "2025-05-28T02:07:52+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.21889v2",
    "title": "EFIM: Efficient Serving of LLMs for Infilling Tasks with Improved KV Cache Reuse",
    "authors": [
      "Tianyu Guo",
      "Hande Dong",
      "Yichong Leng",
      "Feng Liu",
      "Cheater Lin",
      "Nong Xiao",
      "Xianwei Zhang"
    ],
    "abstract": "Large language models (LLMs) are often used for infilling tasks, which\ninvolve predicting or generating missing information in a given text. These\ntasks typically require multiple interactions with similar context. To reduce\nthe computation of repeated historical tokens, cross-request key-value (KV)\ncache reuse, a technique that stores and reuses intermediate computations, has\nbecome a crucial method in multi-round interactive services. However, in\ninfilling tasks, the KV cache reuse is often hindered by the structure of the\nprompt format, which typically consists of a prefix and suffix relative to the\ninsertion point. Specifically, the KV cache of the prefix or suffix part is\nfrequently invalidated as the other part (suffix or prefix) is incrementally\ngenerated. To address the issue, we propose EFIM, a transformed prompt format\nof FIM to unleash the performance potential of KV cache reuse. Although the\ntransformed prompt can solve the inefficiency, it exposes subtoken generation\nproblems in current LLMs, where they have difficulty generating partial words\naccurately. Therefore, we introduce a fragment tokenization training method\nwhich splits text into multiple fragments before tokenization during data\nprocessing. Experiments on two representative LLMs show that LLM serving with\nEFIM can lower the latency by 52% and improve the throughput by 98% while\nmaintaining the original infilling capability. EFIM's source code is publicly\navailable at https://github.com/gty111/EFIM.",
    "pdf_url": "http://arxiv.org/pdf/2505.21889v2",
    "published": "2025-05-28T02:07:03+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.21888v1",
    "title": "Dissecting Exciton-Polariton Transport in Organic Molecular Crystals: Emerging Conductivity Assisted by Intermolecular Vibrational Coupling",
    "authors": [
      "Guangming Liu",
      "Hsing-Ta Chen"
    ],
    "abstract": "In this work, we systematically investigate the spectral and transport\nproperties of exciton-polaritons under the explicit influence of intermolecular\nvibrational coupling, which introduces dynamic disorder. In the context of a\none-dimensional molecular chain strongly interacting with a cavity photon, we\ndemonstrate the polaritonic characteristics of the spectral function and its\ninteractions with the electronic band broadened by the coupling disorder. We\nfurther dissect the current flux into its bare excitonic contribution and\ntransport via the cavity photon. Our results reveal that the enhancement in the\ncharge carrier mobility and frequency-resolved conductivity stems from the\nphoton-mediated current. More importantly, contrary to the intuition that\ndynamic disorder hinders transport, intermolecular vibrational coupling can\nfacilitate exciton-polariton transport, offering an additional degree of\ntunability for material properties.",
    "pdf_url": "http://arxiv.org/pdf/2505.21888v1",
    "published": "2025-05-28T02:03:57+00:00",
    "categories": [
      "physics.chem-ph",
      "cond-mat.mes-hall"
    ],
    "primary_category": "physics.chem-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.21887v2",
    "title": "SVRPBench: A Realistic Benchmark for Stochastic Vehicle Routing Problem",
    "authors": [
      "Ahmed Heakl",
      "Yahia Salaheldin Shaaban",
      "Martin Takac",
      "Salem Lahlou",
      "Zangir Iklassov"
    ],
    "abstract": "Robust routing under uncertainty is central to real-world logistics, yet most\nbenchmarks assume static, idealized settings. We present SVRPBench, the first\nopen benchmark to capture high-fidelity stochastic dynamics in vehicle routing\nat urban scale. Spanning more than 500 instances with up to 1000 customers, it\nsimulates realistic delivery conditions: time-dependent congestion, log-normal\ndelays, probabilistic accidents, and empirically grounded time windows for\nresidential and commercial clients. Our pipeline generates diverse,\nconstraint-rich scenarios, including multi-depot and multi-vehicle setups.\nBenchmarking reveals that state-of-the-art RL solvers like POMO and AM degrade\nby over 20% under distributional shift, while classical and metaheuristic\nmethods remain robust. To enable reproducible research, we release the dataset\nand evaluation suite. SVRPBench challenges the community to design solvers that\ngeneralize beyond synthetic assumptions and adapt to real-world uncertainty.",
    "pdf_url": "http://arxiv.org/pdf/2505.21887v2",
    "published": "2025-05-28T02:03:31+00:00",
    "categories": [
      "cs.AI",
      "cs.CE",
      "cs.LG"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2505.21886v1",
    "title": "Geometry effects on zonal flow dynamics and turbulent transport in optimized stellarators",
    "authors": [
      "Haotian Chen",
      "Xishuo Wei",
      "Hongxuan Zhu",
      "Zhihong Lin"
    ],
    "abstract": "Global gyrokinetic simulations find a strong suppression of ion temperature\ngradient (ITG) turbulence by zonal flows in stellarators optimized for\nneoclassical transport. The reduction of the ITG transport by the zonal flows\nin quasi-helicalsymmetric (QH) and quasi-isodynamic (QI) stellarators are much\nlarger than a quasi-axisymmetric (QA) stellarator or a tokamak, thanks to\nhigher linear residual levels and lower nonlinear frequencies of the zonal\nflows in the QH and QI. The transport level and energy confinement time in the\nQH and QI are similar to the tokamak with the same size and temperature\ngradient, despite the much larger linear growth rates in the stellarators.",
    "pdf_url": "http://arxiv.org/pdf/2505.21886v1",
    "published": "2025-05-28T02:01:19+00:00",
    "categories": [
      "physics.plasm-ph"
    ],
    "primary_category": "physics.plasm-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.21885v1",
    "title": "Gravitational wave signatures of primordial black hole accretion during early matter domination",
    "authors": [
      "Rouzbeh Allahverdi",
      "James B. Dent",
      "Ngo Phuc Duc Loc",
      "Tao Xu"
    ],
    "abstract": "We present a scenario in which primordial black holes (PBHs) form in a\npost-inflationary radiation-dominated (RD) phase and then experience\nsignificant accretion during a phase of early matter dominated (EMD). We show\nthat PBH masses could grow by up to two orders of magnitude. Restricting to the\nlinear perturbation regime, we compute the gravitational wave (GW) spectrum\nthat features two peaks. The high-frequency peak is associated with the PBH\nformation in the RD phase, while the low-frequency peak is due to the sudden\ntransition from EMD to the later, standard RD phase. We identify a PBH mass\nrange where one or both peaks can be observed by a combination of different GW\ndetectors. Finally, we show the signal-to-noise ratio of the total GW spectrum\nfor PBHs in the asteroid mass window, where they could comprise the totality of\ndark matter.",
    "pdf_url": "http://arxiv.org/pdf/2505.21885v1",
    "published": "2025-05-28T02:00:33+00:00",
    "categories": [
      "hep-ph",
      "astro-ph.CO",
      "gr-qc"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.21884v1",
    "title": "Online distributed optimization for spatio-temporally constrained real-time peer-to-peer energy trading",
    "authors": [
      "Junhong Liu",
      "Qinfei Long",
      "Rong-Peng Liu",
      "Wenjie Liu",
      "Yunhe Hou"
    ],
    "abstract": "The proliferation of distributed renewable energy triggers the peer-to-peer\n(P2P) energy market formations. To make profits, prosumers equipped with\nphotovoltaic (PV) panels and even the energy storage system (ESS) can actively\nparticipate in the real-time P2P energy market and trade energy. However, in\nreal situations, system states such as energy demands and renewable energy\npower generation are highly uncertain, making it difficult for prosumers to\nmake optimal real-time decisions. Moreover, severe problems with the physical\nnetwork can arise from the real-time P2P energy trading, such as bus voltage\nviolations and line overload. To handle these problems, this work first\nformulates the real-time P2P energy trading problem as a spatio-temporally\nconstrained stochastic optimization problem by considering ESS and the spatial\nphysical network constraints. To deal with the uncertainties online, a modified\nLyapunov optimization method is innovatively proposed to approximately\nreformulate the stochastic optimization problem into an online one by relaxing\nthe time-coupling constraints. Compared with the state-of-the-art online\nmethods, the proposed one renders more flexibility and better performance for\nthe real-time P2P energy market operation. Additionally, to protect the\nprosumers' privacy, an online distributed algorithm based on the consensus\nalternating direction method of multipliers (ADMM) is developed to solve the\nreformulated online problem by decoupling the spatial constraints. The\ntheoretical near-optimal performance guarantee of the proposed online\ndistributed algorithm is derived, and its performance can be further improved\nby minimizing the performance gap. Simulation results demonstrate that the\nproposed online distributed algorithm can guarantee the fast, stable, and safe\nlong-term operation of the real-time P2P energy market.",
    "pdf_url": "http://arxiv.org/pdf/2505.21884v1",
    "published": "2025-05-28T01:59:59+00:00",
    "categories": [
      "eess.SY",
      "cs.SY",
      "math.OC"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2505.21883v1",
    "title": "Spin polarization of holographic baryon in strongly coupled fluid",
    "authors": [
      "Si-wen Li",
      "Shu Lin"
    ],
    "abstract": "The spin polarization for baryon in a hydrodynamic medium has been\nextensively studied in the weakly coupled regime using quantum kinetic theory.\nAs a first study of this problem in the strongly coupled regime, we investigate\nholographically the spectral function of a probe baryon in the fluid-gravity\nbackground. This is done by carefully performing gradient expansion of the\nDirac equation in the fluid-gravity background. Different contributions in the\nexpansion are understood in terms of density matrices of the probe baryon and\nthe medium. The resulting spectral functions indicate that the holographic\nbaryonic is polarized as responses to fluid acceleration, shear stress and\nvorticity. The structures of the responses are similar to those found in weakly\ncoupled studies.",
    "pdf_url": "http://arxiv.org/pdf/2505.21883v1",
    "published": "2025-05-28T01:59:47+00:00",
    "categories": [
      "hep-th",
      "hep-ph",
      "nucl-th"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2505.21882v2",
    "title": "HydraNet: Momentum-Driven State Space Duality for Multi-Granularity Tennis Tournaments Analysis",
    "authors": [
      "Ruijie Li",
      "Xiang Zhao",
      "Qiao Ning",
      "Shikai Guo"
    ],
    "abstract": "In tennis tournaments, momentum, a critical yet elusive phenomenon, reflects\nthe dynamic shifts in performance of athletes that can decisively influence\nmatch outcomes. Despite its significance, momentum in terms of effective\nmodeling and multi-granularity analysis across points, games, sets, and matches\nin tennis tournaments remains underexplored. In this study, we define a novel\nMomentum Score (MS) metric to quantify a player's momentum level in\nmulti-granularity tennis tournaments, and design HydraNet, a momentum-driven\nstate-space duality-based framework, to model MS by integrating thirty-two\nheterogeneous dimensions of athletes performance in serve, return, psychology\nand fatigue. HydraNet integrates a Hydra module, which builds upon a\nstate-space duality (SSD) framework, capturing explicit momentum with a\nsliding-window mechanism and implicit momentum through cross-game state\npropagation. It also introduces a novel Versus Learning method to better\nenhance the adversarial nature of momentum between the two athletes at a macro\nlevel, along with a Collaborative-Adversarial Attention Mechanism (CAAM) for\ncapturing and integrating intra-player and inter-player dynamic momentum at a\nmicro level. Additionally, we construct a million-level tennis cross-tournament\ndataset spanning from 2012-2023 Wimbledon and 2013-2023 US Open, and validate\nthe multi-granularity modeling capability of HydraNet for the MS metric on this\ndataset. Extensive experimental evaluations demonstrate that the MS metric\nconstructed by the HydraNet framework provides actionable insights into how\nmomentum impacts outcomes at different granularities, establishing a new\nfoundation for momentum modeling and sports analysis. To the best of our\nknowledge, this is the first work to explore and effectively model momentum\nacross multiple granularities in professional tennis tournaments.",
    "pdf_url": "http://arxiv.org/pdf/2505.21882v2",
    "published": "2025-05-28T01:58:44+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.21881v1",
    "title": "Global-Local Duality of Energetic Control Cost in Multipartite Quantum Correlated Systems",
    "authors": [
      "Rui Guan",
      "Junjie Liu",
      "Jian-Hua Jiang"
    ],
    "abstract": "Multipartite quantum correlated systems (MQCSs) are widely utilized in\ndiverse quantum information tasks, where their sophisticated control inherently\nincurs energetic costs. However, the fundamental characteristics of these\ncontrol costs remain elusive, largely due to the lack of thermodynamic\ndescriptions capable of capturing the full complexities of MQCSs. Here, we\nuncover universal thermodynamic relations for arbitrary MQCSs weakly coupled to\na thermal bath, establishing an intrinsic global-local duality of control\ncosts. Using these relations, we elucidate the exact role of multipartite\ncorrelation--a defining quantum feature of MQCSs--in shaping control costs at\nfinite times. We also demonstrate that the relative magnitude between global\nand local control costs is undetermined, which perplexes the cost management of\nMQCSs under finite-time controls. Our results are numerically corroborated with\napplications to experimentally realizable multi-qubit systems undergoing\nfinite-time qubit reset processes.",
    "pdf_url": "http://arxiv.org/pdf/2505.21881v1",
    "published": "2025-05-28T01:56:12+00:00",
    "categories": [
      "quant-ph",
      "cond-mat.stat-mech"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.21880v2",
    "title": "Incorporating LLMs for Large-Scale Urban Complex Mobility Simulation",
    "authors": [
      "Yu-Lun Song",
      "Chung-En Tsern",
      "Che-Cheng Wu",
      "Yu-Ming Chang",
      "Syuan-Bo Huang",
      "Wei-Chu Chen",
      "Michael Chia-Liang Lin",
      "Yu-Ta Lin"
    ],
    "abstract": "This study presents an innovative approach to urban mobility simulation by\nintegrating a Large Language Model (LLM) with Agent-Based Modeling (ABM).\nUnlike traditional rule-based ABM, the proposed framework leverages LLM to\nenhance agent diversity and realism by generating synthetic population\nprofiles, allocating routine and occasional locations, and simulating\npersonalized routes. Using real-world data, the simulation models individual\nbehaviors and large-scale mobility patterns in Taipei City. Key insights, such\nas route heat maps and mode-specific indicators, provide urban planners with\nactionable information for policy-making. Future work focuses on establishing\nrobust validation frameworks to ensure accuracy and reliability in urban\nplanning applications.",
    "pdf_url": "http://arxiv.org/pdf/2505.21880v2",
    "published": "2025-05-28T01:54:28+00:00",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.CL",
      "cs.CY"
    ],
    "primary_category": "cs.MA"
  },
  {
    "id": "http://arxiv.org/abs/2505.21879v1",
    "title": "Symbolic Foundation Regressor on Complex Networks",
    "authors": [
      "Weiting Liu",
      "Jiaxu Cui",
      "Jiao Hu",
      "En Wang",
      "Bo Yang"
    ],
    "abstract": "In science, we are interested not only in forecasting but also in\nunderstanding how predictions are made, specifically what the interpretable\nunderlying model looks like. Data-driven machine learning technology can\nsignificantly streamline the complex and time-consuming traditional manual\nprocess of discovering scientific laws, helping us gain insights into\nfundamental issues in modern science. In this work, we introduce a pre-trained\nsymbolic foundation regressor that can effectively compress complex data with\nnumerous interacting variables while producing interpretable physical\nrepresentations. Our model has been rigorously tested on non-network symbolic\nregression, symbolic regression on complex networks, and the inference of\nnetwork dynamics across various domains, including physics, biochemistry,\necology, and epidemiology. The results indicate a remarkable improvement in\nequation inference efficiency, being three times more effective than baseline\napproaches while maintaining accurate predictions. Furthermore, we apply our\nmodel to uncover more intuitive laws of interaction transmission from global\nepidemic outbreak data, achieving optimal data fitting. This model extends the\napplication boundary of pre-trained symbolic regression models to complex\nnetworks, and we believe it provides a foundational solution for revealing the\nhidden mechanisms behind changes in complex phenomena, enhancing\ninterpretability, and inspiring further scientific discoveries.",
    "pdf_url": "http://arxiv.org/pdf/2505.21879v1",
    "published": "2025-05-28T01:53:29+00:00",
    "categories": [
      "cs.SC",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.SC"
  },
  {
    "id": "http://arxiv.org/abs/2505.21878v3",
    "title": "Machine learning assisted speckle and OAM spectrum analysis for enhanced turbulence characterisation",
    "authors": [
      "Wenjie Jiang",
      "Mingjian Cheng",
      "Lixin Guo",
      "Xiang Yi",
      "Jiangting Li",
      "Junli Wang",
      "Andrew Forbes"
    ],
    "abstract": "Atmospheric turbulence degrades the performance of free-space optical (FSO)\ncommunication and remote sensing systems by introducing phase and intensity\ndistortions. While a majority of research focuses on mitigating these effects\nto ensure robust signal transmission, an underexplored alternative is to\nleverage the transformation of structured light to characterize the turbulent\nmedium itself. Here, we introduce a deep learning framework that fuses\npost-propagation intensity speckle patterns and orbital angular momentum (OAM)\nspectral data for atmospheric turbulence parameter inference. Our architecture,\nbased on a modified InceptionNet backbone, is optimized to extract and\nintegrate multi-scale features from these distinct optical modalities. This\nmultimodal approach achieves validation accuracies exceeding 80%, substantially\noutperforming conventional single-modality baselines. The framework\ndemonstrates high inference accuracy and enhanced training stability across a\nbroad range of simulated turbulent conditions, quantified by varying Fried\nparameters (r0) and Reynolds numbers (Re). This work presents a scalable and\ndata-efficient method for turbulence characterization, offering a pathway\ntoward robust environmental sensing and the optimization of dynamic FSO\nsystems.",
    "pdf_url": "http://arxiv.org/pdf/2505.21878v3",
    "published": "2025-05-28T01:48:12+00:00",
    "categories": [
      "physics.optics"
    ],
    "primary_category": "physics.optics"
  },
  {
    "id": "http://arxiv.org/abs/2505.21877v1",
    "title": "Hybrid Batch Normalisation: Resolving the Dilemma of Batch Normalisation in Federated Learning",
    "authors": [
      "Hongyao Chen",
      "Tianyang Xu",
      "Xiaojun Wu",
      "Josef Kittler"
    ],
    "abstract": "Batch Normalisation (BN) is widely used in conventional deep neural network\ntraining to harmonise the input-output distributions for each batch of data.\nHowever, federated learning, a distributed learning paradigm, faces the\nchallenge of dealing with non-independent and identically distributed data\namong the client nodes. Due to the lack of a coherent methodology for updating\nBN statistical parameters, standard BN degrades the federated learning\nperformance. To this end, it is urgent to explore an alternative normalisation\nsolution for federated learning. In this work, we resolve the dilemma of the BN\nlayer in federated learning by developing a customised normalisation approach,\nHybrid Batch Normalisation (HBN). HBN separates the update of statistical\nparameters (i.e. , means and variances used for evaluation) from that of\nlearnable parameters (i.e. , parameters that require gradient updates),\nobtaining unbiased estimates of global statistical parameters in distributed\nscenarios. In contrast with the existing solutions, we emphasise the supportive\npower of global statistics for federated learning. The HBN layer introduces a\nlearnable hybrid distribution factor, allowing each computing node to\nadaptively mix the statistical parameters of the current batch with the global\nstatistics. Our HBN can serve as a powerful plugin to advance federated\nlearning performance. It reflects promising merits across a wide range of\nfederated learning settings, especially for small batch sizes and heterogeneous\ndata.",
    "pdf_url": "http://arxiv.org/pdf/2505.21877v1",
    "published": "2025-05-28T01:46:34+00:00",
    "categories": [
      "cs.LG",
      "cs.DC"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.21876v1",
    "title": "EPiC: Efficient Video Camera Control Learning with Precise Anchor-Video Guidance",
    "authors": [
      "Zun Wang",
      "Jaemin Cho",
      "Jialu Li",
      "Han Lin",
      "Jaehong Yoon",
      "Yue Zhang",
      "Mohit Bansal"
    ],
    "abstract": "Recent approaches on 3D camera control in video diffusion models (VDMs) often\ncreate anchor videos to guide diffusion models as a structured prior by\nrendering from estimated point clouds following annotated camera trajectories.\nHowever, errors inherent in point cloud estimation often lead to inaccurate\nanchor videos. Moreover, the requirement for extensive camera trajectory\nannotations further increases resource demands. To address these limitations,\nwe introduce EPiC, an efficient and precise camera control learning framework\nthat automatically constructs high-quality anchor videos without expensive\ncamera trajectory annotations. Concretely, we create highly precise anchor\nvideos for training by masking source videos based on first-frame visibility.\nThis approach ensures high alignment, eliminates the need for camera trajectory\nannotations, and thus can be readily applied to any in-the-wild video to\ngenerate image-to-video (I2V) training pairs. Furthermore, we introduce\nAnchor-ControlNet, a lightweight conditioning module that integrates anchor\nvideo guidance in visible regions to pretrained VDMs, with less than 1% of\nbackbone model parameters. By combining the proposed anchor video data and\nControlNet module, EPiC achieves efficient training with substantially fewer\nparameters, training steps, and less data, without requiring modifications to\nthe diffusion model backbone typically needed to mitigate rendering\nmisalignments. Although being trained on masking-based anchor videos, our\nmethod generalizes robustly to anchor videos made with point clouds during\ninference, enabling precise 3D-informed camera control. EPiC achieves SOTA\nperformance on RealEstate10K and MiraData for I2V camera control task,\ndemonstrating precise and robust camera control ability both quantitatively and\nqualitatively. Notably, EPiC also exhibits strong zero-shot generalization to\nvideo-to-video scenarios.",
    "pdf_url": "http://arxiv.org/pdf/2505.21876v1",
    "published": "2025-05-28T01:45:26+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.10013v2",
    "title": "Immersive Fantasy Based on Digital Nostalgia: Environmental Narratives for the Korean Millennials and Gen Z",
    "authors": [
      "Yerin Doh",
      "Joonhyung Bae"
    ],
    "abstract": "This study introduces the media artwork Dear Passenger, Please Wear a Mask,\ndesigned to offer a layered exploration of single-use mask waste, which\nescalated during the COVID-19 pandemic. The piece reframes underappreciated\necological concerns by interweaving digital nostalgia and airline travel\nrecollections of Millennials and Gen Z with a unique fantasy narrative. Via a\npoint-and-click game and an immersive exhibition, participants traverse both\nvirtual and real domains, facing ethical and environmental dilemmas. While it\nfosters empathy and potential action, resource use and post-experience\nengagement challenges persist.",
    "pdf_url": "http://arxiv.org/pdf/2506.10013v2",
    "published": "2025-05-28T01:44:03+00:00",
    "categories": [
      "cs.MM",
      "cs.CY"
    ],
    "primary_category": "cs.MM"
  },
  {
    "id": "http://arxiv.org/abs/2505.21875v1",
    "title": "Broadening Our View: Assistive Technology for Cerebral Visual Impairment",
    "authors": [
      "Bhanuka Gamage",
      "Leona Holloway",
      "Nicola McDowell",
      "Thanh-Toan Do",
      "Nicholas Seow Chiang Price",
      "Arthur James Lowery",
      "Kim Marriott"
    ],
    "abstract": "Over the past decade, considerable research has been directed towards\nassistive technologies to support people with vision impairments using machine\nlearning, computer vision, image enhancement, and/or augmented/virtual reality.\nHowever, this has almost totally overlooked a growing demographic: people with\nCerebral Visual Impairment (CVI). Unlike Ocular Vision Impairments (OVI), CVI\narises from damage to the brain's visual processing centres. This paper\nintroduces CVI and reveals a wide research gap in addressing the needs of this\ndemographic. Through a scoping review, we identified 14 papers at the\nintersection of these technologies and CVI. Of these, only three papers\ndescribed assistive technologies focused on people living with CVI, with the\nothers focusing on diagnosis, understanding, simulation or rehabilitation. Our\nfindings highlight the opportunity for the Human-Computer Interaction and\nAssistive Technologies research community to explore and address this\nunderrepresented domain, thereby enhancing the quality of life for people with\nCVI.",
    "pdf_url": "http://arxiv.org/pdf/2505.21875v1",
    "published": "2025-05-28T01:40:55+00:00",
    "categories": [
      "cs.HC"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2505.21874v1",
    "title": "MAMBO-NET: Multi-Causal Aware Modeling Backdoor-Intervention Optimization for Medical Image Segmentation Network",
    "authors": [
      "Ruiguo Yu",
      "Yiyang Zhang",
      "Yuan Tian",
      "Yujie Diao",
      "Di Jin",
      "Witold Pedrycz"
    ],
    "abstract": "Medical image segmentation methods generally assume that the process from\nmedical image to segmentation is unbiased, and use neural networks to establish\nconditional probability models to complete the segmentation task. This\nassumption does not consider confusion factors, which can affect medical\nimages, such as complex anatomical variations and imaging modality limitations.\nConfusion factors obfuscate the relevance and causality of medical image\nsegmentation, leading to unsatisfactory segmentation results. To address this\nissue, we propose a multi-causal aware modeling backdoor-intervention\noptimization (MAMBO-NET) network for medical image segmentation. Drawing\ninsights from causal inference, MAMBO-NET utilizes self-modeling with\nmulti-Gaussian distributions to fit the confusion factors and introduce causal\nintervention into the segmentation process. Moreover, we design appropriate\nposterior probability constraints to effectively train the distributions of\nconfusion factors. For the distributions to effectively guide the segmentation\nand mitigate and eliminate the Impact of confusion factors on the segmentation,\nwe introduce classical backdoor intervention techniques and analyze their\nfeasibility in the segmentation task. To evaluate the effectiveness of our\napproach, we conducted extensive experiments on five medical image datasets.\nThe results demonstrate that our method significantly reduces the influence of\nconfusion factors, leading to enhanced segmentation accuracy.",
    "pdf_url": "http://arxiv.org/pdf/2505.21874v1",
    "published": "2025-05-28T01:40:10+00:00",
    "categories": [
      "eess.IV",
      "cs.CV"
    ],
    "primary_category": "eess.IV"
  },
  {
    "id": "http://arxiv.org/abs/2505.21873v1",
    "title": "HelixDesign-Binder: A Scalable Production-Grade Platform for Binder Design Built on HelixFold3",
    "authors": [
      "Jie Gao",
      "Jun Li",
      "Jing Hu",
      "Shanzhuo Zhang",
      "Kunrui Zhu",
      "Yueyang Huang",
      "Xiaonan Zhang",
      "Xiaomin Fang"
    ],
    "abstract": "Protein binder design is central to therapeutics, diagnostics, and synthetic\nbiology, yet practical deployment remains challenging due to fragmented\nworkflows, high computational costs, and complex tool integration. We present\nHelixDesign-Binder, a production-grade, high-throughput platform built on\nHelixFold3 that automates the full binder design pipeline, from backbone\ngeneration and sequence design to structural evaluation and multi-dimensional\nscoring. By unifying these stages into a scalable and user-friendly system,\nHelixDesign-Binder enables efficient exploration of binder candidates with\nfavorable structural, energetic, and physicochemical properties. The platform\nleverages Baidu Cloud's high-performance infrastructure to support large-scale\ndesign and incorporates advanced scoring metrics, including ipTM, predicted\nbinding free energy, and interface hydrophobicity. Benchmarking across six\nprotein targets demonstrates that HelixDesign-Binder reliably produces diverse\nand high-quality binders, some of which match or exceed validated designs in\npredicted binding affinity. HelixDesign-Binder is accessible via an interactive\nweb interface in PaddleHelix platform, supporting both academic research and\nindustrial applications in antibody and protein binder development.",
    "pdf_url": "http://arxiv.org/pdf/2505.21873v1",
    "published": "2025-05-28T01:39:31+00:00",
    "categories": [
      "q-bio.BM",
      "cs.AI",
      "q-bio.QM"
    ],
    "primary_category": "q-bio.BM"
  },
  {
    "id": "http://arxiv.org/abs/2505.21872v1",
    "title": "Targeted Unlearning Using Perturbed Sign Gradient Methods With Applications On Medical Images",
    "authors": [
      "George R. Nahass",
      "Zhu Wang",
      "Homa Rashidisabet",
      "Won Hwa Kim",
      "Sasha Hubschman",
      "Jeffrey C. Peterson",
      "Ghasem Yazdanpanah",
      "Chad A. Purnell",
      "Pete Setabutr",
      "Ann Q. Tran",
      "Darvin Yi",
      "Sathya N. Ravi"
    ],
    "abstract": "Machine unlearning aims to remove the influence of specific training samples\nfrom a trained model without full retraining. While prior work has largely\nfocused on privacy-motivated settings, we recast unlearning as a\ngeneral-purpose tool for post-deployment model revision. Specifically, we focus\non utilizing unlearning in clinical contexts where data shifts, device\ndeprecation, and policy changes are common. To this end, we propose a bilevel\noptimization formulation of boundary-based unlearning that can be solved using\niterative algorithms. We provide convergence guarantees when first-order\nalgorithms are used to unlearn. Our method introduces tunable loss design for\ncontrolling the forgetting-retention tradeoff and supports novel model\ncomposition strategies that merge the strengths of distinct unlearning runs.\nAcross benchmark and real-world clinical imaging datasets, our approach\noutperforms baselines on both forgetting and retention metrics, including\nscenarios involving imaging devices and anatomical outliers. This work\nestablishes machine unlearning as a modular, practical alternative to\nretraining for real-world model maintenance in clinical applications.",
    "pdf_url": "http://arxiv.org/pdf/2505.21872v1",
    "published": "2025-05-28T01:36:57+00:00",
    "categories": [
      "eess.IV",
      "cs.LG"
    ],
    "primary_category": "eess.IV"
  },
  {
    "id": "http://arxiv.org/abs/2505.21871v1",
    "title": "Global Dynamics Of Quadratic And Cubic Planar Quasi-homogeneous Differential Systems",
    "authors": [
      "Jaume Llibre",
      "Yilei Tang",
      "Jiang Yu",
      "Pengyu Zhou"
    ],
    "abstract": "In this paper we obtain the global dynamics and phase portraits of quadratic\nand cubic quasi-homogeneous but non-homogeneous systems. We first prove that\nall planar quadratic and cubic quasi-homogeneous but non-homogeneous polynomial\nsystems can be reduced to three homogeneous ones. Then for the homogeneous\nsystems, we employ blow-up method, normal sector method, Poincar\\'e\ncompactification and other techniques to discuss their dynamics. Finally we\ncharacterize the global phase portraits of quadratic and cubic\nquasi-homogeneous but non-homogeneous polynomial systems.",
    "pdf_url": "http://arxiv.org/pdf/2505.21871v1",
    "published": "2025-05-28T01:36:25+00:00",
    "categories": [
      "math.DS",
      "math.CA"
    ],
    "primary_category": "math.DS"
  },
  {
    "id": "http://arxiv.org/abs/2505.21870v1",
    "title": "Evaluating the Retrieval Robustness of Large Language Models",
    "authors": [
      "Shuyang Cao",
      "Karthik Radhakrishnan",
      "David Rosenberg",
      "Steven Lu",
      "Pengxiang Cheng",
      "Lu Wang",
      "Shiyue Zhang"
    ],
    "abstract": "Retrieval-augmented generation (RAG) generally enhances large language\nmodels' (LLMs) ability to solve knowledge-intensive tasks. But RAG may also\nlead to performance degradation due to imperfect retrieval and the model's\nlimited ability to leverage retrieved content. In this work, we evaluate the\nrobustness of LLMs in practical RAG setups (henceforth retrieval robustness).\nWe focus on three research questions: (1) whether RAG is always better than\nnon-RAG; (2) whether more retrieved documents always lead to better\nperformance; (3) and whether document orders impact results. To facilitate this\nstudy, we establish a benchmark of 1500 open-domain questions, each with\nretrieved documents from Wikipedia. We introduce three robustness metrics, each\ncorresponds to one research question. Our comprehensive experiments, involving\n11 LLMs and 3 prompting strategies, reveal that all of these LLMs exhibit\nsurprisingly high retrieval robustness; nonetheless, different degrees of\nimperfect robustness hinders them from fully utilizing the benefits of RAG.",
    "pdf_url": "http://arxiv.org/pdf/2505.21870v1",
    "published": "2025-05-28T01:34:31+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.21869v1",
    "title": "Examples of entire zero-mean curvature graphs of mixed-type in Lorentz-Minkowski space via Konderak's formulas",
    "authors": [
      "Takeki Komatsu",
      "Masaaki Umehara"
    ],
    "abstract": "Using Konderak's representation formula, we construct an entire zero-mean\ncurvature graph of mixed-type in Lorentz-Minkowski 3-space over a space-like\nplane, which does not belong to the class of \"Kobayashi surfaces\". We also\npoint out the existence of an entire zero-mean curvature graph of mixed-type in\nLorentz-Minkowski space over a light-like plane. These examples suggest that\nentire mixed-type zero-mean curvature graphs contain an unexpectedly large\nnumber of interesting examples.",
    "pdf_url": "http://arxiv.org/pdf/2505.21869v1",
    "published": "2025-05-28T01:33:38+00:00",
    "categories": [
      "math.DG"
    ],
    "primary_category": "math.DG"
  },
  {
    "id": "http://arxiv.org/abs/2505.21868v1",
    "title": "Cross-DINO: Cross the Deep MLP and Transformer for Small Object Detection",
    "authors": [
      "Guiping Cao",
      "Wenjian Huang",
      "Xiangyuan Lan",
      "Jianguo Zhang",
      "Dongmei Jiang",
      "Yaowei Wang"
    ],
    "abstract": "Small Object Detection (SOD) poses significant challenges due to limited\ninformation and the model's low class prediction score. While Transformer-based\ndetectors have shown promising performance, their potential for SOD remains\nlargely unexplored. In typical DETR-like frameworks, the CNN backbone network,\nspecialized in aggregating local information, struggles to capture the\nnecessary contextual information for SOD. The multiple attention layers in the\nTransformer Encoder face difficulties in effectively attending to small objects\nand can also lead to blurring of features. Furthermore, the model's lower class\nprediction score of small objects compared to large objects further increases\nthe difficulty of SOD. To address these challenges, we introduce a novel\napproach called Cross-DINO. This approach incorporates the deep MLP network to\naggregate initial feature representations with both short and long range\ninformation for SOD. Then, a new Cross Coding Twice Module (CCTM) is applied to\nintegrate these initial representations to the Transformer Encoder feature,\nenhancing the details of small objects. Additionally, we introduce a new kind\nof soft label named Category-Size (CS), integrating the Category and Size of\nobjects. By treating CS as new ground truth, we propose a new loss function\ncalled Boost Loss to improve the class prediction score of the model. Extensive\nexperimental results on COCO, WiderPerson, VisDrone, AI-TOD, and SODA-D\ndatasets demonstrate that Cross-DINO efficiently improves the performance of\nDETR-like models on SOD. Specifically, our model achieves 36.4% APs on COCO for\nSOD with only 45M parameters, outperforming the DINO by +4.4% APS (36.4% vs.\n32.0%) with fewer parameters and FLOPs, under 12 epochs training setting. The\nsource codes will be available at https://github.com/Med-Process/Cross-DINO.",
    "pdf_url": "http://arxiv.org/pdf/2505.21868v1",
    "published": "2025-05-28T01:33:23+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.23820v1",
    "title": "Arbiters of Ambivalence: Challenges of Using LLMs in No-Consensus Tasks",
    "authors": [
      "Bhaktipriya Radharapu",
      "Manon Revel",
      "Megan Ung",
      "Sebastian Ruder",
      "Adina Williams"
    ],
    "abstract": "The increasing use of LLMs as substitutes for humans in ``aligning'' LLMs has\nraised questions about their ability to replicate human judgments and\npreferences, especially in ambivalent scenarios where humans disagree. This\nstudy examines the biases and limitations of LLMs in three roles: answer\ngenerator, judge, and debater. These roles loosely correspond to previously\ndescribed alignment frameworks: preference alignment (judge) and scalable\noversight (debater), with the answer generator reflecting the typical setting\nwith user interactions. We develop a ``no-consensus'' benchmark by curating\nexamples that encompass a variety of a priori ambivalent scenarios, each\npresenting two possible stances. Our results show that while LLMs can provide\nnuanced assessments when generating open-ended answers, they tend to take a\nstance on no-consensus topics when employed as judges or debaters. These\nfindings underscore the necessity for more sophisticated methods for aligning\nLLMs without human oversight, highlighting that LLMs cannot fully capture human\ndisagreement even on topics where humans themselves are divided.",
    "pdf_url": "http://arxiv.org/pdf/2505.23820v1",
    "published": "2025-05-28T01:31:54+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.21867v1",
    "title": "Stoichiometry control and epitaxial growth of AgCrSe2 thin films by pulsed-laser deposition",
    "authors": [
      "Yusuke Tajima",
      "Kenshin Inamura",
      "Sebun Masaki",
      "Takumi Yamazaki",
      "Takeshi Seki",
      "Kazutaka Kudo",
      "Jobu Matsuno",
      "Junichi Shiogai"
    ],
    "abstract": "We report on epitaxial growth in thin-film synthesis of a polar magnetic\nsemiconductor AgCrSe2 on lattice-matched yttria-stabilized zirconia (111)\nsubstrate by pulsed-layer deposition (PLD). By using Ag-rich PLD target to\ncompensate for Ag deficiency in thin films, the nucleation of impurity phases\nis suppressed, resulting in the c-axis-oriented and single-phase AgCrSe2 thin\nfilm. Structural analysis using x-ray diffraction and cross-sectional scanning\ntransmission electron microscopy reveals epitaxial growth with the presence of\nboth twisted and polar domains. Optical absorbance spectrum and magnetization\nmeasurements show absorption edge at around 0.84 eV and magnetic transition\ntemperature at 41 K, respectively. These values are consistent with the\nreported values of direct bandgap and N\\'eel temperature of bulk AgCrSe2,\nreflecting a single-phase and stoichiometric feature of the obtained film. Our\ndemonstration of epitaxial thin-film growth of AgCrSe2 serves as a bedrock for\nexploration of its potential thermoelectric and spintronic functionalities at\nsurface or heterointerfaces.",
    "pdf_url": "http://arxiv.org/pdf/2505.21867v1",
    "published": "2025-05-28T01:31:53+00:00",
    "categories": [
      "cond-mat.mtrl-sci",
      "cond-mat.str-el"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2505.21866v1",
    "title": "CSI-Bench: A Large-Scale In-the-Wild Dataset for Multi-task WiFi Sensing",
    "authors": [
      "Guozhen Zhu",
      "Yuqian Hu",
      "Weihang Gao",
      "Wei-Hsiang Wang",
      "Beibei Wang",
      "K. J. Ray Liu"
    ],
    "abstract": "WiFi sensing has emerged as a compelling contactless modality for human\nactivity monitoring by capturing fine-grained variations in Channel State\nInformation (CSI). Its ability to operate continuously and non-intrusively\nwhile preserving user privacy makes it particularly suitable for health\nmonitoring. However, existing WiFi sensing systems struggle to generalize in\nreal-world settings, largely due to datasets collected in controlled\nenvironments with homogeneous hardware and fragmented, session-based recordings\nthat fail to reflect continuous daily activity.\n  We present CSI-Bench, a large-scale, in-the-wild benchmark dataset collected\nusing commercial WiFi edge devices across 26 diverse indoor environments with\n35 real users. Spanning over 461 hours of effective data, CSI-Bench captures\nrealistic signal variability under natural conditions. It includes\ntask-specific datasets for fall detection, breathing monitoring, localization,\nand motion source recognition, as well as a co-labeled multitask dataset with\njoint annotations for user identity, activity, and proximity. To support the\ndevelopment of robust and generalizable models, CSI-Bench provides standardized\nevaluation splits and baseline results for both single-task and multi-task\nlearning. CSI-Bench offers a foundation for scalable, privacy-preserving WiFi\nsensing systems in health and broader human-centric applications.",
    "pdf_url": "http://arxiv.org/pdf/2505.21866v1",
    "published": "2025-05-28T01:29:29+00:00",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.DB"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2505.21865v1",
    "title": "Hot donors in cataclysmic variables: The case of EI Psc",
    "authors": [
      "J. K√°ra",
      "S. Zharikov",
      "M. Wolf",
      "N. Vaidman",
      "A. Agishev",
      "S. Khokhlov",
      "C. E. Chavez"
    ],
    "abstract": "Context: We present results of time-resolved optical spectroscopy and\nphotometry of the short-orbital period dwarf nova EI Psc.\n  Aims: This study aims to determine fundamental system parameters of EI Psc,\nstudy properties of accretion structures in the system, and investigate its\norigin and current evolution state.\n  Methods: We analyse newly obtained time-resolved spectroscopic and\nphotometric observations as well as archival data. We used light curve\nmodelling, Doppler tomography, and MESA evolutionary models to study the\ncharacteristics of EI Psc.\n  Results: The system contains a relatively low temperature ($T_{\\rm eff} =\n6130\\,\\mathrm{K}$) white dwarf with mass of $M_{\\mathrm WD} =\n0.70(4)\\,\\mathrm{M}_{\\odot}$. The mass of the warm ($T_2 = 4440\\,\\mathrm{K}$)\nsecondary is $M_2 = 0.13\\,\\mathrm{M}_{\\odot}$. The inclination of the system is\n$i= 44.5\\deg(7)$. The mass accretion rate is $\\approx$\n$4\\times10^{-13}\\,\\mathrm{M}_\\odot\\,\\mathrm{year}^{-1}$. The long-term light\ncurve of the system shows outbursts and superoutbursts. The quiescence light\ncurve is double-humped and is formed by the combination of radiation from the\nRoche lobe filling the hot secondary and the hot spot. The radius of the outer\ndisc is about two times smaller than the tidal truncation radius. Most of the\ndisc's emission consists of emission lines and radiation from the hot spot at\nthe stream-disc impact region.\n  Conclusions: These types of systems are formed from progenitors with a low\nmass WD $\\mathrm{M}_{\\mathrm{WD}} \\lesssim 0.6\\,\\mathrm{M}_\\odot$ and\nrelatively massive secondaries $1.1-1.5\\,\\mathrm{M}_\\odot$ with initial orbital\nperiods on a scale of days. The number of similar systems is expected to be\nsignificantly lower than the usual CVs due to a lower forming rate of their\nrelatively massive progenitors.",
    "pdf_url": "http://arxiv.org/pdf/2505.21865v1",
    "published": "2025-05-28T01:27:10+00:00",
    "categories": [
      "astro-ph.SR"
    ],
    "primary_category": "astro-ph.SR"
  },
  {
    "id": "http://arxiv.org/abs/2505.21864v2",
    "title": "DexUMI: Using Human Hand as the Universal Manipulation Interface for Dexterous Manipulation",
    "authors": [
      "Mengda Xu",
      "Han Zhang",
      "Yifan Hou",
      "Zhenjia Xu",
      "Linxi Fan",
      "Manuela Veloso",
      "Shuran Song"
    ],
    "abstract": "We present DexUMI - a data collection and policy learning framework that uses\nthe human hand as the natural interface to transfer dexterous manipulation\nskills to various robot hands. DexUMI includes hardware and software\nadaptations to minimize the embodiment gap between the human hand and various\nrobot hands. The hardware adaptation bridges the kinematics gap using a\nwearable hand exoskeleton. It allows direct haptic feedback in manipulation\ndata collection and adapts human motion to feasible robot hand motion. The\nsoftware adaptation bridges the visual gap by replacing the human hand in video\ndata with high-fidelity robot hand inpainting. We demonstrate DexUMI's\ncapabilities through comprehensive real-world experiments on two different\ndexterous robot hand hardware platforms, achieving an average task success rate\nof 86%.",
    "pdf_url": "http://arxiv.org/pdf/2505.21864v2",
    "published": "2025-05-28T01:25:27+00:00",
    "categories": [
      "cs.RO"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.21863v3",
    "title": "GETReason: Enhancing Image Context Extraction through Hierarchical Multi-Agent Reasoning",
    "authors": [
      "Shikhhar Siingh",
      "Abhinav Rawat",
      "Chitta Baral",
      "Vivek Gupta"
    ],
    "abstract": "Publicly significant images from events hold valuable contextual information,\ncrucial for journalism and education. However, existing methods often struggle\nto extract this relevance accurately. To address this, we introduce GETReason\n(Geospatial Event Temporal Reasoning), a framework that moves beyond\nsurface-level image descriptions to infer deeper contextual meaning. We propose\nthat extracting global event, temporal, and geospatial information enhances\nunderstanding of an image's significance. Additionally, we introduce GREAT\n(Geospatial Reasoning and Event Accuracy with Temporal Alignment), a new metric\nfor evaluating reasoning-based image understanding. Our layered multi-agent\napproach, assessed using a reasoning-weighted metric, demonstrates that\nmeaningful insights can be inferred, effectively linking images to their\nbroader event context.",
    "pdf_url": "http://arxiv.org/pdf/2505.21863v3",
    "published": "2025-05-28T01:19:23+00:00",
    "categories": [
      "cs.CV",
      "cs.CL"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.21862v1",
    "title": "Towards Scalable Language-Image Pre-training for 3D Medical Imaging",
    "authors": [
      "Chenhui Zhao",
      "Yiwei Lyu",
      "Asadur Chowdury",
      "Edward Harake",
      "Akhil Kondepudi",
      "Akshay Rao",
      "Xinhai Hou",
      "Honglak Lee",
      "Todd Hollon"
    ],
    "abstract": "Language-image pre-training has demonstrated strong performance in 2D medical\nimaging, but its success in 3D modalities such as CT and MRI remains limited\ndue to the high computational demands of volumetric data, which pose a\nsignificant barrier to training on large-scale, uncurated clinical studies. In\nthis study, we introduce Hierarchical attention for Language-Image Pre-training\n(HLIP), a scalable pre-training framework for 3D medical imaging. HLIP adopts a\nlightweight hierarchical attention mechanism inspired by the natural hierarchy\nof radiology data: slice, scan, and study. This mechanism exhibits strong\ngeneralizability, e.g., +4.3% macro AUC on the Rad-ChestCT benchmark when\npre-trained on CT-RATE. Moreover, the computational efficiency of HLIP enables\ndirect training on uncurated datasets. Trained on 220K patients with 3.13\nmillion scans for brain MRI and 240K patients with 1.44 million scans for head\nCT, HLIP achieves state-of-the-art performance, e.g., +32.4% balanced ACC on\nthe proposed publicly available brain MRI benchmark Pub-Brain-5; +1.4% and\n+6.9% macro AUC on head CT benchmarks RSNA and CQ500, respectively. These\nresults demonstrate that, with HLIP, directly pre-training on uncurated\nclinical datasets is a scalable and effective direction for language-image\npre-training in 3D medical imaging. The code is available at\nhttps://github.com/Zch0414/hlip",
    "pdf_url": "http://arxiv.org/pdf/2505.21862v1",
    "published": "2025-05-28T01:16:34+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.21861v1",
    "title": "Robust and Symmetric Magnetic Field Dependency of Superconducting Diode Effect in Asymmetric Dirac Semimetal SQUIDs",
    "authors": [
      "H. C. Travaglini",
      "J. J. Cuozzo",
      "K. R. Sapkota",
      "I. A. Leahy",
      "A. D. Rice",
      "K. Alberi",
      "W. Pan"
    ],
    "abstract": "The recent demonstration of the superconducting diode effect (SDE) has\ngenerated renewed interests in superconducting electronics in which devices\nsuch as compact superconducting diodes that can perform signal rectification\nwhere low-energy operations are needed. In this article, we present our results\nof robust and symmetric-in-magnetic-field SDE in asymmetric superconducting\nquantum interference devices (SQUIDs) realized in high-quality Dirac semimetal\nCd3As2 thin film grown by the molecular beam epitaxy (MBE) technique.\nConsistent with previous work, a zero magnetic field SDE is observed.\nFurthermore, the difference in switching current is independent of the strength\nand polarity of an out-plane magnetic field in the range of -10 mT and 10 mT.\nWe speculate that this robust symmetric-in-field SDE in our Dirac semimetal\nSQUIDs is due to the formation of helical spin texture, theoretically predicted\nin Dirac semimetals.",
    "pdf_url": "http://arxiv.org/pdf/2505.21861v1",
    "published": "2025-05-28T01:16:09+00:00",
    "categories": [
      "cond-mat.supr-con",
      "cond-mat.mes-hall",
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.supr-con"
  },
  {
    "id": "http://arxiv.org/abs/2505.21860v1",
    "title": "GXJoin: Generalized Cell Transformations for Explainable Joinability",
    "authors": [
      "Soroush Omidvartehrani",
      "Arash Dargahi Nobari",
      "Davood Rafiei"
    ],
    "abstract": "Describing real-world entities can vary across different sources, posing a\nchallenge when integrating or exchanging data. We study the problem of\njoinability under syntactic transformations, where two columns are not\nequi-joinable but can become equi-joinable after some transformations.\nDiscovering those transformations is a challenge because of the large space of\npossible candidates, which grows with the input length and the number of rows.\nOur focus is on the generality of transformations, aiming to make the relevant\nmodels applicable across various instances and domains. We explore a few\ngeneralization techniques, emphasizing those that yield transformations\ncovering a larger number of rows and are often easier to explain. Through\nextensive evaluation on two real-world datasets and employing diverse metrics\nfor measuring the coverage and simplicity of the transformations, our approach\ndemonstrates superior performance over state-of-the-art approaches by\ngenerating fewer, simpler and hence more explainable transformations as well as\nimproving the join performance.",
    "pdf_url": "http://arxiv.org/pdf/2505.21860v1",
    "published": "2025-05-28T01:15:26+00:00",
    "categories": [
      "cs.DB"
    ],
    "primary_category": "cs.DB"
  },
  {
    "id": "http://arxiv.org/abs/2505.21859v1",
    "title": "Principled Content Selection to Generate Diverse and Personalized Multi-Document Summaries",
    "authors": [
      "Vishakh Padmakumar",
      "Zichao Wang",
      "David Arbour",
      "Jennifer Healey"
    ],
    "abstract": "While large language models (LLMs) are increasingly capable of handling\nlonger contexts, recent work has demonstrated that they exhibit the \"lost in\nthe middle\" phenomenon (Liu et al., 2024) of unevenly attending to different\nparts of the provided context. This hinders their ability to cover diverse\nsource material in multi-document summarization, as noted in the DiverseSumm\nbenchmark (Huang et al., 2024). In this work, we contend that principled\ncontent selection is a simple way to increase source coverage on this task. As\nopposed to prompting an LLM to perform the summarization in a single step, we\nexplicitly divide the task into three steps -- (1) reducing document\ncollections to atomic key points, (2) using determinantal point processes (DPP)\nto perform select key points that prioritize diverse content, and (3) rewriting\nto the final summary. By combining prompting steps, for extraction and\nrewriting, with principled techniques, for content selection, we consistently\nimprove source coverage on the DiverseSumm benchmark across various LLMs.\nFinally, we also show that by incorporating relevance to a provided user intent\ninto the DPP kernel, we can generate personalized summaries that cover relevant\nsource information while retaining coverage.",
    "pdf_url": "http://arxiv.org/pdf/2505.21859v1",
    "published": "2025-05-28T01:12:50+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2505.21858v1",
    "title": "Regression Analysis of Ordinal Panel Count Data in Recurrent Medication Non-adherence",
    "authors": [
      "Jiangjie Zhou",
      "Baosheng Liang"
    ],
    "abstract": "Panel count data arise in clinical trials when patients are asked to report\ntheir occurrences of events of interest periodically but the exact event times\nare unknown, only the count of events between two successive examinations are\nobserved. Ordinal panel count data goes even further as the exact event counts\nare not observed, the only information available is rank of event counts, for\nexample, 'never', 'sometimes' and 'always'. Currently, there is lacking of\nstandard and efficient methods for analyzing this type of data. In this paper,\nwe proposed a semiparametric proportional intensity model to analyze such data.\nWe developed a maximum sieve likelihood estimation using monotone spline under\nthe nonhomogeneous Poisson process model assumption for statistical inference.\nSimulation studies show that our method performs well with finite sample sizes\nand is relatively robust to model misspecification. In addition, we compared\nthe proposed method with other competitors and the proposed method outperforms\nin various settings. Finally, we investigated the recurrence of medication\nnon-adherence in a clinical trial on non-psychotic major depressive disorder\nusing the proposed method.",
    "pdf_url": "http://arxiv.org/pdf/2505.21858v1",
    "published": "2025-05-28T01:11:28+00:00",
    "categories": [
      "stat.ME"
    ],
    "primary_category": "stat.ME"
  },
  {
    "id": "http://arxiv.org/abs/2505.21857v1",
    "title": "Revisiting Bayesian Model Averaging in the Era of Foundation Models",
    "authors": [
      "Mijung Park"
    ],
    "abstract": "We revisit the classical, full-fledged Bayesian model averaging (BMA)\nparadigm to ensemble pre-trained and/or lightly-finetuned foundation models to\nenhance the classification performance on image and text data. To make BMA\ntractable under foundation models, we introduce trainable linear classifiers\nthat take frozen features from the pre-trained foundation models as inputs. The\nmodel posteriors over the linear classifiers tell us which linear heads and\nfrozen features are better suited for a given dataset, resulting in a\nprincipled model ensembling method. Furthermore, we propose a computationally\ncheaper, optimizable model averaging scheme (OMA). In OMA, we directly optimize\nthe model ensemble weights, just like those weights based on model posterior\ndistributions in BMA, by reducing the amount of surprise (expected entropy of\nthe predictions) we get from predictions of ensembled models. With the rapid\ndevelopment of foundation models, these approaches will enable the\nincorporation of future, possibly significantly better foundation models to\nenhance the performance of challenging classification tasks.",
    "pdf_url": "http://arxiv.org/pdf/2505.21857v1",
    "published": "2025-05-28T01:03:28+00:00",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.21856v1",
    "title": "Scheme Dependence of the One-Loop Domain Wall Tension",
    "authors": [
      "Jarah Evslin",
      "Hui Liu"
    ],
    "abstract": "The one-loop tension of the domain wall in the 3+1 dimensional $\\phi^4$\ndouble-well model was derived long ago using dimensional regularization. The\nmethods used can only be applied to solitons depending on a single dimension.\nIn the past few months, domain wall tensions have been recalculated using\nspectral methods with Born subtractions and also linearized soliton\nperturbation theory, both of which may be generalized to arbitrary solitons. It\nhas been shown that the former agrees with the results of Rebhan et al. In the\npresent work, we argue that, if the same renormalization scheme is chosen, both\nnew results agree.",
    "pdf_url": "http://arxiv.org/pdf/2505.21856v1",
    "published": "2025-05-28T01:02:55+00:00",
    "categories": [
      "hep-th"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2505.21855v1",
    "title": "Extracting Research Instruments from Educational Literature Using LLMs",
    "authors": [
      "Jiseung Yoo",
      "Curran Mahowald",
      "Meiyu Li",
      "Wei Ai"
    ],
    "abstract": "Large Language Models (LLMs) are transforming information extraction from\nacademic literature, offering new possibilities for knowledge management. This\nstudy presents an LLM-based system designed to extract detailed information\nabout research instruments used in the education field, including their names,\ntypes, target respondents, measured constructs, and outcomes. Using multi-step\nprompting and a domain-specific data schema, it generates structured outputs\noptimized for educational research. Our evaluation shows that this system\nsignificantly outperforms other approaches, particularly in identifying\ninstrument names and detailed information. This demonstrates the potential of\nLLM-powered information extraction in educational contexts, offering a\nsystematic way to organize research instrument information. The ability to\naggregate such information at scale enhances accessibility for researchers and\neducation leaders, facilitating informed decision-making in educational\nresearch and policy.",
    "pdf_url": "http://arxiv.org/pdf/2505.21855v1",
    "published": "2025-05-28T01:00:32+00:00",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2505.22688v2",
    "title": "Investigating the effectiveness of multimodal data in forecasting SARS-COV-2 case surges",
    "authors": [
      "Palur Venkata Raghuvamsi",
      "Siyuan Brandon Loh",
      "Prasanta Bhattacharya",
      "Joses Ho",
      "Raphael Lee Tze Chuen",
      "Alvin X. Han",
      "Sebastian Maurer-Stroh"
    ],
    "abstract": "The COVID-19 pandemic response relied heavily on statistical and machine\nlearning models to predict key outcomes such as case prevalence and fatality\nrates. These predictions were instrumental in enabling timely public health\ninterventions that helped break transmission cycles. While most existing models\nare grounded in traditional epidemiological data, the potential of alternative\ndatasets, such as those derived from genomic information and human behavior,\nremains underexplored. In the current study, we investigated the usefulness of\ndiverse modalities of feature sets in predicting case surges. Our results\nhighlight the relative effectiveness of biological (e.g., mutations), public\nhealth (e.g., case counts, policy interventions) and human behavioral features\n(e.g., mobility and social media conversations) in predicting country-level\ncase surges. Importantly, we uncover considerable heterogeneity in predictive\nperformance across countries and feature modalities, suggesting that surge\nprediction models may need to be tailored to specific national contexts and\npandemic phases. Overall, our work highlights the value of integrating\nalternative data sources into existing disease surveillance frameworks to\nenhance the prediction of pandemic dynamics.",
    "pdf_url": "http://arxiv.org/pdf/2505.22688v2",
    "published": "2025-05-28T01:00:02+00:00",
    "categories": [
      "q-bio.QM",
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "q-bio.QM"
  },
  {
    "id": "http://arxiv.org/abs/2505.21854v1",
    "title": "Rethinking Gradient-based Adversarial Attacks on Point Cloud Classification",
    "authors": [
      "Jun Chen",
      "Xinke Li",
      "Mingyue Xu",
      "Tianrui Li",
      "Chongshou Li"
    ],
    "abstract": "Gradient-based adversarial attacks have become a dominant approach for\nevaluating the robustness of point cloud classification models. However,\nexisting methods often rely on uniform update rules that fail to consider the\nheterogeneous nature of point clouds, resulting in excessive and perceptible\nperturbations. In this paper, we rethink the design of gradient-based attacks\nby analyzing the limitations of conventional gradient update mechanisms and\npropose two new strategies to improve both attack effectiveness and\nimperceptibility. First, we introduce WAAttack, a novel framework that\nincorporates weighted gradients and an adaptive step-size strategy to account\nfor the non-uniform contribution of points during optimization. This approach\nenables more targeted and subtle perturbations by dynamically adjusting updates\naccording to the local structure and sensitivity of each point. Second, we\npropose SubAttack, a complementary strategy that decomposes the point cloud\ninto subsets and focuses perturbation efforts on structurally critical regions.\nTogether, these methods represent a principled rethinking of gradient-based\nadversarial attacks for 3D point cloud classification. Extensive experiments\ndemonstrate that our approach outperforms state-of-the-art baselines in\ngenerating highly imperceptible adversarial examples. Code will be released\nupon paper acceptance.",
    "pdf_url": "http://arxiv.org/pdf/2505.21854v1",
    "published": "2025-05-28T00:55:36+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.21853v1",
    "title": "Quantitative Macromolecular Proton Fraction Imaging using Pulsed Spin-Lock",
    "authors": [
      "Qianxue Shan",
      "Ziqiang Yu",
      "Baiyan Jiang",
      "Jian Hou",
      "Qiuyi Shen",
      "Winnie CW Chu",
      "Vincent WS Wong",
      "Weitian Chen"
    ],
    "abstract": "Purpose: Recent studies have shown that spin-lock MRI can simplify\nquantitative magnetization transfer (MT) by eliminating its dependency on water\npool parameters, removing the need for a T1 map in macromolecular proton\nfraction (MPF) quantification. However, its application is often limited by the\nrequirement for long radiofrequency (RF) pulse durations, which are constrained\nby RF hardware capabilities despite remaining within specific absorption rate\n(SAR) safety limits.\n  Methods: To address this challenge, we propose a novel method, MPF mapping\nusing pulsed spin-lock (MPF-PSL). MPF-PSL employs a pulsed spin-lock train with\nintermittent free precession periods, enabling extended total spin-lock\ndurations without exceeding hardware and specific absorption rate limits. A\ncomprehensive analytical framework was developed to model the magnetization\ndynamics of the two-pool MT system under pulsed spin-lock, demonstrating that\nMPF-PSL achieves MT-specific quantification while minimizing confounding\neffects from the water pool. The proposed method is validated with\nBloch-McConnell simulations, phantoms, and in vivo studies at 3T.\n  Results: Both Bloch-McConnell simulations and phantom validation demonstrated\nthat MPF-PSL exhibits robust insensitivity to water pool parameters while\nenabling high-SNR MPF quantification. In vivo validation studies confirmed the\nmethod's clinical utility in detecting collagen deposition in patients with\nliver fibrosis.\n  Conclusion: MPF-PSL presents a practical solution for quantitative MT\nimaging, with strong potential for clinical applications.",
    "pdf_url": "http://arxiv.org/pdf/2505.21853v1",
    "published": "2025-05-28T00:53:45+00:00",
    "categories": [
      "physics.med-ph",
      "physics.app-ph"
    ],
    "primary_category": "physics.med-ph"
  },
  {
    "id": "http://arxiv.org/abs/2505.21852v1",
    "title": "A Provable Approach for End-to-End Safe Reinforcement Learning",
    "authors": [
      "Akifumi Wachi",
      "Kohei Miyaguchi",
      "Takumi Tanabe",
      "Rei Sato",
      "Youhei Akimoto"
    ],
    "abstract": "A longstanding goal in safe reinforcement learning (RL) is a method to ensure\nthe safety of a policy throughout the entire process, from learning to\noperation. However, existing safe RL paradigms inherently struggle to achieve\nthis objective. We propose a method, called Provably Lifetime Safe RL (PLS),\nthat integrates offline safe RL with safe policy deployment to address this\nchallenge. Our proposed method learns a policy offline using return-conditioned\nsupervised learning and then deploys the resulting policy while cautiously\noptimizing a limited set of parameters, known as target returns, using Gaussian\nprocesses (GPs). Theoretically, we justify the use of GPs by analyzing the\nmathematical relationship between target and actual returns. We then prove that\nPLS finds near-optimal target returns while guaranteeing safety with high\nprobability. Empirically, we demonstrate that PLS outperforms baselines both in\nsafety and reward performance, thereby achieving the longstanding goal to\nobtain high rewards while ensuring the safety of a policy throughout the\nlifetime from learning to operation.",
    "pdf_url": "http://arxiv.org/pdf/2505.21852v1",
    "published": "2025-05-28T00:48:20+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.IT",
      "cs.RO",
      "math.IT"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.21851v1",
    "title": "Streaming Flow Policy: Simplifying diffusion$/$flow-matching policies by treating action trajectories as flow trajectories",
    "authors": [
      "Sunshine Jiang",
      "Xiaolin Fang",
      "Nicholas Roy",
      "Tom√°s Lozano-P√©rez",
      "Leslie Pack Kaelbling",
      "Siddharth Ancha"
    ],
    "abstract": "Recent advances in diffusion$/$flow-matching policies have enabled imitation\nlearning of complex, multi-modal action trajectories. However, they are\ncomputationally expensive because they sample a trajectory of trajectories: a\ndiffusion$/$flow trajectory of action trajectories. They discard intermediate\naction trajectories, and must wait for the sampling process to complete before\nany actions can be executed on the robot. We simplify diffusion$/$flow policies\nby treating action trajectories as flow trajectories. Instead of starting from\npure noise, our algorithm samples from a narrow Gaussian around the last\naction. Then, it incrementally integrates a velocity field learned via flow\nmatching to produce a sequence of actions that constitute a single trajectory.\nThis enables actions to be streamed to the robot on-the-fly during the flow\nsampling process, and is well-suited for receding horizon policy execution.\nDespite streaming, our method retains the ability to model multi-modal\nbehavior. We train flows that stabilize around demonstration trajectories to\nreduce distribution shift and improve imitation learning performance. Streaming\nflow policy outperforms prior methods while enabling faster policy execution\nand tighter sensorimotor loops for learning-based robot control. Project\nwebsite: https://streaming-flow-policy.github.io/",
    "pdf_url": "http://arxiv.org/pdf/2505.21851v1",
    "published": "2025-05-28T00:48:19+00:00",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2505.23819v2",
    "title": "Linear Layouts: Robust Code Generation of Efficient Tensor Computation Using $\\mathbb{F}_2$",
    "authors": [
      "Keren Zhou",
      "Mario Lezcano",
      "Adam Goucher",
      "Akhmed Rakhmati",
      "Jeff Niu",
      "Justin Lebar",
      "Pawel Szczerbuk",
      "Peter Bell",
      "Phil Tillet",
      "Thomas Raoux",
      "Zahi Moudallal"
    ],
    "abstract": "Efficient tensor computation is a cornerstone of modern deep learning (DL)\nworkloads, yet existing approaches struggle to achieve flexible and performant\ndesign and implementation of tensor layouts -- mappings between logical tensors\nand hardware resources. The increasing complexity of DL algorithms and hardware\ndemands a generic and systematic approach to handling tensor layouts. In this\nwork, we introduce Linear Layouts, a novel approach that models tensor layouts\nusing linear algebra over $\\mathbb{F}_2$. By representing tensor layouts as\nbinary matrices acting on the bits of the hardware representation, our approach\nenables a generic layout definition -- as opposed to the classical case-by-case\napproach -- and allows for generic layout-to-layout conversions, eliminating\nthe quadratic explosion that plagues existing solutions. We integrate linear\nlayouts with Triton and demonstrate their effectiveness in optimizing\nindividual Triton operators as well as kernels written in Triton. We also show\nthat linear layouts reduce engineering effort in the compiler backend while\nfixing several bugs in Triton's legacy layout system.",
    "pdf_url": "http://arxiv.org/pdf/2505.23819v2",
    "published": "2025-05-28T00:45:50+00:00",
    "categories": [
      "cs.PL",
      "cs.AR",
      "cs.DC",
      "cs.PF"
    ],
    "primary_category": "cs.PL"
  },
  {
    "id": "http://arxiv.org/abs/2506.15695v2",
    "title": "SimuGen: Multi-modal Agentic Framework for Constructing Block Diagram-Based Simulation Models",
    "authors": [
      "Xinxing Ren",
      "Qianbo Zang",
      "Zekun Guo"
    ],
    "abstract": "Recent advances in large language models (LLMs) have shown impressive\nperformance in mathematical reasoning and code generation. However, LLMs still\nstruggle in the simulation domain, particularly in generating Simulink models,\nwhich are essential tools in engineering and scientific research. Our\npreliminary experiments indicate that LLM agents often fail to produce reliable\nand complete Simulink simulation code from text-only inputs, likely due to the\nlack of Simulink-specific data in their pretraining. To address this challenge,\nwe propose SimuGen, a multimodal agent-based framework that automatically\ngenerates accurate Simulink simulation code by leveraging both the visual\nSimulink diagram and domain knowledge. SimuGen coordinates several specialized\nagents, including an investigator, unit test reviewer, code generator,\nexecutor, debug locator, and report writer, supported by a domain-specific\nknowledge base. This collaborative and modular design enables interpretable,\nrobust, and reproducible Simulink simulation generation. Our source code is\npublicly available at https://github.com/renxinxing123/SimuGen_beta.",
    "pdf_url": "http://arxiv.org/pdf/2506.15695v2",
    "published": "2025-05-28T00:35:43+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.21850v2",
    "title": "Beyond Perception: Evaluating Abstract Visual Reasoning through Multi-Stage Task",
    "authors": [
      "Yanbei Jiang",
      "Yihao Ding",
      "Chao Lei",
      "Jiayang Ao",
      "Jey Han Lau",
      "Krista A. Ehinger"
    ],
    "abstract": "Current Multimodal Large Language Models (MLLMs) excel in general visual\nreasoning but remain underexplored in Abstract Visual Reasoning (AVR), which\ndemands higher-order reasoning to identify abstract rules beyond simple\nperception. Existing AVR benchmarks focus on single-step reasoning, emphasizing\nthe end result but neglecting the multi-stage nature of reasoning process. Past\nstudies found MLLMs struggle with these benchmarks, but it doesn't explain how\nthey fail. To address this gap, we introduce MultiStAR, a Multi-Stage AVR\nbenchmark, based on RAVEN, designed to assess reasoning across varying levels\nof complexity. Additionally, existing metrics like accuracy only focus on the\nfinal outcomes while do not account for the correctness of intermediate steps.\nTherefore, we propose a novel metric, MSEval, which considers the correctness\nof intermediate steps in addition to the final outcomes. We conduct\ncomprehensive experiments on MultiStAR using 17 representative close-source and\nopen-source MLLMs. The results reveal that while existing MLLMs perform\nadequately on basic perception tasks, they continue to face challenges in more\ncomplex rule detection stages.",
    "pdf_url": "http://arxiv.org/pdf/2505.21850v2",
    "published": "2025-05-28T00:34:45+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.10012v1",
    "title": "Thief of Truth: VR comics about the relationship between AI and humans",
    "authors": [
      "Joonhyung Bae"
    ],
    "abstract": "Thief of Truth is a first-person perspective Virtual Reality (VR) comic that\nexplores the relationship between humans and artificial intelligence (AI). The\nwork tells the story of a mind-uploaded human being reborn as a new subject\nwhile interacting with an AI that is looking for the meaning of life. In order\nto experiment with the expandability of VR comics, the work was produced by\nfocusing on three problems. First, the comic is designed using the viewing\ncontrol effect of VR. Second, through VR controller-based interaction, the\nplayer's immersion in the work is increased. Third, a method for increasing\naccessibility to VR comics was devised. This work aims to present an example of\nan experimental attempt in VR Comics.",
    "pdf_url": "http://arxiv.org/pdf/2506.10012v1",
    "published": "2025-05-28T00:33:55+00:00",
    "categories": [
      "cs.MM",
      "cs.HC"
    ],
    "primary_category": "cs.MM"
  },
  {
    "id": "http://arxiv.org/abs/2505.21849v1",
    "title": "Xinyu AI Search: Enhanced Relevance and Comprehensive Results with Rich Answer Presentations",
    "authors": [
      "Bo Tang",
      "Junyi Zhu",
      "Chenyang Xi",
      "Yunhang Ge",
      "Jiahao Wu",
      "Yuchen Feng",
      "Yijun Niu",
      "Wenqiang Wei",
      "Yu Yu",
      "Chunyu Li",
      "Zehao Lin",
      "Hao Wu",
      "Ning Liao",
      "Yebin Yang",
      "Jiajia Wang",
      "Zhiyu Li",
      "Feiyu Xiong",
      "Jingrun Chen"
    ],
    "abstract": "Traditional search engines struggle to synthesize fragmented information for\ncomplex queries, while generative AI search engines face challenges in\nrelevance, comprehensiveness, and presentation. To address these limitations,\nwe introduce Xinyu AI Search, a novel system that incorporates a\nquery-decomposition graph to dynamically break down complex queries into\nsub-queries, enabling stepwise retrieval and generation. Our retrieval pipeline\nenhances diversity through multi-source aggregation and query expansion, while\nfiltering and re-ranking strategies optimize passage relevance. Additionally,\nXinyu AI Search introduces a novel approach for fine-grained, precise built-in\ncitation and innovates in result presentation by integrating timeline\nvisualization and textual-visual choreography. Evaluated on recent real-world\nqueries, Xinyu AI Search outperforms eight existing technologies in human\nassessments, excelling in relevance, comprehensiveness, and insightfulness.\nAblation studies validate the necessity of its key sub-modules. Our work\npresents the first comprehensive framework for generative AI search engines,\nbridging retrieval, generation, and user-centric presentation.",
    "pdf_url": "http://arxiv.org/pdf/2505.21849v1",
    "published": "2025-05-28T00:30:22+00:00",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2505.21848v1",
    "title": "FPAN: Mitigating Replication in Diffusion Models through the Fine-Grained Probabilistic Addition of Noise to Token Embeddings",
    "authors": [
      "Jingqi Xu",
      "Chenghao Li",
      "Yuke Zhang",
      "Peter A. Beerel"
    ],
    "abstract": "Diffusion models have demonstrated remarkable potential in generating\nhigh-quality images. However, their tendency to replicate training data raises\nserious privacy concerns, particularly when the training datasets contain\nsensitive or private information. Existing mitigation strategies primarily\nfocus on reducing image duplication, modifying the cross-attention mechanism,\nand altering the denoising backbone architecture of diffusion models. Moreover,\nrecent work has shown that adding a consistent small amount of noise to text\nembeddings can reduce replication to some degree. In this work, we begin by\nanalyzing the impact of adding varying amounts of noise. Based on our analysis,\nwe propose a fine-grained noise injection technique that probabilistically adds\na larger amount of noise to token embeddings. We refer to our method as\nFine-grained Probabilistic Addition of Noise (FPAN). Through our extensive\nexperiments, we show that our proposed FPAN can reduce replication by an\naverage of 28.78% compared to the baseline diffusion model without\nsignificantly impacting image quality, and outperforms the prior\nconsistent-magnitude-noise-addition approach by 26.51%. Moreover, when combined\nwith other existing mitigation methods, our FPAN approach can further reduce\nreplication by up to 16.82% with similar, if not improved, image quality.",
    "pdf_url": "http://arxiv.org/pdf/2505.21848v1",
    "published": "2025-05-28T00:29:20+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.21847v2",
    "title": "RePaViT: Scalable Vision Transformer Acceleration via Structural Reparameterization on Feedforward Network Layers",
    "authors": [
      "Xuwei Xu",
      "Yang Li",
      "Yudong Chen",
      "Jiajun Liu",
      "Sen Wang"
    ],
    "abstract": "We reveal that feedforward network (FFN) layers, rather than attention\nlayers, are the primary contributors to Vision Transformer (ViT) inference\nlatency, with their impact signifying as model size increases. This finding\nhighlights a critical opportunity for optimizing the efficiency of large-scale\nViTs by focusing on FFN layers. In this work, we propose a novel channel idle\nmechanism that facilitates post-training structural reparameterization for\nefficient FFN layers during testing. Specifically, a set of feature channels\nremains idle and bypasses the nonlinear activation function in each FFN layer,\nthereby forming a linear pathway that enables structural reparameterization\nduring inference. This mechanism results in a family of ReParameterizable\nVision Transformers (RePaViTs), which achieve remarkable latency reductions\nwith acceptable sacrifices (sometimes gains) in accuracy across various ViTs.\nThe benefits of our method scale consistently with model sizes, demonstrating\ngreater speed improvements and progressively narrowing accuracy gaps or even\nhigher accuracies on larger models. In particular, RePa-ViT-Large and\nRePa-ViT-Huge enjoy 66.8% and 68.7% speed-ups with +1.7% and +1.1% higher top-1\naccuracies under the same training strategy, respectively. RePaViT is the first\nto employ structural reparameterization on FFN layers to expedite ViTs to our\nbest knowledge, and we believe that it represents an auspicious direction for\nefficient ViTs. Source code is available at\nhttps://github.com/Ackesnal/RePaViT.",
    "pdf_url": "http://arxiv.org/pdf/2505.21847v2",
    "published": "2025-05-28T00:27:18+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.21846v1",
    "title": "Ultra High Energy Cosmic Rays",
    "authors": [
      "No√©mie Globus",
      "Roger Blandford"
    ],
    "abstract": "Ultra High Energy Cosmic Rays, UHECR, are charged particles with energies\nbetween $\\sim10^{18}\\,{\\rm eV}$ and $\\sim3\\times10^{20}\\,{\\rm eV}\\sim50\\,{\\rm\nJ}$. They exhibit fundamental physics at energies inaccessible to terrestrial\naccelerators, challenge experimental physics and connect strongly to\nastronomical observations through electromagnetic, neutrino and even\ngravitational wave channels. There has been much theoretical and observational\nprogress in the sixty years that have elapsed since the discovery of UHECR, to\ndivine their nature and identify their sources. The highest energy UHECR appear\nto be heavy nuclei with rigidity extending up to $\\sim10\\,{\\rm EV}$; A\nsignificant ($6.9\\sigma$) dipole anisotropy has been measured but our poor\nunderstanding of the Galactic magnetic fields makes this hard to interpret; The\nUHECR luminosity density is $\\sim 10^{44}$ erg Mpc$^{-3}$ yr$^{-1}$ which\nconstrains explanations of their origin; The most promising acceleration\nmechanisms involve diffusive shock acceleration and unipolar induction; The\nmost promising sources include intergalactic accretion shocks, and relativistic\njets from stellar-mass or supermassive black holes. We explore the prospects\nfor using the highest energy events, combined with multimessenger astronomy, to\nhelp us solve the riddle of UHECR.",
    "pdf_url": "http://arxiv.org/pdf/2505.21846v1",
    "published": "2025-05-28T00:25:23+00:00",
    "categories": [
      "astro-ph.HE"
    ],
    "primary_category": "astro-ph.HE"
  },
  {
    "id": "http://arxiv.org/abs/2505.21845v1",
    "title": "Spectral clustering for dependent community Hawkes process models of temporal networks",
    "authors": [
      "Lingfei Zhao",
      "Hadeel Soliman",
      "Kevin S. Xu",
      "Subhadeep Paul"
    ],
    "abstract": "Temporal networks observed continuously over time through timestamped\nrelational events data are commonly encountered in application settings\nincluding online social media communications, financial transactions, and\ninternational relations. Temporal networks often exhibit community structure\nand strong dependence patterns among node pairs. This dependence can be modeled\nthrough mutual excitations, where an interaction event from a sender to a\nreceiver node increases the possibility of future events among other node\npairs.\n  We provide statistical results for a class of models that we call dependent\ncommunity Hawkes (DCH) models, which combine the stochastic block model with\nmutually exciting Hawkes processes for modeling both community structure and\ndependence among node pairs, respectively. We derive a non-asymptotic upper\nbound on the misclustering error of spectral clustering on the event count\nmatrix as a function of the number of nodes and communities, time duration, and\nthe amount of dependence in the model. Our result leverages recent results on\nbounding an appropriate distance between a multivariate Hawkes process count\nvector and a Gaussian vector, along with results from random matrix theory. We\nalso propose a DCH model that incorporates only self and reciprocal excitation\nalong with highly scalable parameter estimation using a Generalized Method of\nMoments (GMM) estimator that we demonstrate to be consistent for growing\nnetwork size and time duration.",
    "pdf_url": "http://arxiv.org/pdf/2505.21845v1",
    "published": "2025-05-28T00:25:10+00:00",
    "categories": [
      "stat.ML",
      "cs.LG",
      "cs.SI",
      "stat.ME"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2505.21844v1",
    "title": "Test-Time Adaptation of Vision-Language Models for Open-Vocabulary Semantic Segmentation",
    "authors": [
      "Mehrdad Noori",
      "David Osowiechi",
      "Gustavo Adolfo Vargas Hakim",
      "Ali Bahri",
      "Moslem Yazdanpanah",
      "Sahar Dastani",
      "Farzad Beizaee",
      "Ismail Ben Ayed",
      "Christian Desrosiers"
    ],
    "abstract": "Recently, test-time adaptation has attracted wide interest in the context of\nvision-language models for image classification. However, to the best of our\nknowledge, the problem is completely overlooked in dense prediction tasks such\nas Open-Vocabulary Semantic Segmentation (OVSS). In response, we propose a\nnovel TTA method tailored to adapting VLMs for segmentation during test time.\nUnlike TTA methods for image classification, our Multi-Level and Multi-Prompt\n(MLMP) entropy minimization integrates features from intermediate\nvision-encoder layers and is performed with different text-prompt templates at\nboth the global CLS token and local pixel-wise levels. Our approach could be\nused as plug-and-play for any segmentation network, does not require additional\ntraining data or labels, and remains effective even with a single test sample.\nFurthermore, we introduce a comprehensive OVSS TTA benchmark suite, which\nintegrates a rigorous evaluation protocol, seven segmentation datasets, and 15\ncommon corruptions, with a total of 82 distinct test scenarios, establishing a\nstandardized and comprehensive testbed for future TTA research in\nopen-vocabulary segmentation. Our experiments on this suite demonstrate that\nour segmentation-tailored method consistently delivers significant gains over\ndirect adoption of TTA classification baselines.",
    "pdf_url": "http://arxiv.org/pdf/2505.21844v1",
    "published": "2025-05-28T00:24:47+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2505.21843v2",
    "title": "Determination of Light Curve Parameters of Poorly Studied Eclipsing Variables Using Data from Tess and Other Sky Surveys",
    "authors": [
      "Vladyslava I. Marsakova",
      "Ivan L. Andronov",
      "Victoriia O. Borshchenko",
      "Illia. A. Garbazhii-Romanchenko",
      "Anastasiia D. Lashkova",
      "Sofia A. Kreminska",
      "Pavol A. Dubovsky",
      "Vladyslav V. Dubovskyi",
      "Karol Petrik"
    ],
    "abstract": "A group of poorly studied eclipsing variables (the classification of which is\nmarked as uncertain and/or the period of brightness changes is uncertain) has\nbeen studied with the using of the photometric observations of the TESS mission\nand NSVS, ASAS-SN sky surveys. We also obtained some observations covering the\nbrightness minima of our variables by our group using the telescopes at\nAstronomical Observatory on Kolonica Saddle (Slovakia) and Observatory and\nPlanetarium in Hlohovec (Slovakia) during the \"Variable-2024\" astrocamp. The\nperiods and classification were corrected. For NSV 575 and NSV 014 the periods\nwere found for the first time, but it is doubtful that NSV 014 is an eclipsing\nvariable, because there are no eclipses but the asymmetric wave is present,\nwhich indicates that the variable star can be re-classified as a low-amplitude\npulsating one. Different methods were used for approximation of the light\ncurves and further calculation of stellar system's parameters such as eclipse\ndepths and durations, values of reflection effect and effect of ellipticity of\nstars. The initial period was estimated using the periodogram based on the\ntrigonometrical polynomial fit of high order (up to 10). For better\napproximation of the complete eclipsing phase curve, the \"New Algol Variable\"\n(NAV) software was used. The methods of \"asymptotic parabolas\" and\n\"wall-supported asymptotic parabolas\" were used for calculation of moments of\neclipses, which use only near-eclipse part of the observations instead of a\ncomplete curve. These methods were implemented in the software MAVKA among a\nlarger set of features. For the variables NSV 489 and NSV 1884, our moments of\neclipses and the ones found in the literature, were used for the O-C curves.\nFor NSV 489, the period was adjusted taking into account the slope of the O-C\ndiagram.",
    "pdf_url": "http://arxiv.org/pdf/2505.21843v2",
    "published": "2025-05-28T00:22:02+00:00",
    "categories": [
      "astro-ph.SR",
      "astro-ph.IM",
      "85",
      "D.1; J.2"
    ],
    "primary_category": "astro-ph.SR"
  },
  {
    "id": "http://arxiv.org/abs/2505.21842v1",
    "title": "A Physics-Informed Learning Framework to Solve the Infinite-Horizon Optimal Control Problem",
    "authors": [
      "Filippos Fotiadis",
      "Kyriakos G. Vamvoudakis"
    ],
    "abstract": "We propose a physics-informed neural networks (PINNs) framework to solve the\ninfinite-horizon optimal control problem of nonlinear systems. In particular,\nsince PINNs are generally able to solve a class of partial differential\nequations (PDEs), they can be employed to learn the value function of the\ninfinite-horizon optimal control problem via solving the associated\nsteady-state Hamilton-Jacobi-Bellman (HJB) equation. However, an issue here is\nthat the steady-state HJB equation generally yields multiple solutions; hence\nif PINNs are directly employed to it, they may end up approximating a solution\nthat is different from the optimal value function of the problem. We tackle\nthis by instead applying PINNs to a finite-horizon variant of the steady-state\nHJB that has a unique solution, and which uniformly approximates the optimal\nvalue function as the horizon increases. An algorithm to verify if the chosen\nhorizon is large enough is also given, as well as a method to extend it -- with\nreduced computations and robustness to approximation errors -- in case it is\nnot. Unlike many existing methods, the proposed technique works well with\nnon-polynomial basis functions, does not require prior knowledge of a\nstabilizing controller, and does not perform iterative policy evaluations.\nSimulations are performed, which verify and clarify theoretical findings.",
    "pdf_url": "http://arxiv.org/pdf/2505.21842v1",
    "published": "2025-05-28T00:21:49+00:00",
    "categories": [
      "eess.SY",
      "cs.LG",
      "cs.SY"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2505.21841v1",
    "title": "An Optimistic Algorithm for online CMDPS with Anytime Adversarial Constraints",
    "authors": [
      "Jiahui Zhu",
      "Kihyun Yu",
      "Dabeen Lee",
      "Xin Liu",
      "Honghao Wei"
    ],
    "abstract": "Online safe reinforcement learning (RL) plays a key role in dynamic\nenvironments, with applications in autonomous driving, robotics, and\ncybersecurity. The objective is to learn optimal policies that maximize rewards\nwhile satisfying safety constraints modeled by constrained Markov decision\nprocesses (CMDPs). Existing methods achieve sublinear regret under stochastic\nconstraints but often fail in adversarial settings, where constraints are\nunknown, time-varying, and potentially adversarially designed. In this paper,\nwe propose the Optimistic Mirror Descent Primal-Dual (OMDPD) algorithm, the\nfirst to address online CMDPs with anytime adversarial constraints. OMDPD\nachieves optimal regret O(sqrt(K)) and strong constraint violation O(sqrt(K))\nwithout relying on Slater's condition or the existence of a strictly known safe\npolicy. We further show that access to accurate estimates of rewards and\ntransitions can further improve these bounds. Our results offer practical\nguarantees for safe decision-making in adversarial environments.",
    "pdf_url": "http://arxiv.org/pdf/2505.21841v1",
    "published": "2025-05-28T00:16:34+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2505.21840v1",
    "title": "Matter Accumulations and Accretion Tori around Wormholes",
    "authors": [
      "Kristian Gjorgjieski",
      "Jutta Kunz",
      "Petya Nedkova"
    ],
    "abstract": "We study circular orbits and accretion structures around symmetric wormholes.\nAs exemplary solutions we choose three different wormhole spacetimes, namely\nrotating traversable wormholes from the Teo class, the rotating Simpson-Visser\nmetric with the parameter spectrum corresponding to wormholes and a static\nwormhole from beyond Horndeski theories. We show the existence of a spectrum of\ncircular orbits at the wormhole throat for each of these wormhole solutions and\nanalyze the boundaries of this spectrum across the respective wormhole\nparameter range. For each of the solutions we identified that vast regions of\nthe parameter space correspond to stable orbits. The presence of this orbit\nspectrum can be linked through accretion disk models to matter accumulations\nwhich may form at the throat. We present here examples of such disk solutions\nby implementing the Polish Doughnut model. In some cases, these matter\naccumulations are encapsulating the throat and could imply central bright\nregions of the wormhole spacetime. Furthermore, the combined analysis of the\nequatorial Keplerian orbits and the throat orbits, leads to a set of different\ndisk configurations, where matter accumulations at the throat may be present\nwith outer tori around them, in some cases also as a connected structure. Our\nresults may hint to possible instabilities of wormholes, especially if they\nhave an ergoregion. Moreover, wormholes with such disks, may appear more\nstar-like when it comes to their observational signature, due to the\ncentralized and more spherical emission profile associated with the possible\nmatter accumulations at the throat.",
    "pdf_url": "http://arxiv.org/pdf/2505.21840v1",
    "published": "2025-05-28T00:14:58+00:00",
    "categories": [
      "gr-qc"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2505.21839v1",
    "title": "Polytropic Wind-Driven Bubbles and their Shock Structures in Radially Stratified Ambient Media",
    "authors": [
      "Dmitrii Zagorulia",
      "Hsien Shang",
      "Ruben Krasnopolsky"
    ],
    "abstract": "We extend the analytic expressions for polytropic wind-driven bubbles and\ntheir shock structures, formulated initially in Koo and McKee 1992(a,b),\nfocusing on spherically symmetric configurations in astrophysical environments\nwith $\\rho\\propto r^{-2}$, which arises naturally in the star-forming\nenvironment and has applications to winds flowing into a preexisting bubble.\nWind luminosity is assumed to be constant, and as a result the shock velocities\nof these bubbles are constant in time. The ratio of specific heats is assumed\nto be the same in the shocked ambient medium and the shocked wind. Numerical\nresults are presented for one selected ratio of wind density to ambient\ndensity. Exact ODEs are written for the compressed wind region and approximate\nsolutions are found by fitting the ODE solutions. By analyzing the interactions\nbetween stellar winds and ambient media in the strong compression limit, we\nmodel the formation and evolution of spherical bubbles, highlighting their\nshock fronts and contact discontinuities. Our analytic method provides an\nintuitive approach to calculating the thickness of bubble shells, which is\ncrucial for understanding their dynamics and observational characteristics. A\nnumerical method explores conditions without explicitly requiring the strong\ncompression limit, and then we compare numerical to analytical results under\nvarious conditions.",
    "pdf_url": "http://arxiv.org/pdf/2505.21839v1",
    "published": "2025-05-28T00:14:04+00:00",
    "categories": [
      "astro-ph.HE",
      "physics.comp-ph"
    ],
    "primary_category": "astro-ph.HE"
  },
  {
    "id": "http://arxiv.org/abs/2505.21838v1",
    "title": "Nonadaptive Output Regulation of Second-Order Nonlinear Uncertain Systems",
    "authors": [
      "Maobin Lu",
      "Martin Guay",
      "Telema Harry",
      "Shimin Wang",
      "Jordan Cooper"
    ],
    "abstract": "This paper investigates the robust output regulation problem of second-order\nnonlinear uncertain systems with an unknown exosystem. Instead of the adaptive\ncontrol approach, this paper resorts to a robust control methodology to solve\nthe problem and thus avoid the bursting phenomenon. In particular, this paper\nconstructs generic internal models for the steady-state state and input\nvariables of the system. By introducing a coordinate transformation, this paper\nconverts the robust output regulation problem into a nonadaptive stabilization\nproblem of an augmented system composed of the second-order nonlinear uncertain\nsystem and the generic internal models. Then, we design the stabilization\ncontrol law and construct a strict Lyapunov function that guarantees the\nrobustness with respect to unmodeled disturbances. The analysis shows that the\noutput zeroing manifold of the augmented system can be made attractive by the\nproposed nonadaptive control law, which solves the robust output regulation\nproblem. Finally, we demonstrate the effectiveness of the proposed nonadaptive\ninternal model approach by its application to the control of the Duffing\nsystem.",
    "pdf_url": "http://arxiv.org/pdf/2505.21838v1",
    "published": "2025-05-28T00:13:37+00:00",
    "categories": [
      "eess.SY",
      "cs.AI",
      "cs.SY",
      "math.OC",
      "nlin.CD"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2505.21837v1",
    "title": "UniMoGen: Universal Motion Generation",
    "authors": [
      "Aliasghar Khani",
      "Arianna Rampini",
      "Evan Atherton",
      "Bruno Roy"
    ],
    "abstract": "Motion generation is a cornerstone of computer graphics, animation, gaming,\nand robotics, enabling the creation of realistic and varied character\nmovements. A significant limitation of existing methods is their reliance on\nspecific skeletal structures, which restricts their versatility across\ndifferent characters. To overcome this, we introduce UniMoGen, a novel\nUNet-based diffusion model designed for skeleton-agnostic motion generation.\nUniMoGen can be trained on motion data from diverse characters, such as humans\nand animals, without the need for a predefined maximum number of joints. By\ndynamically processing only the necessary joints for each character, our model\nachieves both skeleton agnosticism and computational efficiency. Key features\nof UniMoGen include controllability via style and trajectory inputs, and the\nability to continue motions from past frames. We demonstrate UniMoGen's\neffectiveness on the 100style dataset, where it outperforms state-of-the-art\nmethods in diverse character motion generation. Furthermore, when trained on\nboth the 100style and LAFAN1 datasets, which use different skeletons, UniMoGen\nachieves high performance and improved efficiency across both skeletons. These\nresults highlight UniMoGen's potential to advance motion generation by\nproviding a flexible, efficient, and controllable solution for a wide range of\ncharacter animations.",
    "pdf_url": "http://arxiv.org/pdf/2505.21837v1",
    "published": "2025-05-28T00:03:39+00:00",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CV"
  }
]