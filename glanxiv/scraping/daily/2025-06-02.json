[
  {
    "id": "http://arxiv.org/abs/2506.02331v2",
    "title": "Four-point correlation functions in axion inflation",
    "authors": [
      "Hing-Tong Cho",
      "Kin-Wang Ng"
    ],
    "abstract": "We study parity violation in the early universe by examining the four-point\ncorrelation function within the axion inflation model. Using an open quantum\nsystem formalism from our previous work, we calculate the influence functional\nto fourth order, from which we then derive the inflaton four-point correlation\nfunction. When we decompose this function using isotropic basis functions, the\nexpansion coefficients $\\zeta_{\\ell',\\ell'',\\ell'''}$ naturally split into\nparity-even and parity-odd components. In the large $\\xi$ approximation, which\nenhances the production of right-handed photons in the model, the derivation of\nthese coefficients simplifies. We work out the lowest-order nonvanishing\nparity-odd $\\zeta_{234}$ term which clearly indicates the presence of parity\nviolation. Moreover, our derived values of the coefficients are consistent with\nrecent observational data from galaxy surveys.",
    "pdf_url": "http://arxiv.org/pdf/2506.02331v2",
    "published": "2025-06-02T23:52:53+00:00",
    "categories": [
      "hep-ph",
      "astro-ph.CO",
      "gr-qc",
      "hep-th"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.02330v1",
    "title": "Measurement of the longitudinal flow-plane decorrelation using multi-plane cumulants in sqrt(s_NN) = 200 GeV Au+Au, Ru+Ru, and Zr+Zr collisions",
    "authors": [
      "The STAR Collaboration"
    ],
    "abstract": "Measurements of the variation of anisotropic flow-plane angles (Psi_n) with\nrapidity, commonly known as flow-plane decorrelation, provide important\ninsights into the initial conditions of the matter produced in heavy-ion\ncollisions. In this paper, using data collected by the STAR experiment, we\nreport the first measurement of the four-plane cumulant observable T_n{ba;dc} =\n<<sin[n(Psi_n^b - Psi_n^a)] sin[n(Psi_n^d - Psi_n^c)]>>, where superscripts a,\nb, c, and d denote sequential regions in pseudorapidity, with a corresponding\nto the most backward pseudorapidity region. The measurement is performed for\nelliptic and triangular flow (i.e., n = 2 and 3) in Au+Au and isobar (Ru+Ru,\nZr+Zr) collisions at sqrt(s_NN) = 200 GeV. The goal of calculating the\ncorrelation of flow-plane angle variations from backward pseudorapidity (eta_a)\nto mid-pseudorapidity (eta_b) region and from mid-pseudorapidity (eta_c) to\nforward pseudorapidity (eta_d) region, is to probe the systematic variation of\nflow angle over a wide pseudorapidity range. In mid-central collisions (10-30\npercent centrality), we find T_2{ba;dc} = -0.004 +/- 0.001 (stat) +/- 0.002\n(syst), independent of the collision system. Such a small value of T_2 favors a\n\"random-walk\" variation of the flow-plane angles, where the rapidity\ncorrelation length is smaller than the pseudorapidity region under study. These\nmeasurements provide new information on the decorrelation patterns in the\nsystem and offer a quantitative estimate of possible systematic variations in\nanisotropic flow angles-such as \"twist\" between forward and backward\npseudorapidity regions. This opens new opportunities for understanding the\nthree-dimensional structure of the quark-gluon plasma created in heavy-ion\ncollisions.",
    "pdf_url": "http://arxiv.org/pdf/2506.02330v1",
    "published": "2025-06-02T23:51:41+00:00",
    "categories": [
      "nucl-ex",
      "hep-ex"
    ],
    "primary_category": "nucl-ex"
  },
  {
    "id": "http://arxiv.org/abs/2506.02329v1",
    "title": "A remark on Continuous K-theory and Fourier-Sato transform",
    "authors": [
      "Bingyu Zhang"
    ],
    "abstract": "In this note, we prove a generalization of Efimov's computation for the\nuniversal localizing invariant of categories of sheaves with certain\nmicrosupport constraints. The proof is based on certain categorical\nequivalences given by the Fourier-Sato transform, which is different from the\noriginal proof. As an application, we compute the universal localizing\ninvariant of the category of almost quasi-coherent sheaves on the Novikov toric\nscheme introduced by Vaintrob.",
    "pdf_url": "http://arxiv.org/pdf/2506.02329v1",
    "published": "2025-06-02T23:51:31+00:00",
    "categories": [
      "math.AT",
      "math.KT",
      "math.SG"
    ],
    "primary_category": "math.AT"
  },
  {
    "id": "http://arxiv.org/abs/2506.02328v1",
    "title": "The transformative capability of quantum-accurate machine learning interatomic potentials",
    "authors": [
      "Alfredo A. Correa",
      "Sebastien Hamel"
    ],
    "abstract": "Many materials's properties and phase boundaries are generally not well known\nunder extreme pressure and temperature conditions. This is a consequence of the\nscarcity of experimental information and the difficulty of extrapolating\napproximations to the atomic interactions in such conditions. Nguyen-Cong and\ncolleagues, in their publication (J.Phys.Chem.Lett. 15, 1152 (2024)), achieved\nan impressive result using a SNAP (Spectral Neighbor Analysis Potential), an\ninteratomic potential for carbon obtained by machine learning techniques. In a\nway, their contribution closes a full circle of research that spanned more than\nthree decades.",
    "pdf_url": "http://arxiv.org/pdf/2506.02328v1",
    "published": "2025-06-02T23:51:27+00:00",
    "categories": [
      "physics.comp-ph"
    ],
    "primary_category": "physics.comp-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.02327v1",
    "title": "Medical World Model: Generative Simulation of Tumor Evolution for Treatment Planning",
    "authors": [
      "Yijun Yang",
      "Zhao-Yang Wang",
      "Qiuping Liu",
      "Shuwen Sun",
      "Kang Wang",
      "Rama Chellappa",
      "Zongwei Zhou",
      "Alan Yuille",
      "Lei Zhu",
      "Yu-Dong Zhang",
      "Jieneng Chen"
    ],
    "abstract": "Providing effective treatment and making informed clinical decisions are\nessential goals of modern medicine and clinical care. We are interested in\nsimulating disease dynamics for clinical decision-making, leveraging recent\nadvances in large generative models. To this end, we introduce the Medical\nWorld Model (MeWM), the first world model in medicine that visually predicts\nfuture disease states based on clinical decisions. MeWM comprises (i)\nvision-language models to serve as policy models, and (ii) tumor generative\nmodels as dynamics models. The policy model generates action plans, such as\nclinical treatments, while the dynamics model simulates tumor progression or\nregression under given treatment conditions. Building on this, we propose the\ninverse dynamics model that applies survival analysis to the simulated\npost-treatment tumor, enabling the evaluation of treatment efficacy and the\nselection of the optimal clinical action plan. As a result, the proposed MeWM\nsimulates disease dynamics by synthesizing post-treatment tumors, with\nstate-of-the-art specificity in Turing tests evaluated by radiologists.\nSimultaneously, its inverse dynamics model outperforms medical-specialized GPTs\nin optimizing individualized treatment protocols across all metrics. Notably,\nMeWM improves clinical decision-making for interventional physicians, boosting\nF1-score in selecting the optimal TACE protocol by 13%, paving the way for\nfuture integration of medical world models as the second readers.",
    "pdf_url": "http://arxiv.org/pdf/2506.02327v1",
    "published": "2025-06-02T23:50:40+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.02326v1",
    "title": "Something Just Like TRuST : Toxicity Recognition of Span and Target",
    "authors": [
      "Berk Atil",
      "Namrata Sureddy",
      "Rebecca J. Passonneau"
    ],
    "abstract": "Toxicity in online content, including content generated by language models,\nhas become a critical concern due to its potential for negative psychological\nand social impact. This paper introduces TRuST, a comprehensive dataset\ndesigned to improve toxicity detection that merges existing datasets, and has\nlabels for toxicity, target social group, and toxic spans. It includes a\ndiverse range of target groups such as ethnicity, gender, religion, disability,\nand politics, with both human/machine-annotated and human machine-generated\ndata. We benchmark state-of-the-art large language models (LLMs) on toxicity\ndetection, target group identification, and toxic span extraction. We find that\nfine-tuned models consistently outperform zero-shot and few-shot prompting,\nthough performance remains low for certain social groups. Further, reasoning\ncapabilities do not significantly improve performance, indicating that LLMs\nhave weak social reasoning skills.",
    "pdf_url": "http://arxiv.org/pdf/2506.02326v1",
    "published": "2025-06-02T23:48:16+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.02325v1",
    "title": "Ultrahigh-Q Torsional Nanomechanics through Bayesian Optimization",
    "authors": [
      "Atkin D. Hyatt",
      "Aman R. Agrawal",
      "Christian M. Pluchar",
      "Charles A. Condos",
      "Dalziel J. Wilson"
    ],
    "abstract": "Recently it was discovered that torsion modes of strained nanoribbons exhibit\ndissipation dilution, giving a route to enhanced torque sensing and quantum\noptomechanics experiments. As with all strained nanomechanical resonators, an\nimportant limitation is bending loss due to mode curvature at the clamps. Here\nwe use Bayesian optimization to design nanoribbons with optimal dissipation\ndilution of the fundamental torsion mode. Applied to centimeter-scale\nSi$_3$N$_4$ nanoribbons, we realize $Q$ factors exceeding 100 million and\n$Q$-frequency products exceeding $10^{13}$ Hz at room temperature. The thermal\ntorque sensitivity of the reported devices is at the level of\n$10^{-20}\\;\\text{N}\\,\\text{m}/\\sqrt{\\text{Hz}}$ and the zero point angular\ndisplacement spectral density is at the level of\n$10^{-10}\\;\\text{rad}/\\sqrt{\\text{Hz}}$; they are moreover simple to fabricate,\nhave high thermal conductivity, and can be heavily mass-loaded without\ndiminishing their $Q$, making them attractive for diverse fundamental and\napplied weak force sensing tasks.",
    "pdf_url": "http://arxiv.org/pdf/2506.02325v1",
    "published": "2025-06-02T23:45:41+00:00",
    "categories": [
      "cond-mat.mes-hall",
      "physics.app-ph"
    ],
    "primary_category": "cond-mat.mes-hall"
  },
  {
    "id": "http://arxiv.org/abs/2506.02324v1",
    "title": "Are Crypto Ecosystems (De)centralizing? A Framework for Longitudinal Analysis",
    "authors": [
      "Harang Ju",
      "Ehsan Valavi",
      "Madhav Kumar",
      "Sinan Aral"
    ],
    "abstract": "Blockchain technology relies on decentralization to resist faults and attacks\nwhile operating without trusted intermediaries. Although industry experts have\ntouted decentralization as central to their promise and disruptive potential,\nit is still unclear whether the crypto ecosystems built around blockchains are\nbecoming more or less decentralized over time. As crypto plays an increasing\nrole in facilitating economic transactions and peer-to-peer interactions,\nmeasuring their decentralization becomes even more essential. We thus propose a\nsystematic framework for measuring the decentralization of crypto ecosystems\nover time and compare commonly used decentralization metrics. We applied this\nframework to seven prominent crypto ecosystems, across five distinct subsystems\nand across their lifetime for over 15 years. Our analysis revealed that while\ncrypto has largely become more decentralized over time, recent trends show a\nshift toward centralization in the consensus layer, NFT marketplaces, and\ndevelopers. Our framework and results inform researchers, policymakers, and\npractitioners about the design, regulation, and implementation of crypto\necosystems and provide a systematic, replicable foundation for future studies.",
    "pdf_url": "http://arxiv.org/pdf/2506.02324v1",
    "published": "2025-06-02T23:45:33+00:00",
    "categories": [
      "cs.CR"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2506.14801v1",
    "title": "GLASD: A Loss-Function-Agnostic Global Optimizer for Robust Correlation Estimation under Data Contamination and Heavy Tails",
    "authors": [
      "Priyam Das"
    ],
    "abstract": "Robust correlation estimation is essential in high-dimensional settings,\nparticularly when data are contaminated by outliers or exhibit heavy-tailed\nbehavior. Many robust loss functions of practical interest-such as those\ninvolving truncation or redescending M-estimators-lead to objective functions\nthat are inherently non-convex and non-differentiable. Traditional methods\ntypically focus on a single loss function tailored to a specific contamination\nmodel and develop custom algorithms tightly coupled with that loss, limiting\ngenerality and adaptability. We introduce GLASD (Global Adaptive Stochastic\nDescent), a general-purpose black-box optimization algorithm designed to\noperate over the manifold of positive definite correlation matrices. Unlike\nconventional solvers, GLASD requires no gradient information and imposes no\nassumptions of convexity or smoothness, making it ideally suited for optimizing\na wide class of loss functions-including non-convex, non-differentiable, or\ndiscontinuous objectives. This flexibility allows GLASD to serve as a unified\nframework for robust estimation under arbitrary user-defined criteria. We\ndemonstrate its effectiveness through extensive simulations involving\ncontaminated and heavy-tailed distributions, as well as a real-data application\nto breast cancer proteomic network inference, where GLASD successfully\nidentifies biologically plausible interactions despite the presence of\noutliers. The proposed method is scalable, constraint-aware, and available as\nopen-source software at GitHub.",
    "pdf_url": "http://arxiv.org/pdf/2506.14801v1",
    "published": "2025-06-02T23:34:09+00:00",
    "categories": [
      "stat.AP",
      "math.OC",
      "stat.CO"
    ],
    "primary_category": "stat.AP"
  },
  {
    "id": "http://arxiv.org/abs/2506.02323v1",
    "title": "Sensitivity-Aware Density Estimation in Multiple Dimensions",
    "authors": [
      "Aleix Boquet-Pujadas",
      "Pol del Aguila Pla",
      "Michael Unser"
    ],
    "abstract": "We formulate an optimization problem to estimate probability densities in the\ncontext of multidimensional problems that are sampled with uneven probability.\nIt considers detector sensitivity as an heterogeneous density and takes\nadvantage of the computational speed and flexible boundary conditions offered\nby splines on a grid. We choose to regularize the Hessian of the spline via the\nnuclear norm to promote sparsity. As a result, the method is spatially adaptive\nand stable against the choice of the regularization parameter, which plays the\nrole of the bandwidth. We test our computational pipeline on standard densities\nand provide software. We also present a new approach to PET rebinning as an\napplication of our framework.",
    "pdf_url": "http://arxiv.org/pdf/2506.02323v1",
    "published": "2025-06-02T23:28:49+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CE",
      "cs.DS",
      "eess.SP"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.02322v1",
    "title": "New level density parameter beyond Egidy-Bucurescu's systematics",
    "authors": [
      "Junzhe Zhang",
      "Yanan Zheng",
      "Caixin Yuan",
      "Yangyang Shen",
      "Yingchen Mao"
    ],
    "abstract": "Extending beyond the Egidy-Bucurescu systematics, the nuclear level density\nparameters (LDPs) for the back-shifted Fermi gas model were compiled. Three\nforms of LDPs were fitted: the liquid-drop model (LDM), the droplet model (DM),\nand the power-law dependence on mass number A. Additionally, the\nroot-mean-square deviations (RMSDs) of the new LDPs and existing literature\nvalues were calculated. The newly fitted global LDM-type parameters outperform\nthe commonly used Toke-Swiatecki parameters in various statistical model\ncalculations. In contrast, neither the global nor the combined DM-type\nparameters yielded satisfactory results. Among the tested parameter sets, the\nwidely adopted Reisdorf parameters exhibited the best overall performance, as\nevidenced by the larger number of experimental data points falling within their\nnarrower RMSD confidence intervals. For the power-law A-dependence, the new\nglobal parameters performed better than the existing homogeneous ones. The\nground-state deformation and isospin correction factors had minimal overall\nimpact on the LDP fits. However, the current results suggest that theoretical\ncalculations for transitional nuclei should account for ground-state\ndeformation effects.",
    "pdf_url": "http://arxiv.org/pdf/2506.02322v1",
    "published": "2025-06-02T23:28:48+00:00",
    "categories": [
      "nucl-th"
    ],
    "primary_category": "nucl-th"
  },
  {
    "id": "http://arxiv.org/abs/2506.02321v1",
    "title": "Quantifying Misattribution Unfairness in Authorship Attribution",
    "authors": [
      "Pegah Alipoormolabashi",
      "Ajay Patel",
      "Niranjan Balasubramanian"
    ],
    "abstract": "Authorship misattribution can have profound consequences in real life. In\nforensic settings simply being considered as one of the potential authors of an\nevidential piece of text or communication can result in undesirable scrutiny.\nThis raises a fairness question: Is every author in the candidate pool at equal\nrisk of misattribution? Standard evaluation measures for authorship attribution\nsystems do not explicitly account for this notion of fairness. We introduce a\nsimple measure, Misattribution Unfairness Index (MAUIk), which is based on how\noften authors are ranked in the top k for texts they did not write. Using this\nmeasure we quantify the unfairness of five models on two different datasets.\nAll models exhibit high levels of unfairness with increased risks for some\nauthors. Furthermore, we find that this unfairness relates to how the models\nembed the authors as vectors in the latent search space. In particular, we\nobserve that the risk of misattribution is higher for authors closer to the\ncentroid (or center) of the embedded authors in the haystack. These results\nindicate the potential for harm and the need for communicating with and\ncalibrating end users on misattribution risk when building and providing such\nmodels for downstream use.",
    "pdf_url": "http://arxiv.org/pdf/2506.02321v1",
    "published": "2025-06-02T23:28:24+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.02320v1",
    "title": "Greedy recursion parameter selection for the One-Way Navier-Stokes (OWNS) equations",
    "authors": [
      "Michael K. Sleeman",
      "Tim Colonius"
    ],
    "abstract": "The One-Way Navier-Stokes (OWNS) equations use recursive filtering to\nconstruct efficient, well-posed one-way approximations to linear hyperbolic\nsystems. The recursion parameters are critical to the accuracy and stability of\nthe method, and have previously been chosen based on heuristic estimates of key\neigenvalues (or their branches), which converges slowly and requires\ntrial-and-error tuning for new systems. We review the projection and recursive\nOWNS formulations (OWNS-P and OWNS-R) for inhomogeneous equations and propose a\ngreedy algorithm for parameter selection. We show that it converges faster and\nleads to a net decrease in computational cost.",
    "pdf_url": "http://arxiv.org/pdf/2506.02320v1",
    "published": "2025-06-02T23:15:41+00:00",
    "categories": [
      "math.NA",
      "cs.NA",
      "physics.comp-ph",
      "physics.flu-dyn"
    ],
    "primary_category": "math.NA"
  },
  {
    "id": "http://arxiv.org/abs/2506.02319v1",
    "title": "Finiteness properties of stabilisers of oligomorphic actions",
    "authors": [
      "Francesco Fournier-Facio",
      "Peter H. Kropholler",
      "Robert Alonzo Lyman",
      "Matthew C. B. Zaremsky"
    ],
    "abstract": "An action of a group on a set is oligomorphic if it has finitely many orbits\nof $n$-element subsets for all $n$. We prove that for a large class of groups\n(including all groups of finite virtual cohomological dimension and all\ncountable linear groups), for any oligomorphic action of such a group on an\ninfinite set there exists a finite subset whose stabiliser is not of type\n$\\mathrm{FP}_\\infty$. This leads to obstructions on finiteness properties for\npermutational wreath products and twisted Brin-Thompson groups. We also prove a\nversion for actions on flag complexes, and discuss connections to the\nBoone-Higman conjecture. In the appendix, we improve on the criterion of\nBartholdi-Cornulier-Kochloukova for finiteness properties of wreath products,\nand the criterion of Kropholler-Martino for finiteness properties of\ngraph-wreath products.",
    "pdf_url": "http://arxiv.org/pdf/2506.02319v1",
    "published": "2025-06-02T23:15:33+00:00",
    "categories": [
      "math.GR",
      "math.GT",
      "20F65, 20B07"
    ],
    "primary_category": "math.GR"
  },
  {
    "id": "http://arxiv.org/abs/2506.02318v1",
    "title": "Absorb and Converge: Provable Convergence Guarantee for Absorbing Discrete Diffusion Models",
    "authors": [
      "Yuchen Liang",
      "Renxiang Huang",
      "Lifeng Lai",
      "Ness Shroff",
      "Yingbin Liang"
    ],
    "abstract": "Discrete state space diffusion models have shown significant advantages in\napplications involving discrete data, such as text and image generation. It has\nalso been observed that their performance is highly sensitive to the choice of\nrate matrices, particularly between uniform and absorbing rate matrices. While\nempirical results suggest that absorbing rate matrices often yield better\ngeneration quality compared to uniform rate matrices, existing theoretical\nworks have largely focused on the uniform rate matrices case. Notably,\nconvergence guarantees and error analyses for absorbing diffusion models are\nstill missing. In this work, we provide the first finite-time error bounds and\nconvergence rate analysis for discrete diffusion models using absorbing rate\nmatrices. We begin by deriving an upper bound on the KL divergence of the\nforward process, introducing a surrogate initialization distribution to address\nthe challenge posed by the absorbing stationary distribution, which is a\nsingleton and causes the KL divergence to be ill-defined. We then establish the\nfirst convergence guarantees for both the $\\tau$-leaping and uniformization\nsamplers under absorbing rate matrices, demonstrating improved rates over their\ncounterparts using uniform rate matrices. Furthermore, under suitable\nassumptions, we provide convergence guarantees without early stopping. Our\nanalysis introduces several new technical tools to address challenges unique to\nabsorbing rate matrices. These include a Jensen-type argument for bounding\nforward process convergence, novel techniques for bounding absorbing score\nfunctions, and a non-divergent upper bound on the score near initialization\nthat removes the need of early-stopping.",
    "pdf_url": "http://arxiv.org/pdf/2506.02318v1",
    "published": "2025-06-02T23:14:35+00:00",
    "categories": [
      "cs.LG",
      "eess.SP",
      "math.ST",
      "stat.TH"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.02317v1",
    "title": "Period matrices and homological quasi-trees on discrete Riemann surfaces",
    "authors": [
      "Wai Yeung Lam",
      "On-Hei Solomon Lo",
      "Chi Ho Yuen"
    ],
    "abstract": "We study discrete period matrices associated with graphs cellularly embedded\non closed surfaces, resembling classical period matrices of Riemann surfaces.\nDefined via integrals of discrete harmonic 1-forms, these period matrices are\nknown to encode discrete conformal structure in the sense of circle patterns.\nWe obtain a combinatorial interpretation of the discrete period matrix, where\nits minors correspond to weighted sums over certain spanning subgraphs, which\nwe call homological quasi-trees. Furthermore, we relate the period matrix to\nthe determinant of the Laplacian for a flat complex line bundle. We derive a\ncombinatorial analogue of the Weil-Petersson potential on Teichm\\\"uller space,\nexpressed as a weighted sum over homological quasi-trees. Finally, we prove\nthat the collection of homological quasi-trees form a delta-matroid. The\ndiscrete period matrix plays a role similar to that of the response matrix in\ncircular planar networks, thereby addressing a question posed by Richard\nKenyon.",
    "pdf_url": "http://arxiv.org/pdf/2506.02317v1",
    "published": "2025-06-02T23:13:58+00:00",
    "categories": [
      "math.CV",
      "math-ph",
      "math.CO",
      "math.GT",
      "math.MP",
      "53A70, 52C26, 30F60, 05B35, 05C10"
    ],
    "primary_category": "math.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.02316v2",
    "title": "Rapid stellar and binary population synthesis with COMPAS: methods paper II",
    "authors": [
      "Ilya Mandel",
      "Jeff Riley",
      "Adam Boesky",
      "Adam Brcek",
      "Ryosuke Hirai",
      "Veome Kapil",
      "Mike Y. M. Lau",
      "JD Merritt",
      "Nicolás Rodríguez-Segovia",
      "Isobel Romero-Shaw",
      "Yuzhe Song",
      "Simon Stevenson",
      "Avi Vajpeyi",
      "L. A. C. van Son",
      "Alejandro Vigna-Gómez",
      "Reinhold Willcox"
    ],
    "abstract": "The COMPAS public rapid binary population synthesis code has undergone a\nnumber of key improvements since the original COMPAS methods paper (Team\nCOMPAS: Riley et al., 2022) was published. These include more sophisticated and\nrobust treatments of binary interactions: mass transfer physics,\ncommon-envelope events, tides and gravitational-wave radiation reaction; and\nupdated prescriptions for stellar evolution, winds and supernovae. The code\nstructure and outputs have also been updated, with a focus on improving\nresolution without sacrificing computational speed. This paper describes the\nsubstantive changes in the code between the previous methods paper and COMPAS\nv03.22.01.",
    "pdf_url": "http://arxiv.org/pdf/2506.02316v2",
    "published": "2025-06-02T23:13:50+00:00",
    "categories": [
      "astro-ph.SR",
      "astro-ph.HE",
      "astro-ph.IM"
    ],
    "primary_category": "astro-ph.SR"
  },
  {
    "id": "http://arxiv.org/abs/2506.02315v1",
    "title": "A Data-Based Architecture for Flight Test without Test Points",
    "authors": [
      "D. Isaiah Harp",
      "Joshua Ott",
      "John Alora",
      "Dylan Asmar"
    ],
    "abstract": "The justification for the \"test point\" derives from the test pilot's\nobligation to reproduce faithfully the pre-specified conditions of some model\nprediction. Pilot deviation from those conditions invalidates the model\nassumptions. Flight test aids have been proposed to increase accuracy on more\nchallenging test points. However, the very existence of databands and\ntolerances is the problem more fundamental than inadequate pilot skill. We\npropose a novel approach, which eliminates test points. We start with a\nhigh-fidelity digital model of an air vehicle. Instead of using this model to\ngenerate a point prediction, we use a machine learning method to produce a\nreduced-order model (ROM). The ROM has two important properties. First, it can\ngenerate a prediction based on any set of conditions the pilot flies. Second,\nif the test result at those conditions differ from the prediction, the ROM can\nbe updated using the new data. The outcome of flight test is thus a refined ROM\nat whatever conditions were flown. This ROM in turn updates and validates the\nhigh-fidelity model. We present a single example of this \"point-less\"\narchitecture, using T-38C flight test data. We first use a generic aircraft\nmodel to build a ROM of longitudinal pitching motion as a hypersurface. We then\ningest unconstrained flight test data and use Gaussian Process Regression to\nupdate and condition the hypersurface. By proposing a second-order equivalent\nsystem for the T-38C, this hypersurface then generates parameters necessary to\nassess MIL-STD-1797B compliance for longitudinal dynamics.",
    "pdf_url": "http://arxiv.org/pdf/2506.02315v1",
    "published": "2025-06-02T23:05:52+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.02314v1",
    "title": "ResearchCodeBench: Benchmarking LLMs on Implementing Novel Machine Learning Research Code",
    "authors": [
      "Tianyu Hua",
      "Harper Hua",
      "Violet Xiang",
      "Benjamin Klieger",
      "Sang T. Truong",
      "Weixin Liang",
      "Fan-Yun Sun",
      "Nick Haber"
    ],
    "abstract": "Large language models (LLMs) have shown promise in transforming machine\nlearning research, yet their capability to faithfully implement novel ideas\nfrom recent research papers-ideas unseen during pretraining-remains unclear. We\nintroduce ResearchCodeBench, a benchmark of 212 coding challenges that\nevaluates LLMs' ability to translate cutting-edge ML contributions from top\n2024-2025 research papers into executable code. We assessed 30+ proprietary and\nopen-source LLMs, finding that even the best models correctly implement less\nthan 40% of the code. We find Gemini-2.5-Pro-Preview to perform best at 37.3%\nsuccess rate, with O3 (High) and O4-mini (High) following behind at 32.3% and\n30.8% respectively. We present empirical findings on performance comparison,\ncontamination, and error patterns. By providing a rigorous and community-driven\nevaluation platform, ResearchCodeBench enables continuous understanding and\nadvancement of LLM-driven innovation in research code generation.",
    "pdf_url": "http://arxiv.org/pdf/2506.02314v1",
    "published": "2025-06-02T23:04:12+00:00",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2506.02313v1",
    "title": "Euclidean-Monte-Carlo-informed ground-state preparation for quantum simulation of scalar field theory",
    "authors": [
      "Navya Gupta",
      "Christopher David White",
      "Zohreh Davoudi"
    ],
    "abstract": "Quantum simulators offer great potential for investigating dynamical\nproperties of quantum field theories. However, preparing accurate non-trivial\ninitial states for these simulations is challenging. Classical Euclidean-time\nMonte-Carlo methods provide a wealth of information about states of interest to\nquantum simulations. Thus, it is desirable to facilitate state preparation on\nquantum simulators using this information. To this end, we present a fully\nclassical pipeline for generating efficient quantum circuits for preparing the\nground state of an interacting scalar field theory in 1+1 dimensions. The first\nelement of this pipeline is a variational ansatz family based on the stellar\nhierarchy for bosonic quantum systems. The second element of this pipeline is\nthe classical moment-optimization procedure that augments the standard\nvariational energy minimization by penalizing deviations in selected sets of\nground-state correlation functions (i.e., moments). The values of ground-state\nmoments are sourced from classical Euclidean methods. The resulting states\nyield comparable ground-state energy estimates but exhibit distinct\ncorrelations and local non-Gaussianity. The third element of this pipeline is\ntranslating the moment-optimized ansatz into an efficient quantum circuit with\nan asymptotic cost that is polynomial in system size. This work opens the way\nto systematically applying classically obtained knowledge of states to prepare\naccurate initial states in quantum field theories of interest in nature.",
    "pdf_url": "http://arxiv.org/pdf/2506.02313v1",
    "published": "2025-06-02T23:02:45+00:00",
    "categories": [
      "quant-ph",
      "hep-lat",
      "hep-ph",
      "nucl-th"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.02312v1",
    "title": "Dual encoding feature filtering generalized attention UNET for retinal vessel segmentation",
    "authors": [
      "Md Tauhidul Islam",
      "Wu Da-Wen",
      "Tang Qing-Qing",
      "Zhao Kai-Yang",
      "Yin Teng",
      "Li Yan-Fei",
      "Shang Wen-Yi",
      "Liu Jing-Yu",
      "Zhang Hai-Xian"
    ],
    "abstract": "Retinal blood vessel segmentation is crucial for diagnosing ocular and\ncardiovascular diseases. Although the introduction of U-Net in 2015 by Olaf\nRonneberger significantly advanced this field, yet issues like limited training\ndata, imbalance data distribution, and inadequate feature extraction persist,\nhindering both the segmentation performance and optimal model generalization.\nAddressing these critical issues, the DEFFA-Unet is proposed featuring an\nadditional encoder to process domain-invariant pre-processed inputs, thereby\nimproving both richer feature encoding and enhanced model generalization. A\nfeature filtering fusion module is developed to ensure the precise feature\nfiltering and robust hybrid feature fusion. In response to the task-specific\nneed for higher precision where false positives are very costly, traditional\nskip connections are replaced with the attention-guided feature reconstructing\nfusion module. Additionally, innovative data augmentation and balancing methods\nare proposed to counter data scarcity and distribution imbalance, further\nboosting the robustness and generalization of the model. With a comprehensive\nsuite of evaluation metrics, extensive validations on four benchmark datasets\n(DRIVE, CHASEDB1, STARE, and HRF) and an SLO dataset (IOSTAR), demonstrate the\nproposed method's superiority over both baseline and state-of-the-art models.\nParticularly the proposed method significantly outperforms the compared methods\nin cross-validation model generalization.",
    "pdf_url": "http://arxiv.org/pdf/2506.02312v1",
    "published": "2025-06-02T23:01:15+00:00",
    "categories": [
      "eess.IV",
      "cs.CV",
      "I.4; I.5"
    ],
    "primary_category": "eess.IV"
  },
  {
    "id": "http://arxiv.org/abs/2506.02311v2",
    "title": "Unicorn-CIM: Uncovering the Vulnerability and Improving the Resilience of High-Precision Compute-in-Memory",
    "authors": [
      "Qiufeng Li",
      "Yiwen Liang",
      "Weidong Cao"
    ],
    "abstract": "Compute-in-memory (CIM) architecture has been widely\n  explored to address the von Neumann bottleneck in accelerating deep\n  neural networks (DNNs). However, its reliability remains largely\nunderstudied, particularly in the emerging domain of floating-point (FP)\n  CIM, which is crucial for speeding up high-precision inference and on device\ntraining. This paper introduces Unicorn-CIM, a framework to\n  uncover the vulnerability and improve the resilience of high-precision\n  CIM, built on static random-access memory (SRAM)-based FP CIM\n  architecture. Through the development of fault injection and extensive\n  characterizations across multiple DNNs, Unicorn-CIM reveals how soft\n  errors manifest in FP operations and impact overall model performance.\n  Specifically, we find that high-precision DNNs are extremely sensitive\n  to errors in the exponent part of FP numbers. Building on this insight,\n  Unicorn-CIM develops an efficient algorithm-hardware co-design method\n  that optimizes model exponent distribution through fine-tuning and\n  incorporates a lightweight Error Correcting Code (ECC) scheme to\n  safeguard high-precision DNNs on FP CIM. Comprehensive experiments\n  show that our approach introduces just an 8.98% minimal logic overhead\n  on the exponent processing path while providing robust error protection\n  and maintaining model accuracy. This work paves the way for developing\n  more reliable and efficient CIM hardware.",
    "pdf_url": "http://arxiv.org/pdf/2506.02311v2",
    "published": "2025-06-02T22:59:49+00:00",
    "categories": [
      "cs.AR"
    ],
    "primary_category": "cs.AR"
  },
  {
    "id": "http://arxiv.org/abs/2506.02310v2",
    "title": "Dark Matter in X-rays: Revised XMM-Newton Limits and New Constraints from eROSITA",
    "authors": [
      "Shyam Balaji",
      "Damon Cleaver",
      "Pedro De la Torre Luque",
      "Miltiadis Michailidis"
    ],
    "abstract": "We investigate two classes of dark matter (DM) candidates, sub-GeV particles\nand primordial black holes (PBHs), that can inject low-energy electrons and\npositrons into the Milky Way and leave observable signatures in the X-ray sky.\nIn the case of sub-GeV DM, annihilation or decay into $e^+e^-$ contributes to\nthe diffuse sea of cosmic-ray (CR) leptons, which can generate bremsstrahlung\nand inverse Compton (IC) emission on Galactic photon fields, producing a broad\nspectrum from X-rays to $\\gamma$-rays detectable by instruments such as eROSITA\nand XMM-Newton. For PBHs with masses below $\\sim10^{17}$ g, Hawking evaporation\nsimilarly yields low-energy $e^\\pm$, leading to comparable diffuse emission.\nUsing the first data release from eROSITA and incorporating up-to-date CR\npropagation and diffusion parameters, we derive new constraints on both\nscenarios. For sub-GeV DM, we exclude thermally averaged annihilation cross\nsections in the range $\\sim 10^{-27}-10^{-25} \\ \\mathrm{cm^3/s}$ and decay\nlifetimes of $\\sim 10^{24}-10^{25}$ s for masses between 1 MeV and 1 GeV, with\neROSITA outperforming previous X-ray constraints below $\\sim$ 30 MeV. For\nasteroid-mass PBHs, we set new bounds on the DM fraction based on their\nHawking-induced emission. Finally, we revisit earlier constraints from\nXMM-Newton, finding that they were approximately four orders of magnitude too\nstringent due to the use of the instrument's geometric solid angle rather than\nits exposure-weighted solid angle. Upon using the exposure-weighted solid\nangle, we show that the revised XMM-Newton limits are slightly weaker than\nthose from eROSITA.",
    "pdf_url": "http://arxiv.org/pdf/2506.02310v2",
    "published": "2025-06-02T22:58:23+00:00",
    "categories": [
      "hep-ph",
      "astro-ph.HE"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.02309v2",
    "title": "SIL Allocation for Mitigation Safety Functions",
    "authors": [
      "Hamid Jahanian"
    ],
    "abstract": "SIL (Safety Integrity Level) allocation plays a pivotal role in evaluating\nthe significance of Safety Functions (SFs) within high-risk industries. The\noutcomes of a SIL allocation study determine the design specifications\nnecessary to uphold the Probability of Failure on Demand (PFD) below\npermissible limits, thus managing risk effectively. While extensive research\nhas focused on SIL allocation for preventive SFs, there is a noticeable gap in\nattention towards mitigation SFs. To address this gap, this paper discusses the\nshortcomings of current methods and proposes a new approach to overcome them.\nThe principles of the proposed method are substantiated by detailed\nmathematical formulation and the practical application of the method is\ndemonstrated through a case study in a road tunnel project.",
    "pdf_url": "http://arxiv.org/pdf/2506.02309v2",
    "published": "2025-06-02T22:57:51+00:00",
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2506.02308v3",
    "title": "MINT: Multimodal Instruction Tuning with Multimodal Interaction Grouping",
    "authors": [
      "Xiaojun Shan",
      "Qi Cao",
      "Xing Han",
      "Haofei Yu",
      "Paul Pu Liang"
    ],
    "abstract": "Recent advances in multimodal foundation models have achieved\nstate-of-the-art performance across a range of tasks. These breakthroughs are\nlargely driven by new pre-training paradigms that leverage large-scale,\nunlabeled multimodal data, followed by instruction fine-tuning on curated\nlabeled datasets and high-quality prompts. While there is growing interest in\nscaling instruction fine-tuning to ever-larger datasets in both quantity and\nscale, our findings reveal that simply increasing the number of\ninstruction-tuning tasks does not consistently yield better performance.\nInstead, we observe that grouping tasks by the common interactions across\nmodalities, such as discovering redundant shared information, prioritizing\nmodality selection with unique information, or requiring synergistic fusion to\ndiscover new information from both modalities, encourages the models to learn\ntransferrable skills within a group while suppressing interference from\nmismatched tasks. To this end, we introduce MINT, a simple yet surprisingly\neffective task-grouping strategy based on the type of multimodal interaction.\nWe demonstrate that the proposed method greatly outperforms existing task\ngrouping baselines for multimodal instruction tuning, striking an effective\nbalance between generalization and specialization.",
    "pdf_url": "http://arxiv.org/pdf/2506.02308v3",
    "published": "2025-06-02T22:55:23+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.02307v1",
    "title": "Homological Invariants of Left and Right Serial Path Algebras",
    "authors": [
      "Ruoyu Guo"
    ],
    "abstract": "We investigate the relationship between the delooping level (dell) and the\nfinitistic dimension of left and right serial path algebras. These 2-syzygy\nfinite algebras have finite delooping level, and it can be calculated with an\neasy and finite algorithm. When the algebra is right serial, its right\nfinitistic dimension is equal to its left delooping level. When the algebra is\nleft serial, the above equality only holds under certain conditions. We provide\nexamples to demonstrate this and include discussions on the sub-derived\n(subddell) and derived delooping level (ddell). Both subddell and ddell are\nimprovements of the delooping level. We motivate their definitions and showcase\nhow they can behave better than the delooping level in certain situations\nthroughout the paper.",
    "pdf_url": "http://arxiv.org/pdf/2506.02307v1",
    "published": "2025-06-02T22:54:50+00:00",
    "categories": [
      "math.RT",
      "math.RA",
      "16G20, 16E05, 16E10"
    ],
    "primary_category": "math.RT"
  },
  {
    "id": "http://arxiv.org/abs/2506.03209v1",
    "title": "Predicting Postoperative Stroke in Elderly SICU Patients: An Interpretable Machine Learning Model Using MIMIC Data",
    "authors": [
      "Tinghuan Li",
      "Shuheng Chen",
      "Junyi Fan",
      "Elham Pishgar",
      "Kamiar Alaei",
      "Greg Placencia",
      "Maryam Pishgar"
    ],
    "abstract": "Postoperative stroke remains a critical complication in elderly surgical\nintensive care unit (SICU) patients, contributing to prolonged hospitalization,\nelevated healthcare costs, and increased mortality. Accurate early risk\nstratification is essential to enable timely intervention and improve clinical\noutcomes. We constructed a combined cohort of 19,085 elderly SICU admissions\nfrom the MIMIC-III and MIMIC-IV databases and developed an interpretable\nmachine learning (ML) framework to predict in-hospital stroke using clinical\ndata from the first 24 hours of Intensive Care Unit (ICU) stay. The\npreprocessing pipeline included removal of high-missingness features, iterative\nSingular Value Decomposition (SVD) imputation, z-score normalization, one-hot\nencoding, and class imbalance correction via the Adaptive Synthetic Sampling\n(ADASYN) algorithm. A two-stage feature selection process-combining Recursive\nFeature Elimination with Cross-Validation (RFECV) and SHapley Additive\nexPlanations (SHAP)-reduced the initial 80 variables to 20 clinically\ninformative predictors. Among eight ML models evaluated, CatBoost achieved the\nbest performance with an AUROC of 0.8868 (95% CI: 0.8802--0.8937). SHAP\nanalysis and ablation studies identified prior cerebrovascular disease, serum\ncreatinine, and systolic blood pressure as the most influential risk factors.\nOur results highlight the potential of interpretable ML approaches to support\nearly detection of postoperative stroke and inform decision-making in\nperioperative critical care.",
    "pdf_url": "http://arxiv.org/pdf/2506.03209v1",
    "published": "2025-06-02T22:53:12+00:00",
    "categories": [
      "q-bio.QM",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "q-bio.QM"
  },
  {
    "id": "http://arxiv.org/abs/2506.02306v1",
    "title": "CACTI: Leveraging Copy Masking and Contextual Information to Improve Tabular Data Imputation",
    "authors": [
      "Aditya Gorla",
      "Ryan Wang",
      "Zhengtong Liu",
      "Ulzee An",
      "Sriram Sankararaman"
    ],
    "abstract": "We present CACTI, a masked autoencoding approach for imputing tabular data\nthat leverages the structure in missingness patterns and contextual\ninformation. Our approach employs a novel median truncated copy masking\ntraining strategy that encourages the model to learn from empirical patterns of\nmissingness while incorporating semantic relationships between features -\ncaptured by column names and text descriptions - to better represent feature\ndependence. These dual sources of inductive bias enable CACTI to outperform\nstate-of-the-art methods - an average $R^2$ gain of 7.8% over the next best\nmethod (13.4%, 6.1%, and 5.3% under missing not at random, at random and\ncompletely at random, respectively) - across a diverse range of datasets and\nmissingness conditions. Our results highlight the value of leveraging\ndataset-specific contextual information and missingness patterns to enhance\nimputation performance.",
    "pdf_url": "http://arxiv.org/pdf/2506.02306v1",
    "published": "2025-06-02T22:50:22+00:00",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.02305v1",
    "title": "Characterization of positive superharmonic functions in a half-space",
    "authors": [
      "Lorenzo D'Ambrosio",
      "Enzo Mitidieri"
    ],
    "abstract": "We prove a representation formula for superharmonic functions on the\nhalf-space $\\mathbb{R}^N_+ := \\mathbb{R}^{N-1}\\times]0,+\\infty[$. As a\nconsequence, we derive some comparison principles and various positivity\nresults.",
    "pdf_url": "http://arxiv.org/pdf/2506.02305v1",
    "published": "2025-06-02T22:48:08+00:00",
    "categories": [
      "math.AP"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2506.02304v1",
    "title": "Classification of exact structures using the Ziegler spectrum",
    "authors": [
      "Julia Sauter"
    ],
    "abstract": "Given an idempotent complete additive category, we show the there is an\nexplicitly constructed topological space such that the lattice of exact\nsubstructures is anti-isomorphic to the lattice of closed subsets. In the\nspecial case that the additive category has weak cokernels, this topological\nspace is an open subset of the Ziegler spectrum and this is a result of Kevin\nSchlegel. We also look at some module categories of rings where the Ziegler\nspectrum is known and calculate the global dimensions of the corresponding\nexact substructures.",
    "pdf_url": "http://arxiv.org/pdf/2506.02304v1",
    "published": "2025-06-02T22:46:52+00:00",
    "categories": [
      "math.RT",
      "math.CT",
      "18G25 (Primary), 18G05, 18E45 (Secondary)"
    ],
    "primary_category": "math.RT"
  },
  {
    "id": "http://arxiv.org/abs/2506.02303v1",
    "title": "A Bayesian Spatio-Temporal Top-Down Framework for Estimating Opioid Use Disorder Risk Under Data Sparsity",
    "authors": [
      "Emily N Peterson",
      "Alex Edwards",
      "Martha Wetzel",
      "Lance A Waller",
      "Hannah Cooper",
      "Courtney Yarbrough"
    ],
    "abstract": "County-level estimates of opioid use disorder (OUD) are essential for\nunderstanding the influence of local economic and social conditions. They\nprovide policymakers with the granular information needed to identify, target,\nand implement effective interventions and allocate resources appropriately.\nTraditional disease mapping methods typically rely on Poisson regression,\nmodeling observed counts while adjusting for local covariates that are treated\nas fixed and known. However, these methods may fail to capture the complexities\nand uncertainties in areas with sparse or absent data. To address this\nchallenge, we developed a Bayesian hierarchical spatio-temporal top-down\napproach designed to estimate county-level OUD rates when direct small-area\n(county) data is unavailable. This method allows us to infer small-area OUD\nrates and quantify associated uncertainties, even in data-sparse environments\nusing observed state-level OUD rates and a combination of state and county\nlevel informative covariates. We applied our approach to estimate OUD rates for\n3,143 counties in the United States between 2010 and 2025. Model performance\nwas assessed through simulation studies.",
    "pdf_url": "http://arxiv.org/pdf/2506.02303v1",
    "published": "2025-06-02T22:46:17+00:00",
    "categories": [
      "stat.AP"
    ],
    "primary_category": "stat.AP"
  },
  {
    "id": "http://arxiv.org/abs/2506.02302v1",
    "title": "Explain-then-Process: Using Grammar Prompting to Enhance Grammatical Acceptability Judgments",
    "authors": [
      "Russell Scheinberg",
      "Ameeta Agrawal",
      "Amber Shore",
      "So Young Lee"
    ],
    "abstract": "Large language models (LLMs) can explain grammatical rules, yet they often\nfail to apply those rules when judging sentence acceptability. We present\n\"grammar prompting\", an explain-then-process paradigm: a large LLM first\nproduces a concise explanation of the relevant syntactic phenomenon, then that\nexplanation is fed back as additional context to the target model -- either an\nLLM or a smaller language model (SLM) -- before deciding which sentence of a\nminimal pair is grammatical. On the English BLiMP, Chinese SLING, and Russian\nRuBLiMP benchmarks, this simple prompt design yields substantial improvements\nover strong baselines across many syntactic phenomena. Feeding an LLM's\nmetalinguistic explanation back to the target model bridges the gap between\nknowing a rule and using it. On SLMs, grammar prompting alone trims the average\nLLM-SLM accuracy gap by about 20%, and when paired with chain-of-thought, by\n56% (13.0 pp -> 5.8 pp), all at negligible cost. The lightweight,\nlanguage-agnostic cue lets low-cost SLMs approach frontier-LLM performance in\nmultilingual settings.",
    "pdf_url": "http://arxiv.org/pdf/2506.02302v1",
    "published": "2025-06-02T22:42:33+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.02301v1",
    "title": "`Translation invariant' black hole: autoparallels and complete integrability",
    "authors": [
      "Jens Boos"
    ],
    "abstract": "We consider the autoparallel motion of test bodies in static, spherically\nsymmetric spacetimes with torsion. We prove complete integrability of such\nmotion for a wide range of off-shell geometries via four commuting autoparallel\nKilling vectors. Since these vectors reduce to translation generators in a\ncertain limit, we refer to these geometries as `translation invariant.'\nInvoking the field equations of quadratic Poincar\\'e gauge gravity we re-derive\nan exact Schwarzschild black hole solution endowed with a non-trivial torsion\nfield scaling as $GM/r^2$, where $M$ denotes the ADM mass of the black hole.\nStudying the qualitative orbital dynamics via effective potentials we find\nnotable discrepancies between autoparallels (straightest possible paths) and\ngeodesics (shortest possible paths).",
    "pdf_url": "http://arxiv.org/pdf/2506.02301v1",
    "published": "2025-06-02T22:39:57+00:00",
    "categories": [
      "gr-qc"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2506.02300v3",
    "title": "Through a Steerable Lens: Magnifying Neural Network Interpretability via Phase-Based Extrapolation",
    "authors": [
      "Farzaneh Mahdisoltani",
      "Saeed Mahdisoltani",
      "Roger B. Grosse",
      "David J. Fleet"
    ],
    "abstract": "Understanding the internal representations and decision mechanisms of deep\nneural networks remains a critical open challenge. While existing\ninterpretability methods often identify influential input regions, they may not\nelucidate how a model distinguishes between classes or what specific changes\nwould transition an input from one category to another. To address these\nlimitations, we propose a novel framework that visualizes the implicit path\nbetween classes by treating the network gradient as a form of infinitesimal\nmotion. Drawing inspiration from phase-based motion magnification, we first\ndecompose images using invertible transforms-specifically the Complex Steerable\nPyramid-then compute class-conditional gradients in the transformed space.\nRather than iteratively integrating the gradient to trace a full path, we\namplify the one-step gradient to the input and perform a linear extrapolation\nto expose how the model moves from source to target class. By operating in the\nsteerable pyramid domain, these amplified gradients produce semantically\nmeaningful, spatially coherent morphs that highlight the classifier's most\nsensitive directions, giving insight into the geometry of its decision\nboundaries. Experiments on both synthetic and real-world datasets demonstrate\nthat our phase-focused extrapolation yields perceptually aligned, semantically\nmeaningful transformations, offering a novel, interpretable lens into neural\nclassifiers' internal representations.",
    "pdf_url": "http://arxiv.org/pdf/2506.02300v3",
    "published": "2025-06-02T22:39:40+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.02299v1",
    "title": "Weyl formula improvement for product of Zoll manifolds",
    "authors": [
      "Yanfei Wang"
    ],
    "abstract": "Iosevich and Wyman have proved in ~\\cite{IoWy} that the remainder term in\nclassical Weyl law can be improved from $O(\\lambda^{d-1})$ to\n$o(\\lambda^{d-1})$ in the case of product manifold by using a famous result of\nDuistermaat and Guillemin. They also showed that we could have polynomial\nimprovement in the special case of Cartesian product of round spheres by\nreducing the problem to the study of the distribution of weighted integer\nlattice points. In this paper, we show that we can extend this result to the\ncase of Cartesian product of Zoll manifolds by investigating the eigenvalue\nclusters of Zoll manifold and reducing the problem to the study of the\ndistribution of weighted integer lattice points too.",
    "pdf_url": "http://arxiv.org/pdf/2506.02299v1",
    "published": "2025-06-02T22:37:13+00:00",
    "categories": [
      "math.AP"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2506.02298v1",
    "title": "LAM SIMULATOR: Advancing Data Generation for Large Action Model Training via Online Exploration and Trajectory Feedback",
    "authors": [
      "Thai Hoang",
      "Kung-Hsiang Huang",
      "Shirley Kokane",
      "Jianguo Zhang",
      "Zuxin Liu",
      "Ming Zhu",
      "Jake Grigsby",
      "Tian Lan",
      "Michael S Ryoo",
      "Chien-Sheng Wu",
      "Shelby Heinecke",
      "Huan Wang",
      "Silvio Savarese",
      "Caiming Xiong",
      "Juan Carlos Niebles"
    ],
    "abstract": "Large Action Models (LAMs) for AI Agents offer incredible potential but face\nchallenges due to the need for high-quality training data, especially for\nmulti-steps tasks that involve planning, executing tool calls, and responding\nto feedback. To address these issues, we present LAM SIMULATOR, a comprehensive\nframework designed for online exploration of agentic tasks with high-quality\nfeedback. Our framework features a dynamic task query generator, an extensive\ncollection of tools, and an interactive environment where Large Language Model\n(LLM) Agents can call tools and receive real-time feedback. This setup enables\nLLM Agents to explore and solve tasks autonomously, facilitating the discovery\nof multiple approaches to tackle any given task. The resulting action\ntrajectory data are then used to create high-quality training datasets for\nLAMs. Our experiments on popular agentic benchmarks, ToolBench and CRMArena,\nhighlight the effectiveness of LAM SIMULATOR: models trained with\nself-generated datasets using our framework achieve significant performance\ngains, up to a 49.3\\% improvement over their original baselines. LAM SIMULATOR\nrequires minimal human input during dataset creation, highlighting LAM\nSIMULATOR's efficiency and effectiveness in speeding up development of AI\nagents.",
    "pdf_url": "http://arxiv.org/pdf/2506.02298v1",
    "published": "2025-06-02T22:36:02+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.02297v1",
    "title": "Experimental Covert Communication Using Software-Defined Radio",
    "authors": [
      "Rohan Bali",
      "Trevor E. Bailey",
      "Michael S. Bullock",
      "Boulat A. Bash"
    ],
    "abstract": "The fundamental information-theoretic limits of covert, or low probability of\ndetection (LPD), communication have been extensively studied for over a decade,\nresulting in the square root law (SRL): only $L\\sqrt{n}$ covert bits can be\nreliably transmitted over time-bandwidth product $n$, for constant $L>0$.\nTransmitting more either results in detection or decoding errors. The SRL\nimposes significant constraints on hardware realization of provably-secure\ncovert communication. Thus, experimental validation of covert communication is\nunderexplored: to date, only two experimental studies of SRL-based covert\ncommunication are available, both focusing on optical channels. Here, we report\nour initial results demonstrating the provably-secure covert radio-frequency\n(RF) communication using software-defined radios (SDRs). These validate\ntheoretical predictions, open practical avenues for implementing covert\ncommunication systems, as well as raise future research questions.",
    "pdf_url": "http://arxiv.org/pdf/2506.02297v1",
    "published": "2025-06-02T22:30:54+00:00",
    "categories": [
      "cs.NI",
      "cs.IT",
      "cs.SY",
      "eess.SY",
      "math.IT"
    ],
    "primary_category": "cs.NI"
  },
  {
    "id": "http://arxiv.org/abs/2506.02296v2",
    "title": "A Wide Field Map of Ultra-Compact Dwarfs in the Coma Cluster",
    "authors": [
      "Richard T. Pomeroy",
      "Juan P. Madrid",
      "Conor R. O'Neill",
      "Alexander T. Gagliano"
    ],
    "abstract": "A dataset of 23,351 globular clusters (GCs) and ultra-compact dwarfs (UCDs)\nin the Coma cluster of galaxies was built using Hubble Space Telescope Advanced\nCamera for Surveys data. Based on the standard magnitude cut of $M_V \\leq -11$,\na total of 523 UCD candidates are found within this dataset of Compact Stellar\nSystems (CSS). From a color-magnitude diagram (CMD) analysis built using this\ncatalog, we find a clear mass-magnitude relation extending marginally into the\nUCD parameter space. The luminosity function defined by this dataset, shows an\nexcess of sources at bright magnitudes, suggesting a bimodal formation scenario\nfor UCDs. We estimate the number of UCDs with a different origin than GC to be\n$N_{UCD} \\geq 32 \\pm 1$. We derive the total number of CSS within the core (1\nMpc) of Coma to be $N_{CSS} \\approx 69,400 \\pm 1400$. The radial distribution\nof UCDs in Coma shows that, like GCs, UCDs agglomerate around three giant\nellipticals: NGC 4874, NGC 4889, and IC 4051. We find UCDs are more centrally\nconcentrated around these three ellipticals than GCs. IC 4051 has a satellite\npopulation of UCDs similar to NGC 4874 and NGC 4889. We estimate only ~14% of\nUCDs, inhabit the intracluster space (ICUCD) between galaxies in the region, in\ncomparison to ~24% for GCs (ICGC). We find red (metal-rich) UCDs are more\nlikely located closer to a host galaxy, with blue (metal-poor) UCDs showing a\ngreater dispersion and lower average density in the region.",
    "pdf_url": "http://arxiv.org/pdf/2506.02296v2",
    "published": "2025-06-02T22:28:57+00:00",
    "categories": [
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2506.02295v1",
    "title": "QARI-OCR: High-Fidelity Arabic Text Recognition through Multimodal Large Language Model Adaptation",
    "authors": [
      "Ahmed Wasfy",
      "Omer Nacar",
      "Abdelakreem Elkhateb",
      "Mahmoud Reda",
      "Omar Elshehy",
      "Adel Ammar",
      "Wadii Boulila"
    ],
    "abstract": "The inherent complexities of Arabic script; its cursive nature, diacritical\nmarks (tashkeel), and varied typography, pose persistent challenges for Optical\nCharacter Recognition (OCR). We present Qari-OCR, a series of vision-language\nmodels derived from Qwen2-VL-2B-Instruct, progressively optimized for Arabic\nthrough iterative fine-tuning on specialized synthetic datasets. Our leading\nmodel, QARI v0.2, establishes a new open-source state-of-the-art with a Word\nError Rate (WER) of 0.160, Character Error Rate (CER) of 0.061, and BLEU score\nof 0.737 on diacritically-rich texts. Qari-OCR demonstrates superior handling\nof tashkeel, diverse fonts, and document layouts, alongside impressive\nperformance on low-resolution images. Further explorations (QARI v0.3) showcase\nstrong potential for structural document understanding and handwritten text.\nThis work delivers a marked improvement in Arabic OCR accuracy and efficiency,\nwith all models and datasets released to foster further research.",
    "pdf_url": "http://arxiv.org/pdf/2506.02295v1",
    "published": "2025-06-02T22:21:06+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.02294v2",
    "title": "Improving Knowledge Distillation Under Unknown Covariate Shift Through Confidence-Guided Data Augmentation",
    "authors": [
      "Niclas Popp",
      "Kevin Alexander Laube",
      "Matthias Hein",
      "Lukas Schott"
    ],
    "abstract": "Large foundation models trained on extensive datasets demonstrate strong\nzero-shot capabilities in various domains. To replicate their success when data\nand model size are constrained, knowledge distillation has become an\nestablished tool for transferring knowledge from foundation models to small\nstudent networks. However, the effectiveness of distillation is critically\nlimited by the available training data. This work addresses the common\npractical issue of covariate shift in knowledge distillation, where spurious\nfeatures appear during training but not at test time. We ask the question: when\nthese spurious features are unknown, yet a robust teacher is available, is it\npossible for a student to also become robust to them? We address this problem\nby introducing a novel diffusion-based data augmentation strategy that\ngenerates images by maximizing the disagreement between the teacher and the\nstudent, effectively creating challenging samples that the student struggles\nwith. Experiments demonstrate that our approach significantly improves worst\ngroup and mean group accuracy on CelebA and SpuCo Birds as well as the spurious\nmAUC on spurious ImageNet under covariate shift, outperforming state-of-the-art\ndiffusion-based data augmentation baselines",
    "pdf_url": "http://arxiv.org/pdf/2506.02294v2",
    "published": "2025-06-02T22:15:59+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.03208v1",
    "title": "Intrinsic Resolution of Organic Scintillators",
    "authors": [
      "O. Smirnov"
    ],
    "abstract": "Fluctuations in photon production within scintillators contribute to the\noverall energy resolution of scintillation detectors. While typically\nnegligible, this contribution - known as intrinsic resolution (IR) - presents\nsignificant challenges for both experimental measurement and Monte Carlo\nsimulation. Using the phenomenological model proposed in~[1], we interpreted\nmultiple datasets of IR measurements in organic scintillators. Although our\nresults generally agree with the IR dataset examined in~[1], a comprehensive\nevaluation of systematic uncertainties highlights the necessity for more\ndetailed investigation. Based on our findings, we offer specific\nrecommendations for future measurements.",
    "pdf_url": "http://arxiv.org/pdf/2506.03208v1",
    "published": "2025-06-02T22:09:55+00:00",
    "categories": [
      "physics.ins-det"
    ],
    "primary_category": "physics.ins-det"
  },
  {
    "id": "http://arxiv.org/abs/2506.06355v1",
    "title": "LLMs as World Models: Data-Driven and Human-Centered Pre-Event Simulation for Disaster Impact Assessment",
    "authors": [
      "Lingyao Li",
      "Dawei Li",
      "Zhenhui Ou",
      "Xiaoran Xu",
      "Jingxiao Liu",
      "Zihui Ma",
      "Runlong Yu",
      "Min Deng"
    ],
    "abstract": "Efficient simulation is essential for enhancing proactive preparedness for\nsudden-onset disasters such as earthquakes. Recent advancements in large\nlanguage models (LLMs) as world models show promise in simulating complex\nscenarios. This study examines multiple LLMs to proactively estimate perceived\nearthquake impacts. Leveraging multimodal datasets including geospatial,\nsocioeconomic, building, and street-level imagery data, our framework generates\nModified Mercalli Intensity (MMI) predictions at zip code and county scales.\nEvaluations on the 2014 Napa and 2019 Ridgecrest earthquakes using USGS ''Did\nYou Feel It? (DYFI)'' reports demonstrate significant alignment, as evidenced\nby a high correlation of 0.88 and a low RMSE of 0.77 as compared to real\nreports at the zip code level. Techniques such as RAG and ICL can improve\nsimulation performance, while visual inputs notably enhance accuracy compared\nto structured numerical data alone. These findings show the promise of LLMs in\nsimulating disaster impacts that can help strengthen pre-event planning.",
    "pdf_url": "http://arxiv.org/pdf/2506.06355v1",
    "published": "2025-06-02T22:07:53+00:00",
    "categories": [
      "cs.CY",
      "cs.CE",
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.CY"
  },
  {
    "id": "http://arxiv.org/abs/2506.02293v1",
    "title": "On Universality Classes of Equivariant Networks",
    "authors": [
      "Marco Pacini",
      "Gabriele Santin",
      "Bruno Lepri",
      "Shubhendu Trivedi"
    ],
    "abstract": "Equivariant neural networks provide a principled framework for incorporating\nsymmetry into learning architectures and have been extensively analyzed through\nthe lens of their separation power, that is, the ability to distinguish inputs\nmodulo symmetry. This notion plays a central role in settings such as graph\nlearning, where it is often formalized via the Weisfeiler-Leman hierarchy. In\ncontrast, the universality of equivariant models-their capacity to approximate\ntarget functions-remains comparatively underexplored. In this work, we\ninvestigate the approximation power of equivariant neural networks beyond\nseparation constraints. We show that separation power does not fully capture\nexpressivity: models with identical separation power may differ in their\napproximation ability. To demonstrate this, we characterize the universality\nclasses of shallow invariant networks, providing a general framework for\nunderstanding which functions these architectures can approximate. Since\nequivariant models reduce to invariant ones under projection, this analysis\nyields sufficient conditions under which shallow equivariant networks fail to\nbe universal. Conversely, we identify settings where shallow models do achieve\nseparation-constrained universality. These positive results, however, depend\ncritically on structural properties of the symmetry group, such as the\nexistence of adequate normal subgroups, which may not hold in important cases\nlike permutation symmetry.",
    "pdf_url": "http://arxiv.org/pdf/2506.02293v1",
    "published": "2025-06-02T22:07:52+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.02292v1",
    "title": "Energy minima and ordering in ferromagnets with quenched randomness",
    "authors": [
      "D. A. Garanin"
    ],
    "abstract": "Energy minimization at T=0 and Monte Carlo simulations at T>0 have been\nperformed for 2D and 3D random-field and random-anisotropy systems of up to 100\nmillion classical spins. The main finding is that 3D random-anisotropy systems\nmagnetically order on lowering temperature, contrary to the theoretical\npredictions based on the Imry-Ma argument. If random-anisotropy is stronger\nthan the exchange, which can be the case in sintered materials, the system\nstill orders but the magnetization is strongly reduced and there is a large\nspin-glass component in the spin state, the heat capacity having a cusp instead\nof a divergence. 3D random-field systems do not magnetically order on lowering\ntemperature but rather freeze into the correlated spin-glass state. Here,\nalthough magnetized local energy minima have lower energies than non-magnetized\nones, magnetic ordering is prevented by singularities pinned by the random\nfield.",
    "pdf_url": "http://arxiv.org/pdf/2506.02292v1",
    "published": "2025-06-02T22:07:09+00:00",
    "categories": [
      "cond-mat.stat-mech"
    ],
    "primary_category": "cond-mat.stat-mech"
  },
  {
    "id": "http://arxiv.org/abs/2506.02291v1",
    "title": "Entity Image and Mixed-Modal Image Retrieval Datasets",
    "authors": [
      "Cristian-Ioan Blaga",
      "Paul Suganthan",
      "Sahil Dua",
      "Krishna Srinivasan",
      "Enrique Alfonseca",
      "Peter Dornbach",
      "Tom Duerig",
      "Imed Zitouni",
      "Zhe Dong"
    ],
    "abstract": "Despite advances in multimodal learning, challenging benchmarks for\nmixed-modal image retrieval that combines visual and textual information are\nlacking. This paper introduces a novel benchmark to rigorously evaluate image\nretrieval that demands deep cross-modal contextual understanding. We present\ntwo new datasets: the Entity Image Dataset (EI), providing canonical images for\nWikipedia entities, and the Mixed-Modal Image Retrieval Dataset (MMIR), derived\nfrom the WIT dataset. The MMIR benchmark features two challenging query types\nrequiring models to ground textual descriptions in the context of provided\nvisual entities: single entity-image queries (one entity image with descriptive\ntext) and multi-entity-image queries (multiple entity images with relational\ntext). We empirically validate the benchmark's utility as both a training\ncorpus and an evaluation set for mixed-modal retrieval. The quality of both\ndatasets is further affirmed through crowd-sourced human annotations. The\ndatasets are accessible through the GitHub page:\nhttps://github.com/google-research-datasets/wit-retrieval.",
    "pdf_url": "http://arxiv.org/pdf/2506.02291v1",
    "published": "2025-06-02T22:04:06+00:00",
    "categories": [
      "cs.CV",
      "cs.IR"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.02290v2",
    "title": "HEC: Equivalence Verification Checking for Code Transformation via Equality Saturation",
    "authors": [
      "Jiaqi Yin",
      "Zhan Song",
      "Nicolas Bohm Agostini",
      "Antonino Tumeo",
      "Cunxi Yu"
    ],
    "abstract": "In modern computing systems, compilation employs numerous optimization\ntechniques to enhance code performance. Source-to-source code transformations,\nwhich include control flow and datapath transformations, have been widely used\nin High-Level Synthesis (HLS) and compiler optimization.\n  While researchers actively investigate methods to improve performance with\nsource-to-source code transformations, they often overlook the significance of\nverifying their correctness. Current tools cannot provide a holistic\nverification of these transformations. This paper introduces HEC, a framework\nfor equivalence checking that leverages the e-graph data structure to\ncomprehensively verify functional equivalence between programs. HEC utilizes\nthe MLIR as its frontend and integrates MLIR into the e-graph framework.\nThrough the combination of dynamic and static e-graph rewriting, HEC\nfacilitates the validation of comprehensive code transformations.\n  We demonstrate effectiveness of HEC on PolyBenchC benchmarks, successfully\nverifying loop unrolling, tiling, and fusion transformations. HEC processes\nover 100,000 lines of MLIR code in 40 minutes with predictable runtime scaling.\nImportantly, HEC identified two critical compilation errors in mlir-opt: loop\nboundary check errors causing unintended executions during unrolling, and\nmemory read-after-write violations in loop fusion that alter program semantics.\nThese findings demonstrate HEC practical value in detecting real-world compiler\nbugs and highlight the importance of formal verification in optimization\npipelines.",
    "pdf_url": "http://arxiv.org/pdf/2506.02290v2",
    "published": "2025-06-02T21:59:17+00:00",
    "categories": [
      "cs.AR",
      "cs.PL"
    ],
    "primary_category": "cs.AR"
  },
  {
    "id": "http://arxiv.org/abs/2506.02289v1",
    "title": "Radiation GRMHD Models of Accretion onto Stellar-Mass Black Holes: I. Survey of Eddington Ratios",
    "authors": [
      "Lizhong Zhang",
      "James M. Stone",
      "Patrick D. Mullen",
      "Shane W. Davis",
      "Yan-Fei Jiang",
      "Christopher J. White"
    ],
    "abstract": "We summarize results from a survey of radiation-dominated black hole\naccretion flows across a wide range of mass accretion rates, as well as two\nvalues of black hole spin and initial magnetic field geometry. These models\napply an algorithm targeting direct solutions to the radiation transport\nequation in full general relativity and have been enabled by access to modern\nexascale computing systems. Super-Eddington accretion flows form geometrically\nthick radiation pressure supported disks that drive powerful equatorial\noutflows. A narrow funnel-shaped photosphere in the inner region results in\nvery low radiative efficiencies in this regime. The structure of near- and\nsub-Eddington accretion depends on whether there is net vertical magnetic flux\nat the midplane of the disk. With net flux, the disk forms a thin, dense layer\nat the midplane surrounded by a magnetically-dominated corona, whereas without\nnet flux the disk remains magnetically dominated everywhere. Although none of\nour models achieve the magnetically arrested disk (MAD) regime, those with net\nvertical flux and a rapidly spinning black hole still produce powerful\nrelativistic jets. Our calculations adopt simple opacity models (with scalings\nappropriate to stellar-mass black hole accretion). We discuss the application\nof our results to observations of X-ray binaries and ultraluminous X-ray\nsources such as Cyg X-3 and SS433. We also speculate on the application of our\nsuper-Eddington models to the interpretation of little red dots (LRDs) recently\ndiscovered by JWST.",
    "pdf_url": "http://arxiv.org/pdf/2506.02289v1",
    "published": "2025-06-02T21:59:09+00:00",
    "categories": [
      "astro-ph.HE"
    ],
    "primary_category": "astro-ph.HE"
  },
  {
    "id": "http://arxiv.org/abs/2506.02288v2",
    "title": "A Parameter Survey of Neutron Star Accretion Column Simulations",
    "authors": [
      "Lizhong Zhang",
      "Omer Blaes",
      "Yan-Fei Jiang"
    ],
    "abstract": "We conduct a parameter survey of neutron star accretion column simulations by\nsolving the relativistic radiation MHD equations with opacities that account\nfor strong magnetic fields and pair production. We study how column properties\ndepend on accretion rate, magnetic field strength, and accretion flow geometry.\nAll the simulated accretion columns exhibit kHz oscillatory behavior,\nconsistent with our previous findings. We show how the predicted oscillation\nproperties depend on the column parameters. At higher accretion rates for fixed\nmagnetic field, the column height increases, reducing the local field strength\nand leading to an anti-correlation between the observed cyclotron line energy\nand luminosity. We estimate the line energy from the simulations and find\nagreement with the observed trend. Downward scattering in the free-fall zone\nplays a key role in shaping sideways emission properties and column height.\nStrong downward scattering not only re-injects heat back into the column,\nincreasing its height, but also compresses sideways emission, potentially\nsmearing out shock oscillation signals. When the pair-production regime is\nreached at the base of the column, the system quickly readjusts to a force\nbalance between gravity and radiative support. The high opacity in the\npair-production region raises the radiation energy density, enhancing sideways\nemission through a large horizontal gradient. This shifts the sideways fan-beam\nradiation toward lower altitudes. In a hollow column geometry, both pencil- and\nfan-beam radiation emission occurs. Self-illumination across the hollow region\nincreases the height and stabilizes the inner wall of the column, while shock\noscillations persist in the outer regions.",
    "pdf_url": "http://arxiv.org/pdf/2506.02288v2",
    "published": "2025-06-02T21:59:06+00:00",
    "categories": [
      "astro-ph.HE"
    ],
    "primary_category": "astro-ph.HE"
  },
  {
    "id": "http://arxiv.org/abs/2506.02287v1",
    "title": "Visualizing the treatment effect on kidney hierarchical composite endpoints: From mosaic to maraca plots",
    "authors": [
      "Martin Karpefors",
      "Dustin J Little",
      "Hiddo J L Heerspink",
      "Samvel B Gasparyan"
    ],
    "abstract": "Visualizations, alongside summary tables and participant-level listings, are\nessential for presenting clinical trial results transparently and\ncomprehensively. When reporting the results of clinical trials, the goal of\nvisualization is to communicate the results of specific pre-planned analyses\nwith visualization that are tailored to the endpoint and analysis being\nreported. We are considering the visualization of HCEs, combining multiple\ntime-to-event outcomes, ordered according to a given prioritization and the\ntiming of events, with a single continuous outcome. An illustrative example is\nthe kidney disease progression HCE with a straightforward structure of the\ncomposite of clinical events of death and kidney failure and declines in eGFR\nas surrogates for kidney failure. The HCEs are analyzed by win statistics and\nvisualized using maraca plots. Although maraca plots are very granular and\nallow for a detailed presentation of the distribution of HCE, researchers are\nstill tasked with explanation of the magnitude of the treatment effect\nestimated by win odds. In explaining the magnitude of the treatment effect, we\npropose a comprehensive visualization approach. In the clinical trial design\nstage, we propose the sunset plots to visualize all possible treatment effects\nthat can be observed based on the treatment effects on components. In reporting\nthe results of the trial, we recommend the maraca plots as the primary method\nof visualization of the results. While the 2-d mosaic plot with the ordinal\ndominance graph directly corresponds to the win odds as treatment effect\nmeasure and can be used as the primary analysis-specific visualization method.\nAnd finally, we propose the Dustin plot to visualize the supportive analysis of\nthe components, added cumulatively from the event of highest priority to assess\nthe consistency of the treatment effect on all outcomes.",
    "pdf_url": "http://arxiv.org/pdf/2506.02287v1",
    "published": "2025-06-02T21:58:39+00:00",
    "categories": [
      "stat.AP"
    ],
    "primary_category": "stat.AP"
  },
  {
    "id": "http://arxiv.org/abs/2506.02286v2",
    "title": "Efficient Manipulation-Enhanced Semantic Mapping With Uncertainty-Informed Action Selection",
    "authors": [
      "Nils Dengler",
      "Jesper Mücke",
      "Rohit Menon",
      "Maren Bennewitz"
    ],
    "abstract": "Service robots operating in cluttered human environments such as homes,\noffices, and schools cannot rely on predefined object arrangements and must\ncontinuously update their semantic and spatial estimates while dealing with\npossible frequent rearrangements. Efficient and accurate mapping under such\nconditions demands selecting informative viewpoints and targeted manipulations\nto reduce occlusions and uncertainty. In this work, we present a\nmanipulation-enhanced semantic mapping framework for occlusion-heavy shelf\nscenes that integrates evidential metric-semantic mapping with\nreinforcement-learning-based next-best view planning and targeted action\nselection. Our method thereby exploits uncertainty estimates from Dirichlet and\nBeta distributions in the map prediction networks to guide both active sensor\nplacement and object manipulation, focusing on areas with high uncertainty and\nselecting actions with high expected information gain. Furthermore, we\nintroduce an uncertainty-informed push strategy that targets occlusion-critical\nobjects and generates minimally invasive actions to reveal hidden regions by\nreducing overall uncertainty in the scene. The experimental evaluation shows\nthat our framework enables to accurately map cluttered scenes, while\nsubstantially reducing object displacement and achieving a 95% reduction in\nplanning time compared to the state-of-the-art, thereby realizing real-world\napplicability.",
    "pdf_url": "http://arxiv.org/pdf/2506.02286v2",
    "published": "2025-06-02T21:57:53+00:00",
    "categories": [
      "cs.RO"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2506.02285v2",
    "title": "Why Gradients Rapidly Increase Near the End of Training",
    "authors": [
      "Aaron Defazio"
    ],
    "abstract": "During long-duration Large Language Model (LLM) training runs the gradient\nnorm increases rapidly near the end of training. In this short note, we show\nthat this increase is due to an unintended interaction between weight decay,\nnormalization layers, and the learning rate schedule. We propose a simple\ncorrection that fixes this behavior while also resulting in lower loss values\nthroughout training.",
    "pdf_url": "http://arxiv.org/pdf/2506.02285v2",
    "published": "2025-06-02T21:51:04+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.02284v1",
    "title": "Learning Optimal Posted Prices for a Unit-Demand Buyer",
    "authors": [
      "Yifeng Teng",
      "Yifan Wang"
    ],
    "abstract": "We study the problem of learning the optimal item pricing for a unit-demand\nbuyer with independent item values, and the learner has query access to the\nbuyer's value distributions. We consider two common query models in the\nliterature: the sample access model where the learner can obtain a sample of\neach item value, and the pricing query model where the learner can set a price\nfor an item and obtain a binary signal on whether the sampled value of the item\nis greater than our proposed price. In this work, we give nearly tight sample\ncomplexity and pricing query complexity of the unit-demand pricing problem.",
    "pdf_url": "http://arxiv.org/pdf/2506.02284v1",
    "published": "2025-06-02T21:48:12+00:00",
    "categories": [
      "cs.GT",
      "cs.DS",
      "cs.LG"
    ],
    "primary_category": "cs.GT"
  },
  {
    "id": "http://arxiv.org/abs/2506.02283v1",
    "title": "Sounding Like a Winner? Prosodic Differences in Post-Match Interviews",
    "authors": [
      "Sofoklis Kakouros",
      "Haoyu Chen"
    ],
    "abstract": "This study examines the prosodic characteristics associated with winning and\nlosing in post-match tennis interviews. Additionally, this research explores\nthe potential to classify match outcomes solely based on post-match interview\nrecordings using prosodic features and self-supervised learning (SSL)\nrepresentations. By analyzing prosodic elements such as pitch and intensity,\nalongside SSL models like Wav2Vec 2.0 and HuBERT, the aim is to determine\nwhether an athlete has won or lost their match. Traditional acoustic features\nand deep speech representations are extracted from the data, and machine\nlearning classifiers are employed to distinguish between winning and losing\nplayers. Results indicate that SSL representations effectively differentiate\nbetween winning and losing outcomes, capturing subtle speech patterns linked to\nemotional states. At the same time, prosodic cues -- such as pitch variability\n-- remain strong indicators of victory.",
    "pdf_url": "http://arxiv.org/pdf/2506.02283v1",
    "published": "2025-06-02T21:45:39+00:00",
    "categories": [
      "cs.CL",
      "eess.AS"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.02282v1",
    "title": "Singularity Blockchain Key Management via non-custodial key management",
    "authors": [
      "Sumit Vohra"
    ],
    "abstract": "web3 wallets are key to managing user identity on blockchain. The main\npurpose of a web3 wallet application is to manage the private key for the user\nand provide an interface to interact with the blockchain. The key management\nscheme ( KMS ) used by the wallet to store and recover the private key can be\neither custodial, where the keys are permissioned and in custody of the wallet\nprovider or noncustodial where the keys are in custody of the user. The\nexisting non-custodial key management schemes tend to offset the burden of\nstoring and recovering the key entirely on the user by asking them to remember\nseed-phrases. This creates onboarding hassles for the user and introduces the\nrisk that the user may lose their assets if they forget or lose their\nseedphrase/private key. In this paper, we propose a novel method of backing up\nuser keys using a non-custodial key management technique that allows users to\nsave and recover a backup of their private key using any independent sign-in\nmethod such as google-oAuth or other 3P oAuth.",
    "pdf_url": "http://arxiv.org/pdf/2506.02282v1",
    "published": "2025-06-02T21:44:50+00:00",
    "categories": [
      "cs.CE",
      "cs.CR"
    ],
    "primary_category": "cs.CE"
  },
  {
    "id": "http://arxiv.org/abs/2506.02281v1",
    "title": "Angles Don't Lie: Unlocking Training-Efficient RL Through the Model's Own Signals",
    "authors": [
      "Qinsi Wang",
      "Jinghan Ke",
      "Hancheng Ye",
      "Yueqian Lin",
      "Yuzhe Fu",
      "Jianyi Zhang",
      "Kurt Keutzer",
      "Chenfeng Xu",
      "Yiran Chen"
    ],
    "abstract": "Current Reinforcement Fine-tuning (RFT) paradigms for Large Language Models\n(LLMs) suffer from sample inefficiency due to the redundant exposure of\nidentical queries under uniform data sampling. While previous work has explored\ncurriculum learning via heuristic difficulty metrics, these strategies exhibit\nlimitations by neglecting the intrinsic learning signals generated by the model\nitself, thus leading to suboptimal training regimes. In this paper, we identify\na model-inherent signal termed angle concentration that effectively reflects an\nLLM's capacity to learn from specific data. We theoretically and empirically\ndemonstrate a correlation between the angular distribution of token hidden\nstate vectors and the resulting gradient, revealing a learning preference for\ndata exhibiting higher angle concentration. Inspired by this finding, we\npropose GAIN-RL, a Gradient-driven Angle-Informed Navigated RL framework. By\nleveraging the model's intrinsic angle concentration signal, GAIN-RL\ndynamically selects training data in each epoch, ensuring consistently\nimpactful gradient updates and thus significantly enhancing overall training\nefficiency. Empirical evaluations show that GAIN-RL (GRPO) achieves over a 2.5x\nacceleration in training efficiency across diverse mathematical and coding\ntasks and varying model scales. Furthermore, GAIN-RL (GRPO)'s efficient\nsampling yields data-efficient training, achieving better performance with half\nthe original data compared to vanilla GRPO with full training data. Code is\nrealsed at https://github.com/wangqinsi1/GAINRL/tree/main.",
    "pdf_url": "http://arxiv.org/pdf/2506.02281v1",
    "published": "2025-06-02T21:40:38+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.02280v3",
    "title": "The State of Large Language Models for African Languages: Progress and Challenges",
    "authors": [
      "Kedir Yassin Hussen",
      "Walelign Tewabe Sewunetie",
      "Abinew Ali Ayele",
      "Sukairaj Hafiz Imam",
      "Shamsuddeen Hassan Muhammad",
      "Seid Muhie Yimam"
    ],
    "abstract": "Large Language Models (LLMs) are transforming Natural Language Processing\n(NLP), but their benefits are largely absent for Africa's 2,000 low-resource\nlanguages. This paper comparatively analyzes African language coverage across\nsix LLMs, eight Small Language Models (SLMs), and six Specialized SLMs (SSLMs).\nThe evaluation covers language coverage, training sets, technical limitations,\nscript problems, and language modelling roadmaps. The work identifies 42\nsupported African languages and 23 available public data sets, and it shows a\nbig gap where four languages (Amharic, Swahili, Afrikaans, and Malagasy) are\nalways treated while there is over 98\\% of unsupported African languages.\nMoreover, the review shows that just Latin, Arabic, and Ge'ez scripts are\nidentified while 20 active scripts are neglected. Some of the primary\nchallenges are lack of data, tokenization biases, computational costs being\nvery high, and evaluation issues. These issues demand language standardization,\ncorpus development by the community, and effective adaptation methods for\nAfrican languages.",
    "pdf_url": "http://arxiv.org/pdf/2506.02280v3",
    "published": "2025-06-02T21:39:40+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2506.02279v1",
    "title": "ImpRAG: Retrieval-Augmented Generation with Implicit Queries",
    "authors": [
      "Wenzheng Zhang",
      "Xi Victoria Lin",
      "Karl Stratos",
      "Wen-tau Yih",
      "Mingda Chen"
    ],
    "abstract": "Retrieval-Augmented Generation (RAG) systems traditionally treat retrieval\nand generation as separate processes, requiring explicit textual queries to\nconnect them. This separation can limit the ability of models to generalize\nacross diverse tasks. In this work, we propose a query-free RAG system, named\nImpRAG, which integrates retrieval and generation into a unified model. ImpRAG\nallows models to implicitly express their information needs, eliminating the\nneed for human-specified queries. By dividing pretrained decoder-only language\nmodels into specialized layer groups, ImpRAG optimizes retrieval and generation\ntasks simultaneously. Our approach employs a two-stage inference process, using\nthe same model parameters and forward pass for both retrieval and generation,\nthereby minimizing the disparity between retrievers and language models.\nExperiments on 8 knowledge-intensive tasks demonstrate that ImpRAG achieves\n3.6-11.5 improvements in exact match scores on unseen tasks with diverse\nformats, highlighting its effectiveness in enabling models to articulate their\nown information needs and generalize across tasks. Our analysis underscores the\nimportance of balancing retrieval and generation parameters and leveraging\ngeneration perplexities as retrieval training objectives for enhanced\nperformance.",
    "pdf_url": "http://arxiv.org/pdf/2506.02279v1",
    "published": "2025-06-02T21:38:21+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.02278v1",
    "title": "Separable motions for self-gravitating hyperelastic matter",
    "authors": [
      "Juhi Jang",
      "Trevor M. Leslie"
    ],
    "abstract": "In this paper, we prove the existence of separable solutions to the equations\nof motion for self-gravitating hyperelastic matter, under an appropriate class\nof constitutive assumptions on the strain-energy function. Our framework\nincludes both global-in-time solutions which expand and also solutions which\ncollapse to a point in finite time. Other authors have constructed expanding\nsolutions in similar settings, but to the best of our knowledge, the collapsing\nsolutions we construct are completely new.",
    "pdf_url": "http://arxiv.org/pdf/2506.02278v1",
    "published": "2025-06-02T21:37:57+00:00",
    "categories": [
      "math.AP"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2506.03207v1",
    "title": "Fingerprinting Deep Learning Models via Network Traffic Patterns in Federated Learning",
    "authors": [
      "Md Nahid Hasan Shuvo",
      "Moinul Hossain"
    ],
    "abstract": "Federated Learning (FL) is increasingly adopted as a decentralized machine\nlearning paradigm due to its capability to preserve data privacy by training\nmodels without centralizing user data. However, FL is susceptible to indirect\nprivacy breaches via network traffic analysis-an area not explored in existing\nresearch. The primary objective of this research is to study the feasibility of\nfingerprinting deep learning models deployed within FL environments by\nanalyzing their network-layer traffic information. In this paper, we conduct an\nexperimental evaluation using various deep learning architectures (i.e., CNN,\nRNN) within a federated learning testbed. We utilize machine learning\nalgorithms, including Support Vector Machines (SVM), Random Forest, and\nGradient-Boosting, to fingerprint unique patterns within the traffic data. Our\nexperiments show high fingerprinting accuracy, achieving 100% accuracy using\nRandom Forest and around 95.7% accuracy using SVM and Gradient Boosting\nclassifiers. This analysis suggests that we can identify specific architectures\nrunning within the subsection of the network traffic. Hence, if an adversary\nknows about the underlying DL architecture, they can exploit that information\nand conduct targeted attacks. These findings suggest a notable security\nvulnerability in FL systems and the necessity of strengthening it at the\nnetwork level.",
    "pdf_url": "http://arxiv.org/pdf/2506.03207v1",
    "published": "2025-06-02T21:37:20+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.02277v2",
    "title": "Parallel Repetition for Post-Quantum Arguments",
    "authors": [
      "Andrew Huang",
      "Yael Tauman Kalai"
    ],
    "abstract": "In this work, we show that parallel repetition of public-coin interactive\narguments reduces the soundness error at an exponential rate even in the\npost-quantum setting. Moreover, we generalize this result to hold for threshold\nverifiers, where the parallel repeated verifier accepts if and only if at least\n$t$ of the executions are accepted (for some threshold $t$). Prior to this\nwork, these results were known only when the cheating prover was assumed to be\nclassical.\n  We also prove a similar result for three-message private-coin arguments.\nPreviously, Bostanci, Qian, Spooner, and Yuen (STOC 2024) proved such a\nparallel repetition result in the more general setting of quantum protocols,\nwhere the verifier and communication may be quantum. We consider only protocols\nwhere the verifier is classical, but obtain a simplified analysis, and for the\nmore general setting of threshold verifiers.",
    "pdf_url": "http://arxiv.org/pdf/2506.02277v2",
    "published": "2025-06-02T21:36:31+00:00",
    "categories": [
      "quant-ph",
      "cs.CR"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.02276v1",
    "title": "Latent Stochastic Interpolants",
    "authors": [
      "Saurabh Singh",
      "Dmitry Lagun"
    ],
    "abstract": "Stochastic Interpolants (SI) are a powerful framework for generative\nmodeling, capable of flexibly transforming between two probability\ndistributions. However, their use in jointly optimized latent variable models\nremains unexplored as they require direct access to the samples from the two\ndistributions. This work presents Latent Stochastic Interpolants (LSI) enabling\njoint learning in a latent space with end-to-end optimized encoder, decoder and\nlatent SI models. We achieve this by developing a principled Evidence Lower\nBound (ELBO) objective derived directly in continuous time. The joint\noptimization allows LSI to learn effective latent representations along with a\ngenerative process that transforms an arbitrary prior distribution into the\nencoder-defined aggregated posterior. LSI sidesteps the simple priors of the\nnormal diffusion models and mitigates the computational demands of applying SI\ndirectly in high-dimensional observation spaces, while preserving the\ngenerative flexibility of the SI framework. We demonstrate the efficacy of LSI\nthrough comprehensive experiments on the standard large scale ImageNet\ngeneration benchmark.",
    "pdf_url": "http://arxiv.org/pdf/2506.02276v1",
    "published": "2025-06-02T21:34:50+00:00",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.02275v1",
    "title": "Discrete Painlevé equations from pencils of quadrics in $\\mathbb P^3$ with branching generators",
    "authors": [
      "Jaume Alonso",
      "Yuri B. Suris"
    ],
    "abstract": "In this paper we extend the novel approach to discrete Painlev\\'e equations\ninitiated in our previous work [2]. A classification scheme for discrete\nPainlev\\'e equations proposed by Sakai interprets them as birational\nisomorphisms between generalized Halphen surfaces (surfaces obtained from\n$\\mathbb P^1\\times\\mathbb P^1$ by blowing up at eight points). Sakai's\nclassification is thus based on the classification of generalized Halphen\nsurfaces. In our scheme, the family of generalized Halphen surfaces is replaced\nby a pencil of quadrics in $\\mathbb P^3$. A discrete Painlev\\'e equation is\nviewed as an autonomous transformation of $\\mathbb P^3$ that preserves the\npencil and maps each quadric of the pencil to a different one. Thus, our scheme\nis based on the classification of pencils of quadrics in $\\mathbb P^3$.\nCompared to our previous work, here we consider a technically more demanding\ncase where the characteristic polynomial $\\Delta(\\lambda)$ of the pencil of\nquadrics is not a complete square. As a consequence, traversing the pencil via\na 3D Painlev\\'e map corresponds to a translation on the universal cover of the\nRiemann surface of $\\sqrt{\\Delta(\\lambda)}$, rather than to a M\\\"obius\ntransformation of the pencil parameter $\\lambda$ as in [2].",
    "pdf_url": "http://arxiv.org/pdf/2506.02275v1",
    "published": "2025-06-02T21:34:15+00:00",
    "categories": [
      "math-ph",
      "math.DS",
      "math.MP",
      "nlin.SI"
    ],
    "primary_category": "math-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.02274v2",
    "title": "A General Approach to the Shape Transition of Run-and-Tumble Particles: The 1D PDMP Framework for Invariant Measure Regularity",
    "authors": [
      "Leo Hahn"
    ],
    "abstract": "Run-and-tumble particles (RTPs) have emerged as a paradigmatic example for\nstudying nonequilibrium phenomena in statistical mechanics. The invariant\nmeasure of a wide class of RTPs subjected to a potential possesses a density\nthat is continuous at high tumble rates but exhibits divergences at low ones.\nThis key feature, known as shape transition, constitutes a qualitative\nindicator of the relative closeness (continuous density) or strong deviation\n(diverging density) from the equilibrium setting. Furthermore, the points at\nwhich the density diverges correspond to the configurations where the system\nspends most of its time in the low tumble rate regime. Building on and\nextending existing results concerning the regularity of the invariant measure\nof one-dimensional piecewise-deterministic Markov processes (PDMPs), we show\nhow to characterize the shape transition even in situations where the invariant\nmeasure cannot be computed explicitly. Our analysis confirms shape transition\nas a robust, general feature of RTPs subjected to a potential. We also refine\nthe regularity theory for the invariant measure of one-dimensional PDMPs.",
    "pdf_url": "http://arxiv.org/pdf/2506.02274v2",
    "published": "2025-06-02T21:32:57+00:00",
    "categories": [
      "cond-mat.stat-mech",
      "math.PR"
    ],
    "primary_category": "cond-mat.stat-mech"
  },
  {
    "id": "http://arxiv.org/abs/2506.02273v1",
    "title": "Particle-in-Cell Simulations of Burning ICF Capsule Implosions",
    "authors": [
      "Johannes J. van de Wetering",
      "Justin R. Angus",
      "W. Farmer",
      "V. Geyko",
      "D. Ghosh",
      "D. Grote",
      "C. Weber",
      "G. Zimmerman"
    ],
    "abstract": "Anomalies observed in the neutron spectral shift of high-yield shots at the\nNational Ignition Facility (NIF) suggest the presence of suprathermal ions,\nimplying that kinetic effects play a significant role in burning inertial\nconfinement fusion (ICF) plasmas. Furthermore, recent measurements of\nreaction-in-flight (RIF) neutrons offer a direct probe of the stopping power in\nthe burning fuel region of high energy alpha particles and up-scattered fuel\nions. We have developed the particle-in-cell code PICNIC, an exactly\nenergy-conserving particle-in-cell Monte-Carlo collision (PIC-MCC) code to\nsimulate the burn stage in ICF. We present results from 1D spherical\nsimulations of NIF shot N210808. We find that the suprathermal ions generated\nby large-angle Rutherford and nuclear elastic scattering (NES) with fusion\nalphas produce an alpha knock-on neutron (AKN) signal consistent with\nexperiments. We also find that the inclusion of large-angle scattering physics\ndoes not explain the anomalously large spectral shift observed in experiment.",
    "pdf_url": "http://arxiv.org/pdf/2506.02273v1",
    "published": "2025-06-02T21:32:19+00:00",
    "categories": [
      "physics.plasm-ph",
      "physics.comp-ph"
    ],
    "primary_category": "physics.plasm-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.02272v1",
    "title": "Converting entanglement into ensemble basis-free coherence",
    "authors": [
      "Aleksei Kodukhov"
    ],
    "abstract": "The resource theory of coherence addresses the extent to which quantum\nproperties are present in a given quantum system. While coherence has been\nextensively studied for individual quantum states, measures of coherence for\nensembles of quantum states remain an area of active research. The\nentanglement-based approach to ensemble coherence - where a partial measurement\nof an entangled state generates an ensemble - relates the ensemble coherence to\nboth the initial entanglement and the measurement's uncertainty. This paper\npresents two methods for generating ensemble coherence from a fixed amount of\nentanglement. The first method involves applying a von Neumann measurement to\none part of a non-maximally entangled bipartite state, resulting in a pair of\nnon-orthogonal states whose coherence can equal the initial entanglement. The\nsecond method considers a class of symmetric observables capable of generating\nensembles used in quantum key distribution (QKD) protocols such as B92, BB84,\nand three-state QKD. As a result, this work contributes to understanding how\nmuch ensemble coherence can be obtained from a given amount of entanglement.",
    "pdf_url": "http://arxiv.org/pdf/2506.02272v1",
    "published": "2025-06-02T21:32:11+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.02271v2",
    "title": "Prediction of the SVOM MXT camera end of life spectral performance based on proton irradiation results",
    "authors": [
      "Clara Plasse",
      "Diego Götz",
      "Aline Meuris",
      "Miguel Fernandez Moita",
      "Philippe Ferrando",
      "Leo Favier",
      "Francesco Ceraudo"
    ],
    "abstract": "SVOM, the Space-based Variable astronomical Object Monitor, launched on June\n22nd 2024, is a Chinese-French mission focused on exploring the brightest\nphenomena in the cosmos - Gamma-Ray Bursts. Among the four instruments on board\nis the Micro-channel X-ray Telescope (MXT). The MXT camera features a 256x256\npixel pnCCD detector to perform X-ray imaging and spectroscopy in the 0.2-10\nkeV energy range. Cruising in a low-Earth orbit (600 km) that crosses the South\nAtlantic Anomaly, the MXT focal plane is exposed to radiation, primarily\nprotons, that will lead to performance degradation over time. The challenge for\nMXT, and possibly for future missions with similar mass and mechanical\nconstraints, is to maintain spectral performance all along the mission\nduration. To assess the expected radiation-induced performance degradation, a\nspare flight model of MXT focal plane underwent an irradiation campaign with 50\nMeV protons at the Arronax cyclotron facility in June 2022. Then, the proton\nirradiated spare model was characterized in detail at the X-ray Metrology\nbeamline of the SOLEIL Synchrotron facility in June 2023, as well as with a\nlaboratory X-ray fluorescence source. We find through the evaluation of key\nindicators of performance such as the charge transfer inefficiency (CTI) and\nthe low energy threshold, that MXT will remain compliant to its requirements\nover the SVOM mission lifetime. We also report an unexpected effect of proton\nirradiation that is the inversion of the trend of CTI with energy, recovered\nwith two different sources illuminating the detector, and never reported in\nliterature so far.",
    "pdf_url": "http://arxiv.org/pdf/2506.02271v2",
    "published": "2025-06-02T21:31:18+00:00",
    "categories": [
      "astro-ph.IM"
    ],
    "primary_category": "astro-ph.IM"
  },
  {
    "id": "http://arxiv.org/abs/2506.02270v1",
    "title": "Analytical solution for dynamic evaporation of liquid in isothermal condition",
    "authors": [
      "Luiz Eduardo Czelusniak",
      "Tim Niklas Bingert",
      "Stephan Simonis",
      "Alexander J. Wagner",
      "Mathias J. Krause"
    ],
    "abstract": "An analytical solution based on a diffuse interface model is presented for an\nisothermal evaporation problem under sub-saturation pressure. The macroscopic\nequations are derived from the free-energy method, widely recognized in the\nlattice Boltzmann literature, distinguishing our approach from conventional\nevaporation models that rely on jump conditions or pure kinetic theory. The\ninterface behavior is fully described by differential equations, eliminating\nthe need for assumptions such as local equilibrium at the interface. We derive\nan exact analytical solution for the inviscid case and propose an approximate\nsolution when viscosity effects are considered. Our model unveils a novel\nrelationship between evaporation rate and viscosity, providing new insights\nthat have not been thoroughly explored in the literature. The analytical\nresults are validated through numerical simulations using the open-source\nparallel library OpenLB, demonstrating excellent agreement in predicting the\nphysical behavior of the evaporation phenomena within the framework of diffuse\ninterface methods.",
    "pdf_url": "http://arxiv.org/pdf/2506.02270v1",
    "published": "2025-06-02T21:29:44+00:00",
    "categories": [
      "physics.flu-dyn",
      "physics.comp-ph"
    ],
    "primary_category": "physics.flu-dyn"
  },
  {
    "id": "http://arxiv.org/abs/2506.02269v1",
    "title": "A Tale of Two Symmetries: Exploring the Loss Landscape of Equivariant Models",
    "authors": [
      "YuQing Xie",
      "Tess Smidt"
    ],
    "abstract": "Equivariant neural networks have proven to be effective for tasks with known\nunderlying symmetries. However, optimizing equivariant networks can be tricky\nand best training practices are less established than for standard networks. In\nparticular, recent works have found small training benefits from relaxing\nequivariance constraints. This raises the question: do equivariance constraints\nintroduce fundamental obstacles to optimization? Or do they simply require\ndifferent hyperparameter tuning? In this work, we investigate this question\nthrough a theoretical analysis of the loss landscape geometry. We focus on\nnetworks built using permutation representations, which we can view as a subset\nof unconstrained MLPs. Importantly, we show that the parameter symmetries of\nthe unconstrained model has nontrivial effects on the loss landscape of the\nequivariant subspace and under certain conditions can provably prevent learning\nof the global minima. Further, we empirically demonstrate in such cases,\nrelaxing to an unconstrained MLP can sometimes solve the issue. Interestingly,\nthe weights eventually found via relaxation corresponds to a different choice\nof group representation in the hidden layer. From this, we draw 3 key\ntakeaways. (1) Viewing any class of networks in the context of larger\nunconstrained function space can give important insights on loss landscape\nstructure. (2) Within the unconstrained function space, equivariant networks\nform a complicated union of linear hyperplanes, each associated with a specific\nchoice of internal group representation. (3) Effective relaxation of\nequivariance may require not only adding nonequivariant degrees of freedom, but\nalso rethinking the fixed choice of group representations in hidden layers.",
    "pdf_url": "http://arxiv.org/pdf/2506.02269v1",
    "published": "2025-06-02T21:15:36+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.02268v1",
    "title": "Energetics of self-organization in a dissipative two-site quantum system driven by single-photon pulses",
    "authors": [
      "Thiago Ganascini",
      "Wendel Lopes da Silva",
      "Daniel Valente"
    ],
    "abstract": "Finding principles of nonequilibrium self-organization in dissipative quantum\nsystems is an open problem. One example is the notion of quantum dissipative\nadaptation (QDA), that relates the transition probability between the ground\nstates of a quantum system to the nonequilibrium work absorbed during the\ntransition. However, QDA has been originally derived with three-level systems\nin lambda ({\\Lambda}) configuration. Here, we consider a model consisting of a\ntwo-site system driven by single-photon pulses. We find that the absorbed work\nis generally related to the sum of {\\Lambda}-type transition probabilities,\ninstead of the direct transition probability between the two ground states.\nAlthough this is equivalent to standard QDA in most scenarios, we find an\nexception whereby optimal self-organization does not maximize work consumption.\nWe show how quantum coherence leaves this kind of imprint in the energetics of\nself-organization in the present model.",
    "pdf_url": "http://arxiv.org/pdf/2506.02268v1",
    "published": "2025-06-02T21:15:33+00:00",
    "categories": [
      "quant-ph",
      "cond-mat.stat-mech"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.02267v1",
    "title": "TransAct V2: Lifelong User Action Sequence Modeling on Pinterest Recommendation",
    "authors": [
      "Xue Xia",
      "Saurabh Vishwas Joshi",
      "Kousik Rajesh",
      "Kangnan Li",
      "Yangyi Lu",
      "Nikil Pancha",
      "Dhruvil Deven Badani",
      "Jiajing Xu",
      "Pong Eksombatchai"
    ],
    "abstract": "Modeling user action sequences has become a popular focus in industrial\nrecommendation system research, particularly for Click-Through Rate (CTR)\nprediction tasks. However, industry-scale CTR models often rely on short user\nsequences, limiting their ability to capture long-term behavior. Additionally,\nthese models typically lack an integrated action-prediction task within a\npoint-wise ranking framework, reducing their predictive power. They also rarely\naddress the infrastructure challenges involved in efficiently serving\nlarge-scale sequential models. In this paper, we introduce TransAct V2, a\nproduction model for Pinterest's Homefeed ranking system, featuring three key\ninnovations: (1) leveraging very long user sequences to improve CTR\npredictions, (2) integrating a Next Action Loss function for enhanced user\naction forecasting, and (3) employing scalable, low-latency deployment\nsolutions tailored to handle the computational demands of extended user action\nsequences.",
    "pdf_url": "http://arxiv.org/pdf/2506.02267v1",
    "published": "2025-06-02T21:15:20+00:00",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2506.02266v1",
    "title": "Magneto-optical trapping of aluminum monofluoride",
    "authors": [
      "J. E. Padilla-Castillo",
      "J. Cai",
      "P. Agarwal",
      "P. Kukreja",
      "R. Thomas",
      "B. G. Sartakov",
      "S. Truppe",
      "G. Meijer",
      "S. C. Wright"
    ],
    "abstract": "Magneto-optical trapping of molecules has thus far been restricted to\nmolecules with $^2\\Sigma$ electronic ground states. These species are\nchemically reactive and only support a simple laser cooling scheme from their\nfirst excited rotational level. Here, we demonstrate a magneto-optical trap\n(MOT) of aluminum monofluoride (AlF), a deeply bound and intrinsically stable\ndiatomic molecule with a $^1\\Sigma^+$ electronic ground state. The MOT operates\non the strong A$^1\\Pi\\leftarrow{}$X$^1\\Sigma^+$ transition near 227.5~nm, whose\nQ$(J)$ lines are all rotationally closed. We demonstrate a MOT of about\n$6\\times 10^4$ molecules for the $J=1$ level of AlF, more than $10^4$ molecules\nfor $J=2$ and $3$, and with no fundamental limit in going to higher rotational\nlevels. Laser cooling and trapping of AlF is conceptually similar to the\nintroduction of alkaline-earth atoms into cold atom physics, and is key to\nleveraging its spin-forbidden a$^3\\Pi \\leftarrow{}$X$^1\\Sigma^+$ transition for\nprecision spectroscopy and narrow-line cooling.",
    "pdf_url": "http://arxiv.org/pdf/2506.02266v1",
    "published": "2025-06-02T21:15:14+00:00",
    "categories": [
      "physics.atom-ph",
      "quant-ph"
    ],
    "primary_category": "physics.atom-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.02265v1",
    "title": "Rig3R: Rig-Aware Conditioning for Learned 3D Reconstruction",
    "authors": [
      "Samuel Li",
      "Pujith Kachana",
      "Prajwal Chidananda",
      "Saurabh Nair",
      "Yasutaka Furukawa",
      "Matthew Brown"
    ],
    "abstract": "Estimating agent pose and 3D scene structure from multi-camera rigs is a\ncentral task in embodied AI applications such as autonomous driving. Recent\nlearned approaches such as DUSt3R have shown impressive performance in\nmultiview settings. However, these models treat images as unstructured\ncollections, limiting effectiveness in scenarios where frames are captured from\nsynchronized rigs with known or inferable structure.\n  To this end, we introduce Rig3R, a generalization of prior multiview\nreconstruction models that incorporates rig structure when available, and\nlearns to infer it when not. Rig3R conditions on optional rig metadata\nincluding camera ID, time, and rig poses to develop a rig-aware latent space\nthat remains robust to missing information. It jointly predicts pointmaps and\ntwo types of raymaps: a pose raymap relative to a global frame, and a rig\nraymap relative to a rig-centric frame consistent across time. Rig raymaps\nallow the model to infer rig structure directly from input images when metadata\nis missing.\n  Rig3R achieves state-of-the-art performance in 3D reconstruction, camera pose\nestimation, and rig discovery, outperforming both traditional and learned\nmethods by 17-45% mAA across diverse real-world rig datasets, all in a single\nforward pass without post-processing or iterative refinement.",
    "pdf_url": "http://arxiv.org/pdf/2506.02265v1",
    "published": "2025-06-02T21:15:00+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.02264v1",
    "title": "CoDial: Interpretable Task-Oriented Dialogue Systems Through Dialogue Flow Alignment",
    "authors": [
      "Radin Shayanfar",
      "Chu Fei Luo",
      "Rohan Bhambhoria",
      "Samuel Dahan",
      "Xiaodan Zhu"
    ],
    "abstract": "It is often challenging to teach specialized, unseen tasks to dialogue\nsystems due to the high cost of expert knowledge, training data, and high\ntechnical difficulty. To support domain-specific applications - such as law,\nmedicine, or finance - it is essential to build frameworks that enable\nnon-technical experts to define, test, and refine system behaviour with minimal\neffort. Achieving this requires cross-disciplinary collaboration between\ndevelopers and domain specialists. In this work, we introduce a novel\nframework, CoDial (Code for Dialogue), that converts expert knowledge,\nrepresented as a novel structured heterogeneous graph, into executable\nconversation logic. CoDial can be easily implemented in existing guardrailing\nlanguages, such as Colang, to enable interpretable, modifiable, and true\nzero-shot specification of task-oriented dialogue systems. Empirically, CoDial\nachieves state-of-the-art performance on the STAR dataset for inference-based\nmodels and is competitive with similar baselines on the well-known MultiWOZ\ndataset. We also demonstrate CoDial's iterative improvement via manual and\nLLM-aided feedback, making it a practical tool for expert-guided alignment of\nLLMs in high-stakes domains.",
    "pdf_url": "http://arxiv.org/pdf/2506.02264v1",
    "published": "2025-06-02T21:12:27+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.02263v1",
    "title": "Identifying interactions across brain areas while accounting for individual-neuron dynamics with a Transformer-based variational autoencoder",
    "authors": [
      "Qi Xin",
      "Robert E. Kass"
    ],
    "abstract": "Advances in large-scale recording technologies now enable simultaneous\nmeasurements from multiple brain areas, offering new opportunities to study\nsignal transmission across interacting components of neural circuits. However,\nneural responses exhibit substantial trial-to-trial variability, often driven\nby unobserved factors such as subtle changes in animal behavior or internal\nstates. To prevent evolving background dynamics from contaminating\nidentification of functional coupling, we developed a hybrid neural spike train\nmodel, GLM-Transformer, that incorporates flexible, deep latent variable models\ninto a point process generalized linear model (GLM) having an interpretable\ncomponent for cross-population interactions. A Transformer-based variational\nautoencoder captures nonstationary individual-neuron dynamics that vary across\ntrials, while standard nonparametric regression GLM coupling terms provide\nestimates of directed interactions between neural populations. We incorporate a\nlow-rank structure on population-to-population coupling effects to improve\nscalability. Across synthetic datasets and mechanistic simulations,\nGLM-Transformer recovers known coupling structure and remains robust to shared\nbackground fluctuations. When applied to the Allen Institute Visual Coding\ndataset, it identifies feedforward pathways consistent with established visual\nhierarchies. This work offers a step toward improved identification of neural\npopulation interactions, and contributes to ongoing efforts aimed at achieving\ninterpretable results while harvesting the benefits of deep learning.",
    "pdf_url": "http://arxiv.org/pdf/2506.02263v1",
    "published": "2025-06-02T21:12:15+00:00",
    "categories": [
      "q-bio.NC"
    ],
    "primary_category": "q-bio.NC"
  },
  {
    "id": "http://arxiv.org/abs/2506.02262v1",
    "title": "Composable Building Blocks for Controllable and Transparent Interactive AI Systems",
    "authors": [
      "Sebe Vanbrabant",
      "Gustavo Rovelo Ruiz",
      "Davy Vanacken"
    ],
    "abstract": "While the increased integration of AI technologies into interactive systems\nenables them to solve an equally increasing number of tasks, the black box\nproblem of AI models continues to spread throughout the interactive system as a\nwhole. Explainable AI (XAI) techniques can make AI models more accessible by\nemploying post-hoc methods or transitioning to inherently interpretable models.\nWhile this makes individual AI models clearer, the overarching system\narchitecture remains opaque. To this end, we propose an approach to represent\ninteractive systems as sequences of structural building blocks, such as AI\nmodels and control mechanisms grounded in the literature. These can then be\nexplained through accompanying visual building blocks, such as XAI techniques.\nThe flow and APIs of the structural building blocks form an explicit overview\nof the system. This serves as a communication basis for both humans and\nautomated agents like LLMs, aligning human and machine interpretability of AI\nmodels. We discuss a selection of building blocks and concretize our flow-based\napproach in an architecture and accompanying prototype interactive system.",
    "pdf_url": "http://arxiv.org/pdf/2506.02262v1",
    "published": "2025-06-02T21:10:51+00:00",
    "categories": [
      "cs.HC",
      "cs.AI",
      "H.5.2; I.2.0"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2506.02261v1",
    "title": "Towards Human-like Preference Profiling in Sequential Recommendation",
    "authors": [
      "Zhongyu Ouyang",
      "Qianlong Wen",
      "Chunhui Zhang",
      "Yanfang Ye",
      "Soroush Vosoughi"
    ],
    "abstract": "Sequential recommendation systems aspire to profile users by interpreting\ntheir interaction histories, echoing how humans make decisions by weighing\nexperience, relative preference strength, and situational relevance. Yet,\nexisting large language model (LLM)-based recommenders often fall short of\nmimicking the flexible, context-aware decision strategies humans exhibit,\nneglecting the structured, dynamic, and context-aware mechanisms fundamental to\nhuman behaviors. To bridge this gap, we propose RecPO, a preference\noptimization framework that models structured feedback and contextual delay to\nemulate human-like prioritization in sequential recommendation RecPO exploits\nadaptive reward margins based on inferred preference hierarchies and temporal\nsignals, enabling the model to favor immediately relevant items and to\ndistinguish between varying degrees of preference and aversion. Extensive\nexperiments across five real-world datasets demonstrate that RecPO not only\nyields performance gains over state-of-the-art baselines, but also mirrors key\ncharacteristics of human decision-making: favoring timely satisfaction,\nmaintaining coherent preferences, and exercising discernment under shifting\ncontexts.",
    "pdf_url": "http://arxiv.org/pdf/2506.02261v1",
    "published": "2025-06-02T21:09:29+00:00",
    "categories": [
      "cs.IR",
      "cs.LG"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2506.03206v1",
    "title": "Out-of-Vocabulary Sampling Boosts Speculative Decoding",
    "authors": [
      "Nadav Timor",
      "Jonathan Mamou",
      "Oren Pereg",
      "Hongyang Zhang",
      "David Harel"
    ],
    "abstract": "Speculative decoding relies on fast and accurate drafters. Recent\nstate-of-the-art language models employ larger and larger vocabularies, which\nsignificantly slows down drafters. One promising approach to boost the\nefficiency of speculative decoding is to use drafters with smaller\nvocabularies. However, existing sampling methods cannot draw out-of-vocabulary\ntokens, creating a tradeoff between drafters' vocabulary size and acceptance\nrates. This paper introduces Redistributing Drafter Kernels (RDK), the first\nout-of-vocabulary sampler that effectively recovers acceptance rates by\nvirtually restoring pruned target tokens. RDK leverages token-affinity priors\nto reallocate drafter mass towards high-overlap regions. We prove\nmathematically that RDK can achieve higher acceptance rates than vanilla and\nstate-of-the-art samplers. We provide an efficient first-order approximation of\nRDK and prove that it reduces redistribution times from $O(N^2)$ to $O(N)$,\nenabling lightweight implementations for large vocabularies. Our experiments\ndemonstrate that this linear-time RDK significantly boosts acceptance rates\neven after extreme pruning (removing more than 75% of the drafter's\nvocabulary), where existing samplers fail. RDK opens the door to extremely\npruned drafters, which were previously impractical.",
    "pdf_url": "http://arxiv.org/pdf/2506.03206v1",
    "published": "2025-06-02T21:08:02+00:00",
    "categories": [
      "cs.LG",
      "cs.CL"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.02260v2",
    "title": "MoCA: Multi-modal Cross-masked Autoencoder for Digital Health Measurements",
    "authors": [
      "Howon Ryu",
      "Yuliang Chen",
      "Yacun Wang",
      "Andrea Z. LaCroix",
      "Chongzhi Di",
      "Loki Natarajan",
      "Yu Wang",
      "Jingjing Zou"
    ],
    "abstract": "The growing prevalence of digital health technologies has led to the\ngeneration of complex multi-modal data, such as physical activity measurements\nsimultaneously collected from various sensors of mobile and wearable devices.\nThese data hold immense potential for advancing health studies, but current\nmethods predominantly rely on supervised learning, requiring extensive labeled\ndatasets that are often expensive or impractical to obtain, especially in\nclinical studies. To address this limitation, we propose a self-supervised\nlearning framework called Multi-modal Cross-masked Autoencoder (MoCA) that\nleverages cross-modality masking and the Transformer autoencoder architecture\nto utilize both temporal correlations within modalities and cross-modal\ncorrelations between data streams. We also provide theoretical guarantees to\nsupport the effectiveness of the cross-modality masking scheme in MoCA.\nComprehensive experiments and ablation studies demonstrate that our method\noutperforms existing approaches in both reconstruction and downstream tasks. We\nrelease open-source code for data processing, pre-training, and downstream\ntasks in the supplementary materials. This work highlights the transformative\npotential of self-supervised learning in digital health and multi-modal data.",
    "pdf_url": "http://arxiv.org/pdf/2506.02260v2",
    "published": "2025-06-02T21:07:25+00:00",
    "categories": [
      "stat.ML",
      "cs.LG",
      "stat.AP"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2506.02259v1",
    "title": "Stochastically Dominant Peer Prediction",
    "authors": [
      "Yichi Zhang",
      "Shengwei Xu",
      "David Pennock",
      "Grant Schoenebeck"
    ],
    "abstract": "Eliciting reliable human feedback is essential for many machine learning\ntasks, such as learning from noisy labels and aligning AI systems with human\npreferences. Peer prediction mechanisms incentivize truthful reporting without\nground truth verification by scoring agents based on correlations with peers.\nTraditional mechanisms, which ensure that truth-telling maximizes the expected\nscores in equilibrium, can elicit honest information while assuming agents'\nutilities are linear functions of their scores. However, in practice,\nnon-linear payment rules are usually preferred, or agents' utilities are\ninherently non-linear.\n  We propose stochastically dominant truthfulness (SD-truthfulness) as a\nstronger guarantee: the score distribution of truth-telling stochastically\ndominates all other strategies, incentivizing truthful reporting for a wide\nrange of monotone utility functions. Our first observation is that no existing\npeer prediction mechanism naturally satisfies this criterion without strong\nassumptions. A simple solution -- rounding scores into binary lotteries -- can\nenforce SD-truthfulness, but often degrades sensitivity, a key property related\nto fairness and statistical efficiency. We demonstrate how a more careful\napplication of rounding can better preserve sensitivity. Furthermore, we\nintroduce a new enforced agreement (EA) mechanism that is theoretically\nguaranteed to be SD-truthful in binary-signal settings under mild assumptions,\nand empirically achieves the highest sensitivity among all known SD-truthful\nmechanisms.",
    "pdf_url": "http://arxiv.org/pdf/2506.02259v1",
    "published": "2025-06-02T21:07:24+00:00",
    "categories": [
      "cs.GT",
      "cs.AI"
    ],
    "primary_category": "cs.GT"
  },
  {
    "id": "http://arxiv.org/abs/2506.02258v1",
    "title": "Are Mamba-based Audio Foundation Models the Best Fit for Non-Verbal Emotion Recognition?",
    "authors": [
      "Mohd Mujtaba Akhtar",
      "Orchid Chetia Phukan",
      "Girish",
      "Swarup Ranjan Behera",
      "Ananda Chandra Nayak",
      "Sanjib Kumar Nayak",
      "Arun Balaji Buduru",
      "Rajesh Sharma"
    ],
    "abstract": "In this work, we focus on non-verbal vocal sounds emotion recognition (NVER).\nWe investigate mamba-based audio foundation models (MAFMs) for the first time\nfor NVER and hypothesize that MAFMs will outperform attention-based audio\nfoundation models (AAFMs) for NVER by leveraging its state-space modeling to\ncapture intrinsic emotional structures more effectively. Unlike AAFMs, which\nmay amplify irrelevant patterns due to their attention mechanisms, MAFMs will\nextract more stable and context-aware representations, enabling better\ndifferentiation of subtle non-verbal emotional cues. Our experiments with\nstate-of-the-art (SOTA) AAFMs and MAFMs validates our hypothesis. Further,\nmotivated from related research such as speech emotion recognition, synthetic\nspeech detection, where fusion of foundation models (FMs) have showed improved\nperformance, we also explore fusion of FMs for NVER. To this end, we propose,\nRENO, that uses renyi-divergence as a novel loss function for effective\nalignment of the FMs. It also makes use of self-attention for better\nintra-representation interaction of the FMs. With RENO, through the\nheterogeneous fusion of MAFMs and AAFMs, we show the topmost performance in\ncomparison to individual FMs, its fusion and also setting SOTA in comparison to\nprevious SOTA work.",
    "pdf_url": "http://arxiv.org/pdf/2506.02258v1",
    "published": "2025-06-02T21:04:29+00:00",
    "categories": [
      "eess.AS",
      "cs.SD"
    ],
    "primary_category": "eess.AS"
  },
  {
    "id": "http://arxiv.org/abs/2506.02257v1",
    "title": "Assumption-free stability for ranking problems",
    "authors": [
      "Ruiting Liang",
      "Jake A. Soloff",
      "Rina Foygel Barber",
      "Rebecca Willett"
    ],
    "abstract": "In this work, we consider ranking problems among a finite set of candidates:\nfor instance, selecting the top-$k$ items among a larger list of candidates or\nobtaining the full ranking of all items in the set. These problems are often\nunstable, in the sense that estimating a ranking from noisy data can exhibit\nhigh sensitivity to small perturbations. Concretely, if we use data to provide\na score for each item (say, by aggregating preference data over a sample of\nusers), then for two items with similar scores, small fluctuations in the data\ncan alter the relative ranking of those items. Many existing theoretical\nresults for ranking problems assume a separation condition to avoid this\nchallenge, but real-world data often contains items whose scores are\napproximately tied, limiting the applicability of existing theory. To address\nthis gap, we develop a new algorithmic stability framework for ranking\nproblems, and propose two novel ranking operators for achieving stable ranking:\nthe \\emph{inflated top-$k$} for the top-$k$ selection problem and the\n\\emph{inflated full ranking} for ranking the full list. To enable stability,\neach method allows for expressing some uncertainty in the output. For both of\nthese two problems, our proposed methods provide guaranteed stability, with no\nassumptions on data distributions and no dependence on the total number of\ncandidates to be ranked. Experiments on real-world data confirm that the\nproposed methods offer stability without compromising the informativeness of\nthe output.",
    "pdf_url": "http://arxiv.org/pdf/2506.02257v1",
    "published": "2025-06-02T21:02:13+00:00",
    "categories": [
      "stat.ML",
      "cs.LG",
      "math.ST",
      "stat.ME",
      "stat.TH"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2506.02256v1",
    "title": "Human Heterogeneity Invariant Stress Sensing",
    "authors": [
      "Yi Xiao",
      "Harshit Sharma",
      "Sawinder Kaur",
      "Dessa Bergen-Cico",
      "Asif Salekin"
    ],
    "abstract": "Stress affects physical and mental health, and wearable devices have been\nwidely used to detect daily stress through physiological signals. However,\nthese signals vary due to factors such as individual differences and health\nconditions, making generalizing machine learning models difficult. To address\nthese challenges, we present Human Heterogeneity Invariant Stress Sensing\n(HHISS), a domain generalization approach designed to find consistent patterns\nin stress signals by removing person-specific differences. This helps the model\nperform more accurately across new people, environments, and stress types not\nseen during training. Its novelty lies in proposing a novel technique called\nperson-wise sub-network pruning intersection to focus on shared features across\nindividuals, alongside preventing overfitting by leveraging continuous labels\nwhile training. The study focuses especially on people with opioid use disorder\n(OUD)-a group where stress responses can change dramatically depending on their\ntime of daily medication taking. Since stress often triggers cravings, a model\nthat can adapt well to these changes could support better OUD rehabilitation\nand recovery. We tested HHISS on seven different stress datasets-four of which\nwe collected ourselves and three public ones. Four are from lab setups, one\nfrom a controlled real-world setting, driving, and two are from real-world\nin-the-wild field datasets without any constraints. This is the first study to\nevaluate how well a stress detection model works across such a wide range of\ndata. Results show HHISS consistently outperformed state-of-the-art baseline\nmethods, proving both effective and practical for real-world use. Ablation\nstudies, empirical justifications, and runtime evaluations confirm HHISS's\nfeasibility and scalability for mobile stress sensing in sensitive real-world\napplications.",
    "pdf_url": "http://arxiv.org/pdf/2506.02256v1",
    "published": "2025-06-02T21:00:00+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.02255v1",
    "title": "SafeOR-Gym: A Benchmark Suite for Safe Reinforcement Learning Algorithms on Practical Operations Research Problems",
    "authors": [
      "Asha Ramanujam",
      "Adam Elyoumi",
      "Hao Chen",
      "Sai Madhukiran Kompalli",
      "Akshdeep Singh Ahluwalia",
      "Shraman Pal",
      "Dimitri J. Papageorgiou",
      "Can Li"
    ],
    "abstract": "Most existing safe reinforcement learning (RL) benchmarks focus on robotics\nand control tasks, offering limited relevance to high-stakes domains that\ninvolve structured constraints, mixed-integer decisions, and industrial\ncomplexity. This gap hinders the advancement and deployment of safe RL in\ncritical areas such as energy systems, manufacturing, and supply chains. To\naddress this limitation, we present SafeOR-Gym, a benchmark suite of nine\noperations research (OR) environments tailored for safe RL under complex\nconstraints. Each environment captures a realistic planning, scheduling, or\ncontrol problems characterized by cost-based constraint violations, planning\nhorizons, and hybrid discrete-continuous action spaces. The suite integrates\nseamlessly with the Constrained Markov Decision Process (CMDP) interface\nprovided by OmniSafe. We evaluate several state-of-the-art safe RL algorithms\nacross these environments, revealing a wide range of performance: while some\ntasks are tractable, others expose fundamental limitations in current\napproaches. SafeOR-Gym provides a challenging and practical testbed that aims\nto catalyze future research in safe RL for real-world decision-making problems.\nThe SafeOR-Gym framework and all accompanying code are available at:\nhttps://github.com/li-group/SafeOR-Gym.",
    "pdf_url": "http://arxiv.org/pdf/2506.02255v1",
    "published": "2025-06-02T20:59:45+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.02254v1",
    "title": "Enabling Probabilistic Learning on Manifolds through Double Diffusion Maps",
    "authors": [
      "Dimitris G Giovanis",
      "Nikolaos Evangelou",
      "Ioannis G Kevrekidis",
      "Roger G Ghanem"
    ],
    "abstract": "We present a generative learning framework for probabilistic sampling based\non an extension of the Probabilistic Learning on Manifolds (PLoM) approach,\nwhich is designed to generate statistically consistent realizations of a random\nvector in a finite-dimensional Euclidean space, informed by a limited (yet\nrepresentative) set of observations. In its original form, PLoM constructs a\nreduced-order probabilistic model by combining three main components: (a)\nkernel density estimation to approximate the underlying probability measure,\n(b) Diffusion Maps to uncover the intrinsic low-dimensional manifold structure,\nand (c) a reduced-order Ito Stochastic Differential Equation (ISDE) to sample\nfrom the learned distribution. A key challenge arises, however, when the number\nof available data points N is small and the dimensionality of the diffusion-map\nbasis approaches N, resulting in overfitting and loss of generalization. To\novercome this limitation, we propose an enabling extension that implements a\nsynthesis of Double Diffusion Maps -- a technique capable of capturing\nmultiscale geometric features of the data -- with Geometric Harmonics (GH), a\nnonparametric reconstruction method that allows smooth nonlinear interpolation\nin high-dimensional ambient spaces. This approach enables us to solve a\nfull-order ISDE directly in the latent space, preserving the full dynamical\ncomplexity of the system, while leveraging its reduced geometric\nrepresentation. The effectiveness and robustness of the proposed method are\nillustrated through two numerical studies: one based on data generated from\ntwo-dimensional Hermite polynomial functions and another based on high-fidelity\nsimulations of a detonation wave in a reactive flow.",
    "pdf_url": "http://arxiv.org/pdf/2506.02254v1",
    "published": "2025-06-02T20:58:49+00:00",
    "categories": [
      "stat.ML",
      "cs.LG",
      "math.PR"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2506.02253v1",
    "title": "Stability of a cluster-disrupted mean-motion resonance (chain) in HR 8799 and PDS 70",
    "authors": [
      "Brent Maas",
      "Shuo Huang",
      "Simon Portegies Zwart"
    ],
    "abstract": "HR~8799 is a planetary system with four planets potentially in a mean-motion\nresonance chain. It is unclear from the observations if they are in mean-motion\nresonance. Similarly, PDS~70 has two observed planets also potentially in\nmean-motion resonance. We simulate HR~8799 and PDS~70 under external\nperturbations to study their responds if in resonance or mean-motion resonance.\nWe integrate the equations of motion for HR~8799 and PDS~70 starting with\neither in resonance or in mean-motion resonance and study their in isolation\nand in a star cluster. In the star cluster, we take the effects of passing\nstars into account. The dynamics of the star cluster is resolved using the\nLonely Planets module in AMUSE. HR~8799 and PDS~70 in mean-motion resonance are\nstable, whereas in non-resonance they dissolve in $0.303\\pm0.042$Myr and\n$1.26\\pm0.25$Myr, respectively. In a cluster, the non-resonant HR~8799 is\nslightly more stable than in isolation, but still dissolves in\n$0.300\\pm0.043$Myr, whereas the resonant planetary system remains stable for at\nleast $0.71$Myr. In contrast, a non-resonant PDS~70 system is approximately\nequally stable in a cluster compared to isolation, and dissolves in\n$1.03\\pm0.20$Myr, whereas the resonant PDS~70 system remains stable for at\nleast $0.83$Myr. Considering the more stable solutions of mean-motion resonance\nfor HR~8799, we argue that the planetary system was born in mean-motion\nresonance and that the mean-motion resonance was preserved. If HR~8799 was not\nborn in resonance, the probability that it survived until the present day is\nnegligible. Similarly, we argue that PDS~70 was probably born in mean-motion\nresonance and that its state was preserved. We also find that it is almost\npossible for planetary systems with a broken mean-motion resonance chain to\nsurvive longer in a perturbing cluster environment compared to isolation.",
    "pdf_url": "http://arxiv.org/pdf/2506.02253v1",
    "published": "2025-06-02T20:58:41+00:00",
    "categories": [
      "astro-ph.EP",
      "astro-ph.GA",
      "astro-ph.SR"
    ],
    "primary_category": "astro-ph.EP"
  },
  {
    "id": "http://arxiv.org/abs/2506.02252v1",
    "title": "Targeted searches for gravitational waves from SN 2023ixf and SGR 1935+2154",
    "authors": [
      "Marek J. Szczepańczyk"
    ],
    "abstract": "The fourth observing run of Advanced LIGO, Advanced Virgo, and KAGRA has\nprovided so far over 200 new gravitational-wave candidates, and it is still\nongoing. A few results from this run are published and in this proceeding, we\nsummarize the latest targeted search for GWs from SN 2023ixf and consider\npredictions for future searches. We also summarize the targeted search for GWs\nfrom a fast radio burst source SGR 1935+2154.",
    "pdf_url": "http://arxiv.org/pdf/2506.02252v1",
    "published": "2025-06-02T20:58:16+00:00",
    "categories": [
      "gr-qc",
      "astro-ph.HE"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2506.02251v2",
    "title": "Search for millicharged particles in proton-proton collisions at $\\sqrt{s} = 13.6$ TeV",
    "authors": [
      "S. Alcott",
      "Z. Bhatti",
      "J. Brooke",
      "C. Campagnari",
      "M. Carrigan",
      "M. Citron",
      "R. De Los Santos",
      "A. De Roeck",
      "C. Dorofeev",
      "T. Du",
      "J. Goldstein",
      "F. Golf",
      "N. Gonzalez",
      "A. Haas",
      "J. Heymann",
      "C. S. Hill",
      "D. Imani",
      "M. Joyce",
      "K. Larina",
      "R. Loos",
      "S. Lowette",
      "H. Mei",
      "D. W. Miller",
      "B. Peng",
      "S. N. Santpu",
      "I. Reed",
      "E. Schaffer",
      "R. Schmitz",
      "J. Steenis",
      "D. Stuart",
      "J. S. Tafoya Vargas",
      "D. Vannerom",
      "T. Wybouw",
      "Z. Xiao",
      "H. Zaraket",
      "G. Zecchinelli",
      "C. Zheng"
    ],
    "abstract": "We report on a search for elementary particles with charges much smaller than\nthe electron charge using a data sample of proton-proton collisions provided by\nthe CERN Large Hadron Collider in 2023--24, corresponding to an integrated\nluminosity of 124.7~fb$^{-1}$ at a center-of-mass energy of 13.6~TeV. The\nanalysis presented uses the completed Run 3 milliQan bar detector to set the\nmost stringent constraints to date for particles with charges $\\leq0.24~\\rm{e}$\nand masses $\\geq0.45~\\rm{GeV}$.",
    "pdf_url": "http://arxiv.org/pdf/2506.02251v2",
    "published": "2025-06-02T20:55:15+00:00",
    "categories": [
      "hep-ex"
    ],
    "primary_category": "hep-ex"
  },
  {
    "id": "http://arxiv.org/abs/2506.02250v1",
    "title": "Seeking Spinning Subpopulations of Black Hole Binaries via Iterative Density Estimation",
    "authors": [
      "Jam Sadiq",
      "Thomas Dent",
      "Ana Lorenzo-Medina"
    ],
    "abstract": "Attempts to understand the formation of binary black hole (BBH) systems\ndetected via gravitational wave (GW) emission are affected by many unknowns and\nuncertainties, from both the observational and theoretical (astrophysical\nmodelling) sides. Binary component spins have been proposed as a means to\ninvestigate formation channels, however obtaining clear inferences is\nchallenging, given the apparently low magnitude of almost all merging BH spins\nand their high measurement uncertainties. Even for the effective aligned spin\n$\\chi_{\\mathrm{eff}}$ which is more precisely measured than component spins,\nspecific model assumptions have been required to identify any clear trends.\nHere, we reconstruct the joint component mass and $\\chi_{\\mathrm{eff}}$\ndistribution of BBH mergers with minimal assumptions using the GWTC-3 catalog,\nusing an iterative kernel density estimation (KDE)-based method. We reproduce\nsome features seen in previous analyses, for instance a small but\npreferentially positive $\\chi_{\\mathrm{eff}}$ for low-mass mergers; we also\nidentify a possible subpopulation of higher-spin BBH with\n$|\\chi_{\\mathrm{eff}}|$ up to $\\sim\\! 0.75$ for primary masses $m_1 \\gtrsim\n40\\,M_\\odot$, in addition to the bulk of the distribution with\n$|\\chi_{\\mathrm{eff}}| \\lesssim 0.2$. This finding is consistent with previous\nstudies indicating a broader spin distribution at high mass, suggesting a\ndistinct origin for the high-spin systems. We also identify a\npreviously-unnoticed trend at lower masses: the population mean of\n$\\chi_{\\mathrm{eff}}$ increases (decreases) with $m_1$ ($m_2$) \\emph{within}\nthe overdensity around $m_1 \\sim 10 M_\\odot$. This ``spin fine structure'' may\npartly explain a previously reported anticorrelation between mass ratio and\n$\\chi_{\\mathrm{eff}}$.",
    "pdf_url": "http://arxiv.org/pdf/2506.02250v1",
    "published": "2025-06-02T20:54:09+00:00",
    "categories": [
      "astro-ph.HE",
      "gr-qc"
    ],
    "primary_category": "astro-ph.HE"
  },
  {
    "id": "http://arxiv.org/abs/2506.02249v2",
    "title": "Using Diffusion Models to do Data Assimilation",
    "authors": [
      "Daniel Hodyss",
      "Matthias Morzfeld"
    ],
    "abstract": "The recent surge in machine learning (ML) methods for geophysical modeling\nhas raised the question of how these methods might be applied to data\nassimilation (DA). We focus on diffusion modeling (a form of generative\nartificial intelligence) for systems that can perform the entire DA process,\nrather than on ML-based tools used within a conventional DA system. We identify\nat least three distinct types of diffusion-based DA systems and show that they\ndiffer in the posterior distribution they target for sampling. These posterior\ndistributions correspond to different priors and/or likelihoods, which in turn\nresult in unique training datasets, computational requirements, and state\nestimate qualities. Our analysis further shows that a diffusion DA system\ndesigned to target the same posterior distribution as current ensemble DA\nalgorithms requires re-training at each DA cycle, which is computationally\ncostly. We discuss the implications of these findings for the use of diffusion\nmodeling in DA.",
    "pdf_url": "http://arxiv.org/pdf/2506.02249v2",
    "published": "2025-06-02T20:51:32+00:00",
    "categories": [
      "physics.ao-ph",
      "physics.data-an"
    ],
    "primary_category": "physics.ao-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.02248v1",
    "title": "Analysis of in-vivo skin anisotropy using elastic wave measurements and Bayesian modelling",
    "authors": [
      "Matt Nagle",
      "Susan Price",
      "Antonia Trotta",
      "Michel Destrade",
      "Michael Fop",
      "Aisling Ní Annaidh"
    ],
    "abstract": "In vivo skin exhibits viscoelastic, hyper-elastic and non-linear\ncharacteristics. It is under a constant non-equibiaxial tension in its natural\nconfiguration and is reinforced with oriented collagen fibers, giving rise to\nanisotropic behaviour. Understanding the complex mechanical behaviour of skin\nhas relevance across many sectors including pharmaceuticals, cosmetics and\nsurgery. However, there is a dearth of quality data characterizing human skin\nanisotropy in vivo. The available data is usually confined to limited\npopulation groups and/or limited angular resolution. Here, we use elastic waves\ntravelling through the skin to obtain measurements from 78 volunteers from 3 to\n93 years old. Using a Bayesian framework, we analyse the effect that age,\ngender and level of skin tension have on the skin anisotropy and stiffness.\nFirst, we propose a new measurement of anisotropy based on the eccentricity of\nangular data and conclude that it is a more robust measurement compared to the\nclassic ``anisotropic ratio\". We then find that in vivo skin anisotropy\nincreases logarithmically with age, while the skin stiffness increases linearly\nalong the direction of Langer Lines. We also conclude that gender does not\nsignificantly affect the skin anisotropy level, but does affect the overall\nstiffness, with males having stiffer skin on average. Finally, we find that\nskin tension significantly affects both the anisotropy and stiffness\nmeasurements, indicating that elastic wave measurements have promising\napplications in determining in vivo skin tension. In contrast to earlier\nstudies, these results represent a comprehensive assessment of the variation of\nskin anisotropy with age and gender using a sizeable dataset and robust modern\nstatistical analysis. This data has implications for the planning of surgical\nprocedures and the adoption of universal cosmetic surgery practices for young\nor elderly patients.",
    "pdf_url": "http://arxiv.org/pdf/2506.02248v1",
    "published": "2025-06-02T20:51:23+00:00",
    "categories": [
      "physics.bio-ph",
      "cond-mat.soft"
    ],
    "primary_category": "physics.bio-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.02247v2",
    "title": "EgoVIS@CVPR: PAIR-Net: Enhancing Egocentric Speaker Detection via Pretrained Audio-Visual Fusion and Alignment Loss",
    "authors": [
      "Yu Wang",
      "Juhyung Ha",
      "David J. Crandall"
    ],
    "abstract": "Active speaker detection (ASD) in egocentric videos presents unique\nchallenges due to unstable viewpoints, motion blur, and off-screen speech\nsources - conditions under which traditional visual-centric methods degrade\nsignificantly. We introduce PAIR-Net (Pretrained Audio-Visual Integration with\nRegularization Network), an effective model that integrates a partially frozen\nWhisper audio encoder with a fine-tuned AV-HuBERT visual backbone to robustly\nfuse cross-modal cues. To counteract modality imbalance, we introduce an\ninter-modal alignment loss that synchronizes audio and visual representations,\nenabling more consistent convergence across modalities. Without relying on\nmulti-speaker context or ideal frontal views, PAIR-Net achieves\nstate-of-the-art performance on the Ego4D ASD benchmark with 76.6% mAP,\nsurpassing LoCoNet and STHG by 8.2% and 12.9% mAP, respectively. Our results\nhighlight the value of pretrained audio priors and alignment-based fusion for\nrobust ASD under real-world egocentric conditions.",
    "pdf_url": "http://arxiv.org/pdf/2506.02247v2",
    "published": "2025-06-02T20:49:52+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.02246v2",
    "title": "Higher symmetries in twisted eleven-dimensional supergravity",
    "authors": [
      "Fabian Hahner",
      "Natalie M. Paquette",
      "Surya Raghavendran"
    ],
    "abstract": "In supersymmetric theories, protected quantities can be reorganized into\nholomorphic-topological theories by twisting. Recently, it was observed by\n\\cite{JKY} that residual super-Poincar\\'e symmetries in certain twisted\ntheories can receive higher corrections, turning them into $L_\\infty$ algebras\nwith non-strict actions on the twisted fields. In this note, we show that the\nsame phenomenon occurs for the two admissible twists of eleven-dimensional\nsupergravity. Along the way, we discuss in detail the connection between\ncomponents of physical and twisted fields.",
    "pdf_url": "http://arxiv.org/pdf/2506.02246v2",
    "published": "2025-06-02T20:46:37+00:00",
    "categories": [
      "hep-th",
      "math-ph",
      "math.MP",
      "83E50, 17B81"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2506.02245v1",
    "title": "Dynamical Dark Energy from $F(R)$ Gravity Models Unifying Inflation with Dark Energy: Confronting the Latest Observational Data",
    "authors": [
      "S. D. Odintsov",
      "V. K. Oikonomou",
      "G. S. Sharov"
    ],
    "abstract": "A class of viable $F(R)$ gravity models which can provide a unified\ndescription of inflation with the dark energy era is confronted with the latest\nobservational data on the dark energy era. These models have the unique\ncharacteristic that the de Sitter scalaron mass in the Einstein frame\ncounterpart theory is a monotonic function of the curvature, which renders them\nviable descriptions for both the inflationary and the late-time acceleration\neras. We also compare these models with other well-known viable $F(R)$ gravity\nmodels and with the $\\Lambda$-Cold-Dark-Matter model. As we show, the most\nphenomenologically successful models are those which deviate significantly from\nthe $\\Lambda$-Cold-Dark-Matter model. Also some of the models presented,\nprovide a statistically favorable description of the dark energy eras, compared\nwith the exponential $F(R)$ gravity model and of course compared with the\n$\\Lambda$-Cold-Dark-Matter model. All the models we present in this article are\nconfronted with the observational data from the Planck collaboration, the\nPantheon plus data from Type Ia supernovae, the two rounds of observations of\nthe Dark Energy Spectroscopic Instrument, data from baryon acoustic\noscillations and the Hubble constant measurements by SH0ES group. As we show,\ntwo of the models are statistically favorable by the data.",
    "pdf_url": "http://arxiv.org/pdf/2506.02245v1",
    "published": "2025-06-02T20:46:16+00:00",
    "categories": [
      "gr-qc",
      "astro-ph.CO"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2506.03205v1",
    "title": "Q-ARDNS-Multi: A Multi-Agent Quantum Reinforcement Learning Framework with Meta-Cognitive Adaptation for Complex 3D Environments",
    "authors": [
      "Umberto Gonçalves de Sousa"
    ],
    "abstract": "This paper presents Q-ARDNS-Multi, an advanced multi-agent quantum\nreinforcement learning (QRL) framework that extends the ARDNS-FN-Quantum model,\nwhere Q-ARDNS-Multi stands for \"Quantum Adaptive Reward-Driven Neural Simulator\n- Multi-Agent\". It integrates quantum circuits with RY gates, meta-cognitive\nadaptation, and multi-agent coordination mechanisms for complex 3D\nenvironments. Q-ARDNS-Multi leverages a 2-qubit quantum circuit for action\nselection, a dual-memory system inspired by human cognition, a shared memory\nmodule for agent cooperation, and adaptive exploration strategies modulated by\nreward variance and intrinsic motivation. Evaluated in a $10 \\times 10 \\times\n3$ GridWorld environment with two agents over 5000 episodes, Q-ARDNS-Multi\nachieves success rates of 99.6\\% and 99.5\\% for Agents 0 and 1, respectively,\noutperforming Multi-Agent Deep Deterministic Policy Gradient (MADDPG) and Soft\nActor-Critic (SAC) in terms of success rate, stability, navigation efficiency,\nand collision avoidance. The framework records mean rewards of $-304.2891 \\pm\n756.4636$ and $-295.7622 \\pm 752.7103$, averaging 210 steps to goal,\ndemonstrating its robustness in dynamic settings. Comprehensive analyses,\nincluding learning curves, reward distributions, statistical tests, and\ncomputational efficiency evaluations, highlight the contributions of quantum\ncircuits and meta-cognitive adaptation. By bridging quantum computing,\ncognitive science, and multi-agent RL, Q-ARDNS-Multi offers a scalable,\nhuman-like approach for applications in robotics, autonomous navigation, and\ndecision-making under uncertainty.",
    "pdf_url": "http://arxiv.org/pdf/2506.03205v1",
    "published": "2025-06-02T20:43:33+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2506.02244v1",
    "title": "Motion aware video generative model",
    "authors": [
      "Bowen Xue",
      "Giuseppe Claudio Guarnera",
      "Shuang Zhao",
      "Zahra Montazeri"
    ],
    "abstract": "Recent advances in diffusion-based video generation have yielded\nunprecedented quality in visual content and semantic coherence. However,\ncurrent approaches predominantly rely on statistical learning from vast\ndatasets without explicitly modeling the underlying physics of motion,\nresulting in subtle yet perceptible non-physical artifacts that diminish the\nrealism of generated videos. This paper introduces a physics-informed frequency\ndomain approach to enhance the physical plausibility of generated videos. We\nfirst conduct a systematic analysis of the frequency-domain characteristics of\ndiverse physical motions (translation, rotation, scaling), revealing that each\nmotion type exhibits distinctive and identifiable spectral signatures. Building\non this theoretical foundation, we propose two complementary components: (1) a\nphysical motion loss function that quantifies and optimizes the conformity of\ngenerated videos to ideal frequency-domain motion patterns, and (2) a frequency\ndomain enhancement module that progressively learns to adjust video features to\nconform to physical motion constraints while preserving original network\nfunctionality through a zero-initialization strategy. Experiments across\nmultiple video diffusion architectures demonstrate that our approach\nsignificantly enhances motion quality and physical plausibility without\ncompromising visual quality or semantic alignment. Our frequency-domain\nphysical motion framework generalizes effectively across different video\ngeneration architectures, offering a principled approach to incorporating\nphysical constraints into deep learning-based video synthesis pipelines. This\nwork seeks to establish connections between data-driven models and\nphysics-based motion models.",
    "pdf_url": "http://arxiv.org/pdf/2506.02244v1",
    "published": "2025-06-02T20:42:54+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.02243v1",
    "title": "From Features to Structure: Task-Aware Graph Construction for Relational and Tabular Learning with GNNs",
    "authors": [
      "Tamara Cucumides",
      "Floris Geerts"
    ],
    "abstract": "Tabular and relational data remain the most ubiquitous formats in real-world\nmachine learning applications, spanning domains from finance to healthcare.\nAlthough both formats offer structured representations, they pose distinct\nchallenges for modern deep learning methods, which typically assume flat,\nfeature-aligned inputs. Graph Neural Networks (GNNs) have emerged as a\npromising solution by capturing structural dependencies within and between\ntables. However, existing GNN-based approaches often rely on rigid,\nschema-derived graphs -- such as those based on primary-foreign key links --\nthereby underutilizing rich, predictive signals in non key attributes. In this\nwork, we introduce auGraph, a unified framework for task-aware graph\naugmentation that applies to both tabular and relational data. auGraph enhances\nbase graph structures by selectively promoting attributes into nodes, guided by\nscoring functions that quantify their relevance to the downstream prediction\ntask. This augmentation preserves the original data schema while injecting\ntask-relevant structural signal. Empirically, auGraph outperforms schema-based\nand heuristic graph construction methods by producing graphs that better\nsupport learning for relational and tabular prediction tasks.",
    "pdf_url": "http://arxiv.org/pdf/2506.02243v1",
    "published": "2025-06-02T20:42:53+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.02242v2",
    "title": "From Street Views to Urban Science: Discovering Road Safety Factors with Multimodal Large Language Models",
    "authors": [
      "Yihong Tang",
      "Ao Qu",
      "Xujing Yu",
      "Weipeng Deng",
      "Jun Ma",
      "Jinhua Zhao",
      "Lijun Sun"
    ],
    "abstract": "Urban and transportation research has long sought to uncover statistically\nmeaningful relationships between key variables and societal outcomes such as\nroad safety, to generate actionable insights that guide the planning,\ndevelopment, and renewal of urban and transportation systems. However,\ntraditional workflows face several key challenges: (1) reliance on human\nexperts to propose hypotheses, which is time-consuming and prone to\nconfirmation bias; (2) limited interpretability, particularly in deep learning\napproaches; and (3) underutilization of unstructured data that can encode\ncritical urban context. Given these limitations, we propose a Multimodal Large\nLanguage Model (MLLM)-based approach for interpretable hypothesis inference,\nenabling the automated generation, evaluation, and refinement of hypotheses\nconcerning urban context and road safety outcomes. Our method leverages MLLMs\nto craft safety-relevant questions for street view images (SVIs), extract\ninterpretable embeddings from their responses, and apply them in\nregression-based statistical models. UrbanX supports iterative hypothesis\ntesting and refinement, guided by statistical evidence such as coefficient\nsignificance, thereby enabling rigorous scientific discovery of previously\noverlooked correlations between urban design and safety. Experimental\nevaluations on Manhattan street segments demonstrate that our approach\noutperforms pretrained deep learning models while offering full\ninterpretability. Beyond road safety, UrbanX can serve as a general-purpose\nframework for urban scientific discovery, extracting structured insights from\nunstructured urban data across diverse socioeconomic and environmental\noutcomes. This approach enhances model trustworthiness for policy applications\nand establishes a scalable, statistically grounded pathway for interpretable\nknowledge discovery in urban and transportation studies.",
    "pdf_url": "http://arxiv.org/pdf/2506.02242v2",
    "published": "2025-06-02T20:40:56+00:00",
    "categories": [
      "cs.LG",
      "cs.CY"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.02241v1",
    "title": "Second-order AAA algorithms for structured data-driven modeling",
    "authors": [
      "Michael S. Ackermann",
      "Ion Victor Gosea",
      "Serkan Gugercin",
      "Steffen W. R. Werner"
    ],
    "abstract": "The data-driven modeling of dynamical systems has become an essential tool\nfor the construction of accurate computational models from real-world data. In\nthis process, the inherent differential structures underlying the considered\nphysical phenomena are often neglected making the reinterpretation of the\nlearned models in a physically meaningful sense very challenging. In this work,\nwe present three data-driven modeling approaches for the construction of\ndynamical systems with second-order differential structure directly from\nfrequency domain data. Based on the second-order structured barycentric form,\nwe extend the well-known Adaptive Antoulas-Anderson algorithm to the case of\nsecond-order systems. Depending on the available computational resources, we\npropose variations of the proposed method that prioritize either higher\ncomputation speed or greater modeling accuracy, and we present a theoretical\nanalysis for the expected accuracy and performance of the proposed methods.\nThree numerical examples demonstrate the effectiveness of our new structured\napproaches in comparison to classical unstructured data-driven modeling.",
    "pdf_url": "http://arxiv.org/pdf/2506.02241v1",
    "published": "2025-06-02T20:34:18+00:00",
    "categories": [
      "math.NA",
      "cs.LG",
      "cs.NA",
      "cs.SY",
      "eess.SY",
      "math.DS",
      "math.OC",
      "41A20, 65D15, 93B15, 93C05, 93C80"
    ],
    "primary_category": "math.NA"
  },
  {
    "id": "http://arxiv.org/abs/2506.02240v1",
    "title": "Wheeler-DeWitt equation and Bondi-Metzner-Sachs (BMS) symmetry",
    "authors": [
      "Marc Henneaux"
    ],
    "abstract": "The Hamiltonian formulation of the BMS symmetry on spacelike hypersurfaces\nenables one to define its action on solutions of the Wheeler-DeWitt equation.\nUsing the BRST reformulation of the theory, we provide operator expressions for\nthe matrix elements of the BMS operators between Wheeler-DeWitt states. To that\nend, we construct the BRST-invariant extensions of the BMS generators, which\nform a BRST-extension of the BMS algebra.",
    "pdf_url": "http://arxiv.org/pdf/2506.02240v1",
    "published": "2025-06-02T20:32:47+00:00",
    "categories": [
      "hep-th",
      "gr-qc"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2506.02239v1",
    "title": "Investigating the Impact of Word Informativeness on Speech Emotion Recognition",
    "authors": [
      "Sofoklis Kakouros"
    ],
    "abstract": "In emotion recognition from speech, a key challenge lies in identifying\nspeech signal segments that carry the most relevant acoustic variations for\ndiscerning specific emotions. Traditional approaches compute functionals for\nfeatures such as energy and F0 over entire sentences or longer speech portions,\npotentially missing essential fine-grained variation in the long-form\nstatistics. This research investigates the use of word informativeness, derived\nfrom a pre-trained language model, to identify semantically important segments.\nAcoustic features are then computed exclusively for these identified segments,\nenhancing emotion recognition accuracy. The methodology utilizes standard\nacoustic prosodic features, their functionals, and self-supervised\nrepresentations. Results indicate a notable improvement in recognition\nperformance when features are computed on segments selected based on word\ninformativeness, underscoring the effectiveness of this approach.",
    "pdf_url": "http://arxiv.org/pdf/2506.02239v1",
    "published": "2025-06-02T20:30:48+00:00",
    "categories": [
      "cs.CL",
      "eess.AS"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.02238v1",
    "title": "On the Discontinuous Breaking of Replica Symmetry and Shattering in Mean-Field Spin Glasses",
    "authors": [
      "Antonio Auffinger",
      "Ahmed El Alaoui",
      "Mark Sellke"
    ],
    "abstract": "We show that in mean-field spin glasses, a discontinuous breaking of replica\nsymmetry at the critical inverse temperature $\\beta_c$ implies the existence of\nan intermediate shattered phase. This confirms a prediction from physics\nregarding the nature of random first order phase transitions. On the other\nhand, we give an example of a spherical spin glass which exhibits shattering,\nyet the transition is continuous at $\\beta_c$.",
    "pdf_url": "http://arxiv.org/pdf/2506.02238v1",
    "published": "2025-06-02T20:29:51+00:00",
    "categories": [
      "math.PR",
      "cond-mat.dis-nn",
      "math-ph",
      "math.MP"
    ],
    "primary_category": "math.PR"
  },
  {
    "id": "http://arxiv.org/abs/2506.02237v1",
    "title": "Atomic-scale mapping of interfacial phonon modes in epitaxial YBa2Cu3O7-δ / (La,Sr)(Al,Ta)O3 thin films: The role of surface phonons",
    "authors": [
      "Joaquin E. Reyes Gonzalez",
      "Charles Zhang",
      "Rainni K. Chen",
      "John Y. T. Wei",
      "Maureen J. Lagos"
    ],
    "abstract": "We investigate the behavior of phonons at the epitaxial interface between\nYBa2Cu3O7-{\\delta} thin film and (La,Sr)(Al,Ta)O3 substrate using vibrational\nelectron energy loss spectroscopy. Interfacial phonon modes with different\ndegrees of scattering localization were identified. We find evidence that\nsurface contributions from the surrounding environment can impose additional\nscattering modulation into local EELS measurements at the interface. A method\nto remove those contributions is then used to isolate the phonon information at\nthe interface. This work unveils interfacial phonon modes in a high-Tc cuprate\nsuperconductor, that are not accessible with traditional phonon spectroscopy\ntechniques, and provides a method for probing interfacial phonons in complex\noxide heterostructures.",
    "pdf_url": "http://arxiv.org/pdf/2506.02237v1",
    "published": "2025-06-02T20:28:49+00:00",
    "categories": [
      "cond-mat.supr-con",
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.supr-con"
  },
  {
    "id": "http://arxiv.org/abs/2506.02236v1",
    "title": "Immunometabolism at the Crossroads of Infection: Mechanistic and Systems-Level Perspectives from Host and Pathogen",
    "authors": [
      "Sunayana Malla",
      "Nabia Shahreen",
      "Rajib Saha"
    ],
    "abstract": "The emerging field of immunometabolism has underscored the central role of\nmetabolic pathways in orchestrating immune cell function. Far from being\npassive background processes, metabolic activities actively regulate key immune\nresponses. Fundamental pathways such as glycolysis, the tricarboxylic acid\n(TCA) cycle, and oxidative phosphorylation critically shape the behavior of\nimmune cells, influencing macrophage polarization, T cell activation, and\ndendritic cell function. In this review, we synthesize recent advances in\nimmunometabolism, with a focus on the metabolic mechanisms that govern the\nresponses of both innate and adaptive immune cells to bacterial, viral, and\nfungal pathogens. Drawing on experimental, computational, and integrative\nmethodologies, we highlight how metabolic reprogramming contributes to host\ndefense in response to infection. These findings reveal new opportunities for\ntherapeutic intervention, suggesting that modulation of metabolic pathways\ncould enhance immune function and improve pathogen clearance.",
    "pdf_url": "http://arxiv.org/pdf/2506.02236v1",
    "published": "2025-06-02T20:28:15+00:00",
    "categories": [
      "q-bio.CB"
    ],
    "primary_category": "q-bio.CB"
  },
  {
    "id": "http://arxiv.org/abs/2506.02235v1",
    "title": "A Bayesian PINN Framework for Barrow-Tsallis Holographic Dark Energy with Neutrinos: Toward a Resolution of the Hubble Tension",
    "authors": [
      "Muhammad Yarahmadi",
      "Amin Salehi"
    ],
    "abstract": "We investigate the Barrow-Tsallis Holographic Dark Energy (BTHDE) model using\nboth traditional Markov Chain Monte Carlo (MCMC) methods and a Bayesian\nPhysics-Informed Neural Network (PINN) framework, employing a range of\ncosmological observations. Our analysis incorporates data from Cosmic Microwave\nBackground (CMB), Baryon Acoustic Oscillations (BAO), CMB lensing, Cosmic\nChronometers (CC), and the Pantheon+ Type Ia supernova compilation. We focus on\nconstraining the Hubble constant $ H_0 $, the nonextensive entropy index $ q $,\nthe Barrow exponent $ \\Delta $, and the Granda-Oliveros parameters $ \\alpha $\nand $ \\beta $, along with the total neutrino mass $ \\Sigma m_\\nu $. The\nBayesian PINN approach yields more precise constraints than MCMC, particularly\nfor $ \\beta $, and tighter upper bounds on $ \\Sigma m_\\nu $. The inferred\nvalues of $ H_0 $ from both methods lie between those from Planck 2018 and\nSH$_0$ES (R22), alleviating the Hubble tension to within $ 1.3\\sigma\n$-$2.1\\sigma $ depending on the dataset combination. Notably, the Bayesian PINN\nachieves consistent results across CC and Pantheon+ datasets, while maintaining\nphysical consistency via embedded differential constraints. The combination of\nCMB and late-time probes leads to the most stringent constraints, with $ \\Sigma\nm_\\nu < 0.114 $ eV and $ H_0 = 70.6 \\pm 1.35 $ km/s/Mpc. These findings suggest\nthat the BTHDE model provides a viable framework for addressing cosmological\ntensions and probing modified entropy scenarios, while highlighting the\ncomplementary strengths of machine learning and traditional Bayesian inference\nin cosmological modeling.",
    "pdf_url": "http://arxiv.org/pdf/2506.02235v1",
    "published": "2025-06-02T20:28:10+00:00",
    "categories": [
      "astro-ph.CO",
      "gr-qc"
    ],
    "primary_category": "astro-ph.CO"
  },
  {
    "id": "http://arxiv.org/abs/2506.02234v1",
    "title": "Second-Order-Cone Formulations of Power Flow for Topology Optimization",
    "authors": [
      "Noah Rhodes",
      "James Luedkte",
      "Line Roald"
    ],
    "abstract": "Optimization problems that involve topology optimization in scenarios with\nlarge scale outages, such as post-disaster restoration or public safety power\nshutoff planning, are very challenging to solve. Using simple power flow\nrepresentations such as DC power flow or network flow models results in low\nquality solutions which requires significantly higher-than-predicted load shed\nto become AC feasible. Recent work has shown that formulations based on the\nSecond Order Cone (SOC) power flow formulation find very high quality solutions\nwith low load shed, but the computational burden of these formulations remains\na significant challenge. With the aim of reducing computational time while\nmaintaining high solution quality, this work explores formulations which\nreplace the conic constraints with a small number of linear cuts. The goal of\nthis approach is not to find an exact power flow solution, but rather to\nidentify good binary decisions, where the power flow can be resolved after the\nbinary variables are fixed. We find that a simple reformulation of the Second\nOrder Cone Optimal Power Shutoff problem can greatly improve the solution\nspeed, but that a full linearization of the SOC voltage cone equation results\nin an overestimation of the amount of power that can be delivered to loads.",
    "pdf_url": "http://arxiv.org/pdf/2506.02234v1",
    "published": "2025-06-02T20:27:04+00:00",
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2506.02233v1",
    "title": "Improving compiler support for SIMD offload using Arm Streaming SVE",
    "authors": [
      "Mohamed Husain Noor Mohamed",
      "Adarsh Patil",
      "Latchesar Ionkov",
      "Eric Van Hensbergen"
    ],
    "abstract": "The wider adoption of tightly coupled core-adjacent accelerators, such as Arm\nScalable Matrix Extension (SME), hinges on lowering software programming\ncomplexity. In this paper, we focus on enabling the use of SME architecture in\nStreaming Scalable Vector Extension (SSVE) mode for workloads written in C/C++.\nWhile current compilers optimize loops for all types of SIMD instructions,\nthese techniques primarily target vector units within the core and falter when\napplied to disaggregated, core-adjacent SIMD accelerators. Our goal is to\nenable the compiler to automatically generate code for such accelerators only\nwhen profitable.\n  To this end, we investigate a path towards performant, precise, and\nrepeatable computation offloading through two compiler ecosystems. We revisit\nLLVM compiler passes, MLIR transforms and their associated cost models, and\nheuristics. We hope that these insights can provide directions for evolving\ncompiler capabilities towards automatic code generation for this\nnext-generation vector processing paradigm.",
    "pdf_url": "http://arxiv.org/pdf/2506.02233v1",
    "published": "2025-06-02T20:24:32+00:00",
    "categories": [
      "cs.PL"
    ],
    "primary_category": "cs.PL"
  },
  {
    "id": "http://arxiv.org/abs/2506.02232v1",
    "title": "Investigating the Reasonable Effectiveness of Speaker Pre-Trained Models and their Synergistic Power for SingMOS Prediction",
    "authors": [
      "Orchid Chetia Phukan",
      "Girish",
      "Mohd Mujtaba Akhtar",
      "Swarup Ranjan Behera",
      "Pailla Balakrishna Reddy",
      "Arun Balaji Buduru",
      "Rajesh Sharma"
    ],
    "abstract": "In this study, we focus on Singing Voice Mean Opinion Score (SingMOS)\nprediction. Previous research have shown the performance benefit with the use\nof state-of-the-art (SOTA) pre-trained models (PTMs). However, they haven't\nexplored speaker recognition speech PTMs (SPTMs) such as x-vector, ECAPA and we\nhypothesize that it will be the most effective for SingMOS prediction. We\nbelieve that due to their speaker recognition pre-training, it equips them to\ncapture fine-grained vocal features (e.g., pitch, tone, intensity) from\nsynthesized singing voices in a much more better way than other PTMs. Our\nexperiments with SOTA PTMs including SPTMs and music PTMs validates the\nhypothesis. Additionally, we introduce a novel fusion framework, BATCH that\nuses Bhattacharya Distance for fusion of PTMs. Through BATCH with the fusion of\nspeaker recognition SPTMs, we report the topmost performance comparison to all\nthe individual PTMs and baseline fusion techniques as well as setting SOTA.",
    "pdf_url": "http://arxiv.org/pdf/2506.02232v1",
    "published": "2025-06-02T20:22:59+00:00",
    "categories": [
      "eess.AS",
      "cs.SD"
    ],
    "primary_category": "eess.AS"
  },
  {
    "id": "http://arxiv.org/abs/2506.02231v1",
    "title": "Coherent electrically-charged quantum black holes",
    "authors": [
      "Tommaso Antonelli",
      "Marco Sebastianutti",
      "Andrea Giusti"
    ],
    "abstract": "We improve upon the results presented in [R. Casadio, et al., Phys. Rev. D\n105 (2022) 124026] deriving a quantum-corrected Reissner-Nordstr\\\"om geometry\ncontaining an integrable singularity at its center while being devoid of\nspurious oscillations around the classical configuration. We further\ninvestigate some relevant physical observables, related to geodesics and\nquasinormal modes of scalar perturbations, associated with this geometry to\ncomplement our theoretical analysis.",
    "pdf_url": "http://arxiv.org/pdf/2506.02231v1",
    "published": "2025-06-02T20:16:57+00:00",
    "categories": [
      "gr-qc",
      "83C45, 83C57, 83C75"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2506.04260v2",
    "title": "Turning to Online Forums for Legal Information: A Case Study of GDPR's Legitimate Interests",
    "authors": [
      "Lin Kyi",
      "Cristiana Santos",
      "Sushil Ammanaghatta Shivakumar",
      "Franziska Roesner",
      "Asia Biega"
    ],
    "abstract": "Practitioners building online services and tools often turn to online forums\nsuch as Reddit, Law Stack Exchange, and Stack Overflow for legal guidance to\nensure compliance with the GDPR. The legal information presented in these\nforums directly impacts present-day industry practitioner's decisions. Online\nforums can serve as gateways that, depending on the accuracy and quality of the\nanswers provided, may either support or undermine the protection of privacy and\ndata protection fundamental rights. However, there is a need for deeper\ninvestigation into practitioners' decision-making processes and their\nunderstanding of legal compliance when seeking for legal information online.\n  Using GDPR's ``legitimate interests'' legal ground for processing personal\ndata as a case study, we investigate how practitioners use online forums to\nidentify common areas of confusion in applying legitimate interests in\npractice, and evaluate how legally sound online forum responses are.\n  Our analysis found that applying the legal basis of legitimate interest is\ncomplex for practitioners, with important implications for how the GDPR is\nimplemented in practice. The legal analysis showed that crowdsourced legal\ninformation tends to be legally sound, though sometimes incomplete. We outline\nrecommendations to improve the quality of online forums by ensuring that\nresponses are more legally sound and comprehensive, enabling practitioners to\napply legitimate interests effectively in practice and uphold the GDPR.",
    "pdf_url": "http://arxiv.org/pdf/2506.04260v2",
    "published": "2025-06-02T20:16:01+00:00",
    "categories": [
      "cs.CY",
      "cs.HC"
    ],
    "primary_category": "cs.CY"
  },
  {
    "id": "http://arxiv.org/abs/2506.02230v1",
    "title": "Towards Machine Unlearning for Paralinguistic Speech Processing",
    "authors": [
      "Orchid Chetia Phukan",
      "Girish",
      "Mohd Mujtaba Akhtar",
      "Shubham Singh",
      "Swarup Ranjan Behera",
      "Vandana Rajan",
      "Muskaan Singh",
      "Arun Balaji Buduru",
      "Rajesh Sharma"
    ],
    "abstract": "In this work, we pioneer the study of Machine Unlearning (MU) for\nParalinguistic Speech Processing (PSP). We focus on two key PSP tasks: Speech\nEmotion Recognition (SER) and Depression Detection (DD). To this end, we\npropose, SISA++, a novel extension to previous state-of-the-art (SOTA) MU\nmethod, SISA by merging models trained on different shards with\nweight-averaging. With such modifications, we show that SISA++ preserves\nperformance more in comparison to SISA after unlearning in benchmark SER\n(CREMA-D) and DD (E-DAIC) datasets. Also, to guide future research for easier\nadoption of MU for PSP, we present ``cookbook recipes'' - actionable\nrecommendations for selecting optimal feature representations and downstream\narchitectures that can mitigate performance degradation after the unlearning\nprocess.",
    "pdf_url": "http://arxiv.org/pdf/2506.02230v1",
    "published": "2025-06-02T20:14:22+00:00",
    "categories": [
      "eess.AS",
      "cs.SD"
    ],
    "primary_category": "eess.AS"
  },
  {
    "id": "http://arxiv.org/abs/2506.02229v1",
    "title": "VLCD: Vision-Language Contrastive Distillation for Accurate and Efficient Automatic Placenta Analysis",
    "authors": [
      "Manas Mehta",
      "Yimu Pan",
      "Kelly Gallagher",
      "Alison D. Gernand",
      "Jeffery A. Goldstein",
      "Delia Mwinyelle",
      "Leena Mithal",
      "James Z. Wang"
    ],
    "abstract": "Pathological examination of the placenta is an effective method for detecting\nand mitigating health risks associated with childbirth. Recent advancements in\nAI have enabled the use of photographs of the placenta and pathology reports\nfor detecting and classifying signs of childbirth-related pathologies. However,\nexisting automated methods are computationally extensive, which limits their\ndeployability. We propose two modifications to vision-language contrastive\nlearning (VLC) frameworks to enhance their accuracy and efficiency: (1)\ntext-anchored vision-language contrastive knowledge distillation (VLCD)-a new\nknowledge distillation strategy for medical VLC pretraining, and (2)\nunsupervised predistillation using a large natural images dataset for improved\ninitialization. Our approach distills efficient neural networks that match or\nsurpass the teacher model in performance while achieving model compression and\nacceleration. Our results showcase the value of unsupervised predistillation in\nimproving the performance and robustness of our approach, specifically for\nlower-quality images. VLCD serves as an effective way to improve the efficiency\nand deployability of medical VLC approaches, making AI-based healthcare\nsolutions more accessible, especially in resource-constrained environments.",
    "pdf_url": "http://arxiv.org/pdf/2506.02229v1",
    "published": "2025-06-02T20:12:27+00:00",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.02228v1",
    "title": "On $θ$-extension of continuous mapping",
    "authors": [
      "Andrew Ryabikov"
    ],
    "abstract": "We consider the problem of constructing a weakly-continuous mapping extending\ncontinuous mapping defined on a dense set of a topological space to the entire\nspace. Theorem on necessary and sufficient conditions for the existence of such\nan extension are proved. The axioms of separation and compactness of spaces are\nnot assumed.",
    "pdf_url": "http://arxiv.org/pdf/2506.02228v1",
    "published": "2025-06-02T20:11:21+00:00",
    "categories": [
      "math.GN"
    ],
    "primary_category": "math.GN"
  },
  {
    "id": "http://arxiv.org/abs/2506.02227v1",
    "title": "Can the Infamous Boundary Be Found in Macromolecules? Also, von Neumann vs. Schroedinger ensembles, and `Hund's Paradox' in quantum chemistry",
    "authors": [
      "W. David Wick"
    ],
    "abstract": "John Bell coined the phrase ``Infamous Boundary\" for the point where\nclassical physics splits off from quantum physics. Many authors, including the\npresent one, have advanced theories with the intention of defining and locating\nthis ``shifty split\"; most propose that it lies somewhere on the scale of\napparatus. But what if it resides at the level of macromolecules? I show here\nthat this question is intimately connected to the choice of thermal ensembles\nand to the so-called `Hund's Paradox' in quantum chemistry. I propose an\nexperimental set-up that could in principle reveal the IB lurking in asymmetric\nmacromolecules.",
    "pdf_url": "http://arxiv.org/pdf/2506.02227v1",
    "published": "2025-06-02T20:11:14+00:00",
    "categories": [
      "quant-ph",
      "physics.chem-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.02226v1",
    "title": "Prepare-and-Magic: Semi-Device Independent Magic Certification in the Prepare-and-Measure Scenario",
    "authors": [
      "Santiago Zamora",
      "Rafael A. Macedo",
      "Tailan S. Sarubi",
      "Moisés Alves",
      "Davide Poderini",
      "Rafael Chaves"
    ],
    "abstract": "Non-stabilizerness is an essential resource for quantum computational\nadvantage, as stabilizer states admit efficient classical simulation. We\ndevelop a semi-device-independent framework for certifying non-stabilizer\nstates in prepare-and-measure (PAM) scenarios, relying only on assumptions\nabout the system's dimension. Within this framework, we introduce dimensional\nwitnesses that can distinguish stabilizer from non-stabilizer states, and we\nprovide analytical proofs that threshold violations of these witnesses certify\nnon-stabilizerness. In the simplest setting-three preparations, two\nmeasurements, and qubit systems-surpassing a specific threshold guarantees that\nat least one prepared state lies outside the stabilizer polytope. We extend\nthis approach by linking it to quantum random access codes, also generalizing\nour results to qutrit systems and introducing a necessary condition for\ncertifying non-stabilizerness based on state overlaps (Gram matrices). These\nresults offer a set of semi-device-independent tools for practically and\nsystematically verifying non-stabilizer states using dimensional witnesses in\nPAM scenarios.",
    "pdf_url": "http://arxiv.org/pdf/2506.02226v1",
    "published": "2025-06-02T20:11:10+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.02225v1",
    "title": "Human-in-the-loop: Real-time Preference Optimization",
    "authors": [
      "Wenbin Wang",
      "Wenjie Xu",
      "Colin N. Jones"
    ],
    "abstract": "Human-aware controllers play an important role in engineering systems for\nimproving productivity, efficiency, and sustainability. It is essential to\ndesign such a controller that optimizes user utility while adhering to plant\ndynamics. While most online optimization algorithms rely on first-order or\nzeroth-order oracles, human feedback often appears as pairwise comparisons. In\nthis work, we propose an online feedback optimization algorithm that leverages\nsuch preference feedback. We design a controller that estimates the gradient\nbased on the binary pairwise comparison result between two consecutive points\nand study its coupled behavior with a nonlinear plant. Under mild assumptions\non both the utility and the plant dynamics, we establish explicit stability\ncriteria and quantify sub-optimality. The theoretical findings are further\nsupported through numerical experiments.",
    "pdf_url": "http://arxiv.org/pdf/2506.02225v1",
    "published": "2025-06-02T20:07:39+00:00",
    "categories": [
      "math.OC"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2506.02223v1",
    "title": "Investigating the inclusive $D^0$ photoproduction in ultraperipheral $PbPb$ collisions at the Large Hadron Collider",
    "authors": [
      "Victor P. Goncalves",
      "Luana Santana",
      "Wolfgang Schäfer"
    ],
    "abstract": "The inclusive $D^0$ photoproduction in $PbPb$ collisions at the center - of -\nmass energies of the Large Hadron Collider (LHC) is investigated considering\nthe color dipole $S$ - matrix approach. The analytical expressions for the\ndifferential distributions are derived in the impact parameter and transverse\nmomentum spaces and predictions for the rapidity and transverse momentum\ndistributions are presented considering three distinct models for the\nunintegrated gluon distribution of the nuclear target. In particular, we\ncompare the predictions derived assuming a linear dynamics, with and without\nthe inclusion of nuclear effects, with those obtained by solving the running\ncoupling Balitsky - Kovchegov equation. A comparison of these predictions with\nthe recent (preliminary) CMS data is also performed. Our results indicate that\na detailed analysis of this observable will be very useful to improve our\nunderstanding of the strong interaction theory at high energies and in a\nnuclear medium.",
    "pdf_url": "http://arxiv.org/pdf/2506.02223v1",
    "published": "2025-06-02T20:06:35+00:00",
    "categories": [
      "hep-ph",
      "hep-ex",
      "nucl-ex",
      "nucl-th"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.02224v1",
    "title": "Long-Term Optical Follow Up of S231206cc: Multi-Model Constraints on BBH Merger Emission in AGN Disks",
    "authors": [
      "P. Darc",
      "C. R. Bom",
      "C. D. Kilpatrick",
      "A. Souza Santos",
      "B. Fraga",
      "J. C. Rodríguez-Ramírez",
      "D. A. Coulter",
      "C. Mendes de Oliveira",
      "A. Kanaan",
      "T. Ribeiro",
      "W. Schoenell",
      "E. A. D. Lacerda"
    ],
    "abstract": "The majority of gravitational wave events detected by the LIGO, Virgo, and\nKAGRA Collaboration originate from binary black hole (BBH) mergers, for which\nno confirmed electromagnetic counterparts have been identified to date.\nHowever, if such mergers occur within the disk of an active galactic nucleus\n(AGN), they may generate observable optical flares induced by relativistic jet\nactivity and shock-heated gas. We present results from a long-term optical\nfollow-up of the gravitational wave event S231206cc, conducted with the\nT80-South telescope as part of the S-PLUS Transient Extension Program (STEP).\nOur search prioritized AGN-hosted environments by crossmatching the\ngravitational wave localization with known AGN catalogs. No candidate met the\ncriteria for a viable optical counterpart. We explored three BBH merger\nscenarios predicting optical emission in AGN disks: (i) ram pressure stripping,\n(ii) long-term emission from an emerging jet cocoon, and (iii) jet breakout\nfollowed by shock cooling. Using our observational cadence and depth, we\nconstrained the BBH parameter space, including the remnant's location within\nthe AGN disk, kick velocity, and supermassive black hole (SMBH) mass.\nDetectable flares are most likely when mergers occur at 0.01-0.1 parsecs from\nSMBHs with masses between 10^7 and 10^8 solar masses, where short delay times\nand long durations best align with our follow-up strategy. These results\nprovide a framework for identifying AGN-hosted BBH counterparts and guiding\nfuture multimessenger efforts.",
    "pdf_url": "http://arxiv.org/pdf/2506.02224v1",
    "published": "2025-06-02T20:06:35+00:00",
    "categories": [
      "astro-ph.HE"
    ],
    "primary_category": "astro-ph.HE"
  },
  {
    "id": "http://arxiv.org/abs/2506.02222v1",
    "title": "Performance of multiple filter-cavity schemes for frequency-dependent squeezing in gravitational-wave detectors",
    "authors": [
      "Jacques Ding",
      "Eleonora Capocasa",
      "Isander Ahrend",
      "Fangfei Liu",
      "Yuhang Zhao",
      "Matteo Barsuglia"
    ],
    "abstract": "Gravitational-wave detectors use state-of-the-art quantum technologies to\ncircumvent vacuum fluctuations via squeezed states of light. Future detectors\nsuch as Einstein Telescope may require the use of two filter cavities or a\n3-mirror, coupled filter cavity to achieve a complex rotation of the squeezing\nellipse in order to reduce the quantum noise over the whole detector bandwidth.\nIn this work, we compare the theoretical feasibility and performances of these\ntwo systems and their resilience with respect to different degradation sources\n(optical losses, mismatching, locking precision). We provide both analytical\nmodels and numerical insights. We extend previous analysis on squeezing\ndegradation and find that the coupled cavity scheme provides similar or better\nperformances than the two-cavity option, in terms of resilience with respect to\nimperfections and optical losses. We propose a possible two-step implementation\nscheme for Einstein Telescope using a single filter cavity that can be possibly\nupgraded into a coupled filter cavity.",
    "pdf_url": "http://arxiv.org/pdf/2506.02222v1",
    "published": "2025-06-02T20:06:14+00:00",
    "categories": [
      "gr-qc",
      "astro-ph.IM",
      "physics.optics"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2506.02221v1",
    "title": "Diff2Flow: Training Flow Matching Models via Diffusion Model Alignment",
    "authors": [
      "Johannes Schusterbauer",
      "Ming Gui",
      "Frank Fundel",
      "Björn Ommer"
    ],
    "abstract": "Diffusion models have revolutionized generative tasks through high-fidelity\noutputs, yet flow matching (FM) offers faster inference and empirical\nperformance gains. However, current foundation FM models are computationally\nprohibitive for finetuning, while diffusion models like Stable Diffusion\nbenefit from efficient architectures and ecosystem support. This work addresses\nthe critical challenge of efficiently transferring knowledge from pre-trained\ndiffusion models to flow matching. We propose Diff2Flow, a novel framework that\nsystematically bridges diffusion and FM paradigms by rescaling timesteps,\naligning interpolants, and deriving FM-compatible velocity fields from\ndiffusion predictions. This alignment enables direct and efficient FM\nfinetuning of diffusion priors with no extra computation overhead. Our\nexperiments demonstrate that Diff2Flow outperforms na\\\"ive FM and diffusion\nfinetuning particularly under parameter-efficient constraints, while achieving\nsuperior or competitive performance across diverse downstream tasks compared to\nstate-of-the-art methods. We will release our code at\nhttps://github.com/CompVis/diff2flow.",
    "pdf_url": "http://arxiv.org/pdf/2506.02221v1",
    "published": "2025-06-02T20:05:05+00:00",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.02220v1",
    "title": "On a spherically lifted spin model at finite temperature",
    "authors": [
      "Xun Tang",
      "Yuehaw Khoo",
      "Lexing Ying"
    ],
    "abstract": "We investigate an \\(n\\)-vector model over \\(k\\) sites with generic pairwise\ninteractions and spherical constraints. The model is a lifting of the Ising\nmodel whereby the support of the spin is lifted to a hypersphere. We show that\nthe \\(n\\)-vector model converges to a limiting distribution at a rate of\n\\(n^{-1/2 + o(1)}\\). We show that the limiting distribution for \\(n \\to\n\\infty\\) is determined by the solution of an equality-constrained maximization\ntask over positive definite matrices. We prove that the obtained maximal value\nand maximizer, respectively, give rise to the free energy and correlation\nfunction of the limiting distribution. In the finite temperature regime, the\nmaximization task is a log-determinant regularization of the semidefinite\nprogram (SDP) in the Goemans-Williamson algorithm. Moreover, the inverse\ntemperature determines the regularization strength, with the zero temperature\nlimit converging to the SDP in Goemans-Williamson. Our derivation draws a\ncurious connection between the semidefinite relaxation of integer programming\nand the spherical lifting of sampling on a hypercube. To the authors' best\nknowledge, this work is the first to solve the setting of fixed \\(k\\) and\ninfinite \\(n\\) under unstructured pairwise interactions.",
    "pdf_url": "http://arxiv.org/pdf/2506.02220v1",
    "published": "2025-06-02T20:02:49+00:00",
    "categories": [
      "math.PR",
      "cs.NA",
      "math.NA"
    ],
    "primary_category": "math.PR"
  },
  {
    "id": "http://arxiv.org/abs/2506.02219v1",
    "title": "Stochastic Barnes-Hut Approximation for Fast Summation on the GPU",
    "authors": [
      "Abhishek Madan",
      "Nicholas Sharp",
      "Francis Williams",
      "Ken Museth",
      "David I. W. Levin"
    ],
    "abstract": "We present a novel stochastic version of the Barnes-Hut approximation.\nRegarding the level-of-detail (LOD) family of approximations as control\nvariates, we construct an unbiased estimator of the kernel sum being\napproximated. Through several examples in graphics applications such as winding\nnumber computation and smooth distance evaluation, we demonstrate that our\nmethod is well-suited for GPU computation, capable of outperforming a\nGPU-optimized implementation of the deterministic Barnes-Hut approximation by\nachieving equal median error in up to 9.4x less time.",
    "pdf_url": "http://arxiv.org/pdf/2506.02219v1",
    "published": "2025-06-02T20:02:25+00:00",
    "categories": [
      "cs.GR"
    ],
    "primary_category": "cs.GR"
  },
  {
    "id": "http://arxiv.org/abs/2506.02218v1",
    "title": "First-Principles and Machine Learning Investigation of the Structural and Optoelectronic Properties of Dodecaphenylyne: A Novel Carbon Allotrope",
    "authors": [
      "Kleuton A. L. Lima",
      "Jose A. S. Laranjeira",
      "Nicolas F. Martins",
      "Julio R. Sambrano",
      "Alexandre C. Dias",
      "Luiz A. Ribeiro Junior",
      "Douglas S. Galvao"
    ],
    "abstract": "We report the computational discovery and characterization of Dodecaphenylyne\n(DP), a novel carbon allotrope with a distinctive geometric arrangement. DP\nstructural, thermodynamic, mechanical, electronic, and optical properties were\nevaluated using density functional theory and a machine learning interatomic\npotential trained explicitly for this material. The formation energy of -7.98\neV/atom indicates high thermodynamic stability, further supported by the\nabsence of imaginary phonon modes and the preservation of structural integrity\nup to 1000 K in ab initio molecular dynamics simulations. Mechanical analysis\nreveals high in-plane stiffness with directional dependence: Young's modulus\nvalues of 469.09 GPa and 600.41 GPa along the x and y directions, respectively.\nElectronic band structure and projected density of states analyses confirm the\nDP semiconducting character. Calculations of carrier mobility using the\ndeformation potential theory reveal pronounced anisotropy, with maximum values\nreaching up to $30.6 \\times 10^4$ cm$^2$/V$\\cdot$s (electrons, e) and $8.4\n\\times 10^4$ cm$^2$/V$\\cdot$s (holes, h), much higher than the observed for\nother 2D materials. DP also exhibits anisotropic optical absorption in the\nvisible and ultraviolet spectrum, highlighting its potential for optoelectronic\napplications.",
    "pdf_url": "http://arxiv.org/pdf/2506.02218v1",
    "published": "2025-06-02T20:01:28+00:00",
    "categories": [
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2506.02217v1",
    "title": "Analyzing Contact Patterns in Public Transportation Systems for Opportunistic Communication Services",
    "authors": [
      "Eduardo R. Manika",
      "Emilio C. G. Wille",
      "Joilson Alves Jr"
    ],
    "abstract": "Vehicle mobility has a significant impact on wireless communication between\nvehicles (buses) in Public Transportation Systems (PTS). Nevertheless, the\ntransportation literature does not provide satisfactory models for bus\nmovements because they are influenced by a variety of factors (itineraries,\ntimetables, etc.). Custom-made mobility models that take these issues into\naccount require a great deal of effort and may render simulations unfeasible.\nThis article considers a tool (EMMS) that automatically inserts PTS information\ninto a mobility simulator in order to undertake a complete statistical analysis\nof vehicular density, trip duration, and vehicle-to-vehicle interaction. In\nlight of opportunistic communication services, this analysis is of the utmost\nimportance.",
    "pdf_url": "http://arxiv.org/pdf/2506.02217v1",
    "published": "2025-06-02T20:00:31+00:00",
    "categories": [
      "cs.NI"
    ],
    "primary_category": "cs.NI"
  },
  {
    "id": "http://arxiv.org/abs/2506.02216v1",
    "title": "Mathematics A Missing Factor in Assessing the Antiquity of Vedanga Jyotisa",
    "authors": [
      "Jaidev Dasgupta"
    ],
    "abstract": "While reading ancient texts one has to be cognizant of the assumptions made\nabout the past. One has to ask: Are these assumptions valid? Are we projecting\nthe present views into the past? A case in point is the dating of Vedanga\nJyotisa. This note reports that due to mathematics being overlooked in the\nvarious attempts of assessing the time of composition of the text, the latter\nwas dated much before the period when its mathematics was actually feasible.",
    "pdf_url": "http://arxiv.org/pdf/2506.02216v1",
    "published": "2025-06-02T19:58:31+00:00",
    "categories": [
      "math.HO"
    ],
    "primary_category": "math.HO"
  },
  {
    "id": "http://arxiv.org/abs/2506.02215v4",
    "title": "Active inference as a unified model of collision avoidance behavior in human drivers",
    "authors": [
      "Julian F. Schumann",
      "Johan Engström",
      "Leif Johnson",
      "Matthew O'Kelly",
      "Joao Messias",
      "Jens Kober",
      "Arkady Zgonnikov"
    ],
    "abstract": "Collision avoidance -- involving a rapid threat detection and quick execution\nof the appropriate evasive maneuver -- is a critical aspect of driving.\nHowever, existing models of human collision avoidance behavior are fragmented,\nfocusing on specific scenarios or only describing certain aspects of the\navoidance behavior, such as response times. This paper addresses these gaps by\nproposing a novel computational cognitive model of human collision avoidance\nbehavior based on active inference. Active inference provides a unified\napproach to modeling human behavior: the minimization of free energy. Building\non prior active inference work, our model incorporates established cognitive\nmechanisms such as evidence accumulation to simulate human responses in two\ndistinct collision avoidance scenarios: front-to-rear lead vehicle braking and\nlateral incursion by an oncoming vehicle. We demonstrate that our model\nexplains a wide range of previous empirical findings on human collision\navoidance behavior. Specifically, the model closely reproduces both aggregate\nresults from meta-analyses previously reported in the literature and detailed,\nscenario-specific effects observed in a recent driving simulator study,\nincluding response timing, maneuver selection, and execution. Our results\nhighlight the potential of active inference as a unified framework for\nunderstanding and modeling human behavior in complex real-life driving tasks.",
    "pdf_url": "http://arxiv.org/pdf/2506.02215v4",
    "published": "2025-06-02T19:55:34+00:00",
    "categories": [
      "cs.RO",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2506.02214v1",
    "title": "Is PMBOK Guide the Right Fit for AI? Re-evaluating Project Management in the Face of Artificial Intelligence Projects",
    "authors": [
      "Alexey Burdakov",
      "Max Jaihyun Ahn"
    ],
    "abstract": "This paper critically evaluates the applicability of the Project Management\nBody of Knowledge (PMBOK) Guide framework to Artificial Intelligence (AI)\nsoftware projects, highlighting key limitations and proposing tailored\nadaptations. Unlike traditional projects, AI initiatives rely heavily on\ncomplex data, iterative experimentation, and specialized expertise while\nnavigating significant ethical considerations. Our analysis identifies gaps in\nthe PMBOK Guide, including its limited focus on data management, insufficient\nsupport for iterative development, and lack of guidance on ethical and\nmultidisciplinary challenges. To address these deficiencies, we recommend\nintegrating data lifecycle management, adopting iterative and AI project\nmanagement frameworks, and embedding ethical considerations within project\nplanning and execution. Additionally, we explore alternative approaches that\nbetter align with AI's dynamic and exploratory nature. We aim to enhance\nproject management practices for AI software projects by bridging these gaps.",
    "pdf_url": "http://arxiv.org/pdf/2506.02214v1",
    "published": "2025-06-02T19:54:54+00:00",
    "categories": [
      "cs.SE",
      "cs.CV",
      "D.2.9; I.4"
    ],
    "primary_category": "cs.SE"
  },
  {
    "id": "http://arxiv.org/abs/2506.02213v1",
    "title": "Quantum Ensembling Methods for Healthcare and Life Science",
    "authors": [
      "Kahn Rhrissorrakrai",
      "Kathleen E. Hamilton",
      "Prerana Bangalore Parthsarathy",
      "Aldo Guzman-Saenz",
      "Tyler Alban",
      "Filippo Utro",
      "Laxmi Parida"
    ],
    "abstract": "Learning on small data is a challenge frequently encountered in many\nreal-world applications. In this work we study how effective quantum ensemble\nmodels are when trained on small data problems in healthcare and life sciences.\nWe constructed multiple types of quantum ensembles for binary classification\nusing up to 26 qubits in simulation and 56 qubits on quantum hardware. Our\nensemble designs use minimal trainable parameters but require long-range\nconnections between qubits. We tested these quantum ensembles on synthetic\ndatasets and gene expression data from renal cell carcinoma patients with the\ntask of predicting patient response to immunotherapy. From the performance\nobserved in simulation and initial hardware experiments, we demonstrate how\nquantum embedding structure affects performance and discuss how to extract\ninformative features and build models that can learn and generalize\neffectively. We present these exploratory results in order to assist other\nresearchers in the design of effective learning on small data using ensembles.\nIncorporating quantum computing in these data constrained problems offers hope\nfor a wide range of studies in healthcare and life sciences where biological\nsamples are relatively scarce given the feature space to be explored.",
    "pdf_url": "http://arxiv.org/pdf/2506.02213v1",
    "published": "2025-06-02T19:54:51+00:00",
    "categories": [
      "cs.LG",
      "q-bio.GN",
      "q-bio.QM"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.02212v1",
    "title": "Leveraging Natural Language Processing to Unravel the Mystery of Life: A Review of NLP Approaches in Genomics, Transcriptomics, and Proteomics",
    "authors": [
      "Ella Rannon",
      "David Burstein"
    ],
    "abstract": "Natural Language Processing (NLP) has transformed various fields beyond\nlinguistics by applying techniques originally developed for human language to\nthe analysis of biological sequences. This review explores the application of\nNLP methods to biological sequence data, focusing on genomics, transcriptomics,\nand proteomics. We examine how various NLP methods, from classic approaches\nlike word2vec to advanced models employing transformers and hyena operators,\nare being adapted to analyze DNA, RNA, protein sequences, and entire genomes.\nThe review also examines tokenization strategies and model architectures,\nevaluating their strengths, limitations, and suitability for different\nbiological tasks. We further cover recent advances in NLP applications for\nbiological data, such as structure prediction, gene expression, and\nevolutionary analysis, highlighting the potential of these methods for\nextracting meaningful insights from large-scale genomic data. As language\nmodels continue to advance, their integration into bioinformatics holds immense\npromise for advancing our understanding of biological processes in all domains\nof life.",
    "pdf_url": "http://arxiv.org/pdf/2506.02212v1",
    "published": "2025-06-02T19:54:03+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "q-bio.GN"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.02211v1",
    "title": "Improving LLM-Generated Code Quality with GRPO",
    "authors": [
      "Maxime Robeyns",
      "Laurence Aitchison"
    ],
    "abstract": "Large Language Models (LLMs) are gaining widespread use for code generation.\nRecent training procedures use execution feedback as a reward signal, typically\nfocusing on the functional correctness of the code, using unit test pass rate\nas a reward signal. However, this reward signal fails to capture notions of\nmaintainability, quality and safety of the code produced. We address this\nunder-explored area and develop a comprehensive library to quantify various\naspects of code quality, and use it as a reward in GRPO. We find GRPO increases\ncode quality according to this measure, which is confirmed by expert, blinded\nhuman annotators.",
    "pdf_url": "http://arxiv.org/pdf/2506.02211v1",
    "published": "2025-06-02T19:50:16+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2506.02210v1",
    "title": "Exchangeability in Neural Network Architectures and its Application to Dynamic Pruning",
    "authors": [
      "Pu",
      "Yi",
      "Tianlang Chen",
      "Yifan Yang",
      "Sara Achour"
    ],
    "abstract": "Neural networks (NNs) are equipped with increasingly many parameters and\nrequire more and more resource for deployment. Researchers have explored\nvarious ways to improve the efficiency of NNs by identifying and reducing the\nredundancy, such as pruning or quantizing unimportant weights. Symmetry in the\nNN architectures has been identified by prior work as a possible type of\nredundancy, but exploiting it for efficient inference is not yet explored. In\nthis work, we formalize the symmetry of parameters and intermediate values in\nNNs using the statistical property of exchangeablility. We identify that\nexchangeable values in NN computation may contain overlapping information,\nleading to redundancy. Exploiting the insight, we derive a principled general\ndynamic pruning algorithm ExPrune to remove symmetry-induced redundancy on a\nper-input basis. We also provide an instantiation of ExPrune that performs\nneuron-level dynamic pruning by predicting negative inputs to ReLU activations.\nWe evaluate ExPrune on two computer vision models, one graph model and one\nlanguage model. ExPrune provides 10.98--26.3% reduction in FLOPs with\nnegligible accuracy drop and 21.01--39.05% reduction in FLOPs with at most 1%\naccuracy drop. We also demonstrate that ExPrune composes with static pruning.\nOn models that have been aggressively pruned statically, ExPrune provides\nadditional 10.24--11.11% reduction in FLOPs with negligible accuracy drop and\n13.91--14.39% reduction in FLOPs with at most 1% accuracy drop.",
    "pdf_url": "http://arxiv.org/pdf/2506.02210v1",
    "published": "2025-06-02T19:50:15+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.PF"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.02209v1",
    "title": "Discovery of the Type-II Superconductor Ta$_4$Rh$_2$C$_{1-δ}$ with a High Upper Critical Field",
    "authors": [
      "KeYuan Ma",
      "Sara López-Paz",
      "Karolina Gornicka",
      "Harald O. Jeschke",
      "Tomasz Klimczuk",
      "Fabian O. von Rohr"
    ],
    "abstract": "We report on the discovery of superconductivity in the previously unknown\ncompound Ta$_4$Rh$_2$C$_{1-\\delta}$. Ta$_4$Rh$_2$C$_{1-\\delta}$ crystallizes in\nthe $\\eta$-carbide structure type, in the cubic space group $Fd\\bar{3}m$\n(No.227) with a unit cell parameter of $a = $ 11.7947 \\AA.\nTemperature-dependent magnetic susceptibility, resistivity, and specific heat\ncapacity measurements reveal that Ta$_4$Rh$_2$C$_{1-\\delta}$ is a type-II bulk\nsuperconductor with a critical temperature of $T_{\\rm c}$ = 6.4 K, and a\nnormalized specific heat jump $\\Delta C/\\gamma T_{\\rm c}$ = 1.56. Notably, we\nfind Ta$_4$Rh$_2$C$_{1-\\delta}$ has a high upper critical field of $\\mu_0\nH_{\\rm c2}{\\rm (0)}$ = 17.4 T, which is exceeding the BCS weak coupling Pauli\nlimit of $\\mu_0 H_{\\rm Pauli}$ = 11.9 T.",
    "pdf_url": "http://arxiv.org/pdf/2506.02209v1",
    "published": "2025-06-02T19:48:54+00:00",
    "categories": [
      "cond-mat.supr-con"
    ],
    "primary_category": "cond-mat.supr-con"
  },
  {
    "id": "http://arxiv.org/abs/2506.02208v1",
    "title": "KDRL: Post-Training Reasoning LLMs via Unified Knowledge Distillation and Reinforcement Learning",
    "authors": [
      "Hongling Xu",
      "Qi Zhu",
      "Heyuan Deng",
      "Jinpeng Li",
      "Lu Hou",
      "Yasheng Wang",
      "Lifeng Shang",
      "Ruifeng Xu",
      "Fei Mi"
    ],
    "abstract": "Recent advances in large language model (LLM) post-training have leveraged\ntwo distinct paradigms to enhance reasoning capabilities: reinforcement\nlearning (RL) and knowledge distillation (KD). While RL enables the emergence\nof complex reasoning behaviors, it often suffers from low sample efficiency\nwhen the initial policy struggles to explore high-reward trajectories.\nConversely, KD improves learning efficiency via mimicking the teacher model but\ntends to generalize poorly to out-of-domain scenarios. In this work, we present\n\\textbf{KDRL}, a \\textit{unified post-training framework} that jointly\noptimizes a reasoning model through teacher supervision (KD) and\nself-exploration (RL). Specifically, KDRL leverages policy gradient\noptimization to simultaneously minimize the reverse Kullback-Leibler divergence\n(RKL) between the student and teacher distributions while maximizing the\nexpected rule-based rewards. We first formulate a unified objective that\nintegrates GRPO and KD, and systematically explore how different KL\napproximations, KL coefficients, and reward-guided KD strategies affect the\noverall post-training dynamics and performance. Empirical results on multiple\nreasoning benchmarks demonstrate that KDRL outperforms GRPO and various KD\nbaselines while achieving a favorable balance between performance and reasoning\ntoken efficiency. These findings indicate that integrating KD and RL serves as\nan effective and efficient strategy to train reasoning LLMs.",
    "pdf_url": "http://arxiv.org/pdf/2506.02208v1",
    "published": "2025-06-02T19:46:41+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.02207v1",
    "title": "Selective Excitation of Coupled Resonators via Complex Frequency Driving: Enhanced Efficiency and Crosstalk Suppression",
    "authors": [
      "Deepanshu Trivedi",
      "Laraib Niaz",
      "Andrea Alù",
      "Alex Krasnok"
    ],
    "abstract": "Controlling individual elements of coupled resonator systems poses a\nsignificant challenge, as conventional real-frequency pulses suffer from\ninefficiency and crosstalk, limiting fidelity and scalability. To address this\nchallenge, we propose and explore the use of complex frequency excitations,\ntailoring the driving signal waveform to match the target complex reflection\nzeros. We demonstrate that complex frequency driving can achieve near-unity\nselected energy storage efficiency (100%) in a single resonator, substantially\nexceeding the performance of optimized Gaussian pulses (~80%). In a coupled\nthree-resonator system, our method yields significantly higher efficiency\n(92-95%) along with vastly improved selectivity and crosstalk suppression\ncompared to conventional Gaussian pulse excitations of the same duration. Our\ntechnique achieves dynamic critical coupling, providing a powerful paradigm for\nhigh-fidelity, selective control, crucial for advancing scalable complex\nsystems for sensing and computing.",
    "pdf_url": "http://arxiv.org/pdf/2506.02207v1",
    "published": "2025-06-02T19:46:06+00:00",
    "categories": [
      "physics.optics"
    ],
    "primary_category": "physics.optics"
  },
  {
    "id": "http://arxiv.org/abs/2506.02206v1",
    "title": "Reinforcement Learning with Data Bootstrapping for Dynamic Subgoal Pursuit in Humanoid Robot Navigation",
    "authors": [
      "Chengyang Peng",
      "Zhihao Zhang",
      "Shiting Gong",
      "Sankalp Agrawal",
      "Keith A. Redmill",
      "Ayonga Hereid"
    ],
    "abstract": "Safe and real-time navigation is fundamental for humanoid robot applications.\nHowever, existing bipedal robot navigation frameworks often struggle to balance\ncomputational efficiency with the precision required for stable locomotion. We\npropose a novel hierarchical framework that continuously generates dynamic\nsubgoals to guide the robot through cluttered environments. Our method\ncomprises a high-level reinforcement learning (RL) planner for subgoal\nselection in a robot-centric coordinate system and a low-level Model Predictive\nControl (MPC) based planner which produces robust walking gaits to reach these\nsubgoals. To expedite and stabilize the training process, we incorporate a data\nbootstrapping technique that leverages a model-based navigation approach to\ngenerate a diverse, informative dataset. We validate our method in simulation\nusing the Agility Robotics Digit humanoid across multiple scenarios with random\nobstacles. Results show that our framework significantly improves navigation\nsuccess rates and adaptability compared to both the original model-based method\nand other learning-based methods.",
    "pdf_url": "http://arxiv.org/pdf/2506.02206v1",
    "published": "2025-06-02T19:45:29+00:00",
    "categories": [
      "cs.RO"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2506.02205v2",
    "title": "Bregman Centroid Guided Cross-Entropy Method",
    "authors": [
      "Yuliang Gu",
      "Hongpeng Cao",
      "Marco Caccamo",
      "Naira Hovakimyan"
    ],
    "abstract": "The Cross-Entropy Method (CEM) is a widely adopted trajectory optimizer in\nmodel-based reinforcement learning (MBRL), but its unimodal sampling strategy\noften leads to premature convergence in multimodal landscapes. In this work, we\npropose Bregman Centroid Guided CEM ($\\mathcal{BC}$-EvoCEM), a lightweight\nenhancement to ensemble CEM that leverages $\\textit{Bregman centroids}$ for\nprincipled information aggregation and diversity control.\n$\\textbf{$\\mathcal{BC}$-EvoCEM}$ computes a performance-weighted Bregman\ncentroid across CEM workers and updates the least contributing ones by sampling\nwithin a trust region around the centroid. Leveraging the duality between\nBregman divergences and exponential family distributions, we show that\n$\\textbf{$\\mathcal{BC}$-EvoCEM}$ integrates seamlessly into standard CEM\npipelines with negligible overhead. Empirical results on synthetic benchmarks,\na cluttered navigation task, and full MBRL pipelines demonstrate that\n$\\textbf{$\\mathcal{BC}$-EvoCEM}$ enhances both convergence and solution\nquality, providing a simple yet effective upgrade for CEM.",
    "pdf_url": "http://arxiv.org/pdf/2506.02205v2",
    "published": "2025-06-02T19:44:40+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.02204v2",
    "title": "BehaviorBox: Automated Discovery of Fine-Grained Performance Differences Between Language Models",
    "authors": [
      "Lindia Tjuatja",
      "Graham Neubig"
    ],
    "abstract": "Language model evaluation is a daunting task: prompts are brittle,\ncorpus-level perplexities are vague, and the choice of benchmarks are endless.\nFinding examples that show meaningful, generalizable differences between two\nLMs is crucial to understanding where one model succeeds and another fails. Can\nthis process be done automatically? In this work, we propose methodology for\nautomated comparison of language models that uses performance-aware contextual\nembeddings to find fine-grained features of text where one LM outperforms\nanother. Our method, which we name BehaviorBox, extracts coherent features that\ndemonstrate differences with respect to the ease of generation between two LMs.\nSpecifically, BehaviorBox finds features that describe groups of words in\nfine-grained contexts, such as \"conditional 'were' in the phrase 'if you were'\"\nand \"exclamation marks after emotional statements\", where one model outperforms\nanother within a particular datatset. We apply BehaviorBox to compare models\nthat vary in size, model family, and post-training, and enumerate insights into\nspecific contexts that illustrate meaningful differences in performance which\ncannot be found by measures such as corpus-level perplexity alone.",
    "pdf_url": "http://arxiv.org/pdf/2506.02204v2",
    "published": "2025-06-02T19:44:06+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.02203v1",
    "title": "Constrained Sliced Wasserstein Embedding",
    "authors": [
      "Navid NaderiAlizadeh",
      "Darian Salehi",
      "Xinran Liu",
      "Soheil Kolouri"
    ],
    "abstract": "Sliced Wasserstein (SW) distances offer an efficient method for comparing\nhigh-dimensional probability measures by projecting them onto multiple\n1-dimensional probability distributions. However, identifying informative\nslicing directions has proven challenging, often necessitating a large number\nof slices to achieve desirable performance and thereby increasing computational\ncomplexity. We introduce a constrained learning approach to optimize the\nslicing directions for SW distances. Specifically, we constrain the 1D\ntransport plans to approximate the optimal plan in the original space, ensuring\nmeaningful slicing directions. By leveraging continuous relaxations of these\ntransport plans, we enable a gradient-based primal-dual approach to train the\nslicer parameters, alongside the remaining model parameters. We demonstrate how\nthis constrained slicing approach can be applied to pool high-dimensional\nembeddings into fixed-length permutation-invariant representations. Numerical\nresults on foundation models trained on images, point clouds, and protein\nsequences showcase the efficacy of the proposed constrained learning approach\nin learning more informative slicing directions. Our implementation code can be\nfound at https://github.com/Stranja572/constrainedswe.",
    "pdf_url": "http://arxiv.org/pdf/2506.02203v1",
    "published": "2025-06-02T19:43:40+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.OC",
      "q-bio.QM",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.02202v1",
    "title": "Magnetic field dynamics in presence of Hall conductivity, and thermodiffusion",
    "authors": [
      "G. S. Bisnovatyi-Kogan",
      "M. V. Glushikhina"
    ],
    "abstract": "This anisotropy of kinetic coefficients in presence of a magnetic field is\n  represented by so-called Hall currents, which appear in a collisional medium\ndue to action of the Lorentz force on the charged particles between collisions.\nIn many papers the Hall currents had been considered in different approximate\napproaches.\n  We derive equations, describing dynamics of the magnetic field in presence of\nHall currents, using a standard electrodynamic consideration. We consider\ncollisional media, and take into account a temperature gradients, which create\nthermodiffusional electric current, in presence of the Hall component. The\ninfluence of the Hall currents on the magnetic field structure and damping is\nconsidered in simple models. In presence of thermodiffusion the condition for\ncreation of the seed magnetic field in the non-magnetized media is found, which\nis needed for the action of the mechanism, known as \"Biermann battery\".",
    "pdf_url": "http://arxiv.org/pdf/2506.02202v1",
    "published": "2025-06-02T19:41:56+00:00",
    "categories": [
      "physics.plasm-ph",
      "astro-ph.SR"
    ],
    "primary_category": "physics.plasm-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.02201v2",
    "title": "Computing Hydrogen Tunneling Splittings with Nuclear-Electronic Orbital Multireference Configuration Interaction",
    "authors": [
      "Rachel J. Stein",
      "Christopher L. Malbon",
      "Sharon Hammes-Schiffer"
    ],
    "abstract": "Hydrogen tunneling is an important process that impacts reaction rates and\nmolecular spectra. Describing and understanding this process requires a quantum\nmechanical treatment of the transferring hydrogen. The nuclear-electronic\norbital (NEO) approach treats specified nuclei quantum mechanically on the same\nlevel as electrons and has recently been implemented at the multireference\nconfiguration interaction (MRCI) wavefunction level. The NEO-MRCI method\nincludes both the static correlation necessary to describe hydrogen tunneling\nand the electron-proton dynamic correlation required for computing\nquantitatively accurate nuclear-electronic vibronic states. Herein, the\nNEO-MRCI method is used to compute the nuclear-electronic wavefunctions and\ncorresponding vibronic energies for four hydrogen tunneling systems at fixed\ngeometries for a range of donor-acceptor distances. Comparison of the NEO-MRCI\nresults to numerically exact grid-based calculations shows that the NEO-MRCI\nmethod can be used to obtain accurate hydrogen and deuterium tunneling\nsplittings at fixed geometries. Thus, this work presents an important component\nfor studying hydrogen tunneling systems.",
    "pdf_url": "http://arxiv.org/pdf/2506.02201v2",
    "published": "2025-06-02T19:41:36+00:00",
    "categories": [
      "physics.chem-ph"
    ],
    "primary_category": "physics.chem-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.02200v2",
    "title": "Learning Treatment Representations for Downstream Instrumental Variable Regression",
    "authors": [
      "Shiangyi Lin",
      "Hui Lan",
      "Vasilis Syrgkanis"
    ],
    "abstract": "Traditional instrumental variable (IV) estimators face a fundamental\nconstraint: they can only accommodate as many endogenous treatment variables as\navailable instruments. This limitation becomes particularly challenging in\nsettings where the treatment is presented in a high-dimensional and\nunstructured manner (e.g. descriptions of patient treatment pathways in a\nhospital). In such settings, researchers typically resort to applying\nunsupervised dimension reduction techniques to learn a low-dimensional\ntreatment representation prior to implementing IV regression analysis. We show\nthat such methods can suffer from substantial omitted variable bias due to\nimplicit regularization in the representation learning step. We propose a novel\napproach to construct treatment representations by explicitly incorporating\ninstrumental variables during the representation learning process. Our approach\nprovides a framework for handling high-dimensional endogenous variables with\nlimited instruments. We demonstrate both theoretically and empirically that\nfitting IV models on these instrument-informed representations ensures\nidentification of directions that optimize outcome prediction. Our experiments\nshow that our proposed methodology improves upon the conventional two-stage\napproaches that perform dimension reduction without incorporating instrument\ninformation.",
    "pdf_url": "http://arxiv.org/pdf/2506.02200v2",
    "published": "2025-06-02T19:41:23+00:00",
    "categories": [
      "cs.LG",
      "stat.ME"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.02199v1",
    "title": "WASP-121b's transmission spectrum observed with JWST/NIRSpec G395H reveals thermal dissociation and SiO in the atmosphere",
    "authors": [
      "Cyril Gapp",
      "Thomas M. Evans-Soma",
      "Joanna K. Barstow",
      "Joshua D. Lothringer",
      "David K. Sing",
      "Djemma Ruseva",
      "Eva-Maria Ahrer",
      "Jayesh M. Goyal",
      "Duncan Christie",
      "Laura Kreidberg",
      "Nathan J. Mayne"
    ],
    "abstract": "WASP-121b has been established as a benchmark ultrahot Jupiter, serving as a\nlaboratory for the atmospheric chemistry and dynamics of strongly irradiated\nextrasolar gas giants. Here, we present and analyze WASP-121b's transmission\nspectrum observed with NIRSpec G395H on board the James Webb Space Telescope\nand find evidence for the thermal dissociation of H$_2$O and H$_2$ on the\nplanet's permanent dayside. Additionally, we detect SiO at a statistical\nsignificance of $5.2\\sigma$ which is compatible with chemical equilibrium in\nthe atmosphere. Constraining the abundance of SiO and abundance ratios between\nsilicon and volatile atoms in WASP-121b's atmosphere could help discriminate\nbetween possible migration histories of the planet. The three-dimensional\nnature of thermal dissociation on WASP-121b's dayside and of recombination on\nits nightside, however, poses a challenge to constraining molecular abundances\nand elemental abundance ratios from the transmission spectrum. To account for\nthis, we implemented an atmospheric model in the NEMESIS framework that splits\nthe planet's atmosphere into dayside and nightside. A retrieval applying our\natmospheric model to WASP-121b's transmission spectrum favors a higher H$_2$O\nabundance on the nightside than on the dayside, demonstrating the impact of\nhemispheric heterogeneity when attempting to constrain WASP-121b's bulk H$_2$O\ninventory.",
    "pdf_url": "http://arxiv.org/pdf/2506.02199v1",
    "published": "2025-06-02T19:35:50+00:00",
    "categories": [
      "astro-ph.EP"
    ],
    "primary_category": "astro-ph.EP"
  },
  {
    "id": "http://arxiv.org/abs/2506.06354v1",
    "title": "High-gain MIMO Beamforming Antenna System for DSRC and mmwave 5G Integration in Autonomous Vehicles",
    "authors": [
      "Mohammad Shahed Pervez",
      "Amanpreet Kaur"
    ],
    "abstract": "The evolution of autonomous vehicles necessitates robust, high-speed, and\nlow-latency wireless communication systems. This paper presents a novel\nhigh-gain Multiple-Input Multiple-Output (MIMO) beamforming antenna system that\nconcurrently supports Dedicated Short Range Communications (DSRC) at 5.9 GHz\nand millimeter-wave (mm Wave) 5G communications at 28 GHz. The proposed design\naddresses challenges such as compactness, dual-band operation, beam steering\ncapability, and port-to-port isolation within dynamic vehicular environments.",
    "pdf_url": "http://arxiv.org/pdf/2506.06354v1",
    "published": "2025-06-02T19:35:31+00:00",
    "categories": [
      "eess.SP",
      "cs.IT",
      "cs.SY",
      "eess.SY",
      "math.IT"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2506.02198v1",
    "title": "Nonequilibrium transport through the Hubbard dimer",
    "authors": [
      "Yaroslav Pavlyukh",
      "Riku Tuovinen"
    ],
    "abstract": "We apply a computationally efficient approach to study the time- and\nenergy-resolved spectral properties of a two-site Hubbard model using the\nnonequilibrium Green's function formalism. By employing the iterative\ngeneralized Kadanoff-Baym ansatz ($i$GKBA) within a time-linear framework, we\navoid the computational cost of solving the full two-time Kadanoff-Baym\nequations. Spectral information is extracted by coupling the system to multiple\nnarrow-band leads, establishing a direct analogy to photoemission experiments.\nOur results reveal correlation-induced shifts and broadenings of spectral\nfeatures, along with a suppression of transient current oscillations. This\napproach provides a promising avenue for analyzing correlated electron dynamics\nin open quantum systems.",
    "pdf_url": "http://arxiv.org/pdf/2506.02198v1",
    "published": "2025-06-02T19:35:01+00:00",
    "categories": [
      "cond-mat.str-el"
    ],
    "primary_category": "cond-mat.str-el"
  },
  {
    "id": "http://arxiv.org/abs/2506.02197v2",
    "title": "NTIRE 2025 Challenge on RAW Image Restoration and Super-Resolution",
    "authors": [
      "Marcos V. Conde",
      "Radu Timofte",
      "Zihao Lu",
      "Xiangyu Kong",
      "Xiaoxia Xing",
      "Fan Wang",
      "Suejin Han",
      "MinKyu Park",
      "Tianyu Zhang",
      "Xin Luo",
      "Yeda Chen",
      "Dong Liu",
      "Li Pang",
      "Yuhang Yang",
      "Hongzhong Wang",
      "Xiangyong Cao",
      "Ruixuan Jiang",
      "Senyan Xu",
      "Siyuan Jiang",
      "Xueyang Fu",
      "Zheng-Jun Zha",
      "Tianyu Hao",
      "Yuhong He",
      "Ruoqi Li",
      "Yueqi Yang",
      "Xiang Yu",
      "Guanlan Hong",
      "Minmin Yi",
      "Yuanjia Chen",
      "Liwen Zhang",
      "Zijie Jin",
      "Cheng Li",
      "Lian Liu",
      "Wei Song",
      "Heng Sun",
      "Yubo Wang",
      "Jinghua Wang",
      "Jiajie Lu",
      "Watchara Ruangsan"
    ],
    "abstract": "This paper reviews the NTIRE 2025 RAW Image Restoration and Super-Resolution\nChallenge, highlighting the proposed solutions and results. New methods for RAW\nRestoration and Super-Resolution could be essential in modern Image Signal\nProcessing (ISP) pipelines, however, this problem is not as explored as in the\nRGB domain. The goal of this challenge is two fold, (i) restore RAW images with\nblur and noise degradations, (ii) upscale RAW Bayer images by 2x, considering\nunknown noise and blur. In the challenge, a total of 230 participants\nregistered, and 45 submitted results during thee challenge period. This report\npresents the current state-of-the-art in RAW Restoration.",
    "pdf_url": "http://arxiv.org/pdf/2506.02197v2",
    "published": "2025-06-02T19:34:21+00:00",
    "categories": [
      "eess.IV",
      "cs.CV"
    ],
    "primary_category": "eess.IV"
  },
  {
    "id": "http://arxiv.org/abs/2506.02196v1",
    "title": "Mixed Solutions to the Liouville Equation",
    "authors": [
      "Sujay K. Ashok",
      "Jan Troost"
    ],
    "abstract": "We enlarge the set of explicit classical solutions to the Liouville equation\nwith three singularities to the cases with mixed hyperbolic and elliptic\nmonodromies. We analyze the large hyperbolic monodromy limit of the solutions\nand the farthest geodesics looping one hyperbolic singularity. These\ntwo-dimensional geometries describe a time-symmetric spatial slice of a\nsolution to three-dimensional general relativity. The geodesics are\nreinterpreted as snapshots of horizons of evolving black holes. We study the\nspatial slice with three horizons of very heavy black holes in some detail. We\nuse uniform saddle point integration to present the Liouville and heavy black\nhole geometries in terms of simpler special functions. These make a detailed\nanalysis of mixed particle and black hole geometries possible.",
    "pdf_url": "http://arxiv.org/pdf/2506.02196v1",
    "published": "2025-06-02T19:34:07+00:00",
    "categories": [
      "hep-th",
      "gr-qc"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2506.02195v1",
    "title": "Static vs dynamic rough energy landscapes: Where is diffusion faster?",
    "authors": [
      "Dmitrii E. Makarov",
      "Peter Sollich"
    ],
    "abstract": "Molecules in dense environments, such as biological cells, are subjected to\nforces that fluctuate both in time and in space. While spatial fluctuations are\ncaptured by Lifson-Jackson-Zwanzig's model of \"diffusion in a rough potential\",\nand temporal fluctuations are often viewed as leading to additional friction\neffects, a unified view where the environment fluctuates both in time and in\nspace is currently lacking. Here we introduce a discrete-state model of a\nlandscape fluctuating both in time and in space. Importantly, the model\naccounts for the back-reaction of the diffusing particle on the landscape. As a\nresult we find, surprisingly, that many features of the observable dynamics do\nnot depend on the temporal fluctuation timescales and are already captured by\nthe model of diffusion in a rough potential, even though this assumes a static\nenergy landscape.",
    "pdf_url": "http://arxiv.org/pdf/2506.02195v1",
    "published": "2025-06-02T19:30:28+00:00",
    "categories": [
      "cond-mat.stat-mech",
      "physics.bio-ph",
      "physics.chem-ph"
    ],
    "primary_category": "cond-mat.stat-mech"
  },
  {
    "id": "http://arxiv.org/abs/2506.02194v1",
    "title": "Inverse design for robust inference in integrated computational spectrometry",
    "authors": [
      "Wenchao Ma",
      "Raphaël Pestourie",
      "Zin Lin",
      "Steven G. Johnson"
    ],
    "abstract": "For computational spectrometers, we propose an inverse-design approach in\nwhich the scattering media are topology-optimized to achieve better performance\nin inference, without the need of a training set of spectra and a distribution\nof detector noise. Our approach also allows the selection of the inference\nalgorithm to be decoupled from that of the scatterer. For smooth spectra, we\nadditionally devise a regularized reconstruction algorithm based on Chebyshev\ninterpolation, which yields higher accuracy compared with conventional methods\nin which the spectra are sampled at equally spaced frequencies/wavelengths with\nequal weights. Our approaches are numerically demonstrated via inverse design\nof integrated computational spectrometers and reconstruction of example\nspectra. The inverse-designed spectrometers exhibit significantly better\nperformance in the presence of noise than their counterparts with random\nscatterers.",
    "pdf_url": "http://arxiv.org/pdf/2506.02194v1",
    "published": "2025-06-02T19:30:11+00:00",
    "categories": [
      "physics.optics",
      "physics.app-ph",
      "physics.comp-ph"
    ],
    "primary_category": "physics.optics"
  },
  {
    "id": "http://arxiv.org/abs/2506.02193v1",
    "title": "Fairly Wired: Towards Leximin-Optimal Division of Electricity",
    "authors": [
      "Eden Hartman",
      "Dinesh Kumar Baghel",
      "Erel Segal-Halevi"
    ],
    "abstract": "In many parts of the world - particularly in developing countries - the\ndemand for electricity exceeds the available supply. In such cases, it is\nimpossible to provide electricity to all households simultaneously. This raises\na fundamental question: how should electricity be allocated fairly? In this\npaper, we explore this question through the lens of egalitarianism - a\nprinciple that emphasizes equality by prioritizing the welfare of the worst-off\nhouseholds. One natural rule that aligns with this principle is to maximize the\negalitarian welfare - the smallest utility across all households. We show that\ncomputing such an allocation is NP-hard, even under strong simplifying\nassumptions. Leximin is a stronger fairness notion that generalizes the\negalitarian welfare: it also requires to maximize the smallest utility, but\nthen, subject to that, the second-smallest, then the third, and so on. The\nhardness results extends directly to leximin as well. Despite this, we present\na Fully Polynomial-Time Approximation Scheme (FPTAS) for leximin in the special\ncase where the network connectivity graph is a tree. This means that we can\nefficiently approximate leximin - and, in particular, the egalitarian welfare -\nto any desired level of accuracy.",
    "pdf_url": "http://arxiv.org/pdf/2506.02193v1",
    "published": "2025-06-02T19:30:03+00:00",
    "categories": [
      "cs.GT",
      "cs.DS",
      "cs.MA"
    ],
    "primary_category": "cs.GT"
  },
  {
    "id": "http://arxiv.org/abs/2506.02192v2",
    "title": "Impact of the honeycomb spin-lattice on topological magnons and edge states in ferromagnetic 2D skyrmion crystals",
    "authors": [
      "Doried Ghader",
      "Bilal Jabakhanji"
    ],
    "abstract": "Magnons have been intensively studied in two-dimensional (2D) ferromagnetic\n(FM) skyrmion crystals (SkXs) stabilized on Bravais lattices, particularly\ntriangular and square lattices, where the first two magnon gaps are\ntopologically trivial and do not support topological edge states (TESs).\nMeanwhile, the third gap can host TESs, which may be trivialized through\nfield-induced topological phase transitions (TPTs), enabling controlled\nmagnonic edge transport. However, the magnon topology in non-Bravais spin\nlattices remains largely unexplored. In this work, we theoretically investigate\nthe influence of the honeycomb lattice structure on magnon band topology and\nassociated TESs in FM SkXs, employing realistic parameters for monolayer\nCrI$_3$ and CrBr$_3$. We reveal unique magnonic topological features arising\nspecifically from the honeycomb lattice. Characteristic magnon modes, such as\nelliptical and triangular distortion modes, acquire nontrivial Chern numbers,\ncontrasting their trivial counterparts in triangular-based SkXs. Moreover, the\nsecond magnon gap in honeycomb-based SkXs consistently hosts TESs at low\nmagnetic fields, unlike triangular SkXs. These TESs can be trivialized above a\ncritical magnetic field. Conversely, the third gap is generally trivial at\nhigher magnetic fields but becomes topological at low fields only when the SkX\nperiodicity falls below a critical threshold dependent on Dzyaloshinskii-Moriya\ninteraction (DMI) strength and magnetic anisotropy. Our study further\ndemonstrates a rich magnonic topological phase diagram accessible by magnetic\nfields, potentially enabling selective control of low-energy chiral edge modes.\nThese findings underscore the pivotal role of lattice geometry in shaping the\ntopology of magnons in noncollinear spin textures.",
    "pdf_url": "http://arxiv.org/pdf/2506.02192v2",
    "published": "2025-06-02T19:29:14+00:00",
    "categories": [
      "cond-mat.mes-hall",
      "cond-mat.mtrl-sci",
      "quant-ph"
    ],
    "primary_category": "cond-mat.mes-hall"
  },
  {
    "id": "http://arxiv.org/abs/2506.02191v1",
    "title": "Meta-heuristic design of a light-weight homologous backup structure of the primary reflector for the Large Submillimeter Telescope",
    "authors": [
      "Chihiro Imamura",
      "Yoichi Tamura",
      "Hiroaki Kawamura",
      "Toshiaki Kimura",
      "Akio Taniguchi",
      "Mikio Kurita"
    ],
    "abstract": "The development of large-aperture submillimeter telescopes, such as the Large\nSubmillimeter Telescope (LST) and the Atacama Large Aperture Submillimeter\nTelescope (AtLAST), is essential to overcome the limitations of current\nobservational capabilities in submillimeter astronomy. These telescopes face\nchallenges related to maintaining high surface accuracy of the main reflector\nwhile minimizing the weight of the telescope structure. This study introduces a\ngenetic algorithm (GA)-based structural optimization, previously applied in\nrelated works, to 50 m-class backup structures (BUSes) with a variable focal\nposition, addressing the challenge of achieving both lightweight construction\nand high surface accuracy through the consideration of homologous deformation.\nWe model the BUS as a truss structure and perform multi-objective optimization\nusing a GA. The optimization process considers two structures: axisymmetric and\nnon-axisymmetric between the top and bottom. The optimization aims to find\nstructures that simultaneously minimize the maximum stroke length of actuators\nand the mass of the BUS under practical constraints. The optimized structures\nshow improved surface accuracy, primarily due to the minimization of the\nmaximum actuator stroke length, and reduced weight, both achieved under the\nimposed constraints. Notably, we find a homologous BUS solution that achieves a\nsurface error of down to $\\sim 5\\,\\mu\\mathrm{m}$ RMS with a tiny portion of the\ntruss nodes being actively controlled. The results highlight the potential of\nGA-based optimization in the design of next-generation submillimeter\ntelescopes, suggesting that further exploration of non-axisymmetric structures\ncould yield even more effective solutions. Our findings support the application\nof advanced optimization techniques to achieve high-performance and\ncost-effective telescope designs.",
    "pdf_url": "http://arxiv.org/pdf/2506.02191v1",
    "published": "2025-06-02T19:27:20+00:00",
    "categories": [
      "astro-ph.IM"
    ],
    "primary_category": "astro-ph.IM"
  },
  {
    "id": "http://arxiv.org/abs/2506.02190v1",
    "title": "2-Homogeneous bipartite distance-regular graphs and the quantum group $U^\\prime_q(\\mathfrak{so}_6)$",
    "authors": [
      "Paul Terwilliger"
    ],
    "abstract": "We consider a 2-homogeneous bipartite distance-regular graph $\\Gamma$ with\ndiameter $D \\geq 3$. We assume that $\\Gamma$ is not a hypercube nor a cycle. We\nfix a $Q$-polynomial ordering of the primitive idempotents of $\\Gamma$. This\n$Q$-polynomial ordering is described using a nonzero parameter $q \\in \\mathbb\nC$ that is not a root of unity. We investigate $\\Gamma$ using an\n$S_3$-symmetric approach. In this approach one considers $V^{\\otimes 3} = V\n\\otimes V \\otimes V$ where $V$ is the standard module of $\\Gamma$. We construct\na subspace $\\Lambda$ of $V^{\\otimes 3}$ that has dimension $\\binom{D+3}{3}$,\ntogether with six linear maps from $\\Lambda$ to $\\Lambda$. Using these maps we\nturn $\\Lambda$ into an irreducible module for the nonstandard quantum group\n  $U^\\prime_q(\\mathfrak{so}_6)$ introduced by Gavrilik and Klimyk in 1991.",
    "pdf_url": "http://arxiv.org/pdf/2506.02190v1",
    "published": "2025-06-02T19:26:21+00:00",
    "categories": [
      "math.CO",
      "math.QA",
      "05E30"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2506.02189v1",
    "title": "Self-force framework for merger-ringdown waveforms",
    "authors": [
      "Lorenzo Küchler",
      "Geoffrey Compère",
      "Adam Pound"
    ],
    "abstract": "The prospect of observing asymmetric compact binaries with next-generation\ngravitational-wave detectors has motivated the development of fast and accurate\nwaveform models in gravitational self-force theory. These models are based on a\ntwo-stage process: in a (slow) offline stage, waveform ingredients are\npre-computed as functions on the orbital phase space; in a (fast) online stage,\nthe waveform is generated by evolving through the phase space. While this\nframework has traditionally been restricted to the inspiral stage of a binary,\nwe recently extended it across the transition to plunge, where the small\ncompanion crosses the innermost stable circular orbit around the primary black\nhole. In this paper, for the special case of quasicircular, nonspinning\nbinaries, we show how the \"offline/online\" phase-space paradigm also extends\nthrough the final plunge, which generates the binary's merger-ringdown signal.\nWe implement the method at leading, geodesic order in the plunge. The resulting\nplunge waveform agrees well with a stationary-phase approximation at early\ntimes and with a (self-consistently calculated) quasinormal mode sum at late\ntimes, but we highlight that neither of the two approximations reaches the peak\nof the full plunge waveform. Finally, we compare the plunge waveform to\nnumerical relativity simulations. Our framework offers the prospect of fast,\naccurate inspiral-merger-ringdown waveform models for asymmetric binaries.",
    "pdf_url": "http://arxiv.org/pdf/2506.02189v1",
    "published": "2025-06-02T19:24:06+00:00",
    "categories": [
      "gr-qc"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2506.02188v2",
    "title": "Interior redox state effects on the stability of secondary atmospheres and observational manifestations: LP 791-18 d as a case study for outgassing rocky exoplanets",
    "authors": [
      "Leonardos Gkouvelis",
      "Francisco J. Pozuelos",
      "Thomas Drant",
      "Mohammad Farhat",
      "Meng Tian",
      "Can Akın"
    ],
    "abstract": "Recent advances in space and ground-based facilities now enable atmospheric\ncharacterization of a selected sample of rocky exoplanets. These atmospheres\noffer key insights into planetary formation and evolution, but their\ninterpretation requires models that couple atmospheric processes with both the\nplanetary interior and the surrounding space environment. This work focuses on\nthe Earth-size planet LP791 18d, which is estimated to receive continuous tidal\nheating due to the orbital configuration of the system; thus, it is expected to\nexhibit volcanic activity. We estimate the mantle temperature of 1680-1880 K.\nOur results show that the atmospheric mean molecular weight gradient is\ncontrolled by oxygen fugacity rather than bulk metallicity. Furthermore, we use\nthe atmospheric steady-state solutions produced from the interior redox state\nversus surface pressure parameter space and explore their atmospheric\nstability. We find that stability is achieved only in highly oxidized scenarios\nwhile reduced interior states fall into the hydrodynamic escape regime with\nmass loss rates on the order of 10^5-10^8 kg/s. We argue that scenarios with\nreduced interior states are likely to have exhausted their volatile budget\nduring the planets lifetime. Furthermore, we predict the atmospheric footprint\nof the planets interior based on its oxidation state and assess its\ndetectability using current or forthcoming tools to constrain the internal and\natmospheric composition. We show that the degeneracy between bare rock surfaces\nand thick atmospheres can be resolved by using three photometric bands to\nconstruct a color-color diagram that accounts for potential effects from\nphotochemical hazes and clouds. Our modeling approach connects interior and\natmospheric processes, providing a basis to explore volatile evolution and\npotential habitability.",
    "pdf_url": "http://arxiv.org/pdf/2506.02188v2",
    "published": "2025-06-02T19:23:38+00:00",
    "categories": [
      "astro-ph.EP"
    ],
    "primary_category": "astro-ph.EP"
  },
  {
    "id": "http://arxiv.org/abs/2506.02187v1",
    "title": "Demonstrating magnetic field robustness and reducing temporal T1 noise in transmon qubits through magnetic field engineering",
    "authors": [
      "Bektur Abdisatarov",
      "Tanay Roy",
      "Daniel Bafia",
      "Roman Pilipenko",
      "Matthew Julian Dubiel",
      "David van Zanten",
      "Shaojiang Zhu",
      "Mustafa Bal",
      "Grigory Eremeev",
      "Hani Elsayed-Ali",
      "Akshay Murty",
      "Alexander Romanenko",
      "Anna Grassellino"
    ],
    "abstract": "The coherence of superconducting transmon qubits is often disrupted by\nfluctuations in the energy relaxation time (T1), limiting their performance for\nquantum computing. While background magnetic fields can be harmful to\nsuperconducting devices, we demonstrate that both trapped magnetic flux and\nexternally applied static magnetic fields can suppress temporal fluctuations in\nT1 without significantly degrading its average value or qubit frequency. Using\na three-axis Helmholtz coil system, we applied calibrated magnetic fields\nperpendicular to the qubit plane during cooldown and operation. Remarkably,\ntransmon qubits based on tantalum-capped niobium (Nb/Ta) capacitive pads and\naluminum-based Josephson junctions (JJs) maintained T1 lifetimes near 300\n{\\mu}s even when cooled in fields as high as 600 mG. Both trapped flux up to\n600 mG and applied fields up to 400 mG reduced T1 fluctuations by more than a\nfactor of two, while higher field strengths caused rapid coherence degradation.\nWe attribute this stabilization to the polarization of paramagnetic impurities,\nthe role of trapped flux as a sink for non-equilibrium quasiparticles (QPs),\nand partial saturation of fluctuating two-level systems (TLSs). These findings\nchallenge the conventional view that magnetic fields are inherently detrimental\nand introduce a strategy for mitigating noise in superconducting qubits,\noffering a practical path toward more stable and scalable quantum systems.",
    "pdf_url": "http://arxiv.org/pdf/2506.02187v1",
    "published": "2025-06-02T19:22:54+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.02186v1",
    "title": "Sums of Mixed Independent Positive Random Variables: A Unified Framework",
    "authors": [
      "Fernando Darío Almeida García",
      "Michel Daoud Yacoub",
      "José Cândido Silveira Santos Filho"
    ],
    "abstract": "This paper proposes a comprehensive and unprecedented framework that\nstreamlines the derivation of exact, compact -- yet tractable -- solutions for\nthe probability density function (PDF) and cumulative distribution function\n(CDF) of the sum of a broad spectrum of mixed independent positive random\nvariables (RVs). To showcase the framework's potential and extensive\napplicability, we tackle the enduring challenge of obtaining these statistics\nfor the sum of fading variates in an exact, manageable, and unified manner.\nSpecifically, we derive novel, tractable expressions for the PDF and CDF of the\nsum of Gaussian-class and non-Gaussian-class fading distributions, thereby\ncovering a plethora of conventional, generalized, and recently introduced\nfading models. The proposed framework accommodates independent and identically\ndistributed (i.i.d.) sums, independent but not necessarily identically\ndistributed (i.n.i.d.) sums, and mixed-type sums. Moreover, we introduce the\nstrikingly novel $\\alpha$-$\\mu$ mixture distribution that unifies all\nGaussian-class fading models.",
    "pdf_url": "http://arxiv.org/pdf/2506.02186v1",
    "published": "2025-06-02T19:20:12+00:00",
    "categories": [
      "eess.SP"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2506.03204v1",
    "title": "On the first-order theory of the remainder",
    "authors": [
      "Mihai Prunescu"
    ],
    "abstract": "It is proved that the first-order theory of the structure (N,mod) is\nundecidable. Here mod denotes the operation of computing the remainder for any\ndivision between positive integers; i.e. x mod y is the remainder obtained by\nthe division x : y.",
    "pdf_url": "http://arxiv.org/pdf/2506.03204v1",
    "published": "2025-06-02T19:19:21+00:00",
    "categories": [
      "math.LO",
      "03D35"
    ],
    "primary_category": "math.LO"
  },
  {
    "id": "http://arxiv.org/abs/2506.02185v1",
    "title": "Tunable magnons in a dual-gated 2D antiferromagnet",
    "authors": [
      "Nele Stetzuhn",
      "Abhijeet M. Kumar",
      "Sviatoslav Kovalchuk",
      "Denis Yagodkin",
      "Louis Simon",
      "Samuel Mañas-Valero",
      "Eugenio Coronado",
      "Takashi Taniguchi",
      "Kenji Watanabe",
      "Deepika Gill",
      "Sangeeta Sharma",
      "Piet Brouwer",
      "Clemens von Korff Schmising",
      "Stefan Eisebitt",
      "Kirill I. Bolotin"
    ],
    "abstract": "The layered antiferromagnet CrSBr features magnons coupled to other\nquasiparticles, including excitons and polaritons, enabling their easy optical\naccessibility. In this work, we investigate the tunability of magnons in\nfew-layered devices in response to changes in carrier density and the\napplication of a perpendicular electric field. We demonstrate an on-chip\ntunability of the in- and out-of-phase magnon frequencies by up to 2 GHz. While\nthe frequencies of both modes increase with the electron density, we observe an\nasymmetric response with respect to the electric field in a dual-gated trilayer\ndevice. To understand the mechanism of this disparity, we develop a\nlayer-resolved macrospin model describing the magnetic dynamics in thin,\nnon-uniformly doped devices. Through this model we establish the doping- and\nelectric-field-dependence of the exchange interaction, magnetic anisotropy, and\nmagnetic moment of individual layers. Our results advance the applications of\ngate-tunable magnonic devices based on 2D materials.",
    "pdf_url": "http://arxiv.org/pdf/2506.02185v1",
    "published": "2025-06-02T19:16:19+00:00",
    "categories": [
      "cond-mat.mes-hall"
    ],
    "primary_category": "cond-mat.mes-hall"
  },
  {
    "id": "http://arxiv.org/abs/2506.02184v2",
    "title": "Off forward non-SCHC contributions to exclusive vector quarkonium production from the \"spin dependent BFKL Pomeron\"",
    "authors": [
      "Sanjin Benić",
      "Adrian Dumitru"
    ],
    "abstract": "A novel contribution to off-forward, exclusive vector quarkonium production,\n$\\gamma^{(*)}+p \\to V+p$, at high energy is derived which corresponds to a\n$t$-channel exchange of a BFKL hard Pomeron, with a helicity flip of the\nproton. This ``spin-dependent BFKL Pomeron\" is required in a consistent\nexpansion in powers of the momentum transfer $ t \\approx -\\Delta_\\perp^2$\nbeyond first order. The spin-dependent Pomeron violates $s$-channel helicity\nconservation (SCHC) at ${\\cal O}(\\Delta_\\perp^2)$, and beyond. Expanding to\nleading twist only, it corresponds to GPD $E_g(x,t)$ for vanishing skewness. We\nderive explicit expressions for the eikonal BFKL amplitudes, to all orders in\ndipole size times momentum transfer, for all helicity configurations of the\nparticles in the initial and final states. We also provide numerical estimates\nof the helicity flip two gluon exchange amplitude at moderate $x$ from a\nlight-cone quark model of the proton. The spin dependent BFKL Pomeron could, in\nprinciple, be discovered via double spin asymmetries in $e+p \\to e+p+J/\\psi$\nwith transversely polarized proton and longitudinally polarized electron in the\ninitial state.",
    "pdf_url": "http://arxiv.org/pdf/2506.02184v2",
    "published": "2025-06-02T19:13:52+00:00",
    "categories": [
      "hep-ph"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.02183v1",
    "title": "Natural, Artificial, and Human Intelligences",
    "authors": [
      "Emmanuel M. Pothos",
      "Dominic Widdows"
    ],
    "abstract": "Human achievement, whether in culture, science, or technology, is\nunparalleled in the known existence. This achievement is tied to the enormous\ncommunities of knowledge, made possible by (especially written) language:\nleaving theological content aside, it is very much true that \"in the beginning\nwas the word\". There lies the challenge regarding modern age chatbots: they can\n'do' language apparently as well as ourselves and there is a natural question\nof whether they can be considered intelligent, in the same way as we are or\notherwise. Are humans uniquely intelligent? We consider this question in terms\nof the psychological literature on intelligence, evidence for intelligence in\nnon-human animals, the role of written language in science and technology,\nprogress with artificial intelligence, the history of intelligence testing (for\nboth humans and machines), and the role of embodiment in intelligence. For the\nmost unique accomplishments of human intelligence (such as music symphonies or\ncomplex scientific theories), we think that, together with language, there are\nfour essential ingredients, which can be summarised as invention, capacity for\ncomplex inference, embodiment, and self-awareness. This conclusion makes\nuntenable the position that human intelligence differs qualitatively from that\nof many non-human animals, since, with the exception of complex language, all\nthe other requirements are fulfilled. Regarding chatbots, the current\nlimitations are localised to the lack of embodiment and (apparent) lack of\nawareness.",
    "pdf_url": "http://arxiv.org/pdf/2506.02183v1",
    "published": "2025-06-02T19:11:49+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2506.02182v1",
    "title": "Spegion: Implicit and Non-Lexical Regions with Sized Allocations",
    "authors": [
      "Jack Hughes",
      "Michael Vollmer",
      "Mark Batty"
    ],
    "abstract": "Region based memory management is a powerful tool designed with the goal of\nensuring memory safety statically. The region calculus of Tofte and Talpin is a\nwell known example of a region based system, which uses regions to manage\nmemory in a stack-like fashion. However, the region calculus is lexically\nscoped and requires explicit annotation of memory regions, which can be\ncumbersome for the programmer. Other systems have addressed non-lexical\nregions, but these approaches typically require the use of a substructural type\nsystem to track the lifetimes of regions. We present Spegion, a language with\nimplicit non-lexical regions, which provides these same memory safety\nguarantees for programs that go beyond using memory allocation in a stack-like\nmanner. We are able to achieve this with a concise syntax, and without the use\nof substructural types, relying instead on an effect system to enforce\nconstraints on region allocation and deallocation. These regions may be divided\ninto sub-regions, i.e., Splittable rEgions, allowing fine grained control over\nmemory allocation. Furthermore, Spegion permits sized allocations, where each\nvalue has an associated size which is used to ensure that regions are not\nover-allocated into. We present a type system for Spegion and prove it is type\nsafe with respect to a small-step operational semantics.",
    "pdf_url": "http://arxiv.org/pdf/2506.02182v1",
    "published": "2025-06-02T19:11:46+00:00",
    "categories": [
      "cs.PL"
    ],
    "primary_category": "cs.PL"
  },
  {
    "id": "http://arxiv.org/abs/2506.02181v1",
    "title": "Echoes of Phonetics: Unveiling Relevant Acoustic Cues for ASR via Feature Attribution",
    "authors": [
      "Dennis Fucci",
      "Marco Gaido",
      "Matteo Negri",
      "Mauro Cettolo",
      "Luisa Bentivogli"
    ],
    "abstract": "Despite significant advances in ASR, the specific acoustic cues models rely\non remain unclear. Prior studies have examined such cues on a limited set of\nphonemes and outdated models. In this work, we apply a feature attribution\ntechnique to identify the relevant acoustic cues for a modern Conformer-based\nASR system. By analyzing plosives, fricatives, and vowels, we assess how\nfeature attributions align with their acoustic properties in the time and\nfrequency domains, also essential for human speech perception. Our findings\nshow that the ASR model relies on vowels' full time spans, particularly their\nfirst two formants, with greater saliency in male speech. It also better\ncaptures the spectral characteristics of sibilant fricatives than non-sibilants\nand prioritizes the release phase in plosives, especially burst\ncharacteristics. These insights enhance the interpretability of ASR models and\nhighlight areas for future research to uncover potential gaps in model\nrobustness.",
    "pdf_url": "http://arxiv.org/pdf/2506.02181v1",
    "published": "2025-06-02T19:11:16+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.02180v1",
    "title": "Linearly Distributive Fox Theorem",
    "authors": [
      "Rose Kudzman-Blais"
    ],
    "abstract": "Linearly distributive categories (LDC), introduced by Cockett and Seely to\nmodel multiplicative linear logic, are categories equipped with two monoidal\nstructures that interact via linear distributivities. A seminal result in\nmonoidal category theory is the Fox theorem, which characterizes cartesian\ncategories as symmetric monoidal categories whose objects are equipped with\ncanonical comonoid structures. The aim of this work is to extend the Fox\ntheorem to LDCs and characterize the subclass of cartesian LDCs. To do so, we\nintroduce the concepts of medial linearly distributive categories, medial\nlinear functors, and medial linear transformations. The former are LDCs which\nrespect the logical medial rule, appearing frequently in deep inference, or\nalternatively are the appropriate structure at the intersection of LDCs and\nduoidal categories.",
    "pdf_url": "http://arxiv.org/pdf/2506.02180v1",
    "published": "2025-06-02T19:11:12+00:00",
    "categories": [
      "math.CT",
      "18M45"
    ],
    "primary_category": "math.CT"
  },
  {
    "id": "http://arxiv.org/abs/2506.02179v1",
    "title": "Optimal Coordination of Flexible DERs in Local Energy and Flexibility Markets to Ensure Social Equity",
    "authors": [
      "Niloofar Pourghaderi",
      "Milad Kabirifar",
      "Payman Dehghanian"
    ],
    "abstract": "Local electricity markets offer a promising solution for integrating\nrenewable energy sources and other distributed energy resources (DERs) into\ndistribution networks. These markets enable the effective utilization of\nflexible resources by facilitating coordination among various agents. Beyond\ntechnical and economic considerations, addressing social equity within these\nlocal communities is critical and requires dedicated attention in\nmarket-clearing frameworks. This paper proposes a social equity-based\nmarket-clearing framework for the optimal management of DERs' energy and\nflexibility within local communities. The proposed framework incorporates\nconsumers' energy burden to ensure fair pricing in energy market clearance.\nFurthermore, to ensure equity during unbalanced operating conditions, flexible\nresources are managed in the local flexibility market, ensuring that all\nparticipants can trade power fairly under network disturbances. The model is\nformulated as a second-order cone programming (SOCP) optimization and validated\non the IEEE 33-bus test distribution network.",
    "pdf_url": "http://arxiv.org/pdf/2506.02179v1",
    "published": "2025-06-02T19:07:57+00:00",
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2506.02178v1",
    "title": "Cocktail-Party Audio-Visual Speech Recognition",
    "authors": [
      "Thai-Binh Nguyen",
      "Ngoc-Quan Pham",
      "Alexander Waibel"
    ],
    "abstract": "Audio-Visual Speech Recognition (AVSR) offers a robust solution for speech\nrecognition in challenging environments, such as cocktail-party scenarios,\nwhere relying solely on audio proves insufficient. However, current AVSR models\nare often optimized for idealized scenarios with consistently active speakers,\noverlooking the complexities of real-world settings that include both speaking\nand silent facial segments. This study addresses this gap by introducing a\nnovel audio-visual cocktail-party dataset designed to benchmark current AVSR\nsystems and highlight the limitations of prior approaches in realistic noisy\nconditions. Additionally, we contribute a 1526-hour AVSR dataset comprising\nboth talking-face and silent-face segments, enabling significant performance\ngains in cocktail-party environments. Our approach reduces WER by 67% relative\nto the state-of-the-art, reducing WER from 119% to 39.2% in extreme noise,\nwithout relying on explicit segmentation cues.",
    "pdf_url": "http://arxiv.org/pdf/2506.02178v1",
    "published": "2025-06-02T19:07:51+00:00",
    "categories": [
      "cs.SD",
      "cs.CL"
    ],
    "primary_category": "cs.SD"
  },
  {
    "id": "http://arxiv.org/abs/2506.02177v1",
    "title": "Act Only When It Pays: Efficient Reinforcement Learning for LLM Reasoning via Selective Rollouts",
    "authors": [
      "Haizhong Zheng",
      "Yang Zhou",
      "Brian R. Bartoldson",
      "Bhavya Kailkhura",
      "Fan Lai",
      "Jiawei Zhao",
      "Beidi Chen"
    ],
    "abstract": "Reinforcement learning, such as PPO and GRPO, has powered recent\nbreakthroughs in LLM reasoning. Scaling rollout to sample more prompts enables\nmodels to selectively use higher-quality data for training, which can stabilize\nRL training and improve model performance. However, this comes at the cost of\nsignificant computational overhead. In this paper, we show that a substantial\nportion of this overhead can be avoided by skipping uninformative prompts\nbefore rollout. Our analysis of reward dynamics reveals a strong temporal\nconsistency in prompt value: prompts that are uninformative in one epoch of\ntraining are likely to remain uninformative in future epochs. Based on these\ninsights, we propose GRESO (GRPO with Efficient Selective Rollout), an online,\nlightweight pre-rollout filtering algorithm that predicts and skips\nuninformative prompts using reward training dynamics. By evaluating GRESO on a\nbroad range of math reasoning benchmarks and models, such as Qwen2.5-Math-1.5B,\nDeepSeek-R1-Distill-Qwen-1.5B, and Qwen2.5-Math-7B, we show that GRESO achieves\nup to 2.4x wall-clock time speedup in rollout and up to 2.0x speedup in total\ntraining time without accuracy degradation.",
    "pdf_url": "http://arxiv.org/pdf/2506.02177v1",
    "published": "2025-06-02T19:03:00+00:00",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2506.02176v1",
    "title": "Blast-frozen Dark Matter and Modulated Density Perturbations",
    "authors": [
      "Miha Nemevšek",
      "Yue Zhang"
    ],
    "abstract": "First-order phase transitions (FOPT) are ubiquitous in beyond the Standard\nModel physics and leave distinctive echoes in the history of early universe. We\nconsider a FOPT serving the well-motivated role of dark matter mass generation\nand present {\\it blast-frozen dark matter} (BFDM), which transitions from\nradiation to non-relativistic relic in a period much shorter than the\ncorresponding Hubble time. Its cosmological imprint are strong oscillations in\nthe dark matter density perturbations that seed structure formation on large\nand small scales. For a FOPT occurring not long before the matter-radiation\nequality, next generation cosmological surveys bear a strong potential to\ndiscover BFDM and in turn establish the origin of dark matter mass.",
    "pdf_url": "http://arxiv.org/pdf/2506.02176v1",
    "published": "2025-06-02T19:02:50+00:00",
    "categories": [
      "hep-ph",
      "astro-ph.CO"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.02175v1",
    "title": "AI Debate Aids Assessment of Controversial Claims",
    "authors": [
      "Salman Rahman",
      "Sheriff Issaka",
      "Ashima Suvarna",
      "Genglin Liu",
      "James Shiffer",
      "Jaeyoung Lee",
      "Md Rizwan Parvez",
      "Hamid Palangi",
      "Shi Feng",
      "Nanyun Peng",
      "Yejin Choi",
      "Julian Michael",
      "Liwei Jiang",
      "Saadia Gabriel"
    ],
    "abstract": "As AI grows more powerful, it will increasingly shape how we understand the\nworld. But with this influence comes the risk of amplifying misinformation and\ndeepening social divides-especially on consequential topics like public health\nwhere factual accuracy directly impacts well-being. Scalable Oversight aims to\nensure AI truthfulness by enabling humans to supervise systems that may exceed\nhuman capabilities--yet humans themselves hold different beliefs and biases\nthat impair their judgment. We study whether AI debate can guide biased judges\ntoward the truth by having two AI systems debate opposing sides of\ncontroversial COVID-19 factuality claims where people hold strong prior\nbeliefs. We conduct two studies: one with human judges holding either\nmainstream or skeptical beliefs evaluating factuality claims through\nAI-assisted debate or consultancy protocols, and a second examining the same\nproblem with personalized AI judges designed to mimic these different human\nbelief systems. In our human study, we find that debate-where two AI advisor\nsystems present opposing evidence-based arguments-consistently improves\njudgment accuracy and confidence calibration, outperforming consultancy with a\nsingle-advisor system by 10% overall. The improvement is most significant for\njudges with mainstream beliefs (+15.2% accuracy), though debate also helps\nskeptical judges who initially misjudge claims move toward accurate views\n(+4.7% accuracy). In our AI judge study, we find that AI judges with human-like\npersonas achieve even higher accuracy (78.5%) than human judges (70.1%) and\ndefault AI judges without personas (69.8%), suggesting their potential for\nsupervising frontier AI models. These findings highlight AI debate as a\npromising path toward scalable, bias-resilient oversight--leveraging both\ndiverse human and AI judgments to move closer to truth in contested domains.",
    "pdf_url": "http://arxiv.org/pdf/2506.02175v1",
    "published": "2025-06-02T19:01:53+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.02174v1",
    "title": "An Overview of GPU-based First-Order Methods for Linear Programming and Extensions",
    "authors": [
      "Haihao Lu",
      "Jinwen Yang"
    ],
    "abstract": "The rapid progress in GPU computing has revolutionized many fields, yet its\npotential in mathematical programming, such as linear programming (LP), has\nonly recently begun to be realized. This survey aims to provide a comprehensive\noverview of recent advancements in GPU-based first-order methods for LP, with a\nparticular focus on the design and development of cuPDLP. We begin by\npresenting the design principles and algorithmic foundation of the primal-dual\nhybrid gradient (PDHG) method, which forms the core of the solver. Practical\nenhancements, such as adaptive restarts, preconditioning, Halpern-type\nacceleration and infeasibility detection, are discussed in detail, along with\nempirical comparisons against industrial-grade solvers, highlighting the\nscalability and efficiency of cuPDLP. We also provide a unified theoretical\nframework for understanding PDHG, covering both classical and recent results on\nsublinear and linear convergence under sharpness conditions. Finally, we extend\nthe discussion to GPU-based optimization beyond LP, including quadratic,\nsemidefinite, conic, and nonlinear programming.",
    "pdf_url": "http://arxiv.org/pdf/2506.02174v1",
    "published": "2025-06-02T19:00:36+00:00",
    "categories": [
      "math.OC"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2506.02173v1",
    "title": "Turbulent drag on stellar mass black holes embedded in AGN discs",
    "authors": [
      "Alessandro Alberto Trani",
      "Pierfrancesco Di Cintio"
    ],
    "abstract": "We investigate how AGN disk turbulence affects the orbital dynamics of a\nstellar-mass black hole (BH) initially located at a migration trap, focusing on\nthe long-term behavior of eccentricity and inclination in the quasi-embedded\nregime. We develop a semi-analytical framework in which turbulence is modeled\nas a stochastic velocity field acting through a modified drag force. We\nintegrate the resulting stochastic differential equations both in Cartesian\ncoordinates and in orbital elements using a linearized perturbative approach,\nand compare these results with full numerical simulations. Eccentricity and\ninclination evolve toward steady-state Rayleigh distributions, with variances\ndetermined by the local disk properties and the ratio of the gas damping rate\nto the orbital frequency. The analytical predictions agree well with the\nnumerical simulations. We provide closed-form expressions for the variances in\nboth the fast and slow damping regimes. These results are directly applicable\nto Monte Carlo population models and can serve as physically motivated initial\nconditions for hydrodynamical simulations. Turbulent forcing prevents full\ncircularization and alignment of BH orbits in AGN disks, even in the presence\nof strong gas drag. This has important implications for BH merger and binary\nformation rates, which are sensitive to the residual eccentricity and\ninclination. Our results highlight the need to account for turbulence-induced\nstochastic heating when modeling the dynamical evolution of compact objects in\nAGN environments.",
    "pdf_url": "http://arxiv.org/pdf/2506.02173v1",
    "published": "2025-06-02T19:00:00+00:00",
    "categories": [
      "astro-ph.HE",
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.HE"
  },
  {
    "id": "http://arxiv.org/abs/2506.06353v1",
    "title": "Large Language Models for EEG: A Comprehensive Survey and Taxonomy",
    "authors": [
      "Naseem Babu",
      "Jimson Mathew",
      "A. P. Vinod"
    ],
    "abstract": "The growing convergence between Large Language Models (LLMs) and\nelectroencephalography (EEG) research is enabling new directions in neural\ndecoding, brain-computer interfaces (BCIs), and affective computing. This\nsurvey offers a systematic review and structured taxonomy of recent\nadvancements that utilize LLMs for EEG-based analysis and applications. We\norganize the literature into four domains: (1) LLM-inspired foundation models\nfor EEG representation learning, (2) EEG-to-language decoding, (3) cross-modal\ngeneration including image and 3D object synthesis, and (4) clinical\napplications and dataset management tools. The survey highlights how\ntransformer-based architectures adapted through fine-tuning, few-shot, and\nzero-shot learning have enabled EEG-based models to perform complex tasks such\nas natural language generation, semantic interpretation, and diagnostic\nassistance. By offering a structured overview of modeling strategies, system\ndesigns, and application areas, this work serves as a foundational resource for\nfuture work to bridge natural language processing and neural signal analysis\nthrough language models.",
    "pdf_url": "http://arxiv.org/pdf/2506.06353v1",
    "published": "2025-06-02T18:58:57+00:00",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.ET",
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2506.02172v1",
    "title": "Different Speech Translation Models Encode and Translate Speaker Gender Differently",
    "authors": [
      "Dennis Fucci",
      "Marco Gaido",
      "Matteo Negri",
      "Luisa Bentivogli",
      "Andre Martins",
      "Giuseppe Attanasio"
    ],
    "abstract": "Recent studies on interpreting the hidden states of speech models have shown\ntheir ability to capture speaker-specific features, including gender. Does this\nfinding also hold for speech translation (ST) models? If so, what are the\nimplications for the speaker's gender assignment in translation? We address\nthese questions from an interpretability perspective, using probing methods to\nassess gender encoding across diverse ST models. Results on three language\ndirections (English-French/Italian/Spanish) indicate that while traditional\nencoder-decoder models capture gender information, newer architectures --\nintegrating a speech encoder with a machine translation system via adapters --\ndo not. We also demonstrate that low gender encoding capabilities result in\nsystems' tendency toward a masculine default, a translation bias that is more\npronounced in newer architectures.",
    "pdf_url": "http://arxiv.org/pdf/2506.02172v1",
    "published": "2025-06-02T18:58:41+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.02171v1",
    "title": "Kolmogorov-Arnold Wavefunctions",
    "authors": [
      "Paulo F. Bedaque",
      "Jacob Cigliano",
      "Hersh Kumar",
      "Srijit Paul",
      "Suryansh Rajawat"
    ],
    "abstract": "This work investigates Kolmogorov-Arnold network-based wavefunction ansatz as\nviable representations for quantum Monte Carlo simulations. Through systematic\nanalysis of one-dimensional model systems, we evaluate their computational\nefficiency and representational power against established methods. Our\nnumerical experiments suggest some efficient training methods and we explore\nhow the computational cost scales with desired precision, particle number, and\nsystem parameters. Roughly speaking, KANs seem to be 10 times cheaper\ncomputationally than other neural network based ansatz. We also introduce a\nnovel approach for handling strong short-range potentials-a persistent\nchallenge for many numerical techniques-which generalizes efficiently to\nhigher-dimensional, physically relevant systems with short-ranged strong\npotentials common in atomic and nuclear physics.",
    "pdf_url": "http://arxiv.org/pdf/2506.02171v1",
    "published": "2025-06-02T18:58:14+00:00",
    "categories": [
      "nucl-th",
      "cond-mat.dis-nn",
      "quant-ph"
    ],
    "primary_category": "nucl-th"
  },
  {
    "id": "http://arxiv.org/abs/2506.02170v1",
    "title": "Quantum Vacuum in Matter",
    "authors": [
      "Andrey Baydin",
      "Hanyu Zhu",
      "Motoaki Bamba",
      "Kaden Hazzard",
      "Junichiro Kono"
    ],
    "abstract": "An intriguing consequence of quantum field theory is that vacuum is not empty\nspace; it is full of quantum fluctuating electromagnetic fields, or virtual\nphotons, corresponding to their zero-point energy, even though the average\nnumber of photons is zero. These short-lived vacuum fluctuations are behind\nsome of the most fascinating physical processes in the universe, including\nspontaneous emission, the Lamb shift, and the Casimir force. Recent theory and\nexperiments indicate that the properties of materials placed in photonic\ncavities may be altered, even in the complete absence of any external fields,\nthrough interaction with the fluctuating vacuum electromagnetic fields.\nJudicious engineering of the quantum vacuum surrounding the matter inside a\ncavity can lead to significant and nonintuitive modifications of electronic and\nvibrational states, producing a ``vacuum dressed'' material. These exciting new\nideas have stimulated discussions regarding the fundamental physics of\nvacuum-matter interactions and also broadened the scope of potential\napplications using zero-point fluctuations to engineer materials. This\nPerspective will first discuss recent experimental and theoretical developments\non vacuum-modified condensed matter systems, which usually require the\nrealization of the so-called ultrastrong light-matter coupling regime. Then, we\nwill overview some of the most promising cavity designs for enhancing vacuum\nelectromagnetic fields in materials with various energy scales. Finally, we\nwill discuss urgent open questions and technical challenges to be solved in\nthis emerging field.",
    "pdf_url": "http://arxiv.org/pdf/2506.02170v1",
    "published": "2025-06-02T18:56:09+00:00",
    "categories": [
      "quant-ph",
      "physics.optics"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.11072v1",
    "title": "Can We Trust Machine Learning? The Reliability of Features from Open-Source Speech Analysis Tools for Speech Modeling",
    "authors": [
      "Tahiya Chowdhury",
      "Veronica Romero"
    ],
    "abstract": "Machine learning-based behavioral models rely on features extracted from\naudio-visual recordings. The recordings are processed using open-source tools\nto extract speech features for classification models. These tools often lack\nvalidation to ensure reliability in capturing behaviorally relevant\ninformation. This gap raises concerns about reproducibility and fairness across\ndiverse populations and contexts. Speech processing tools, when used outside of\ntheir design context, can fail to capture behavioral variations equitably and\ncan then contribute to bias. We evaluate speech features extracted from two\nwidely used speech analysis tools, OpenSMILE and Praat, to assess their\nreliability when considering adolescents with autism. We observed considerable\nvariation in features across tools, which influenced model performance across\ncontext and demographic groups. We encourage domain-relevant verification to\nenhance the reliability of machine learning models in clinical applications.",
    "pdf_url": "http://arxiv.org/pdf/2506.11072v1",
    "published": "2025-06-02T18:55:53+00:00",
    "categories": [
      "eess.AS",
      "cs.CL",
      "cs.CY",
      "cs.SD",
      "stat.AP",
      "K.4; J.4; I.2"
    ],
    "primary_category": "eess.AS"
  },
  {
    "id": "http://arxiv.org/abs/2506.02169v2",
    "title": "LoL-NMPC: Low-Level Dynamics Integration in Nonlinear Model Predictive Control for Unmanned Aerial Vehicles",
    "authors": [
      "Parakh M. Gupta",
      "Ondřej Procházka",
      "Jan Hřebec",
      "Matej Novosad",
      "Robert Pěnička",
      "Martin Saska"
    ],
    "abstract": "[Accepted to IROS 2025] In this paper, we address the problem of tracking\nhigh-speed agile trajectories for Unmanned Aerial Vehicles(UAVs), where model\ninaccuracies can lead to large tracking errors. Existing Nonlinear Model\nPredictive Controller(NMPC) methods typically neglect the dynamics of the\nlow-level flight controllers such as underlying PID controller present in many\nflight stacks, and this results in sub-optimal tracking performance at high\nspeeds and accelerations. To this end, we propose a novel NMPC formulation,\nLoL-NMPC, which explicitly incorporates low-level controller dynamics and motor\ndynamics in order to minimize trajectory tracking errors while maintaining\ncomputational efficiency. By leveraging linear constraints inside low-level\ndynamics, our approach inherently accounts for actuator constraints without\nrequiring additional reallocation strategies. The proposed method is validated\nin both simulation and real-world experiments, demonstrating improved tracking\naccuracy and robustness at speeds up to 98.57 km/h and accelerations of 3.5 g.\nOur results show an average 21.97 % reduction in trajectory tracking error over\nstandard NMPC formulation, with LoL-NMPC maintaining real-time feasibility at\n100 Hz on an embedded ARM-based flight computer.",
    "pdf_url": "http://arxiv.org/pdf/2506.02169v2",
    "published": "2025-06-02T18:55:03+00:00",
    "categories": [
      "cs.RO"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2506.06352v1",
    "title": "Will artificial agents pursue power by default?",
    "authors": [
      "Christian Tarsney"
    ],
    "abstract": "Researchers worried about catastrophic risks from advanced AI have argued\nthat we should expect sufficiently capable AI agents to pursue power over\nhumanity because power is a convergent instrumental goal, something that is\nuseful for a wide range of final goals. Others have recently expressed\nskepticism of these claims. This paper aims to formalize the concepts of\ninstrumental convergence and power-seeking in an abstract, decision-theoretic\nframework, and to assess the claim that power is a convergent instrumental\ngoal. I conclude that this claim contains at least an element of truth, but\nmight turn out to have limited predictive utility, since an agent's options\ncannot always be ranked in terms of power in the absence of substantive\ninformation about the agent's final goals. However, the fact of instrumental\nconvergence is more predictive for agents who have a good shot at attaining\nabsolute or near-absolute power.",
    "pdf_url": "http://arxiv.org/pdf/2506.06352v1",
    "published": "2025-06-02T18:54:18+00:00",
    "categories": [
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2506.03203v1",
    "title": "Self-Sustaining Multi-Sensor LoRa-Based Activity Monitoring for Community Workout Parks",
    "authors": [
      "Victor Luder",
      "Michele Magno"
    ],
    "abstract": "With the rise of the Internet of Things (IoT), more sensors are deployed\naround us, covering a wide range of applications from industry and agriculture\nto urban environments such as smart cities. Throughout these applications the\nsensors collect data of various characteristics and support city planners and\ndecision-makers in their work processes, ultimately maximizing the impact of\npublic funds. This paper introduces the design and implementation of a\nself-sustaining wireless sensor node designed to continuously monitor the\nutilization of community street workout parks. The proposed sensor node\nmonitors activity by leveraging acceleration data capturing micro-vibrations\nthat propagate through the steel structures of the workout equipment. This\nallows us to detect activity duration with an average measured error of only\n2.8 seconds. The sensor is optimized with an energy-aware, adaptive sampling\nand transmission algorithm which, in combination with the Long Range Wide Area\nNetwork (LoRaWAN), reduces power consumption to just 1.147 mW in normal\noperation and as low as 0.712 mW in low-power, standby mode allowing 46 days of\nbattery runtime. In addition, the integrated energy-harvesting circuit was\ntested in the field. By monitoring the battery voltage for multiple days, it\nwas shown that the sensor is capable of operating sustainably year-round\nwithout external power sources. To evaluate the sensor effectiveness, we\nconducted a week-long field test in Zurich, placing sensors at various street\nworkout parks throughout the city. Analysis of the collected data revealed\nclear patterns in park usage depending on day and location. This dataset is\nmade publicly available through our online dashboard. Finally, we showcase the\npotential of IoT for city applications in combination with an accessible data\ninterface for decision-makers.",
    "pdf_url": "http://arxiv.org/pdf/2506.03203v1",
    "published": "2025-06-02T18:52:08+00:00",
    "categories": [
      "cs.NI"
    ],
    "primary_category": "cs.NI"
  },
  {
    "id": "http://arxiv.org/abs/2506.02168v1",
    "title": "An Approximation Theory Perspective on Machine Learning",
    "authors": [
      "Hrushikesh N. Mhaskar",
      "Efstratios Tsoukanis",
      "Ameya D. Jagtap"
    ],
    "abstract": "A central problem in machine learning is often formulated as follows: Given a\ndataset $\\{(x_j, y_j)\\}_{j=1}^M$, which is a sample drawn from an unknown\nprobability distribution, the goal is to construct a functional model $f$ such\nthat $f(x) \\approx y$ for any $(x, y)$ drawn from the same distribution. Neural\nnetworks and kernel-based methods are commonly employed for this task due to\ntheir capacity for fast and parallel computation. The approximation\ncapabilities, or expressive power, of these methods have been extensively\nstudied over the past 35 years. In this paper, we will present examples of key\nideas in this area found in the literature. We will discuss emerging trends in\nmachine learning including the role of shallow/deep networks, approximation on\nmanifolds, physics-informed neural surrogates, neural operators, and\ntransformer architectures. Despite function approximation being a fundamental\nproblem in machine learning, approximation theory does not play a central role\nin the theoretical foundations of the field. One unfortunate consequence of\nthis disconnect is that it is often unclear how well trained models will\ngeneralize to unseen or unlabeled data. In this review, we examine some of the\nshortcomings of the current machine learning framework and explore the reasons\nfor the gap between approximation theory and machine learning practice. We will\nthen introduce our novel research to achieve function approximation on unknown\nmanifolds without the need to learn specific manifold features, such as the\neigen-decomposition of the Laplace-Beltrami operator or atlas construction. In\nmany machine learning problems, particularly classification tasks, the labels\n$y_j$ are drawn from a finite set of values.",
    "pdf_url": "http://arxiv.org/pdf/2506.02168v1",
    "published": "2025-06-02T18:50:18+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.02167v1",
    "title": "Fire360: A Benchmark for Robust Perception and Episodic Memory in Degraded 360-Degree Firefighting Videos",
    "authors": [
      "Aditi Tiwari",
      "Farzaneh Masoud",
      "Dac Trong Nguyen",
      "Jill Kraft",
      "Heng Ji",
      "Klara Nahrstedt"
    ],
    "abstract": "Modern AI systems struggle most in environments where reliability is critical\n- scenes with smoke, poor visibility, and structural deformation. Each year,\ntens of thousands of firefighters are injured on duty, often due to breakdowns\nin situational perception. We introduce Fire360, a benchmark for evaluating\nperception and reasoning in safety-critical firefighting scenarios. The dataset\nincludes 228 360-degree videos from professional training sessions under\ndiverse conditions (e.g., low light, thermal distortion), annotated with action\nsegments, object locations, and degradation metadata. Fire360 supports five\ntasks: Visual Question Answering, Temporal Action Captioning, Object\nLocalization, Safety-Critical Reasoning, and Transformed Object Retrieval\n(TOR). TOR tests whether models can match pristine exemplars to fire-damaged\ncounterparts in unpaired scenes, evaluating transformation-invariant\nrecognition. While human experts achieve 83.5% on TOR, models like GPT-4o lag\nsignificantly, exposing failures in reasoning under degradation. By releasing\nFire360 and its evaluation suite, we aim to advance models that not only see,\nbut also remember, reason, and act under uncertainty. The dataset is available\nat: https://uofi.box.com/v/fire360dataset.",
    "pdf_url": "http://arxiv.org/pdf/2506.02167v1",
    "published": "2025-06-02T18:45:56+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.02166v1",
    "title": "Dhvani: A Weakly-supervised Phonemic Error Detection and Personalized Feedback System for Hindi",
    "authors": [
      "Arnav Rustagi",
      "Satvik Bajpai",
      "Nimrat Kaur",
      "Siddharth Siddharth"
    ],
    "abstract": "Computer-Assisted Pronunciation Training (CAPT) has been extensively studied\nfor English. However, there remains a critical gap in its application to Indian\nlanguages with a base of 1.5 billion speakers. Pronunciation tools tailored to\nIndian languages are strikingly lacking despite the fact that millions learn\nthem every year. With over 600 million speakers and being the fourth\nmost-spoken language worldwide, improving Hindi pronunciation is a vital first\nstep toward addressing this gap. This paper proposes 1) Dhvani -- a novel CAPT\nsystem for Hindi, 2) synthetic speech generation for Hindi mispronunciations,\nand 3) a novel methodology for providing personalized feedback to learners.\nWhile the system often interacts with learners using Devanagari graphemes, its\ncore analysis targets phonemic distinctions, leveraging Hindi's highly phonetic\northography to analyze mispronounced speech and provide targeted feedback.",
    "pdf_url": "http://arxiv.org/pdf/2506.02166v1",
    "published": "2025-06-02T18:45:52+00:00",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "eess.AS"
  },
  {
    "id": "http://arxiv.org/abs/2506.02165v1",
    "title": "Scintillation Properties of PSR B1133+16 Measured with Very Long Baseline Interferometry",
    "authors": [
      "Ashley M. Stock",
      "Fardin Syed",
      "Marten H. van Kerkwijk",
      "Rebecca Lin",
      "Franz Kirsten",
      "Ue-Li Pen"
    ],
    "abstract": "The scintillation of pulsars reveals small-scale structure of the\ninterstellar medium.\n  A powerful technique for characterizing the scintillating structures\n(screens) combines analysis of scintillation arcs and very long baseline\ninterferometry (VLBI).\n  We present the results of a VLBI analysis of the scintillation arcs of PSR\nB1133+16 from simultaneous observations with Arecibo, VLA, Jodrell Bank,\nEffelsberg, and Westerbork.\n  Three arcs appear in the data set, all of which appear consistent with being\nthe result of very anisotropic scattering screens.\n  We are able to measure their orientations on the sky, down to uncertainties\nof $3^\\circ$ for the two stronger screens, and measure distances, of\n$140\\pm30$, $180\\pm20$, and $280\\pm50{\\rm\\,pc}$, consistent with, but\nsubstantially more precise than what was inferred previously from annual\nmodulation patterns in the scintillation.\n  Comparing with the differential dust extinction with distance in this\ndirection, the two nearer screens appear associated with the wall of the Local\nBubble.",
    "pdf_url": "http://arxiv.org/pdf/2506.02165v1",
    "published": "2025-06-02T18:45:13+00:00",
    "categories": [
      "astro-ph.HE",
      "astro-ph.GA",
      "astro-ph.SR"
    ],
    "primary_category": "astro-ph.HE"
  },
  {
    "id": "http://arxiv.org/abs/2506.02164v1",
    "title": "Quantifying task-relevant representational similarity using decision variable correlation",
    "authors": [
      "Yu",
      "Qian",
      "Wilson S. Geisler",
      "Xue-Xin Wei"
    ],
    "abstract": "Previous studies have compared the brain and deep neural networks trained on\nimage classification. Intriguingly, while some suggest that their\nrepresentations are highly similar, others argued the opposite. Here, we\npropose a new approach to characterize the similarity of the decision\nstrategies of two observers (models or brains) using decision variable\ncorrelation (DVC). DVC quantifies the correlation between decoded decisions on\nindividual samples in a classification task and thus can capture task-relevant\ninformation rather than general representational alignment. We evaluate this\nmethod using monkey V4/IT recordings and models trained on image classification\ntasks.\n  We find that model--model similarity is comparable to monkey--monkey\nsimilarity, whereas model--monkey similarity is consistently lower and,\nsurprisingly, decreases with increasing ImageNet-1k performance. While\nadversarial training enhances robustness, it does not improve model--monkey\nsimilarity in task-relevant dimensions; however, it markedly increases\nmodel--model similarity. Similarly, pre-training on larger datasets does not\nimprove model--monkey similarity. These results suggest a fundamental\ndivergence between the task-relevant representations in monkey V4/IT and those\nlearned by models trained on image classification tasks.",
    "pdf_url": "http://arxiv.org/pdf/2506.02164v1",
    "published": "2025-06-02T18:45:05+00:00",
    "categories": [
      "cs.CV",
      "cs.LG",
      "q-bio.NC",
      "q-bio.QM"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.02163v1",
    "title": "Search for Higgs boson decay to a charm quark-antiquark pair via $t\\bar{tH}$ production",
    "authors": [
      "Sebastian Wuchterl"
    ],
    "abstract": "In these proceedings, a search for the standard model Higgs boson decaying to\na charm quark-antiquark pair, $H\\to c\\bar{c}$, produced in association with a\ntop quark-antiquark pair ($t\\bar{tH}$) is presented. The search is performed\nusing proton-proton collision data collected by the CMS experiment at $s=13$\nTeV, corresponding to an integrated luminosity of 138 fb$^{-1}$. The Higgs\nboson decay to a bottom quark-antiquark pair is measured simultaneously and the\nobserved $t\\bar{tH(H\\to bb)}$ event rate relative to the standard model\nexpectation is found to be $0.91^{+0.26}_{-0.22}$. The observed (expected)\nupper limit at 95\\% confidence level (CL) for $t\\bar{tH(H\\to cc)}$ production\nis 7.8 (8.7) times the standard model prediction. Combined with a previous\nsearch for $H\\to c\\bar{c}$ via associated production with a W or Z boson, the\nobserved (expected) 95\\% CL interval on the Higgs-charm Yukawa coupling\nmodifier, $\\kappa_{c}$, is $\\kappa_{c} < 3.5$ ($\\kappa_{c} < 2.7$).",
    "pdf_url": "http://arxiv.org/pdf/2506.02163v1",
    "published": "2025-06-02T18:44:51+00:00",
    "categories": [
      "hep-ex"
    ],
    "primary_category": "hep-ex"
  },
  {
    "id": "http://arxiv.org/abs/2506.02162v1",
    "title": "Asymptotically exact variational flows via involutive MCMC kernels",
    "authors": [
      "Zuheng Xu",
      "Trevor Campbell"
    ],
    "abstract": "Most expressive variational families -- such as normalizing flows -- lack\npractical convergence guarantees, as their theoretical assurances typically\nhold only at the intractable global optimum. In this work, we present a general\nrecipe for constructing tuning-free, asymptotically exact variational flows\nfrom involutive MCMC kernels. The core methodological component is a novel\nrepresentation of general involutive MCMC kernels as invertible,\nmeasure-preserving iterated random function systems, which act as the flow maps\nof our variational flows. This leads to three new variational families with\nprovable total variation convergence. Our framework resolves key practical\nlimitations of existing variational families with similar guarantees (e.g.,\nMixFlows), while requiring substantially weaker theoretical assumptions.\nFinally, we demonstrate the competitive performance of our flows across tasks\nincluding posterior approximation, Monte Carlo estimates, and normalization\nconstant estimation, outperforming or matching No-U-Turn sampler (NUTS) and\nblack-box normalizing flows.",
    "pdf_url": "http://arxiv.org/pdf/2506.02162v1",
    "published": "2025-06-02T18:44:35+00:00",
    "categories": [
      "stat.CO",
      "stat.ML"
    ],
    "primary_category": "stat.CO"
  },
  {
    "id": "http://arxiv.org/abs/2506.02161v2",
    "title": "TIIF-Bench: How Does Your T2I Model Follow Your Instructions?",
    "authors": [
      "Xinyu Wei",
      "Jinrui Zhang",
      "Zeqing Wang",
      "Hongyang Wei",
      "Zhen Guo",
      "Lei Zhang"
    ],
    "abstract": "The rapid advancements of Text-to-Image (T2I) models have ushered in a new\nphase of AI-generated content, marked by their growing ability to interpret and\nfollow user instructions. However, existing T2I model evaluation benchmarks\nfall short in limited prompt diversity and complexity, as well as coarse\nevaluation metrics, making it difficult to evaluate the fine-grained alignment\nperformance between textual instructions and generated images. In this paper,\nwe present TIIF-Bench (Text-to-Image Instruction Following Benchmark), aiming\nto systematically assess T2I models' ability in interpreting and following\nintricate textual instructions. TIIF-Bench comprises a set of 5000 prompts\norganized along multiple dimensions, which are categorized into three levels of\ndifficulties and complexities. To rigorously evaluate model robustness to\nvarying prompt lengths, we provide a short and a long version for each prompt\nwith identical core semantics. Two critical attributes, i.e., text rendering\nand style control, are introduced to evaluate the precision of text synthesis\nand the aesthetic coherence of T2I models. In addition, we collect 100\nhigh-quality designer level prompts that encompass various scenarios to\ncomprehensively assess model performance. Leveraging the world knowledge\nencoded in large vision language models, we propose a novel computable\nframework to discern subtle variations in T2I model outputs. Through meticulous\nbenchmarking of mainstream T2I models on TIIF-Bench, we analyze the pros and\ncons of current T2I models and reveal the limitations of current T2I\nbenchmarks. Project Page: https://a113n-w3i.github.io/TIIF_Bench/.",
    "pdf_url": "http://arxiv.org/pdf/2506.02161v2",
    "published": "2025-06-02T18:44:07+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.02160v1",
    "title": "A Dynamic Framework for Semantic Grouping of Common Data Elements (CDE) Using Embeddings and Clustering",
    "authors": [
      "Madan Krishnamurthy",
      "Daniel Korn",
      "Melissa A Haendel",
      "Christopher J Mungall",
      "Anne E Thessen"
    ],
    "abstract": "This research aims to develop a dynamic and scalable framework to facilitate\nharmonization of Common Data Elements (CDEs) across heterogeneous biomedical\ndatasets by addressing challenges such as semantic heterogeneity, structural\nvariability, and context dependence to streamline integration, enhance\ninteroperability, and accelerate scientific discovery. Our methodology\nleverages Large Language Models (LLMs) for context-aware text embeddings that\nconvert CDEs into dense vectors capturing semantic relationships and patterns.\nThese embeddings are clustered using Hierarchical Density-Based Spatial\nClustering of Applications with Noise (HDBSCAN) to group semantically similar\nCDEs. The framework incorporates four key steps: (1) LLM-based text embedding\nto mathematically represent semantic context, (2) unsupervised clustering of\nembeddings via HDBSCAN, (3) automated labeling using LLM summarization, and (4)\nsupervised learning to train a classifier assigning new or unclustered CDEs to\nlabeled clusters. Evaluated on the NIH NLM CDE Repository with over 24,000\nCDEs, the system identified 118 meaningful clusters at an optimized minimum\ncluster size of 20. The classifier achieved 90.46 percent overall accuracy,\nperforming best in larger categories. External validation against Gravity\nProjects Social Determinants of Health domains showed strong agreement\n(Adjusted Rand Index 0.52, Normalized Mutual Information 0.78), indicating that\nembeddings effectively capture cluster characteristics. This adaptable and\nscalable approach offers a practical solution to CDE harmonization, improving\nselection efficiency and supporting ongoing data interoperability.",
    "pdf_url": "http://arxiv.org/pdf/2506.02160v1",
    "published": "2025-06-02T18:43:37+00:00",
    "categories": [
      "cs.IR",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2506.02159v1",
    "title": "Towards a gravitational network: Bridging metric-affine gravity and no-scale supergravity",
    "authors": [
      "Ioannis D. Gialamas",
      "Theodoros Katsoulas",
      "Kyriakos Tamvakis"
    ],
    "abstract": "We consider a class of models in the framework of metric-affine gravity and\nestablish their correspondence to the bosonic sector of a class of no-scale\nsupergravity models. The excellent inflationary behavior of the gravitational\nmodels considered is carried over to the corresponding supergravity ones, thus,\nenriching the landscape of inflation-compatible models.",
    "pdf_url": "http://arxiv.org/pdf/2506.02159v1",
    "published": "2025-06-02T18:42:28+00:00",
    "categories": [
      "hep-th",
      "gr-qc"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2506.02158v1",
    "title": "Reflection-Based Memory For Web navigation Agents",
    "authors": [
      "Ruhana Azam",
      "Aditya Vempaty",
      "Ashish Jagmohan"
    ],
    "abstract": "Web navigation agents have made significant progress, yet current systems\noperate with no memory of past experiences -- leading to repeated mistakes and\nan inability to learn from previous interactions. We introduce\nReflection-Augment Planning (ReAP), a web navigation system to leverage both\nsuccessful and failed past experiences using self-reflections. Our method\nimproves baseline results by 11 points overall and 29 points on previously\nfailed tasks. These findings demonstrate that reflections can transfer to\ndifferent web navigation tasks.",
    "pdf_url": "http://arxiv.org/pdf/2506.02158v1",
    "published": "2025-06-02T18:39:55+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2506.02157v1",
    "title": "HENT-SRT: Hierarchical Efficient Neural Transducer with Self-Distillation for Joint Speech Recognition and Translation",
    "authors": [
      "Amir Hussein",
      "Cihan Xiao",
      "Matthew Wiesner",
      "Dan Povey",
      "Leibny Paola Garcia",
      "Sanjeev Khudanpur"
    ],
    "abstract": "Neural transducers (NT) provide an effective framework for speech streaming,\ndemonstrating strong performance in automatic speech recognition (ASR).\nHowever, the application of NT to speech translation (ST) remains challenging,\nas existing approaches struggle with word reordering and performance\ndegradation when jointly modeling ASR and ST, resulting in a gap with\nattention-based encoder-decoder (AED) models. Existing NT-based ST approaches\nalso suffer from high computational training costs. To address these issues, we\npropose HENT-SRT (Hierarchical Efficient Neural Transducer for Speech\nRecognition and Translation), a novel framework that factorizes ASR and\ntranslation tasks to better handle reordering. To ensure robust ST while\npreserving ASR performance, we use self-distillation with CTC consistency\nregularization. Moreover, we improve computational efficiency by incorporating\nbest practices from ASR transducers, including a down-sampled hierarchical\nencoder, a stateless predictor, and a pruned transducer loss to reduce training\ncomplexity. Finally, we introduce a blank penalty during decoding, reducing\ndeletions and improving translation quality. Our approach is evaluated on three\nconversational datasets Arabic, Spanish, and Mandarin achieving new\nstate-of-the-art performance among NT models and substantially narrowing the\ngap with AED-based systems.",
    "pdf_url": "http://arxiv.org/pdf/2506.02157v1",
    "published": "2025-06-02T18:37:50+00:00",
    "categories": [
      "cs.CL",
      "eess.AS"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.02156v2",
    "title": "Mitigating Data Poisoning Attacks to Local Differential Privacy",
    "authors": [
      "Xiaolin Li",
      "Ninghui Li",
      "Boyang Wang",
      "Wenhai Sun"
    ],
    "abstract": "The distributed nature of local differential privacy (LDP) invites data\npoisoning attacks and poses unforeseen threats to the underlying LDP-supported\napplications. In this paper, we propose a comprehensive mitigation framework\nfor popular frequency estimation, which contains a suite of novel defenses,\nincluding malicious user detection, attack pattern recognition, and damaged\nutility recovery. In addition to existing attacks, we explore new adaptive\nadversarial activities for our mitigation design. For detection, we present a\nnew method to precisely identify bogus reports and thus LDP aggregation can be\nperformed over the ``clean'' data. When the attack behavior becomes stealthy\nand direct filtering out malicious users is difficult, we further propose a\ndetection that can effectively recognize hidden adversarial patterns, thus\nfacilitating the decision-making of service providers. These detection methods\nrequire no additional data and attack information and incur minimal\ncomputational cost. Our experiment demonstrates their excellent performance and\nsubstantial improvement over previous work in various settings. In addition, we\nconduct an empirical analysis of LDP post-processing for corrupted data\nrecovery and propose a new post-processing method, through which we reveal new\ninsights into protocol recommendations in practice and key design principles\nfor future research.",
    "pdf_url": "http://arxiv.org/pdf/2506.02156v2",
    "published": "2025-06-02T18:37:15+00:00",
    "categories": [
      "cs.CR"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2506.02155v1",
    "title": "Bifurcation in optimal retirement",
    "authors": [
      "Bushra Shehnam Ashraf",
      "Thomas S. Salisbury"
    ],
    "abstract": "We study optimal consumption and retirement using a Cobb-Douglas utility and\na simple model in which an interesting bifurcation arises. With high wealth,\nindividuals plan to retire. With low wealth they plan to never retire. At a\ncritical level of initial wealth they may choose to defer this decision,\nleading to a continuum of wealth trajectories with identical utilities.",
    "pdf_url": "http://arxiv.org/pdf/2506.02155v1",
    "published": "2025-06-02T18:36:38+00:00",
    "categories": [
      "q-fin.PM",
      "91G05, 91G10"
    ],
    "primary_category": "q-fin.PM"
  },
  {
    "id": "http://arxiv.org/abs/2506.02154v1",
    "title": "Z-Error Loss for Training Neural Networks",
    "authors": [
      "Guillaume Godin"
    ],
    "abstract": "Outliers introduce significant training challenges in neural networks by\npropagating erroneous gradients, which can degrade model performance and\ngeneralization. We propose the Z-Error Loss, a statistically principled\napproach that minimizes outlier influence during training by masking the\ncontribution of data points identified as out-of-distribution within each\nbatch. This method leverages batch-level statistics to automatically detect and\nexclude anomalous samples, allowing the model to focus its learning on the true\nunderlying data structure. Our approach is robust, adaptive to data quality,\nand provides valuable diagnostics for data curation and cleaning.",
    "pdf_url": "http://arxiv.org/pdf/2506.02154v1",
    "published": "2025-06-02T18:35:30+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.02153v1",
    "title": "Small Language Models are the Future of Agentic AI",
    "authors": [
      "Peter Belcak",
      "Greg Heinrich",
      "Shizhe Diao",
      "Yonggan Fu",
      "Xin Dong",
      "Saurav Muralidharan",
      "Yingyan Celine Lin",
      "Pavlo Molchanov"
    ],
    "abstract": "Large language models (LLMs) are often praised for exhibiting near-human\nperformance on a wide range of tasks and valued for their ability to hold a\ngeneral conversation. The rise of agentic AI systems is, however, ushering in a\nmass of applications in which language models perform a small number of\nspecialized tasks repetitively and with little variation.\n  Here we lay out the position that small language models (SLMs) are\nsufficiently powerful, inherently more suitable, and necessarily more\neconomical for many invocations in agentic systems, and are therefore the\nfuture of agentic AI. Our argumentation is grounded in the current level of\ncapabilities exhibited by SLMs, the common architectures of agentic systems,\nand the economy of LM deployment. We further argue that in situations where\ngeneral-purpose conversational abilities are essential, heterogeneous agentic\nsystems (i.e., agents invoking multiple different models) are the natural\nchoice. We discuss the potential barriers for the adoption of SLMs in agentic\nsystems and outline a general LLM-to-SLM agent conversion algorithm.\n  Our position, formulated as a value statement, highlights the significance of\nthe operational and economic impact even a partial shift from LLMs to SLMs is\nto have on the AI agent industry. We aim to stimulate the discussion on the\neffective use of AI resources and hope to advance the efforts to lower the\ncosts of AI of the present day. Calling for both contributions to and critique\nof our position, we commit to publishing all such correspondence at\nhttps://research.nvidia.com/labs/lpr/slm-agents.",
    "pdf_url": "http://arxiv.org/pdf/2506.02153v1",
    "published": "2025-06-02T18:35:16+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2506.11071v1",
    "title": "Embedded Acoustic Intelligence for Automotive Systems",
    "authors": [
      "Renjith Rajagopal",
      "Peter Winzell",
      "Sladjana Strbac",
      "Konstantin Lindström",
      "Petter Hörling",
      "Faisal Kohestani",
      "Niloofar Mehrzad"
    ],
    "abstract": "Transforming sound insights into actionable streams of data, this abstract\nleverages findings from degree thesis research to enhance automotive system\nintelligence, enabling us to address road type [1].By extracting and\ninterpreting acoustic signatures from microphones installed within the\nwheelbase of a car, we focus on classifying road type.Utilizing deep neural\nnetworks and feature extraction powered by pre-trained models from the Open AI\necosystem (via Hugging Face [2]), our approach enables Autonomous Driving and\nAdvanced Driver- Assistance Systems (AD/ADAS) to anticipate road surfaces,\nsupport adaptive learning for active road noise cancellation, and generate\nvaluable insights for urban planning. The results of this study were\nspecifically captured to support a compelling business case for next-generation\nautomotive systems. This forward-looking approach not only promises to redefine\npassenger comfort and improve vehicle safety, but also paves the way for\nintelligent, data-driven urban road management, making the future of mobility\nboth achievable and sustainable.",
    "pdf_url": "http://arxiv.org/pdf/2506.11071v1",
    "published": "2025-06-02T18:34:40+00:00",
    "categories": [
      "eess.AS",
      "cs.AI"
    ],
    "primary_category": "eess.AS"
  },
  {
    "id": "http://arxiv.org/abs/2506.02152v1",
    "title": "Microscopic mechanisms of Strong Electron Scattering and Giant Anomalous Hall Effect in high-Curie-temperature Fe3GaTe2 van der Waals Films",
    "authors": [
      "Zhengxiao Li",
      "Xin Lin",
      "Yu Zou",
      "Fanjie Tan",
      "Wenliang Zhu",
      "Lijun Zhu"
    ],
    "abstract": "Van der Waals ferromagnet Fe3GaTe2 with room-temperature perpendicular\nmagnetic anisotropy and strong anomalous Hall effect has attracted considerable\ninterest for their potential in spintronics. However, the microscopic\nmechanisms and manipulation of the electron scattering and the anomalous Hall\neffect of Fe3GaTe2 have remained unsettled. Here, we demonstrate strong tuning\nof the electron scattering and anomalous Hall effect of pattern-defined\nFe3GaTe2 Hall-bar devices with perpendicular magnetic anisotropy, high Curie\ntemperature (340 K, as high as that of Fe3GaTe2 bulk), and giant anomalous Hall\neffect by varying the layer thickness and temperature. Temperature-dependent\nresistivity experiments reveal that the electron scattering of the high-quality\nFe3GaTe2 is dominated by impurity scattering and phonon scattering, regardless\nof the thickness. Combined temperature- and thickness-dependent scaling\nanalyses of the anomalous Hall resistivity reveal that the anomalous Hall\neffect of the Fe3GaTe2 is predominantly from the positive,\ntemperature-independent skew-scattering contribution that competes with\nnegative temperature-independent, side-jump contribution, and negative,\ntemperature-dependent intrinsic Berry-curvature contribution. The intrinsic\nanomalous Hall conductivity decreases rapidly with increasing impurity\nscattering, which is consistent with the characteristic variation of intrinsic\nHall conductivities in the dirty-metal regime. These findings advance the\nunderstanding of electron scattering and the anomalous Hall effect in van der\nWaals magnets and would benefit the application of the Fe3GaTe2 in spintronics.",
    "pdf_url": "http://arxiv.org/pdf/2506.02152v1",
    "published": "2025-06-02T18:31:58+00:00",
    "categories": [
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2506.02151v1",
    "title": "Introduction to the theory of generalized locally Toeplitz sequences and its applications",
    "authors": [
      "Carlo Garoni"
    ],
    "abstract": "The theory of generalized locally Toeplitz (GLT) sequences was conceived as\nan apparatus for computing the spectral distribution of matrices arising from\nthe numerical discretization of differential equations (DEs). The purpose of\nthis review is to introduce the reader to the theory of GLT sequences and to\npresent some of its applications to the computation of the spectral\ndistribution of DE discretization matrices. We mainly focus on the\napplications, whereas the theory is presented in a self-contained tool-kit\nfashion, without entering into technical details. The exposition is supposed to\nbe understandable to master's degree students in mathematics. It also discloses\nnew more efficient approaches to the spectral analysis of DE discretization\nmatrices as well as a novel spectral analysis tool that has not been considered\nin the GLT literature heretofore, i.e., the modulus of integral continuity.",
    "pdf_url": "http://arxiv.org/pdf/2506.02151v1",
    "published": "2025-06-02T18:30:49+00:00",
    "categories": [
      "math.NA",
      "cs.NA",
      "15B05, 15A18, 47B06, 65N06, 65N30"
    ],
    "primary_category": "math.NA"
  },
  {
    "id": "http://arxiv.org/abs/2506.02150v1",
    "title": "Implicit Deformable Medical Image Registration with Learnable Kernels",
    "authors": [
      "Stefano Fogarollo",
      "Gregor Laimer",
      "Reto Bale",
      "Matthias Harders"
    ],
    "abstract": "Deformable medical image registration is an essential task in\ncomputer-assisted interventions. This problem is particularly relevant to\noncological treatments, where precise image alignment is necessary for tracking\ntumor growth, assessing treatment response, and ensuring accurate delivery of\ntherapies. Recent AI methods can outperform traditional techniques in accuracy\nand speed, yet they often produce unreliable deformations that limit their\nclinical adoption. In this work, we address this challenge and introduce a\nnovel implicit registration framework that can predict accurate and reliable\ndeformations. Our insight is to reformulate image registration as a signal\nreconstruction problem: we learn a kernel function that can recover the dense\ndisplacement field from sparse keypoint correspondences. We integrate our\nmethod in a novel hierarchical architecture, and estimate the displacement\nfield in a coarse-to-fine manner. Our formulation also allows for efficient\nrefinement at test time, permitting clinicians to easily adjust registrations\nwhen needed. We validate our method on challenging intra-patient thoracic and\nabdominal zero-shot registration tasks, using public and internal datasets from\nthe local University Hospital. Our method not only shows competitive accuracy\nto state-of-the-art approaches, but also bridges the generalization gap between\nimplicit and explicit registration techniques. In particular, our method\ngenerates deformations that better preserve anatomical relationships and\nmatches the performance of specialized commercial systems, underscoring its\npotential for clinical adoption.",
    "pdf_url": "http://arxiv.org/pdf/2506.02150v1",
    "published": "2025-06-02T18:27:11+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.02149v1",
    "title": "Tomographic Foundation Model -- FORCE: Flow-Oriented Reconstruction Conditioning Engine",
    "authors": [
      "Wenjun Xia",
      "Chuang Niu",
      "Ge Wang"
    ],
    "abstract": "Computed tomography (CT) is a major medical imaging modality. Clinical CT\nscenarios, such as low-dose screening, sparse-view scanning, and metal\nimplants, often lead to severe noise and artifacts in reconstructed images,\nrequiring improved reconstruction techniques. The introduction of deep learning\nhas significantly advanced CT image reconstruction. However, obtaining paired\ntraining data remains rather challenging due to patient motion and other\nconstraints. Although deep learning methods can still perform well with\napproximately paired data, they inherently carry the risk of hallucination due\nto data inconsistencies and model instability. In this paper, we integrate the\ndata fidelity with the state-of-the-art generative AI model, referred to as the\nPoisson flow generative model (PFGM) with a generalized version PFGM++, and\npropose a novel CT framework: Flow-Oriented Reconstruction Conditioning Engine\n(FORCE). In our experiments, the proposed method shows superior performance in\nvarious CT imaging tasks, outperforming existing unsupervised reconstruction\napproaches.",
    "pdf_url": "http://arxiv.org/pdf/2506.02149v1",
    "published": "2025-06-02T18:25:12+00:00",
    "categories": [
      "eess.IV",
      "cs.LG",
      "eess.SP"
    ],
    "primary_category": "eess.IV"
  },
  {
    "id": "http://arxiv.org/abs/2506.02148v2",
    "title": "Scalar fields and 3D Flat Space Cosmologies",
    "authors": [
      "Arjun Bagchi",
      "Supratik Biswas",
      "Astha Kakkar",
      "Saikat Mondal"
    ],
    "abstract": "Flat Space Cosmologies (FSC) are time-dependent solutions in Einstein gravity\nin three-dimensional (3D) spacetimes with zero cosmological constant. These are\norbifolds of 3D flat space that have a cosmological horizon and can be thought\nof as analogs of the Banados-Tietelboim-Zanelli (BTZ) black holes of AdS$_3$.\nWe study scalar perturbations about these FSC solutions and explore the\nspectrum of quasi-normal modes (QNMs) crucially treating the cosmological\nhorizon as a hard wall and extending to complex momenta. We connect this\nintrinsic analysis with the flatspace limit of the corresponding analysis in\nthe BTZ black hole. The FSC QNMs are then utilized to build the scalar one-loop\npartition function by methods pioneered by Denef, Hartnoll and Sachdev in\nvarious simplifying limits and compared with existing answers in the\nliterature.",
    "pdf_url": "http://arxiv.org/pdf/2506.02148v2",
    "published": "2025-06-02T18:23:16+00:00",
    "categories": [
      "hep-th"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2506.02147v1",
    "title": "BabyLM's First Constructions: Causal interventions provide a signal of learning",
    "authors": [
      "Joshua Rozner",
      "Leonie Weissweiler",
      "Cory Shain"
    ],
    "abstract": "Construction grammar posits that children acquire constructions (form-meaning\npairings) from the statistics of their environment. Recent work supports this\nhypothesis by showing sensitivity to constructions in pretrained language\nmodels (PLMs), including one recent study (Rozner et al., 2025) demonstrating\nthat constructions shape the PLM's output distribution. However, models under\nstudy have generally been trained on developmentally implausible amounts of\ndata, casting doubt on their relevance to human language learning. Here we use\nRozner et al.'s methods to evaluate constructional learning in models from the\n2024 BabyLM challenge. Our results show that even when trained on\ndevelopmentally plausible quantities of data, models represent diverse\nconstructions, even hard cases that are superficially indistinguishable. We\nfurther find correlational evidence that constructional performance may be\nfunctionally relevant: models that better represent constructions perform\nbetter on the BabyLM benchmarks.",
    "pdf_url": "http://arxiv.org/pdf/2506.02147v1",
    "published": "2025-06-02T18:19:38+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.02146v1",
    "title": "Weiss monotonicity and capillary hypersurfaces",
    "authors": [
      "Otis Chodosh",
      "Nick Edelen",
      "Chao Li"
    ],
    "abstract": "Previous work of the authors established the rigorous limiting behavior of\nminimizing capillary surfaces to minimizers of the Alt--Caffarelli functional\nas the capillary angle tends to zero. We prove here that in this limit, the\ncapillary area-density converges to the Weiss energy density. We apply this to\nobtain angle-independent curvature estimates and regularity results for\ncapillary minimizers.",
    "pdf_url": "http://arxiv.org/pdf/2506.02146v1",
    "published": "2025-06-02T18:18:47+00:00",
    "categories": [
      "math.AP",
      "math.DG"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2506.02145v1",
    "title": "Universal Bound on the Eigenvalues of 2-Positive Trace-Preserving Maps",
    "authors": [
      "Frederik vom Ende",
      "Dariusz Chruściński",
      "Gen Kimura",
      "Paolo Muratore-Ginanneschi"
    ],
    "abstract": "We prove an upper bound on the trace of any 2-positive, trace-preserving map\nin terms of its smallest eigenvalue. We show that this spectral bound is tight,\nand that 2-positivity is necessary for this inequality to hold in general.\nMoreover, we use this to infer a similar bound for generators of one-parameter\nsemigroups of 2-positive trace-preserving maps. With this approach we\ngeneralize known results for completely positive trace-preserving dynamics\nwhile providing a significantly simpler proof that is entirely algebraic.",
    "pdf_url": "http://arxiv.org/pdf/2506.02145v1",
    "published": "2025-06-02T18:18:00+00:00",
    "categories": [
      "math.RA",
      "math-ph",
      "math.DS",
      "math.MP",
      "quant-ph"
    ],
    "primary_category": "math.RA"
  },
  {
    "id": "http://arxiv.org/abs/2506.02144v1",
    "title": "A Pan-STARRS Search for Distant Planets: Part 1",
    "authors": [
      "Matthew J. Holman",
      "Kevin J. Napier",
      "Matthew J. Payne",
      "Jacob A. Kurlander"
    ],
    "abstract": "We present a search for distant planets in Pan-STARRS1. We calibrated our\nsearch by injecting an isotropic control population of synthetic detections\ninto Pan-STARRS1 source catalogs, providing a high-fidelity alternative to\ninjecting synthetic sources at the image level. We found that our method is\nsensitive to a wide range of distances, as well as all rates and directions of\nmotion. We identified 692 solar system objects (109 of which are not yet listed\nin the Minor Planet Center's database), including 642 TNOs, 23 of which are\ndwarf planets. By raw number of detections, this makes our search the third\nmost productive Kuiper Belt survey to date, in spite of the fact that we did\nnot explicitly search for objects closer than 80 au. Although we did not find\nPlanet Nine or any other planetary objects, we were able to show that the\nremaining parameter space for Planet Nine is highly concentrated in the\ngalactic plane.",
    "pdf_url": "http://arxiv.org/pdf/2506.02144v1",
    "published": "2025-06-02T18:13:46+00:00",
    "categories": [
      "astro-ph.EP",
      "astro-ph.IM"
    ],
    "primary_category": "astro-ph.EP"
  },
  {
    "id": "http://arxiv.org/abs/2506.02143v1",
    "title": "Green Shields: The Role of ESG in Uncertain Time",
    "authors": [
      "Fatih Kansoy",
      "Dominykas Stasiulaitis"
    ],
    "abstract": "The rapid growth of sustainable investing, now exceeding 35 trillion USD\nglobally, has transformed financial markets, yet the implications for monetary\npolicy transmission remain underexplored. While existing literature documents\nheterogeneous firm responses to monetary policy through traditional channels\nsuch as size and leverage, it remains unknown whether environmental, social,\nand governance (ESG) characteristics create distinct transmission mechanisms.\nUsing high-frequency identification around 160 Federal Reserve announcements\nfrom 2005 to 2025, we uncover an asymmetric pattern: high-ESG firms gain 1.6\nbasis points of protection from contractionary target surprises, yet suffer 2.6\nbasis points greater sensitivity to forward guidance shocks. This asymmetry\npersists within industries and intensifies with investor climate awareness.\nRemarkably, the Paris Agreement inverted these relationships: before December\n2015, high-ESG firms were more vulnerable to contractionary policy within\nindustries; afterward, they gained protection, representing a 186 basis point\nreversal. We develop a two-period model featuring heterogeneous investors with\nsustainability preferences that quantitatively matches these patterns. The\nmodel reveals how ESG investors' non-pecuniary utility creates differential\ndemand elasticities, simultaneously protecting green firms from immediate rate\nchanges while amplifying forward guidance vulnerability through their longer\ninvestment horizons. These findings establish environmental characteristics as\na new dimension of monetary policy non-neutrality, with important implications\nas sustainable finance continues expanding.",
    "pdf_url": "http://arxiv.org/pdf/2506.02143v1",
    "published": "2025-06-02T18:13:19+00:00",
    "categories": [
      "econ.GN",
      "q-fin.EC"
    ],
    "primary_category": "econ.GN"
  },
  {
    "id": "http://arxiv.org/abs/2506.02142v1",
    "title": "Gravitons on Nariai Edges",
    "authors": [
      "Y. T. Albert Law",
      "Varun Lochab"
    ],
    "abstract": "We show that, for any $d\\geq 3$, the one-loop graviton path integral on\n$S^2\\times S^{d-1}$ factorizes into bulk and edge parts. The bulk equals the\nthermal partition function of an ideal graviton gas in the Lorentzian Nariai\ngeometry. The edge factor is the inverse of the path integral over two\nidentical copies, each containing one shift-symmetric vector and three\nshift-symmetric scalars on $S^{d-1}$. Unlike the round $S^{d+1}$ case, all\nscalars are massless, indicating that graviton edge partition functions probe\nbeyond the horizon's intrinsic geometry - in contrast to $p$-form gauge\ntheories. In the course of this work, we obtain a compact formula for the\none-loop Euclidean graviton path integral on any $\\Lambda >0$ Einstein\nmanifold.",
    "pdf_url": "http://arxiv.org/pdf/2506.02142v1",
    "published": "2025-06-02T18:13:18+00:00",
    "categories": [
      "hep-th",
      "gr-qc"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2506.02141v1",
    "title": "Nonminimal infrared gravitational reheating in light of ACT",
    "authors": [
      "Ayan Chakraborty",
      "Debaprasad Maity",
      "Rajesh Mondal"
    ],
    "abstract": "Inflation is known to produce large infrared scalar fluctuations. Further, if\na scalar field $(\\chi)$ is non-minimally coupled with gravity through $\\xi\n\\chi^2 R$, those infrared modes experience \\textit{tachyonic instability}\nduring and after inflation. Those large non-perturbative infrared modes can\ncollectively produce hot Big Bang universe upon their horizon entry during the\npost-inflationary period. We indeed find that for reheating equation of state\n(EoS), $w_{\\phi} > 1/3$, and coupling strength, $\\xi>1/6$, large infrared\nfluctuations lead to successful reheating. We further analyze perturbative\nreheating by solving the standard Boltzmann equation in both Jordan and\nEinstein frames, and compare the results with the non-perturbative ones.\nFinally, embedding this infrared reheating scenario into the well-known\n$\\alpha-$attractor inflationary model, we examine possible constraints on the\nmodel parameters in light of the latest ACT, DESI results. To arrive at the\nconstraints, we take into account the latest bounds on tensor-to-scalar ratio,\n$r_{0.05}\\leq 0.038$, isocurvature power spectrum, $\\mathcal{P}_{\\mathcal{S}}\n\\lesssim 8.3\\times 10^{-11}$, and effective number of relativistic degrees of\nfreedom, $\\Delta N_{\\rm eff} \\lesssim 0.17 $. Subject to these constraints, we\nfind successful reheating to occur only for EoS $w_{\\phi}\\gtrsim 0.6$, which\ntranslates to a sub-class of $\\alpha-$attractor models being favored and\nplacing them within the 2$\\sigma$ region in the $ n_s-r$ plane of the latest\nACT, DESI data. In this range of EoS, we find that the coupling strength should\nlie within $2.11\\lesssim\\xi\\lesssim 2.95$ for $w_{\\phi}=0.6$. Finally, we\ncompute secondary gravitational wave signals induced by the scalar infrared\nmodes, which are found to be strong enough to be detected by future GW\nobservatories, namely BBO, DECIGO, LISA, and ET.",
    "pdf_url": "http://arxiv.org/pdf/2506.02141v1",
    "published": "2025-06-02T18:13:01+00:00",
    "categories": [
      "astro-ph.CO",
      "hep-ph",
      "hep-th"
    ],
    "primary_category": "astro-ph.CO"
  },
  {
    "id": "http://arxiv.org/abs/2506.02140v1",
    "title": "Sorcha: Optimized Solar System Ephemeris Generation",
    "authors": [
      "Matthew J. Holman",
      "Pedro H. Bernardinelli",
      "Megan E. Schwamb",
      "Mario Jurić",
      "Drew Oldag",
      "Maxine West",
      "Kevin J. Napier",
      "Stephanie R. Merritt",
      "Grigori Fedorets",
      "Samuel Cornwall",
      "Jacob A. Kurlander",
      "Siegfried Eggl",
      "Jeremy Kubica",
      "Kathleen Kiker",
      "Joseph Murtagh",
      "Shantanu P. Naidu",
      "Colin Orion Chandler"
    ],
    "abstract": "Sorcha is a solar system survey simulator built for the Vera C. Rubin\nObservatory's Legacy Survey of Space and Time (LSST) and future large-scale\nwide-field surveys. Over the ten-year survey, the LSST is expected to collect\nroughly a billion observations of minor planets. The task of a solar system\nsurvey simulator is to take a set of input objects (described by orbits and\nphysical properties) and determine what a real or hypothetical survey would\nhave discovered. Existing survey simulators have a computational bottleneck in\ndetermining which input objects lie in each survey field, making them\ninfeasible for LSST data scales. Sorcha can swiftly, efficiently, and\naccurately calculate the on-sky positions for sets of millions of input orbits\nand surveys with millions of visits, identifying which exposures these objects\ncross, in order for later stages of the software to make detailed estimates of\nthe apparent magnitude and detectability of those input small bodies. In this\npaper, we provide the full details of the algorithm and software behind\nSorcha's ephemeris generator. Like many of Sorcha's components, its ephemeris\ngenerator can be easily used for other surveys.",
    "pdf_url": "http://arxiv.org/pdf/2506.02140v1",
    "published": "2025-06-02T18:12:47+00:00",
    "categories": [
      "astro-ph.EP",
      "astro-ph.IM",
      "physics.comp-ph"
    ],
    "primary_category": "astro-ph.EP"
  },
  {
    "id": "http://arxiv.org/abs/2506.02139v4",
    "title": "The Unified Cognitive Consciousness Theory for Language Models: Anchoring Semantics, Thresholds of Activation, and Emergent Reasoning",
    "authors": [
      "Edward Y. Chang",
      "Zeyneb N. Kaya",
      "Ethan Chang"
    ],
    "abstract": "Unified Cognitive Consciousness Theory} (UCCT) casts them instead as vast\nunconscious pattern repositories: apparent reasoning arises only when external\nanchoring mechanisms, few shot prompts, retrieval-augmented context,\nfine-tuning, or multi-agent debate, activate task-relevant patterns. UCCT\nformalizes this process as Bayesian competition between statistical priors\nlearned in pre-training and context-driven target patterns, yielding a single\nquantitative account that unifies existing adaptation techniques. We ground the\ntheory in three principles: threshold crossing, modality universality, and\ndensity-distance predictive power, and validate them with (i) cross-domain\ndemonstrations (text QA, image captioning, multi-agent debate) and (ii) two\ndepth-oriented experiments: a controlled numeral-base study (bases 8, 9, 10)\nthat isolates pattern-density effects, and a layer-wise trajectory analysis\nthat reveals phase transitions inside a 7B-parameter model. Both experiments\nconfirm UCCT's predictions of threshold behavior, asymmetric interference, and\nmemory hysteresis. By showing that LLM ``intelligence'' is created through\nsemantic anchoring rather than contained within the model, UCCT offers a\nprincipled foundation for interpretable diagnostics and practical guidance for\nprompt engineering, model selection, and alignment-centric system design.",
    "pdf_url": "http://arxiv.org/pdf/2506.02139v4",
    "published": "2025-06-02T18:12:43+00:00",
    "categories": [
      "cs.AI",
      "I.2.7"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2506.02138v1",
    "title": "Revisiting LRP: Positional Attribution as the Missing Ingredient for Transformer Explainability",
    "authors": [
      "Yarden Bakish",
      "Itamar Zimerman",
      "Hila Chefer",
      "Lior Wolf"
    ],
    "abstract": "The development of effective explainability tools for Transformers is a\ncrucial pursuit in deep learning research. One of the most promising approaches\nin this domain is Layer-wise Relevance Propagation (LRP), which propagates\nrelevance scores backward through the network to the input space by\nredistributing activation values based on predefined rules. However, existing\nLRP-based methods for Transformer explainability entirely overlook a critical\ncomponent of the Transformer architecture: its positional encoding (PE),\nresulting in violation of the conservation property, and the loss of an\nimportant and unique type of relevance, which is also associated with\nstructural and positional features. To address this limitation, we reformulate\nthe input space for Transformer explainability as a set of position-token\npairs. This allows us to propose specialized theoretically-grounded LRP rules\ndesigned to propagate attributions across various positional encoding methods,\nincluding Rotary, Learnable, and Absolute PE. Extensive experiments with both\nfine-tuned classifiers and zero-shot foundation models, such as LLaMA 3,\ndemonstrate that our method significantly outperforms the state-of-the-art in\nboth vision and NLP explainability tasks. Our code is publicly available.",
    "pdf_url": "http://arxiv.org/pdf/2506.02138v1",
    "published": "2025-06-02T18:07:55+00:00",
    "categories": [
      "cs.LG",
      "I.2.6; I.2.7"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.02137v1",
    "title": "Line shapes in time- and angle-resolved photoemission spectroscopy explored by machine learning",
    "authors": [
      "Tami C. Meyer",
      "Gesa-R. Siemann",
      "Paulina Majchrzak",
      "Thomas Seyller",
      "Jennifer Rigden",
      "Yu Zhang",
      "Emma Springate",
      "Charlotte Sanders",
      "Philip Hofmann"
    ],
    "abstract": "Time- and angle-resolved photoemission spectroscopy is a powerful technique\nfor investigating the dynamics of excited carriers in quantum materials.\nTypically, data analysis proceeds via the inspection of time distribution\ncurves (TDCs), which represent the time-dependent photoemission intensity in a\nregion of interest -- often chosen somewhat arbitrarily -- in energy-momentum\nspace. Here, we employ $k$-means, an unsupervised machine learning technique,\nto systematically investigate trends in TDC line shape for quasi-free-standing\nmonolayer graphene and for a simple analytical model. Our analysis reveals how\nfinite energy and time resolution can affect the TDC line shape. We discuss how\nthis can be taken into account in a quantitative analysis, and under what\nconditions the time-dependent photoemission intensity after laser excitation\ncan be approximated by a simple exponential decay.",
    "pdf_url": "http://arxiv.org/pdf/2506.02137v1",
    "published": "2025-06-02T18:07:26+00:00",
    "categories": [
      "cond-mat.str-el"
    ],
    "primary_category": "cond-mat.str-el"
  },
  {
    "id": "http://arxiv.org/abs/2506.02136v1",
    "title": "Attracting measures",
    "authors": [
      "Julian Newman",
      "Peter Ashwin"
    ],
    "abstract": "Under mild assumptions, the SRB measure $\\mu$ associated to an Axiom A\nattractor $A$ has the following properties: (i) the empirical measure starting\nat a typical point near $A$ converges weakly to $\\mu$; (ii) the pushforward of\nany Lebesgue-absolutely continuous probability measure supported near $A$\nconverges weakly to $\\mu$. In general, a measure with the first property is\ncalled a \"physical measure\", and physical measures are recognised as generally\nimportant in their own right. In this paper, we highlight the second property\nas also important in its own right, and we prove a result that serves as a\ntopological abstraction of the original result that establishes the second\nproperty for SRB measures on Axiom A attractors.",
    "pdf_url": "http://arxiv.org/pdf/2506.02136v1",
    "published": "2025-06-02T18:06:37+00:00",
    "categories": [
      "math.DS"
    ],
    "primary_category": "math.DS"
  },
  {
    "id": "http://arxiv.org/abs/2506.02135v3",
    "title": "Analysis of Multiple Long-Run Relations in Panel Data Models",
    "authors": [
      "Alexander Chudik",
      "M. Hashem Pesaran",
      "Ron P. Smith"
    ],
    "abstract": "The literature on panel cointegration is extensive but does not cover data\nsets where the cross section dimension, $n$, is larger than the time series\ndimension $T$. This paper proposes a novel methodology that filters out the\nshort run dynamics using sub-sample time averages as deviations from their\nfull-sample counterpart, and estimates the number of long-run relations and\ntheir coefficients using eigenvalues and eigenvectors of the pooled covariance\nmatrix of these sub-sample deviations. We refer to this procedure as pooled\nminimum eigenvalue (PME). We show that PME estimator is consistent and\nasymptotically normal as $n$ and $T \\rightarrow \\infty$ jointly, such that\n$T\\approx n^{d}$, with $d>0$ for consistency and $d>1/2$ for asymptotic\nnormality. Extensive Monte Carlo studies show that the number of long-run\nrelations can be estimated with high precision, and the PME estimators have\ngood size and power properties. The utility of our approach is illustrated by\nmicro and macro applications using Compustat and Penn World Tables.",
    "pdf_url": "http://arxiv.org/pdf/2506.02135v3",
    "published": "2025-06-02T18:06:23+00:00",
    "categories": [
      "econ.EM"
    ],
    "primary_category": "econ.EM"
  },
  {
    "id": "http://arxiv.org/abs/2506.02134v1",
    "title": "ReconXF: Graph Reconstruction Attack via Public Feature Explanations on Privatized Node Features and Labels",
    "authors": [
      "Rishi Raj Sahoo",
      "Rucha Bhalchandra Joshi",
      "Subhankar Mishra"
    ],
    "abstract": "Graph Neural Networks (GNNs) achieve high performance across many\napplications but function as black-box models, limiting their use in critical\ndomains like healthcare and criminal justice. Explainability methods address\nthis by providing feature-level explanations that identify important node\nattributes for predictions. These explanations create privacy risks. Combined\nwith auxiliary information, feature explanations can enable adversaries to\nreconstruct graph structure, exposing sensitive relationships. Existing graph\nreconstruction attacks assume access to original auxiliary data, but practical\nsystems use differential privacy to protect node features and labels while\nproviding explanations for transparency. We study a threat model where\nadversaries access public feature explanations along with privatized node\nfeatures and labels. We show that existing explanation-based attacks like GSEF\nperform poorly with privatized data due to noise from differential privacy\nmechanisms. We propose ReconXF, a graph reconstruction attack for scenarios\nwith public explanations and privatized auxiliary data. Our method adapts\nexplanation-based frameworks by incorporating denoising mechanisms that handle\ndifferential privacy noise while exploiting structural signals in explanations.\nExperiments across multiple datasets show ReconXF outperforms SoTA methods in\nprivatized settings, with improvements in AUC and average precision. Results\nindicate that public explanations combined with denoising enable graph\nstructure recovery even under the privacy protection of auxiliary data. Code is\navailable at (link to be made public after acceptance).",
    "pdf_url": "http://arxiv.org/pdf/2506.02134v1",
    "published": "2025-06-02T18:06:02+00:00",
    "categories": [
      "cs.LG",
      "I.2.6; K.6.5"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.02133v1",
    "title": "Characterization of latency and jitter in TSN emulation",
    "authors": [
      "Álex Gracia",
      "José Luis Briz",
      "Héctor Blanco-Alcaine",
      "Juan Segarra",
      "Alitzel G. Torres-Macías",
      "Antonio Ramírez-Treviño"
    ],
    "abstract": "This research focuses on timestamping methods for profiling network traffic\nin software-based environments. Accurate timestamping is crucial for evaluating\nnetwork performance, particularly in Time-Sensitive Networking (TSN). We\nexplore and compare four timestamping techniques within a TSN emulation\ncontext, though its findings extend to other network scenarios. The study\nleverages the Mininet emulator to model TSN networks, defining hosts, bridges,\nlinks, and traffic streams. It characterizes bridge latencies and jitter,\nsolves the TSN scheduling problem based on measured parameters, and evaluates\nthe correctness of a deployed schedule for a use case. Key contributions\ninclude a methodology for software-based timestamping, solutions for TSN\nemulation challenges in Linux and Mininet, and experimental insights for\noptimizing TSN emulation platforms on various system configurations, with and\nwithout Intel TCC, either on a high-end workstation or on an industrial PC.",
    "pdf_url": "http://arxiv.org/pdf/2506.02133v1",
    "published": "2025-06-02T18:04:15+00:00",
    "categories": [
      "cs.NI"
    ],
    "primary_category": "cs.NI"
  },
  {
    "id": "http://arxiv.org/abs/2506.02132v3",
    "title": "Model Internal Sleuthing: Finding Lexical Identity and Inflectional Morphology in Modern Language Models",
    "authors": [
      "Michael Li",
      "Nishant Subramani"
    ],
    "abstract": "Large transformer-based language models dominate modern NLP, yet our\nunderstanding of how they encode linguistic information is rooted in studies of\nearly models like BERT and GPT-2. To better understand today's language models,\nwe investigate how 25 models - from classical architectures (BERT, DeBERTa,\nGPT-2) to modern large language models (Pythia, OLMo-2, Gemma-2, Qwen2.5,\nLlama-3.1) - represent lexical identity and inflectional morphology across six\ntypologically diverse languages. Using linear and nonlinear classifiers trained\non hidden activations, we predict word lemmas and inflectional features layer\nby layer. We find that models concentrate lexical information linearly in early\nlayers and increasingly nonlinearly in later layers, while keeping inflectional\ninformation uniformly accessible and linearly separable throughout. Additional\nexperiments probe the nature of these encodings: attention and residual\nanalyses examine where within layers information can be recovered, steering\nvector experiments test what information can be functionally manipulated, and\nintrinsic dimensionality analyses explore how the representational structure\nevolves across layers. Remarkably, these encoding patterns emerge across all\nmodels we test, despite differences in architecture, size, and training regime\n(pretrained and instruction-tuned variants). This suggests that, even with\nsubstantial advances in LLM technologies, transformer models organize\nlinguistic information in similar ways, indicating that these properties are\nimportant for next token prediction and are learned early during pretraining.\nOur code is available at https://github.com/ml5885/model_internal_sleuthing",
    "pdf_url": "http://arxiv.org/pdf/2506.02132v3",
    "published": "2025-06-02T18:01:56+00:00",
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.02131v1",
    "title": "Quantum correlation beyond entanglement: Holographic discord and multipartite generalizations",
    "authors": [
      "Takato Mori"
    ],
    "abstract": "While entanglement is a cornerstone of quantum theory and holography, quantum\ncorrelations arising from superposition, such as quantum discord, offer a\nbroader perspective that has remained largely unexplored in holography. We\nconstruct gravity duals of quantum discord and classical correlation. In both\nholographic systems and Haar random states, discord exceeds entanglement,\nrevealing an additional quantum correlation linked to the Markov gap and\nnon-distillable entanglement, suggesting holographic states are intrinsically\nnon-bipartite. In black hole setups, discord can increase despite decoherence\nand persists beyond the sudden death of distillable entanglement. Motivated by\nthe holographic formula, we define reflected discord -- an optimization-free\nboundary quantity based on reflected entropy -- which remains effective even\noutside the holographic regime. We also propose several multipartite\ngeneralizations of discord, including a holography-inspired one based on\nmulti-entropy. These results provide new tools for quantifying quantum\ncorrelations beyond entanglement in strongly coupled many-body systems and\noffer a novel approach to multipartite correlation measures.",
    "pdf_url": "http://arxiv.org/pdf/2506.02131v1",
    "published": "2025-06-02T18:01:09+00:00",
    "categories": [
      "hep-th",
      "cond-mat.str-el",
      "gr-qc",
      "quant-ph"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2506.02129v1",
    "title": "Benchmarking Large Language Models for Polymer Property Predictions",
    "authors": [
      "Sonakshi Gupta",
      "Akhlak Mahmood",
      "Shivank Shukla",
      "Rampi Ramprasad"
    ],
    "abstract": "Machine learning has revolutionized polymer science by enabling rapid\nproperty prediction and generative design. Large language models (LLMs) offer\nfurther opportunities in polymer informatics by simplifying workflows that\ntraditionally rely on large labeled datasets, handcrafted representations, and\ncomplex feature engineering. LLMs leverage natural language inputs through\ntransfer learning, eliminating the need for explicit fingerprinting and\nstreamlining training. In this study, we finetune general purpose LLMs --\nopen-source LLaMA-3-8B and commercial GPT-3.5 -- on a curated dataset of 11,740\nentries to predict key thermal properties: glass transition, melting, and\ndecomposition temperatures. Using parameter-efficient fine-tuning and\nhyperparameter optimization, we benchmark these models against traditional\nfingerprinting-based approaches -- Polymer Genome, polyGNN, and polyBERT --\nunder single-task (ST) and multi-task (MT) learning. We find that while\nLLM-based methods approach traditional models in performance, they generally\nunderperform in predictive accuracy and efficiency. LLaMA-3 consistently\noutperforms GPT-3.5, likely due to its tunable open-source architecture.\nAdditionally, ST learning proves more effective than MT, as LLMs struggle to\ncapture cross-property correlations, a key strength of traditional methods.\nAnalysis of molecular embeddings reveals limitations of general purpose LLMs in\nrepresenting nuanced chemo-structural information compared to handcrafted\nfeatures and domain-specific embeddings. These findings provide insight into\nthe interplay between molecular embeddings and natural language processing,\nguiding LLM selection for polymer informatics.",
    "pdf_url": "http://arxiv.org/pdf/2506.02129v1",
    "published": "2025-06-02T18:01:07+00:00",
    "categories": [
      "cs.CE"
    ],
    "primary_category": "cs.CE"
  },
  {
    "id": "http://arxiv.org/abs/2506.02130v1",
    "title": "fftvis: A Non-Uniform Fast Fourier Transform Based Interferometric Visibility Simulator",
    "authors": [
      "Tyler A. Cox",
      "Steven G. Murray",
      "Aaron R. Parsons",
      "Joshua S. Dillon",
      "Kartik Mandar",
      "Zachary E. Martinot",
      "Robert Pascua",
      "Piyanat Kittiwisit",
      "James E. Aguirre"
    ],
    "abstract": "The detection and characterization of the 21cm signal from the Epoch of\nReionization (EoR) demands extraordinary precision in radio interferometric\nobservations and analysis. For modern low-frequency arrays, achieving the\ndynamic range necessary to detect this signal requires simulation frameworks to\nvalidate analysis techniques and characterize systematic effects. However, the\ncomputational expense of direct visibility calculations grows rapidly with sky\nmodel complexity and array size, posing a potential bottleneck for scalable\nforward modeling. In this paper, we present fftvis, a high-performance\nvisibility simulator built on the Flatiron Non-Uniform Fast-Fourier Transform\n(finufft) algorithm. We show that fftvis matches the well-validated matvis\nsimulator to near numerical precision while delivering substantial runtime\nreductions, up to two orders of magnitude for dense, many-element arrays. We\nprovide a detailed description of the fftvis algorithm and benchmark its\ncomputational performance, memory footprint, and numerical accuracy against\nmatvis, including a validation study against analytic solutions for diffuse sky\nmodels. We further assess the utility of fftvis in validating 21cm analysis\npipelines through a study of the dynamic range in simulated delay and\nfringe-rate spectra. Our results establish fftvis as a fast, precise, and\nscalable simulation tool for 21cm cosmology experiments, enabling end-to-end\nvalidation of analysis pipelines.",
    "pdf_url": "http://arxiv.org/pdf/2506.02130v1",
    "published": "2025-06-02T18:01:07+00:00",
    "categories": [
      "astro-ph.IM"
    ],
    "primary_category": "astro-ph.IM"
  },
  {
    "id": "http://arxiv.org/abs/2506.02127v3",
    "title": "Quantum Complexity and Chaos in Many-Qudit Doped Clifford Circuits",
    "authors": [
      "Beatrice Magni",
      "Xhek Turkeshi"
    ],
    "abstract": "We investigate the emergence of quantum complexity and chaos in doped\nClifford circuits acting on qudits of odd prime dimension $d$. Using doped\nClifford Weingarten calculus and a replica tensor network formalism, we derive\nexact results and perform large-scale simulations in regimes challenging for\ntensor network and Pauli-based methods. We begin by analyzing generalized\nstabilizer entropies, computable magic monotones in many-qudit systems, and\nidentify a dynamical phase transition in the doping rate, marking the breakdown\nof classical simulability and the onset of Haar-random behavior. The critical\nbehavior is governed by the qudit dimension and the magic content of the\nnon-Clifford gate. Using the qudit $T$-gate as a benchmark, we show that\nhigher-dimensional qudits converge faster to Haar-typical stabilizer entropies.\nFor qutrits ($d=3$), analytical predictions match numerics on brickwork\ncircuits, showing that locality plays a limited role in magic spreading. We\nalso examine anticoncentration and entanglement growth, showing that $O(\\log\nN)$ non-Clifford gates suffice for approximating Haar expectation values to\nprecision $\\varepsilon$, and relate antiflatness measures to stabilizer\nentropies in qutrit systems. Finally, we analyze out-of-time-order correlators\nand show that a finite density of non-Clifford gates is needed to induce chaos,\nwith a sharp transition fixed by the local dimension, twice that of the magic\ntransition. Altogether, these results establish a unified framework for\ndiagnosing complexity in doped Clifford circuits and deepen our understanding\nof resource theories in multiqudit systems.",
    "pdf_url": "http://arxiv.org/pdf/2506.02127v3",
    "published": "2025-06-02T18:01:01+00:00",
    "categories": [
      "quant-ph",
      "cond-mat.stat-mech"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.02128v2",
    "title": "Anyon delocalization transitions out of a disordered FQAH insulator",
    "authors": [
      "Zhengyan Darius Shi",
      "T. Senthil"
    ],
    "abstract": "Motivated by the experimental discovery of the fractional quantum anomalous\nHall (FQAH) effect, we develop a theory of doping-induced transitions out of\nthe $\\nu = 2/3$ lattice Jain state in the presence of quenched disorder. We\nshow that disorder strongly affects the evolution into the conducting phases\ndescribed in our previous work. The delocalization of charge $2/3$ anyons leads\nto a chiral topological superconductor through a direct second order transition\nfor a smooth random potential with long-wavelength modulations. The\nlongitudinal resistance has a universal peak at the associated quantum critical\npoint. Close to the transition, we show that the superconducting ground state\nis an ``Anomalous Vortex Glass (AVG)'' stabilized in the absence of an external\nmagnetic field. For short-wavelength disorder, this transition generically\nsplits into three distinct ones with intermediate insulating topological\nphases. If instead, the charge $1/3$ anyon delocalizes, then at low doping the\nresult is a Reentrant Integer Quantum Hall state with $\\rho_{xy} = h/e^2$. At\nhigher doping this undergoes a second transition to a Fermi liquid metal. We\nshow that this framework provides a plausible explanation for the complex phase\ndiagram recently observed in twisted MoTe$_2$ near $\\nu = 2/3$ and discuss\nfuture experiments that can test our theory in more detail.",
    "pdf_url": "http://arxiv.org/pdf/2506.02128v2",
    "published": "2025-06-02T18:01:01+00:00",
    "categories": [
      "cond-mat.str-el"
    ],
    "primary_category": "cond-mat.str-el"
  },
  {
    "id": "http://arxiv.org/abs/2506.02126v1",
    "title": "Knowledge or Reasoning? A Close Look at How LLMs Think Across Domains",
    "authors": [
      "Juncheng Wu",
      "Sheng Liu",
      "Haoqin Tu",
      "Hang Yu",
      "Xiaoke Huang",
      "James Zou",
      "Cihang Xie",
      "Yuyin Zhou"
    ],
    "abstract": "Recent advances in reasoning-enhanced Large Language Models such as\nOpenAI-o1/3 and DeepSeek-R1 have significantly improved performance on complex\ntasks. However, the quality and transparency of their internal reasoning\nprocesses remain underexplored. This work moves beyond the final-answer\naccuracy and investigates step-by-step reasoning in the medical and\nmathematical domains by explicitly decomposing the thinking trajectories into\ntwo parts: knowledge and reasoning. Specifically, we introduce a fine-grained\nevaluation framework that judges: (1) the correctness of knowledge used\n(measured by Knowledge Index (KI)) and (2) the quality of reasoning (measured\nby Information Gain (InfoGain)). Using this framework, we study R1-distilled\nand base Qwen models trained with supervised fine-tuning (SFT) and/or\nreinforcement learning (RL) in the medical and math domains. Three intriguing\nfindings emerge: (1) The general reasoning abilities in R1-distilled models do\nnot transfer effectively to the medical domain through either SFT or RL. (2)\nSFT raises final-answer accuracy in both domains, but often at the cost of\nreasoning quality: InfoGain drops by 38.9% on average compared with untrained\nmodels; In the medical domain, however, SFT remains crucial because domain\nknowledge is indispensable. (3) RL enhances medical reasoning by pruning\ninaccurate or irrelevant knowledge from reasoning paths, thereby improving both\nreasoning accuracy and knowledge correctness.",
    "pdf_url": "http://arxiv.org/pdf/2506.02126v1",
    "published": "2025-06-02T18:01:00+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.02125v1",
    "title": "Descriptive History Representations: Learning Representations by Answering Questions",
    "authors": [
      "Guy Tennenholtz",
      "Jihwan Jeong",
      "Chih-Wei Hsu",
      "Yinlam Chow",
      "Craig Boutilier"
    ],
    "abstract": "Effective decision making in partially observable environments requires\ncompressing long interaction histories into informative representations. We\nintroduce Descriptive History Representations (DHRs): sufficient statistics\ncharacterized by their capacity to answer relevant questions about past\ninteractions and potential future outcomes. DHRs focus on capturing the\ninformation necessary to address task-relevant queries, providing a structured\nway to summarize a history for optimal control. We propose a multi-agent\nlearning framework, involving representation, decision, and question-asking\ncomponents, optimized using a joint objective that balances reward maximization\nwith the representation's ability to answer informative questions. This yields\nrepresentations that capture the salient historical details and predictive\nstructures needed for effective decision making. We validate our approach on\nuser modeling tasks with public movie and shopping datasets, generating\ninterpretable textual user profiles which serve as sufficient statistics for\npredicting preference-driven behavior of users.",
    "pdf_url": "http://arxiv.org/pdf/2506.02125v1",
    "published": "2025-06-02T18:00:41+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2506.02124v1",
    "title": "The Relationship Between Eddington Ratio and Column Density in U/LIRG AGN",
    "authors": [
      "Jaya Nagarajan-Swenson",
      "George C. Privon",
      "Aaron S. Evans",
      "Loreto Barcos-Muñoz",
      "Claudio Ricci",
      "Anne M. Medling",
      "Vivian U",
      "Alejandro Saravia",
      "Kara N. Green",
      "Makoto Johnstone",
      "Gabriela A. Meza"
    ],
    "abstract": "The local X-ray AGN population appears to follow a growth cycle regulated by\nthe AGN's own radiation, marked by changes in their obscuration and Eddington\nratio during accretion events. Because AGN in infrared-selected galaxies are\nmore likely to be Compton-thick and have evidence for over-massive black holes,\nwe explore whether infrared-selected AGN follow the radiation-regulated AGN\ngrowth scheme. We calculate the Eddington ratios of nine U/LIRG AGN with\ndynamical BH mass measurements, finding that though the number of objects is\nlimited, AGN in IR-selected galaxies appear consistent with radiation\npressure-regulated growth. We suggest that enlarging the sample of dynamical BH\nmass measurements in IR-selected systems will provide more stringent tests of\nwhether their AGN are primarily regulated by radiation pressure.",
    "pdf_url": "http://arxiv.org/pdf/2506.02124v1",
    "published": "2025-06-02T18:00:20+00:00",
    "categories": [
      "astro-ph.GA",
      "astro-ph.HE"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2506.02123v1",
    "title": "CLUES III: Do User Choices Impact The Results of SED Fitting? Tests of 'Off-The-Shelf' Stellar Population and Dust Extinction Models in the CLUES Sample",
    "authors": [
      "Andrew Mizener",
      "Daniela Calzetti",
      "Angela Adamo",
      "Aida Wofford",
      "Matthew J. Hayes",
      "John Chisholm",
      "Michele Fumagalli",
      "Svea Hernandez",
      "Matteo Maria Messa",
      "Linda J. Smith",
      "Arjan Bik",
      "Kathryn Grasha",
      "Mattia Sirressi"
    ],
    "abstract": "The simple stellar population models produced by stellar population and\nspectral synthesis (SPS) codes are used as spectral templates in a variety of\nastrophysical contexts. In this paper, we test the predictions of four commonly\nused stellar population synthesis codes (YGGDRASIL, BPASS, FSPS, and a modified\nform of GALAXEV which we call GALAXEVneb) by using them as spectral templates\nfor photometric SED fitting with a sample of 18 young stellar clusters. All\nclusters have existing HST COS FUV spectroscopy that provide constraints on\ntheir ages as well as broadband photometry from HST ACS and WFC3. We use model\nspectra that account for both nebular and stellar emission, and additionally\ntest four extinction curves at different values of $R_V$. We find that for\nindividual clusters, choice of extinction curve and SPS model can introduce\nsignificant scatter into the results of SED fitting. Model choice can introduce\nscatter of 34.8 Myr in age, a factor of 9.5 in mass, and 0.40mag in extinction.\nExtinction curve choice can introduce scatter of up to a factor of 32.3 Myr in\nage, a factor of 10.4 in mass, and 0.41mag in extinction. We caution that\nbecause of this scatter, one-to-one comparisons between the properties of\nindividual objects derived using different SED fitting setups may not be\nmeaningful. However, our results also suggest that SPS model and extinction\ncurve choice do not introduce major systematic differences into SED fitting\nresults when the entire cluster population is considered. The distribution of\ncluster properties for a large enough sample is relatively robust to user\nchoice of SPS code and extinction curve.",
    "pdf_url": "http://arxiv.org/pdf/2506.02123v1",
    "published": "2025-06-02T18:00:18+00:00",
    "categories": [
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2506.02122v2",
    "title": "Uplifting, Depressing, and Tilting Dark Energy",
    "authors": [
      "Eric V. Linder"
    ],
    "abstract": "Current data in the form of baryon acoustic oscillation, supernova, and\ncosmic microwave background distances prefer a cosmology that accelerates more\nstrongly than $\\Lambda$CDM at $z\\approx0.5-1.5$, and more weakly at\n$z\\lesssim0.5$. We examine dark energy physics that can accommodate this,\nshowing that interactions (decays, coupling to matter, nonminimal coupling to\ngravity) fairly generically tend not to give a satisfactory solution (in terms\nof fitting both distances and growth) even if they enable the effective dark\nenergy equation of state to cross $w=-1$. To fit the cosmological data it\nappears the dark energy by itself must cross $w=-1$, a highly unusual physical\nbehavior.",
    "pdf_url": "http://arxiv.org/pdf/2506.02122v2",
    "published": "2025-06-02T18:00:08+00:00",
    "categories": [
      "astro-ph.CO"
    ],
    "primary_category": "astro-ph.CO"
  },
  {
    "id": "http://arxiv.org/abs/2506.02119v1",
    "title": "Symmetries and conservation laws in discrete spacetime",
    "authors": [
      "Samuel Richard Totorica"
    ],
    "abstract": "Noether's theorem connects symmetries to invariants in continuous systems,\nhowever its extension to discrete systems has remained elusive. Recognizing the\nlowest-order finite difference as the foundation of local continuity, a viable\nmethod for obtaining discrete conservation laws is developed by working in\nexact analogy to the continuous Noether's theorem. A detailed application is\ngiven to electromagnetism, where energy-momentum conservation laws are rapidly\nobtained in highly generalized forms that disrupt conventional notions\nregarding conservative algorithms. Field-matter couplings and energy-momentum\ntensors with optional deviations at the discreteness scale properly reduce in\nthe continuous limit. Nonlocal symmetries give rise to an additional\nconservation channel for each spacetime displacement, permitting generalized\nnonlocal couplings. Prescriptions for conservative particle integrators emerge\ndirectly from field-matter coupling terms, enabling the development of fully\nexplicit, energy-conserving particle-in-cell algorithms. The demonstration of\nexact conservation laws in discrete spacetime that preserve canonical structure\nhas deep implications for numerical algorithms and fundamental physics.",
    "pdf_url": "http://arxiv.org/pdf/2506.02119v1",
    "published": "2025-06-02T18:00:07+00:00",
    "categories": [
      "astro-ph.HE",
      "physics.plasm-ph"
    ],
    "primary_category": "astro-ph.HE"
  },
  {
    "id": "http://arxiv.org/abs/2506.02120v2",
    "title": "Random-key genetic algorithms: Principles and applications",
    "authors": [
      "Mariana A. Londe",
      "Luciana S. Pessoa",
      "Carlos E. Andrade",
      "José F. Gonçalves",
      "Mauricio G. C. Resende"
    ],
    "abstract": "A random-key genetic algorithm is an evolutionary metaheuristic for discrete\nand global optimization. Each solution is encoded as a vector of N random keys,\nwhere a random key is a real number randomly generated in the continuous\ninterval [0, 1). A decoder maps each vector of random keys to a solution of the\noptimization problem being solved and computes its cost. The benefit of this\napproach is that all genetic operators and transformations can be maintained\nwithin the unitary hypercube, regardless of the problem being addressed. This\nenhances the productivity and maintainability of the core framework. The\nalgorithm starts with a population of P vectors of random keys. At each\niteration, the vectors are partitioned into two sets: a smaller set of\nhigh-valued elite solutions and the remaining non-elite solutions. All elite\nelements are copied, without change, to the next population. A small number of\nrandom-key vectors (the mutants) is added to the population of the next\niteration. The remaining elements of the population of the next iteration are\ngenerated by combining, with the parametrized uniform crossover of Spears and\nDeJong (1991), pairs of solutions. This chapter reviews random-key genetic\nalgorithms and describes an effective variant called biased random-key genetic\nalgorithms.",
    "pdf_url": "http://arxiv.org/pdf/2506.02120v2",
    "published": "2025-06-02T18:00:07+00:00",
    "categories": [
      "cs.NE",
      "cs.AI",
      "math.OC",
      "90-02, 90B40, 90C27",
      "G.1.6; G.2.1; I.2.8"
    ],
    "primary_category": "cs.NE"
  },
  {
    "id": "http://arxiv.org/abs/2506.02121v1",
    "title": "A GPU Code for Finding Microlensing Critical Curves and Caustics",
    "authors": [
      "Luke Weisenbach"
    ],
    "abstract": "Advancements in analyses of caustic crossing events in gravitationally\nmicrolensed quasars and supernovae can benefit from numerical simulations which\nlocate the caustics in conjunction with the creation of magnification maps. We\npresent a GPU code which efficiently solves this problem; the code is available\nat https://github.com/weisluke/microlensing/. We discuss how the locations of\nthe microcaustics can be used to determine the number of caustic crossings and\nthe distances to caustics, both of which can be used to constrain the space of\nnuisance parameters such as source position and velocity within magnification\nmaps.",
    "pdf_url": "http://arxiv.org/pdf/2506.02121v1",
    "published": "2025-06-02T18:00:07+00:00",
    "categories": [
      "astro-ph.GA",
      "astro-ph.IM"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2506.02118v1",
    "title": "SN 2024bfu, SN 2025qe, and the early light curves of type Iax supernovae",
    "authors": [
      "M. R. Magee",
      "T. L. Killestein",
      "M. Pursiainen",
      "B. Godson",
      "D. Jarvis",
      "C. Jiménez-Palau",
      "J. D. Lyman",
      "D. Steeghs",
      "B. Warwick",
      "J. P. Anderson",
      "T. Butterley",
      "T. -W. Chen",
      "V. S. Dhillon",
      "L. Galbany",
      "S. González-Gaitán",
      "M. Gromadzki",
      "C. Inserra",
      "L. Kelsey",
      "A. Kumar",
      "G. Leloudas",
      "S. Mattila",
      "T. E. Müller-Bravo",
      "K. Noysena",
      "G. Ramsay",
      "S. Srivastav",
      "R. Starling",
      "R. W. Wilson",
      "D. R. Young",
      "K. Ackley",
      "R. P. Breton",
      "J. Casares Velázquez",
      "M. J. Dyer",
      "D. K. Galloway",
      "E. Kankare",
      "R. Kotak",
      "L. K. Nuttall",
      "D. O'Neill",
      "P. Pessi",
      "D. Pollacco",
      "K. Ulaczyk",
      "O. Yaron"
    ],
    "abstract": "Type Iax supernovae (SNe Iax) are perhaps the most numerous class of peculiar\nthermonuclear supernova and yet their sample size, particularly those observed\nshortly after explosion, remains relatively small. In this paper we present\nphotometric and spectroscopic observations of two SNe Iax discovered shortly\nafter explosion, SN 2024bfu and SN 2025qe. Both SNe were observed by multiple\nall-sky surveys, enabling tight constraints on the moment of first light and\nthe shape of the early light curve. Our observations of SN 2025qe begin <2 d\nafter the estimated time of first light and represent some of the earliest\nobservations of any SN Iax. We identify features consistent with carbon\nabsorption throughout the spectroscopic evolution of SN 2025qe, potentially\nindicating the presence of unburned material throughout the ejecta. Inspired by\nour early light curve coverage, we gather a sample of SNe Iax observed by\nATLAS, GOTO, and ZTF, and measure their rise times and early light curve\npower-law rise indices. We compare our findings to a sample of normal SNe Ia\nand find indications that SNe Iax show systematically shorter rise times, but\nthe small sample size and relatively large uncertainties prevent us from\nidentifying statistically significant differences in most bands. We find some\nindication that SNe Iax show systematically lower rise indices than normal SNe\nIa in all bands. The low rise indices observed among SNe Iax is qualitatively\nconsistent with extended $^{56}$Ni distributions and more thoroughly-mixed\nejecta compared to normal SNe Ia, similar to predictions from pure deflagration\nexplosions.",
    "pdf_url": "http://arxiv.org/pdf/2506.02118v1",
    "published": "2025-06-02T18:00:06+00:00",
    "categories": [
      "astro-ph.HE",
      "astro-ph.SR"
    ],
    "primary_category": "astro-ph.HE"
  },
  {
    "id": "http://arxiv.org/abs/2506.02117v1",
    "title": "Black Shell Thermodynamics",
    "authors": [
      "Ulf Danielsson",
      "Vyshnav Mohan",
      "Larus Thorlacius"
    ],
    "abstract": "Black shells have been proposed as black hole mimickers, i.e. horizonless\nultra-compact objects that replace black holes. In this paper, we assume the\nexistence of black shells and consider their thermodynamic properties, but\nremain agnostic about their wider role in gravitational physics. An ambient\nnegative cosmological constant is introduced in order to have a well-defined\ncanonical ensemble, leading to a rich phase structure. In particular, the\nHawking-Page transition between thermal AdS vacuum and large AdS black holes is\nsplit in two, with an intermediate black shell phase, which may play a role in\ngauge/gravity duality at finite volume. Similarly, for non-vanishing electric\ncharge below a critical value, a black shell phase separates two black hole\nphases at low and high temperatures. Above the critical charge, there are no\nphase transitions and large AdS black holes always have the lowest free energy.",
    "pdf_url": "http://arxiv.org/pdf/2506.02117v1",
    "published": "2025-06-02T18:00:05+00:00",
    "categories": [
      "hep-th"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2506.02112v2",
    "title": "SAB3R: Semantic-Augmented Backbone in 3D Reconstruction",
    "authors": [
      "Xuweiyi Chen",
      "Tian Xia",
      "Sihan Xu",
      "Jianing Yang",
      "Joyce Chai",
      "Zezhou Cheng"
    ],
    "abstract": "We introduce a new task, Map and Locate, which unifies the traditionally\ndistinct objectives of open-vocabulary segmentation - detecting and segmenting\nobject instances based on natural language queries - and 3D reconstruction, the\nprocess of estimating a scene's 3D structure from visual inputs. Specifically,\nMap and Locate involves generating a point cloud from an unposed video and\nsegmenting object instances based on open-vocabulary queries. This task serves\nas a critical step toward real-world embodied AI applications and introduces a\npractical task that bridges reconstruction, recognition and reorganization. To\ntackle this task, we introduce a simple yet effective baseline, which we denote\nas SAB3R. Our approach builds upon MASt3R, a recent breakthrough in 3D computer\nvision, and incorporates a lightweight distillation strategy. This method\ntransfers dense, per-pixel semantic features from 2D vision backbones (eg, CLIP\nand DINOv2) to enhance MASt3R's capabilities. Without introducing any auxiliary\nfrozen networks, our model generates per-pixel semantic features and constructs\ncohesive point maps in a single forward pass. Compared to separately deploying\nMASt3R and CLIP, our unified model, SAB3R, achieves superior performance on the\nMap and Locate benchmark. Furthermore, we evaluate SAB3R on both 2D semantic\nsegmentation and 3D tasks to comprehensively validate its effectiveness.",
    "pdf_url": "http://arxiv.org/pdf/2506.02112v2",
    "published": "2025-06-02T18:00:04+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.02113v1",
    "title": "Classical spin liquids from frustrated Ising models in hyperbolic space",
    "authors": [
      "Fabian Köhler",
      "Johanna Erdmenger",
      "Roderich Moessner",
      "Matthias Vojta"
    ],
    "abstract": "Antiferromagnetic Ising models on frustrated lattices can realize classical\nspin liquids, with highly degenerate ground states and, possibly,\nfractionalized excitations and emergent gauge fields. Motivated by the recent\ninterest in many-body system in negatively curved space, we study hyperbolic\nfrustrated Ising models. Specifically, we consider nearest-neighbor Ising\nmodels on tesselations with odd-length loops in two-dimensional hyperbolic\nspace. For finite systems with open boundaries we determine the ground-state\ndegeneracy exactly, and we perform extensive finite-temperature Monte-Carlo\nsimulations to obtain thermodynamic data as well as correlation functions. We\nshow that the shape of the boundary, constituting an extensive part of the\nsystem, can be used to control low-energy states: Depending on the boundary, we\nfind ordered or disordered ground states. Our results demonstrate how geometric\nfrustration acts in curved space to produce classical spin liquids.",
    "pdf_url": "http://arxiv.org/pdf/2506.02113v1",
    "published": "2025-06-02T18:00:04+00:00",
    "categories": [
      "cond-mat.str-el",
      "cond-mat.mes-hall",
      "hep-th"
    ],
    "primary_category": "cond-mat.str-el"
  },
  {
    "id": "http://arxiv.org/abs/2506.02114v1",
    "title": "Rootin' Tootin' Efficient Ray Shootin': Creating Microlensing Magnification Maps with GPUs",
    "authors": [
      "Luke Weisenbach"
    ],
    "abstract": "The impending discovery and monitoring of hundreds of new gravitationally\nlensed quasars and supernovae from upcoming ground and space based large area\nsurveys such as LSST, \\textit{Euclid}, and \\textit{Roman} necessitates the\ndevelopment of improved numerical methods for studying gravitational\nmicrolensing. We present in this work the fastest microlensing map generation\ncode currently publicly available. We utilize graphics processing units to take\nadvantage of the inherent parallelizable nature of creating magnification maps,\nin addition to using 1) the fast multipole method to reduce the runtime\ndependence on the number of microlenses and 2) inverse polygon mapping to\nreduce the number of rays required. The code is available at\nhttps://github.com/weisluke/microlensing/.",
    "pdf_url": "http://arxiv.org/pdf/2506.02114v1",
    "published": "2025-06-02T18:00:04+00:00",
    "categories": [
      "astro-ph.GA",
      "astro-ph.IM"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2506.02115v1",
    "title": "The error budget of binary neutron star merger simulations for configurations with high spin",
    "authors": [
      "Hao-Jui Kuan",
      "Ivan Markin",
      "Maximiliano Ujevic",
      "Tim Dietrich",
      "Kenta Kiuchi",
      "Masaru Shibata",
      "Wolfgang Tichy"
    ],
    "abstract": "Numerical-relativity simulations offer a unique approach to investigating the\ndynamics of binary neutron star mergers and provide the most accurate\npredictions of waveforms in the late inspiral phase. However, the numerical\npredictions are prone to systematic biases originating from the construction of\ninitial quasi-circular binary configurations, the numerical methods used to\nevolve them, and to extract gravitational signals. To assess uncertainties\narising from these aspects, we analyze mergers of highly spinning neutron stars\nwith dimensionless spin parameter $\\chi=0.5$. The initial data are prepared by\ntwo solvers, \\textsc{FUKA} and \\textsc{SGRID}, which are then evolved by two\nindependent codes, \\textsc{SACRA} and \\textsc{BAM}. We assess the impact of\nnumerical discretizations, finite extraction radii, and differences in\nnumerical frameworks on the resulting gravitational waveforms. Our analysis\nreveals that the primary source of uncertainty in numerical waveforms is the\nevolution code, while the initial data solver has a smaller impact. We also\ncompare our numerical-relativity waveforms with state-of-the-art analytical\nmodels, finding that the discrepancies between them exceed the estimated\nnumerical uncertainties. Few suggestions are offered: (i) the analytic waveform\nbecomes an inadequate approximation after the two neutron stars come into\ncontact and the binary enters the essentially-one-body phase, (ii) the\nanalytical models may not capture finite-size effects beyond quadrupole moment,\nand (iii) the inconsistent use of the binary black hole baseline in the\nanalytical models may also be contributing to these discrepancies. The\npresented results benchmark the error budget for numerical waveforms of binary\nneutron star mergers, and provide information for the analytic models to\nexplore further the high spin parameter space of binary neutron star mergers.",
    "pdf_url": "http://arxiv.org/pdf/2506.02115v1",
    "published": "2025-06-02T18:00:04+00:00",
    "categories": [
      "gr-qc",
      "astro-ph.HE"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2506.02116v1",
    "title": "Primordial Gravitational Waves from Phase Transitions during Reheating",
    "authors": [
      "Amitayus Banik",
      "Nicolás Bernal",
      "Fazlollah Hajkarim"
    ],
    "abstract": "We study primordial gravitational waves (GWs) generated from first-order\nphase transitions (PTs) during cosmic reheating. Using a minimal particle\nphysics model, and a general parametrization of the inflaton energy density and\nthe evolution of the Standard Model temperature, we explore the conditions\nunder which PTs occur and determine the corresponding PT parameters (the PT\ntemperature, duration and strength), which depend on the evolution of the\nbackground during reheating. We find that, in certain cosmological scenarios,\nPTs can be delayed and prolonged compared to the standard post-inflationary\nevolution. Incorporating these PT parameters, we compute the resulting GW\nspectrum generated from the various processes occurring during a first-order\nPT: bubble collisions, sound waves, and magneto-hydrodynamic turbulence. We\nfind that, in comparison to the standard cosmological history, the GW amplitude\nand peak frequency can be modified by several orders of magnitude due to the\nadditional enhancement or suppression arising from the cosmological evolution\nduring reheating. In particular, the GW spectra could be within the reach of\nnext-generation GW and CMB observatories.",
    "pdf_url": "http://arxiv.org/pdf/2506.02116v1",
    "published": "2025-06-02T18:00:04+00:00",
    "categories": [
      "astro-ph.CO",
      "hep-ph"
    ],
    "primary_category": "astro-ph.CO"
  },
  {
    "id": "http://arxiv.org/abs/2506.02111v1",
    "title": "The particle spectra of parity-violating theories: A less radical approach and an upgrade of PSALTer",
    "authors": [
      "Will Barker",
      "Georgios K. Karananas",
      "Haochen Tu"
    ],
    "abstract": "Due to computational barriers, the effects of parity violation have so far\nbeen grossly neglected in gravitational model-building, leading to a serious\ngap in the space of prior models. We present a new algorithm for efficiently\ncomputing the particle spectrum for any parity-violating tensorial field\ntheory. It allows to extract conditions for the absence of massive ghosts\nwithout resorting to any manipulation of radicals in cases where the particle\nmasses are irrational functions of the Lagrangian coupling coefficients. We\ntest it against several examples, among which is the most general\nparity-indefinite Einstein-Cartan/Poincar\\'e gravity that propagates two\nhealthy massive scalars (in addition to the massless graviton). Importantly, we\nupgrade the PSALTer software in the Wolfram Language to accommodate\nparity-violating theories. PSALTer is a contribution to the xAct project.",
    "pdf_url": "http://arxiv.org/pdf/2506.02111v1",
    "published": "2025-06-02T18:00:03+00:00",
    "categories": [
      "hep-th",
      "gr-qc",
      "hep-ph"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2506.02109v1",
    "title": "Towards a microscopic description of de Sitter dynamics",
    "authors": [
      "Vladimir Narovlansky"
    ],
    "abstract": "Describing dynamics in a gravitational universe with positive cosmological\nconstant, such as de Sitter space, is a conceptually challenging problem. We\npropose a principle for constructing a quantum system that can potentially be\nused to study this question. This quantum system describes a heavy object in\nsuch a universe interacting with its environment, to which gauge invariant\ndynamical observables can be anchored. In order to describe gravity with\npositive cosmological constant, the proposed quantum system needs to agree with\nall known semiclassical results. We investigate this with a particular\nmicroscopic realization constructed using SYK. We first find that correlators\nmatch the classical limit of gravity, given by quantum fields in rigid de\nSitter space. In particular, the usual UV behavior of quantum fields is\nsurprisingly reproduced by the quantum mechanical system. In order to probe\nsmall effects in the gravitational constant, we also consider the intrinsically\ndynamical out-of-time-order correlators (OTOCs). These correspond to\ngravitational scattering in the bulk away from the worldline associated with\nthe quantum system. Such OTOCs have highly non-trivial features in de Sitter\nspace, including a Lyapunov exponent which is twice as big as the maximal chaos\nexponent from the bound on chaos, as well as an unusual behavior of the\ncoefficients in various OTOCs. Interestingly, we find that these features are\nreproduced by the quantum system.",
    "pdf_url": "http://arxiv.org/pdf/2506.02109v1",
    "published": "2025-06-02T18:00:02+00:00",
    "categories": [
      "hep-th",
      "gr-qc"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2506.02110v1",
    "title": "Wigner negativity, random matrices and gravity",
    "authors": [
      "Ritam Basu",
      "Pratyusha Chowdhury",
      "Anirban Ganguly",
      "Souparna Nath",
      "Onkar Parrikar",
      "Suprakash Paul"
    ],
    "abstract": "Given a choice of an ordered, orthonormal basis for a $D$-dimensional Hilbert\nspace, one can define a discrete version of the Wigner function -- a\nquasi-probability distribution which represents any quantum state as a real,\nnormalized function on a discrete phase space. The Wigner function, in general,\ntakes on negative values, and the amount of negativity in the Wigner function\ngives an operationally meaningful measure of the complexity of simulating the\nquantum state on a classical computer. Further, Wigner negativity also gives a\nlower bound on an entropic measure of spread complexity. In this paper, we\nstudy the growth of Wigner negativity for a generic initial state under time\nevolution with chaotic Hamiltonians. In arXiv:2402.13694, a perturbative\nargument was given to show that the Krylov basis minimizes the early time\ngrowth of Wigner negativity in the large-$D$ limit. Using tools from random\nmatrix theory, here we show that for a generic choice of basis, the Wigner\nnegativity for a classical initial state becomes exponentially large in an\n$O(1)$ amount of time evolution. On the other hand, we show that in the Krylov\nbasis the negativity grows at most as a power law, and becomes exponentially\nlarge only at exponential times. We take this as evidence that the Krylov basis\nis ideally suited for a dual, semi-classical effective description of chaotic\nquantum dynamics for large-$D$ at sub-exponential times. For the Gaussian\nunitary ensemble, this effective description is the $q\\to 0$ limit of\n$q$-deformed JT gravity.",
    "pdf_url": "http://arxiv.org/pdf/2506.02110v1",
    "published": "2025-06-02T18:00:02+00:00",
    "categories": [
      "hep-th"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2506.02105v1",
    "title": "Learning Circuits with Infinite Tensor Networks",
    "authors": [
      "Joe Gibbs",
      "Lukasz Cincio"
    ],
    "abstract": "Hamiltonian simulation on quantum computers is strongly constrained by gate\ncounts, motivating techniques to reduce circuit depths. While tensor networks\nare natural competitors to quantum computers, we instead leverage them to\nsupport circuit design, with datasets of tensor networks enabling a unitary\nsynthesis inspired by quantum machine learning. For a target simulation in the\nthermodynamic limit, translation invariance is exploited to significantly\nreduce the optimization complexity, avoiding a scaling with system size. Our\napproach finds circuits to efficiently prepare ground states, and perform time\nevolution on both infinite and finite systems with substantially lower gate\ndepths than conventional Trotterized methods. In addition to reducing CNOT\ndepths, we motivate similar utility for fault-tolerant quantum algorithms, with\na demonstrated $5.2\\times$ reduction in $T$-count to realize $e^{-iHt}$. The\nkey output of our approach is the optimized unit-cell of a translation\ninvariant circuit. This provides an advantage for Hamiltonian simulation of\nfinite, yet arbitrarily large, systems on real quantum computers.",
    "pdf_url": "http://arxiv.org/pdf/2506.02105v1",
    "published": "2025-06-02T18:00:01+00:00",
    "categories": [
      "quant-ph",
      "cond-mat.str-el"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.02106v1",
    "title": "On-shell recursion relations for higher-spin Compton amplitudes",
    "authors": [
      "Yohei Ema",
      "Ting Gao",
      "Wenqi Ke",
      "Zhen Liu",
      "Ishmam Mahbub"
    ],
    "abstract": "We recursively construct tree-level electromagnetic and gravitational Compton\namplitudes of higher-spin massive particles by the all-line transverse momentum\nshift. With three-point amplitude as input, we demonstrate that higher-point\nelectromagnetic and gravitational Compton amplitudes are on-shell constructible\nup to spin $s = 3/2$ and $s = 5/2$, respectively, under the all-line transverse\nshift after imposing the current constraint condition. We unambiguously derive\nthe four-point electromagnetic and gravitational Compton amplitudes for $s \\leq\n3/2$ and $s \\leq 5/2$, which are uniquely determined by the on-shell recursion\nrelation and are free from unphysical spurious poles. In addition, we explore\namplitudes of spin-$3/2$ particles with non-minimal three-point interactions\nwith photon, as well as $s > 3/2$ particles, and comment on their notable\nfeatures. Our work furthers the understanding of on-shell methods for massive\namplitudes, with hopes to shed light on physical observables in particle\nphysics and higher-spin amplitudes relevant for Kerr black-hole scattering.",
    "pdf_url": "http://arxiv.org/pdf/2506.02106v1",
    "published": "2025-06-02T18:00:01+00:00",
    "categories": [
      "hep-th",
      "gr-qc",
      "hep-ph"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2506.02107v1",
    "title": "Surrogate models for lightcurves and photosphere properties of Type II supernovae",
    "authors": [
      "Nikhil Sarin",
      "Takashi J. Moriya",
      "Avinash Singh",
      "Anjasha Gangopadhyay",
      "K-Ryan Hinds",
      "Steve Schulze",
      "Conor M. B. Omand",
      "Kaustav K. Das"
    ],
    "abstract": "Inferences on the properties Type II supernovae (SNe) can provide significant\ninsights into the lives and deaths of the astrophysical population of massive\nstars and potentially provide measurements of luminosity distance, independent\nof the distance ladder. Here, we introduce surrogate models for the\nphotospheric properties and lightcurves of Type II SNe trained on a large grid\nof simulations from the radiation hydrodynamics code, {\\sc stella}. The trained\nmodel can accurately and efficiently ($\\sim 30$ms) predict the lightcurves and\nproperties of Type II SNe within a large parameter space of progenitor ($10-18\nM_{\\odot}$ at ZAMS) and nickel masses ($0.001-0.3M_{\\odot}$), progenitor\nmass-loss rate ($10^{-5}-10^{-1}~M_{\\odot}$yr$^{-1}$), CSM radius\n($1-10\\times10^{14}$cm), and SN explosion energies ($0.5-5 \\times 10^{51}$erg).\nWe validate this model through inference on lightcurves and photosphere\nproperties drawn directly from the original {\\sc stella} simulations not\nincluded in training. In particular, for a synthetic Type II SNe observed\nwithin the 10-year LSST survey, we find we can measure the progenitor and\nnickel masses with $\\approx 9\\%$ and $\\approx 25\\%$ precision, respectively,\nwhen fitting the photometric data while accounting for the uncertainty in the\nsurrogate model itself. Meanwhile, from real observations of SN~2004et,\nSN~2012aw, and SN~2017gmr we infer a progenitor ZAMS mass of\n$12.15_{-1.06}^{+1.03} M_{\\odot}$, $10.61_{-0.32}^{+0.37} M_{\\odot}$, $10.4 \\pm\n0.3 M_{\\odot}$, respectively. We discuss systematic uncertainties from our\nsurrogate modelling approach and likelihood approaches to account for these\nuncertainties. We further discuss future extensions to the model to enable\nstronger constraints on properties of Type II SNe and their progenitors, for\ncosmological applications, and applications of our surrogate modelling approach\nto other transients.",
    "pdf_url": "http://arxiv.org/pdf/2506.02107v1",
    "published": "2025-06-02T18:00:01+00:00",
    "categories": [
      "astro-ph.HE"
    ],
    "primary_category": "astro-ph.HE"
  },
  {
    "id": "http://arxiv.org/abs/2506.02108v1",
    "title": "Anyon superconductivity and plateau transitions in doped fractional quantum anomalous Hall insulators",
    "authors": [
      "Pavel A. Nosov",
      "Zhaoyu Han",
      "Eslam Khalaf"
    ],
    "abstract": "Recent experiments reported evidence of superconductivity and re-entrant\ninteger quantum anomalous Hall (RIQAH) insulator upon doping the $\\nu_e = 2/3$\nfractional quantum anomalous Hall states (FQAH) in twisted MoTe${}_2$,\nseparated by narrow resistive regions. Anyons of a FQAH generally have a finite\neffective mass, and when described by anyon-flux composite fermions (CF),\nexperience statistical magnetic fields with a commensurate filling. Here, we\nshow that most of the experimental observations can be explained by invoking\nthe effects of disorder on the Landau-Hofstadter bands of CFs. In particular,\nby making minimal assumptions about the anyon energetics and dispersion, we\nshow that doping anyons drives plateau transitions of CFs into integer quantum\nHall states, which physically corresponds to either to a superconductor or to a\nRIQAH phase. We develop a dictionary that allows us to infer the response in\nthese phases and the critical regions from the knowledge of the response\nfunctions of the plateau transitions. In particular, this allows us to relate\nthe superfluid stiffness of the superconductor to the polarizability of CFs. As\na first step towards a quantitative understanding, we borrow results from the\ncelebrated integer quantum Hall plateau transitions to make quantitative\nprediction for the critical behavior of the superfluid stiffness, longitudinal\nand Hall conductivity, and response to out-of-plane magnetic field, all of\nwhich agree reasonably well with the experimental observations. Our results\nprovide strong support for anyon superconductivity being the mechanism for the\nobserved superconductor in the vicinity of the $\\nu_e = 2/3$ FQAH insulator.",
    "pdf_url": "http://arxiv.org/pdf/2506.02108v1",
    "published": "2025-06-02T18:00:01+00:00",
    "categories": [
      "cond-mat.str-el",
      "cond-mat.supr-con"
    ],
    "primary_category": "cond-mat.str-el"
  },
  {
    "id": "http://arxiv.org/abs/2506.02100v1",
    "title": "Post-glitch Recovery and the Neutron Star Structure: The Vela Pulsar",
    "authors": [
      "Himanshu Grover",
      "Erbil Gügercinoğlu",
      "Bhal Chandra Joshi",
      "M. A. Krishnakumar",
      "Shantanu Desai",
      "P. Arumugam",
      "Debades Bandyopadhyay"
    ],
    "abstract": "Pulsar glitches, sudden changes in a neutron star's rotation, offer a unique\nwindow into the extreme physics governing these celestial bodies. The\npost-glitch recovery phase, characterized by a gradual recovery, reveals\ninsights into the superfluid dynamics within the star. The post-glitch recovery\nphase probes the coupling mechanisms between different stellar components,\nsheds light on the properties of neutron star matter at supra-nuclear densities\nand even allows us to predict the time to the next glitch. In this work, we\npresent a detailed analysis of the Vela pulsar's rotational behavior using\naround 100 months of observational data spanning from September 2016 to January\n2025, during which four glitches were identified. Here, we demonstrate the\npost-glitch recovery of these glitches within the framework of the vortex creep\nmodel, providing new insights into the Vela pulsar's internal structure.\nNotably, we present the first-ever investigation of vortex residuals (the\ndiscrepancy between observed values and those predicted by the vortex creep\nmodel) through the lens of the vortex bending model, marking a significant step\nforward in understanding neutron star physics through pulsar glitches.",
    "pdf_url": "http://arxiv.org/pdf/2506.02100v1",
    "published": "2025-06-02T18:00:00+00:00",
    "categories": [
      "astro-ph.HE",
      "astro-ph.IM"
    ],
    "primary_category": "astro-ph.HE"
  },
  {
    "id": "http://arxiv.org/abs/2506.02101v2",
    "title": "Relativistic Magnetic Reconnection in Astrophysical Plasmas: A Powerful Mechanism of Nonthermal Emission",
    "authors": [
      "Lorenzo Sironi",
      "Dmitri A. Uzdensky",
      "Dimitrios Giannios"
    ],
    "abstract": "Magnetic reconnection -- a fundamental plasma physics process, where magnetic\nfield lines of opposite polarity annihilate -- is invoked in astrophysical\nplasmas as a powerful mechanism of nonthermal particle acceleration, able to\nexplain fast-evolving, bright high-energy flares. Near black holes and neutron\nstars, reconnection occurs in the ``relativistic'' regime, in which the mean\nmagnetic energy per particle exceeds the rest mass energy. This review reports\nrecent advances in our understanding of the kinetic physics of relativistic\nreconnection: (1) Kinetic simulations have elucidated the physics of plasma\nheating and nonthermal particle acceleration in relativistic reconnection; (2)\nThe physics of radiative relativistic reconnection, with its self-consistent\ninterplay between photons and reconnection-accelerated particles -- a\npeculiarity of luminous, high-energy astrophysical sources -- is the new\nfrontier of research; (3) Relativistic reconnection plays a key role in global\nmodels of high-energy sources, both in terms of global-scale layers, as well as\nof reconnection sites generated as a byproduct of local magnetohydrodynamic\ninstabilities. We summarize themes of active investigation and future\ndirections, emphasizing the role of upcoming observational capabilities,\nlaboratory experiments, and new computational tools.",
    "pdf_url": "http://arxiv.org/pdf/2506.02101v2",
    "published": "2025-06-02T18:00:00+00:00",
    "categories": [
      "astro-ph.HE",
      "physics.plasm-ph",
      "physics.space-ph"
    ],
    "primary_category": "astro-ph.HE"
  },
  {
    "id": "http://arxiv.org/abs/2506.02102v1",
    "title": "The near infrared airglow continuum conundrum. Constraints for ground-based faint object spectroscopy",
    "authors": [
      "J. K. M. Viuho",
      "J. P. U. Fynbo",
      "M. I. Andersen"
    ],
    "abstract": "The airglow continuum in the near infrared is a challenge to quantify due to\nits faintness, and the grating scattered light from atmospheric hydroxyl (OH)\nemission lines. Despite its faintness, the airglow continuum sets the\nfundamental limits for ground-based spectroscopy of faint targets, and makes\nthe difference between ground and space-based observation in the interline\nregions between atmospheric emission lines. We aim to quantify the level of\nairglow continuum radiance in the VIS -- NIR wavelength range observable with\nsilicon photodetectors for the site Observatorio del Roque de los Muchachos in\na way that our measurement will not be biased by the grating scattered light.\nWe aim to do this by measuring the airglow continuum radiance with a minimal\nand controlled contamination from the broad instrumental scattering wings\ncaused by the bright atmospheric OH lines. We measure the airglow continuum\nradiance with longslit $\\lambda/\\Delta\\lambda\\sim4000$ spectrograph in\n$\\sim$100\\r{A} wide narrow band passes centered at 6720, 7700, 8700 and\n10500\\r{A} (in line with the R, I, and Z broadbands) with the 2.5-meter Nordic\nOptical Telescope under photometric dark sky conditions. The bandpasses are\nchosen to be as clean as possible from atmospheric absorption and the OH line\nemission keeping the radiation reaching the grating surface at minimum. We\nobserve the zenith equivalent airglow continuum to be 22.5mag/arcsec2 at\n6720\\r{A} band, and 22mag/arcsec2 at 8700\\r{A}. We derive upper limits of\n22mag/arcsec2 at 7700\\r{A} due to difficulty to find a clean part of spectrum\nfor measurement, and 20.8mag/arcsec2 at 10500\\r{A} due to low system\nsensitivity. Within measurement errors and the natural variability expected for\nthe airglow emission our results for the Observatorio del Roque de los\nMuchachos are comparable to values reported for other major observatory sites.\n(abridged)",
    "pdf_url": "http://arxiv.org/pdf/2506.02102v1",
    "published": "2025-06-02T18:00:00+00:00",
    "categories": [
      "astro-ph.IM"
    ],
    "primary_category": "astro-ph.IM"
  },
  {
    "id": "http://arxiv.org/abs/2506.02103v1",
    "title": "2D Entanglement from a Single Motzkin Spaghetto",
    "authors": [
      "Zhao Zhang"
    ],
    "abstract": "While highly entangled ground states of gapless local Hamiltonians have been\nknown to exist in one dimension, their 2D counterparts were only recently\nfound, with rather sophisticated interactions involving at least 4 neighboring\ndegrees of freedom. In this letter, a 2D lattice system interacting only\nbetween two nearest neighboring sites is proposed, which has a unique ground\nstate with volume scaling of entanglement entropy. The system undergoes an\nentanglement phase transition with enhanced entanglement entropy at the\ncritical point compared to the previous construction from coupling orthogonal\narrays of one-dimensional chains, but the spectral gap in the highly entangled\nphase decays faster. A tensor network representation is composed of tensors\nwith lower rank, and has a similar global geometry.",
    "pdf_url": "http://arxiv.org/pdf/2506.02103v1",
    "published": "2025-06-02T18:00:00+00:00",
    "categories": [
      "quant-ph",
      "cond-mat.stat-mech",
      "math-ph",
      "math.MP"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.02104v1",
    "title": "Collisionless relaxation to quasi-steady state attractors in cold dark matter halos: origin of the universal NFW profile",
    "authors": [
      "Uddipan Banik",
      "Amitava Bhattacharjee"
    ],
    "abstract": "Collisionless self-gravitating systems such as cold dark matter halos are\nknown to harbor universal density profiles despite the intricate non-linear\nphysics of hierarchical structure formation in the $\\Lambda$CDM paradigm. The\norigin of these attractor states has been a persistent mystery, particularly\nbecause the physics of collisionless relaxation is not well understood. To\nsolve this long-standing problem, we develop a self-consistent quasilinear\ntheory in action-angle space for the collisionless relaxation of inhomogeneous,\nself-gravitating systems by perturbing the governing Vlasov-Poisson equations.\nWe obtain a quasilinear diffusion equation that describes the secular evolution\nof the mean coarse-grained distribution function $f_0$ of accreted matter in\nthe fluctuating force field of a halo. The diffusion coefficient not only\ndepends on the fluctuation power spectrum but also on the evolving potential of\nthe system, which reflects the self-consistency of the problem. Diffusive\nheating by an initially cored halo develops an $r^{-1}$ cusp in the density\nprofile of the accreted material, with $r$ the halocentric radius. Subsequent\naccretion and relaxation around this $r^{-1}$ cusp develops an $r^{-3}$\nfall-off, establishing the Navarro-Frenk-White (NFW) density profile, a\nquasi-steady state attractor of collisionless relaxation that is not\nparticularly sensitive to initial conditions. Given enough time though, the\nhalo tends to Maxwellianize and develop an isothermal sphere profile. We\ndemonstrate for the first time that the universal NFW profile emerges as an\nattractor solution to a self-consistent theory for collisionless relaxation.",
    "pdf_url": "http://arxiv.org/pdf/2506.02104v1",
    "published": "2025-06-02T18:00:00+00:00",
    "categories": [
      "astro-ph.GA",
      "astro-ph.CO",
      "physics.plasm-ph"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2506.01957v2",
    "title": "Violation of Universal Operator Growth Hypothesis in $W_3$ Conformal Field Theories",
    "authors": [
      "Dileep P. Jatkar",
      "Sujoy Mahato",
      "Sukrut Mondkar",
      "Praveen Thalore"
    ],
    "abstract": "We show that a large central charge conformal field theory with $W_3$\nsymmetry exhibits violation of the conjectured operator growth bound if the\nLiouvillian is modified to incorporate $W_3$ generators. We get 23 classes of\nLanczos coefficients, obtained by the action of the Liouvillian on a descendant\nstate. Among these, 10 classes of Lanczos coefficients violate the conjectured\nupper bound by exhibiting a faster-than-linear growth with the descendant level\n$N$. Two classes of them have asymptotic growth saturating at $N^2$, displaying\nmaximal violation.",
    "pdf_url": "http://arxiv.org/pdf/2506.01957v2",
    "published": "2025-06-02T17:59:59+00:00",
    "categories": [
      "hep-th",
      "cond-mat.str-el",
      "quant-ph"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2506.02099v1",
    "title": "The Stellar Populations and Rest-Frame Colors of Star-Forming Galaxies at $z \\approx 8$: Exploring the Impact of Filter Choice and Star Formation History Assumption with JADES",
    "authors": [
      "Jakob M. Helton",
      "Stacey Alberts",
      "George H. Rieke",
      "Kevin N. Hainline",
      "Zhiyuan Ji",
      "Marcia J. Rieke",
      "Benjamin D. Johnson",
      "Brant Robertson",
      "Sandro Tacchella",
      "Lily Whitler",
      "William M. Baker",
      "Rachana Bhatawdekar",
      "Kristan Boyett",
      "Andrew J. Bunker",
      "Phillip A. Cargile",
      "Stefano Carniani",
      "Stephane Charlot",
      "Jacopo Chevallard",
      "Emma Curtis-Lake",
      "Eiichi Egami",
      "Daniel J. Eisenstein",
      "Ryan Hausen",
      "Jianwei Lyu",
      "Roberto Maiolino",
      "Erica Nelson",
      "Pablo G. Pérez-González",
      "Pierluigi Rinaldi",
      "Meredith Stone",
      "Fengwu Sun",
      "Christina C. Williams",
      "Christopher N. A. Willmer",
      "Chris Willott",
      "Joris Witstok"
    ],
    "abstract": "Our understanding of the physical properties of star-forming galaxies during\nthe Epoch of Reionization (EoR, at $z > 6$) suffers from degeneracies among the\napparent properties of the stars, the nebular gas, and the dust. These\ndegeneracies are most prominent with photometry, which has insufficient (1)\nspectral resolution and (2) rest-frame spectral coverage. We explore ways to\nbreak these degeneracies with a sample of $N = 22$ high-redshift star-forming\ngalaxies at $7 < z_{\\mathrm{phot}} \\leq 9$, using some of the deepest existing\nimaging from JWST/NIRCam and JWST/MIRI with JADES. Key to this study is the\nimaging from JWST/MIRI at $7.7\\ \\mu\\mathrm{m}$, which provides coverage of the\nrest-frame $I$-band at the observed redshifts. We infer stellar population\nproperties and rest-frame colors using a variety of filter sets and star\nformation history assumptions to explore the impact of these choices.\nEvaluating these quantities both with and without the $7.7\\ \\mu\\mathrm{m}$ data\npoint shows that dense spectral coverage with JWST/NIRCam (eight or more\nfilters, including at least one medium-band) can compensate for lacking the\nrest-frame $I$-band coverage for the vast majority ($\\approx 80\\%$) of our\nsample. Furthermore, these galaxy properties are most consistently determined\nby assuming the delayed-tau star formation history, which provides the smallest\noffsets and scatters around these offsets when including JWST/MIRI. Within\nextragalactic surveys like JADES and CEERS, our findings suggest that robust\ncharacterization of the stellar population properties and rest-frame colors for\nhigh-redshift star-forming galaxies is possible with JWST/NIRCam alone at $z\n\\approx 8$.",
    "pdf_url": "http://arxiv.org/pdf/2506.02099v1",
    "published": "2025-06-02T17:59:59+00:00",
    "categories": [
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2506.01956v2",
    "title": "Rapid and accurate numerical evolution of linear cosmological perturbations with non-cold relics",
    "authors": [
      "Nanoom Lee",
      "José Luis Bernal",
      "Sven Günther",
      "Lingyuan Ji",
      "Marc Kamionkowski"
    ],
    "abstract": "We describe the implementation of a new approach to the numerical evaluation\nof the effects of non-cold relics on the evolution of cosmological\nperturbations. The Boltzmann hierarchies used to compute the contributions of\nthese relics to the stress-energy tensor are replaced with a set of integral\nequations. These integral equations take the form of convolutions and are\nsolved iteratively with the rest of the system. We develop efficient algorithms\nfor evaluating these convolutions using non-uniform fast Fourier transforms\n(NUFFTs). This approach enables efficient and accurate evaluation of the cosmic\nmicrowave background anisotropies and matter power spectra, all the way through\nthe history of the Universe, without relying on semi-analytic approximations at\nlate times. We implement this method in the Boltzmann solver CLASS, resulting\nin a new code called CLASSIER (for CLASS Integral Equation Revision), and apply\nit to massive-neutrino perturbations as a demonstration. The implementation is\noptimized to accurately capture the distinct behaviors of perturbations in both\nsuper-/near-horizon and sub-horizon regimes. Our results match the accuracy of\na fully converged Boltzmann hierarchy solution while avoiding numerical\nartifacts from truncation of the Boltzmann hierarchy at finite multipole and\noffering substantial speedups depending on the required precision and the range\nof scales of interest. This new framework provides a practical and robust\nalternative for the truncated Boltzmann hierarchy approach, especially for\nstudying beyond $\\Lambda$CDM non-cold relics with signatures on small scales.\nCLASSIER is publicly available at https://github.com/nanoomlee/CLASSIER.",
    "pdf_url": "http://arxiv.org/pdf/2506.01956v2",
    "published": "2025-06-02T17:59:58+00:00",
    "categories": [
      "astro-ph.CO"
    ],
    "primary_category": "astro-ph.CO"
  },
  {
    "id": "http://arxiv.org/abs/2506.01955v1",
    "title": "Dual-Process Image Generation",
    "authors": [
      "Grace Luo",
      "Jonathan Granskog",
      "Aleksander Holynski",
      "Trevor Darrell"
    ],
    "abstract": "Prior methods for controlling image generation are limited in their ability\nto be taught new tasks. In contrast, vision-language models, or VLMs, can learn\ntasks in-context and produce the correct outputs for a given input. We propose\na dual-process distillation scheme that allows feed-forward image generators to\nlearn new tasks from deliberative VLMs. Our scheme uses a VLM to rate the\ngenerated images and backpropagates this gradient to update the weights of the\nimage generator. Our general framework enables a wide variety of new control\ntasks through the same text-and-image based interface. We showcase a handful of\napplications of this technique for different types of control signals, such as\ncommonsense inferences and visual prompts. With our method, users can implement\nmultimodal controls for properties such as color palette, line weight, horizon\nposition, and relative depth within a matter of minutes. Project page:\nhttps://dual-process.github.io.",
    "pdf_url": "http://arxiv.org/pdf/2506.01955v1",
    "published": "2025-06-02T17:59:56+00:00",
    "categories": [
      "cs.CV",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.01953v1",
    "title": "Fast-in-Slow: A Dual-System Foundation Model Unifying Fast Manipulation within Slow Reasoning",
    "authors": [
      "Hao Chen",
      "Jiaming Liu",
      "Chenyang Gu",
      "Zhuoyang Liu",
      "Renrui Zhang",
      "Xiaoqi Li",
      "Xiao He",
      "Yandong Guo",
      "Chi-Wing Fu",
      "Shanghang Zhang",
      "Pheng-Ann Heng"
    ],
    "abstract": "Generalized policy and execution efficiency constitute the two critical\nchallenges in robotic manipulation. While recent foundation policies benefit\nfrom the common-sense reasoning capabilities of internet-scale pretrained\nvision-language models (VLMs), they often suffer from low execution frequency.\nTo mitigate this dilemma, dual-system approaches, inspired by Kahneman's\ntheory, have been proposed to leverage a VLM-based System 2 model handling\nhigh-level reasoning and a separate System 1 action model ensuring real-time\ncontrol. However, existing designs maintain both systems as separate models,\nlimiting System 1 from fully leveraging the rich pretrained knowledge from the\nVLM-based System 2. In this work, we propose Fast-in-Slow (FiS), a unified\ndual-system vision-language-action (VLA) model that embeds the System 1\nexecution module within the VLM-based System 2 by partially sharing parameters.\nThis innovative paradigm not only enables high-frequency execution in System 1\nbut also facilitates coordination between the reasoning and execution\ncomponents within a single foundation model of System 2. Given their\nfundamentally distinct roles within FiS-VLA, we design the two systems to\nincorporate heterogeneous modality inputs alongside asynchronous operating\nfrequencies, enabling both fast and precise manipulation. To enable\ncoordination between the two systems, a dual-aware co-training strategy is\nproposed that equips System 1 with action generation capabilities while\npreserving System 2's contextual reasoning representation. For evaluation,\nFiS-VLA outperforms previous state-of-the-art methods by 8% in simulation and\n11% in real-world tasks in terms of average success rate, while achieving a\n117.7 Hz control frequency with action chunk set to eight. Project web page:\nfast-in-slow.github.io.",
    "pdf_url": "http://arxiv.org/pdf/2506.01953v1",
    "published": "2025-06-02T17:59:51+00:00",
    "categories": [
      "cs.RO"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2506.01954v1",
    "title": "DRAG: Distilling RAG for SLMs from LLMs to Transfer Knowledge and Mitigate Hallucination via Evidence and Graph-based Distillation",
    "authors": [
      "Jennifer Chen",
      "Aidar Myrzakhan",
      "Yaxin Luo",
      "Hassaan Muhammad Khan",
      "Sondos Mahmoud Bsharat",
      "Zhiqiang Shen"
    ],
    "abstract": "Retrieval-Augmented Generation (RAG) methods have proven highly effective for\ntasks requiring factual consistency and robust knowledge retrieval. However,\nlarge-scale RAG systems consume significant computational resources and are\nprone to generating hallucinated content from Humans. In this work, we\nintroduce $\\texttt{DRAG}$, a novel framework for distilling RAG knowledge from\nlarge-scale Language Models (LLMs) into small LMs (SLMs). Our approach\nleverages evidence- and knowledge graph-based distillation, ensuring that the\ndistilled model retains critical factual knowledge while significantly reducing\nmodel size and computational cost. By aligning the smaller model's predictions\nwith a structured knowledge graph and ranked evidence, $\\texttt{DRAG}$\neffectively mitigates hallucinations and improves factual accuracy. We further\npresent a case demonstrating how our framework mitigates user privacy risks and\nintroduce a corresponding benchmark. Experimental evaluations on multiple\nbenchmarks demonstrate that our method outperforms the prior competitive RAG\nmethods like MiniRAG for SLMs by up to 27.7% using the same models, preserving\nhigh-level efficiency and reliability. With $\\texttt{DRAG}$, we provide a\npractical and resource-efficient roadmap to deploying enhanced retrieval and\ngeneration capabilities in small-sized LLMs.",
    "pdf_url": "http://arxiv.org/pdf/2506.01954v1",
    "published": "2025-06-02T17:59:51+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.01952v1",
    "title": "WebChoreArena: Evaluating Web Browsing Agents on Realistic Tedious Web Tasks",
    "authors": [
      "Atsuyuki Miyai",
      "Zaiying Zhao",
      "Kazuki Egashira",
      "Atsuki Sato",
      "Tatsumi Sunada",
      "Shota Onohara",
      "Hiromasa Yamanishi",
      "Mashiro Toyooka",
      "Kunato Nishina",
      "Ryoma Maeda",
      "Kiyoharu Aizawa",
      "Toshihiko Yamasaki"
    ],
    "abstract": "Powered by a large language model (LLM), a web browsing agent operates web\nbrowsers in a human-like manner and offers a highly transparent path toward\nautomating a wide range of everyday tasks. As web agents become increasingly\ncapable and demonstrate proficiency in general browsing tasks, a critical\nquestion emerges: Can they go beyond general browsing to robustly handle tasks\nthat are tedious and complex, or chores that humans often avoid doing\nthemselves? In this paper, we introduce WebChoreArena, a new fully reproducible\nbenchmark comprising 532 carefully curated tasks designed to extend the scope\nof WebArena beyond general browsing to more labor-intensive and tedious tasks.\nWebChoreArena systematically integrates three key challenges: (i) Massive\nMemory tasks requiring accurate retrieval of large amounts of information in\nthe observations, (ii) Calculation tasks demanding precise mathematical\nreasoning, and (iii) Long-Term Memory tasks necessitating long-term memory\nacross multiple webpages. Built on top of the fully reproducible and widely\nadopted four WebArena simulation environments, WebChoreArena ensures strict\nreproducibility and enables fair, direct comparisons with the established\nWebArena benchmark, offering key insights into agent progress. Our experimental\nresults demonstrate that as LLMs evolve, represented by GPT-4o, Claude 3.7\nSonnet, and Gemini 2.5 Pro, significant improvements in performance are\nobserved on WebChoreArena. These findings suggest that WebChoreArena is\nwell-suited to measure the advancement of state-of-the-art LLMs with greater\nclarity. Nevertheless, the results also indicate that even with Gemini 2.5 Pro,\nthere remains substantial room for improvement compared to WebArena,\nhighlighting the increased challenges posed by WebChoreArena.",
    "pdf_url": "http://arxiv.org/pdf/2506.01952v1",
    "published": "2025-06-02T17:59:45+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.02098v1",
    "title": "LibriBrain: Over 50 Hours of Within-Subject MEG to Improve Speech Decoding Methods at Scale",
    "authors": [
      "Miran Özdogan",
      "Gilad Landau",
      "Gereon Elvers",
      "Dulhan Jayalath",
      "Pratik Somaiya",
      "Francesco Mantegna",
      "Mark Woolrich",
      "Oiwi Parker Jones"
    ],
    "abstract": "LibriBrain represents the largest single-subject MEG dataset to date for\nspeech decoding, with over 50 hours of recordings -- 5$\\times$ larger than the\nnext comparable dataset and 50$\\times$ larger than most. This unprecedented\n`depth' of within-subject data enables exploration of neural representations at\na scale previously unavailable with non-invasive methods. LibriBrain comprises\nhigh-quality MEG recordings together with detailed annotations from a single\nparticipant listening to naturalistic spoken English, covering nearly the full\nSherlock Holmes canon. Designed to support advances in neural decoding,\nLibriBrain comes with a Python library for streamlined integration with deep\nlearning frameworks, standard data splits for reproducibility, and baseline\nresults for three foundational decoding tasks: speech detection, phoneme\nclassification, and word classification. Baseline experiments demonstrate that\nincreasing training data yields substantial improvements in decoding\nperformance, highlighting the value of scaling up deep, within-subject\ndatasets. By releasing this dataset, we aim to empower the research community\nto advance speech decoding methodologies and accelerate the development of\nsafe, effective clinical brain-computer interfaces.",
    "pdf_url": "http://arxiv.org/pdf/2506.02098v1",
    "published": "2025-06-02T17:59:41+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.01951v1",
    "title": "Self-ensemble: Mitigating Confidence Distortion for Large Language Models",
    "authors": [
      "Zicheng Xu",
      "Guanchu Wang",
      "Guangyao Zheng",
      "Yu-Neng Chuang",
      "Alexander Szalay",
      "Xia Hu",
      "Vladimir Braverman"
    ],
    "abstract": "Although Large Language Models (LLMs) perform well in general fields, they\nexhibit a confidence distortion problem on multi-choice question-answering\n(MCQA), particularly as the number of answer choices increases. Specifically,\non MCQA with many choices, LLMs suffer from under-confidence in correct\npredictions and over-confidence in incorrect ones, leading to a substantially\ndegraded performance. To solve this problem, we propose Self-ensemble in this\nwork. Our method splits the choices into several groups and ensembles LLM\npredictions across these groups to reach a final decision. The advantage of\nSelf-ensemble is its plug-and-play nature, where it can be integrated into\nexisting LLM architecture based on a designed attention mask and positional\nencoding, without requiring labeled datasets for parameter tuning. Experimental\nresults on three LLMs and datasets demonstrate that Self-ensemble\ncomprehensively addresses the confidence distortion problem of LLMs,\noutperforming standard inference as well as baseline methods.",
    "pdf_url": "http://arxiv.org/pdf/2506.01951v1",
    "published": "2025-06-02T17:59:29+00:00",
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.02097v2",
    "title": "Hybrid AI for Responsive Multi-Turn Online Conversations with Novel Dynamic Routing and Feedback Adaptation",
    "authors": [
      "Priyaranjan Pattnayak",
      "Amit Agarwal",
      "Hansa Meghwani",
      "Hitesh Laxmichand Patel",
      "Srikant Panda"
    ],
    "abstract": "Retrieval-Augmented Generation (RAG) systems and large language model\n(LLM)-powered chatbots have significantly advanced conversational AI by\ncombining generative capabilities with external knowledge retrieval. Despite\ntheir success, enterprise-scale deployments face critical challenges, including\ndiverse user queries, high latency, hallucinations, and difficulty integrating\nfrequently updated domain-specific knowledge. This paper introduces a novel\nhybrid framework that integrates RAG with intent-based canned responses,\nleveraging predefined high-confidence responses for efficiency while\ndynamically routing complex or ambiguous queries to the RAG pipeline. Our\nframework employs a dialogue context manager to ensure coherence in multi-turn\ninteractions and incorporates a feedback loop to refine intents, dynamically\nadjust confidence thresholds, and expand response coverage over time.\nExperimental results demonstrate that the proposed framework achieves a balance\nof high accuracy (95\\%) and low latency (180ms), outperforming RAG and\nintent-based systems across diverse query types, positioning it as a scalable\nand adaptive solution for enterprise conversational AI applications.",
    "pdf_url": "http://arxiv.org/pdf/2506.02097v2",
    "published": "2025-06-02T17:59:27+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2506.01950v3",
    "title": "DualMap: Online Open-Vocabulary Semantic Mapping for Natural Language Navigation in Dynamic Changing Scenes",
    "authors": [
      "Jiajun Jiang",
      "Yiming Zhu",
      "Zirui Wu",
      "Jie Song"
    ],
    "abstract": "We introduce DualMap, an online open-vocabulary mapping system that enables\nrobots to understand and navigate dynamically changing environments through\nnatural language queries. Designed for efficient semantic mapping and\nadaptability to changing environments, DualMap meets the essential requirements\nfor real-world robot navigation applications. Our proposed hybrid segmentation\nfrontend and object-level status check eliminate the costly 3D object merging\nrequired by prior methods, enabling efficient online scene mapping. The\ndual-map representation combines a global abstract map for high-level candidate\nselection with a local concrete map for precise goal-reaching, effectively\nmanaging and updating dynamic changes in the environment. Through extensive\nexperiments in both simulation and real-world scenarios, we demonstrate\nstate-of-the-art performance in 3D open-vocabulary segmentation, efficient\nscene mapping, and online language-guided navigation.Project page:\nhttps://eku127.github.io/DualMap/",
    "pdf_url": "http://arxiv.org/pdf/2506.01950v3",
    "published": "2025-06-02T17:59:10+00:00",
    "categories": [
      "cs.RO",
      "cs.CV"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2506.01949v1",
    "title": "IMAGHarmony: Controllable Image Editing with Consistent Object Quantity and Layout",
    "authors": [
      "Fei Shen",
      "Xiaoyu Du",
      "Yutong Gao",
      "Jian Yu",
      "Yushe Cao",
      "Xing Lei",
      "Jinhui Tang"
    ],
    "abstract": "Recent diffusion models have advanced image editing by enhancing visual\nquality and control, supporting broad applications across creative and\npersonalized domains. However, current image editing largely overlooks\nmulti-object scenarios, where precise control over object categories, counts,\nand spatial layouts remains a significant challenge. To address this, we\nintroduce a new task, quantity-and-layout consistent image editing (QL-Edit),\nwhich aims to enable fine-grained control of object quantity and spatial\nstructure in complex scenes. We further propose IMAGHarmony, a structure-aware\nframework that incorporates harmony-aware attention (HA) to integrate\nmultimodal semantics, explicitly modeling object counts and layouts to enhance\nediting accuracy and structural consistency. In addition, we observe that\ndiffusion models are susceptible to initial noise and exhibit strong\npreferences for specific noise patterns. Motivated by this, we present a\npreference-guided noise selection (PNS) strategy that chooses semantically\naligned initial noise samples based on vision-language matching, thereby\nimproving generation stability and layout consistency in multi-object editing.\nTo support evaluation, we construct HarmonyBench, a comprehensive benchmark\ncovering diverse quantity and layout control scenarios. Extensive experiments\ndemonstrate that IMAGHarmony consistently outperforms state-of-the-art methods\nin structural alignment and semantic accuracy. The code and model are available\nat https://github.com/muzishen/IMAGHarmony.",
    "pdf_url": "http://arxiv.org/pdf/2506.01949v1",
    "published": "2025-06-02T17:59:09+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.01948v2",
    "title": "Multi-mode NOON states generation with ultracold atoms via geodesic counterdiabatic driving",
    "authors": [
      "Simon Dengis",
      "Sandro Wimberger",
      "Peter Schlagheck"
    ],
    "abstract": "We present a protocol for the generation of NOON states with ultracold atoms,\nleveraging the Bose-Hubbard model in the self-trapping regime. By the means of\nan optimized adiabatic protocol, we achieve a significant reduction in the time\nrequired for the preparation of highly entangled NOON states, involving two or\nmore modes. Our method saturates the quantum speed limit, ensuring both\nefficiency and high fidelity in state preparation. A detailed analysis of the\ngeodesic counterdiabatic driving protocol and its application to the\nBose-Hubbard system highlights its ability to expand the energy gap,\nfacilitating faster adiabatic evolution. Through perturbation theory, we derive\neffective parameters that emulate the counterdiabatic Hamiltonian, enabling\nexperimentally viable implementations with constant physical parameters. This\napproach is demonstrated to yield exponential time savings compared to standard\ngeodesic driving, making it a powerful tool for creating complex entangled\nstates for applications in quantum metrology and quantum information. Our\nfindings pave the way for scalable and precise quantum state control in\nultracold atomic systems.",
    "pdf_url": "http://arxiv.org/pdf/2506.01948v2",
    "published": "2025-06-02T17:58:58+00:00",
    "categories": [
      "cond-mat.quant-gas",
      "quant-ph"
    ],
    "primary_category": "cond-mat.quant-gas"
  },
  {
    "id": "http://arxiv.org/abs/2506.01947v1",
    "title": "RAW Image Reconstruction from RGB on Smartphones. NTIRE 2025 Challenge Report",
    "authors": [
      "Marcos V. Conde",
      "Radu Timofte",
      "Radu Berdan",
      "Beril Besbinar",
      "Daisuke Iso",
      "Pengzhou Ji",
      "Xiong Dun",
      "Zeying Fan",
      "Chen Wu",
      "Zhansheng Wang",
      "Pengbo Zhang",
      "Jiazi Huang",
      "Qinglin Liu",
      "Wei Yu",
      "Shengping Zhang",
      "Xiangyang Ji",
      "Kyungsik Kim",
      "Minkyung Kim",
      "Hwalmin Lee",
      "Hekun Ma",
      "Huan Zheng",
      "Yanyan Wei",
      "Zhao Zhang",
      "Jing Fang",
      "Meilin Gao",
      "Xiang Yu",
      "Shangbin Xie",
      "Mengyuan Sun",
      "Huanjing Yue",
      "Jingyu Yang Huize Cheng",
      "Shaomeng Zhang",
      "Zhaoyang Zhang",
      "Haoxiang Liang"
    ],
    "abstract": "Numerous low-level vision tasks operate in the RAW domain due to its linear\nproperties, bit depth, and sensor designs. Despite this, RAW image datasets are\nscarce and more expensive to collect than the already large and public sRGB\ndatasets. For this reason, many approaches try to generate realistic RAW images\nusing sensor information and sRGB images. This paper covers the second\nchallenge on RAW Reconstruction from sRGB (Reverse ISP). We aim to recover RAW\nsensor images from smartphones given the corresponding sRGB images without\nmetadata and, by doing this, ``reverse\" the ISP transformation. Over 150\nparticipants joined this NTIRE 2025 challenge and submitted efficient models.\nThe proposed methods and benchmark establish the state-of-the-art for\ngenerating realistic RAW data.",
    "pdf_url": "http://arxiv.org/pdf/2506.01947v1",
    "published": "2025-06-02T17:58:31+00:00",
    "categories": [
      "eess.IV",
      "cs.CV"
    ],
    "primary_category": "eess.IV"
  },
  {
    "id": "http://arxiv.org/abs/2506.01946v1",
    "title": "MLLMs Need 3D-Aware Representation Supervision for Scene Understanding",
    "authors": [
      "Xiaohu Huang",
      "Jingjing Wu",
      "Qunyi Xie",
      "Kai Han"
    ],
    "abstract": "Recent advances in scene understanding have leveraged multimodal large\nlanguage models (MLLMs) for 3D reasoning by capitalizing on their strong 2D\npretraining. However, the lack of explicit 3D data during MLLM pretraining\nlimits 3D representation capability. In this paper, we investigate the\n3D-awareness of MLLMs by evaluating multi-view correspondence and reveal a\nstrong positive correlation between the quality of 3D-aware representation and\ndownstream task performance. Motivated by this, we propose 3DRS, a framework\nthat enhances MLLM 3D representation learning by introducing supervision from\npretrained 3D foundation models. Our approach aligns MLLM visual features with\nrich 3D knowledge distilled from 3D models, effectively improving scene\nunderstanding. Extensive experiments across multiple benchmarks and MLLMs --\nincluding visual grounding, captioning, and question answering -- demonstrate\nconsistent performance gains. Project page: https://visual-ai.github.io/3drs",
    "pdf_url": "http://arxiv.org/pdf/2506.01946v1",
    "published": "2025-06-02T17:58:24+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.01945v1",
    "title": "Stock Market Telepathy: Graph Neural Networks Predicting the Secret Conversations between MINT and G7 Countries",
    "authors": [
      "Nurbanu Bursa"
    ],
    "abstract": "Emerging economies, particularly the MINT countries (Mexico, Indonesia,\nNigeria, and T\\\"urkiye), are gaining influence in global stock markets,\nalthough they remain susceptible to the economic conditions of developed\ncountries like the G7 (Canada, France, Germany, Italy, Japan, the United\nKingdom, and the United States). This interconnectedness and sensitivity of\nfinancial markets make understanding these relationships crucial for investors\nand policymakers to predict stock price movements accurately. To this end, we\nexamined the main stock market indices of G7 and MINT countries from 2012 to\n2024, using a recent graph neural network (GNN) algorithm called multivariate\ntime series forecasting with graph neural network (MTGNN). This method allows\nfor considering complex spatio-temporal connections in multivariate time\nseries. In the implementations, MTGNN revealed that the US and Canada are the\nmost influential G7 countries regarding stock indices in the forecasting\nprocess, and Indonesia and T\\\"urkiye are the most influential MINT countries.\nAdditionally, our results showed that MTGNN outperformed traditional methods in\nforecasting the prices of stock market indices for MINT and G7 countries.\nConsequently, the study offers valuable insights into economic blocks' markets\nand presents a compelling empirical approach to analyzing global stock market\ndynamics using MTGNN.",
    "pdf_url": "http://arxiv.org/pdf/2506.01945v1",
    "published": "2025-06-02T17:58:21+00:00",
    "categories": [
      "econ.EM",
      "cs.LG",
      "stat.AP"
    ],
    "primary_category": "econ.EM"
  },
  {
    "id": "http://arxiv.org/abs/2506.01944v1",
    "title": "Feel the Force: Contact-Driven Learning from Humans",
    "authors": [
      "Ademi Adeniji",
      "Zhuoran Chen",
      "Vincent Liu",
      "Venkatesh Pattabiraman",
      "Raunaq Bhirangi",
      "Siddhant Haldar",
      "Pieter Abbeel",
      "Lerrel Pinto"
    ],
    "abstract": "Controlling fine-grained forces during manipulation remains a core challenge\nin robotics. While robot policies learned from robot-collected data or\nsimulation show promise, they struggle to generalize across the diverse range\nof real-world interactions. Learning directly from humans offers a scalable\nsolution, enabling demonstrators to perform skills in their natural embodiment\nand in everyday environments. However, visual demonstrations alone lack the\ninformation needed to infer precise contact forces. We present FeelTheForce\n(FTF): a robot learning system that models human tactile behavior to learn\nforce-sensitive manipulation. Using a tactile glove to measure contact forces\nand a vision-based model to estimate hand pose, we train a closed-loop policy\nthat continuously predicts the forces needed for manipulation. This policy is\nre-targeted to a Franka Panda robot with tactile gripper sensors using shared\nvisual and action representations. At execution, a PD controller modulates\ngripper closure to track predicted forces-enabling precise, force-aware\ncontrol. Our approach grounds robust low-level force control in scalable human\nsupervision, achieving a 77% success rate across 5 force-sensitive manipulation\ntasks. Code and videos are available at https://feel-the-force-ftf.github.io.",
    "pdf_url": "http://arxiv.org/pdf/2506.01944v1",
    "published": "2025-06-02T17:57:52+00:00",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2506.01943v2",
    "title": "Learning Video Generation for Robotic Manipulation with Collaborative Trajectory Control",
    "authors": [
      "Xiao Fu",
      "Xintao Wang",
      "Xian Liu",
      "Jianhong Bai",
      "Runsen Xu",
      "Pengfei Wan",
      "Di Zhang",
      "Dahua Lin"
    ],
    "abstract": "Recent advances in video diffusion models have demonstrated strong potential\nfor generating robotic decision-making data, with trajectory conditions further\nenabling fine-grained control. However, existing trajectory-based methods\nprimarily focus on individual object motion and struggle to capture\nmulti-object interaction crucial in complex robotic manipulation. This\nlimitation arises from multi-feature entanglement in overlapping regions, which\nleads to degraded visual fidelity. To address this, we present RoboMaster, a\nnovel framework that models inter-object dynamics through a collaborative\ntrajectory formulation. Unlike prior methods that decompose objects, our core\nis to decompose the interaction process into three sub-stages: pre-interaction,\ninteraction, and post-interaction. Each stage is modeled using the feature of\nthe dominant object, specifically the robotic arm in the pre- and\npost-interaction phases and the manipulated object during interaction, thereby\nmitigating the drawback of multi-object feature fusion present during\ninteraction in prior work. To further ensure subject semantic consistency\nthroughout the video, we incorporate appearance- and shape-aware latent\nrepresentations for objects. Extensive experiments on the challenging Bridge V2\ndataset, as well as in-the-wild evaluation, demonstrate that our method\noutperforms existing approaches, establishing new state-of-the-art performance\nin trajectory-controlled video generation for robotic manipulation.",
    "pdf_url": "http://arxiv.org/pdf/2506.01943v2",
    "published": "2025-06-02T17:57:06+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.01942v1",
    "title": "OD3: Optimization-free Dataset Distillation for Object Detection",
    "authors": [
      "Salwa K. Al Khatib",
      "Ahmed ElHagry",
      "Shitong Shao",
      "Zhiqiang Shen"
    ],
    "abstract": "Training large neural networks on large-scale datasets requires substantial\ncomputational resources, particularly for dense prediction tasks such as object\ndetection. Although dataset distillation (DD) has been proposed to alleviate\nthese demands by synthesizing compact datasets from larger ones, most existing\nwork focuses solely on image classification, leaving the more complex detection\nsetting largely unexplored. In this paper, we introduce OD3, a novel\noptimization-free data distillation framework specifically designed for object\ndetection. Our approach involves two stages: first, a candidate selection\nprocess in which object instances are iteratively placed in synthesized images\nbased on their suitable locations, and second, a candidate screening process\nusing a pre-trained observer model to remove low-confidence objects. We perform\nour data synthesis framework on MS COCO and PASCAL VOC, two popular detection\ndatasets, with compression ratios ranging from 0.25% to 5%. Compared to the\nprior solely existing dataset distillation method on detection and conventional\ncore set selection methods, OD3 delivers superior accuracy, establishes new\nstate-of-the-art results, surpassing prior best method by more than 14% on COCO\nmAP50 at a compression ratio of 1.0%. Code and condensed datasets are available\nat: https://github.com/VILA-Lab/OD3.",
    "pdf_url": "http://arxiv.org/pdf/2506.01942v1",
    "published": "2025-06-02T17:56:02+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.01941v1",
    "title": "FreeTacMan: Robot-free Visuo-Tactile Data Collection System for Contact-rich Manipulation",
    "authors": [
      "Longyan Wu",
      "Checheng Yu",
      "Jieji Ren",
      "Li Chen",
      "Ran Huang",
      "Guoying Gu",
      "Hongyang Li"
    ],
    "abstract": "Enabling robots with contact-rich manipulation remains a pivotal challenge in\nrobot learning, which is substantially hindered by the data collection gap,\nincluding its inefficiency and limited sensor setup. While prior work has\nexplored handheld paradigms, their rod-based mechanical structures remain rigid\nand unintuitive, providing limited tactile feedback and posing challenges for\nhuman operators. Motivated by the dexterity and force feedback of human motion,\nwe propose FreeTacMan, a human-centric and robot-free data collection system\nfor accurate and efficient robot manipulation. Concretely, we design a wearable\ndata collection device with dual visuo-tactile grippers, which can be worn by\nhuman fingers for intuitive and natural control. A high-precision optical\ntracking system is introduced to capture end-effector poses, while\nsynchronizing visual and tactile feedback simultaneously. FreeTacMan achieves\nmultiple improvements in data collection performance compared to prior works,\nand enables effective policy learning for contact-rich manipulation tasks with\nthe help of the visuo-tactile information. We will release the work to\nfacilitate reproducibility and accelerate research in visuo-tactile\nmanipulation.",
    "pdf_url": "http://arxiv.org/pdf/2506.01941v1",
    "published": "2025-06-02T17:55:23+00:00",
    "categories": [
      "cs.RO"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2506.01940v2",
    "title": "Making Rotation Averaging Fast and Robust with Anisotropic Coordinate Descent",
    "authors": [
      "Yaroslava Lochman",
      "Carl Olsson",
      "Christopher Zach"
    ],
    "abstract": "Anisotropic rotation averaging has recently been explored as a natural\nextension of respective isotropic methods. In the anisotropic formulation,\nuncertainties of the estimated relative rotations -- obtained via standard\ntwo-view optimization -- are propagated to the optimization of absolute\nrotations. The resulting semidefinite relaxations are able to recover global\nminima but scale poorly with the problem size. Local methods are fast and also\nadmit robust estimation but are sensitive to initialization. They usually\nemploy minimum spanning trees and therefore suffer from drift accumulation and\ncan get trapped in poor local minima. In this paper, we attempt to bridge the\ngap between optimality, robustness and efficiency of anisotropic rotation\naveraging. We analyze a family of block coordinate descent methods initially\nproposed to optimize the standard chordal distances, and derive a much simpler\nformulation and an anisotropic extension obtaining a fast general solver. We\nintegrate this solver into the extended anisotropic large-scale robust rotation\naveraging pipeline. The resulting algorithm achieves state-of-the-art\nperformance on public structure-from-motion datasets. Project page:\nhttps://ylochman.github.io/acd",
    "pdf_url": "http://arxiv.org/pdf/2506.01940v2",
    "published": "2025-06-02T17:55:02+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.01939v1",
    "title": "Beyond the 80/20 Rule: High-Entropy Minority Tokens Drive Effective Reinforcement Learning for LLM Reasoning",
    "authors": [
      "Shenzhi Wang",
      "Le Yu",
      "Chang Gao",
      "Chujie Zheng",
      "Shixuan Liu",
      "Rui Lu",
      "Kai Dang",
      "Xionghui Chen",
      "Jianxin Yang",
      "Zhenru Zhang",
      "Yuqiong Liu",
      "An Yang",
      "Andrew Zhao",
      "Yang Yue",
      "Shiji Song",
      "Bowen Yu",
      "Gao Huang",
      "Junyang Lin"
    ],
    "abstract": "Reinforcement Learning with Verifiable Rewards (RLVR) has emerged as a\npowerful approach to enhancing the reasoning capabilities of Large Language\nModels (LLMs), while its mechanisms are not yet well understood. In this work,\nwe undertake a pioneering exploration of RLVR through the novel perspective of\ntoken entropy patterns, comprehensively analyzing how different tokens\ninfluence reasoning performance. By examining token entropy patterns in\nChain-of-Thought (CoT) reasoning, we observe that only a small fraction of\ntokens exhibit high entropy, and these tokens act as critical forks that steer\nthe model toward diverse reasoning pathways. Furthermore, studying how entropy\npatterns evolve during RLVR training reveals that RLVR largely adheres to the\nbase model's entropy patterns, primarily adjusting the entropy of high-entropy\ntokens. These findings highlight the significance of high-entropy tokens (i.e.,\nforking tokens) to RLVR. We ultimately improve RLVR by restricting policy\ngradient updates to forking tokens and uncover a finding even beyond the 80/20\nrule: utilizing only 20% of the tokens while maintaining performance comparable\nto full-gradient updates on the Qwen3-8B base model and significantly\nsurpassing full-gradient updates on the Qwen3-32B (+11.04 on AIME'25 and +7.71\non AIME'24) and Qwen3-14B (+4.79 on AIME'25 and +5.21 on AIME'24) base models,\nhighlighting a strong scaling trend. In contrast, training exclusively on the\n80% lowest-entropy tokens leads to a marked decline in performance. These\nfindings indicate that the efficacy of RLVR primarily arises from optimizing\nthe high-entropy tokens that decide reasoning directions. Collectively, our\nresults highlight the potential to understand RLVR through a token-entropy\nperspective and optimize RLVR by leveraging high-entropy minority tokens to\nfurther improve LLM reasoning.",
    "pdf_url": "http://arxiv.org/pdf/2506.01939v1",
    "published": "2025-06-02T17:54:39+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.01938v1",
    "title": "Novel Benchmark for NER in the Wastewater and Stormwater Domain",
    "authors": [
      "Franco Alberto Cardillo",
      "Franca Debole",
      "Francesca Frontini",
      "Mitra Aelami",
      "Nanée Chahinian",
      "Serge Conrad"
    ],
    "abstract": "Effective wastewater and stormwater management is essential for urban\nsustainability and environmental protection. Extracting structured knowledge\nfrom reports and regulations is challenging due to domainspecific terminology\nand multilingual contexts. This work focuses on domain-specific Named Entity\nRecognition (NER) as a first step towards effective relation and information\nextraction to support decision making. A multilingual benchmark is crucial for\nevaluating these methods. This study develops a French-Italian domain-specific\ntext corpus for wastewater management. It evaluates state-of-the-art NER\nmethods, including LLM-based approaches, to provide a reliable baseline for\nfuture strategies and explores automated annotation projection in view of an\nextension of the corpus to new languages.",
    "pdf_url": "http://arxiv.org/pdf/2506.01938v1",
    "published": "2025-06-02T17:54:16+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.01937v1",
    "title": "RewardBench 2: Advancing Reward Model Evaluation",
    "authors": [
      "Saumya Malik",
      "Valentina Pyatkin",
      "Sander Land",
      "Jacob Morrison",
      "Noah A. Smith",
      "Hannaneh Hajishirzi",
      "Nathan Lambert"
    ],
    "abstract": "Reward models are used throughout the post-training of language models to\ncapture nuanced signals from preference data and provide a training target for\noptimization across instruction following, reasoning, safety, and more domains.\nThe community has begun establishing best practices for evaluating reward\nmodels, from the development of benchmarks that test capabilities in specific\nskill areas to others that test agreement with human preferences. At the same\ntime, progress in evaluation has not been mirrored by the effectiveness of\nreward models in downstream tasks -- simpler direct alignment algorithms are\nreported to work better in many cases. This paper introduces RewardBench 2, a\nnew multi-skill reward modeling benchmark designed to bring new, challenging\ndata for accuracy-based reward model evaluation -- models score about 20 points\non average lower on RewardBench 2 compared to the first RewardBench -- while\nbeing highly correlated with downstream performance. Compared to most other\nbenchmarks, RewardBench 2 sources new human prompts instead of existing prompts\nfrom downstream evaluations, facilitating more rigorous evaluation practices.\nIn this paper, we describe our benchmark construction process and report how\nexisting models perform on it, while quantifying how performance on the\nbenchmark correlates with downstream use of the models in both inference-time\nscaling algorithms, like best-of-N sampling, and RLHF training algorithms like\nproximal policy optimization.",
    "pdf_url": "http://arxiv.org/pdf/2506.01937v1",
    "published": "2025-06-02T17:54:04+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.01936v1",
    "title": "Should Decision-Makers Reveal Classifiers in Online Strategic Classification?",
    "authors": [
      "Han Shao",
      "Shuo Xie",
      "Kunhe Yang"
    ],
    "abstract": "Strategic classification addresses a learning problem where a decision-maker\nimplements a classifier over agents who may manipulate their features in order\nto receive favorable predictions. In the standard model of online strategic\nclassification, in each round, the decision-maker implements and publicly\nreveals a classifier, after which agents perfectly best respond based on this\nknowledge. However, in practice, whether to disclose the classifier is often\ndebated -- some decision-makers believe that hiding the classifier can prevent\nmisclassification errors caused by manipulation.\n  In this paper, we formally examine how limiting the agents' access to the\ncurrent classifier affects the decision-maker's performance. Specifically, we\nconsider an extended online strategic classification setting where agents lack\ndirect knowledge about the current classifier and instead manipulate based on a\nweighted average of historically implemented classifiers. Our main result shows\nthat in this setting, the decision-maker incurs $(1-\\gamma)^{-1}$ or\n$k_{\\text{in}}$ times more mistakes compared to the full-knowledge setting,\nwhere $k_{\\text{in}}$ is the maximum in-degree of the manipulation graph\n(representing how many distinct feature vectors can be manipulated to appear as\na single one), and $\\gamma$ is the discount factor indicating agents' memory of\npast classifiers. Our results demonstrate how withholding access to the\nclassifier can backfire and degrade the decision-maker's performance in online\nstrategic classification.",
    "pdf_url": "http://arxiv.org/pdf/2506.01936v1",
    "published": "2025-06-02T17:53:49+00:00",
    "categories": [
      "cs.GT",
      "cs.LG"
    ],
    "primary_category": "cs.GT"
  },
  {
    "id": "http://arxiv.org/abs/2506.01935v1",
    "title": "Low-Rank Head Avatar Personalization with Registers",
    "authors": [
      "Sai Tanmay Reddy Chakkera",
      "Aggelina Chatziagapi",
      "Md Moniruzzaman",
      "Chen-Ping Yu",
      "Yi-Hsuan Tsai",
      "Dimitris Samaras"
    ],
    "abstract": "We introduce a novel method for low-rank personalization of a generic model\nfor head avatar generation. Prior work proposes generic models that achieve\nhigh-quality face animation by leveraging large-scale datasets of multiple\nidentities. However, such generic models usually fail to synthesize unique\nidentity-specific details, since they learn a general domain prior. To adapt to\nspecific subjects, we find that it is still challenging to capture\nhigh-frequency facial details via popular solutions like low-rank adaptation\n(LoRA). This motivates us to propose a specific architecture, a Register\nModule, that enhances the performance of LoRA, while requiring only a small\nnumber of parameters to adapt to an unseen identity. Our module is applied to\nintermediate features of a pre-trained model, storing and re-purposing\ninformation in a learnable 3D feature space. To demonstrate the efficacy of our\npersonalization method, we collect a dataset of talking videos of individuals\nwith distinctive facial details, such as wrinkles and tattoos. Our approach\nfaithfully captures unseen faces, outperforming existing methods quantitatively\nand qualitatively. We will release the code, models, and dataset to the public.",
    "pdf_url": "http://arxiv.org/pdf/2506.01935v1",
    "published": "2025-06-02T17:53:14+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.01934v1",
    "title": "RoboEgo System Card: An Omnimodal Model with Native Full Duplexity",
    "authors": [
      "Yiqun Yao",
      "Xiang Li",
      "Xin Jiang",
      "Xuezhi Fang",
      "Naitong Yu",
      "Aixin Sun",
      "Yequan Wang"
    ],
    "abstract": "Humans naturally process real-world multimodal information in a full-duplex\nmanner. In artificial intelligence, replicating this capability is essential\nfor advancing model development and deployment, particularly in embodied\ncontexts. The development of multimodal models faces two primary challenges:\n(1) effectively handling more than three modalities-such as vision, audio, and\ntext; and (2) delivering full-duplex responses to rapidly evolving human\ninstructions. To facilitate research on models that support both omnimodal\nprocessing and full duplexity, we present RoboEgo (alias: FLM-Ego), a unified\nmodel system designed to address both challenges. RoboEgo incorporates a\nbackbone architecture and algorithms that natively support full duplexity,\nachieving a theoretical duplex latency of 80 ms. In streaming visually grounded\nconversations under real-world conditions, RoboEgo exhibits superior\nresponsiveness and speech naturalness, while maintaining comparable content\nqualities to state-of-the-art semi-duplex omnimodal models-a feat previously\nconsidered unattainable by native full-duplex systems.",
    "pdf_url": "http://arxiv.org/pdf/2506.01934v1",
    "published": "2025-06-02T17:53:10+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2506.01933v3",
    "title": "E3D-Bench: A Benchmark for End-to-End 3D Geometric Foundation Models",
    "authors": [
      "Wenyan Cong",
      "Yiqing Liang",
      "Yancheng Zhang",
      "Ziyi Yang",
      "Yan Wang",
      "Boris Ivanovic",
      "Marco Pavone",
      "Chen Chen",
      "Zhangyang Wang",
      "Zhiwen Fan"
    ],
    "abstract": "Spatial intelligence, encompassing 3D reconstruction, perception, and\nreasoning, is fundamental to applications such as robotics, aerial imaging, and\nextended reality. A key enabler is the real-time, accurate estimation of core\n3D attributes (camera parameters, point clouds, depth maps, and 3D point\ntracks) from unstructured or streaming imagery. Inspired by the success of\nlarge foundation models in language and 2D vision, a new class of end-to-end 3D\ngeometric foundation models (GFMs) has emerged, directly predicting dense 3D\nrepresentations in a single feed-forward pass, eliminating the need for slow or\nunavailable precomputed camera parameters. Since late 2023, the field has\nexploded with diverse variants, but systematic evaluation is lacking. In this\nwork, we present the first comprehensive benchmark for 3D GFMs, covering five\ncore tasks: sparse-view depth estimation, video depth estimation, 3D\nreconstruction, multi-view pose estimation, novel view synthesis, and spanning\nboth standard and challenging out-of-distribution datasets. Our standardized\ntoolkit automates dataset handling, evaluation protocols, and metric\ncomputation to ensure fair, reproducible comparisons. We evaluate 16\nstate-of-the-art GFMs, revealing their strengths and limitations across tasks\nand domains, and derive key insights to guide future model scaling and\noptimization. All code, evaluation scripts, and processed data will be publicly\nreleased to accelerate research in 3D spatial intelligence.",
    "pdf_url": "http://arxiv.org/pdf/2506.01933v3",
    "published": "2025-06-02T17:53:09+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.01932v5",
    "title": "Nonlocal pseudosymmetries and Bäcklund transformations as $\\mathcal{C}$-morphisms",
    "authors": [
      "Diego Catalano Ferraioli",
      "Tarcísio Castro Silva"
    ],
    "abstract": "In this paper, we show how factorisation with respect to nonlocal\npseudosymmetries allows one to obtain B\\\"acklund transformations, interpreted\nas nonlocal $\\mathcal{C}$-morphisms of differential equations. According to\nthis approach, which is illustrated through several examples, the B\\\"acklund\ntransformations are determined by basic invariants of the exploited nonlocal\npseudosymmetries.",
    "pdf_url": "http://arxiv.org/pdf/2506.01932v5",
    "published": "2025-06-02T17:50:34+00:00",
    "categories": [
      "math.DG",
      "math-ph",
      "math.MP",
      "35B06, 53A55, 35Q51, 17B80, 53D22"
    ],
    "primary_category": "math.DG"
  },
  {
    "id": "http://arxiv.org/abs/2506.01931v1",
    "title": "Red Teaming AI Policy: A Taxonomy of Avoision and the EU AI Act",
    "authors": [
      "Rui-Jie Yew",
      "Bill Marino",
      "Suresh Venkatasubramanian"
    ],
    "abstract": "The shape of AI regulation is beginning to emerge, most prominently through\nthe EU AI Act (the \"AIA\"). By 2027, the AIA will be in full effect, and firms\nare starting to adjust their behavior in light of this new law. In this paper,\nwe present a framework and taxonomy for reasoning about \"avoision\" -- conduct\nthat walks the line between legal avoidance and evasion -- that firms might\nengage in so as to minimize the regulatory burden the AIA poses. We organize\nthese avoision strategies around three \"tiers\" of increasing AIA exposure that\nregulated entities face depending on: whether their activities are (1) within\nscope of the AIA, (2) exempted from provisions of the AIA, or are (3) placed in\na category with higher regulatory scrutiny. In each of these tiers and for each\nstrategy, we specify the organizational and technological forms through which\navoision may manifest. Our goal is to provide an adversarial framework for \"red\nteaming\" the AIA and AI regulation on the horizon.",
    "pdf_url": "http://arxiv.org/pdf/2506.01931v1",
    "published": "2025-06-02T17:48:54+00:00",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY"
  },
  {
    "id": "http://arxiv.org/abs/2506.01930v1",
    "title": "Statistical Interaction Driven Thermoelectricity and Violation of Wiedemann-Franz Law",
    "authors": [
      "Sampurna Karmakar",
      "Amulya Ratnakar",
      "Sourin Das"
    ],
    "abstract": "Quantum transport anomalies in systems obeying Haldane-Wu fractional\nexclusion statistics, characterized by the statistical interactions parameter\n$g$ are investigated. We identify particle-hole symmetry breaking of the\nHaldane-Wu distribution function via its deviations of the maximum entropy\n($\\mathcal{S}_{g}^{max}$), evaluated at the chemical potential, from the value\n${k_B} \\ln 2$ (a value that holds only at the free fermion limit, $g=1$). A\nduality relation, $g\\,\\mathcal{S}_{g}^{max}=\\mathcal{S}_{1/g}^{max}$,\nquantifying the degree of violation is obtained. This symmetry breaking\nmanifests in transport phenomena as: significant violations of the\nWiedemann-Franz law arising for $g>1$ (but remain absent for $g\\leq 1$) across\na broad temperature range. Moreover, the thermoelectric figure of merit $ZT$ is\nsubstantially enhanced for $g>1$ and suppressed for $g<1$, indicating new\nroutes to optimize energy conversion. These results deepen the understanding of\nthe interplay between equilibrium statistics and transport, suggesting avenues\nfor engineering advanced thermoelectric materials.",
    "pdf_url": "http://arxiv.org/pdf/2506.01930v1",
    "published": "2025-06-02T17:48:39+00:00",
    "categories": [
      "cond-mat.mes-hall"
    ],
    "primary_category": "cond-mat.mes-hall"
  },
  {
    "id": "http://arxiv.org/abs/2506.15716v2",
    "title": "Alternates, Assemble! Selecting Optimal Alternates for Citizens' Assemblies",
    "authors": [
      "Angelos Assos",
      "Carmel Baharav",
      "Bailey Flanigan",
      "Ariel Procaccia"
    ],
    "abstract": "Citizens' assemblies are an increasingly influential form of deliberative\ndemocracy, where randomly selected people discuss policy questions. The\nlegitimacy of these assemblies hinges on their representation of the broader\npopulation, but participant dropout often leads to an unbalanced composition.\nIn practice, dropouts are replaced by preselected alternates, but existing\nmethods do not address how to choose these alternates. To address this gap, we\nintroduce an optimization framework for alternate selection. Our algorithmic\napproach, which leverages learning-theoretic machinery, estimates dropout\nprobabilities using historical data and selects alternates to minimize expected\nmisrepresentation. Our theoretical bounds provide guarantees on sample\ncomplexity (with implications for computational efficiency) and on loss due to\ndropout probability mis-estimation. Empirical evaluation using real-world data\ndemonstrates that, compared to the status quo, our method significantly\nimproves representation while requiring fewer alternates.",
    "pdf_url": "http://arxiv.org/pdf/2506.15716v2",
    "published": "2025-06-02T17:48:33+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.GT"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.01929v1",
    "title": "Image Generation from Contextually-Contradictory Prompts",
    "authors": [
      "Saar Huberman",
      "Or Patashnik",
      "Omer Dahary",
      "Ron Mokady",
      "Daniel Cohen-Or"
    ],
    "abstract": "Text-to-image diffusion models excel at generating high-quality, diverse\nimages from natural language prompts. However, they often fail to produce\nsemantically accurate results when the prompt contains concept combinations\nthat contradict their learned priors. We define this failure mode as contextual\ncontradiction, where one concept implicitly negates another due to entangled\nassociations learned during training. To address this, we propose a stage-aware\nprompt decomposition framework that guides the denoising process using a\nsequence of proxy prompts. Each proxy prompt is constructed to match the\nsemantic content expected to emerge at a specific stage of denoising, while\nensuring contextual coherence. To construct these proxy prompts, we leverage a\nlarge language model (LLM) to analyze the target prompt, identify\ncontradictions, and generate alternative expressions that preserve the original\nintent while resolving contextual conflicts. By aligning prompt information\nwith the denoising progression, our method enables fine-grained semantic\ncontrol and accurate image generation in the presence of contextual\ncontradictions. Experiments across a variety of challenging prompts show\nsubstantial improvements in alignment to the textual prompt.",
    "pdf_url": "http://arxiv.org/pdf/2506.01929v1",
    "published": "2025-06-02T17:48:12+00:00",
    "categories": [
      "cs.GR",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.GR"
  },
  {
    "id": "http://arxiv.org/abs/2506.01928v1",
    "title": "Esoteric Language Models",
    "authors": [
      "Subham Sekhar Sahoo",
      "Zhihan Yang",
      "Yash Akhauri",
      "Johnna Liu",
      "Deepansha Singh",
      "Zhoujun Cheng",
      "Zhengzhong Liu",
      "Eric Xing",
      "John Thickstun",
      "Arash Vahdat"
    ],
    "abstract": "Diffusion-based language models offer a compelling alternative to\nautoregressive (AR) models by enabling parallel and controllable generation.\nAmong this family of models, Masked Diffusion Models (MDMs) achieve the\nstrongest performance but still underperform AR models in perplexity and lack\nkey inference-time efficiency features--most notably, KV caching. In this work,\nwe introduce Eso-LMs, a new family of models that fuses AR and MDM paradigms,\nenabling smooth interpolation between their perplexities while overcoming their\nrespective limitations. Eso-LMs set a new state of the art on standard language\nmodeling benchmarks. Crucially, we are the **first to introduce KV caching for\nMDMs** while preserving parallel generation, significantly improving inference\nefficiency. Combined with an optimized sampling schedule, our method achieves\nup to **65x** faster inference than standard MDMs and **4x** faster inference\nthan prior semi-autoregressive approaches. We provide the code and model\ncheckpoints on the project page:\n[http://s-sahoo.github.io/Eso-LMs](http://s-sahoo.github.io/Eso-LMs)",
    "pdf_url": "http://arxiv.org/pdf/2506.01928v1",
    "published": "2025-06-02T17:47:27+00:00",
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.04259v1",
    "title": "Quantum Index Report 2025",
    "authors": [
      "Jonathan Ruane",
      "Elif Kiesow",
      "Johannes Galatsanos",
      "Carl Dukatz",
      "Edward Blomquist",
      "Prashant Shukla"
    ],
    "abstract": "The inaugural edition of the MIT Quantum Index Report (QIR). Quantum\ntechnologies are evolving from theoretical concepts into tangible technologies\nwith commercial promise. Their rapid progress is capturing global attention and\nsuggests we stand on the cusp of a second quantum revolution. Unlocking the\nquantum opportunity is not simple. One challenge is that quantum technologies\ncan present a high barrier to understanding for nonexperts because they often\nrely on complex principles and concepts from a variety of specialist fields.\nThis can lead to confusion and intimidation for business leaders, educators,\npolicymakers and others. The Quantum Index Report aims to reduce the complexity\nand make it possible for a wider audience to have a deeper understanding of the\nquantum landscape. The Quantum Index Report provides a comprehensive,\ndata-driven assessment of the state of quantum technologies. For this inaugural\nedition we have focused on quantum computing and networking. The report tracks,\nmeasures, and visualizes trends across research, development, education and\npublic acceptance. It aggregates data from academia, industry and policy\nsources and aims to provide nonpartisan insights.",
    "pdf_url": "http://arxiv.org/pdf/2506.04259v1",
    "published": "2025-06-02T17:47:11+00:00",
    "categories": [
      "physics.soc-ph",
      "quant-ph"
    ],
    "primary_category": "physics.soc-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.01927v1",
    "title": "Online Competitive Information Gathering for Partially Observable Trajectory Games",
    "authors": [
      "Mel Krusniak",
      "Hang Xu",
      "Parker Palermo",
      "Forrest Laine"
    ],
    "abstract": "Game-theoretic agents must make plans that optimally gather information about\ntheir opponents. These problems are modeled by partially observable stochastic\ngames (POSGs), but planning in fully continuous POSGs is intractable without\nheavy offline computation or assumptions on the order of belief maintained by\neach player. We formulate a finite history/horizon refinement of POSGs which\nadmits competitive information gathering behavior in trajectory space, and\nthrough a series of approximations, we present an online method for computing\nrational trajectory plans in these games which leverages particle-based\nestimations of the joint state space and performs stochastic gradient play. We\nalso provide the necessary adjustments required to deploy this method on\nindividual agents. The method is tested in continuous pursuit-evasion and\nwarehouse-pickup scenarios (alongside extensions to $N > 2$ players and to more\ncomplex environments with visual and physical obstacles), demonstrating\nevidence of active information gathering and outperforming passive competitors.",
    "pdf_url": "http://arxiv.org/pdf/2506.01927v1",
    "published": "2025-06-02T17:45:58+00:00",
    "categories": [
      "cs.GT",
      "cs.AI",
      "cs.MA",
      "cs.RO"
    ],
    "primary_category": "cs.GT"
  },
  {
    "id": "http://arxiv.org/abs/2506.02096v1",
    "title": "SynthRL: Scaling Visual Reasoning with Verifiable Data Synthesis",
    "authors": [
      "Zijian Wu",
      "Jinjie Ni",
      "Xiangyan Liu",
      "Zichen Liu",
      "Hang Yan",
      "Michael Qizhe Shieh"
    ],
    "abstract": "Vision-language models (VLMs) trained via reinforcement learning with\nverifiable reward (RLVR) have shown notable progress in scaling test-time\ncompute effectively. In this work, we investigate how synthesized RL data can\nfurther improve RLVR. To this end, we propose \\textbf{SynthRL}-a scalable and\nguaranteed pipeline for automatic data scaling in reasoning-oriented RL\ntraining. SynthRL comprises three key stages: (1) selecting seed questions with\nappropriate distribution, (2) augmenting them into more challenging variants\nwhile preserving the original answers, and (3) a guaranteed verification stage\nthat ensures near-perfect correctness and difficulty enhancement. Our empirical\nexperiments demonstrate SynthRL's scalability and effectiveness. When applied\nto the MMK12 dataset, SynthRL synthesizes over 3.3K additional verifiable,\nchallenging questions from approximately 8K seed samples. Models trained with\nour synthesized data achieve consistent gains across five out-of-domain visual\nmath reasoning benchmarks, with a significant improvement over baseline models\ntrained on seed data alone. Notably, detailed analysis reveals that the gains\nare more pronounced on the most challenging evaluation samples, highlighting\nSynthRL's effectiveness in eliciting deeper and more complex reasoning\npatterns.",
    "pdf_url": "http://arxiv.org/pdf/2506.02096v1",
    "published": "2025-06-02T17:45:16+00:00",
    "categories": [
      "cs.LG",
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.01926v1",
    "title": "Large language models can learn and generalize steganographic chain-of-thought under process supervision",
    "authors": [
      "Joey Skaf",
      "Luis Ibanez-Lissen",
      "Robert McCarthy",
      "Connor Watts",
      "Vasil Georgiv",
      "Hannes Whittingham",
      "Lorena Gonzalez-Manzano",
      "David Lindner",
      "Cameron Tice",
      "Edward James Young",
      "Puria Radmard"
    ],
    "abstract": "Chain-of-thought (CoT) reasoning not only enhances large language model\nperformance but also provides critical insights into decision-making processes,\nmarking it as a useful tool for monitoring model intent and planning. By\nproactively preventing models from acting on CoT indicating misaligned or\nharmful intent, CoT monitoring can be used to reduce risks associated with\ndeploying models. However, developers may be incentivized to train away the\nappearance of harmful intent from CoT traces, by either customer preferences or\nregulatory requirements. Recent works have shown that banning mention of a\nspecific example of reward hacking, which may be done either to make CoT\npresentable to users or as a naive attempt to prevent the behavior, causes\nobfuscation of the undesired reasoning traces but the persistence of the\nundesired behavior. Such obfuscation threatens the reliability of CoT\nmonitoring. However, obfuscation of reasoning can be due to its internalization\nto latent space computation, or its encoding within the CoT. Here, we provide\nan extension to these results. First, we show that penalizing the use of\nspecific strings within load-bearing reasoning traces causes models to\nsubstitute alternative strings. Crucially, this does not alter the underlying\nmethod by which the model performs the task, demonstrating that the model can\nlearn to steganographically encode its reasoning. We further demonstrate that\nmodels can generalize an encoding scheme. When the penalized strings belong to\nan overarching class, the model learns not only to substitute strings seen in\ntraining, but also develops a general encoding scheme for all members of the\nclass which it can apply to held-out testing strings.",
    "pdf_url": "http://arxiv.org/pdf/2506.01926v1",
    "published": "2025-06-02T17:45:15+00:00",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2506.01925v1",
    "title": "Characterization of the Combined Effective Radiation Pattern of UAV-Mounted Antennas and Ground Station",
    "authors": [
      "Mushfiqur Rahman",
      "Ismail Guvenc",
      "Jason A. Abrahamson",
      "Amitabh Mishra",
      "Arupjyoti Bhuyan"
    ],
    "abstract": "An Unmanned Aerial Vehicle (UAV)-based communication typically involves a\nlink between a UAV-mounted antenna and a ground station. The radiation pattern\nof both antennas is influenced by nearby reflecting surfaces and scatterers,\nsuch as the UAV body and the ground. Experimentally characterizing the\neffective radiation patterns of both antennas is challenging, as the received\npower depends on their interaction. In this study, we learn a combined\nradiation pattern from experimental UAV flight data, assuming the UAV travels\nwith a fixed orientation (constant yaw angle and zero pitch/roll). We validate\nthe characterized radiation pattern by cross-referencing it with experiments\ninvolving different UAV trajectories, all conducted under identical ground\nstation and UAV orientation conditions. Experimental results show that the\nlearned combined radiation pattern reduces received power estimation error by\nup to 10 dB, compared to traditional anechoic chamber radiation patterns that\nneglect the effects of the UAV body and surrounding objects.",
    "pdf_url": "http://arxiv.org/pdf/2506.01925v1",
    "published": "2025-06-02T17:44:05+00:00",
    "categories": [
      "eess.SP"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2506.01924v1",
    "title": "A Concurrent Multiscale Framework Coupling Direct Simulation Monte Carlo and Molecular Dynamics",
    "authors": [
      "Tim Linke",
      "Dane Sterbentz",
      "Niels Grønbech-Jensen",
      "Jean-Pierre Delplanque",
      "Jonathan Belof"
    ],
    "abstract": "We present a new method to couple the Direct Simulation Monte Carlo (DSMC)\nalgorithm with molecular dynamics (MD). The coupling approach generalizes prior\ncoupling methods using a cell-based decision. The approach is supported by a\nlifting and restricting operator, which translate length and time scales\nbetween DSMC and MD. We verify the framework on basic conservation laws, and\ndemonstrate its usability on a hypersonic flow example. Its accuracy gain is\ndiscussed in light of conventional DSMC simulations. Advantages and limitations\nare discussed, and additional use cases are highlighted.",
    "pdf_url": "http://arxiv.org/pdf/2506.01924v1",
    "published": "2025-06-02T17:43:58+00:00",
    "categories": [
      "physics.comp-ph",
      "cond-mat.mes-hall",
      "cond-mat.stat-mech"
    ],
    "primary_category": "physics.comp-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.01923v2",
    "title": "TaxaDiffusion: Progressively Trained Diffusion Model for Fine-Grained Species Generation",
    "authors": [
      "Amin Karimi Monsefi",
      "Mridul Khurana",
      "Rajiv Ramnath",
      "Anuj Karpatne",
      "Wei-Lun Chao",
      "Cheng Zhang"
    ],
    "abstract": "We propose TaxaDiffusion, a taxonomy-informed training framework for\ndiffusion models to generate fine-grained animal images with high morphological\nand identity accuracy. Unlike standard approaches that treat each species as an\nindependent category, TaxaDiffusion incorporates domain knowledge that many\nspecies exhibit strong visual similarities, with distinctions often residing in\nsubtle variations of shape, pattern, and color. To exploit these relationships,\nTaxaDiffusion progressively trains conditioned diffusion models across\ndifferent taxonomic levels -- starting from broad classifications such as Class\nand Order, refining through Family and Genus, and ultimately distinguishing at\nthe Species level. This hierarchical learning strategy first captures\ncoarse-grained morphological traits shared by species with common ancestors,\nfacilitating knowledge transfer before refining fine-grained differences for\nspecies-level distinction. As a result, TaxaDiffusion enables accurate\ngeneration even with limited training samples per species. Extensive\nexperiments on three fine-grained animal datasets demonstrate that outperforms\nexisting approaches, achieving superior fidelity in fine-grained animal image\ngeneration. Project page: https://amink8.github.io/TaxaDiffusion/",
    "pdf_url": "http://arxiv.org/pdf/2506.01923v2",
    "published": "2025-06-02T17:43:55+00:00",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.01922v1",
    "title": "Anisotropy effects on heavy quark dynamics in Gribov modified gluon plasma",
    "authors": [
      "Sumit",
      "Jai Parkash",
      "Santosh K. Das",
      "Najmul Haque"
    ],
    "abstract": "In the early stages of relativistic heavy-ion collisions, the momentum\ndistribution of the quark-gluon plasma is anisotropic, leading to instabilities\nin the system due to chromomagnetic plasma modes. In this work, we consider the\nanisotropic momentum distribution of the medium constituents to investigate its\neffects on heavy quark dynamics using the nonperturbative Gribov resummation\napproach within the framework of the Fokker-Planck equation. Specifically, we\nstudy the influence of nonperturbative effects and weak anisotropies on the\nheavy quark transport coefficients, taking into account the angular dependence\nbetween the anisotropy vector and the direction of heavy quark motion.\nFurthermore, the calculated drag and diffusion coefficients are employed to\nestimate the energy loss of heavy quarks and the nuclear modification factor,\nincorporating both elastic collisions and inelastic processes. Our findings\nindicate that momentum anisotropy, angular dependence, and nonperturbative\neffects-captured through the scattering amplitudes-play a significant role in\ndetermining the transport properties of heavy quarks.",
    "pdf_url": "http://arxiv.org/pdf/2506.01922v1",
    "published": "2025-06-02T17:43:05+00:00",
    "categories": [
      "hep-ph",
      "nucl-th"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.01921v4",
    "title": "Diagnosing Reliability in Text-Guided Medical Image Editing",
    "authors": [
      "Minghao Liu",
      "Zhitao He",
      "Zhiyuan Fan",
      "Qingyun Wang",
      "Yi R. Fung"
    ],
    "abstract": "Text-guided image editing has seen rapid progress in natural image domains,\nbut its adaptation to medical imaging remains limited and lacks standardized\nevaluation. Clinically, such editing holds promise for simulating surgical\noutcomes, creating personalized teaching materials, and enhancing patient\ncommunication. To bridge this gap, we introduce MedEBench, a comprehensive\nbenchmark for evaluating text-guided medical image editing. It consists of\n1,182 clinically sourced image-prompt triplets spanning 70 tasks across 13\nanatomical regions. MedEBench offers three key contributions: (1) a clinically\nrelevant evaluation framework covering Editing Accuracy, Contextual\nPreservation, and Visual Quality, supported by detailed descriptions of\nexpected change and ROI (Region of Interest) masks; (2) a systematic comparison\nof seven state-of-the-art models, revealing common failure patterns; and (3) a\nfailure analysis protocol based on attention grounding, using IoU between\nattention maps and ROIs to identify mislocalization. MedEBench provides a solid\nfoundation for developing and evaluating reliable, clinically meaningful\nmedical image editing systems. Project website:\nhttps://mliuby.github.io/MedEBench_Website/",
    "pdf_url": "http://arxiv.org/pdf/2506.01921v4",
    "published": "2025-06-02T17:43:01+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.02095v1",
    "title": "Cycle Consistency as Reward: Learning Image-Text Alignment without Human Preferences",
    "authors": [
      "Hyojin Bahng",
      "Caroline Chan",
      "Fredo Durand",
      "Phillip Isola"
    ],
    "abstract": "Learning alignment between language and vision is a fundamental challenge,\nespecially as multimodal data becomes increasingly detailed and complex.\nExisting methods often rely on collecting human or AI preferences, which can be\ncostly and time-intensive. We propose an alternative approach that leverages\ncycle consistency as a supervisory signal. Given an image and generated text,\nwe map the text back to image space using a text-to-image model and compute the\nsimilarity between the original image and its reconstruction. Analogously, for\ntext-to-image generation, we measure the textual similarity between an input\ncaption and its reconstruction through the cycle. We use the cycle consistency\nscore to rank candidates and construct a preference dataset of 866K comparison\npairs. The reward model trained on our dataset outperforms state-of-the-art\nalignment metrics on detailed captioning, with superior inference-time\nscalability when used as a verifier for Best-of-N sampling. Furthermore,\nperforming DPO and Diffusion DPO using our dataset enhances performance across\na wide range of vision-language tasks and text-to-image generation. Our\ndataset, model, and code are at https://cyclereward.github.io",
    "pdf_url": "http://arxiv.org/pdf/2506.02095v1",
    "published": "2025-06-02T17:42:58+00:00",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.01920v1",
    "title": "From Guidelines to Practice: A New Paradigm for Arabic Language Model Evaluation",
    "authors": [
      "Serry Sibaee",
      "Omer Nacar",
      "Adel Ammar",
      "Yasser Al-Habashi",
      "Abdulrahman Al-Batati",
      "Wadii Boulila"
    ],
    "abstract": "This paper addresses critical gaps in Arabic language model evaluation by\nestablishing comprehensive theoretical guidelines and introducing a novel\nevaluation framework. We first analyze existing Arabic evaluation datasets,\nidentifying significant issues in linguistic accuracy, cultural alignment, and\nmethodological rigor. To address these limitations in LLMs, we present the\nArabic Depth Mini Dataset (ADMD), a carefully curated collection of 490\nchallenging questions spanning ten major domains (42 sub-domains, see Figure 1.\nUsing ADMD, we evaluate five leading language models: GPT-4, Claude 3.5 Sonnet,\nGemini Flash 1.5, CommandR 100B, and Qwen-Max. Our results reveal significant\nvariations in model performance across different domains, with particular\nchallenges in areas requiring deep cultural understanding and specialized\nknowledge. Claude 3.5 Sonnet demonstrated the highest overall accuracy at 30\\%,\nshowing relative strength in mathematical theory in Arabic, Arabic language,\nand islamic domains. This work provides both theoretical foundations and\npractical insights for improving Arabic language model evaluation, emphasizing\nthe importance of cultural competence alongside technical capabilities.",
    "pdf_url": "http://arxiv.org/pdf/2506.01920v1",
    "published": "2025-06-02T17:39:50+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.01919v1",
    "title": "Transformers as Multi-task Learners: Decoupling Features in Hidden Markov Models",
    "authors": [
      "Yifan Hao",
      "Chenlu Ye",
      "Chi Han",
      "Tong Zhang"
    ],
    "abstract": "Transformer based models have shown remarkable capabilities in sequence\nlearning across a wide range of tasks, often performing well on specific task\nby leveraging input-output examples. Despite their empirical success, a\ncomprehensive theoretical understanding of this phenomenon remains limited. In\nthis work, we investigate the layerwise behavior of Transformers to uncover the\nmechanisms underlying their multi-task generalization ability. Taking\nexplorations on a typical sequence model, i.e, Hidden Markov Models, which are\nfundamental to many language tasks, we observe that: first, lower layers of\nTransformers focus on extracting feature representations, primarily influenced\nby neighboring tokens; second, on the upper layers, features become decoupled,\nexhibiting a high degree of time disentanglement. Building on these empirical\ninsights, we provide theoretical analysis for the expressiveness power of\nTransformers. Our explicit constructions align closely with empirical\nobservations, providing theoretical support for the Transformer's effectiveness\nand efficiency on sequence learning across diverse tasks.",
    "pdf_url": "http://arxiv.org/pdf/2506.01919v1",
    "published": "2025-06-02T17:39:31+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.01918v1",
    "title": "Spatial Coordinates as a Cell Language: A Multi-Sentence Framework for Imaging Mass Cytometry Analysis",
    "authors": [
      "Chi-Jane Chen",
      "Yuhang Chen",
      "Sukwon Yun",
      "Natalie Stanley",
      "Tianlong Chen"
    ],
    "abstract": "Image mass cytometry (IMC) enables high-dimensional spatial profiling by\ncombining mass cytometry's analytical power with spatial distributions of cell\nphenotypes. Recent studies leverage large language models (LLMs) to extract\ncell states by translating gene or protein expression into biological context.\nHowever, existing single-cell LLMs face two major challenges: (1) Integration\nof spatial information: they struggle to generalize spatial coordinates and\neffectively encode spatial context as text, and (2) Treating each cell\nindependently: they overlook cell-cell interactions, limiting their ability to\ncapture biological relationships. To address these limitations, we propose\nSpatial2Sentence, a novel framework that integrates single-cell expression and\nspatial information into natural language using a multi-sentence approach.\nSpatial2Sentence constructs expression similarity and distance matrices,\npairing spatially adjacent and expressionally similar cells as positive pairs\nwhile using distant and dissimilar cells as negatives. These multi-sentence\nrepresentations enable LLMs to learn cellular interactions in both expression\nand spatial contexts. Equipped with multi-task learning, Spatial2Sentence\noutperforms existing single-cell LLMs on preprocessed IMC datasets, improving\ncell-type classification by 5.98% and clinical status prediction by 4.18% on\nthe diabetes dataset while enhancing interpretability. The source code can be\nfound here: https://github.com/UNITES-Lab/Spatial2Sentence.",
    "pdf_url": "http://arxiv.org/pdf/2506.01918v1",
    "published": "2025-06-02T17:38:59+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.01917v1",
    "title": "Cavity QED with molecular defects coupled to a photonic crystal cavity",
    "authors": [
      "Christian M. Lange",
      "Arya D. Keni",
      "Ishita Agarwal",
      "Emma Daggett",
      "Adhyyan S. Mansukhani",
      "Ankit Kundu",
      "Benjamin Cerjan",
      "Libai Huang",
      "Jonathan D. Hood"
    ],
    "abstract": "We implement permanent spectral tuning to bring lifetime-limited emitters\ninto collective resonance within an integrated photonic cavity. This addresses\na fundamental challenge in solid-state cavity QED: combining multiple coherent\nquantum emitters with scalable nanophotonics. Our hybrid approach decouples\nemitter synthesis from nanophotonic fabrication using straightforward\ntechniques that make cavity QED broadly accessible. High doping densities allow\nus to couple several coherent emitters to a single cavity mode, while\noptically-induced frequency shifting provides long-lived spectral control. By\ntuning two molecules into resonance, we demonstrate controlled formation of\ncollective quantum states, establishing a scalable platform for many-body\ncavity QED. This opens pathways toward chemically-designed quantum systems\nwhere optical properties are engineered through synthetic chemistry.",
    "pdf_url": "http://arxiv.org/pdf/2506.01917v1",
    "published": "2025-06-02T17:37:02+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.01916v1",
    "title": "DNCASR: End-to-End Training for Speaker-Attributed ASR",
    "authors": [
      "Xianrui Zheng",
      "Chao Zhang",
      "Philip C. Woodland"
    ],
    "abstract": "This paper introduces DNCASR, a novel end-to-end trainable system designed\nfor joint neural speaker clustering and automatic speech recognition (ASR),\nenabling speaker-attributed transcription of long multi-party meetings. DNCASR\nuses two separate encoders to independently encode global speaker\ncharacteristics and local waveform information, along with two linked decoders\nto generate speaker-attributed transcriptions. The use of linked decoders\nallows the entire system to be jointly trained under a unified loss function.\nBy employing a serialised training approach, DNCASR effectively addresses\noverlapping speech in real-world meetings, where the link improves the\nprediction of speaker indices in overlapping segments. Experiments on the\nAMI-MDM meeting corpus demonstrate that the jointly trained DNCASR outperforms\na parallel system that does not have links between the speaker and ASR\ndecoders. Using cpWER to measure the speaker-attributed word error rate, DNCASR\nachieves a 9.0% relative reduction on the AMI-MDM Eval set.",
    "pdf_url": "http://arxiv.org/pdf/2506.01916v1",
    "published": "2025-06-02T17:36:57+00:00",
    "categories": [
      "eess.AS"
    ],
    "primary_category": "eess.AS"
  },
  {
    "id": "http://arxiv.org/abs/2506.01915v1",
    "title": "Magnetic correlations in the $SU(3)$ triangular-lattice $t$-$J$ model at finite doping",
    "authors": [
      "Annika Böhler",
      "Fabian Grusdt",
      "Annabelle Bohrdt"
    ],
    "abstract": "Quantum simulation platforms have become powerful tools for investigating\nstrongly correlated systems beyond the capabilities of classical computation.\nUltracold alkaline-earth atoms and molecules now enable experimental\nrealizations of SU(N)-symmetric Fermi-Hubbard models, yet theoretical\nunderstanding of these systems, particularly at finite doping remains limited.\nHere we investigate the strong-coupling limit of the $SU(3)$ symmetric\nFermi-Hubbard model on the triangular lattice with dimensions up to $9\\times9$\nlattice sites across the full doping range. Using a three-flavor extension of\nGutzwiller-projected hidden fermion determinant states (G-HFDS), a neural\nnetwork based variational ansatz, we analyze two- and three-point spin-spin and\nspin-spin-hole correlations of the $SU(3)$ Cartan generators. We further study\nbinding energies for large periodic systems, and compare our results to the\nparadigmatic $SU(2)$ square lattice equivalent, finding strikingly similar\nmagnetic correlations, but enhanced binding energies. Our results provide a\nfoundation for future exploration of doped SU(N) Mott insulators, providing\nvaluable insights for both theoretical developments and quantum simulation\nexperiments.",
    "pdf_url": "http://arxiv.org/pdf/2506.01915v1",
    "published": "2025-06-02T17:35:58+00:00",
    "categories": [
      "cond-mat.quant-gas",
      "cond-mat.dis-nn",
      "cond-mat.str-el"
    ],
    "primary_category": "cond-mat.quant-gas"
  },
  {
    "id": "http://arxiv.org/abs/2506.01914v1",
    "title": "Multi-sample rank tests for location against Lehmann-type alternatives",
    "authors": [
      "Nikolay I. Nikolov",
      "Eugenia Stoimenova"
    ],
    "abstract": "This paper deals with testing the equality of $k$ ($k\\ge 2$) distribution\nfunctions against possible stochastic ordering among them. Two classes of rank\ntests are proposed for this testing problem. The statistics of the tests under\nstudy are based on precedence and exceedance statistics and are natural\nextension of corresponding statistics for the two-sample testing problem.\nFurthermore, as an extension of the Lehmann alternative for the two-sample\nlocation problem, we propose a new subclass of the general alternative for the\nstochastic order of multiple samples. We show that under the new Lehmann-type\nalternative any rank test statistics is distribution free. The power functions\nof the two new families of rank tests are compared to the power performance of\nthe Jonckheere-Terpstra rank test.",
    "pdf_url": "http://arxiv.org/pdf/2506.01914v1",
    "published": "2025-06-02T17:34:46+00:00",
    "categories": [
      "math.ST",
      "stat.TH"
    ],
    "primary_category": "math.ST"
  },
  {
    "id": "http://arxiv.org/abs/2506.01913v1",
    "title": "Generalized Gradient Norm Clipping & Non-Euclidean $(L_0,L_1)$-Smoothness",
    "authors": [
      "Thomas Pethick",
      "Wanyun Xie",
      "Mete Erdogan",
      "Kimon Antonakopoulos",
      "Tony Silveti-Falls",
      "Volkan Cevher"
    ],
    "abstract": "This work introduces a hybrid non-Euclidean optimization method which\ngeneralizes gradient norm clipping by combining steepest descent and\nconditional gradient approaches. The method achieves the best of both worlds by\nestablishing a descent property under a generalized notion of\n($L_0$,$L_1$)-smoothness. Weight decay is incorporated in a principled manner\nby identifying a connection to the Frank-Wolfe short step. In the stochastic\ncase, we show an order optimal $O(n^{-1/4})$ convergence rate by leveraging a\nmomentum based gradient estimator. We discuss how to instantiate the algorithms\nfor deep learning and demonstrate their properties on image classification and\nlanguage modeling.",
    "pdf_url": "http://arxiv.org/pdf/2506.01913v1",
    "published": "2025-06-02T17:34:29+00:00",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.01912v1",
    "title": "Elucidating the representation of images within an unconditional diffusion model denoiser",
    "authors": [
      "Zahra Kadkhodaie",
      "Stéphane Mallat",
      "Eero Simoncelli"
    ],
    "abstract": "Generative diffusion models learn probability densities over diverse image\ndatasets by estimating the score with a neural network trained to remove noise.\nDespite their remarkable success in generating high-quality images, the\ninternal mechanisms of the underlying score networks are not well understood.\nHere, we examine a UNet trained for denoising on the ImageNet dataset, to\nbetter understand its internal representation and computation of the score. We\nshow that the middle block of the UNet decomposes individual images into sparse\nsubsets of active channels, and that the vector of spatial averages of these\nchannels can provide a nonlinear representation of the underlying clean images.\nWe develop a novel algorithm for stochastic reconstruction of images from this\nrepresentation and demonstrate that it recovers a sample from a set of images\ndefined by a target image representation. We then study the properties of the\nrepresentation and demonstrate that Euclidean distances in the latent space\ncorrespond to distances between conditional densities induced by\nrepresentations as well as semantic similarities in the image space. Applying a\nclustering algorithm in the representation space yields groups of images that\nshare both fine details (e.g., specialized features, textured regions, small\nobjects), as well as global structure, but are only partially aligned with\nobject identities. Thus, we show for the first time that a network trained\nsolely on denoising contains a rich and accessible sparse representation of\nimages.",
    "pdf_url": "http://arxiv.org/pdf/2506.01912v1",
    "published": "2025-06-02T17:33:34+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.01911v1",
    "title": "Parity solves the Strong CP problem",
    "authors": [
      "Ravi Kuchimanchi"
    ],
    "abstract": "A recent paper \"What can solve the strong CP problem?\" goes counter to\nconventional wisdom by arguing that the universe was in an initial state that\ncombines different eigenstates of $\\theta$ (of the theta vacuum of QCD), and\nasserts that for such an initial state, axionless solutions to the Strong CP\nProblem based on P and CP symmetries will not work. We discuss the nature of\nthe theta vacuum in light of this work, and find that the conventional framing\nand solutions based on P and CP symmetries are on a firm footing.",
    "pdf_url": "http://arxiv.org/pdf/2506.01911v1",
    "published": "2025-06-02T17:33:29+00:00",
    "categories": [
      "hep-ph"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.01910v2",
    "title": "GLoSS: Generative Language Models with Semantic Search for Sequential Recommendation",
    "authors": [
      "Krishna Acharya",
      "Aleksandr V. Petrov",
      "Juba Ziani"
    ],
    "abstract": "We propose Generative Low-rank language model with Semantic Search (GLoSS), a\ngenerative recommendation framework that combines large language models with\ndense retrieval for sequential recommendation. Unlike prior methods such as\nGPT4Rec, which rely on lexical matching via BM25, GLoSS uses semantic search to\nretrieve relevant items beyond lexical matching. For query generation, we\nemploy 4-bit quantized LlaMA-3 models fine-tuned with low-rank adaptation\n(LoRA), enabling efficient training and inference on modest hardware. We\nevaluate GLoSS on three real-world Amazon review datasets: Beauty, Toys, and\nSports, and find that it achieves state-of-the-art performance. Compared to\ntraditional ID-based baselines, GLoSS improves Recall@5 by 33.3%, 52.8%, and\n15.2%, and NDCG@5 by 30.0%, 42.6%, and 16.1%, respectively. It also outperforms\nLLM-based recommenders such as P5, GPT4Rec, LlamaRec and E4SRec with Recall@5\ngains of 4.3%, 22.8%, and 29.5%. Additionally, user segment evaluations show\nthat GLoSS performs particularly well for cold-start users in the Amazon Toys\nand Sports datasets, and benefits from longer user histories in Amazon Beauty\ndataset, demonstrating robustness across different levels of interaction\nlengths.",
    "pdf_url": "http://arxiv.org/pdf/2506.01910v2",
    "published": "2025-06-02T17:31:42+00:00",
    "categories": [
      "cs.IR"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2506.01909v1",
    "title": "Coarse-graining dynamics to maximize irreversibility",
    "authors": [
      "Qiwei Yu",
      "Matthew P. Leighton",
      "Christopher W. Lynn"
    ],
    "abstract": "In many far-from-equilibrium biological systems, energy injected by\nirreversible processes at microscopic scales propagates to larger scales to\nfulfill important biological functions. But given dissipative dynamics at the\nmicroscale, how much irreversibility can persist at the macroscale? Here, we\npropose a model-free coarse-graining procedure that merges microscopic states\nto minimize the amount of lost irreversibility. Beginning with dynamical\nmeasurements, this procedure produces coarse-grained dynamics that retain as\nmuch information as possible about the underlying irreversibility. In synthetic\nand experimental data spanning molecular motors, biochemical oscillators, and\nrecordings of neural activity, we derive simplified descriptions that capture\nthe essential nonequilibrium processes. These results provide the tools to\nstudy the fundamental limits on the emergence of macroscopic irreversibility.",
    "pdf_url": "http://arxiv.org/pdf/2506.01909v1",
    "published": "2025-06-02T17:31:33+00:00",
    "categories": [
      "cond-mat.stat-mech",
      "cond-mat.dis-nn",
      "physics.bio-ph",
      "q-bio.QM"
    ],
    "primary_category": "cond-mat.stat-mech"
  },
  {
    "id": "http://arxiv.org/abs/2506.01908v1",
    "title": "Reinforcement Learning Tuning for VideoLLMs: Reward Design and Data Efficiency",
    "authors": [
      "Hongyu Li",
      "Songhao Han",
      "Yue Liao",
      "Junfeng Luo",
      "Jialin Gao",
      "Shuicheng Yan",
      "Si Liu"
    ],
    "abstract": "Understanding real-world videos with complex semantics and long temporal\ndependencies remains a fundamental challenge in computer vision. Recent\nprogress in multimodal large language models (MLLMs) has demonstrated strong\ncapabilities in vision-language tasks, while reinforcement learning tuning\n(RLT) has further improved their reasoning abilities. In this work, we explore\nRLT as a post-training strategy to enhance the video-specific reasoning\ncapabilities of MLLMs. Built upon the Group Relative Policy Optimization (GRPO)\nframework, we propose a dual-reward formulation that supervises both semantic\nand temporal reasoning through discrete and continuous reward signals. To\nfacilitate effective preference-based optimization, we introduce a\nvariance-aware data selection strategy based on repeated inference to identify\nsamples that provide informative learning signals. We evaluate our approach\nacross eight representative video understanding tasks, including VideoQA,\nTemporal Video Grounding, and Grounded VideoQA. Our method consistently\noutperforms supervised fine-tuning and existing RLT baselines, achieving\nsuperior performance with significantly less training data. These results\nunderscore the importance of reward design and data selection in advancing\nreasoning-centric video understanding with MLLMs. Notably, The initial code\nrelease (two months ago) has now been expanded with updates, including\noptimized reward mechanisms and additional datasets. The latest version is\navailable at https://github.com/appletea233/Temporal-R1 .",
    "pdf_url": "http://arxiv.org/pdf/2506.01908v1",
    "published": "2025-06-02T17:28:26+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.01907v1",
    "title": "SMOTE-DP: Improving Privacy-Utility Tradeoff with Synthetic Data",
    "authors": [
      "Yan Zhou",
      "Bradley Malin",
      "Murat Kantarcioglu"
    ],
    "abstract": "Privacy-preserving data publication, including synthetic data sharing, often\nexperiences trade-offs between privacy and utility. Synthetic data is generally\nmore effective than data anonymization in balancing this trade-off, however,\nnot without its own challenges. Synthetic data produced by generative models\ntrained on source data may inadvertently reveal information about outliers.\nTechniques specifically designed for preserving privacy, such as introducing\nnoise to satisfy differential privacy, often incur unpredictable and\nsignificant losses in utility. In this work we show that, with the right\nmechanism of synthetic data generation, we can achieve strong privacy\nprotection without significant utility loss. Synthetic data generators\nproducing contracting data patterns, such as Synthetic Minority Over-sampling\nTechnique (SMOTE), can enhance a differentially private data generator,\nleveraging the strengths of both. We prove in theory and through empirical\ndemonstration that this SMOTE-DP technique can produce synthetic data that not\nonly ensures robust privacy protection but maintains utility in downstream\nlearning tasks.",
    "pdf_url": "http://arxiv.org/pdf/2506.01907v1",
    "published": "2025-06-02T17:27:10+00:00",
    "categories": [
      "cs.LG",
      "cs.CR",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.01906v1",
    "title": "Flux Trapping Characterization for Superconducting Electronics Using a Cryogenic Widefield NV-Diamond Microscope",
    "authors": [
      "Rohan T. Kapur",
      "Pauli Kehayias",
      "Sergey K. Tolpygo",
      "Adam A. Libson",
      "George Haldeman",
      "Collin N. Muniz",
      "Alex Wynn",
      "Nathaniel J. O'Connor",
      "Neel A. Parmar",
      "Ryan Johnson",
      "Andrew C. Maccabe",
      "John Cummings",
      "Justin L. Mallek",
      "Danielle A. Braje",
      "Jennifer M. Schloss"
    ],
    "abstract": "Magnetic flux trapping is a significant hurdle limiting reliability and\nscalability of superconducting electronics, yet tools for imaging flux vortices\nremain slow or insensitive. We present a cryogenic widefield NV-diamond\nmagnetic microscope capable of rapid, micron-scale imaging of flux trapping in\nsuperconducting devices. Using this technique, we measure vortex expulsion\nfields in Nb thin films and patterned strips, revealing a crossover in\nexpulsion behavior between $10$ and $20~\\mu$m strip widths. The observed\nscaling agrees with theoretical models and suggests the influence of film\ndefects on vortex expulsion dynamics. This instrument enables high-throughput\nmagnetic characterization of superconducting materials and circuits, providing\nnew insight for flux mitigation strategies in scalable superconducting\nelectronics.",
    "pdf_url": "http://arxiv.org/pdf/2506.01906v1",
    "published": "2025-06-02T17:26:55+00:00",
    "categories": [
      "cond-mat.supr-con",
      "physics.app-ph",
      "physics.ins-det",
      "quant-ph"
    ],
    "primary_category": "cond-mat.supr-con"
  },
  {
    "id": "http://arxiv.org/abs/2506.01905v1",
    "title": "Tree-based methods for estimating heterogeneous model performance and model combining",
    "authors": [
      "Ruotao Zhang",
      "Constantine Gatsonis",
      "Jon Steingrimsson"
    ],
    "abstract": "Model performance is frequently reported only for the overall population\nunder consideration. However, due to heterogeneity, overall performance\nmeasures often do not accurately represent model performance within specific\nsubgroups. We develop tree-based methods for the data-driven identification of\nsubgroups with differential model performance, where splitting decisions are\nmade to maximize heterogeneity in performance between subgroups. We extend\nthese methods to tree ensembles, including both random forests and gradient\nboosting. Lastly, we illustrate how these ensembles can be used for model\ncombination. We evaluate the methods through simulations and apply them to lung\ncancer screening data.",
    "pdf_url": "http://arxiv.org/pdf/2506.01905v1",
    "published": "2025-06-02T17:26:47+00:00",
    "categories": [
      "stat.ME"
    ],
    "primary_category": "stat.ME"
  },
  {
    "id": "http://arxiv.org/abs/2506.01904v1",
    "title": "Machine-Learned Sampling of Conditioned Path Measures",
    "authors": [
      "Qijia Jiang",
      "Reuben Cohn-Gordon"
    ],
    "abstract": "We propose algorithms for sampling from posterior path measures $P(C([0, T],\n\\mathbb{R}^d))$ under a general prior process. This leverages ideas from (1)\ncontrolled equilibrium dynamics, which gradually transport between two path\nmeasures, and (2) optimization in $\\infty$-dimensional probability space\nendowed with a Wasserstein metric, which can be used to evolve a density curve\nunder the specified likelihood. The resulting algorithms are theoretically\ngrounded and can be integrated seamlessly with neural networks for learning the\ntarget trajectory ensembles, without access to data.",
    "pdf_url": "http://arxiv.org/pdf/2506.01904v1",
    "published": "2025-06-02T17:25:03+00:00",
    "categories": [
      "stat.ML",
      "cs.LG",
      "stat.CO"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2506.01903v1",
    "title": "Getting almost all the bits from a quantum random access code",
    "authors": [
      "Han-Hsuan Lin",
      "Ronald de Wolf"
    ],
    "abstract": "A quantum random access code (QRAC) is a map $x\\mapsto\\rho_x$ that encodes\n$n$-bit strings $x$ into $m$-qubit quantum states $\\rho_x$, in a way that\nallows us to recover any one bit of $x$ with success probability $\\geq p$. The\nmeasurement on $\\rho_x$ that is used to recover, say, $x_1$ may destroy all the\ninformation about the other bits; this is in fact what happens in the\nwell-known QRAC that encodes $n=2$ bits into $m=1$ qubits. Does this generalize\nto large $n$, i.e., could there exist QRACs that are so \"obfuscated\" that one\ncannot get much more than one bit out of them? Here we show that this is not\nthe case: for every QRAC there exists a measurement that (with high\nprobability) recovers the full $n$-bit string $x$ up to small Hamming distance,\neven for the worst-case $x$.",
    "pdf_url": "http://arxiv.org/pdf/2506.01903v1",
    "published": "2025-06-02T17:24:30+00:00",
    "categories": [
      "quant-ph",
      "cs.IR"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.01902v1",
    "title": "Enhancing Biomedical Multi-modal Representation Learning with Multi-scale Pre-training and Perturbed Report Discrimination",
    "authors": [
      "Xinliu Zhong",
      "Kayhan Batmanghelich",
      "Li Sun"
    ],
    "abstract": "Vision-language models pre-trained on large scale of unlabeled biomedical\nimages and associated reports learn generalizable semantic representations.\nThese multi-modal representations can benefit various downstream tasks in the\nbiomedical domain. Contrastive learning is widely used to pre-train\nvision-language models for general natural images and associated captions.\nDespite its popularity, we found biomedical texts have complex and\ndomain-specific semantics that are often neglected by common contrastive\nmethods. To address this issue, we propose a novel method, perturbed report\ndiscrimination, for pre-train biomedical vision-language models. First, we\ncurate a set of text perturbation methods that keep the same words, but disrupt\nthe semantic structure of the sentence. Next, we apply different types of\nperturbation to reports, and use the model to distinguish the original report\nfrom the perturbed ones given the associated image. Parallel to this, we\nenhance the sensitivity of our method to higher level of granularity for both\nmodalities by contrasting attention-weighted image sub-regions and sub-words in\nthe image-text pairs. We conduct extensive experiments on multiple downstream\ntasks, and our method outperforms strong baseline methods. The results\ndemonstrate that our approach learns more semantic meaningful and robust\nmulti-modal representations.",
    "pdf_url": "http://arxiv.org/pdf/2506.01902v1",
    "published": "2025-06-02T17:23:25+00:00",
    "categories": [
      "cs.CV",
      "cs.CL"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.01901v1",
    "title": "Understanding Overadaptation in Supervised Fine-Tuning: The Role of Ensemble Methods",
    "authors": [
      "Yifan Hao",
      "Xingyuan Pan",
      "Hanning Zhang",
      "Chenlu Ye",
      "Rui Pan",
      "Tong Zhang"
    ],
    "abstract": "Supervised fine-tuning (SFT) on domain-specific data is the dominant approach\nfor adapting foundation models to specialized tasks. However, it has been\nobserved that SFT models tend to forget knowledge acquired during pretraining.\nIn vision models, ensembling a pretrained model with its fine-tuned counterpart\nhas been shown to mitigate this issue. In this work, we demonstrate that the\nsame holds for language models, and, more strikingly, we observe an\noveradaptation phenomenon: the ensemble model not only retains general\nknowledge from the foundation model but also outperforms the fine-tuned model\neven on the fine-tuning domain itself. Despite the empirical success of\nensembling, a theoretical understanding of its benefits remains underexplored.\nWe develop a formal theoretical analysis of the overadaptation phenomenon.\nEnsembling mitigates this by balancing two primary sources of error: bias,\ncaused by insufficient fine-tuning, and variance, introduced by overfitting to\nfine-tuning data. While regularization techniques aim to address this\ntrade-off, we show that ensembling provides a more effective solution. We\nanalyze this phenomenon in over-parameterized linear settings and demonstrate\nthat interpolating between pretrained and fine-tuned weights significantly\nimproves performance. These findings offer theoretical justification for the\nobserved advantages of model ensembling, supported by empirical experiments\nconsistent with our analysis.",
    "pdf_url": "http://arxiv.org/pdf/2506.01901v1",
    "published": "2025-06-02T17:23:16+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2506.01900v1",
    "title": "COALESCE: Economic and Security Dynamics of Skill-Based Task Outsourcing Among Team of Autonomous LLM Agents",
    "authors": [
      "Manish Bhatt",
      "Ronald F. Del Rosario",
      "Vineeth Sai Narajala",
      "Idan Habler"
    ],
    "abstract": "The meteoric rise and proliferation of autonomous Large Language Model (LLM)\nagents promise significant capabilities across various domains. However, their\ndeployment is increasingly constrained by substantial computational demands,\nspecifically for Graphics Processing Unit (GPU) resources. This paper addresses\nthe critical problem of optimizing resource utilization in LLM agent systems.\nWe introduce COALESCE (Cost-Optimized and Secure Agent Labour Exchange via\nSkill-based Competence Estimation), a novel framework designed to enable\nautonomous LLM agents to dynamically outsource specific subtasks to\nspecialized, cost-effective third-party LLM agents. The framework integrates\nmechanisms for hybrid skill representation, dynamic skill discovery, automated\ntask decomposition, a unified cost model comparing internal execution costs\nagainst external outsourcing prices, simplified market-based decision-making\nalgorithms, and a standardized communication protocol between LLM agents.\nComprehensive validation through 239 theoretical simulations demonstrates\n41.8\\% cost reduction potential, while large-scale empirical validation across\n240 real LLM tasks confirms 20.3\\% cost reduction with proper epsilon-greedy\nexploration, establishing both theoretical viability and practical\neffectiveness. The emergence of proposed open standards like Google's\nAgent2Agent (A2A) protocol further underscores the need for frameworks like\nCOALESCE that can leverage such standards for efficient agent interaction. By\nfacilitating a dynamic market for agent capabilities, potentially utilizing\nprotocols like A2A for communication, COALESCE aims to significantly reduce\noperational costs, enhance system scalability, and foster the emergence of\nspecialized agent economies, making complex LLM agent functionalities more\naccessible and economically viable.",
    "pdf_url": "http://arxiv.org/pdf/2506.01900v1",
    "published": "2025-06-02T17:22:47+00:00",
    "categories": [
      "cs.AI",
      "cs.CE",
      "cs.CR"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2506.01899v1",
    "title": "The Complexity of Correlated Equilibria in Generalized Games",
    "authors": [
      "Martino Bernasconi",
      "Matteo Castiglioni",
      "Andrea Celli",
      "Gabriele Farina"
    ],
    "abstract": "Correlated equilibria -- and their generalization $\\Phi$-equilibria -- are a\nfundamental object of study in game theory, offering a more tractable\nalternative to Nash equilibria in multi-player settings. While computational\naspects of equilibrium computation are well-understood in some settings,\nfundamental questions are still open in generalized games, that is, games in\nwhich the set of strategies allowed to each player depends on the other\nplayers' strategies. These classes of games model fundamental settings in\neconomics and have been a cornerstone of economics research since the seminal\npaper of Arrow and Debreu [1954]. Recently, there has been growing interest,\nboth in economics and in computer science, in studying correlated equilibria in\ngeneralized games. It is known that finding a social welfare maximizing\ncorrelated equilibrium in generalized games is NP-hard. However, the existence\nof efficient algorithms to find any equilibrium remains an important open\nquestion. In this paper, we answer this question negatively, showing that this\nproblem is PPAD-complete.",
    "pdf_url": "http://arxiv.org/pdf/2506.01899v1",
    "published": "2025-06-02T17:21:51+00:00",
    "categories": [
      "cs.GT"
    ],
    "primary_category": "cs.GT"
  },
  {
    "id": "http://arxiv.org/abs/2506.01898v2",
    "title": "Multiband parameter estimation with phase coherence and extrinsic marginalization: Extracting more information from low-SNR CBC signals in LISA data",
    "authors": [
      "Shichao Wu",
      "Alexander H. Nitz",
      "Ian Harry",
      "Stanislav Babak",
      "Michael J. Williams",
      "Collin Capano",
      "Connor Weaving"
    ],
    "abstract": "This paper presents a novel coherent multiband analysis framework for\ncharacterizing stellar- and intermediate-mass binary black holes using LISA and\nnext-generation ground-based detectors (ET and CE), leveraging the latest\ndevelopments in the \\texttt{PyCBC} pipeline. Given the population parameters\ninferred from LVK results and LISA's sensitivity limits at high frequencies,\nmost stellar-mass binary black holes would likely have SNRs below 5 in LISA,\nbut the most state-of-the-art multiband parameter estimation methods, such as\nthose using ET and CE posteriors as priors for LISA, typically struggle to\nanalyze sources with a LISA SNR less than 5. We present a novel coherent\nmultiband parameter estimation method that directly calculates a joint\nlikelihood, which is highly efficient; this efficiency is enabled by multiband\nmarginalization of the extrinsic parameter space, implemented using importance\nsampling, which can work robustly even when the LISA SNR is as low as 3. Having\nan SNR of $\\sim 3$ allows LISA to contribute nearly double the number of\nmultiband sources. Even if LISA only observes for one year, most of the\nmultiband detector-frame chirp mass's 90\\% credible interval (less than\n$10^{-4} \\mathrm{M}_\\odot$) is still better than that of the most accurately\nmeasured events for ET+2CE network in 7.5 years of observation, by at least one\norder of magnitude. For the first time, we show efficient multiband Bayesian\nparameter estimation results on the population scale, which paves the way for\nlarge-scale astrophysical tests using multibanding.",
    "pdf_url": "http://arxiv.org/pdf/2506.01898v2",
    "published": "2025-06-02T17:21:37+00:00",
    "categories": [
      "gr-qc",
      "astro-ph.IM"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2506.01897v2",
    "title": "MLorc: Momentum Low-rank Compression for Large Language Model Adaptation",
    "authors": [
      "Wei Shen",
      "Zhang Yaxiang",
      "Minhui Huang",
      "Mengfan Xu",
      "Jiawei Zhang",
      "Cong Shen"
    ],
    "abstract": "With increasing size of large language models (LLMs), full-parameter\nfine-tuning imposes substantial memory demands. To alleviate this, we propose a\nnovel memory-efficient training paradigm called Momentum Low-rank compression\n(MLorc). By directly compressing and reconstructing momentum rather than\ngradients, MLorc avoids imposing a fixed-rank constraint on weight update\nmatrices and better preserves the training dynamics of full-parameter\nfine-tuning, in contrast to existing low-rank approaches such as LoRA and\nGaLore. Empirically, MLorc consistently outperforms other memory-efficient\ntraining methods, matches or even exceeds the performance of full fine-tuning\nwith a small rank (e.g., $r=4$), and generalizes well across different\noptimizers -- all while not compromising time or memory efficiency.\nFurthermore, we provide a theoretical guarantee for its convergence under\nreasonable assumptions.",
    "pdf_url": "http://arxiv.org/pdf/2506.01897v2",
    "published": "2025-06-02T17:21:10+00:00",
    "categories": [
      "cs.LG",
      "cs.IT",
      "math.IT",
      "math.OC"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.01895v1",
    "title": "Second quantization of nonlinear Vlasov-Poisson system for quantum computation",
    "authors": [
      "Michael Q. May",
      "Hong Qin"
    ],
    "abstract": "The Vlasov-Poisson equations, fundamental in plasma physics and astrophysical\napplications, are rendered linear, finite-dimensional, and discrete by second\nquantization. Conditions for correspondence between the pre-quantized and\nquantized equations are derived, and numerical simulations demonstrating the\nquantized linear system can capture nonlinear dynamics are presented. Finally,\nencouraging scaling relations emphasizing the prospect of using quantum\ncomputers to efficiently integrate the second quantized Vlasov-Poisson\nequations as a model for the usual Vlasov-Poisson equations are derived.",
    "pdf_url": "http://arxiv.org/pdf/2506.01895v1",
    "published": "2025-06-02T17:20:25+00:00",
    "categories": [
      "physics.plasm-ph",
      "quant-ph"
    ],
    "primary_category": "physics.plasm-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.01896v1",
    "title": "Sums and differences of sets: a further improvement over AlphaEvolve",
    "authors": [
      "Fan Zheng"
    ],
    "abstract": "We present a new advancement in the sum and difference of sets problem, which\nimproves upon recent results by both DeepMind's AlphaEvolve ($\\theta = 1.1584$)\nand subsequent explicit constructions ($\\theta = 1.173050$). In this work, we\nconstruct a sequence of $U$ sets which in the limit establishes a new lower\nbound of $\\theta = 1.173077$.",
    "pdf_url": "http://arxiv.org/pdf/2506.01896v1",
    "published": "2025-06-02T17:20:25+00:00",
    "categories": [
      "math.CO",
      "math.NT"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2506.01894v1",
    "title": "Enhancing van-Hove singularities in SrRuO$_3$ films by vacancy engineerings",
    "authors": [
      "Moon Hyoung Lee",
      "Hyungwoo Lee",
      "Jun-Won Rhim"
    ],
    "abstract": "Flat bands, characterized by their localized electronic states and van Hove\nsingularities, provide an ideal platform for exploring many-body physics.\nHowever, transition metal oxides hosting flat bands are quite rare. In this\nstudy, we investigate the origin of the existing nearly flat bands (NFBs) in\nSrRuO$_3$ thin films and demonstrate how to increase the number of them through\nstructural modifications. Using a tight-binding model that replicates\nexperimental band structures, we analyze the SrRuO$_3$ monolayer, revealing the\norigin of its NFBs along the $x$ and $y$ directions. These NFBs arise from\ndestructive interference stabilizing strip-type compact localized states. By\nintroducing periodic Ru-site vacancies, additional NFBs are generated,\nclassified as partial or complete, depending on their Brillouin zone coverage.\nThe compact localized states associated with these NFBs are identified,\nproviding insight into their physical origin. For a 4-layer SrRuO$_3$\nmultilayer film, we uncover many partial NFBs along the $\\Gamma$X and XM\ndirections and reveal the distinct origin of their development. Our findings\nhighlight the potential of engineering flat bands in SrRuO$_3$ films, offering\nnew opportunities for exploring correlated electronic phases and expanding the\nmaterial platform for flat-band physics.",
    "pdf_url": "http://arxiv.org/pdf/2506.01894v1",
    "published": "2025-06-02T17:20:19+00:00",
    "categories": [
      "cond-mat.str-el"
    ],
    "primary_category": "cond-mat.str-el"
  },
  {
    "id": "http://arxiv.org/abs/2506.01893v2",
    "title": "Variational Inference for Latent Variable Models in High Dimensions",
    "authors": [
      "Chenyang Zhong",
      "Sumit Mukherjee",
      "Bodhisattva Sen"
    ],
    "abstract": "Variational inference (VI) is a popular method for approximating intractable\nposterior distributions in Bayesian inference and probabilistic machine\nlearning. In this paper, we introduce a general framework for quantifying the\nstatistical accuracy of mean-field variational inference (MFVI) for posterior\napproximation in Bayesian latent variable models with categorical local latent\nvariables (and arbitrary global latent variables). Utilizing our general\nframework, we capture the exact regime where MFVI 'works' for the celebrated\nlatent Dirichlet allocation model. Focusing on the mixed membership stochastic\nblockmodel, we show that the vanilla fully factorized MFVI, often used in the\nliterature, is suboptimal. We propose a partially grouped VI algorithm for this\nmodel and show that it works, and derive its exact finite-sample performance.\nWe further illustrate that our bounds are tight for both the above models. Our\nproof techniques, which extend the framework of nonlinear large deviations,\nopen the door for the analysis of MFVI in other latent variable models.",
    "pdf_url": "http://arxiv.org/pdf/2506.01893v2",
    "published": "2025-06-02T17:19:58+00:00",
    "categories": [
      "math.ST",
      "math.PR",
      "stat.ML",
      "stat.TH",
      "62F15, 62C10, 60F10"
    ],
    "primary_category": "math.ST"
  },
  {
    "id": "http://arxiv.org/abs/2506.01892v1",
    "title": "Coherent polarization self-rotation",
    "authors": [
      "Roy Shaham",
      "Orr Meron",
      "Or Katz",
      "Dimitry Yankelev",
      "Ofer Firstenberg"
    ],
    "abstract": "We introduce and study coherent polarization self-rotation (CPSR), a\ntwo-photon light-matter interaction in dense alkali-metal vapors that enables\nboth narrowband optical spectroscopy of magnetic transitions and coherent\ncoupling between light and collective atomic spins. Unlike conventional\npolarization self-rotation, CPSR requires initial spin polarization and a\npredominantly linearly polarized probe. It operates efficiently even in\noptically thick vapors with high buffer-gas pressure, rapid spin-exchange\ncollisions, and optically-unresolved hyperfine structure. We demonstrate CPSR\nwith near-unity contrast in rubidium and achieve an exceptionally narrow\ntwo-photon linewidth of 10 Hz in potassium. CPSR realizes a coherent interface\nbetween one optical quadrature and the long-lived collective electronic spin,\noffering a robust and scalable light-spin coupling in optically thick\nplatforms. This opens new opportunities for quantum optics, including coherent\ntransduction between light and ultra-long-lived noble-gas spins via alkali\nspins.",
    "pdf_url": "http://arxiv.org/pdf/2506.01892v1",
    "published": "2025-06-02T17:18:48+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.01891v4",
    "title": "Probing Quantum Spin Systems with Kolmogorov-Arnold Neural Network Quantum States",
    "authors": [
      "Mahmud Ashraf Shamim",
      "Eric A F Reinhardt",
      "Talal Ahmed Chowdhury",
      "Sergei Gleyzer",
      "Paulo T Araujo"
    ],
    "abstract": "Neural Quantum States (NQS) are a class of variational wave functions\nparametrized by neural networks (NNs) to study quantum many-body systems. In\nthis work, we propose \\texttt{SineKAN}, a NQS \\textit{ansatz} based on\nKolmogorov-Arnold Networks (KANs), to represent quantum mechanical wave\nfunctions as nested univariate functions. We show that \\texttt{SineKAN}\nwavefunction with learnable sinusoidal activation functions can capture the\nground state energies, fidelities and various correlation functions of the one\ndimensional Transverse-Field Ising model, Anisotropic Heisenberg model, and\nAntiferromagnetic $J_{1}-J_{2}$ model with different chain lengths. In our\nstudy of the $J_1-J_2$ model with $L=100$ sites, we find that the\n\\texttt{SineKAN} model outperforms several previously explored neural quantum\nstate \\textit{ans\\\"atze}, including Restricted Boltzmann Machines (RBMs), Long\nShort-Term Memory models (LSTMs), and Multi-layer Perceptrons (MLP)\n\\textit{a.k.a.} Feed Forward Neural Networks, when compared to the results\nobtained from the Density Matrix Renormalization Group (DMRG) algorithm. We\nfind that \\texttt{SineKAN} models can be trained to high precisions and\naccuracies with minimal computational costs.",
    "pdf_url": "http://arxiv.org/pdf/2506.01891v4",
    "published": "2025-06-02T17:18:40+00:00",
    "categories": [
      "quant-ph",
      "cond-mat.dis-nn",
      "cond-mat.str-el",
      "cs.LG"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.02094v1",
    "title": "Generative AI for Multiple Choice STEM Assessments",
    "authors": [
      "Christina Perdikoulias",
      "Chad Vance",
      "Stephen M. Watt"
    ],
    "abstract": "Artificial intelligence technology enables a range of enhancements in\ncomputer-aided instruction, from accelerating the creation of teaching\nmaterials to customizing learning paths based on learner outcomes. However,\nensuring the mathematical accuracy and semantic integrity of generative AI\noutput remains a significant challenge, particularly in STEM disciplines. In\nthis study, we explore the use of generative AI in which \"hallucinations\" --\ntypically viewed as undesirable inaccuracies -- can instead serve a pedagogical\npurpose. Specifically, we investigate the generation of plausible but incorrect\nalternatives for multiple choice assessments, where credible distractors are\nessential for effective assessment design. We describe the M\\\"obius platform\nfor online instruction, with particular focus on its architecture for handling\nmathematical elements through specialized semantic packages that support\ndynamic, parameterized STEM content. We examine methods for crafting prompts\nthat interact effectively with these mathematical semantics to guide the AI in\ngenerating high-quality multiple choice distractors. Finally, we demonstrate\nhow this approach reduces the time and effort associated with creating robust\nteaching materials while maintaining academic rigor and assessment validity.",
    "pdf_url": "http://arxiv.org/pdf/2506.02094v1",
    "published": "2025-06-02T17:17:37+00:00",
    "categories": [
      "cs.CY"
    ],
    "primary_category": "cs.CY"
  },
  {
    "id": "http://arxiv.org/abs/2506.01890v1",
    "title": "CogniAlign: Word-Level Multimodal Speech Alignment with Gated Cross-Attention for Alzheimer's Detection",
    "authors": [
      "David Ortiz-Perez",
      "Manuel Benavent-Lledo",
      "Javier Rodriguez-Juan",
      "Jose Garcia-Rodriguez",
      "David Tomás"
    ],
    "abstract": "Early detection of cognitive disorders such as Alzheimer's disease is\ncritical for enabling timely clinical intervention and improving patient\noutcomes. In this work, we introduce CogniAlign, a multimodal architecture for\nAlzheimer's detection that integrates audio and textual modalities, two\nnon-intrusive sources of information that offer complementary insights into\ncognitive health. Unlike prior approaches that fuse modalities at a coarse\nlevel, CogniAlign leverages a word-level temporal alignment strategy that\nsynchronizes audio embeddings with corresponding textual tokens based on\ntranscription timestamps. This alignment supports the development of\ntoken-level fusion techniques, enabling more precise cross-modal interactions.\nTo fully exploit this alignment, we propose a Gated Cross-Attention Fusion\nmechanism, where audio features attend over textual representations, guided by\nthe superior unimodal performance of the text modality. In addition, we\nincorporate prosodic cues, specifically interword pauses, by inserting pause\ntokens into the text and generating audio embeddings for silent intervals,\nfurther enriching both streams. We evaluate CogniAlign on the ADReSSo dataset,\nwhere it achieves an accuracy of 90.36%, outperforming existing\nstate-of-the-art methods. A detailed ablation study confirms the advantages of\nour alignment strategy, attention-based fusion, and prosodic modeling.",
    "pdf_url": "http://arxiv.org/pdf/2506.01890v1",
    "published": "2025-06-02T17:17:01+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.01889v2",
    "title": "I-Love-Q relations for Neutron Stars with Dark Energy",
    "authors": [
      "Simone D'Onofrio"
    ],
    "abstract": "The influence of a dark energy fluid on the equation of state of neutron\nstars is investigated. A detailed analysis is conducted for such models,\nincluding the computation of the moment of inertia, the quadrupole moment, and\nthe tidal Love number. The results demonstrate that these quantities are\ninterconnected through the well-known equation of state independent I-Love-Q\nrelations. This work extends the applicability of these universal relations to\na broader class of neutron star models.",
    "pdf_url": "http://arxiv.org/pdf/2506.01889v2",
    "published": "2025-06-02T17:16:19+00:00",
    "categories": [
      "gr-qc"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2506.01888v1",
    "title": "S-algebra in Gauge Theory: Twistor, Spacetime and Holographic Perspectives",
    "authors": [
      "Adam Kmec",
      "Lionel Mason",
      "Romain Ruzziconi",
      "Atul Sharma"
    ],
    "abstract": "The celestial $S$-algebra arose from a reinterpretation of collinear limits\nof the Yang-Mills S-matrix as OPEs in celestial holography. It was subsequently\nrepresented via asymptotic charge aspects defined in the Yang-Mills radiative\nphase space defined at null infinity on the one hand, and via a twisted\nholography vertex algebra construction in twistor space on the other. Here we\nfirst identify it with the traditional symmetry algebra of self-dual Yang-Mills\ntheory as an integrable system via its hierarchies of conserved quantities and\nassociated flows; the self-dual phase space can be canonically identified with\nthat of full Yang-Mills at null infinity $\\mathscr{I}$. We derive the\nassociated canonical generators from the twistor space action, identifying two\ninfinite towers of charges corresponding to the two gluon helicities. These\nexpressions are translated into spacetime data at null infinity using twistor\nintegral formulae. Examining the charge algebra at spacelike infinity reveals\nthe vertex algebras studied in the context of twisted holography. Our\ndiscussion extends directly to the celestial LHam$(\\mathbb{C}^2)$ symmetries of\nself-dual gravity. This analysis provides a unified framework for celestial\nsymmetries, connecting twistor, spacetime, and holographic approaches and\nculminating in a nonlinear extrapolate dictionary for self-dual gauge theory.",
    "pdf_url": "http://arxiv.org/pdf/2506.01888v1",
    "published": "2025-06-02T17:15:31+00:00",
    "categories": [
      "hep-th"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2506.01887v1",
    "title": "Status of the W boson mass and the future of the electroweak fit in the next decades",
    "authors": [
      "Giuseppe Bozzi",
      "Matthias Schott"
    ],
    "abstract": "A precise determination of the W boson mass is an essential test for the\nStandard Model of particle physics: the comparison of experimental value and\ntheoretical prediction allows to probe the internal consistency of the\nelectroweak sector and could possibly highlight signals of New Physics. We\nprovide a concise and up-to-date summary of past and recent measurements at\nlepton and hadron colliders, a discussion of the known perturbative and\nnon-perturbative theoretical ingredients used to provide predictions for the\nrelevant observables, and an overview of future prospects to reduce systematic\nuncertainties and to compare different measurements in a consistent way. We\nconclude with a brief discussion on the relevance of the global electroweak fit\nat present and future colliders.",
    "pdf_url": "http://arxiv.org/pdf/2506.01887v1",
    "published": "2025-06-02T17:15:11+00:00",
    "categories": [
      "hep-ph",
      "hep-ex"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.01886v1",
    "title": "Two $2/5$-level mock theta conjecture-like identities",
    "authors": [
      "Stepan Konenkov",
      "Eric T. Mortenson"
    ],
    "abstract": "Determining the explicit forms and modularity for string functions and\nbranching coefficients for Kac--Moody algebras after Kac, Peterson, and\nWakimoto is an important problem. In a pair of papers, Borozenets and Mortenson\ndetermined the explicit forms for fractional-level string functions for the\nKac--Moody algebra $A_{1}^{(1)}$. For positive fractional-level string\nfunctions they obtained mock theta conjecture-like identities, and for negative\nfractional-level string functions, they obtained mixed false theta function\nexpressions. Here we find two new families of mock theta conjecture-like\nidentities but for the $2/5$-level string functions. Each of these two families\nof identities is composed of the four tenth-order mock theta functions from\nRamanujan's Lost Notebook as well as a simple quotient of theta functions.",
    "pdf_url": "http://arxiv.org/pdf/2506.01886v1",
    "published": "2025-06-02T17:13:16+00:00",
    "categories": [
      "math.NT"
    ],
    "primary_category": "math.NT"
  },
  {
    "id": "http://arxiv.org/abs/2506.01885v2",
    "title": "SoK: Concurrency in Blockchain -- A Systematic Literature Review and the Unveiling of a Misconception",
    "authors": [
      "Atefeh Zareh Chahoki",
      "Maurice Herlihy",
      "Marco Roveri"
    ],
    "abstract": "Smart contracts, the cornerstone of blockchain technology, enable secure,\nautomated distributed execution. Given their role in handling large transaction\nvolumes across clients, miners, and validators, exploring concurrency is\ncritical. This includes concurrent transaction execution or validation within\nblocks, block processing across shards, and miner competition to select and\npersist transactions. Concurrency and parallelism are a double-edged sword:\nwhile they improve throughput, they also introduce risks like race conditions,\nnon-determinism, and vulnerabilities such as deadlock and livelock.\n  This paper presents the first survey of concurrency in smart contracts,\noffering a systematic literature review organized into key dimensions. First,\nit establishes a taxonomy of concurrency levels in blockchain systems and\ndiscusses proposed solutions for future adoption. Second, it examines\nvulnerabilities, attacks, and countermeasures in concurrent operations,\nemphasizing the need for correctness and security. Crucially, we reveal a\nflawed concurrency assumption in a major research category, which has led to\nwidespread misinterpretation. This work aims to correct that and guide future\nresearch toward more accurate models. Finally, we identify gaps in each\ncategory to outline future research directions and support blockchain's\nadvancement.",
    "pdf_url": "http://arxiv.org/pdf/2506.01885v2",
    "published": "2025-06-02T17:13:03+00:00",
    "categories": [
      "cs.CR",
      "cs.DC",
      "cs.PF"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2506.01884v1",
    "title": "Agnostic Reinforcement Learning: Foundations and Algorithms",
    "authors": [
      "Gene Li"
    ],
    "abstract": "Reinforcement Learning (RL) has demonstrated tremendous empirical success\nacross numerous challenging domains. However, we lack a strong theoretical\nunderstanding of the statistical complexity of RL in environments with large\nstate spaces, where function approximation is required for sample-efficient\nlearning. This thesis addresses this gap by rigorously examining the\nstatistical complexity of RL with function approximation from a learning\ntheoretic perspective. Departing from a long history of prior work, we consider\nthe weakest form of function approximation, called agnostic policy learning, in\nwhich the learner seeks to find the best policy in a given class $\\Pi$, with no\nguarantee that $\\Pi$ contains an optimal policy for the underlying task.\n  We systematically explore agnostic policy learning along three key axes:\nenvironment access -- how a learner collects data from the environment;\ncoverage conditions -- intrinsic properties of the underlying MDP measuring the\nexpansiveness of state-occupancy measures for policies in the class $\\Pi$, and\nrepresentational conditions -- structural assumptions on the class $\\Pi$\nitself. Within this comprehensive framework, we (1) design new learning\nalgorithms with theoretical guarantees and (2) characterize fundamental\nperformance bounds of any algorithm. Our results reveal significant statistical\nseparations that highlight the power and limitations of agnostic policy\nlearning.",
    "pdf_url": "http://arxiv.org/pdf/2506.01884v1",
    "published": "2025-06-02T17:12:24+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.03202v1",
    "title": "A combined Machine Learning and Finite Element Modelling tool for the surgical planning of craniosynostosis correction",
    "authors": [
      "Itxasne Antúnez Sáenz",
      "Ane Alberdi Aramendi",
      "David Dunaway",
      "Juling Ong",
      "Lara Deliège",
      "Amparo Sáenz",
      "Anita Ahmadi Birjandi",
      "Noor UI Owase Jeelani",
      "Silvia Schievano",
      "Alessandro Borghi"
    ],
    "abstract": "Craniosynostosis is a medical condition that affects the growth of babies'\nheads, caused by an early fusion of cranial sutures. In recent decades,\nsurgical treatments for craniosynostosis have significantly improved, leading\nto reduced invasiveness, faster recovery, and less blood loss. At Great Ormond\nStreet Hospital (GOSH), the main surgical treatment for patients diagnosed with\nsagittal craniosynostosis (SC) is spring assisted cranioplasty (SAC). This\nprocedure involves a 15x15 mm2 osteotomy, where two springs are inserted to\ninduce distraction. Despite the numerous advantages of this surgical technique\nfor patients, the outcome remains unpredictable due to the lack of efficient\npreoperative planning tools. The surgeon's experience and the baby's age are\ncurrently relied upon to determine the osteotomy location and spring selection.\nPrevious tools for predicting the surgical outcome of SC relied on finite\nelement modeling (FEM), which involved computed tomography (CT) imaging and\nrequired engineering expertise and lengthy calculations. The main goal of this\nresearch is to develop a real-time prediction tool for the surgical outcome of\npatients, eliminating the need for CT scans to minimise radiation exposure\nduring preoperative planning. The proposed methodology involves creating\npersonalised synthetic skulls based on three-dimensional (3D) photographs,\nincorporating population average values of suture location, skull thickness,\nand soft tissue properties. A machine learning (ML) surrogate model is employed\nto achieve the desired surgical outcome. The resulting multi-output support\nvector regressor model achieves a R2 metric of 0.95 and MSE and MAE below 0.13.\nFurthermore, in the future, this model could not only simulate various surgical\nscenarios but also provide optimal parameters for achieving a maximum cranial\nindex (CI).",
    "pdf_url": "http://arxiv.org/pdf/2506.03202v1",
    "published": "2025-06-02T17:11:50+00:00",
    "categories": [
      "eess.IV",
      "cs.CV",
      "cs.LG",
      "physics.med-ph"
    ],
    "primary_category": "eess.IV"
  },
  {
    "id": "http://arxiv.org/abs/2506.01883v1",
    "title": "scDataset: Scalable Data Loading for Deep Learning on Large-Scale Single-Cell Omics",
    "authors": [
      "Davide D'Ascenzo",
      "Sebastiano Cultrera di Montesano"
    ],
    "abstract": "Modern single-cell datasets now comprise hundreds of millions of cells,\npresenting significant challenges for training deep learning models that\nrequire shuffled, memory-efficient data loading. While the AnnData format is\nthe community standard for storing single-cell datasets, existing data loading\nsolutions for AnnData are often inadequate: some require loading all data into\nmemory, others convert to dense formats that increase storage demands, and many\nare hampered by slow random disk access. We present scDataset, a PyTorch\nIterableDataset that operates directly on one or more AnnData files without the\nneed for format conversion. The core innovation is a combination of block\nsampling and batched fetching, which together balance randomness and I/O\nefficiency. On the Tahoe 100M dataset, scDataset achieves up to a 48$\\times$\nspeed-up over AnnLoader, a 27$\\times$ speed-up over HuggingFace Datasets, and\nan 18$\\times$ speed-up over BioNeMo in single-core settings. These advances\ndemocratize large-scale single-cell model training for the broader research\ncommunity.",
    "pdf_url": "http://arxiv.org/pdf/2506.01883v1",
    "published": "2025-06-02T17:11:49+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DB",
      "q-bio.GN",
      "q-bio.QM",
      "68T07, 68P05, 92C40",
      "I.2.6; H.2.8; J.3"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2507.00002v1",
    "title": "Hypertokens: Holographic Associative Memory in Tokenized LLMs",
    "authors": [
      "Christopher James Augeri"
    ],
    "abstract": "Large Language Models (LLMs) exhibit remarkable capabilities but suffer from\napparent precision loss, reframed here as information spreading. This reframing\nshifts the problem from computational precision to an information-theoretic\ncommunication issue. We address the K:V and V:K memory problem in LLMs by\nintroducing HDRAM (Holographically Defined Random Access Memory), a symbolic\nmemory framework treating transformer latent space as a spread-spectrum\nchannel. Built upon hypertokens, structured symbolic codes integrating\nclassical error-correcting codes (ECC), holographic computing, and\nquantum-inspired search, HDRAM recovers distributed information through\nprincipled despreading. These phase-coherent memory addresses enable efficient\nkey-value operations and Grover-style search in latent space. By combining ECC\ngrammar with compressed sensing and Krylov subspace alignment, HDRAM\nsignificantly improves associative retrieval without architectural changes,\ndemonstrating how Classical-Holographic-Quantum-inspired (CHQ) principles can\nfortify transformer architectures.",
    "pdf_url": "http://arxiv.org/pdf/2507.00002v1",
    "published": "2025-06-02T17:11:45+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.01882v1",
    "title": "Learning thermodynamic master equations for open quantum systems",
    "authors": [
      "Peter Sentz",
      "Stanley Nicholson",
      "Yujin Cho",
      "Sohail Reddy",
      "Brendan Keith",
      "Stefanie Günther"
    ],
    "abstract": "The characterization of Hamiltonians and other components of open quantum\ndynamical systems plays a crucial role in quantum computing and other\napplications. Scientific machine learning techniques have been applied to this\nproblem in a variety of ways, including by modeling with deep neural networks.\nHowever, the majority of mathematical models describing open quantum systems\nare linear, and the natural nonlinearities in learnable models have not been\nincorporated using physical principles. We present a data-driven model for open\nquantum systems that includes learnable, thermodynamically consistent terms.\nThe trained model is interpretable, as it directly estimates the system\nHamiltonian and linear components of coupling to the environment. We validate\nthe model on synthetic two and three-level data, as well as experimental\ntwo-level data collected from a quantum device at Lawrence Livermore National\nLaboratory.",
    "pdf_url": "http://arxiv.org/pdf/2506.01882v1",
    "published": "2025-06-02T17:11:16+00:00",
    "categories": [
      "quant-ph",
      "cs.LG",
      "I.2.6; J.2"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.01881v2",
    "title": "WHEN TO ACT, WHEN TO WAIT: Modeling the Intent-Action Alignment Problem in Dialogue",
    "authors": [
      "Yaoyao Qian",
      "Jindan Huang",
      "Yuanli Wang",
      "Simon Yu",
      "Kyrie Zhixuan Zhou",
      "Jiayuan Mao",
      "Mingfu Liang",
      "Hanhan Zhou"
    ],
    "abstract": "Dialogue systems often fail when user utterances are semantically complete\nyet lack the clarity and completeness required for appropriate system action.\nThis mismatch arises because users frequently do not fully understand their own\nneeds, while systems require precise intent definitions. This highlights the\ncritical Intent-Action Alignment Problem: determining when an expression is not\njust understood, but truly ready for a system to act upon. We present STORM, a\nframework modeling asymmetric information dynamics through conversations\nbetween UserLLM (full internal access) and AgentLLM (observable behavior only).\nSTORM produces annotated corpora capturing trajectories of expression phrasing\nand latent cognitive transitions, enabling systematic analysis of how\ncollaborative understanding develops. Our contributions include: (1)\nformalizing asymmetric information processing in dialogue systems; (2) modeling\nintent formation tracking collaborative understanding evolution; and (3)\nevaluation metrics measuring internal cognitive improvements alongside task\nperformance. Experiments across four language models reveal that moderate\nuncertainty (40-60%) can outperform complete transparency in certain scenarios,\nwith model-specific patterns suggesting reconsideration of optimal information\ncompleteness in human-AI collaboration. These findings contribute to\nunderstanding asymmetric reasoning dynamics and inform uncertainty-calibrated\ndialogue system design.",
    "pdf_url": "http://arxiv.org/pdf/2506.01881v2",
    "published": "2025-06-02T17:11:10+00:00",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2506.01880v1",
    "title": "Pearl: Automatic Code Optimization Using Deep Reinforcement Learning",
    "authors": [
      "Djamel Rassem Lamouri",
      "Iheb Nassim Aouadj",
      "Smail Kourta",
      "Riyadh Baghdadi"
    ],
    "abstract": "Compilers are crucial in optimizing programs and accelerating their\nexecution. However, optimizing programs automatically using compilers is not\ntrivial. Recent work has attempted to use reinforcement learning (RL) to solve\nthis problem. It has limitations though. Current methods either do not support\nthe optimization of general loop nests or can only be used to optimize loop\nnests seen during training. In this paper, we propose Pearl, a novel framework\nthat uses deep reinforcement learning to automate compiler code optimization.\nIt uses an RL agent to select the sequence of code optimizations a compiler\nshould apply to make the input code run faster. This agent can optimize general\nloop nests and can generalize to programs unseen during training. To enable the\noptimization of general loop nests, we propose a novel representation of the\naction space that allows the RL agent to select on which part of the loop nest\na given code optimization should be applied. Training RL agents for loop nest\noptimization is slow and data-intensive. We accelerate this process by caching\nresults and pre-training the agent. Integrated with the Tiramisu compiler, our\napproach streamlines optimization and outperforms existing methods. To the best\nof our knowledge, Pearl is the first RL-based system to support general\nprograms composed of loop nests manipulating tensors while still being able to\ngeneralize to programs unseen during training. It is also the first to support\nthe class of polyhedral optimizations, a class of advanced loop nest\noptimizations. We evaluate Pearl on a set of benchmarks, and demonstrate\ncompetitive performance improvements over state-of-the-art compilers. Notably,\nPearl achieves a geometric mean speedup of 2.02x compared to Tiramisu and 3.36x\ncompared to Pluto.",
    "pdf_url": "http://arxiv.org/pdf/2506.01880v1",
    "published": "2025-06-02T17:09:59+00:00",
    "categories": [
      "cs.PL"
    ],
    "primary_category": "cs.PL"
  },
  {
    "id": "http://arxiv.org/abs/2506.01879v1",
    "title": "Free Askey--Wilson functionals and geometric last passage percolation on a strip",
    "authors": [
      "Wlodek Bryc",
      "Kamil Szpojankowski",
      "Jacek Wesolowski"
    ],
    "abstract": "Barraquand, Corwin, and Yang arXiv:2306.05983 established that geometric last\npassage percolation (LPP) on a strip of $\\mathbb{Z}^2$ has a unique stationary\nmeasure. Building on this, Barraquand arXiv:2409.08927 derived explicit contour\nintegral formulas for the model's multipoint probability generating function.\nIn this paper, we introduce free Askey--Wilson functionals and use them to\nextend these generating function formulas. Our framework yields explicit\nexpressions valid over a broader range of boundary parameters than previously\naccessible. This generalization allows us to determine the full phase diagram\nthat characterizes how the large-scale asymptotics of the stationary measure\ndepend on the boundary conditions. In addition, we prove a Poisson\napproximation for the stationary measure when the parameters vary with the\nstrip width.",
    "pdf_url": "http://arxiv.org/pdf/2506.01879v1",
    "published": "2025-06-02T17:09:43+00:00",
    "categories": [
      "math.PR"
    ],
    "primary_category": "math.PR"
  },
  {
    "id": "http://arxiv.org/abs/2506.01878v3",
    "title": "Monte Carlo Simulation and Dosimetric Analysis of Gold Nanoparticles (AuNPs) in Breast Tissue",
    "authors": [
      "Pedro Teles",
      "Catarina Dias",
      "João H. Belo",
      "Célia Sousa",
      "Paula Boaventura",
      "Isabel Bravo",
      "João Santos",
      "Marissa Rylander"
    ],
    "abstract": "Precise radiation delivery is critical for effective radiotherapy, and gold\nnanoparticles (AuNPs) have emerged as promising tools to enhance local dose\ndeposition while sparing the surrounding healthy tissue. In this study, the\nPENELOPE Monte Carlo code was used to investigate the dosimetry of AuNPs under\ndifferent conditions and models. The Dose Enhancement Ratio (DER) was studied\nin water and breast tissue with spherical shapes and in agreement with\npreviously published results. To further analyse the physical interactions of\nthe particles around the AuNP, a Phase Space File (PSF) in a volume around the\nAuNPs was created. This showed that larger AuNPs lead to increased doses, as\nexpected, yielding DER values exceeding 100 times. Finally, results reveal that\nin the volume surrounding the AuNP, 80% of emitted electrons originate from\nphotoelectric absorption, leading to Auger electron emission cascades which\nwere analysed in detail. It was also possible to establish a direct relation\nbetween number of secondaries and the particle volumes. The Local Effect Model\n(LEM) was used to determine survival curves in AuNPs of different sizes at\ndifferent gold concentrations. The last part of this work consisted in\nanalysing a distribution of AuNPs within a flattened cell typical of clonogenic\nassays where a log-normal distribution of dose was observed. This led to the\ndevelopment of a new, mechanistic, Local Effect Model which, if further\nvalidated, can have further applications in-vitro and in-silico.",
    "pdf_url": "http://arxiv.org/pdf/2506.01878v3",
    "published": "2025-06-02T17:08:50+00:00",
    "categories": [
      "physics.med-ph",
      "physics.data-an"
    ],
    "primary_category": "physics.med-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.02093v1",
    "title": "Are Pixel-Wise Metrics Reliable for Sparse-View Computed Tomography Reconstruction?",
    "authors": [
      "Tianyu Lin",
      "Xinran Li",
      "Chuntung Zhuang",
      "Qi Chen",
      "Yuanhao Cai",
      "Kai Ding",
      "Alan L. Yuille",
      "Zongwei Zhou"
    ],
    "abstract": "Widely adopted evaluation metrics for sparse-view CT reconstruction--such as\nStructural Similarity Index Measure and Peak Signal-to-Noise Ratio--prioritize\npixel-wise fidelity but often fail to capture the completeness of critical\nanatomical structures, particularly small or thin regions that are easily\nmissed. To address this limitation, we propose a suite of novel anatomy-aware\nevaluation metrics designed to assess structural completeness across anatomical\nstructures, including large organs, small organs, intestines, and vessels.\nBuilding on these metrics, we introduce CARE, a Completeness-Aware\nReconstruction Enhancement framework that incorporates structural penalties\nduring training to encourage anatomical preservation of significant structures.\nCARE is model-agnostic and can be seamlessly integrated into analytical,\nimplicit, and generative methods. When applied to these methods, CARE\nsubstantially improves structural completeness in CT reconstructions, achieving\nup to +32% improvement for large organs, +22% for small organs, +40% for\nintestines, and +36% for vessels.",
    "pdf_url": "http://arxiv.org/pdf/2506.02093v1",
    "published": "2025-06-02T17:07:10+00:00",
    "categories": [
      "eess.IV",
      "cs.CV"
    ],
    "primary_category": "eess.IV"
  },
  {
    "id": "http://arxiv.org/abs/2506.01877v1",
    "title": "When Should Dense Retrievers Be Updated in Evolving Corpora? Detecting Out-of-Distribution Corpora Using GradNormIR",
    "authors": [
      "Dayoon Ko",
      "Jinyoung Kim",
      "Sohyeon Kim",
      "Jinhyuk Kim",
      "Jaehoon Lee",
      "Seonghak Song",
      "Minyoung Lee",
      "Gunhee Kim"
    ],
    "abstract": "Dense retrievers encode texts into embeddings to efficiently retrieve\nrelevant documents from large databases in response to user queries. However,\nreal-world corpora continually evolve, leading to a shift from the original\ntraining distribution of the retriever. Without timely updates or retraining,\nindexing newly emerging documents can degrade retrieval performance for future\nqueries. Thus, identifying when a dense retriever requires an update is\ncritical for maintaining robust retrieval systems. In this paper, we propose a\nnovel task of predicting whether a corpus is out-of-distribution (OOD) relative\nto a dense retriever before indexing. Addressing this task allows us to\nproactively manage retriever updates, preventing potential retrieval failures.\nWe introduce GradNormIR, an unsupervised approach that leverages gradient norms\nto detect OOD corpora effectively. Experiments on the BEIR benchmark\ndemonstrate that GradNormIR enables timely updates of dense retrievers in\nevolving document collections, significantly enhancing retrieval robustness and\nefficiency.",
    "pdf_url": "http://arxiv.org/pdf/2506.01877v1",
    "published": "2025-06-02T17:06:35+00:00",
    "categories": [
      "cs.IR",
      "cs.CL"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2506.01876v1",
    "title": "Learning to Explore: An In-Context Learning Approach for Pure Exploration",
    "authors": [
      "Alessio Russo",
      "Ryan Welch",
      "Aldo Pacchiano"
    ],
    "abstract": "In this work, we study the active sequential hypothesis testing problem, also\nknown as pure exploration, where the goal is to actively control a data\ncollection process to efficiently identify the correct hypothesis underlying a\ndecision problem. While relevant across multiple domains, devising adaptive\nexploration strategies remains challenging, particularly due to difficulties in\nencoding appropriate inductive biases. Existing Reinforcement Learning\n(RL)-based methods often underperform when relevant information structures are\ninadequately represented, whereas more complex methods, like Best Arm\nIdentification (BAI) techniques, may be difficult to devise and typically rely\non explicit modeling assumptions. To address these limitations, we introduce\nIn-Context Pure Exploration (ICPE), an in-context learning approach that uses\nTransformers to learn exploration strategies directly from experience. ICPE\ncombines supervised learning and reinforcement learning to identify and exploit\nlatent structure across related tasks, without requiring prior assumptions.\nNumerical results across diverse synthetic and semi-synthetic benchmarks\nhighlight ICPE's capability to achieve robust performance performance in\ndeterministic, stochastic, and structured settings. These results demonstrate\nICPE's ability to match optimal instance-dependent algorithms using only deep\nlearning techniques, making it a practical and general approach to\ndata-efficient exploration.",
    "pdf_url": "http://arxiv.org/pdf/2506.01876v1",
    "published": "2025-06-02T17:04:50+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.01875v1",
    "title": "Dynamic Software Updating in Java -- Comparing Concepts and Resource Demands",
    "authors": [
      "Danijel Mlinaric",
      "Vedran Mornar"
    ],
    "abstract": "Dynamic software updating (DSU) is an extremely useful feature to be used\nduring the software evolution. It can be used to reduce downtime costs, for\nsecurity enhancements, profiling and testing the new functionalities. There are\nmany researches and solutions on dynamic software updating regarding diverse\nproblems introduced by the topic, but there is a lack of research which compare\nvarious approaches concerning supported changes and demands on re-sources. In\nthis paper we are comparing currently available con-cepts for Java programming\nlanguage that deal with dynamically applied changes and impact of those changes\non computer resource demands.",
    "pdf_url": "http://arxiv.org/pdf/2506.01875v1",
    "published": "2025-06-02T17:04:49+00:00",
    "categories": [
      "cs.SE"
    ],
    "primary_category": "cs.SE"
  },
  {
    "id": "http://arxiv.org/abs/2506.01874v1",
    "title": "Life Sequence Transformer: Generative Modelling for Counterfactual Simulation",
    "authors": [
      "Alberto Cabezas",
      "Carlotta Montorsi"
    ],
    "abstract": "Social sciences rely on counterfactual analysis using surveys and\nadministrative data, generally depending on strong assumptions or the existence\nof suitable control groups, to evaluate policy interventions and estimate\ncausal effects. We propose a novel approach that leverages the Transformer\narchitecture to simulate counterfactual life trajectories from large-scale\nadministrative records. Our contributions are: the design of a novel encoding\nmethod that transforms longitudinal administrative data to sequences and the\nproposal of a generative model tailored to life sequences with overlapping\nevents across life domains. We test our method using data from the Istituto\nNazionale di Previdenza Sociale (INPS), showing that it enables the realistic\nand coherent generation of life trajectories. This framework offers a scalable\nalternative to classical counterfactual identification strategy, such as\ndifference-in-differences and synthetic controls, particularly in contexts\nwhere these methods are infeasible or their assumptions unverifiable. We\nvalidate the model's utility by comparing generated life trajectories against\nestablished findings from causal studies, demonstrating its potential to enrich\nlabour market research and policy evaluation through individual-level\nsimulations.",
    "pdf_url": "http://arxiv.org/pdf/2506.01874v1",
    "published": "2025-06-02T17:03:11+00:00",
    "categories": [
      "econ.EM",
      "stat.ME"
    ],
    "primary_category": "econ.EM"
  },
  {
    "id": "http://arxiv.org/abs/2506.01873v2",
    "title": "A gradient-enhanced approach for stable finite element approximations of reaction-convection-diffusion problems",
    "authors": [
      "Soheil Firooz",
      "B. Daya Reddy",
      "Paul Steinmann"
    ],
    "abstract": "We develop a micromorphic-based approach for finite element stabilization of\nreaction-convection-diffusion equations, by gradient enhancement of the field\nof interest via introducing an auxiliary variable. The well-posedness of the\ncoupled-field approach is established, together with an error estimate. Through\na set of 1D and 2D numerical examples the high accuracy and enhanced stability\nof the approach in approximating solutions associated with complex problems is\ndemonstrated, for situations of varying reactivity and convection.",
    "pdf_url": "http://arxiv.org/pdf/2506.01873v2",
    "published": "2025-06-02T17:02:43+00:00",
    "categories": [
      "math-ph",
      "math.MP"
    ],
    "primary_category": "math-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.01872v1",
    "title": "Is Extending Modality The Right Path Towards Omni-Modality?",
    "authors": [
      "Tinghui Zhu",
      "Kai Zhang",
      "Muhao Chen",
      "Yu Su"
    ],
    "abstract": "Omni-modal language models (OLMs) aim to integrate and reason over diverse\ninput modalities--such as text, images, video, and audio--while maintaining\nstrong language capabilities. Despite recent advancements, existing models,\nespecially open-source ones, remain far from true omni-modality, struggling to\ngeneralize beyond the specific modality pairs they are trained on or to achieve\nstrong performance when processing multi-modal inputs. We study the effect of\nextending modality, the dominant technique for training multimodal models,\nwhere an off-the-shelf language model is fine-tuned on target-domain and\nlanguage data. Specifically, we investigate three key questions: (1) Does\nmodality extension compromise core language abilities? (2) Can model merging\neffectively integrate independently fine-tuned modality-specific models to\nachieve omni-modality? (3) Does omni-modality extension lead to better\nknowledge sharing and generalization compared to sequential extension? Through\nextensive experiments, we analyze these trade-offs and provide insights into\nthe feasibility of achieving true omni-modality using current approaches.",
    "pdf_url": "http://arxiv.org/pdf/2506.01872v1",
    "published": "2025-06-02T17:01:40+00:00",
    "categories": [
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.01871v2",
    "title": "Modified wave operators for the defocusing cubic nonlinear Schrödinger equation in one space dimension with large scattering data",
    "authors": [
      "Masaki Kawamoto",
      "Haruya Mizutani"
    ],
    "abstract": "In the present paper, we construct modified wave operators for the defocusing\ncubic nonlinear Schr\\\"odinger equation (NLS) in one space dimension without\nsize restriction on scattering data. In the proof, we introduce a new\nformulation of the problem based on the linearization of the NLS around a\nprescribed asymptotic profile. For the linearized equation which is a system of\nSchr\\\"odinger equations with non-symmetric, time-dependent long-range\npotentials, we show a modified energy identity, as well as an associated energy\nestimate, which allow us to apply a simple energy method to construct the\nmodified wave operators. As a byproduct, we also obtain in the focusing case an\nimproved explicit upper bound for the size of scattering data to ensure the\nexistence of modified wave operators. Our argument relies neither on the\ncomplete integrability nor on the smoothness of nonlinearity, and also works\nfor short-range perturbations of the cubic nonlinearity.",
    "pdf_url": "http://arxiv.org/pdf/2506.01871v2",
    "published": "2025-06-02T16:57:11+00:00",
    "categories": [
      "math.AP"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2506.01869v1",
    "title": "Frugal Machine Learning for Energy-efficient, and Resource-aware Artificial Intelligence",
    "authors": [
      "John Violos",
      "Konstantina-Christina Diamanti",
      "Ioannis Kompatsiaris",
      "Symeon Papadopoulos"
    ],
    "abstract": "Frugal Machine Learning (FML) refers to the practice of designing Machine\nLearning (ML) models that are efficient, cost-effective, and mindful of\nresource constraints. This field aims to achieve acceptable performance while\nminimizing the use of computational resources, time, energy, and data for both\ntraining and inference. FML strategies can be broadly categorized into input\nfrugality, learning process frugality, and model frugality, each focusing on\nreducing resource consumption at different stages of the ML pipeline. This\nchapter explores recent advancements, applications, and open challenges in FML,\nemphasizing its importance for smart environments that incorporate edge\ncomputing and IoT devices, which often face strict limitations in bandwidth,\nenergy, or latency. Technological enablers such as model compression,\nenergy-efficient hardware, and data-efficient learning techniques are\ndiscussed, along with adaptive methods including parameter regularization,\nknowledge distillation, and dynamic architecture design that enable incremental\nmodel updates without full retraining. Furthermore, it provides a comprehensive\ntaxonomy of frugal methods, discusses case studies across diverse domains, and\nidentifies future research directions to drive innovation in this evolving\nfield.",
    "pdf_url": "http://arxiv.org/pdf/2506.01869v1",
    "published": "2025-06-02T16:56:21+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.01870v5",
    "title": "Various irrational series involving binomial coefficients",
    "authors": [
      "Zhi-Wei Sun"
    ],
    "abstract": "Motivated by Galois theory, we propose 26 new irrational series of\nRamanujan's type or Zeilberger's type. For example, we conjecture that\n\\begin{align*}&\\sum_{k=1}^\\infty\\frac{(32(91\\sqrt{33}-523))^{k}}{k^3\\binom{2k}k^2\\binom{3k}k}\n\\left((91\\sqrt{33}+891)k-33\\sqrt{33}-225\\right)\n\\\\&\\qquad=320\\left(\\frac{11}3\\sqrt{33}L_{-11}(2)-27L_{-3}(2)\\right),\n\\end{align*} where $$ L_{d}(2)=\\sum_{k=1}^\\infty\\frac{(\\frac{d}k)}{k^2}$$ for\nany integer $d\\equiv0,1\\pmod4$ with $(\\frac{d}k)$ the Kronecker symbol. This\nprovides a quite efficient way to compute the constant $L_{-11}(2)$.",
    "pdf_url": "http://arxiv.org/pdf/2506.01870v5",
    "published": "2025-06-02T16:56:21+00:00",
    "categories": [
      "math.NT",
      "11B65, 11M06, 05A19"
    ],
    "primary_category": "math.NT"
  },
  {
    "id": "http://arxiv.org/abs/2506.01868v1",
    "title": "NepTrain and NepTrainKit: Automated Active Learning and Visualization Toolkit for Neuroevolution Potentials",
    "authors": [
      "Chengbing Chen",
      "Yutong Li",
      "Rui Zhao",
      "Zhoulin Liu",
      "Zheyong Fan",
      "Gang Tang",
      "Zhiyong Wang"
    ],
    "abstract": "As a machine-learned potential, the neuroevolution potential (NEP) method\nfeatures exceptional computational efficiency and has been successfully applied\nin materials science. Constructing high-quality training datasets is crucial\nfor developing accurate NEP models. However, the preparation and screening of\nNEP training datasets remain a bottleneck for broader applications due to their\ntime-consuming, labor-intensive, and resource-intensive nature. In this work,\nwe have developed NepTrain and NepTrainKit, which are dedicated to initializing\nand managing training datasets to generate high-quality training sets while\nautomating NEP model training. NepTrain is an open-source Python package that\nfeatures a bond length filtering method to effectively identify and remove\nnon-physical structures from molecular dynamics trajectories, thereby ensuring\nhigh-quality training datasets. NepTrainKit is a graphical user interface (GUI)\nsoftware designed specifically for NEP training datasets, providing\nfunctionalities for data editing, visualization, and interactive exploration.\nIt integrates key features such as outlier identification, farthest-point\nsampling, non-physical structure detection, and configuration type selection.\nThe combination of these tools enables users to process datasets more\nefficiently and conveniently. Using $\\rm CsPbI_3$ as a case study, we\ndemonstrate the complete workflow for training NEP models with NepTrain and\nfurther validate the models through materials property predictions. We believe\nthis toolkit will greatly benefit researchers working with machine learning\ninteratomic potentials.",
    "pdf_url": "http://arxiv.org/pdf/2506.01868v1",
    "published": "2025-06-02T16:56:11+00:00",
    "categories": [
      "cs.LG",
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.01867v1",
    "title": "EEG Foundation Models for BCI Learn Diverse Features of Electrophysiology",
    "authors": [
      "Mattson Ogg",
      "Rahul Hingorani",
      "Diego Luna",
      "Griffin W. Milsap",
      "William G. Coon",
      "Clara A. Scholl"
    ],
    "abstract": "Brain computer interface (BCI) research, as well as increasing portions of\nthe field of neuroscience, have found success deploying large-scale artificial\nintelligence (AI) pre-training methods in conjunction with vast public\nrepositories of data. This approach of pre-training foundation models using\nlabel-free, self-supervised objectives offers the potential to learn robust\nrepresentations of neurophysiology, potentially addressing longstanding\nchallenges in neural decoding. However, to date, much of this work has focused\nexplicitly on standard BCI benchmarks and tasks, which likely overlooks the\nmultitude of features these powerful methods might learn about brain function\nas well as other electrophysiological information. We introduce a new method\nfor self-supervised BCI foundation model pre-training for EEG inspired by a\ntransformer-based approach adapted from the HuBERT framework originally\ndeveloped for speech processing. Our pipeline is specifically focused on\nlow-profile, real-time usage, involving minimally pre-processed data and just\neight EEG channels on the scalp. We show that our foundation model learned a\nrepresentation of EEG that supports standard BCI tasks (P300, motor imagery),\nbut also that this model learns features of neural data related to individual\nvariability, and other salient electrophysiological components (e.g., alpha\nrhythms). In addition to describing and evaluating a novel approach to\npre-training BCI models and neural decoding, this work opens the aperture for\nwhat kind of tasks and use-cases might exist for neural data in concert with\npowerful AI methods.",
    "pdf_url": "http://arxiv.org/pdf/2506.01867v1",
    "published": "2025-06-02T16:55:26+00:00",
    "categories": [
      "q-bio.NC",
      "eess.SP"
    ],
    "primary_category": "q-bio.NC"
  },
  {
    "id": "http://arxiv.org/abs/2506.01866v1",
    "title": "Hybrid SIS Dynamics for Demand Modeling of Frequently Updated Products",
    "authors": [
      "Ian Walter",
      "Jitesh H. Panchal",
      "Philip E. Paré"
    ],
    "abstract": "We propose a hybrid spreading process model to capture the dynamics of demand\nfor software-based products. We introduce discontinuous jumps in the state to\nmodel sudden surges in demand that can be seen immediately after a product\nupdate is released. After each update, the modeled demand evolves according to\na continuous-time susceptible-infected-susceptible (SIS) epidemic model. We\nidentify the necessary and sufficient conditions for estimating the hybrid\nmodel's parameters for an arbitrary finite number of sequential updates. We\nverify the parameter estimation conditions in simulation, and evaluate how the\nestimation of these parameters is impacted by the presence of observation and\nprocess noise. We then validate our model by applying our estimation method to\ndaily user engagement data for a regularly updating software product, the\nlive-service video game `Apex Legends.'",
    "pdf_url": "http://arxiv.org/pdf/2506.01866v1",
    "published": "2025-06-02T16:53:46+00:00",
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2506.01865v3",
    "title": "Fast converging irrational series for $ L(2,(\\frac d\\cdot))$",
    "authors": [
      "Zhi-Wei Sun",
      "Yajun Zhou"
    ],
    "abstract": "By exploring the theory of Guillera-Rogers, we evaluate some infinite series\nwhose summands are quadratic irrationals, in terms of $\\pi$ and special values\nof Dirichlet $L$-functions $ L_d(2)\\equiv L(2,(\\frac\nd\\cdot)):=\\sum_{k=1}^\\infty\\left( \\frac{d}{k} \\right)\\frac1{k^2}$. Applying\nKronecker's theorem to linear combinations of lattice sums, we obtain\ngeometrically convergent series for $ L_{-56}(2)$, $ L_{-68}(2)$, $\nL_{-87}(2)$, $ L_{-111}(2)$, and $ L_{-116}(2)$, which go beyond the solvable\ncases of Guillera-Rogers.",
    "pdf_url": "http://arxiv.org/pdf/2506.01865v3",
    "published": "2025-06-02T16:53:21+00:00",
    "categories": [
      "math.NT",
      "Primary 11M06, 11F03, 11B65, Secondary 05A19, 33F05"
    ],
    "primary_category": "math.NT"
  },
  {
    "id": "http://arxiv.org/abs/2506.01864v4",
    "title": "Software Portability for Computer Algebra",
    "authors": [
      "Arthur C. Norman",
      "Stephen M. Watt"
    ],
    "abstract": "We have been involved in the creation of multiple software systems for\ncomputer algebra, including Reduce, Maple, Axiom and Aldor as well as a number\nof smaller specialised programs. We relate observations on how the meaning of\nsoftware portability has changed over time and how it continues to evolve. We\ndescribe how the systems with which we have first-hand experience have achieved\nportability, how the central issues have changed over time and the challenges\nthat remain.",
    "pdf_url": "http://arxiv.org/pdf/2506.01864v4",
    "published": "2025-06-02T16:53:04+00:00",
    "categories": [
      "cs.SC"
    ],
    "primary_category": "cs.SC"
  },
  {
    "id": "http://arxiv.org/abs/2506.01863v1",
    "title": "Unified Scaling Laws for Compressed Representations",
    "authors": [
      "Andrei Panferov",
      "Alexandra Volkova",
      "Ionut-Vlad Modoranu",
      "Vage Egiazarian",
      "Mher Safaryan",
      "Dan Alistarh"
    ],
    "abstract": "Scaling laws have shaped recent advances in machine learning by enabling\npredictable scaling of model performance based on model size, computation, and\ndata volume. Concurrently, the rise in computational cost for AI has motivated\nmodel compression techniques, notably quantization and sparsification, which\nhave emerged to mitigate the steep computational demands associated with\nlarge-scale training and inference. This paper investigates the interplay\nbetween scaling laws and compression formats, exploring whether a unified\nscaling framework can accurately predict model performance when training occurs\nover various compressed representations, such as sparse, scalar-quantized,\nsparse-quantized or even vector-quantized formats. Our key contributions\ninclude validating a general scaling law formulation and showing that it is\napplicable both individually but also composably across compression types.\nBased on this, our main finding is demonstrating both theoretically and\nempirically that there exists a simple \"capacity\" metric -- based on the\nrepresentation's ability to fit random Gaussian data -- which can robustly\npredict parameter efficiency across multiple compressed representations. On the\npractical side, we extend our formulation to directly compare the accuracy\npotential of different compressed formats, and to derive better algorithms for\ntraining over sparse-quantized formats.",
    "pdf_url": "http://arxiv.org/pdf/2506.01863v1",
    "published": "2025-06-02T16:52:51+00:00",
    "categories": [
      "cs.LG",
      "cs.CL"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.01862v3",
    "title": "Modeling the Optical Properties of Biological Structures using Symbolic Regression",
    "authors": [
      "Julian Sierra-Velez",
      "Alexandre Vial",
      "Marina Inchaussandague",
      "Diana Skigin",
      "Demetrio Macías"
    ],
    "abstract": "We present a Machine Learning approach based on Symbolic Regression to\nderive, from either numerically generated or experimentally measured spectral\ndata, closed-form expressions that model the optical properties of biological\nmaterials. To evaluate the performance of our approach, we consider three case\nstudies with the aim of retrieving the refractive index of the materials that\nconstitute the biological structures considered. The results obtained show\nthat, in addition to retrieving readable and dimensionally homogeneous\ndispersion models, the expressions found have a physical meaning and their\nalgebraic form is similar to that of the models used to characterize the\ndispersive behavior of transparent dielectrics in the visible region.",
    "pdf_url": "http://arxiv.org/pdf/2506.01862v3",
    "published": "2025-06-02T16:51:49+00:00",
    "categories": [
      "physics.comp-ph",
      "physics.bio-ph",
      "physics.optics"
    ],
    "primary_category": "physics.comp-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.01861v2",
    "title": "Proximity-induced Rashba spin-orbit interaction in BaMnO$_\\text{3}|$KTaO$_\\text{3}$ heterostructure for antiferromagnetic spintronics",
    "authors": [
      "Vivek Kumar",
      "Nirmal Ganguli"
    ],
    "abstract": "Antiferromagnetic spintronics, a promising technology for ultra-fast\nelectronic devices, faces several challenges, including the lack of materials\nsimultaneously hosting robust antiferromagnetism and adequate Rashba-like\ninteraction. We design a heterostructure of BaMnO$_3|$KTaO$_3$ with the idea of\nproximity-inducing strong Rashba spin-orbit interaction from KTaO$_3$ part to\nBaMnO$_3$ part, where the latter is already a robust antiferromagnet. Within\nour DFT calculations, the heterostructure reveals BaMnO$_3$ bands near the\nFermi level with a significant magnetic moment per Mn atom and a decent\nordering temperature. Further, the BaMnO$_3$ bands in the heterostructure\nexhibit linear Rashba interaction with a sizable Rashba coefficient, owing to\nits proximity to KTaO$_3$. Our work can motivate future research by\ndemonstrating the road map to proximity-induced Rashba interaction for\nantiferromagnetic spintronics.",
    "pdf_url": "http://arxiv.org/pdf/2506.01861v2",
    "published": "2025-06-02T16:51:08+00:00",
    "categories": [
      "cond-mat.mtrl-sci",
      "cond-mat.str-el"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2506.01860v1",
    "title": "Benchmarking Universal Machine Learning Interatomic Potentials for Real-Time Analysis of Inelastic Neutron Scattering Data",
    "authors": [
      "Bowen Han",
      "Yongqiang Cheng"
    ],
    "abstract": "The accurate calculation of phonons and vibrational spectra remains a\nsignificant challenge, requiring highly precise evaluations of interatomic\nforces. Traditional methods based on the quantum description of the electronic\nstructure, while widely used, are computationally expensive and demand\nsubstantial expertise. Emerging universal machine learning interatomic\npotentials (uMLIPs) offer a transformative alternative by employing pre-trained\nneural network surrogates to predict interatomic forces directly from atomic\ncoordinates. This approach dramatically reduces computation time and minimizes\nthe need for technical knowledge. In this paper, we produce a phonon database\ncomprising nearly 5,000 inorganic crystals to benchmark the performance of\nseveral leading uMLIPs. We further assess these models in real-world\napplications by using them to analyze experimental inelastic neutron scattering\ndata collected on a variety of materials. Through detailed comparisons, we\nidentify the strengths and limitations of these uMLIPs, providing insights into\ntheir accuracy and suitability for fast calculations of phonons and related\nproperties, as well as for real-time interpretation of neutron scattering\nspectra. Our findings highlight how the rapid advancement of AI in science is\nrevolutionizing experimental research and data analysis.",
    "pdf_url": "http://arxiv.org/pdf/2506.01860v1",
    "published": "2025-06-02T16:50:29+00:00",
    "categories": [
      "physics.comp-ph",
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "physics.comp-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.01859v1",
    "title": "CONFETTI: Conversational Function-Calling Evaluation Through Turn-Level Interactions",
    "authors": [
      "Tamer Alkhouli",
      "Katerina Margatina",
      "James Gung",
      "Raphael Shu",
      "Claudia Zaghi",
      "Monica Sunkara",
      "Yi Zhang"
    ],
    "abstract": "We introduce Conversational Function-Calling Evaluation Through Turn-Level\nInteractions (CONFETTI), a conversational benchmark1 designed to evaluate the\nfunction-calling capabilities and response quality of large language models\n(LLMs). Current benchmarks lack comprehensive assessment of LLMs in complex\nconversational scenarios. CONFETTI addresses this gap through 109\nhuman-simulated conversations, comprising 313 user turns and covering 86 APIs.\nThese conversations explicitly target various conversational complexities, such\nas follow-ups, goal correction and switching, ambiguous and implicit goals. We\nperform off-policy turn-level evaluation using this benchmark targeting\nfunction-calling. Our benchmark also incorporates dialog act annotations to\nassess agent responses. We evaluate a series of state-of-the-art LLMs and\nanalyze their performance with respect to the number of available APIs,\nconversation lengths, and chained function calling. Our results reveal that\nwhile some models are able to handle long conversations, and leverage more than\n20+ APIs successfully, other models struggle with longer context or when\nincreasing the number of APIs. We also report that the performance on chained\nfunction-calls is severely limited across the models. Overall, the top\nperforming models on CONFETTI are Nova Pro (40.01%), Claude Sonnet v3.5\n(35.46%) and Llama 3.1 405B (33.19%) followed by command-r-plus (31.18%) and\nMistral-Large-2407 (30.07%).",
    "pdf_url": "http://arxiv.org/pdf/2506.01859v1",
    "published": "2025-06-02T16:48:11+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.01858v1",
    "title": "Gauge-invariant Slavnov-Taylor Decomposition for Trilinear Vertices",
    "authors": [
      "Andrea Quadri"
    ],
    "abstract": "We continue the analysis of the gauge-invariant decomposition of amplitudes\nin spontaneously broken massive gauge theories by providing a characterization\nof separately gauge-invariant subsectors for amplitudes involving trilinear\ninteraction vertices for an Abelian theory with chiral fermions. We show that\nthe use of Frohlich-Morchio-Strocchi gauge-invariant dynamical (i.e.\npropagating inside loops) fields yields a very powerful handle on the\ncancellations among unphysical degrees of freedom (the longitudinal mode of the\nmassive gauge field, the Goldstone scalar and the ghosts). The resulting\ncancellations are encoded into separately Slavnov-Taylor invariant sectors for\n1-PI amplitudes. The construction works to all orders in perturbation theory.\nThis decomposition suggests a novel strategy for the determination of finite\ncounter-terms required to restore the Slavnov-Taylor identities in chiral\ntheories in the absence of an invariant regularization scheme.",
    "pdf_url": "http://arxiv.org/pdf/2506.01858v1",
    "published": "2025-06-02T16:47:46+00:00",
    "categories": [
      "hep-th",
      "hep-ph"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2506.04258v1",
    "title": "Differential measurement of m_e/m_p: 3 mm methanol lines toward Sagittarius B2(N) and (M) molecular clouds",
    "authors": [
      "J. S. Vorotyntseva",
      "S. A. Levshakov",
      "C. Henkel"
    ],
    "abstract": "Differential measurement of the fundamental physical constant mu = m_e/m_p\n(the electron-to-proton mass ratio) toward two sources located near the\nGalactic center - the Sagittarius (Sgr) B2(N) and (M) molecular clouds - show a\nlower mu compared to its terrestrial value. Based on methanol (CH3OH) emission\nlines from the frequency range 80-112 GHz (IRAM 30-m telescope archival data),\nthe calculated difference (Delta mu)/mu = (mu_obs - mu_lab)/mu_lab is equal to\n(-3.0 +/- 0.6)*10^(-7) (1 sigma C.L.) in the whole cloud SgrB2. The revealed 5\nsigma signal in mu-variations agrees within the margin of error with the\nrecently obtained result based on methanol emission lines from the higher\nfrequency range 542-543 GHz (Herschel space telescope archival data) for\nSgrB2(N): (Delta mu)/mu = (-4.2 +/- 0.7)*10^(-7).",
    "pdf_url": "http://arxiv.org/pdf/2506.04258v1",
    "published": "2025-06-02T16:46:48+00:00",
    "categories": [
      "astro-ph.GA",
      "astro-ph.CO"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2506.01857v3",
    "title": "Protein folding classes -- High-dimensional geometry of amino acid composition space revisited",
    "authors": [
      "Boryeu Mao"
    ],
    "abstract": "In this study, the distributions of protein structure classes (or folding\ntypes) of experimentally determined structures from a legacy dataset and a\ncomprehensive database (SCOP) are modeled precisely with geometric constructs\nsuch as convex polytopes in high-dimensional amino acid composition space. This\nis a follow-up of a previous non-statistical, geometry-motivated modeling of\nprotein classes with ellipsoidal models, which are superseded presently in\nthree important respects: (1) as a paradigm shift descriptive 'distribution\nmodel' of experimental data is de-coupled from, and serves as the basis for,\npossible future predictive 'domain model' generalizable to proteins in the same\nclass for which 3D structures have yet to be determined experimentally, (2) the\ngeometric and analytic characteristics of class distributions are obtained via\nexact computational geometry calculations, and (3) the full data from a\ncomprehensive database are included in such calculations, eschewing training\nset selection and biases. In contrast to statistical and machine-learning\napproaches, the analytical, non-statistical geometry models of protein class\ndistributions demonstrated in this study furnish complete and precise\ninformation on their size and relative disposition in the high-dimensional\nspace (vis-\\`a-vis any overlaps leading to ambiguity and limits in\nclassification). Intended principally as accurate and summary description of\nthe complex relationships between amino acid composition and protein classes,\nand suitably as a basis for predictive modeling where permissible, the results\nsuggest that pen-ultimately they may be useful adjuncts for validating\nsequence-based protein structure predictions and contribute to theoretical and\nfundamental understanding of secondary structure formation and protein folding,\ndemonstrating the role of high dimensional amino acid composition space in\nprotein studies.",
    "pdf_url": "http://arxiv.org/pdf/2506.01857v3",
    "published": "2025-06-02T16:44:02+00:00",
    "categories": [
      "q-bio.BM",
      "q-bio.QM"
    ],
    "primary_category": "q-bio.BM"
  },
  {
    "id": "http://arxiv.org/abs/2506.01856v1",
    "title": "Synchronic Web Digital Identity: Speculations on the Art of the Possible",
    "authors": [
      "Thien-Nam Dinh",
      "Justin Li",
      "Mitch Negus",
      "Ken Goss"
    ],
    "abstract": "As search, social media, and artificial intelligence continue to reshape\ncollective knowledge, the preservation of trust on the public infosphere has\nbecome a defining challenge of our time. Given the breadth and versatility of\nadversarial threats, the best--and perhaps only--defense is an equally broad\nand versatile infrastructure for digital identity.\n  This document discusses the opportunities and implications of building such\nan infrastructure from the perspective of a national laboratory. The technical\nfoundation for this discussion is the emergence of the Synchronic Web, a\nSandia-developed infrastructure for asserting cryptographic provenance at\nInternet scale. As of the writing of this document, there is ongoing work to\ndevelop the underlying technology and apply it to multiple mission-specific\ndomains within Sandia. The primary objective of this document to extend the\nbody of existing work toward the more public-facing domain of digital identity.\n  Our approach depends on a non-standard, but philosophically defensible notion\nof identity: digital identity is an unbroken sequence of states in a\nwell-defined digital space. From this foundation, we abstractly describe the\ninfrastructural foundations and applied configurations that we expect to\nunderpin future notions of digital identity.",
    "pdf_url": "http://arxiv.org/pdf/2506.01856v1",
    "published": "2025-06-02T16:42:43+00:00",
    "categories": [
      "cs.CR"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2506.01855v1",
    "title": "Trade-offs in Data Memorization via Strong Data Processing Inequalities",
    "authors": [
      "Vitaly Feldman",
      "Guy Kornowski",
      "Xin Lyu"
    ],
    "abstract": "Recent research demonstrated that training large language models involves\nmemorization of a significant fraction of training data. Such memorization can\nlead to privacy violations when training on sensitive user data and thus\nmotivates the study of data memorization's role in learning. In this work, we\ndevelop a general approach for proving lower bounds on excess data\nmemorization, that relies on a new connection between strong data processing\ninequalities and data memorization. We then demonstrate that several simple and\nnatural binary classification problems exhibit a trade-off between the number\nof samples available to a learning algorithm, and the amount of information\nabout the training data that a learning algorithm needs to memorize to be\naccurate. In particular, $\\Omega(d)$ bits of information about the training\ndata need to be memorized when $O(1)$ $d$-dimensional examples are available,\nwhich then decays as the number of examples grows at a problem-specific rate.\nFurther, our lower bounds are generally matched (up to logarithmic factors) by\nsimple learning algorithms. We also extend our lower bounds to more general\nmixture-of-clusters models. Our definitions and results build on the work of\nBrown et al. (2021) and address several limitations of the lower bounds in\ntheir work.",
    "pdf_url": "http://arxiv.org/pdf/2506.01855v1",
    "published": "2025-06-02T16:41:49+00:00",
    "categories": [
      "cs.LG",
      "cs.IT",
      "math.IT",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.01854v1",
    "title": "Black-Box Crypto is Useless for Pseudorandom Codes",
    "authors": [
      "Sanjam Garg",
      "Sam Gunn",
      "Mingyuan Wang"
    ],
    "abstract": "A pseudorandom code is a keyed error-correction scheme with the property that\nany polynomial number of encodings appear random to any computationally bounded\nadversary. We show that the pseudorandomness of any code tolerating a constant\nrate of random errors cannot be based on black-box reductions to almost any\ngeneric cryptographic primitive: for instance, anything that can be built from\nrandom oracles, generic multilinear groups, and virtual black-box obfuscation.\nOur result is optimal, as Ghentiyala and Guruswami (2024) observed that\npseudorandom codes tolerating any sub-constant rate of random errors exist\nusing a black-box reduction from one-way functions.\n  The key technical ingredient in our proof is the hypercontractivity theorem\nfor Boolean functions, which we use to prove our impossibility in the random\noracle model. It turns out that this easily extends to an impossibility in the\npresence of ``crypto oracles,'' a notion recently introduced -- and shown to be\ncapable of implementing all the primitives mentioned above -- by Lin, Mook, and\nWichs (EUROCRYPT 2025).",
    "pdf_url": "http://arxiv.org/pdf/2506.01854v1",
    "published": "2025-06-02T16:41:08+00:00",
    "categories": [
      "cs.CR",
      "cs.CC"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2506.01853v1",
    "title": "ShapeLLM-Omni: A Native Multimodal LLM for 3D Generation and Understanding",
    "authors": [
      "Junliang Ye",
      "Zhengyi Wang",
      "Ruowen Zhao",
      "Shenghao Xie",
      "Jun Zhu"
    ],
    "abstract": "Recently, the powerful text-to-image capabilities of ChatGPT-4o have led to\ngrowing appreciation for native multimodal large language models. However, its\nmultimodal capabilities remain confined to images and text. Yet beyond images,\nthe ability to understand and generate 3D content is equally crucial. To\naddress this gap, we propose ShapeLLM-Omni-a native 3D large language model\ncapable of understanding and generating 3D assets and text in any sequence.\nFirst, we train a 3D vector-quantized variational autoencoder (VQVAE), which\nmaps 3D objects into a discrete latent space to achieve efficient and accurate\nshape representation and reconstruction. Building upon the 3D-aware discrete\ntokens, we innovatively construct a large-scale continuous training dataset\nnamed 3D-Alpaca, encompassing generation, comprehension, and editing, thus\nproviding rich resources for future research and training. Finally, by\nperforming instruction-based training of the Qwen-2.5-vl-7B-Instruct model on\nthe 3D-Alpaca dataset. Our work provides an effective attempt at extending\nmultimodal models with basic 3D capabilities, which contributes to future\nresearch in 3D-native AI. Project page:\nhttps://github.com/JAMESYJL/ShapeLLM-Omni",
    "pdf_url": "http://arxiv.org/pdf/2506.01853v1",
    "published": "2025-06-02T16:40:50+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.01852v2",
    "title": "Emergence of thermodynamic functioning regimes from finite coupling between a quantum thermal machine and a load",
    "authors": [
      "Gauthameshwar S.",
      "Noufal Jaseem",
      "Dario Poletti"
    ],
    "abstract": "Autonomous quantum thermal machines are particularly suited to understand how\ncorrelations between thermal baths, a load, and a thermal machine affect the\noverall thermodynamic functioning of the setup. Here, we show that by tuning\nthe operating temperatures and the magnitude of the coupling between machine\nand load, the thermal machine can operate in four modes: engine, accelerator,\nheater, or refrigerator. In particular, we show that as we increase the\ncoupling strength, the engine mode is suppressed, and the refrigerator mode is\nno longer attainable, leaving the heater as the most pronounced functioning\nmodality, followed by the accelerator. This regime switching can be amplified\nby quantum effects, such as the bosonic enhancement factor for a harmonic\noscillator load, which modifies the effective machine-load coupling, making the\nthermodynamic functioning sensitive to the initial preparation of the load.",
    "pdf_url": "http://arxiv.org/pdf/2506.01852v2",
    "published": "2025-06-02T16:40:21+00:00",
    "categories": [
      "quant-ph",
      "cond-mat.stat-mech"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.01851v1",
    "title": "Bayesian and Markovian classical feedforward for discriminating amplitude damping channels",
    "authors": [
      "Milajiguli Rexiti",
      "Stefano Mancini"
    ],
    "abstract": "We address the issue of multishot discrimination between two qubit-amplitude\ndamping channels by invoking a simple adaptive protocol that employs Helstrom\nmeasurement at each step and classical information feedforward. We contrast the\nperformance of Bayesian and Markovian strategies. We show that the former is\nonly slightly advantageous for a limited parameters' region.",
    "pdf_url": "http://arxiv.org/pdf/2506.01851v1",
    "published": "2025-06-02T16:38:56+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.01850v1",
    "title": "MoDA: Modulation Adapter for Fine-Grained Visual Grounding in Instructional MLLMs",
    "authors": [
      "Wayner Barrios",
      "Andrés Villa",
      "Juan León Alcázar",
      "SouYoung Jin",
      "Bernard Ghanem"
    ],
    "abstract": "Recently, Multimodal Large Language Models (MLLMs) have demonstrated\nimpressive performance on instruction-following tasks by integrating pretrained\nvisual encoders with large language models (LLMs). However, existing approaches\noften struggle to ground fine-grained visual concepts in complex scenes. In\nthis paper, we propose MoDA (Modulation Adapter), a lightweight yet effective\nmodule designed to refine pre-aligned visual features through\ninstruction-guided modulation. Our approach follows the standard LLaVA training\nprotocol, consisting of a two-stage process: (1) aligning image features to the\nLLMs input space via a frozen vision encoder and adapter layers, and (2)\nrefining those features using the MoDA adapter during the instructional tuning\nstage. MoDA employs a Transformer-based cross-attention mechanism to generate a\nmodulation mask over the aligned visual tokens, thereby emphasizing\nsemantically relevant embedding dimensions based on the language instruction.\nThe modulated features are then passed to the LLM for autoregressive language\ngeneration. Our experimental evaluation shows that MoDA improves visual\ngrounding and generates more contextually appropriate responses, demonstrating\nits effectiveness as a general-purpose enhancement for image-based MLLMs.",
    "pdf_url": "http://arxiv.org/pdf/2506.01850v1",
    "published": "2025-06-02T16:38:50+00:00",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.MM"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.01849v1",
    "title": "Trojan Horse Hunt in Time Series Forecasting for Space Operations",
    "authors": [
      "Krzysztof Kotowski",
      "Ramez Shendy",
      "Jakub Nalepa",
      "Przemysław Biecek",
      "Piotr Wilczyński",
      "Agata Kaczmarek",
      "Dawid Płudowski",
      "Artur Janicki",
      "Evridiki Ntagiou"
    ],
    "abstract": "This competition hosted on Kaggle\n(https://www.kaggle.com/competitions/trojan-horse-hunt-in-space) is the first\npart of a series of follow-up competitions and hackathons related to the\n\"Assurance for Space Domain AI Applications\" project funded by the European\nSpace Agency (https://assurance-ai.space-codev.org/). The competition idea is\nbased on one of the real-life AI security threats identified within the project\n-- the adversarial poisoning of continuously fine-tuned satellite telemetry\nforecasting models. The task is to develop methods for finding and\nreconstructing triggers (trojans) in advanced models for satellite telemetry\nforecasting used in safety-critical space operations. Participants are provided\nwith 1) a large public dataset of real-life multivariate satellite telemetry\n(without triggers), 2) a reference model trained on the clean data, 3) a set of\npoisoned neural hierarchical interpolation (N-HiTS) models for time series\nforecasting trained on the dataset with injected triggers, and 4) Jupyter\nnotebook with the training pipeline and baseline algorithm (the latter will be\npublished in the last month of the competition). The main task of the\ncompetition is to reconstruct a set of 45 triggers (i.e., short multivariate\ntime series segments) injected into the training data of the corresponding set\nof 45 poisoned models. The exact characteristics (i.e., shape, amplitude, and\nduration) of these triggers must be identified by participants. The popular\nNeural Cleanse method is adopted as a baseline, but it is not designed for time\nseries analysis and new approaches are necessary for the task. The impact of\nthe competition is not limited to the space domain, but also to many other\nsafety-critical applications of advanced time series analysis where model\npoisoning may lead to serious consequences.",
    "pdf_url": "http://arxiv.org/pdf/2506.01849v1",
    "published": "2025-06-02T16:38:16+00:00",
    "categories": [
      "cs.LG",
      "cs.CR"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.01848v2",
    "title": "Identifying Key Expert Actors in Cybercrime Forums Based on their Technical Expertise",
    "authors": [
      "Estelle Ruellan",
      "Francois Labreche",
      "Masarah Paquet-Clouston"
    ],
    "abstract": "The advent of Big Data has made the collection and analysis of cyber threat\nintelligence challenging due to its volume, leading research to focus on\nidentifying key threat actors; yet these studies have failed to consider the\ntechnical expertise of these actors. Expertise, especially towards specific\nattack patterns, is crucial for cybercrime intelligence, as it focuses on\ntargeting actors with the knowledge and skills to attack enterprises. Using\nCVEs and CAPEC classifications to build a bimodal network, as well as community\ndetection, k-means and a criminological framework, this study addresses the key\nhacker identification problem by identifying communities interested in specific\nattack patterns across cybercrime forums and their related key expert actors.\nThe analyses reveal several key contributions. First, the community structure\nof the CAPEC-actor bimodal network shows that there exists groups of actors\ninterested in similar attack patterns across cybercrime forums. Second, key\nactors identified in this study account for about 4% of the study population.\nThird, about half of the study population are amateurs who show little\ntechnical expertise. Finally, key actors highlighted in this study represent a\npromising scarcity for resources allocation in cyber threat intelligence\nproduction. Further research should look into how they develop and use their\ntechnical expertise in cybercrime forums.",
    "pdf_url": "http://arxiv.org/pdf/2506.01848v2",
    "published": "2025-06-02T16:34:03+00:00",
    "categories": [
      "cs.CR",
      "cs.CY"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2506.01847v2",
    "title": "A Quantum-Inspired Framework for Subjective Evaluation: Cognitive Polarization and Entropic Measures",
    "authors": [
      "Bumned Soodchomshom"
    ],
    "abstract": "We propose a quantum-inspired framework to model subjective evaluation\nprocesses using state vectors in Hilbert space. In this approach, individual\npreferences are represented as cognitive states polarized between 'like' and\n'dislike', enabling a continuous interpretation of evaluative attitudes. The\nevolution of these states is characterized on the Bloch sphere, and the\ncognitive coherence is interpreted geometrically. To further analyze the\nuncertainty and diversity in subjective preferences, we introduce both Shannon\nentropy (at the individual level) and Von Neumann entropy (at the group level)\ninto the framework. A small-scale simulated dataset is used to conceptually\ndemonstrate how these entropy measures can reveal internal indecisiveness and\ncollective incoherence. The model offers a physically grounded and\nmathematically expressive tool for quantifying subjectivity.",
    "pdf_url": "http://arxiv.org/pdf/2506.01847v2",
    "published": "2025-06-02T16:33:00+00:00",
    "categories": [
      "cond-mat.mes-hall"
    ],
    "primary_category": "cond-mat.mes-hall"
  },
  {
    "id": "http://arxiv.org/abs/2506.01846v2",
    "title": "Code-Switching and Syntax: A Large-Scale Experiment",
    "authors": [
      "Igor Sterner",
      "Simone Teufel"
    ],
    "abstract": "The theoretical code-switching (CS) literature provides numerous pointwise\ninvestigations that aim to explain patterns in CS, i.e. why bilinguals switch\nlanguage in certain positions in a sentence more often than in others. A\nresulting consensus is that CS can be explained by the syntax of the\ncontributing languages. There is however no large-scale, multi-language,\ncross-phenomena experiment that tests this claim. When designing such an\nexperiment, we need to make sure that the system that is predicting where\nbilinguals tend to switch has access only to syntactic information. We provide\nsuch an experiment here. Results show that syntax alone is sufficient for an\nautomatic system to distinguish between sentences in minimal pairs of CS, to\nthe same degree as bilingual humans. Furthermore, the learnt syntactic patterns\ngeneralise well to unseen language pairs.",
    "pdf_url": "http://arxiv.org/pdf/2506.01846v2",
    "published": "2025-06-02T16:32:14+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.01845v1",
    "title": "On-device Streaming Discrete Speech Units",
    "authors": [
      "Kwanghee Choi",
      "Masao Someki",
      "Emma Strubell",
      "Shinji Watanabe"
    ],
    "abstract": "Discrete speech units (DSUs) are derived from clustering the features of\nself-supervised speech models (S3Ms). DSUs offer significant advantages for\non-device streaming speech applications due to their rich phonetic information,\nhigh transmission efficiency, and seamless integration with large language\nmodels. However, conventional DSU-based approaches are impractical as they\nrequire full-length speech input and computationally expensive S3Ms. In this\nwork, we reduce both the attention window and the model size while preserving\nthe effectiveness of DSUs. Our results demonstrate that we can reduce\nfloating-point operations (FLOPs) by 50% with only a relative increase of 6.5%\nin character error rate (CER) on the ML-SUPERB 1h dataset. These findings\nhighlight the potential of DSUs for real-time speech processing in\nresource-constrained environments.",
    "pdf_url": "http://arxiv.org/pdf/2506.01845v1",
    "published": "2025-06-02T16:30:38+00:00",
    "categories": [
      "eess.AS",
      "cs.LG",
      "cs.SD"
    ],
    "primary_category": "eess.AS"
  },
  {
    "id": "http://arxiv.org/abs/2506.01844v1",
    "title": "SmolVLA: A Vision-Language-Action Model for Affordable and Efficient Robotics",
    "authors": [
      "Mustafa Shukor",
      "Dana Aubakirova",
      "Francesco Capuano",
      "Pepijn Kooijmans",
      "Steven Palma",
      "Adil Zouitine",
      "Michel Aractingi",
      "Caroline Pascal",
      "Martino Russi",
      "Andres Marafioti",
      "Simon Alibert",
      "Matthieu Cord",
      "Thomas Wolf",
      "Remi Cadene"
    ],
    "abstract": "Vision-language models (VLMs) pretrained on large-scale multimodal datasets\nencode rich visual and linguistic knowledge, making them a strong foundation\nfor robotics. Rather than training robotic policies from scratch, recent\napproaches adapt VLMs into vision-language-action (VLA) models that enable\nnatural language-driven perception and control. However, existing VLAs are\ntypically massive--often with billions of parameters--leading to high training\ncosts and limited real-world deployability. Moreover, they rely on academic and\nindustrial datasets, overlooking the growing availability of\ncommunity-collected data from affordable robotic platforms. In this work, we\npresent SmolVLA, a small, efficient, and community-driven VLA that drastically\nreduces both training and inference costs, while retaining competitive\nperformance. SmolVLA is designed to be trained on a single GPU and deployed on\nconsumer-grade GPUs or even CPUs. To further improve responsiveness, we\nintroduce an asynchronous inference stack decoupling perception and action\nprediction from action execution, allowing higher control rates with chunked\naction generation. Despite its compact size, SmolVLA achieves performance\ncomparable to VLAs that are 10x larger. We evaluate SmolVLA on a range of both\nsimulated as well as real-world robotic benchmarks and release all code,\npretrained models, and training data.",
    "pdf_url": "http://arxiv.org/pdf/2506.01844v1",
    "published": "2025-06-02T16:30:19+00:00",
    "categories": [
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.01843v2",
    "title": "Projective error models: Stabilizer codes, Clifford codes, and weak stabilizer codes",
    "authors": [
      "Jonas Eidesen"
    ],
    "abstract": "We introduce more general notions of Clifford codes and stabilizer codes, the\nlatter we call weak stabilizer codes. This is all formulated in the language of\nprojective representation theory of finite groups and we give a novel\ndescription of the detectable errors for a Clifford code. We give a complete\ncharacterization of when a Clifford code is also a weak stabilizer code in the\ncase where the considered error model is a nice error basis. We also give\nexamples of infinite families of non-stabilizer Clifford codes as well as\nexamples of non-Clifford weak stabilizer codes. The latter of these types of\nexamples is a class of codes that have not been studied in the same systematic\nframework as Clifford codes and stabilizer codes.",
    "pdf_url": "http://arxiv.org/pdf/2506.01843v2",
    "published": "2025-06-02T16:29:44+00:00",
    "categories": [
      "quant-ph",
      "math.RT"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.01842v1",
    "title": "An Assessment of Organics Detection and Characterization on the Surface of Europa with Infrared Spectroscopy",
    "authors": [
      "Ishan Mishra",
      "Nikole Lewis",
      "Jonathan Lunine",
      "Kevin P. Hand"
    ],
    "abstract": "Organics, if they do exist on Europa, may only be present in trace amounts on\nthe surface. NASA's upcoming mission Europa Clipper is going to provide global,\nhigh quality data of the surface of Europa in the near-infrared (NIR),\nspecifically the 3-5~$\\mu$m region, where organics are rich in spectroscopic\nfeatures. In this work we investigate Europa Clipper's ability to constrain the\nabundance of selected trace species of interest that span different chemical\nbonds found in organics, such as C-H, C=C, C$\\equiv$C, C=O and C$\\equiv$N, via\nNIR spectroscopy in the 3-5~$\\mu$m wavelength region. We simulate reflectance\nspectra of these trace species mixed with water ice, at varying SNR and\nabundance fractions. The evidence for the trace species in a mixture is\nevaluated using two approaches: 1) calculating average strength of absorption\nfeature(s), and 2) Bayesian model comparison (BMC) analysis. Our simulations\nshow that sharp and strong spectroscopic features of trace ($\\sim 5\\%$\nabundance by number) organic species should be detectable at $> 3\\sigma$\nsignificance in Europa Clipper quality data. A BMC analysis pushes the\n$3\\sigma$ detection threshold of trace species even lower to $<1 \\%$ abundance.\nWe also consider an example with all trace species mixed together, with\noverlapping features, and BMC is able to retrieve strong evidence for all of\nthem and also provide constraints on their abundance. These results are\npromising for Europa Clipper's capability to detect trace organic species,\nwhich would allow correlations to be drawn between the composition and\ngeological regions with possibly endogenic material.",
    "pdf_url": "http://arxiv.org/pdf/2506.01842v1",
    "published": "2025-06-02T16:28:13+00:00",
    "categories": [
      "astro-ph.EP"
    ],
    "primary_category": "astro-ph.EP"
  },
  {
    "id": "http://arxiv.org/abs/2506.01841v1",
    "title": "Beyond Pixel Agreement: Large Language Models as Clinical Guardrails for Reliable Medical Image Segmentation",
    "authors": [
      "Jiaxi Sheng",
      "Leyi Yu",
      "Haoyue Li",
      "Yifan Gao",
      "Xin Gao"
    ],
    "abstract": "Evaluating AI-generated medical image segmentations for clinical\nacceptability poses a significant challenge, as traditional pixelagreement\nmetrics often fail to capture true diagnostic utility. This paper introduces\nHierarchical Clinical Reasoner (HCR), a novel framework that leverages Large\nLanguage Models (LLMs) as clinical guardrails for reliable, zero-shot quality\nassessment. HCR employs a structured, multistage prompting strategy that guides\nLLMs through a detailed reasoning process, encompassing knowledge recall,\nvisual feature analysis, anatomical inference, and clinical synthesis, to\nevaluate segmentations. We evaluated HCR on a diverse dataset across six\nmedical imaging tasks. Our results show that HCR, utilizing models like Gemini\n2.5 Flash, achieved a classification accuracy of 78.12%, performing comparably\nto, and in instances exceeding, dedicated vision models such as ResNet50\n(72.92% accuracy) that were specifically trained for this task. The HCR\nframework not only provides accurate quality classifications but also generates\ninterpretable, step-by-step reasoning for its assessments. This work\ndemonstrates the potential of LLMs, when appropriately guided, to serve as\nsophisticated evaluators, offering a pathway towards more trustworthy and\nclinically-aligned quality control for AI in medical imaging.",
    "pdf_url": "http://arxiv.org/pdf/2506.01841v1",
    "published": "2025-06-02T16:28:03+00:00",
    "categories": [
      "eess.IV"
    ],
    "primary_category": "eess.IV"
  },
  {
    "id": "http://arxiv.org/abs/2506.01840v2",
    "title": "Minimal Pair-Based Evaluation of Code-Switching",
    "authors": [
      "Igor Sterner",
      "Simone Teufel"
    ],
    "abstract": "There is a lack of an evaluation methodology that estimates the extent to\nwhich large language models (LLMs) use code-switching (CS) in the same way as\nbilinguals. Existing methods do not have wide language coverage, fail to\naccount for the diverse range of CS phenomena, or do not scale. We propose an\nintervention based on minimal pairs of CS. Each minimal pair contains one\nnaturally occurring CS sentence and one minimally manipulated variant. We\ncollect up to 1,000 such pairs each for 11 language pairs. Our human\nexperiments show that, for every language pair, bilinguals consistently prefer\nthe naturally occurring CS sentence. Meanwhile our experiments with current\nLLMs show that the larger the model, the more consistently it assigns higher\nprobability to the naturally occurring CS sentence than to the variant. In\naccordance with theoretical claims, the largest probability differences arise\nin those pairs where the manipulated material consisted of closed-class words.",
    "pdf_url": "http://arxiv.org/pdf/2506.01840v2",
    "published": "2025-06-02T16:27:53+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.01839v1",
    "title": "Beyond Static Responses: Multi-Agent LLM Systems as a New Paradigm for Social Science Research",
    "authors": [
      "Jennifer Haase",
      "Sebastian Pokutta"
    ],
    "abstract": "As large language models (LLMs) transition from static tools to fully agentic\nsystems, their potential for transforming social science research has become\nincreasingly evident. This paper introduces a structured framework for\nunderstanding the diverse applications of LLM-based agents, ranging from simple\ndata processors to complex, multi-agent systems capable of simulating emergent\nsocial dynamics. By mapping this developmental continuum across six levels, the\npaper clarifies the technical and methodological boundaries between different\nagentic architectures, providing a comprehensive overview of current\ncapabilities and future potential. It highlights how lower-tier systems\nstreamline conventional tasks like text classification and data annotation,\nwhile higher-tier systems enable novel forms of inquiry, including the study of\ngroup dynamics, norm formation, and large-scale social processes. However,\nthese advancements also introduce significant challenges, including issues of\nreproducibility, ethical oversight, and the risk of emergent biases. The paper\ncritically examines these concerns, emphasizing the need for robust validation\nprotocols, interdisciplinary collaboration, and standardized evaluation\nmetrics. It argues that while LLM-based agents hold transformative potential\nfor the social sciences, realizing this promise will require careful,\ncontext-sensitive deployment and ongoing methodological refinement. The paper\nconcludes with a call for future research that balances technical innovation\nwith ethical responsibility, encouraging the development of agentic systems\nthat not only replicate but also extend the frontiers of social science,\noffering new insights into the complexities of human behavior.",
    "pdf_url": "http://arxiv.org/pdf/2506.01839v1",
    "published": "2025-06-02T16:27:29+00:00",
    "categories": [
      "cs.MA"
    ],
    "primary_category": "cs.MA"
  },
  {
    "id": "http://arxiv.org/abs/2506.01838v1",
    "title": "On the genericity of irreducible subfactors",
    "authors": [
      "Yoonkyeong Lee",
      "Brent Nelson"
    ],
    "abstract": "We show that finitely generated irreducible $\\mathrm{II}_1$ subfactors are\ngeneric in the following sense. Given a separable $\\mathrm{II}_1$ factor $M$\nand an integer $n\\geq 2$, equip the set of $n$-tuples of self-adjoint operators\nin $M$ with norm at most $1$ with the metric $d(x,y) = \\max_{1\\leq i \\leq n}\n\\|x_i - y_i\\|_2$. Then the set of $n$-tuples that generate an irreducible\nsubfactor of $M$ forms a dense $G_\\delta$ set in this metric space. On the way\nto proving this result, we show that closable derivations vanish on the\nanticoarse space associated to their kernels, which leads to new applications\nof conjugate systems in free probability.",
    "pdf_url": "http://arxiv.org/pdf/2506.01838v1",
    "published": "2025-06-02T16:27:04+00:00",
    "categories": [
      "math.OA",
      "46L10, 46L54"
    ],
    "primary_category": "math.OA"
  },
  {
    "id": "http://arxiv.org/abs/2506.01837v3",
    "title": "Inverse Microparticle Design for Enhanced Optical Trapping and Detection Efficiency in All Six Degrees of Freedom",
    "authors": [
      "Moosung Lee",
      "Benjamin A. Stickler",
      "Thomas Pertsch",
      "Sungkun Hong"
    ],
    "abstract": "Achieving quantum-limited motional control of optically trapped particles\nbeyond the sub-micrometer scale is an outstanding problem in levitated\noptomechanics. A key obstacle is solving the light scattering problem and\nidentifying particle geometries that allow stable trapping and efficient\nmotional detection of their center of mass and rotational motion in three\ndimensions. Here, we present a computational framework that combines an\nefficient electromagnetic scattering solver with the adjoint method to\ninversely design printable microparticles tailored for levitated optomechanics.\nOur method allows identifying optimized geometries, characterized by enhanced\noptical trapping and detection efficiencies compared to conventional\nmicrospheres. This improves the feasibility of quantum-limited motional control\nof all translational and rotational degrees of freedom in a standard\nstanding-wave optical trap.",
    "pdf_url": "http://arxiv.org/pdf/2506.01837v3",
    "published": "2025-06-02T16:27:00+00:00",
    "categories": [
      "physics.optics",
      "quant-ph"
    ],
    "primary_category": "physics.optics"
  },
  {
    "id": "http://arxiv.org/abs/2506.02092v1",
    "title": "Towards Better Generalization and Interpretability in Unsupervised Concept-Based Models",
    "authors": [
      "Francesco De Santis",
      "Philippe Bich",
      "Gabriele Ciravegna",
      "Pietro Barbiero",
      "Danilo Giordano",
      "Tania Cerquitelli"
    ],
    "abstract": "To increase the trustworthiness of deep neural networks, it is critical to\nimprove the understanding of how they make decisions. This paper introduces a\nnovel unsupervised concept-based model for image classification, named\nLearnable Concept-Based Model (LCBM) which models concepts as random variables\nwithin a Bernoulli latent space. Unlike traditional methods that either require\nextensive human supervision or suffer from limited scalability, our approach\nemploys a reduced number of concepts without sacrificing performance. We\ndemonstrate that LCBM surpasses existing unsupervised concept-based models in\ngeneralization capability and nearly matches the performance of black-box\nmodels. The proposed concept representation enhances information retention and\naligns more closely with human understanding. A user study demonstrates the\ndiscovered concepts are also more intuitive for humans to interpret. Finally,\ndespite the use of concept embeddings, we maintain model interpretability by\nmeans of a local linear combination of concepts.",
    "pdf_url": "http://arxiv.org/pdf/2506.02092v1",
    "published": "2025-06-02T16:26:41+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.01836v1",
    "title": "Your Interface, Your Control: Adapting Takeover Requests for Seamless Handover in Semi-Autonomous Vehicles",
    "authors": [
      "Amr Gomaa",
      "Simon Engel",
      "Elena Meiser",
      "Abdulrahman Mohamed Selim",
      "Tobias Jungbluth",
      "Aeneas Leon Sommer",
      "Sarah Kohlmann",
      "Michael Barz",
      "Maurice Rekrut",
      "Michael Feld",
      "Daniel Sonntag",
      "Antonio Krüger"
    ],
    "abstract": "With the automotive industry transitioning towards conditionally automated\ndriving, takeover warning systems are crucial for ensuring safe collaborative\ndriving between users and semi-automated vehicles. However, previous work has\nfocused on static warning systems that do not accommodate different driver\nstates. Therefore, we propose an adaptive takeover warning system that is\npersonalised to drivers, enhancing their experience and safety. We conducted\ntwo user studies investigating semi-autonomous driving scenarios in rural and\nurban environments while participants performed non-driving-related tasks such\nas text entry and visual search. We investigated the effects of varying time\nbudgets and head-up versus head-down displays for takeover requests on drivers'\nsituational awareness and mental state. Through our statistical and clustering\nanalyses, we propose strategies for designing adaptable takeover systems, e.g.,\nusing longer time budgets and head-up displays for non-hazardous takeover\nevents in high-complexity environments while using shorter time budgets and\nhead-down displays for hazardous events in low-complexity environments.",
    "pdf_url": "http://arxiv.org/pdf/2506.01836v1",
    "published": "2025-06-02T16:26:20+00:00",
    "categories": [
      "cs.HC"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2506.01835v4",
    "title": "Discrete vortex-based broadcast mode analysis for mitigation of dynamic stall",
    "authors": [
      "Het D. Patel",
      "Yi Tsung Lee",
      "Ashok Gopalarathnam",
      "Chi-An Yeh"
    ],
    "abstract": "We integrate a discrete vortex method with complex network analysis to\nstrategize dynamic stall mitigation over a pitching airfoil with active flow\ncontrol. The objective is to inform actuator placement and timing to introduce\ncontrol inputs during the transient evolution of dynamic stall. To this end, we\nrepresent the massively separated flow as a network of discrete vortical\nelements and quantify the interactions among these vortical nodes by tracking\nthe spread of displacement perturbations between each pair of elements using\nthe discrete vortex method. This enables a network broadcast mode analysis to\nidentify an optimal set of vortices, critical timing, and direction to seed\nperturbations as control inputs. Motivated by the goal of mitigating dynamic\nstall, the optimality is defined as minimizing the total circulation of free\nvortices generated from the leading edge over a prescribed time horizon. We\ndemonstrate the framework on two cases: two-dimensional flow over a flat plate\nairfoil and three-dimensional turbulent flow over a SD7003 airfoil. The\nanalysis reveals that optimal timing for introducing disturbances occurs just\nafter separation onset, when the shear layer pinches up to form the core of the\ndynamic stall vortex. Broadcast modes indicate that vortical nodes along the\nshear layer are optimal for control, guiding actuator placement. Flow\nsimulations validate these insights: placing actuators near the leading edge\nand triggering them shortly after separation yields a 12% and 30% reduction in\npeak lift for the flat plate and SD7003 cases, respectively. A corresponding\ndecrease in vorticity injection under control confirms the analysis objective.\nThis study highlights the potential of combining discrete vortex methods with\nnetwork analysis to guide active flow control in unsteady aerodynamics.",
    "pdf_url": "http://arxiv.org/pdf/2506.01835v4",
    "published": "2025-06-02T16:25:30+00:00",
    "categories": [
      "physics.flu-dyn"
    ],
    "primary_category": "physics.flu-dyn"
  },
  {
    "id": "http://arxiv.org/abs/2506.01834v1",
    "title": "Pressure-induced structural disordering and anomalous pressure-volume behaviour in high-entropy zirconates",
    "authors": [
      "Yogendar Singh",
      "Xinghua Su",
      "Vivek Kumar",
      "H. K. Poswal",
      "K. K. Pandey",
      "Pawan Kumar Kulriya"
    ],
    "abstract": "The ambient-temperature high-pressure behaviour of\n(La0.2Nd0.2Sm0.2Gd0.2Yb0.2)2Zr2O7 zirconate (HEZ) nanopowders with three\ndifferent average particle sizes (~25nm, ~45 nm and ~ 68nm) were studied using\nsynchrotron X-ray diffraction (SR-XRD) measurements up to ~30 GPa. Smaller\nparticle-size HEZ nanopowder (~25 nm), synthesized at the lower sintering\ntemperature, exhibits pure defect-fluorite (DF) phase, whereas larger\nparticle-size HEZ nanopowders (~45nm and ~68nm), synthesized at the higher\nsintering temperature, exhibit mixture of DF and pyrochlore phase (PY). The\nphase fraction of the PY phase increases with sintering temperature and hence\nwith the particle size. All the HEZ nanopowders exhibit stability of initial\nstructures (DF and PY) up to ~ 30 GPa, though phase fraction of PY phase in\nlarger particle-size HEZ nanopowders successively reduces with pressure which\nis concomitant with significant variation in ox48f fractional coordinate in PY\nphase. Both the phases in all the studied samples exhibit anomalous\npressure-volume (P-V) behaviour between ~7 to 15 GPa. The anomaly decreases\nwith increasing particle size of HEZ nanopowders. The variation of bond lengths\nand polyhedron volume with pressure suggests that the anomalous P-V behaviour\nand structural changes at high pressures are primarily due to the distortion of\nthe polyhedrons in DF and PY structures in HEZ nanopowders.",
    "pdf_url": "http://arxiv.org/pdf/2506.01834v1",
    "published": "2025-06-02T16:23:34+00:00",
    "categories": [
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2506.01833v1",
    "title": "SPACE: Your Genomic Profile Predictor is a Powerful DNA Foundation Model",
    "authors": [
      "Zhao Yang",
      "Jiwei Zhu",
      "Bing Su"
    ],
    "abstract": "Inspired by the success of unsupervised pre-training paradigms, researchers\nhave applied these approaches to DNA pre-training. However, we argue that these\napproaches alone yield suboptimal results because pure DNA sequences lack\nsufficient information, since their functions are regulated by genomic profiles\nlike chromatin accessibility. Here, we demonstrate that supervised training for\ngenomic profile prediction serves as a more effective alternative to pure\nsequence pre-training. Furthermore, considering the multi-species and\nmulti-profile nature of genomic profile prediction, we introduce our\n$\\textbf{S}$pecies-$\\textbf{P}$rofile $\\textbf{A}$daptive\n$\\textbf{C}$ollaborative $\\textbf{E}$xperts (SPACE) that leverages Mixture of\nExperts (MoE) to better capture the relationships between DNA sequences across\ndifferent species and genomic profiles, thereby learning more effective DNA\nrepresentations. Through extensive experiments across various tasks, our model\nachieves state-of-the-art performance, establishing that DNA models trained\nwith supervised genomic profiles serve as powerful DNA representation learners.\nThe code is available at https://github.com/ZhuJiwei111/SPACE.",
    "pdf_url": "http://arxiv.org/pdf/2506.01833v1",
    "published": "2025-06-02T16:23:05+00:00",
    "categories": [
      "cs.LG",
      "q-bio.GN"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.01832v2",
    "title": "Pseudorandom bits for non-commutative programs",
    "authors": [
      "Chin Ho Lee",
      "Emanuele Viola"
    ],
    "abstract": "We obtain new explicit pseudorandom generators for several computational\nmodels involving groups. Our main results are as follows:\n  1. We consider read-once group-products over a finite group $G$, i.e., tests\nof the form $\\prod_{i=1}^n g_i^{x_i}$ where $g_i\\in G$, a special case of\nread-once permutation branching programs. We give generators with optimal seed\nlength $c_G \\log(n/\\varepsilon)$ over any $p$-group. The proof uses the\nsmall-bias plus noise paradigm, but derandomizes the noise to avoid the\nrecursion in previous work. Our generator works when the bits are read in any\norder. Previously for any non-commutative group the best seed length was\n$\\ge\\log n\\log(1/\\varepsilon)$, even for a fixed order.\n  2. We give a reduction that \"lifts\" suitable generators for group products\nover $G$ to a generator that fools width-$w$ block products, i.e., tests of the\nform $\\prod g_i^{f_i}$ where the $f_i$ are arbitrary functions on disjoint\nblocks of $w$ bits. Block products generalize several previously studied\nclasses. The reduction applies to groups that are mixing in a\nrepresentation-theoretic sense that we identify.\n  3. Combining (2) with (1) and other works we obtain new generators for block\nproducts over the quaternions or over any commutative group, with nearly\noptimal seed length. In particular, we obtain generators for read-once\npolynomials modulo any fixed $m$ with nearly optimal seed length. Previously\nthis was known only for $m=2$.\n  4. We give a new generator for products over \"mixing groups.\" The\nconstruction departs from previous work and uses representation theory. For\nconstant error, we obtain optimal seed length, improving on previous work\n(which applied to any group).\n  This paper identifies a challenge in the area that is reminiscent of a\nroadblock in circuit complexity -- handling composite moduli -- and points to\nseveral classes of groups to be attacked next.",
    "pdf_url": "http://arxiv.org/pdf/2506.01832v2",
    "published": "2025-06-02T16:21:30+00:00",
    "categories": [
      "cs.CC"
    ],
    "primary_category": "cs.CC"
  },
  {
    "id": "http://arxiv.org/abs/2506.01831v1",
    "title": "Non-adiabatically driven quantum interference effects in the ultracold K + KRb $\\longrightarrow$ Rb + K$_{2}$ chemical reaction",
    "authors": [
      "H. da Silva Jr.",
      "B. K. Kendrick",
      "H. Li",
      "S. Kotochigova",
      "N. Balakrishnan"
    ],
    "abstract": "The K + KRb $\\longrightarrow$ Rb + K$_{2}$ chemical reaction is the first\nultracold atom-diatom chemical reaction for which experimental results have\nbeen reported for temperatures below 1 $\\mu$K more than a decade ago. The\nreaction occurs through coupling with an excited electronic state that is\naccessible even in the ultracold limit. A previous quantum dynamics study,\nexcluding non-adiabatic effects, has reported a rate coefficient that is about\n35\\% below the experimental value. Here, we report the first non-adiabatic\nquantum dynamics study of this reaction and obtain rate coefficients in better\nagreement with experiments. Our results show that short-range dynamics mediated\nby coupling with the excited electronic state introduces quantum interference\neffects that influence both the state-to-state rate coefficients and the\noverall reaction rates.",
    "pdf_url": "http://arxiv.org/pdf/2506.01831v1",
    "published": "2025-06-02T16:20:17+00:00",
    "categories": [
      "physics.chem-ph",
      "physics.atm-clus",
      "quant-ph"
    ],
    "primary_category": "physics.chem-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.01830v2",
    "title": "On a Recursive Integer Sequence Implying the Nonexistence of Odd Perfect Numbers",
    "authors": [
      "Ritesh Dwivedi",
      "Rohit Yadav"
    ],
    "abstract": "We define a sequence of positive integers recursively, where each term is\ndetermined as follows: starting with a given positive integer, if the term is\nodd, the next is the sum of its positive divisors; if the term is even, the\nsubsequent term is half the term. In this paper, we conjecture that this\nsequence eventually reaches one for all initial values. Furthermore, we\nclassify a family of integers for which this conjecture holds.",
    "pdf_url": "http://arxiv.org/pdf/2506.01830v2",
    "published": "2025-06-02T16:18:03+00:00",
    "categories": [
      "math.NT",
      "11A25, 11A51, 11Y70"
    ],
    "primary_category": "math.NT"
  },
  {
    "id": "http://arxiv.org/abs/2506.01829v1",
    "title": "CiteEval: Principle-Driven Citation Evaluation for Source Attribution",
    "authors": [
      "Yumo Xu",
      "Peng Qi",
      "Jifan Chen",
      "Kunlun Liu",
      "Rujun Han",
      "Lan Liu",
      "Bonan Min",
      "Vittorio Castelli",
      "Arshit Gupta",
      "Zhiguo Wang"
    ],
    "abstract": "Citation quality is crucial in information-seeking systems, directly\ninfluencing trust and the effectiveness of information access. Current\nevaluation frameworks, both human and automatic, mainly rely on Natural\nLanguage Inference (NLI) to assess binary or ternary supportiveness from cited\nsources, which we argue is a suboptimal proxy for citation evaluation. In this\nwork we introduce CiteEval, a citation evaluation framework driven by\nprinciples focusing on fine-grained citation assessment within a broad context,\nencompassing not only the cited sources but the full retrieval context, user\nquery, and generated text. Guided by the proposed framework, we construct\nCiteBench, a multi-domain benchmark with high-quality human annotations on\ncitation quality. To enable efficient evaluation, we further develop\nCiteEval-Auto, a suite of model-based metrics that exhibit strong correlation\nwith human judgments. Experiments across diverse systems demonstrate\nCiteEval-Auto's superior ability to capture the multifaceted nature of\ncitations compared to existing metrics, offering a principled and scalable\napproach to evaluate and improve model-generated citations.",
    "pdf_url": "http://arxiv.org/pdf/2506.01829v1",
    "published": "2025-06-02T16:15:34+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.01828v2",
    "title": "Stabilization of the Spread-Global Dimension",
    "authors": [
      "Benjamin Blanchette",
      "Justin Desrochers",
      "Eric J. Hanson",
      "Luis Scoccola"
    ],
    "abstract": "Motivated by constructions from applied topology, there has been recent\ninterest in the homological algebra of linear representations of posets,\nparticularly in the context of homological algebra relative to non-standard\nexact structures. A prominent example is the spread exact structure on the\ncategory of representations of a fixed poset, in which the indecomposable\nprojectives are the spread representations (that is, the indicator\nrepresentations of convex and connected subsets). The spread-global dimension\nis known to be finite for finite posets and not uniformly bounded on the\ncollection of all Cartesian products between two arbitrary finite total orders.\nIt was conjectured in [AENY23] that the spread-global dimension is uniformly\nbounded on the collection of all Cartesian products between a fixed finite\ntotal order and an arbitrary finite total order. We provide a positive answer\nto this conjecture and, more generally, prove that the spread-global dimension\nis uniformly bounded on the collection of all Cartesian products between a\nfixed finite poset and an arbitrary finite total order. In doing so, we also\nestablish the existence of finite spread-resolutions for finitely presented\nrepresentations of arbitrary grid posets.",
    "pdf_url": "http://arxiv.org/pdf/2506.01828v2",
    "published": "2025-06-02T16:15:07+00:00",
    "categories": [
      "math.RT",
      "math.AT",
      "math.CO"
    ],
    "primary_category": "math.RT"
  },
  {
    "id": "http://arxiv.org/abs/2506.01827v1",
    "title": "Memory Access Characterization of Large Language Models in CPU Environment and its Potential Impacts",
    "authors": [
      "Spencer Banasik"
    ],
    "abstract": "As machine learning algorithms are shown to be an increasingly valuable tool,\nthe demand for their access has grown accordingly. Oftentimes, it is infeasible\nto run inference with larger models without an accelerator, which may be\nunavailable in environments that have constraints such as energy consumption,\nsecurity, or cost. To increase the availability of these models, we aim to\nimprove the LLM inference speed on a CPU-only environment by modifying the\ncache architecture. To determine what improvements could be made, we conducted\ntwo experiments using Llama.cpp and the QWEN model: running various cache\nconfigurations and evaluating their performance, and outputting a trace of the\nmemory footprint. Using these experiments, we investigate the memory access\npatterns and performance characteristics to identify potential optimizations.",
    "pdf_url": "http://arxiv.org/pdf/2506.01827v1",
    "published": "2025-06-02T16:12:22+00:00",
    "categories": [
      "cs.LG",
      "cs.AR"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.01826v1",
    "title": "Efficient Learning of Balanced Signed Graphs via Sparse Linear Programming",
    "authors": [
      "Haruki Yokota",
      "Hiroshi Higashi",
      "Yuichi Tanaka",
      "Gene Cheung"
    ],
    "abstract": "Signed graphs are equipped with both positive and negative edge weights,\nencoding pairwise correlations as well as anti-correlations in data. A balanced\nsigned graph is a signed graph with no cycles containing an odd number of\nnegative edges. Laplacian of a balanced signed graph has eigenvectors that map\nvia a simple linear transform to ones in a corresponding positive graph\nLaplacian, thus enabling reuse of spectral filtering tools designed for\npositive graphs. We propose an efficient method to learn a balanced signed\ngraph Laplacian directly from data. Specifically, extending a previous linear\nprogramming (LP) based sparse inverse covariance estimation method called\nCLIME, we formulate a new LP problem for each Laplacian column $i$, where the\nlinear constraints restrict weight signs of edges stemming from node $i$, so\nthat nodes of same / different polarities are connected by positive / negative\nedges. Towards optimal model selection, we derive a suitable CLIME parameter\n$\\rho$ based on a combination of the Hannan-Quinn information criterion and a\nminimum feasibility criterion. We solve the LP problem efficiently by tailoring\na sparse LP method based on ADMM. We theoretically prove local solution\nconvergence of our proposed iterative algorithm. Extensive experimental results\non synthetic and real-world datasets show that our balanced graph learning\nmethod outperforms competing methods and enables reuse of spectral filters,\nwavelets, and graph convolutional nets (GCN) constructed for positive graphs.",
    "pdf_url": "http://arxiv.org/pdf/2506.01826v1",
    "published": "2025-06-02T16:09:51+00:00",
    "categories": [
      "cs.LG",
      "eess.SP"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.01825v1",
    "title": "Which Factors Make Code LLMs More Vulnerable to Backdoor Attacks? A Systematic Study",
    "authors": [
      "Chenyu Wang",
      "Zhou Yang",
      "Yaniv Harel",
      "David Lo"
    ],
    "abstract": "Code LLMs are increasingly employed in software development. However, studies\nhave shown that they are vulnerable to backdoor attacks: when a trigger (a\nspecific input pattern) appears in the input, the backdoor will be activated\nand cause the model to generate malicious outputs. Researchers have designed\nvarious triggers and demonstrated the feasibility of implanting backdoors by\npoisoning a fraction of the training data. Some basic conclusions have been\nmade, such as backdoors becoming easier to implant when more training data are\nmodified. However, existing research has not explored other factors influencing\nbackdoor attacks on Code LLMs, such as training batch size, epoch number, and\nthe broader design space for triggers, e.g., trigger length.\n  To bridge this gap, we use code summarization as an example to perform an\nempirical study that systematically investigates the factors affecting backdoor\neffectiveness and understands the extent of the threat posed. Three categories\nof factors are considered: data, model, and inference, revealing previously\noverlooked findings. We find that the prevailing consensus -- that attacks are\nineffective at extremely low poisoning rates -- is incorrect. The absolute\nnumber of poisoned samples matters as well. Specifically, poisoning just 20 out\nof 454K samples (0.004\\% poisoning rate -- far below the minimum setting of\n0.1\\% in prior studies) successfully implants backdoors! Moreover, the common\ndefense is incapable of removing even a single poisoned sample from it.\nAdditionally, small batch sizes increase the risk of backdoor attacks. We also\nuncover other critical factors such as trigger types, trigger length, and the\nrarity of tokens in the triggers, leading to valuable insights for assessing\nCode LLMs' vulnerability to backdoor attacks. Our study highlights the urgent\nneed for defense mechanisms against extremely low poisoning rate settings.",
    "pdf_url": "http://arxiv.org/pdf/2506.01825v1",
    "published": "2025-06-02T16:07:34+00:00",
    "categories": [
      "cs.CR",
      "cs.SE"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2506.01824v2",
    "title": "A Quantum Information Theoretic Approach to Tractable Probabilistic Models",
    "authors": [
      "Pedro Zuidberg Dos Martires"
    ],
    "abstract": "By recursively nesting sums and products, probabilistic circuits have emerged\nin recent years as an attractive class of generative models as they enjoy, for\ninstance, polytime marginalization of random variables. In this work we study\nthese machine learning models using the framework of quantum information\ntheory, leading to the introduction of positive unital circuits (PUnCs), which\ngeneralize circuit evaluations over positive real-valued probabilities to\ncircuit evaluations over positive semi-definite matrices. As a consequence,\nPUnCs strictly generalize probabilistic circuits as well as recently introduced\ncircuit classes such as PSD circuits.",
    "pdf_url": "http://arxiv.org/pdf/2506.01824v2",
    "published": "2025-06-02T16:07:08+00:00",
    "categories": [
      "quant-ph",
      "cs.AI"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.01823v1",
    "title": "Phenomenology of altermagnets",
    "authors": [
      "Maxim Mostovoy"
    ],
    "abstract": "Altermagnets have recently emerged as a new class of magnetic materials\nsharing properties of both antiferromagnets and ferromagnets. Despite very\nsmall net magnetization, they show phenomena usually associated with\nferromagnetism, such as the Faraday, Kerr and Anomalous Hall effects, resulting\nfrom the relativistic spin-orbit coupling, as well as the spin splitting of\nelectron bands and Spin Hall Effect of non-relativistic origin. Spin space\ngroups and magnetic multipoles are used to explain symmetry properties of\naltermagnets. Here, I show that the conventional phenomenological description\nin terms of a vector antiferromagnetic order parameter can be applied to all\neffects observed in altermagnets with collinear and non-collinear spin orders.\nI also discuss non-relativistic effects in non-altermagnets.",
    "pdf_url": "http://arxiv.org/pdf/2506.01823v1",
    "published": "2025-06-02T16:06:46+00:00",
    "categories": [
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2506.01822v1",
    "title": "GSCodec Studio: A Modular Framework for Gaussian Splat Compression",
    "authors": [
      "Sicheng Li",
      "Chengzhen Wu",
      "Hao Li",
      "Xiang Gao",
      "Yiyi Liao",
      "Lu Yu"
    ],
    "abstract": "3D Gaussian Splatting and its extension to 4D dynamic scenes enable\nphotorealistic, real-time rendering from real-world captures, positioning\nGaussian Splats (GS) as a promising format for next-generation immersive media.\nHowever, their high storage requirements pose significant challenges for\npractical use in sharing, transmission, and storage. Despite various studies\nexploring GS compression from different perspectives, these efforts remain\nscattered across separate repositories, complicating benchmarking and the\nintegration of best practices. To address this gap, we present GSCodec Studio,\na unified and modular framework for GS reconstruction, compression, and\nrendering. The framework incorporates a diverse set of 3D/4D GS reconstruction\nmethods and GS compression techniques as modular components, facilitating\nflexible combinations and comprehensive comparisons. By integrating best\npractices from community research and our own explorations, GSCodec Studio\nsupports the development of compact representation and compression solutions\nfor static and dynamic Gaussian Splats, namely our Static and Dynamic GSCodec,\nachieving competitive rate-distortion performance in static and dynamic GS\ncompression. The code for our framework is publicly available at\nhttps://github.com/JasonLSC/GSCodec_Studio , to advance the research on\nGaussian Splats compression.",
    "pdf_url": "http://arxiv.org/pdf/2506.01822v1",
    "published": "2025-06-02T16:04:25+00:00",
    "categories": [
      "cs.CV",
      "cs.MM"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.01821v1",
    "title": "Traveling waves for a two-phase Stefan problem with radiation",
    "authors": [
      "Elena Demattè",
      "Juan J. L. Velázquez"
    ],
    "abstract": "In this paper we study the existence of traveling wave solutions for a\nfree-boundary problem modeling the phase transition of a material where the\nheat is transported by both conduction and radiation. Specifically, we consider\na one-dimensional two-phase Stefan problem with an additional non-local\nnon-linear integral term describing the situation in which the heat is\ntransferred in the solid phase also by radiation, while the liquid phase is\ncompletely transparent, not interacting with radiation. We will prove that\nthere are traveling wave solutions for the considered model, differently from\nthe case of the classical Stefan problem in which only self-similar solutions\nwith the parabolic scale $ x\\sim \\sqrt{t} $ exist. In particular we will show\nthat there exist traveling waves for which the solid expands. The properties of\nthese solutions will be studied using maximum-principle methods, blow-up limits\nand Liouville-type Theorems for non-linear integral-differential equations.",
    "pdf_url": "http://arxiv.org/pdf/2506.01821v1",
    "published": "2025-06-02T16:03:55+00:00",
    "categories": [
      "math.AP"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2506.01820v1",
    "title": "Fodor and Pylyshyn's Legacy -- Still No Human-like Systematic Compositionality in Neural Networks",
    "authors": [
      "Tim Woydt",
      "Moritz Willig",
      "Antonia Wüst",
      "Lukas Helff",
      "Wolfgang Stammer",
      "Constantin A. Rothkopf",
      "Kristian Kersting"
    ],
    "abstract": "Strong meta-learning capabilities for systematic compositionality are\nemerging as an important skill for navigating the complex and changing tasks of\ntoday's world. However, in presenting models for robust adaptation to novel\nenvironments, it is important to refrain from making unsupported claims about\nthe performance of meta-learning systems that ultimately do not stand up to\nscrutiny. While Fodor and Pylyshyn famously posited that neural networks\ninherently lack this capacity as they are unable to model compositional\nrepresentations or structure-sensitive operations, and thus are not a viable\nmodel of the human mind, Lake and Baroni recently presented meta-learning as a\npathway to compositionality. In this position paper, we critically revisit this\nclaim and highlight limitations in the proposed meta-learning framework for\ncompositionality. Our analysis shows that modern neural meta-learning systems\ncan only perform such tasks, if at all, under a very narrow and restricted\ndefinition of a meta-learning setup. We therefore claim that `Fodor and\nPylyshyn's legacy' persists, and to date, there is no human-like systematic\ncompositionality learned in neural networks.",
    "pdf_url": "http://arxiv.org/pdf/2506.01820v1",
    "published": "2025-06-02T16:02:53+00:00",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2506.01819v2",
    "title": "Not All Jokes Land: Evaluating Large Language Models Understanding of Workplace Humor",
    "authors": [
      "Mohammadamin Shafiei",
      "Hamidreza Saffari"
    ],
    "abstract": "With the recent advances in Artificial Intelligence (AI) and Large Language\nModels (LLMs), the automation of daily tasks, like automatic writing, is\ngetting more and more attention. Hence, efforts have focused on aligning LLMs\nwith human values, yet humor, particularly professional industrial humor used\nin workplaces, has been largely neglected. To address this, we develop a\ndataset of professional humor statements along with features that determine the\nappropriateness of each statement. Our evaluation of five LLMs shows that LLMs\noften struggle to judge the appropriateness of humor accurately.",
    "pdf_url": "http://arxiv.org/pdf/2506.01819v2",
    "published": "2025-06-02T16:00:50+00:00",
    "categories": [
      "cs.CL",
      "cs.CY"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.01818v1",
    "title": "Inductive-Effect-Driven Tunability of Magnetism and Lumines-cence in Triangular Layers ANd(SO4)2 (A = Rb, Cs)",
    "authors": [
      "Xudong Huai",
      "Ebube E. Oyeka",
      "Uchenna Chinaegbomkpa",
      "Michal J. Winiarski",
      "Hugo Sanabria",
      "Thao T. Tran"
    ],
    "abstract": "Tuning the energy landscape of manybody electronic states in extended solids\nthrough the inductive effect-a concept widely used in organic chemistry-offers\na new, effective strategy for materials development. Here, we demonstrate this\napproach using the ANd(SO4)2 (A = Rb, Cs) model system, which possesses\ndifferent A-site electronegativity and displays a distorted triangular lattice\nof Nd3+ (4I9/2 ground term). Magnetization data indicate appreciable\nantiferromagnetic interactions without long-range ordering down to 1.8 K while\nhighlighting the tunable population of the electronic states.\nTemperature-dependent and time-resolved photoluminescence measurements reveal\nthat emissions and nonradiative processes can be modified by the inductive\neffect at the atomic level. Heat capacity data confirm no magnetic ordering and\nadd insight into the role of phonons in emission lifetime. Density functional\ntheory calculations prove enhanced covalency in the Cs compound compared to the\nRb counterpart while acknowledging the adjustable magnetic intralayer and\ninter-layer exchange pathways. These results demonstrate a viable framework for\nutilizing the inductive effect as an important knob for simultaneously dialing\nin magnetic, optical, and electronic properties in quantum materials.",
    "pdf_url": "http://arxiv.org/pdf/2506.01818v1",
    "published": "2025-06-02T16:00:16+00:00",
    "categories": [
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2506.01817v1",
    "title": "BD at BEA 2025 Shared Task: MPNet Ensembles for Pedagogical Mistake Identification and Localization in AI Tutor Responses",
    "authors": [
      "Shadman Rohan",
      "Ishita Sur Apan",
      "Muhtasim Ibteda Shochcho",
      "Md Fahim",
      "Mohammad Ashfaq Ur Rahman",
      "AKM Mahbubur Rahman",
      "Amin Ahsan Ali"
    ],
    "abstract": "We present Team BD's submission to the BEA 2025 Shared Task on Pedagogical\nAbility Assessment of AI-powered Tutors, under Track 1 (Mistake Identification)\nand Track 2 (Mistake Location). Both tracks involve three-class classification\nof tutor responses in educational dialogues - determining if a tutor correctly\nrecognizes a student's mistake (Track 1) and whether the tutor pinpoints the\nmistake's location (Track 2). Our system is built on MPNet, a Transformer-based\nlanguage model that combines BERT and XLNet's pre-training advantages. We\nfine-tuned MPNet on the task data using a class-weighted cross-entropy loss to\nhandle class imbalance, and leveraged grouped cross-validation (10 folds) to\nmaximize the use of limited data while avoiding dialogue overlap between\ntraining and validation. We then performed a hard-voting ensemble of the best\nmodels from each fold, which improves robustness and generalization by\ncombining multiple classifiers. Our approach achieved strong results on both\ntracks, with exact-match macro-F1 scores of approximately 0.7110 for Mistake\nIdentification and 0.5543 for Mistake Location on the official test set. We\ninclude comprehensive analysis of our system's performance, including confusion\nmatrices and t-SNE visualizations to interpret classifier behavior, as well as\na taxonomy of common errors with examples. We hope our ensemble-based approach\nand findings provide useful insights for designing reliable tutor response\nevaluation systems in educational dialogue settings.",
    "pdf_url": "http://arxiv.org/pdf/2506.01817v1",
    "published": "2025-06-02T15:57:49+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.01816v1",
    "title": "An adaptive data sampling strategy for stabilizing dynamical systems via controller inference",
    "authors": [
      "Steffen W. R. Werner",
      "Benjamin Peherstorfer"
    ],
    "abstract": "Learning stabilizing controllers from data is an important task in\nengineering applications; however, collecting informative data is challenging\nbecause unstable systems often lead to rapidly growing or erratic trajectories.\nIn this work, we propose an adaptive sampling scheme that generates data while\nsimultaneously stabilizing the system to avoid instabilities during the data\ncollection. Under mild assumptions, the approach provably generates data sets\nthat are informative for stabilization and have minimal size. The numerical\nexperiments demonstrate that controller inference with the novel adaptive\nsampling approach learns controllers with up to one order of magnitude fewer\ndata samples than unguided data generation. The results show that the proposed\napproach opens the door to stabilizing systems in edge cases and limit states\nwhere instabilities often occur and data collection is inherently difficult.",
    "pdf_url": "http://arxiv.org/pdf/2506.01816v1",
    "published": "2025-06-02T15:56:17+00:00",
    "categories": [
      "math.OC",
      "cs.LG",
      "cs.NA",
      "math.DS",
      "math.NA",
      "37N35, 65F55, 90C22, 90C59, 93B52"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2506.01815v1",
    "title": "Path Signatures for Feature Extraction. An Introduction to the Mathematics Underpinning an Efficient Machine Learning Technique",
    "authors": [
      "Stephan Sturm"
    ],
    "abstract": "We provide an introduction to the topic of path signatures as means of\nfeature extraction for machine learning from data streams. The article stresses\nthe mathematical theory underlying the signature methodology, highlighting the\nconceptual character without plunging into the technical details of rigorous\nproofs. These notes are based on an introductory presentation given to students\nof the Research Experience for Undergraduates in Industrial Mathematics and\nStatistics at Worcester Polytechnic Institute in June 2024.",
    "pdf_url": "http://arxiv.org/pdf/2506.01815v1",
    "published": "2025-06-02T15:55:26+00:00",
    "categories": [
      "cs.LG",
      "math.PR",
      "60L10, 62H30"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.01814v1",
    "title": "Analysis of LLM Bias (Chinese Propaganda & Anti-US Sentiment) in DeepSeek-R1 vs. ChatGPT o3-mini-high",
    "authors": [
      "PeiHsuan Huang",
      "ZihWei Lin",
      "Simon Imbot",
      "WenCheng Fu",
      "Ethan Tu"
    ],
    "abstract": "Large language models (LLMs) increasingly shape public understanding and\ncivic decisions, yet their ideological neutrality is a growing concern. While\nexisting research has explored various forms of LLM bias, a direct,\ncross-lingual comparison of models with differing geopolitical\nalignments-specifically a PRC-system model versus a non-PRC counterpart-has\nbeen lacking. This study addresses this gap by systematically evaluating\nDeepSeek-R1 (PRC-aligned) against ChatGPT o3-mini-high (non-PRC) for\nChinese-state propaganda and anti-U.S. sentiment. We developed a novel corpus\nof 1,200 de-contextualized, reasoning-oriented questions derived from\nChinese-language news, presented in Simplified Chinese, Traditional Chinese,\nand English. Answers from both models (7,200 total) were assessed using a\nhybrid evaluation pipeline combining rubric-guided GPT-4o scoring with human\nannotation. Our findings reveal significant model-level and language-dependent\nbiases. DeepSeek-R1 consistently exhibited substantially higher proportions of\nboth propaganda and anti-U.S. bias compared to ChatGPT o3-mini-high, which\nremained largely free of anti-U.S. sentiment and showed lower propaganda\nlevels. For DeepSeek-R1, Simplified Chinese queries elicited the highest bias\nrates; these diminished in Traditional Chinese and were nearly absent in\nEnglish. Notably, DeepSeek-R1 occasionally responded in Simplified Chinese to\nTraditional Chinese queries and amplified existing PRC-aligned terms in its\nChinese answers, demonstrating an \"invisible loudspeaker\" effect. Furthermore,\nsuch biases were not confined to overtly political topics but also permeated\ncultural and lifestyle content, particularly in DeepSeek-R1.",
    "pdf_url": "http://arxiv.org/pdf/2506.01814v1",
    "published": "2025-06-02T15:54:06+00:00",
    "categories": [
      "cs.CL",
      "cs.SI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.01813v3",
    "title": "The Ultimate Test of Superintelligent AI Agents: Can an AI Balance Care and Control in Asymmetric Relationships?",
    "authors": [
      "Djallel Bouneffouf",
      "Matthew Riemer",
      "Kush Varshney"
    ],
    "abstract": "This paper introduces the Shepherd Test, a new conceptual test for assessing\nthe moral and relational dimensions of superintelligent artificial agents. The\ntest is inspired by human interactions with animals, where ethical\nconsiderations about care, manipulation, and consumption arise in contexts of\nasymmetric power and self-preservation. We argue that AI crosses an important,\nand potentially dangerous, threshold of intelligence when it exhibits the\nability to manipulate, nurture, and instrumentally use less intelligent agents,\nwhile also managing its own survival and expansion goals. This includes the\nability to weigh moral trade-offs between self-interest and the well-being of\nsubordinate agents. The Shepherd Test thus challenges traditional AI evaluation\nparadigms by emphasizing moral agency, hierarchical behavior, and complex\ndecision-making under existential stakes. We argue that this shift is critical\nfor advancing AI governance, particularly as AI systems become increasingly\nintegrated into multi-agent environments. We conclude by identifying key\nresearch directions, including the development of simulation environments for\ntesting moral behavior in AI, and the formalization of ethical manipulation\nwithin multi-agent systems.",
    "pdf_url": "http://arxiv.org/pdf/2506.01813v3",
    "published": "2025-06-02T15:53:56+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2506.01812v1",
    "title": "Two-colour balanced optical cross-correlator using fibre-coupled PPLN waveguides",
    "authors": [
      "Jonathan Christie",
      "James R. Henderson",
      "Edward W. Snedden",
      "Laura Corner"
    ],
    "abstract": "We present a two-colour fully fibre-coupled balanced optical cross-correlator\n(BOXC) based on sum-frequency generation (SFG) between 1560 nm and 800 nm laser\npulses using waveguides implemented in type-0 phase-matched periodically poled\nLiNbO$_{3}$ (PPLN) crystals. The interaction has an effective nonlinear\ncoefficient of $d_{eff}$ = 16.1 pm/V, many times higher than comparable\nnonlinear crystals used for this SFG interaction such as barium borate (BBO).\nThe resulting sensitivity of the cross-correlator is measured to be 5.11 mV/fs,\nfive times greater than current bulk-optic BOXCs after accounting for\ndifferences in transimpedance gain and photodetector responsivity, with the\npotential for significantly higher sensitivity after optimisations to the\ncross-correlator design.",
    "pdf_url": "http://arxiv.org/pdf/2506.01812v1",
    "published": "2025-06-02T15:53:53+00:00",
    "categories": [
      "physics.optics",
      "physics.acc-ph",
      "physics.ins-det"
    ],
    "primary_category": "physics.optics"
  },
  {
    "id": "http://arxiv.org/abs/2506.01811v2",
    "title": "Quantum Circuit Encodings of Polynomial Chaos Expansions",
    "authors": [
      "Junaid Aftab",
      "Christoph Schwab",
      "Haizhao Yang",
      "Jakob Zech"
    ],
    "abstract": "This work investigates the expressive power of quantum circuits in\napproximating high-dimensional, real-valued functions. We focus on\ncountably-parametric holomorphic maps $u:U\\to \\mathbb{R}$, where the parameter\ndomain is $U=[-1,1]^{\\mathbb{N}}$. We establish dimension-independent quantum\ncircuit approximation rates via the best $n$-term truncations of generalized\npolynomial chaos (gPC) expansions of these parametric maps, demonstrating that\nthese rates depend solely on the summability exponent of the gPC expansion\ncoefficients. The key to our findings is based on the fact that so-called\n``$(\\boldsymbol{b},\\epsilon)$-holomorphic'' functions, where $\\boldsymbol{b}\\in\n(0,1]^\\mathbb N \\cap \\ell^p(\\mathbb N)$ for some $p\\in(0,1)$, permit structured\nand sparse gPC expansions. Then, $n$-term truncated gPC expansions are known to\nadmit approximation rates of order $n^{-1/p + 1/2}$ in the $L^2$ norm and of\norder $n^{-1/p + 1}$ in the $L^\\infty$ norm. We show the existence of\nparameterized quantum circuit (PQC) encodings of these $n$-term truncated gPC\nexpansions, and bound PQC depth and width via (i) tensorization of univariate\nPQCs that encode Cheby\\v{s}ev-polynomials in $[-1,1]$ and (ii) linear\ncombination of unitaries (LCU) to build PQC emulations of $n$-term truncated\ngPC expansions. The results provide a rigorous mathematical foundation for the\nuse of quantum algorithms in high-dimensional function approximation. As\ncountably-parametric holomorphic maps naturally arise in parametric PDE models\nand uncertainty quantification (UQ), our results have implications for\nquantum-enhanced algorithms for a wide range of maps in applications.",
    "pdf_url": "http://arxiv.org/pdf/2506.01811v2",
    "published": "2025-06-02T15:53:36+00:00",
    "categories": [
      "math.NA",
      "cs.NA",
      "quant-ph"
    ],
    "primary_category": "math.NA"
  },
  {
    "id": "http://arxiv.org/abs/2506.01809v1",
    "title": "Electronic Temperature-Driven Phase Stability and Structural Evolution of Iron at High Pressure",
    "authors": [
      "S. Azadi",
      "S. M. Vinko"
    ],
    "abstract": "We present Gibbs free-energy phase diagrams for compressed iron within a\npressure range of 20 to 300 GPa and electronic temperature up to 3 eV obtained\nusing finite-temperature density functional and density functional perturbation\ntheories. Our results for bcc, fcc, and hcp phases predict solid-solid phase\ntransitions in iron driven purely by electronic entropy and temperature. We\nfound a phase transition from hcp to bcc at pressures above 200 GPa, which\ndepends on the electronic temperature. An experimental observation of the\nstability of the bcc phase above 200 GPa by X-ray Free Electron Laser has\nrecently been reported.",
    "pdf_url": "http://arxiv.org/pdf/2506.01809v1",
    "published": "2025-06-02T15:53:11+00:00",
    "categories": [
      "cond-mat.mtrl-sci",
      "cond-mat.other",
      "physics.comp-ph",
      "physics.geo-ph"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2506.01810v1",
    "title": "On the homological shifts of cover ideals of Cohen-Macaulay graphs",
    "authors": [
      "Amit Roy",
      "Kamalesh Saha"
    ],
    "abstract": "For a non-negative integer $k$, let $\\mathrm{HS}_{k}(J(G))$ denote the\n$k^{\\text{th}}$ homological shift ideal of the vertex cover ideal $J(G)$ of a\ngraph $G$. For each $k\\geq 2$, we construct a Cohen-Macaulay very well-covered\ngraph $G_k$ which is both Cohen-Macaulay bipartite and a whiskered graph so\nthat $\\mathrm{HS}_{k}(J(G))$ does not have a linear resolution. This\ncontradicts several results as well as disproves a conjecture in [J. Algebra,\n$\\mathbf{629}$, (2023), 76-108] and [Mediterr. J. Math., $\\mathbf{21}$, 135\n(2024)]. The graphs $G_k$ are also examples of clique-whiskered graphs\nintroduced by Cook and Nagel, which include Cohen-Macaulay chordal graphs,\nCohen-Macaulay Cameron-Walker graphs, and clique corona graphs. Surprisingly,\nfor Cohen-Macaulay chordal graphs, we can use a special ordering on the minimal\ngenerators to show that $\\mathrm{HS}_{k}(J(G))$ has linear quotients for all\n$k$. Moreover, for all Cohen-Macaulay Cameron-Walker graphs and certain clique\ncorona graphs, we show that $\\mathrm{HS}_{k}(J(G))$ is weakly polymatroidal,\nand thus, has linear quotients for all $k$.",
    "pdf_url": "http://arxiv.org/pdf/2506.01810v1",
    "published": "2025-06-02T15:53:11+00:00",
    "categories": [
      "math.AC",
      "math.CO",
      "Primary: 13D02, 05E40, Secondary: 13F55, 13H10"
    ],
    "primary_category": "math.AC"
  },
  {
    "id": "http://arxiv.org/abs/2506.01808v1",
    "title": "NAVER LABS Europe Submission to the Instruction-following Track",
    "authors": [
      "Beomseok Lee",
      "Marcely Zanon Boito",
      "Laurent Besacier",
      "Ioan Calapodescu"
    ],
    "abstract": "In this paper we describe NAVER LABS Europe submission to the\ninstruction-following speech processing short track at IWSLT 2025. We\nparticipate in the constrained settings, developing systems that can\nsimultaneously perform ASR, ST, and SQA tasks from English speech input into\nthe following target languages: Chinese, Italian, and German. Our solution\nleverages two pretrained modules: (1) a speech-to-LLM embedding projector\ntrained using representations from the SeamlessM4T-v2-large speech encoder; and\n(2) LoRA adapters trained on text data on top of a Llama-3.1-8B-Instruct. These\nmodules are jointly loaded and further instruction-tuned for 1K steps on\nmultilingual and multimodal data to form our final system submitted for\nevaluation.",
    "pdf_url": "http://arxiv.org/pdf/2506.01808v1",
    "published": "2025-06-02T15:52:57+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.01807v2",
    "title": "Propaganda and Information Dissemination in the Russo-Ukrainian War: Natural Language Processing of Russian and Western Twitter Narratives",
    "authors": [
      "Zaur Gouliev"
    ],
    "abstract": "The conflict in Ukraine has been not only characterised by military\nengagement but also by a significant information war, with social media\nplatforms like X, formerly known as Twitter playing an important role in\nshaping public perception. This article provides an analysis of tweets from\npropaganda accounts and trusted accounts collected from the onset of the war,\nFebruary 2022 until the middle of May 2022 with n=40,000 total tweets. We\nutilise natural language processing and machine learning algorithms to assess\nthe sentiment and identify key themes, topics and narratives across the dataset\nwith human-in-the-loop (HITL) analysis throughout. Our findings indicate\ndistinct strategies in how information is created, spread, and targeted at\ndifferent audiences by both sides. Propaganda accounts frequently employ\nemotionally charged language and disinformation to evoke fear and distrust,\nwhereas other accounts, primarily Western tend to focus on factual reporting\nand humanitarian aspects of the conflict. Clustering analysis reveals groups of\naccounts with similar behaviours, which we suspect indicates the presence of\ncoordinated efforts. This research attempts to contribute to our understanding\nof the dynamics of information warfare and offers techniques for future studies\non social media influence in military conflicts.",
    "pdf_url": "http://arxiv.org/pdf/2506.01807v2",
    "published": "2025-06-02T15:52:04+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.01806v1",
    "title": "Ridgeformer: Mutli-Stage Contrastive Training For Fine-grained Cross-Domain Fingerprint Recognition",
    "authors": [
      "Shubham Pandey",
      "Bhavin Jawade",
      "Srirangaraj Setlur"
    ],
    "abstract": "The increasing demand for hygienic and portable biometric systems has\nunderscored the critical need for advancements in contactless fingerprint\nrecognition. Despite its potential, this technology faces notable challenges,\nincluding out-of-focus image acquisition, reduced contrast between fingerprint\nridges and valleys, variations in finger positioning, and perspective\ndistortion. These factors significantly hinder the accuracy and reliability of\ncontactless fingerprint matching. To address these issues, we propose a novel\nmulti-stage transformer-based contactless fingerprint matching approach that\nfirst captures global spatial features and subsequently refines localized\nfeature alignment across fingerprint samples. By employing a hierarchical\nfeature extraction and matching pipeline, our method ensures fine-grained,\ncross-sample alignment while maintaining the robustness of global feature\nrepresentation. We perform extensive evaluations on publicly available datasets\nsuch as HKPolyU and RidgeBase under different evaluation protocols, such as\ncontactless-to-contact matching and contactless-to-contactless matching and\ndemonstrate that our proposed approach outperforms existing methods, including\nCOTS solutions.",
    "pdf_url": "http://arxiv.org/pdf/2506.01806v1",
    "published": "2025-06-02T15:51:45+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.01805v1",
    "title": "The Shannon-McMillan-Breiman theorem of random dynamical systems for amenable group actions",
    "authors": [
      "Yuan Lian",
      "Bin Zhu"
    ],
    "abstract": "The Shannon-McMillan-Breiman theorem is one of the most important results in\ninformation theory, which can describe the random ergodic process, and its\nproof uses the famous Birkhoff ergodic theorem, so it can be seen that it plays\na crucial role in ergodic theory. In this paper, the Shannon-McMillan-Breiman\ntheorem in the random dynamical systems is proved from the perspective of an\namenable group action, which provides a boost for the development of entropy\ntheory in the random dynamical systems for amenable group actions.",
    "pdf_url": "http://arxiv.org/pdf/2506.01805v1",
    "published": "2025-06-02T15:51:28+00:00",
    "categories": [
      "math.DS"
    ],
    "primary_category": "math.DS"
  },
  {
    "id": "http://arxiv.org/abs/2506.14800v1",
    "title": "A micromorphic-based artificial diffusion method for stabilized finite element approximation of convection-diffusion problems",
    "authors": [
      "Soheil Firooz",
      "B. Daya Reddy",
      "Paul Steinmann"
    ],
    "abstract": "We present a novel artificial diffusion method to circumvent the\ninstabilities associated with the standard finite element approximation of\nconvection-diffusion equations. Motivated by the micromorphic approach, we\nintroduce an auxiliary variable, which is related to the gradient of the field\nof interest, and which leads to a coupled problem. Conditions for\nwell-posedness of the resulting formulation are established. We carry out a\ncomprehensive numerical study to compare the proposed methodology against some\nwell-established approaches in one- and two-dimensional settings. The proposed\nmethod outperforms established approaches in general in approximating\naccurately the solutions to pertinent and challenging problems.",
    "pdf_url": "http://arxiv.org/pdf/2506.14800v1",
    "published": "2025-06-02T15:47:18+00:00",
    "categories": [
      "math.NA",
      "cs.NA",
      "math-ph",
      "math.MP"
    ],
    "primary_category": "math.NA"
  },
  {
    "id": "http://arxiv.org/abs/2506.01804v2",
    "title": "A Study on the MCP x A2A Framework for Enhancing Interoperability of LLM-based Autonomous Agents",
    "authors": [
      "Cheonsu Jeong"
    ],
    "abstract": "This paper provides an in-depth technical analysis and implementation\nmethodology of the open-source Agent-to-Agent (A2A) protocol developed by\nGoogle and the Model Context Protocol (MCP) introduced by Anthropic. While the\nevolution of LLM-based autonomous agents is rapidly accelerating, efficient\ninteractions among these agents and their integration with external systems\nremain significant challenges. In modern AI systems, collaboration between\nautonomous agents and integration with external tools have become essential\nelements for building practical AI applications. A2A offers a standardized\ncommunication method that enables agents developed in heterogeneous\nenvironments to collaborate effectively, while MCP provides a structured I/O\nframework for agents to connect with external tools and resources. Prior\nstudies have focused primarily on the features and applications of either A2A\nor MCP individually. In contrast, this study takes an integrated approach,\nexploring how the two protocols can complement each other to address\ninteroperability issues and facilitate efficient collaboration within complex\nagent ecosystems.",
    "pdf_url": "http://arxiv.org/pdf/2506.01804v2",
    "published": "2025-06-02T15:46:16+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2506.01803v1",
    "title": "Dimension of Besicovitch-Eggleston sets for non-autonomous systems with countable symbolic dynamics",
    "authors": [
      "Jonny Imbierski",
      "Charlene Kalle"
    ],
    "abstract": "In this article we derive a formula for the Hausdorff dimension of\nBesicovitch-Eggleston level sets associated with non-autonomous dynamics\nconstructed from families of countable affine iterated function systems. The\nformula obtained shows that the universal-lower-bound phenomenon present in the\nautonomous case studied by Fan et al. (2010) persists in this non-autonomous\nsetting.",
    "pdf_url": "http://arxiv.org/pdf/2506.01803v1",
    "published": "2025-06-02T15:43:26+00:00",
    "categories": [
      "math.DS",
      "11K55, 37H99"
    ],
    "primary_category": "math.DS"
  },
  {
    "id": "http://arxiv.org/abs/2506.01802v1",
    "title": "UMA: Ultra-detailed Human Avatars via Multi-level Surface Alignment",
    "authors": [
      "Heming Zhu",
      "Guoxing Sun",
      "Christian Theobalt",
      "Marc Habermann"
    ],
    "abstract": "Learning an animatable and clothed human avatar model with vivid dynamics and\nphotorealistic appearance from multi-view videos is an important foundational\nresearch problem in computer graphics and vision. Fueled by recent advances in\nimplicit representations, the quality of the animatable avatars has achieved an\nunprecedented level by attaching the implicit representation to drivable human\ntemplate meshes. However, they usually fail to preserve the highest level of\ndetail, particularly apparent when the virtual camera is zoomed in and when\nrendering at 4K resolution and higher. We argue that this limitation stems from\ninaccurate surface tracking, specifically, depth misalignment and surface drift\nbetween character geometry and the ground truth surface, which forces the\ndetailed appearance model to compensate for geometric errors. To address this,\nwe propose a latent deformation model and supervising the 3D deformation of the\nanimatable character using guidance from foundational 2D video point trackers,\nwhich offer improved robustness to shading and surface variations, and are less\nprone to local minima than differentiable rendering. To mitigate the drift over\ntime and lack of 3D awareness of 2D point trackers, we introduce a cascaded\ntraining strategy that generates consistent 3D point tracks by anchoring point\ntracks to the rendered avatar, which ultimately supervises our avatar at the\nvertex and texel level. To validate the effectiveness of our approach, we\nintroduce a novel dataset comprising five multi-view video sequences, each over\n10 minutes in duration, captured using 40 calibrated 6K-resolution cameras,\nfeaturing subjects dressed in clothing with challenging texture patterns and\nwrinkle deformations. Our approach demonstrates significantly improved\nperformance in rendering quality and geometric accuracy over the prior state of\nthe art.",
    "pdf_url": "http://arxiv.org/pdf/2506.01802v1",
    "published": "2025-06-02T15:42:33+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.01801v1",
    "title": "OmniV2V: Versatile Video Generation and Editing via Dynamic Content Manipulation",
    "authors": [
      "Sen Liang",
      "Zhentao Yu",
      "Zhengguang Zhou",
      "Teng Hu",
      "Hongmei Wang",
      "Yi Chen",
      "Qin Lin",
      "Yuan Zhou",
      "Xin Li",
      "Qinglin Lu",
      "Zhibo Chen"
    ],
    "abstract": "The emergence of Diffusion Transformers (DiT) has brought significant\nadvancements to video generation, especially in text-to-video and\nimage-to-video tasks. Although video generation is widely applied in various\nfields, most existing models are limited to single scenarios and cannot perform\ndiverse video generation and editing through dynamic content manipulation. We\npropose OmniV2V, a video model capable of generating and editing videos across\ndifferent scenarios based on various operations, including: object movement,\nobject addition, mask-guided video edit, try-on, inpainting, outpainting, human\nanimation, and controllable character video synthesis. We explore a unified\ndynamic content manipulation injection module, which effectively integrates the\nrequirements of the above tasks. In addition, we design a visual-text\ninstruction module based on LLaVA, enabling the model to effectively understand\nthe correspondence between visual content and instructions. Furthermore, we\nbuild a comprehensive multi-task data processing system. Since there is data\noverlap among various tasks, this system can efficiently provide data\naugmentation. Using this system, we construct a multi-type, multi-scenario\nOmniV2V dataset and its corresponding OmniV2V-Test benchmark. Extensive\nexperiments show that OmniV2V works as well as, and sometimes better than, the\nbest existing open-source and commercial models for many video generation and\nediting tasks.",
    "pdf_url": "http://arxiv.org/pdf/2506.01801v1",
    "published": "2025-06-02T15:42:06+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.01800v1",
    "title": "A Precise Metallicity and Carbon-to-Oxygen Ratio for a Warm Giant Exoplanet from its Panchromatic JWST Emission Spectrum",
    "authors": [
      "Lindsey S. Wiser",
      "Taylor J. Bell",
      "Michael R. Line",
      "Everett Schlawin",
      "Thomas G. Beatty",
      "Luis Welbanks",
      "Thomas P. Greene",
      "Vivien Parmentier",
      "Matthew M. Murphy",
      "Jonathan J. Fortney",
      "Kenny Arnold",
      "Nishil Mehta",
      "Kazumasa Ohno",
      "Sagnick Mukherjee"
    ],
    "abstract": "WASP-80 b, a warm sub-Jovian (equilibrium temperature ~820 K, 0.5 Jupiter\nmasses), presents an opportunity to characterize a rare gas giant exoplanet\naround a low-mass star. In addition, its moderate temperature enables its\natmosphere to host a range of carbon and oxygen species (H$_2$O, CH$_4$, CO,\nCO$_2$, NH$_3$). In this paper, we present a panchromatic emission spectrum of\nWASP-80 b, the first gas giant around a late K/early M-dwarf star and the\ncoolest planet for which the James Webb Space Telescope has obtained a complete\nemission spectrum spanning 2.4-12 $\\mu$m, including NIRCam F322W2 (2.4-4\n$\\mu$m) and F444W (4-5 $\\mu$m), and MIRI LRS (5-12 $\\mu$m). We report confident\ndetections of H$_2$O, CH$_4$, CO, and CO$_2$, and a tentative detection of\nNH$_3$. We estimate WASP-80 b's atmospheric metallicity and carbon-to-oxygen\nratio and compare them with estimates for other gas giants. Despite the\nrelative rarity of giant planets around low-mass stars, we find that WASP-80\nb's composition is consistent with other hot gas giants, suggesting that the\nformation pathway of WASP-80 b may not be dissimilar from hot gas giants around\nhigher-mass stars.",
    "pdf_url": "http://arxiv.org/pdf/2506.01800v1",
    "published": "2025-06-02T15:41:33+00:00",
    "categories": [
      "astro-ph.EP"
    ],
    "primary_category": "astro-ph.EP"
  },
  {
    "id": "http://arxiv.org/abs/2506.01799v1",
    "title": "WorldExplorer: Towards Generating Fully Navigable 3D Scenes",
    "authors": [
      "Manuel-Andreas Schneider",
      "Lukas Höllein",
      "Matthias Nießner"
    ],
    "abstract": "Generating 3D worlds from text is a highly anticipated goal in computer\nvision. Existing works are limited by the degree of exploration they allow\ninside of a scene, i.e., produce streched-out and noisy artifacts when moving\nbeyond central or panoramic perspectives. To this end, we propose\nWorldExplorer, a novel method based on autoregressive video trajectory\ngeneration, which builds fully navigable 3D scenes with consistent visual\nquality across a wide range of viewpoints. We initialize our scenes by creating\nmulti-view consistent images corresponding to a 360 degree panorama. Then, we\nexpand it by leveraging video diffusion models in an iterative scene generation\npipeline. Concretely, we generate multiple videos along short, pre-defined\ntrajectories, that explore the scene in depth, including motion around objects.\nOur novel scene memory conditions each video on the most relevant prior views,\nwhile a collision-detection mechanism prevents degenerate results, like moving\ninto objects. Finally, we fuse all generated views into a unified 3D\nrepresentation via 3D Gaussian Splatting optimization. Compared to prior\napproaches, WorldExplorer produces high-quality scenes that remain stable under\nlarge camera motion, enabling for the first time realistic and unrestricted\nexploration. We believe this marks a significant step toward generating\nimmersive and truly explorable virtual 3D environments.",
    "pdf_url": "http://arxiv.org/pdf/2506.01799v1",
    "published": "2025-06-02T15:41:31+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.01798v4",
    "title": "Shape and ionization of equatorial matter near compact objects from X-ray polarization reflection signatures",
    "authors": [
      "J. Podgorný"
    ],
    "abstract": "Motivated by the success of the IXPE mission, we elucidate what can be\ninferred about 3D matter structures forming about the equatorial plane of\naccreting compact objects from 0.1-100 keV linear polarization induced by\nnon-relativistic large-scale reflection. We construct a model of an optically\nthick elevated axially symmetric reflecting medium with arbitrary ionization\nprofile, representing the known diverse scattering environments: from thick\nwinds and super-Eddington funnel structures formed around black holes and\nneutron stars, to Compton-thick dusty tori of active galactic nuclei and their\nbroad line regions. We assume a central X-ray power-law source with an\nisotropic, cosine, and slab-corona emission distribution, including intrinsic\npolarization. The reprocessing is based on constant-density local reflection\ntables produced with a Monte Carlo method combined with detailed non-LTE\nradiative transfer, although we also show examples with classical\n(semi-)analytical reflection prescriptions. We conclude that varying ionization\nhas a similarly strong impact on observed polarization as the observer's\ninclination and the skew and opening angle of the reflector's inner walls,\naltogether producing up to tens of % of reflected polarization both parallelly\nor perpendicularly to the projected axis, depending on the parameter values\ncombination. After testing 3 different ad-hoc shapes of the reflector: a cone,\nan elliptical torus, and a bowl, we conclude that while in some configurations,\ntheir altered curvature produces more than 30% absolute difference in observed\ntotal polarization, in others, the adopted shape has a marginal impact. Lastly,\nwe discuss the change of the observed polarization due to relaxing the\noptically thick assumption on equatorial winds and accreted matter, providing a\ncontinuous range of energy-dependent examples between the optically thick and\nthin scenarios.",
    "pdf_url": "http://arxiv.org/pdf/2506.01798v4",
    "published": "2025-06-02T15:39:36+00:00",
    "categories": [
      "astro-ph.HE"
    ],
    "primary_category": "astro-ph.HE"
  },
  {
    "id": "http://arxiv.org/abs/2506.01797v1",
    "title": "Superconducting diode effect in a meso-wedge geometry with Abrikosov vortices",
    "authors": [
      "C. A. Aguirre",
      "J. Barba-Ortega",
      "A. S. de Arruda",
      "J. Faundez"
    ],
    "abstract": "In this study, we explore the behavior of a superconducting meso-wedge\ngeometry in 3+1 dimensions (three spatial dimensions plus time) subjected to\nexternal transport currents at its boundaries and surfaces, as well as external\nfields applied along the $\\hat{z}$-direction. The transport currents are\nincluded as two opposite polarities, $\\textbf{J}>0$ and $\\textbf{J}<0$. Using\nthe generalized time-dependent Ginzburg-Landau theory and considering the order\nparameter $\\kappa$, we focus on two scenarios: a fixed external magnetic field\nwith variable $\\kappa$, and fixed $\\kappa$ with variable external magnetic\nfield. As a result, under both scenarios, we analyze the voltage-current\ncharacteristics of the superconducting meso-wedge, finding that the critical\ncurrents differ between polarities, demonstrating the system's non-reciprocity.\nWe further examine the efficiency of the diode as a function of $\\kappa$ and\nthe external magnetic field applied. Furthermore, our observations reveal that\nthe current polarity strongly influences the vortex configuration, the\nparameter $\\kappa$, and the applied magnetic field. In particular, the\nformation of Abrikosov-type vortices exhibits pronounced inhomogeneity\ndepending on the direction of the transport currents. This underscores that the\ndiode effect in the superconducting meso-wedge is intimately associated with\nthe anisotropic nucleation of Abrikosov vortices. Notably, the emergence of\npolarity-dependent vortex patterns can serve as a distinctive hallmark of the\ndiode effect in these superconducting systems.",
    "pdf_url": "http://arxiv.org/pdf/2506.01797v1",
    "published": "2025-06-02T15:38:11+00:00",
    "categories": [
      "cond-mat.supr-con"
    ],
    "primary_category": "cond-mat.supr-con"
  },
  {
    "id": "http://arxiv.org/abs/2506.01796v1",
    "title": "Read it in Two Steps: Translating Extremely Low-Resource Languages with Code-Augmented Grammar Books",
    "authors": [
      "Chen Zhang",
      "Jiuheng Lin",
      "Xiao Liu",
      "Zekai Zhang",
      "Yansong Feng"
    ],
    "abstract": "While large language models (LLMs) have shown promise in translating\nextremely low-resource languages using resources like dictionaries, the\neffectiveness of grammar books remains debated. This paper investigates the\nrole of grammar books in translating extremely low-resource languages by\ndecomposing it into two key steps: grammar rule retrieval and application. To\nfacilitate the study, we introduce ZhuangRules, a modularized dataset of\ngrammar rules and their corresponding test sentences. Our analysis reveals that\nrule retrieval constitutes a primary bottleneck in grammar-based translation.\nMoreover, although LLMs can apply simple rules for translation when explicitly\nprovided, they encounter difficulties in handling more complex rules. To\naddress these challenges, we propose representing grammar rules as code\nfunctions, considering their similarities in structure and the benefit of code\nin facilitating LLM reasoning. Our experiments show that using code rules\nsignificantly boosts both rule retrieval and application, ultimately resulting\nin a 13.1% BLEU improvement in translation.",
    "pdf_url": "http://arxiv.org/pdf/2506.01796v1",
    "published": "2025-06-02T15:36:37+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.01795v1",
    "title": "R2SM: Referring and Reasoning for Selective Masks",
    "authors": [
      "Yu-Lin Shih",
      "Wei-En Tai",
      "Cheng Sun",
      "Yu-Chiang Frank Wang",
      "Hwann-Tzong Chen"
    ],
    "abstract": "We introduce a new task, Referring and Reasoning for Selective Masks (R2SM),\nwhich extends text-guided segmentation by incorporating mask-type selection\ndriven by user intent. This task challenges vision-language models to determine\nwhether to generate a modal (visible) or amodal (complete) segmentation mask\nbased solely on natural language prompts. To support the R2SM task, we present\nthe R2SM dataset, constructed by augmenting annotations of COCOA-cls, D2SA, and\nMUVA. The R2SM dataset consists of both modal and amodal text queries, each\npaired with the corresponding ground-truth mask, enabling model finetuning and\nevaluation for the ability to segment images as per user intent. Specifically,\nthe task requires the model to interpret whether a given prompt refers to only\nthe visible part of an object or to its complete shape, including occluded\nregions, and then produce the appropriate segmentation. For example, if a\nprompt explicitly requests the whole shape of a partially hidden object, the\nmodel is expected to output an amodal mask that completes the occluded parts.\nIn contrast, prompts without explicit mention of hidden regions should generate\nstandard modal masks. The R2SM benchmark provides a challenging and insightful\ntestbed for advancing research in multimodal reasoning and intent-aware\nsegmentation.",
    "pdf_url": "http://arxiv.org/pdf/2506.01795v1",
    "published": "2025-06-02T15:36:31+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.01794v2",
    "title": "Consideraciones para una formulacion termodinamica neo-gibbsiana aplicada a sistemas sociales",
    "authors": [
      "Victor Alcides Guzman Rodriguez",
      "Esneiber Hibraim Solano Herrera"
    ],
    "abstract": "This work proposes a first approach towards a neo-Gibbsian thermodynamic\ntheory for social systems, grounded in quantifiable economic and cultural\nparameters, while deliberately avoiding direct analogies with classical\nthermodynamic equations of state. Building on previous thermodynamic approaches\nto economic modeling, we introduce a conceptual basis for defining intensive\nvariables capable of characterizing equilibrium states and evolutionary\ndynamics in societies. Particular attention is given to cultural and structural\ndiversification of goods and resources, as well as to the phenomenon of\nmulti-currency systems. A non-decreasing function $S$ is defined over all\nsocial processes to represent the accumulation of laws, norms, and other\nquantifiable symbolic elements. Finally, we examine its interpretation in terms\nof thermodynamic forces, focusing on the case of equilibrium between two simple\ninteracting social systems exchanging resources.",
    "pdf_url": "http://arxiv.org/pdf/2506.01794v2",
    "published": "2025-06-02T15:35:29+00:00",
    "categories": [
      "physics.soc-ph"
    ],
    "primary_category": "physics.soc-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.01793v1",
    "title": "Human-Centric Evaluation for Foundation Models",
    "authors": [
      "Yijin Guo",
      "Kaiyuan Ji",
      "Xiaorong Zhu",
      "Junying Wang",
      "Farong Wen",
      "Chunyi Li",
      "Zicheng Zhang",
      "Guangtao Zhai"
    ],
    "abstract": "Currently, nearly all evaluations of foundation models focus on objective\nmetrics, emphasizing quiz performance to define model capabilities. While this\nmodel-centric approach enables rapid performance assessment, it fails to\nreflect authentic human experiences. To address this gap, we propose a\nHuman-Centric subjective Evaluation (HCE) framework, focusing on three core\ndimensions: problem-solving ability, information quality, and interaction\nexperience. Through experiments involving Deepseek R1, OpenAI o3 mini, Grok 3,\nand Gemini 2.5, we conduct over 540 participant-driven evaluations, where\nhumans and models collaborate on open-ended research tasks, yielding a\ncomprehensive subjective dataset. This dataset captures diverse user feedback\nacross multiple disciplines, revealing distinct model strengths and\nadaptability. Our findings highlight Grok 3's superior performance, followed by\nDeepseek R1 and Gemini 2.5, with OpenAI o3 mini lagging behind. By offering a\nnovel framework and a rich dataset, this study not only enhances subjective\nevaluation methodologies but also lays the foundation for standardized,\nautomated assessments, advancing LLM development for research and practical\nscenarios. Our dataset link is\nhttps://github.com/yijinguo/Human-Centric-Evaluation.",
    "pdf_url": "http://arxiv.org/pdf/2506.01793v1",
    "published": "2025-06-02T15:33:29+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.01792v1",
    "title": "Comment on \"Neutron diffraction evidence of the 3-dimensional structure of Ba2MnTeO6 and misidentification of the triangular layers within the face-centred cubic lattice\"",
    "authors": [
      "J. Khatua",
      "T. Arh",
      "Shashi B. Mishra",
      "H. Luetkens",
      "A. Zorko",
      "B. Sana",
      "M. S. Ramachandra Rao",
      "B. R. K. Nanda",
      "P. Khuntia"
    ],
    "abstract": "Frustrated magnetism continues to attract significant attention due to its\npotential to host novel quantum many-body phenomena and associated exotic\nexcitations that transcend existing paradigms. Herein, we present our reply to\nthe comment on our recent thermodynamic and muon spin relaxation studies on a\nfrustrated double perovskite, Ba2MnTeO6 (henceforth BMTO). Previous studies by\nfour independent groups, including our group, suggested a trigonal space group\nbased on single-crystal and polycrystalline samples of BMTO, while the recent\ncomment reports a cubic space group based on polycrystalline samples. We\nbelieve that the structure is fairly intricate because of the slight variations\nbetween the two space groups, refining the crystal structure of BMTO remains an\nunresolved problem that needs additional high-resolution XRD and neutron\ndiffraction studies on high-quality single crystals. It is thought, however,\nthat structural assignments will not greatly influence any of the primary\nfindings related to the magnetism and spin dynamics of BMTO. These consist of a\nmagnetic phase transition at around 21 K, the observation of antiferromagnetic\nmagnon excitations exhibiting a gap of 1.4 K beneath the phase transition, the\npresence of short-range spin correlations well above the antiferromagnetic\nphase transition, and the persistence of spin dynamics even within the\nmagnetically ordered phase. It is important to note that the magnetization,\nspecific heat, and muon spin relaxation findings that constitute the core of\nour earlier study are independent; the interpretation of these findings did not\nrely on any specific space group. Concerning the final allocation of the\nsymmetry of BMTO, a definitive differentiation in certain physical\ncharacteristics resulting from the symmetry is still necessary.",
    "pdf_url": "http://arxiv.org/pdf/2506.01792v1",
    "published": "2025-06-02T15:33:25+00:00",
    "categories": [
      "cond-mat.str-el",
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.str-el"
  },
  {
    "id": "http://arxiv.org/abs/2506.01791v2",
    "title": "Tight Convergence Rates in Gradient Mapping for the Difference-of-Convex Algorithm",
    "authors": [
      "Teodor Rotaru",
      "Panagiotis Patrinos",
      "François Glineur"
    ],
    "abstract": "We establish new theoretical convergence guarantees for the\ndifference-of-convex algorithm (DCA), where the second function is allowed to\nbe weakly-convex, measuring progress via composite gradient mapping. Based on a\ntight analysis of two iterations of DCA, we identify six parameter regimes\nleading to sublinear convergence rates toward critical points and establish\nthose rates by proving adapted descent lemmas. We recover existing rates for\nthe standard difference-of-convex decompositions of nonconvex-nonconcave\nfunctions, while for all other curvature settings our results are new,\ncomplementing recently obtained rates on the gradient residual. Three of our\nsublinear rates are tight for any number of DCA iterations, while for the other\nthree regimes we conjecture exact rates, using insights from the tight analysis\nof gradient descent and numerical validation using the performance estimation\nmethodology. Finally, we show how the equivalence between proximal gradient\ndescent (PGD) and DCA allows the derivation of exact PGD rates for any constant\nstepsize.",
    "pdf_url": "http://arxiv.org/pdf/2506.01791v2",
    "published": "2025-06-02T15:32:43+00:00",
    "categories": [
      "math.OC",
      "cs.NA",
      "math.NA"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2506.01790v2",
    "title": "IF-GUIDE: Influence Function-Guided Detoxification of LLMs",
    "authors": [
      "Zachary Coalson",
      "Juhan Bae",
      "Nicholas Carlini",
      "Sanghyun Hong"
    ],
    "abstract": "We study how training data contributes to the emergence of toxic behaviors in\nlarge-language models. Most prior work on reducing model toxicity adopts\n$reactive$ approaches, such as fine-tuning pre-trained (and potentially toxic)\nmodels to align them with human values. In contrast, we propose a $proactive$\napproach$-$IF-Guide$-$which leverages influence functions to identify harmful\ntokens within any training data and suppress their impact during training. To\nthis end, we first show that standard influence functions are ineffective at\ndiscovering harmful training records. We then present a novel adaptation that\nmeasures token-level attributions from training data to model toxicity, along\nwith techniques for selecting toxic training documents and a learning objective\nthat can be integrated into both pre-training and fine-tuning. Moreover,\nIF-Guide does not rely on human-preference data, which is typically required by\nexisting alignment methods. In evaluation, we demonstrate that IF-Guide\nsubstantially reduces both explicit and implicit toxicity$-$by up to 10$\\times$\ncompared to uncensored models, and up to 3$\\times$ compared to baseline\nalignment methods, e.g., DPO and RAD$-$across both pre-training and fine-tuning\nscenarios. IF-Guide is computationally efficient: a billion-parameter model is\n$not$ $necessary$ for computing influence scores; a million-parameter\nmodel$-$with 7.5$\\times$ fewer parameters$-$can effectively serve as a proxy\nfor identifying harmful data. Our code is publicly available at:\nhttps://github.com/ztcoalson/IF-Guide",
    "pdf_url": "http://arxiv.org/pdf/2506.01790v2",
    "published": "2025-06-02T15:32:36+00:00",
    "categories": [
      "cs.LG",
      "cs.CR"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.01789v2",
    "title": "Datasheets Aren't Enough: DataRubrics for Automated Quality Metrics and Accountability",
    "authors": [
      "Genta Indra Winata",
      "David Anugraha",
      "Emmy Liu",
      "Alham Fikri Aji",
      "Shou-Yi Hung",
      "Aditya Parashar",
      "Patrick Amadeus Irawan",
      "Ruochen Zhang",
      "Zheng-Xin Yong",
      "Jan Christian Blaise Cruz",
      "Niklas Muennighoff",
      "Seungone Kim",
      "Hanyang Zhao",
      "Sudipta Kar",
      "Kezia Erina Suryoraharjo",
      "M. Farid Adilazuarda",
      "En-Shiun Annie Lee",
      "Ayu Purwarianti",
      "Derry Tanti Wijaya",
      "Monojit Choudhury"
    ],
    "abstract": "High-quality datasets are fundamental to training and evaluating machine\nlearning models, yet their creation-especially with accurate human\nannotations-remains a significant challenge. Many dataset paper submissions\nlack originality, diversity, or rigorous quality control, and these\nshortcomings are often overlooked during peer review. Submissions also\nfrequently omit essential details about dataset construction and properties.\nWhile existing tools such as datasheets aim to promote transparency, they are\nlargely descriptive and do not provide standardized, measurable methods for\nevaluating data quality. Similarly, metadata requirements at conferences\npromote accountability but are inconsistently enforced. To address these\nlimitations, this position paper advocates for the integration of systematic,\nrubric-based evaluation metrics into the dataset review process-particularly as\nsubmission volumes continue to grow. We also explore scalable, cost-effective\nmethods for synthetic data generation, including dedicated tools and\nLLM-as-a-judge approaches, to support more efficient evaluation. As a call to\naction, we introduce DataRubrics, a structured framework for assessing the\nquality of both human- and model-generated datasets. Leveraging recent advances\nin LLM-based evaluation, DataRubrics offers a reproducible, scalable, and\nactionable solution for dataset quality assessment, enabling both authors and\nreviewers to uphold higher standards in data-centric research. We also release\ncode to support reproducibility of LLM-based evaluations at\nhttps://github.com/datarubrics/datarubrics.",
    "pdf_url": "http://arxiv.org/pdf/2506.01789v2",
    "published": "2025-06-02T15:31:52+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CV",
      "eess.AS"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.01788v3",
    "title": "Superconducting gap structure and bosonic mode in La2PrNi2O7 thin films at ambient pressure",
    "authors": [
      "Shengtai Fan",
      "Mengjun Ou",
      "Marius Scholten",
      "Qing Li",
      "Zhiyuan Shang",
      "Yi Wang",
      "Jiasen Xu",
      "Huan Yang",
      "Ilya M. Eremin",
      "Hai-Hu Wen"
    ],
    "abstract": "The recent discovery of high temperature superconductivity in nickelate\nsystems has generated tremendous interests in the field of superconductivity.\nThe core issue to understand the superconductivity mechanism is about the\nsuperconducting gap and its symmetry. By using the substrate of SrLaAlO4(00l),\nwe have successfully synthesized the superconducting thin film of La2PrNi2O7\nwith Tc(onset) = 41.5 K. Superconducting tunneling spectra are successfully\nmeasured on the terraces after we expose the superconducting layer by using the\ntip-excavation technique. The spectrum shows a two-gap structure with Delta1=19\nmeV, Delta2=6-8 meV, and fittings based on the Dynes model indicate that the\ndominant gap should have an anisotropic s-wave structure, this allows us to put\nthe priority in selecting the s+- among the two arguable pairing models: s+-\nand d-wave. Furthermore, a clear bosonic mode with energy Omega=30+-2 meV is\nobserved, which further supports a sign reversal gap. Our results shed new\nlight in understanding the mystery of superconductivity in bilayer nickelate\nsuperconductors.",
    "pdf_url": "http://arxiv.org/pdf/2506.01788v3",
    "published": "2025-06-02T15:31:51+00:00",
    "categories": [
      "cond-mat.supr-con",
      "cond-mat.str-el"
    ],
    "primary_category": "cond-mat.supr-con"
  },
  {
    "id": "http://arxiv.org/abs/2506.01787v1",
    "title": "Branch lengths for geodesics in the directed landscape and mutation patterns in growing spatially structured populations",
    "authors": [
      "Shirshendu Ganguly",
      "Jason Schweinsberg",
      "Yubo Shuai"
    ],
    "abstract": "Consider a population that is expanding in two-dimensional space. Suppose we\ncollect data from a sample of individuals taken at random either from the\nentire population, or from near the outer boundary of the population. A\nquantity of interest in population genetics is the site frequency spectrum,\nwhich is the number of mutations that appear on $k$ of the $n$ sampled\nindividuals, for $k = 1, \\dots, n-1$. As long as the mutation rate is constant,\nthis number will be roughly proportional to the total length of all branches in\nthe genealogical tree that are on the ancestral line of $k$ sampled\nindividuals. While the rigorous literature has primarily focused on models\nwithout any spatial structure, in many natural settings, such as tumors or\nbacteria colonies, growth is dictated by spatial constraints. A large number of\nsuch two dimensional growth models are expected to fall in the KPZ universality\nclass exhibiting similar features as the Kardar-Parisi-Zhang equation.\n  In this article we adopt the perspective that for population models in the\nKPZ universality class, the genealogical tree can be approximated by the tree\nformed by the infinite upward geodesics in the directed landscape, a universal\nscaling limit constructed in \\cite{dov22}, starting from $n$ randomly chosen\npoints. Relying on geodesic coalescence, we prove new asymptotic results for\nthe lengths of the portions of these geodesics that are ancestral to $k$ of the\n$n$ sampled points and consequently obtain exponents driving the site frequency\nspectrum as predicted in \\cite{fgkah16}. An important ingredient in the proof\nis a new tight estimate of the probability that three infinite upward geodesics\nstay disjoint up to time $t$, i.e., a sharp quantitative version of the well\nstudied N3G problem, which is of independent interest.",
    "pdf_url": "http://arxiv.org/pdf/2506.01787v1",
    "published": "2025-06-02T15:31:05+00:00",
    "categories": [
      "math.PR",
      "q-bio.PE",
      "60K35, 60J90, 92D25, 60J65"
    ],
    "primary_category": "math.PR"
  },
  {
    "id": "http://arxiv.org/abs/2506.01786v2",
    "title": "Science Prospects for the Southern Wide-field Gamma-ray Observatory: SWGO",
    "authors": [
      "SWGO Collaboration",
      "P. Abreu",
      "R. Alfaro",
      "A. Alfonso",
      "M. Andrade",
      "E. O. Angüner",
      "E. A. Anita-Rangel",
      "O. Aquines-Gutiérrez",
      "C. Arcaro",
      "R. Arceo",
      "J. C. Arteaga-Velázquez",
      "P. Assis",
      "H. A. Ayala Solares",
      "A. Bakalova",
      "E. M. Bandeira",
      "P. Bangale",
      "U. Barres de Almeida",
      "P. Batista",
      "I. Batković",
      "J. Bazo",
      "E. Belmont",
      "J. Bennemann",
      "S. Y. BenZvi",
      "A. Bernal",
      "W. Bian",
      "C. Bigongiari",
      "E. Bottacini",
      "R. Branada",
      "P. Brogueira",
      "A. M. Brown",
      "T. Bulik",
      "K. S. Caballero-Mora",
      "P. Camarri",
      "W. Cao",
      "Z. Cao",
      "Z. Cao",
      "T. Capistrán",
      "M. Cardillo",
      "C. Casentini",
      "C. Castromonte",
      "P. M. Chadwick",
      "J. Chanamé",
      "J. Chang",
      "S. Chen",
      "A. Chiavassa",
      "L. Chytka",
      "R. Colalillo",
      "R. Conceição",
      "G. Consolati",
      "R. Cordero",
      "P. J. Costa",
      "R. Covarelli",
      "X. Cui",
      "X. Cui",
      "A. De Angelis",
      "E. de Gouveia Dal Pino",
      "R. de Menezes",
      "P. Desiati",
      "N. Di Lalla",
      "F. Di Pierro",
      "G. Di Sciascio",
      "J. C. Díaz Vélez",
      "C. Dib",
      "B. Dingus",
      "J. Djuvsland",
      "C. Dobrigkeit",
      "L. M. Domingues Mendes",
      "T. Dorigo",
      "M. Doro",
      "A. C. dos Reis",
      "M. Du Vernois",
      "D. Elsaesser",
      "K. Engel",
      "T. Ergin",
      "M. Errando",
      "K. Fang",
      "A. Fazzi",
      "C. Feng",
      "M. Feroci",
      "C. N. Ferreira",
      "N. Fraija",
      "S. Fraija",
      "A. Franceschini",
      "G. F. Franco",
      "S. Funk",
      "R. Galleguillos",
      "B. Gao",
      "C. Gao",
      "A. M. Garcia Reyes",
      "S. Garcia",
      "F. Garfias",
      "G. Giacinti",
      "L. Gibilisco",
      "B. Giovanni",
      "J. Glombitza",
      "H. Goksu",
      "G. Gong",
      "B. S. González",
      "M. M. González",
      "J. Goodman",
      "V. M. Grieco",
      "M. Gu",
      "F. Guarino",
      "G. P. Guedes",
      "J. Gyeong",
      "F. Haist",
      "G. Han",
      "P. Hansen",
      "J. P. Harding",
      "S. Hernandez Cadena",
      "I. Herzog",
      "J. Hinton",
      "W. Hofmann",
      "C. Hou",
      "Hou C.",
      "K. Hu",
      "D. Huang",
      "P. Huentemeyer",
      "A. Iriarte",
      "J. Isaković",
      "A. Jardin-Blicq",
      "L. I. Junoy",
      "J. Juryšek",
      "S. Kaci",
      "B. Khelifi",
      "D. Kieda",
      "F. La Monaca",
      "G. La Mura",
      "R. G. Lang",
      "J. S. Lapington",
      "R. Laspiur",
      "L. Lavitola",
      "J. Lee",
      "F. Leitl",
      "M. Lemoine-Goumard",
      "L. Lessio",
      "T. Lewis",
      "C. Li",
      "J. Li",
      "K. Li",
      "T. Li",
      "B. Liberti",
      "S. Lin",
      "R. A. Lineros",
      "D. Liu",
      "J. Liu",
      "R. Liu",
      "F. Longo",
      "Y. Luo",
      "J. Lv",
      "E. Macerata",
      "G. Magugliani",
      "K. Malone",
      "A. Mancilla",
      "D. Mandat",
      "M. Manganaro",
      "M. Mariani",
      "A. Mariazzi",
      "M. Mariotti",
      "T. Marrodan",
      "H. Martínez-Huerta",
      "I. Martins",
      "S. Medina",
      "D. Melo",
      "L. F. Mendes",
      "E. Meza",
      "R. Micali",
      "D. Miceli",
      "S. Miozzi",
      "L. S. Miranda",
      "P. E. Mirón Enriquez",
      "A. Mitchell",
      "A. Molinario",
      "A. Montero",
      "O. G. Morales-Olivares",
      "A. Morselli",
      "E. Mossini",
      "M. Mostafá",
      "F. Muleri",
      "F. Nardi",
      "A. P. Nayak",
      "A. Negro",
      "L. Nellen",
      "M. Nisa",
      "V. Novotny",
      "L. Olivera-Nieto",
      "N. Omodei",
      "E. Orlando",
      "S. Ortolani",
      "M. Osorio-Archila",
      "T. Ota",
      "L. Otiniano",
      "Z. Ou",
      "A. Paoloni",
      "I. M. Pepe",
      "R. Perca",
      "M. Peresano",
      "Y. Pérez Araujo",
      "T. Petrosillo-Lago",
      "G. Piano",
      "D. Piccolo",
      "A. Pichel",
      "M. Pimenta",
      "M. Pirke",
      "A. Porcelli",
      "T. Porter",
      "E. Prandini",
      "A. Pratts",
      "R. Pretsch",
      "A. Qi",
      "J. Qin",
      "S. Rainò",
      "L. Recabarren",
      "M. Regeard",
      "A. Reisenegger",
      "Q. Remy",
      "H. X. Ren",
      "F. Rescic",
      "B. Reville",
      "M. Reyes",
      "C. D. Rho",
      "M. Riquelme",
      "J. I. Rivadeneira",
      "G. Rodriguez Fernandez",
      "B. Rossi",
      "A. C. Rovero",
      "A. Ruina",
      "E. Ruiz-Velasco",
      "G. Salazar",
      "C. Salotto",
      "F. Sanchez",
      "A. Sandoval",
      "F. Sansone",
      "M. Santander",
      "R. Santonico",
      "G. L. P. Santos",
      "A. Santos-Guevara",
      "D. Sartirana",
      "M. Schneider",
      "M. Schneider",
      "H. Schoorlemmer",
      "F. G. Schröder",
      "F. Schussler",
      "H. Schutte",
      "J. Serna-Franco",
      "M. Shoaib",
      "A. Smith",
      "A. J. Smith",
      "Y. Son",
      "O. Soto",
      "S. T. Spencer",
      "R. W. Springer",
      "J. Stewart",
      "L. A. Stuani",
      "H. Sun",
      "M. Tambone",
      "R. Tang",
      "Z. Tang",
      "S. Tapia",
      "M. Tavani",
      "R. Terrier",
      "T. Terzić",
      "K. Tollefson",
      "B. Tomé",
      "I. Torres",
      "R. Torres-Escobedo",
      "G. C. Trinchero",
      "R. Turner",
      "P. Ulloa",
      "L. Valore",
      "C. van Eldik",
      "J. Vega",
      "I. D. Vergara Quispe",
      "A. Viana",
      "J. Vícha",
      "C. F. Vigorito",
      "V. Vittorini",
      "B. Wang",
      "L. Wang",
      "X. Wang",
      "X. Wang",
      "X. Wang",
      "Z. Wang",
      "Z. Wang",
      "M. Waqas",
      "I. J. Watson",
      "F. Werner",
      "R. White",
      "C. Wiebusch",
      "F. Wohlleben",
      "S. Xi",
      "G. Xiao",
      "H. Xiao",
      "H. Xiao",
      "L. Yang",
      "R. Yang",
      "Z. Yang",
      "Z. Yang",
      "R. Yanyachi",
      "Z. Yao",
      "D. Zavrtanik",
      "H. Zhang",
      "H. Zhang",
      "J. Zhang",
      "J. Zhang",
      "S. Zhang",
      "S. Zhang",
      "X. Zhang",
      "Y. Zhang",
      "Y. Zhang",
      "Y. Zhang",
      "J. Zhao",
      "L. Zhao",
      "H. Zhou",
      "C. Zhu",
      "H. Zhu",
      "H. Zhu",
      "P. Zhu",
      "X. Zuo",
      "P. Zyla"
    ],
    "abstract": "Ground-based gamma-ray astronomy is now well established as a key\nobservational approach to address critical topics at the frontiers of\nastroparticle physics and high-energy astrophysics. Whilst the field of TeV\nastronomy was once dominated by arrays of atmospheric Cherenkov Telescopes,\nground-level particle detection has now been demonstrated to be an equally\nviable and strongly complementary approach. Ground-level particle detection\nprovides continuous monitoring of the overhead sky, critical for the mapping of\nextended structures and capturing transient phenomena. As demonstrated by HAWC\nand LHAASO, the technique provides the best available sensitivity above a few\ntens of TeV, and for the first time access to the PeV energy range. Despite the\nsuccess of this approach, there is so far no major ground-level particle-based\nobservatory with access to the Southern sky. HESS, located in Namibia, is the\nonly major gamma-ray instrument in the Southern Hemisphere, and has shown the\nextraordinary richness of the inner galaxy in the TeV band, but is limited in\nterms of field of view and energy reach.\n  SWGO is an international effort to construct the first wide-field instrument\nin the south with deep sensitivity from 100s of GeV into the PeV domain. The\nproject is now close to the end of its development phase and planning for\nconstruction of the array in Chile has begun. Here we describe the baseline\ndesign, expected sensitivity and resolution, and describe in detail the main\nscientific topics that will be addressed by this new facility and its initial\nphase SWGO-A. We show that SWGO will have a transformational impact on a wide\nrange of topics from cosmic-ray acceleration and transport to the nature of\ndark matter. SWGO represents a key piece of infrastructure for multi-messenger\nastronomy in the next decade, with strong scientific synergies with the nearby\nCTA Observatory.",
    "pdf_url": "http://arxiv.org/pdf/2506.01786v2",
    "published": "2025-06-02T15:30:30+00:00",
    "categories": [
      "astro-ph.HE",
      "astro-ph.IM"
    ],
    "primary_category": "astro-ph.HE"
  },
  {
    "id": "http://arxiv.org/abs/2506.01785v1",
    "title": "Infinite symmetry prevents disorder-induced localization in 2D",
    "authors": [
      "Carlo A. Trugenberger"
    ],
    "abstract": "We show that 2D gapped many-body quantum states are constrained by an\ninfinite-dimensional symmetry which renders them transparent to weak disorder.\nThis prevents disorder-induced localization when interactions are strong enough\nto open a gap. Using purely algebraic methods we derive all possible quantum\nstates near the superconductor-to-insulator (SIT) transition and we compute the\nmeson spectrum of superinsulators.",
    "pdf_url": "http://arxiv.org/pdf/2506.01785v1",
    "published": "2025-06-02T15:30:14+00:00",
    "categories": [
      "cond-mat.supr-con",
      "cond-mat.mtrl-sci",
      "cond-mat.str-el"
    ],
    "primary_category": "cond-mat.supr-con"
  },
  {
    "id": "http://arxiv.org/abs/2506.01784v2",
    "title": "iQUEST: An Iterative Question-Guided Framework for Knowledge Base Question Answering",
    "authors": [
      "Shuai Wang",
      "Yinan Yu"
    ],
    "abstract": "While Large Language Models (LLMs) excel at many natural language processing\ntasks, they often suffer from factual inaccuracies in knowledge-intensive\nscenarios. Integrating external knowledge resources, particularly knowledge\ngraphs (KGs), provides a transparent and updatable foundation for more reliable\nreasoning. Knowledge Base Question Answering (KBQA), which queries and reasons\nover KGs, is central to this effort, especially for complex, multi-hop queries.\nHowever, multi-hop reasoning poses two key challenges: (1)~maintaining coherent\nreasoning paths, and (2)~avoiding prematurely discarding critical multi-hop\nconnections. To address these issues, we introduce iQUEST, a question-guided\nKBQA framework that iteratively decomposes complex queries into simpler\nsub-questions, ensuring a structured and focused reasoning trajectory.\nAdditionally, we integrate a Graph Neural Network (GNN) to look ahead and\nincorporate 2-hop neighbor information at each reasoning step. This dual\napproach strengthens the reasoning process, enabling the model to explore\nviable paths more effectively. Detailed experiments demonstrate the consistent\nimprovement delivered by iQUEST across four benchmark datasets and four LLMs.",
    "pdf_url": "http://arxiv.org/pdf/2506.01784v2",
    "published": "2025-06-02T15:30:02+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.01783v1",
    "title": "FaceCoT: A Benchmark Dataset for Face Anti-Spoofing with Chain-of-Thought Reasoning",
    "authors": [
      "Honglu Zhang",
      "Zhiqin Fang",
      "Ningning Zhao",
      "Saihui Hou",
      "Long Ma",
      "Renwang Pei",
      "Zhaofeng He"
    ],
    "abstract": "Face Anti-Spoofing (FAS) typically depends on a single visual modality when\ndefending against presentation attacks such as print attacks, screen replays,\nand 3D masks, resulting in limited generalization across devices, environments,\nand attack types. Meanwhile, Multimodal Large Language Models (MLLMs) have\nrecently achieved breakthroughs in image-text understanding and semantic\nreasoning, suggesting that integrating visual and linguistic co-inference into\nFAS can substantially improve both robustness and interpretability. However,\nthe lack of a high-quality vision-language multimodal dataset has been a\ncritical bottleneck. To address this, we introduce FaceCoT (Face\nChain-of-Thought), the first large-scale Visual Question Answering (VQA)\ndataset tailored for FAS. FaceCoT covers 14 spoofing attack types and enriches\nmodel learning with high-quality CoT VQA annotations. Meanwhile, we develop a\ncaption model refined via reinforcement learning to expand the dataset and\nenhance annotation quality. Furthermore, we introduce a CoT-Enhanced\nProgressive Learning (CEPL) strategy to better leverage the CoT data and boost\nmodel performance on FAS tasks. Extensive experiments demonstrate that models\ntrained with FaceCoT and CEPL outperform state-of-the-art methods on multiple\nbenchmark datasets.",
    "pdf_url": "http://arxiv.org/pdf/2506.01783v1",
    "published": "2025-06-02T15:29:41+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.01782v1",
    "title": "Systematic Hazard Analysis for Frontier AI using STPA",
    "authors": [
      "Simon Mylius"
    ],
    "abstract": "All of the frontier AI companies have published safety frameworks where they\ndefine capability thresholds and risk mitigations that determine how they will\nsafely develop and deploy their models. Adoption of systematic approaches to\nrisk modelling, based on established practices used in safety-critical\nindustries, has been recommended, however frontier AI companies currently do\nnot describe in detail any structured approach to identifying and analysing\nhazards. STPA (Systems-Theoretic Process Analysis) is a systematic methodology\nfor identifying how complex systems can become unsafe, leading to hazards. It\nachieves this by mapping out controllers and controlled processes then\nanalysing their interactions and feedback loops to understand how harmful\noutcomes could occur (Leveson & Thomas, 2018). We evaluate STPA's ability to\nbroaden the scope, improve traceability and strengthen the robustness of safety\nassurance for frontier AI systems. Applying STPA to the threat model and\nscenario described in 'A Sketch of an AI Control Safety Case' (Korbak et al.,\n2025), we derive a list of Unsafe Control Actions. From these we select a\nsubset and explore the Loss Scenarios that lead to them if left unmitigated. We\nfind that STPA is able to identify causal factors that may be missed by\nunstructured hazard analysis methodologies thereby improving robustness. We\nsuggest STPA could increase the safety assurance of frontier AI when used to\ncomplement or check coverage of existing AI governance techniques including\ncapability thresholds, model evaluations and emergency procedures. The\napplication of a systematic methodology supports scalability by increasing the\nproportion of the analysis that could be conducted by LLMs, reducing the burden\non human domain experts.",
    "pdf_url": "http://arxiv.org/pdf/2506.01782v1",
    "published": "2025-06-02T15:28:34+00:00",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.CY"
  },
  {
    "id": "http://arxiv.org/abs/2506.01781v1",
    "title": "Enhancing Customer Service Chatbots with Context-Aware NLU through Selective Attention and Multi-task Learning",
    "authors": [
      "Subhadip Nandi",
      "Neeraj Agrawal",
      "Anshika Singh",
      "Priyanka Bhatt"
    ],
    "abstract": "Customer service chatbots are conversational systems aimed at addressing\ncustomer queries, often by directing them to automated workflows. A crucial\naspect of this process is the classification of the customer's intent.\nPresently, most intent classification models for customer care utilise only\ncustomer query for intent prediction. This may result in low-accuracy models,\nwhich cannot handle ambiguous queries. An ambiguous query like \"I didn't\nreceive my package\" could indicate a delayed order, or an order that was\ndelivered but the customer failed to receive it. Resolution of each of these\nscenarios requires the execution of very different sequence of steps. Utilizing\nadditional information, such as the customer's order delivery status, in the\nright manner can help identify the intent for such ambiguous queries. In this\npaper, we have introduced a context-aware NLU model that incorporates both, the\ncustomer query and contextual information from the customer's order status for\npredicting customer intent. A novel selective attention module is used to\nextract relevant context features. We have also proposed a multi-task learning\nparadigm for the effective utilization of different label types available in\nour training data. Our suggested method, Multi-Task Learning Contextual NLU\nwith Selective Attention Weighted Context (MTL-CNLU-SAWC), yields a 4.8%\nincrease in top 2 accuracy score over the baseline model which only uses user\nqueries, and a 3.5% improvement over existing state-of-the-art models that\ncombine query and context. We have deployed our model to production for\nWalmart's customer care domain. Accurate intent prediction through\nMTL-CNLU-SAWC helps to better direct customers to automated workflows, thereby\nsignificantly reducing escalations to human agents, leading to almost a million\ndollars in yearly savings for the company.",
    "pdf_url": "http://arxiv.org/pdf/2506.01781v1",
    "published": "2025-06-02T15:24:28+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.01780v1",
    "title": "Federated Gaussian Mixture Models",
    "authors": [
      "Sophia Zhang Pettersson",
      "Kuo-Yun Liang",
      "Juan Carlos Andresen"
    ],
    "abstract": "This paper introduces FedGenGMM, a novel one-shot federated learning approach\nfor Gaussian Mixture Models (GMM) tailored for unsupervised learning scenarios.\nIn federated learning (FL), where multiple decentralized clients\ncollaboratively train models without sharing raw data, significant challenges\ninclude statistical heterogeneity, high communication costs, and privacy\nconcerns. FedGenGMM addresses these issues by allowing local GMM models,\ntrained independently on client devices, to be aggregated through a single\ncommunication round. This approach leverages the generative property of GMMs,\nenabling the creation of a synthetic dataset on the server side to train a\nglobal model efficiently. Evaluation across diverse datasets covering image,\ntabular, and time series data demonstrates that FedGenGMM consistently achieves\nperformance comparable to non-federated and iterative federated methods, even\nunder significant data heterogeneity. Additionally, FedGenGMM significantly\nreduces communication overhead, maintains robust performance in anomaly\ndetection tasks, and offers flexibility in local model complexities, making it\nparticularly suitable for edge computing environments.",
    "pdf_url": "http://arxiv.org/pdf/2506.01780v1",
    "published": "2025-06-02T15:23:53+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.01779v2",
    "title": "Improved belief propagation is sufficient for real-time decoding of quantum memory",
    "authors": [
      "Tristan Müller",
      "Thomas Alexander",
      "Michael E. Beverland",
      "Markus Bühler",
      "Blake R. Johnson",
      "Thilo Maurer",
      "Drew Vandeth"
    ],
    "abstract": "We introduce a new heuristic decoder, Relay-BP, targeting real-time quantum\ncircuit decoding for large-scale quantum computers. Relay-BP achieves high\naccuracy across circuit-noise decoding problems: significantly outperforming\nBP+OSD+CS-10 for bivariate-bicycle codes and comparable to min-weight-matching\nfor surface codes. As a lightweight message-passing decoder, Relay-BP is\ninherently parallel, enabling rapid low-footprint decoding with FPGA or ASIC\nreal-time implementations, similar to standard BP. A core aspect of our decoder\nis its enhancement of the standard BP algorithm by incorporating disordered\nmemory strengths. This dampens oscillations and breaks symmetries that trap\ntraditional BP algorithms. By dynamically adjusting memory strengths in a relay\napproach, Relay-BP can consecutively encounter multiple valid corrections to\nimprove decoding accuracy. We observe that a problem-dependent distribution of\nmemory strengths that includes negative values is indispensable for good\nperformance.",
    "pdf_url": "http://arxiv.org/pdf/2506.01779v2",
    "published": "2025-06-02T15:23:00+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.01778v1",
    "title": "unMORE: Unsupervised Multi-Object Segmentation via Center-Boundary Reasoning",
    "authors": [
      "Yafei Yang",
      "Zihui Zhang",
      "Bo Yang"
    ],
    "abstract": "We study the challenging problem of unsupervised multi-object segmentation on\nsingle images. Existing methods, which rely on image reconstruction objectives\nto learn objectness or leverage pretrained image features to group similar\npixels, often succeed only in segmenting simple synthetic objects or\ndiscovering a limited number of real-world objects. In this paper, we introduce\nunMORE, a novel two-stage pipeline designed to identify many complex objects in\nreal-world images. The key to our approach involves explicitly learning three\nlevels of carefully defined object-centric representations in the first stage.\nSubsequently, our multi-object reasoning module utilizes these learned object\npriors to discover multiple objects in the second stage. Notably, this\nreasoning module is entirely network-free and does not require human labels.\nExtensive experiments demonstrate that unMORE significantly outperforms all\nexisting unsupervised methods across 6 real-world benchmark datasets, including\nthe challenging COCO dataset, achieving state-of-the-art object segmentation\nresults. Remarkably, our method excels in crowded images where all baselines\ncollapse.",
    "pdf_url": "http://arxiv.org/pdf/2506.01778v1",
    "published": "2025-06-02T15:22:51+00:00",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.01777v1",
    "title": "DRAUN: An Algorithm-Agnostic Data Reconstruction Attack on Federated Unlearning Systems",
    "authors": [
      "Hithem Lamri",
      "Manaar Alam",
      "Haiyan Jiang",
      "Michail Maniatakos"
    ],
    "abstract": "Federated Unlearning (FU) enables clients to remove the influence of specific\ndata from a collaboratively trained shared global model, addressing regulatory\nrequirements such as GDPR and CCPA. However, this unlearning process introduces\na new privacy risk: A malicious server may exploit unlearning updates to\nreconstruct the data requested for removal, a form of Data Reconstruction\nAttack (DRA). While DRAs for machine unlearning have been studied extensively\nin centralized Machine Learning-as-a-Service (MLaaS) settings, their\napplicability to FU remains unclear due to the decentralized, client-driven\nnature of FU. This work presents DRAUN, the first attack framework to\nreconstruct unlearned data in FU systems. DRAUN targets optimization-based\nunlearning methods, which are widely adopted for their efficiency. We\ntheoretically demonstrate why existing DRAs targeting machine unlearning in\nMLaaS fail in FU and show how DRAUN overcomes these limitations. We validate\nour approach through extensive experiments on four datasets and four model\narchitectures, evaluating its performance against five popular unlearning\nmethods, effectively demonstrating that state-of-the-art FU methods remain\nvulnerable to DRAs.",
    "pdf_url": "http://arxiv.org/pdf/2506.01777v1",
    "published": "2025-06-02T15:20:54+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.01776v2",
    "title": "MaXIFE: Multilingual and Cross-lingual Instruction Following Evaluation",
    "authors": [
      "Yile Liu",
      "Ziwei Ma",
      "Xiu Jiang",
      "Jinglu Hu",
      "Jing Chang",
      "Liang Li"
    ],
    "abstract": "With the rapid adoption of large language models (LLMs) in natural language\nprocessing, the ability to follow instructions has emerged as a key metric for\nevaluating their practical utility. However, existing evaluation methods often\nfocus on single-language scenarios, overlooking the challenges and differences\npresent in multilingual and cross-lingual contexts. To address this gap, we\nintroduce MaXIFE: a comprehensive evaluation benchmark designed to assess\ninstruction-following capabilities across 23 different languages with 1667\nverifiable instruction tasks. MaXIFE integrates both Rule-Based Evaluation and\nModel-Based Evaluation, ensuring a balance of efficiency and accuracy. We\napplied MaXIFE to evaluate several leading commercial LLMs, establishing\nbaseline results for future comparisons. By providing a standardized tool for\nmultilingual instruction-following evaluation, MaXIFE aims to advance research\nand development in natural language processing.",
    "pdf_url": "http://arxiv.org/pdf/2506.01776v2",
    "published": "2025-06-02T15:20:20+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.01775v1",
    "title": "Developing a Mixed-Methods Pipeline for Community-Oriented Digitization of Kwak'wala Legacy Texts",
    "authors": [
      "Milind Agarwal",
      "Daisy Rosenblum",
      "Antonios Anastasopoulos"
    ],
    "abstract": "Kwak'wala is an Indigenous language spoken in British Columbia, with a rich\nlegacy of published documentation spanning more than a century, and an active\ncommunity of speakers, teachers, and learners engaged in language\nrevitalization. Over 11 volumes of the earliest texts created during the\ncollaboration between Franz Boas and George Hunt have been scanned but remain\nunreadable by machines. Complete digitization through optical character\nrecognition has the potential to facilitate transliteration into modern\northographies and the creation of other language technologies. In this paper,\nwe apply the latest OCR techniques to a series of Kwak'wala texts only\naccessible as images, and discuss the challenges and unique adaptations\nnecessary to make such technologies work for these real-world texts. Building\non previous methods, we propose using a mix of off-the-shelf OCR methods,\nlanguage identification, and masking to effectively isolate Kwak'wala text,\nalong with post-correction models, to produce a final high-quality\ntranscription.",
    "pdf_url": "http://arxiv.org/pdf/2506.01775v1",
    "published": "2025-06-02T15:20:09+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.01774v2",
    "title": "Greening AI-enabled Systems with Software Engineering: A Research Agenda for Environmentally Sustainable AI Practices",
    "authors": [
      "Luís Cruz",
      "João Paulo Fernandes",
      "Maja H. Kirkeby",
      "Silverio Martínez-Fernández",
      "June Sallou",
      "Hina Anwar",
      "Enrique Barba Roque",
      "Justus Bogner",
      "Joel Castaño",
      "Fernando Castor",
      "Aadil Chasmawala",
      "Simão Cunha",
      "Daniel Feitosa",
      "Alexandra González",
      "Andreas Jedlitschka",
      "Patricia Lago",
      "Henry Muccini",
      "Ana Oprescu",
      "Pooja Rani",
      "João Saraiva",
      "Federica Sarro",
      "Raghavendra Selvan",
      "Karthik Vaidhyanathan",
      "Roberto Verdecchia",
      "Ivan P. Yamshchikov"
    ],
    "abstract": "The environmental impact of Artificial Intelligence (AI)-enabled systems is\nincreasing rapidly, and software engineering plays a critical role in\ndeveloping sustainable solutions. The \"Greening AI with Software Engineering\"\nCECAM-Lorentz workshop (no. 1358, 2025) funded by the Centre Europ\\'een de\nCalcul Atomique et Mol\\'eculaire and the Lorentz Center, provided an\ninterdisciplinary forum for 29 participants, from practitioners to academics,\nto share knowledge, ideas, practices, and current results dedicated to\nadvancing green software and AI research. The workshop was held February 3-7,\n2025, in Lausanne, Switzerland. Through keynotes, flash talks, and\ncollaborative discussions, participants identified and prioritized key\nchallenges for the field. These included energy assessment and standardization,\nbenchmarking practices, sustainability-aware architectures, runtime adaptation,\nempirical methodologies, and education. This report presents a research agenda\nemerging from the workshop, outlining open research directions and practical\nrecommendations to guide the development of environmentally sustainable\nAI-enabled systems rooted in software engineering principles.",
    "pdf_url": "http://arxiv.org/pdf/2506.01774v2",
    "published": "2025-06-02T15:19:49+00:00",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE"
  },
  {
    "id": "http://arxiv.org/abs/2506.01773v2",
    "title": "Spin-induced Scalarized Black Holes in Einstein-Maxwell-scalar Models",
    "authors": [
      "Lang Cheng",
      "Guangzhou Guo",
      "Peng Wang",
      "Haitang Yang"
    ],
    "abstract": "We construct spin-induced scalarized black hole solutions in a class of\nEinstein-Maxwell-scalar models, where a scalar field is non-minimally coupled\nto the electromagnetic field. Our results show that scalar hair develops only\nfor rapidly rotating black holes, while slowly spinning ones remain well\ndescribed by the Kerr-Newman (KN) metric. The scalar field contributes only a\nsmall fraction of the total mass, indicating suppressed nonlinear effects. This\nsuppression may account for the narrow existence domains of scalarized black\nholes and the similarities observed in their existence domains across different\ncoupling functions. Moreover, scalarized black holes are found to coexist with\nlinearly stable, entropically favored KN black holes. These results motivate\nfurther investigations into the nonlinear dynamics and stability of scalarized\nblack holes in these models.",
    "pdf_url": "http://arxiv.org/pdf/2506.01773v2",
    "published": "2025-06-02T15:18:43+00:00",
    "categories": [
      "gr-qc"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2506.01772v3",
    "title": "Extension of algebroids Part I: The Construction",
    "authors": [
      "Simon-Raphael Fischer"
    ],
    "abstract": "In this series of two papers we will generalise the concept of extending a\nLie algebroid by a Lie algebra bundle, leading to a notion of extending a Lie\nalgebroid by another Lie algebroid whose orbits lie in the orbits of the former\nalgebroid. The resulting Lie algebroid's anchor will be the sum of the two\ninitial anchors such that the constructions will be similar to matched pairs of\nLie algebroids, but with the major difference that we will allow curvatures. In\nthis part of this series we will focus on the canonical construction making use\nof strict covariant adjustments, a generalisation of Maurer-Cartan forms in the\ncontext of gauge theories equipped with a Lie groupoid action instead of a Lie\ngroup action. That is, a Cartan connection with certain conditions on the\ncurvature. The second paper will introduce and explain the obstruction of the\nextension provided here. Examples will include locally split structures as in\nPoisson geometry.\n  As a side result we achieve strong hints towards a possible obstruction\ntheory for certain Cartan connections on Lie algebroids, which will be related\nto the obstruction of (non-trivial) action algebroids; generalising the\nstatement of the action algebroid structure induced by flat Cartan connections.",
    "pdf_url": "http://arxiv.org/pdf/2506.01772v3",
    "published": "2025-06-02T15:18:09+00:00",
    "categories": [
      "math.DG"
    ],
    "primary_category": "math.DG"
  },
  {
    "id": "http://arxiv.org/abs/2506.01771v1",
    "title": "SiO and a super-stellar C/O ratio in the atmosphere of the giant exoplanet WASP-121b",
    "authors": [
      "Thomas M. Evans-Soma",
      "David K. Sing",
      "Joanna K. Barstow",
      "Anjali A. A. Piette",
      "Jake Taylor",
      "Joshua D. Lothringer",
      "Henrique Reggiani",
      "Jayesh M. Goyal",
      "Eva-Maria Ahrer",
      "Nathan J. Mayne",
      "Zafar Rustamkulov",
      "Tiffany Kataria",
      "Duncan A. Christie",
      "Cyril Gapp",
      "Jiayin Dong",
      "Daniel Foreman-Mackey",
      "Soichiro Hattori",
      "Mark S. Marley"
    ],
    "abstract": "Refractory elements such as iron, magnesium, and silicon can be detected in\nthe atmospheres of ultrahot giant planets. This provides an opportunity to\nquantify the amount of refractory material accreted during formation, along\nwith volatile gases and ices. However, simultaneous detections of refractories\nand volatiles have proved challenging, as the most prominent spectral features\nof associated atoms and molecules span a broad wavelength range. Here, using a\nsingle JWST observation of the ultrahot giant planet WASP-121b, we report\ndetections of H$_2$O (5.5-13.5$\\sigma$), CO (10.8-12.8$\\sigma$), and SiO\n(5.7-6.2$\\sigma$) in the planet's dayside atmosphere, and CH$_4$\n(3.1-5.1$\\sigma$) in the nightside atmosphere. We measure super-stellar values\nfor the atmospheric C/H, O/H, Si/H, and C/O ratios, which point to the joint\nimportance of pebbles and planetesimals in giant planet formation. The\nCH$_4$-rich nightside composition is also indicative of dynamical processes,\nsuch as strong vertical mixing, having a profound influence on the chemistry of\nultrahot giant planets.",
    "pdf_url": "http://arxiv.org/pdf/2506.01771v1",
    "published": "2025-06-02T15:17:47+00:00",
    "categories": [
      "astro-ph.EP"
    ],
    "primary_category": "astro-ph.EP"
  },
  {
    "id": "http://arxiv.org/abs/2506.01770v1",
    "title": "ReGA: Representation-Guided Abstraction for Model-based Safeguarding of LLMs",
    "authors": [
      "Zeming Wei",
      "Chengcan Wu",
      "Meng Sun"
    ],
    "abstract": "Large Language Models (LLMs) have achieved significant success in various\ntasks, yet concerns about their safety and security have emerged. In\nparticular, they pose risks in generating harmful content and vulnerability to\njailbreaking attacks. To analyze and monitor machine learning models,\nmodel-based analysis has demonstrated notable potential in stateful deep neural\nnetworks, yet suffers from scalability issues when extending to LLMs due to\ntheir vast feature spaces. In this paper, we propose ReGA, a model-based\nanalysis framework with representation-guided abstraction, to safeguard LLMs\nagainst harmful prompts and generations. By leveraging safety-critical\nrepresentations, which are low-dimensional directions emerging in hidden states\nthat indicate safety-related concepts, ReGA effectively addresses the\nscalability issue when constructing the abstract model for safety modeling. Our\ncomprehensive evaluation shows that ReGA performs sufficiently well in\ndistinguishing between safe and harmful inputs, achieving an AUROC of 0.975 at\nthe prompt level and 0.985 at the conversation level. Additionally, ReGA\nexhibits robustness to real-world attacks and generalization across different\nsafety perspectives, outperforming existing safeguard paradigms in terms of\ninterpretability and scalability. Overall, ReGA serves as an efficient and\nscalable solution to enhance LLM safety by integrating representation\nengineering with model-based abstraction, paving the way for new paradigms to\nutilize software insights for AI safety. Our code is available at\nhttps://github.com/weizeming/ReGA.",
    "pdf_url": "http://arxiv.org/pdf/2506.01770v1",
    "published": "2025-06-02T15:17:38+00:00",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG",
      "cs.SE"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2506.01769v2",
    "title": "A law of large numbers for kinetic interacting diffusions",
    "authors": [
      "Carlo Bellingeri",
      "Fabio Coppini"
    ],
    "abstract": "We study the convergence of the empirical distribution associated with a\nsystem of interacting kinetic particles subject to independent Brownian forcing\nin a finite horizon setting, using some recent progress on kinetic non-linear\npartial differential equations. Under general assumptions that require only\nweak convergence on the initial datum -- without assuming independence or\nmoment conditions -- we prove convergence in probability to the corresponding\nnon-linear Fokker-Planck PDE.",
    "pdf_url": "http://arxiv.org/pdf/2506.01769v2",
    "published": "2025-06-02T15:15:32+00:00",
    "categories": [
      "math.PR",
      "60K35, 60F05, 60H20"
    ],
    "primary_category": "math.PR"
  },
  {
    "id": "http://arxiv.org/abs/2506.01768v2",
    "title": "Toward extracting scattering phase shift from integrated correlation functions IV: Coulomb corrections",
    "authors": [
      "Peng Guo",
      "Frank X. Lee"
    ],
    "abstract": "The formalism developed in Refs.~\\cite{Guo:2023ecc,Guo:2024zal,Guo:2024pvt}\nthat relates the integrated correlation functions for a trapped system to the\ninfinite volume scattering phase shifts through a weighted integral is further\nextended to include Coulomb interaction between charged particles. The original\nformalism cannot be applied due to different divergent asymptotic behavior\nresulting from the long-range nature of the Coulomb force. We show that a\nmodified formula in which the difference of integrated correlation functions\nbetween particles interacting with Coulomb plus short-range interaction and\nwith Coulomb interaction alone is free of divergence, and has rapid approach to\nits infinite volume limit. Using an exactly solvable model, we demonstrate that\nthe short-range potential scattering phase shifts can be reliably extracted\nfrom the formula in the presence of Coulomb interaction.",
    "pdf_url": "http://arxiv.org/pdf/2506.01768v2",
    "published": "2025-06-02T15:15:26+00:00",
    "categories": [
      "hep-lat",
      "cond-mat.other",
      "cond-mat.quant-gas",
      "hep-ph",
      "nucl-th"
    ],
    "primary_category": "hep-lat"
  },
  {
    "id": "http://arxiv.org/abs/2506.01767v1",
    "title": "Predictive-CSM: Lightweight Fragment Security for 6LoWPAN IoT Networks",
    "authors": [
      "Somayeh Sobati-M"
    ],
    "abstract": "Fragmentation is a routine part of communication in 6LoWPAN-based IoT\nnetworks,\n  designed to accommodate small frame sizes on constrained wireless links.\nHowever, this process\n  introduces a critical vulnerability fragments are typically stored and\nprocessed before their\n  legitimacy is confirmed, allowing attackers to exploit this gap with minimal\neffort.\n  In this work, we explore a defense strategy that takes a more adaptive,\nbehavior-aware approach to this problem. Our system, called Predictive-CSM,\nintroduces a combination of two\n  lightweight mechanisms. The first tracks how each node behaves over time,\nrewarding consistent\n  and successful interactions while quickly penalizing suspicious or failing\npatterns. The second\n  checks the integrity of packet fragments using a chained hash, allowing\nincomplete or manipulated sequences to be caught early, before they can occupy\nmemory or waste processing time.\n  We put this system to the test using a set of targeted attack simulations,\nincluding early fragment injection, replayed headers, and flooding with fake\ndata. Across all scenarios, Predictive CSM preserved network delivery and\nmaintained energy efficiency, even under pressure. Rather\n  than relying on heavyweight cryptography or rigid filters, this approach\nallows constrained de vices to adapt their defenses in real time based on what\nthey observe, not just what they're\n  told. In that way, it offers a step forward for securing fragmented\ncommunication in real world\n  IoT systems",
    "pdf_url": "http://arxiv.org/pdf/2506.01767v1",
    "published": "2025-06-02T15:15:18+00:00",
    "categories": [
      "cs.CR"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2506.01766v2",
    "title": "Janus correlators and Heun's equation",
    "authors": [
      "Michael Gutperle",
      "Christina Yeo"
    ],
    "abstract": "In this paper we calculate two-point correlation functions of a massive probe\nscalar field in the background of the three-dimensional Janus solution. We\nrelate the equation of motion of the scalar to Heun's equation and use the\nrecently obtained expressions for the connection coefficients to obtain the\ntwo-point function of operators dual to the probe scalar. From the correlators\nwe obtain the corrections to the spectrum of boundary operators and\nbulk-boundary operator product coefficients to second order in the Janus\ndeformation parameter.",
    "pdf_url": "http://arxiv.org/pdf/2506.01766v2",
    "published": "2025-06-02T15:13:40+00:00",
    "categories": [
      "hep-th"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2506.01765v1",
    "title": "Micelle Forming Linear-Dendritic Block Copolymers: A Theoretical Comparison between Random Hyperbranched and Precise Dendrimer Polymer Architectures",
    "authors": [
      "Marios Giannakou",
      "Oleg V. Borisov",
      "Friederike Schmid"
    ],
    "abstract": "Hyperbranched block copolymers offer a simpler and more efficient synthesis\nroute compared to more traditional dendritic systems, while still providing\nexceptional control over surface functionality and self-assembly. This makes\nthem ideal candidates for engineering nanoparticles with tailored properties\nfor applications such as drug delivery and sensing. Here we use self-consistent\nfield calculations to compare the micelle structures formed by copolymers with\na polydisperse hyperbranched (LHBC), monodisperse dendritic (LDBC), and linear\nsolvophilic blocks. Representative LHBC structures were generated by molecular\ndynamics simulations mimicking the slow-monomer addition protocol. We find that\nLHBC micelles are more stable, have a lower critical micelle concentration, and\nare better at accommodating larger drug payloads than LDBC micelles, and these\nproperties further improve with increasing polydispersity. LHBC micelles also\noffer more terminal ends for functionalization than LDBC micelles for LDBCs\nwith up to four branching generations, with the number of terminal ends being\nsurprisingly independent of the LHBC polydispersity. Our findings highlight the\nsuperiority of LHBC micelles in flexibility and performance over LDBC micelles.",
    "pdf_url": "http://arxiv.org/pdf/2506.01765v1",
    "published": "2025-06-02T15:12:41+00:00",
    "categories": [
      "cond-mat.soft",
      "cond-mat.mes-hall",
      "cond-mat.mtrl-sci",
      "cond-mat.stat-mech",
      "physics.chem-ph"
    ],
    "primary_category": "cond-mat.soft"
  },
  {
    "id": "http://arxiv.org/abs/2506.01764v2",
    "title": "Unconventional Superconducting Pairing Symmetries in La$_3$Ni$_2$O$_7$: from the Perspective of Topology",
    "authors": [
      "Guan-Hao Feng",
      "Jun Quan",
      "Yusheng Hou"
    ],
    "abstract": "The recently discovered superconductor La$_3$Ni$_2$O$_7$ has attracted\nsignificant attention due to its remarkably high $T_{c}$ and unconventional\npairing mechanism. High-pressure experiments have demonstrated that the\nemergence of the superconducting phase is associated with a transition to a\nhigher-symmetry structure. Motivated by this observation, we investigate the\nsuperconductivity in La$_3$Ni$_2$O$_7$ under high pressure from the\nperspectives of symmetry and topology. Based on a bilayer two-orbital model\nwith Ni-$d_{3z^{2}-r^{2}}$ and $d_{x^{2}-y^{2}}$ orbitals, we systematically\nexamine all symmetry-allowed multi-orbital superconducting pairings at the\nBogoliubov-de Gennes (BdG) mean-field level, including terms up to next-nearest\nneighbors. By solving the self-consistent gap equations and analyzing the BdG\ncondensation energies, we find that the $A_{1g}$ pairing channel is the most\nprobable one. The dominant pairing is $s_{\\pm}$-wave, originating from the\nintra-orbital interaction of the bilayer Ni-$d_{3z^{2}-r^{2}}$ orbital, while\nthe subdominant pairing is $d_{x^{2}-y^{2}}$-wave, arising from the\ninter-orbital interactions between the $d_{3z^{2}-r^{2}}$ and $d_{x^{2}-y^{2}}$\norbitals. Furthermore, we implement the theory of symmetry indicator (SI) to\nreveal the topological characteristics of each pairing channel, demonstrating\nthat the pairing symmetries can be identified by their distinct topological\nfeatures.",
    "pdf_url": "http://arxiv.org/pdf/2506.01764v2",
    "published": "2025-06-02T15:12:25+00:00",
    "categories": [
      "cond-mat.supr-con",
      "cond-mat.str-el"
    ],
    "primary_category": "cond-mat.supr-con"
  },
  {
    "id": "http://arxiv.org/abs/2506.01763v2",
    "title": "Modelling benthic animals in space and time using Bayesian Point Process with cross validation: the case of Holoturians",
    "authors": [
      "Daniele Poggio",
      "Gian Mario Sangiovanni",
      "Gianluca Mastrantonio",
      "Giovanna Jona Lasinio",
      "Edoardo Casoli",
      "Stefano Moro",
      "Daniele Ventura"
    ],
    "abstract": "Understanding the spatial distribution of Holothurians is an essential task\nfor ecosystem monitoring and sustainable management, particularly in the\nMediterranean habitats. However, species distribution modeling is often\ncomplicated by the presence-only nature of the data and heterogeneous sampling\ndesigns. This study develops a spatio-temporal framework based on Log-Gaussian\nCox Processes to analyze Holothurians' positions collected across nine survey\ncampaigns conducted from 2022 to 2024 near Giglio Island, Italy. The surveys\ncombined high-resolution photogrammetry with diver-based visual censuses,\nleading to varying detection probabilities across habitats, especially within\nPosidonia oceanica meadows. We adopt a model with a shared spatial Gaussian\nprocess component to accommodate this complexity, accounting for habitat\nstructure, environmental covariates, and temporal variability. Model estimation\nis performed using Integrated Nested Laplace Approximation. We evaluate the\npredictive performances of alternative model specifications through a novel\nk-fold cross-validation strategy for point processes, using the Continuous\nRanked Probability Score. Our approach provides a flexible and computationally\nefficient framework for integrating heterogeneous presence-only data in marine\necology and comparing the predictive ability of alternative models.",
    "pdf_url": "http://arxiv.org/pdf/2506.01763v2",
    "published": "2025-06-02T15:11:52+00:00",
    "categories": [
      "stat.AP",
      "stat.OT"
    ],
    "primary_category": "stat.AP"
  },
  {
    "id": "http://arxiv.org/abs/2506.01762v1",
    "title": "Anisotropic Counts-in-Cells in Redshift Space: A New Route to Cosmological Constraints from Galaxy Surveys",
    "authors": [
      "Paweł Drozda",
      "Wojciech A. Hellwing",
      "Maciej Bilicki"
    ],
    "abstract": "We introduce a novel extension of the volume-averaged correlation function\n(VACF) framework by replacing the traditional spherical smoothing kernels with\nanisotropic, ellipsoidal windows. This generalized approach enables the study\nof shape-dependent clustering statistics and captures directional information\nencoded in large-scale structure, particularly in redshift space where galaxy\ndistribution is distorted by peculiar velocities. We define and compute\nellipsoidal VACFs $\\bar{\\xi}_J (r_{\\parallel}, r_{\\perp})$ and the\ncorresponding reduced cumulants $s_J (r_{\\parallel}, r_{\\perp})$, allowing for\njoint sensitivity to both scale and anisotropy across arbitrary statistical\norder J. Using a suite of COLA N-body simulations spanning a grid of\ncosmologies with varying $\\Omega_M$ and $\\sigma_8$, we analyze the behavior of\nellipsoidal VACFs and cumulants in both real and redshift space. We find that\nthe shape of the smoothing kernel that maximizes the clustering signal depends\nstrongly on the redshift-space distortion regime: spherical in real space,\nprolate in the Fingers-of-God-dominated regime, and oblate in the Kaiser\nsquashing-dominated regime. While the standard VACF amplitude is mainly\nsensitive to ${\\sigma}_8$, the shape-dependence of redshift-space skewness\nshows a coherent response to the combined growth parameter $f \\sigma_8$, with a\ntypical sensitivity at the 1-3 $\\sigma$ level between neighboring models. Our\nresults demonstrate that ellipsoidal VACFs offer a computationally efficient\nand information-rich generalization of counts-in-cells analysis, with promising\napplications to galaxy survey data, halo catalogs, and cosmological tests of\ngravity beyond $\\Lambda CDM$.",
    "pdf_url": "http://arxiv.org/pdf/2506.01762v1",
    "published": "2025-06-02T15:11:45+00:00",
    "categories": [
      "astro-ph.CO"
    ],
    "primary_category": "astro-ph.CO"
  },
  {
    "id": "http://arxiv.org/abs/2506.02091v1",
    "title": "Comparison of spectrogram scaling in multi-label Music Genre Recognition",
    "authors": [
      "Bartosz Karpiński",
      "Cyryl Leszczyński"
    ],
    "abstract": "As the accessibility and ease-of-use of digital audio workstations increases,\nso does the quantity of music available to the average listener; additionally,\ndifferences between genres are not always well defined and can be abstract,\nwith widely varying combinations of genres across individual records. In this\narticle, multiple preprocessing methods and approaches to model training are\ndescribed and compared, accounting for the eclectic nature of today's albums. A\ncustom, manually labeled dataset of more than 18000 entries has been used to\nperform the experiments.",
    "pdf_url": "http://arxiv.org/pdf/2506.02091v1",
    "published": "2025-06-02T15:11:36+00:00",
    "categories": [
      "cs.SD",
      "cs.LG",
      "eess.AS"
    ],
    "primary_category": "cs.SD"
  },
  {
    "id": "http://arxiv.org/abs/2506.01761v1",
    "title": "A New 5 bit/2D-symbol Modulation Format for Relative Intensity Noise-dominated IM-DD Systems",
    "authors": [
      "Felipe Villenas",
      "Kaiquan Wu",
      "Yunus Can Gültekin",
      "Jamal Riani",
      "Alex Alvarado"
    ],
    "abstract": "We propose a novel 5-bit/2D-symbol modulation format based on PAM-6 optimized\nfor IM-DD systems dominated by relative intensity noise. The proposed\nmodulation scheme improves SNR by 0.94 dB compared to conventional PAM-6 and\nachieves near-optimal BER performance.",
    "pdf_url": "http://arxiv.org/pdf/2506.01761v1",
    "published": "2025-06-02T15:10:01+00:00",
    "categories": [
      "eess.SP"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2506.03201v1",
    "title": "A planning tool for neutron powder diffraction experiments",
    "authors": [
      "Joseph A. M. Paddison",
      "Stuart Calder",
      "Danielle R. Yahne",
      "Malcolm J. Cochran",
      "Si Athena Chen",
      "Matthias D. Frontzek",
      "Yuanpeng Zhang"
    ],
    "abstract": "We introduce a computer program to simulate the results of neutron\npowder-diffraction experiments at the High Flux Isotope Reactor at Oak Ridge\nNational Laboratory. The program is freely available as a web application at\nhttp://addie.ornl.gov/hfirestimate, and is designed to be straightforward to\nuse for researchers who are new to neutron diffraction. The input includes the\ncrystal structure of the proposed sample, the sample mass, and the instrument\nconfiguration. The results include a plot of the simulated data -- including\nrealistic estimates of background and the error bars due to counting statistics\n-- and suggestions of how to resolve potential problems with the experiment.\nHere, we explain the design and implementation of this program and demonstrate\nits performance using comparisons of simulated and experimental data. We hope\nthat this program will enable researchers to plan neutron-scattering\nexperiments more effectively, increasing the likelihood of successful\nexperiments and improving the productivity of neutron-diffraction research.",
    "pdf_url": "http://arxiv.org/pdf/2506.03201v1",
    "published": "2025-06-02T15:08:37+00:00",
    "categories": [
      "physics.ins-det",
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "physics.ins-det"
  },
  {
    "id": "http://arxiv.org/abs/2506.01760v1",
    "title": "First eccentric inspiral-merger-ringdown analysis of neutron star-black hole mergers",
    "authors": [
      "Maria de Lluc Planas",
      "Sascha Husa",
      "Antoni Ramos-Buades",
      "Jorge Valencia"
    ],
    "abstract": "The gravitational wave event GW200105 was the first confident neutron\nstar-black hole (NSBH) merger identified by the LIGO-Virgo-KAGRA collaboration.\nA recent analysis by Morras et al. with an eccentric precessing waveform model\nthat describes the inspiral phase of the $l=2$ and $m=\\{0,\\pm 2\\}$ modes has\nidentified this event as the first NSBH merger with strong evidence of orbital\neccentricity. In this paper we perform the first analysis of this event with an\naligned-spin eccentric waveform model that describes the full inspiral, merger,\nand ringdown, includes subdominant harmonics, and is partially calibrated to\nnumerical relativity simulations. This analysis confirms the results and finds\nevidence in favor of eccentricity even with a log-uniform prior in\neccentricity. We also analyze the NSBH events GW200115 and GW230529, completing\nthe analysis of all NSBHs with IMRPhenomTEHM, and find that these signal are\nconsistent with vanishing eccentricity. Finally, we briefly discuss\ncomputational challenges when performing the analysis with time-domain\neccentric waveform models.",
    "pdf_url": "http://arxiv.org/pdf/2506.01760v1",
    "published": "2025-06-02T15:08:33+00:00",
    "categories": [
      "astro-ph.HE",
      "gr-qc"
    ],
    "primary_category": "astro-ph.HE"
  },
  {
    "id": "http://arxiv.org/abs/2506.01759v2",
    "title": "ADEPT: Adaptive Diffusion Environment for Policy Transfer Sim-to-Real",
    "authors": [
      "Youwei Yu",
      "Junhong Xu",
      "Lantao Liu"
    ],
    "abstract": "Model-free reinforcement learning has emerged as a powerful method for\ndeveloping robust robot control policies capable of navigating through complex\nand unstructured environments. The effectiveness of these methods hinges on two\nessential elements: (1) the use of massively parallel physics simulations to\nexpedite policy training, and (2) an environment generator tasked with crafting\nsufficiently challenging yet attainable environments to facilitate continuous\npolicy improvement. Existing methods of outdoor environment generation often\nrely on heuristics constrained by a set of parameters, limiting the diversity\nand realism. In this work, we introduce ADEPT, a novel \\textbf{A}daptive\n\\textbf{D}iffusion \\textbf{E}nvironment for \\textbf{P}olicy \\textbf{T}ransfer\nin the zero-shot sim-to-real fashion that leverages Denoising Diffusion\nProbabilistic Models to dynamically expand existing training environments by\nadding more diverse and complex environments adaptive to the current policy.\nADEPT guides the diffusion model's generation process through initial noise\noptimization, blending noise-corrupted environments from existing training\nenvironments weighted by the policy's performance in each corresponding\nenvironment. By manipulating the noise corruption level, ADEPT seamlessly\ntransitions between generating similar environments for policy fine-tuning and\nnovel ones to expand training diversity. To benchmark ADEPT in off-road\nnavigation, we propose a fast and effective multi-layer map representation for\nwild environment generation. Our experiments show that the policy trained by\nADEPT outperforms both procedural generated and natural environments, along\nwith popular navigation methods.",
    "pdf_url": "http://arxiv.org/pdf/2506.01759v2",
    "published": "2025-06-02T15:07:12+00:00",
    "categories": [
      "cs.RO",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2506.01758v2",
    "title": "Many-for-Many: Unify the Training of Multiple Video and Image Generation and Manipulation Tasks",
    "authors": [
      "Tao Yang",
      "Ruibin Li",
      "Yangming Shi",
      "Yuqi Zhang",
      "Qide Dong",
      "Haoran Cheng",
      "Weiguo Feng",
      "Shilei Wen",
      "Bingyue Peng",
      "Lei Zhang"
    ],
    "abstract": "Diffusion models have shown impressive performance in many visual generation\nand manipulation tasks. Many existing methods focus on training a model for a\nspecific task, especially, text-to-video (T2V) generation, while many other\nworks focus on finetuning the pretrained T2V model for image-to-video (I2V),\nvideo-to-video (V2V), image and video manipulation tasks, etc. However,\ntraining a strong T2V foundation model requires a large amount of high-quality\nannotations, which is very costly. In addition, many existing models can\nperform only one or several tasks. In this work, we introduce a unified\nframework, namely many-for-many, which leverages the available training data\nfrom many different visual generation and manipulation tasks to train a single\nmodel for those different tasks. Specifically, we design a lightweight adapter\nto unify the different conditions in different tasks, then employ a joint\nimage-video learning strategy to progressively train the model from scratch.\nOur joint learning leads to a unified visual generation and manipulation model\nwith improved video generation performance. In addition, we introduce depth\nmaps as a condition to help our model better perceive the 3D space in visual\ngeneration. Two versions of our model are trained with different model sizes\n(8B and 2B), each of which can perform more than 10 different tasks. In\nparticular, our 8B model demonstrates highly competitive performance in video\ngeneration tasks compared to open-source and even commercial engines. Our\nmodels and source codes are available at https://github.com/leeruibin/MfM.git.",
    "pdf_url": "http://arxiv.org/pdf/2506.01758v2",
    "published": "2025-06-02T15:05:44+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.01757v1",
    "title": "Efficient Egocentric Action Recognition with Multimodal Data",
    "authors": [
      "Marco Calzavara",
      "Ard Kastrati",
      "Matteo Macchini",
      "Dushan Vasilevski",
      "Roger Wattenhofer"
    ],
    "abstract": "The increasing availability of wearable XR devices opens new perspectives for\nEgocentric Action Recognition (EAR) systems, which can provide deeper human\nunderstanding and situation awareness. However, deploying real-time algorithms\non these devices can be challenging due to the inherent trade-offs between\nportability, battery life, and computational resources. In this work, we\nsystematically analyze the impact of sampling frequency across different input\nmodalities - RGB video and 3D hand pose - on egocentric action recognition\nperformance and CPU usage. By exploring a range of configurations, we provide a\ncomprehensive characterization of the trade-offs between accuracy and\ncomputational efficiency. Our findings reveal that reducing the sampling rate\nof RGB frames, when complemented with higher-frequency 3D hand pose input, can\npreserve high accuracy while significantly lowering CPU demands. Notably, we\nobserve up to a 3x reduction in CPU usage with minimal to no loss in\nrecognition performance. This highlights the potential of multimodal input\nstrategies as a viable approach to achieving efficient, real-time EAR on XR\ndevices.",
    "pdf_url": "http://arxiv.org/pdf/2506.01757v1",
    "published": "2025-06-02T15:04:23+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.02090v1",
    "title": "The Impact of Software Testing with Quantum Optimization Meets Machine Learning",
    "authors": [
      "Gopichand Bandarupalli"
    ],
    "abstract": "Modern software systems complexity challenges efficient testing, as\ntraditional machine learning (ML) struggles with large test suites. This\nresearch presents a hybrid framework integrating Quantum Annealing with ML to\noptimize test case prioritization in CI/CD pipelines. Leveraging quantum\noptimization, it achieves a 25 percent increase in defect detection efficiency\nand a 30 percent reduction in test execution time versus classical ML,\nvalidated on the Defects4J dataset. A simulated CI/CD environment demonstrates\nrobustness across evolving codebases. Visualizations, including defect heatmaps\nand performance graphs, enhance interpretability. The framework addresses\nquantum hardware limits, CI/CD integration, and scalability for 2025s hybrid\nquantum-classical ecosystems, offering a transformative approach to software\nquality assurance.",
    "pdf_url": "http://arxiv.org/pdf/2506.02090v1",
    "published": "2025-06-02T15:04:10+00:00",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.SE"
  },
  {
    "id": "http://arxiv.org/abs/2506.01756v1",
    "title": "Learning with pyCub: A New Simulation and Exercise Framework for Humanoid Robotics",
    "authors": [
      "Lukas Rustler",
      "Matej Hoffmann"
    ],
    "abstract": "We present pyCub, an open-source physics-based simulation of the humanoid\nrobot iCub, along with exercises to teach students the basics of humanoid\nrobotics. Compared to existing iCub similators (iCub SIM, iCub Gazebo), which\nrequire C++ code and YARP as middleware, pyCub works without YARP and with\nPython code. The complete robot with all articulations has been simulated, with\ntwo cameras in the eyes and the unique sensitive skin of the iCub comprising\n4000 receptors on its body surface. The exercises range from basic control of\nthe robot in velocity, joint, and Cartesian space to more complex tasks like\ngazing, grasping, or reactive control. The whole framework is written and\ncontrolled with Python, thus allowing to be used even by people with small or\nalmost no programming practice. The exercises can be scaled to different\ndifficulty levels. We tested the framework in two runs of a course on humanoid\nrobotics. The simulation, exercises, documentation, Docker images, and example\nvideos are publicly available at https://rustlluk.github.io/pyCub.",
    "pdf_url": "http://arxiv.org/pdf/2506.01756v1",
    "published": "2025-06-02T15:03:51+00:00",
    "categories": [
      "cs.RO"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2506.01755v2",
    "title": "Data-assimilated model-informed reinforcement learning",
    "authors": [
      "Defne E. Ozan",
      "Andrea Nóvoa",
      "Georgios Rigas",
      "Luca Magri"
    ],
    "abstract": "The control of spatio-temporally chaos is challenging because of high\ndimensionality and unpredictability. Model-free reinforcement learning (RL)\ndiscovers optimal control policies by interacting with the system, typically\nrequiring observations of the full physical state. In practice, sensors often\nprovide only partial and noisy measurements (observations) of the system. The\nobjective of this paper is to develop a framework that enables the control of\nchaotic systems with partial and noisy observability. The proposed method,\ndata-assimilated model-informed reinforcement learning (DA-MIRL), integrates\n(i) low-order models to approximate high-dimensional dynamics; (ii) sequential\ndata assimilation to correct the model prediction when observations become\navailable; and (iii) an off-policy actor-critic RL algorithm to adaptively\nlearn an optimal control strategy based on the corrected state estimates. We\ntest DA-MIRL on the spatiotemporally chaotic solutions of the\nKuramoto-Sivashinsky equation. We estimate the full state of the environment\nwith (i) a physics-based model, here, a coarse-grained model; and (ii) a\ndata-driven model, here, the control-aware echo state network, which is\nproposed in this paper. We show that DA-MIRL successfully estimates and\nsuppresses the chaotic dynamics of the environment in real time from partial\nobservations and approximate models. This work opens opportunities for the\ncontrol of partially observable chaotic systems.",
    "pdf_url": "http://arxiv.org/pdf/2506.01755v2",
    "published": "2025-06-02T15:02:26+00:00",
    "categories": [
      "eess.SY",
      "cs.LG",
      "cs.SY"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2506.01754v1",
    "title": "Generalized Super-Twisting Observer for a class of interconnected nonlinear systems with uncertainties",
    "authors": [
      "Rania Tafat",
      "Jaime A. Moreno",
      "Stefan Streif"
    ],
    "abstract": "The Generalized Super-Twisting Observer (GSTO) is extended for a strongly\nobservable class of nonlinearly interconnected systems with bounded\nuncertainties/perturbations. A nonsmooth strong Lyapunov function is used to\nprove the finite-time convergence of the proposed observer to the true system's\ntrajectories, in the presence of the uncertainties. A case study on the\ninteraction between two food production systems is presented, comparing the\nproposed observer with the High Gain observer. The results emphasize the\ncritical role of the GSTO's discontinuous term in achieving exact estimation.",
    "pdf_url": "http://arxiv.org/pdf/2506.01754v1",
    "published": "2025-06-02T15:02:25+00:00",
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2506.01753v1",
    "title": "Critical Metallicity of Cool Supergiant Formation. II. Physical Origin",
    "authors": [
      "Po-Sheng Ou",
      "Ke-Jung Chen"
    ],
    "abstract": "This study investigates the physical origin of the critical metallicity\n($Z_{\\rm c}\\sim 0.001$) required for the formation of cool supergiants, as\nrevealed by stellar evolution models. Using model grids that vary in mass,\nmetallicity, opacity, and nuclear reaction rates, we identify a threshold\nterminal-age main-sequence (TAMS) radius ($R_{\\rm T}$) that determines whether\na star of a given mass can evolve into the red supergiant (RSG) phase. Through\nstellar models and homology relations, we show that metallicity affects the\nTAMS radius via its influence on opacity and nuclear energy generation. By\nclassifying the evolutionary pathways of supergiants, we demonstrate how TAMS\nradius, shaped by metallicity, decisively governs the post-main-sequence\noutcome: Stars with metallicities $Z < Z_{\\rm c}$ exhibit TAMS radii smaller\nthan $R_{\\rm T}$ and proceed to advanced core helium or carbon burning while\nretaining compact envelopes, thereby preventing further expansion into the RSG\nregime. In contrast, stars with $Z > Z_{\\rm c}$ have TAMS radii larger than\n$R_{\\rm T}$ and expand into the stable RSG phase during core helium burning.\nThe envelope radius at the onset of core helium burning is the key factor\ndetermining whether a star becomes a red or blue supergiant. Our results\nexplain the origin of the critical metallicity and offer insight into the\nevolution of metal-poor massive stars in the early universe.",
    "pdf_url": "http://arxiv.org/pdf/2506.01753v1",
    "published": "2025-06-02T15:00:54+00:00",
    "categories": [
      "astro-ph.SR",
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.SR"
  },
  {
    "id": "http://arxiv.org/abs/2506.01752v2",
    "title": "A High-Performance Evolutionary Multiobjective Community Detection Algorithm",
    "authors": [
      "Guilherme O. Santos",
      "Lucas S. Vieira",
      "Giulio Rossetti",
      "Carlos H. G. Ferreira",
      "Gladston Moreira"
    ],
    "abstract": "Community detection in complex networks is fundamental across social,\nbiological, and technological domains. While traditional single-objective\nmethods like Louvain and Leiden are computationally efficient, they suffer from\nresolution bias and structural degeneracy. Multi-objective evolutionary\nalgorithms (MOEAs) address these limitations by simultaneously optimizing\nconflicting structural criteria, however, their high computational costs have\nhistorically limited their application to small networks. We present HP-MOCD, a\nHigh-Performance Evolutionary Multiobjective Community Detection Algorithm\nbuilt on Non-dominated Sorting Genetic Algorithm II (NSGA-II), which overcomes\nthese barriers through topology-aware genetic operators, full parallelization,\nand bit-level optimizations, achieving theoretical O(GN_p|V|) complexity. We\nconduct experiments on both synthetic and real-world networks. Results\ndemonstrate strong scalability, with HP-MOCD processing networks of over\n1,000,000 nodes while maintaining high quality across varying noise levels. It\noutperforms other MOEAs by more than 531 times in runtime on synthetic\ndatasets, achieving runtimes as low as 57 seconds for graphs with 40,000 nodes\non moderately powered hardware. Across 14 real-world networks, HP-MOCD was the\nonly MOEA capable of processing the six largest datasets within a reasonable\ntime, with results competitive with single-objective approaches. Unlike\nsingle-solution methods, HP-MOCD produces a Pareto Front, enabling\nindividual-specific trade-offs and providing decision-makers with a spectrum of\nhigh-quality community structures. It introduces the first open-source Python\nMOEA library compatible with networkx and igraph for large-scale community\ndetection.",
    "pdf_url": "http://arxiv.org/pdf/2506.01752v2",
    "published": "2025-06-02T14:59:44+00:00",
    "categories": [
      "cs.SI"
    ],
    "primary_category": "cs.SI"
  },
  {
    "id": "http://arxiv.org/abs/2506.01751v2",
    "title": "An extended Vinogradov's mean value theorem",
    "authors": [
      "Changkeun Oh",
      "Kiseok Yeon"
    ],
    "abstract": "In this paper, we provide novel mean value estimates for exponential sums\nrelated to the extended main conjecture of Vinogradov's mean value theorem, by\ndeveloping the Hardy-Littlewood circle method together with a refined shifting\nvariables argument. Let $d\\geq 2$ be a natural number and\n$\\boldsymbol{\\alpha}=(\\alpha_d,\\ldots, \\alpha_1)\\in \\mathbb{R}^d.$ Define the\nexponential sum \\begin{equation*}\n  f_d(\\boldsymbol{\\alpha};N):=\\sum_{1 \\leq n \\leq N}e(\\alpha_d n^d + \\cdots+\n\\alpha_1 n). \\end{equation*} For $p>0$, consider mean values of the exponential\nsums \\begin{equation*}\n  \\mathcal{I}_{p,d}(u;N):=\\int_{[0,1)\\times [0,N^{-u})\\times\n[0,1)^{d-2}}|f_d(\\boldsymbol{\\alpha};N)|^pd\\boldsymbol{\\alpha}, \\end{equation*}\nwhere we wrote $d\\boldsymbol{\\alpha}=d\\alpha_1 d\\alpha_2\\cdots\nd\\alpha_{d-1}d\\alpha_d.$ By making use of the aforementioned tools, we obtain\nthe sharp upper bound for $\\mathcal{I}_{p,d}(u;N)$, for $d=2,3$ and $0<u\\leq\n1$. Furthermore, for $d \\geq 4$, we obtain analogous results depending on a\nsmall cap decoupling inequality for the moment curves in $\\mathbb{R}^d.$",
    "pdf_url": "http://arxiv.org/pdf/2506.01751v2",
    "published": "2025-06-02T14:59:11+00:00",
    "categories": [
      "math.NT"
    ],
    "primary_category": "math.NT"
  },
  {
    "id": "http://arxiv.org/abs/2506.01750v1",
    "title": "Warming from cold pools: A pathway for mesoscale organization to alter Earth's radiation budget",
    "authors": [
      "Pouriya Alinaghi",
      "Martin Janssens",
      "Fredrik Jansson"
    ],
    "abstract": "Marine shallow cumulus clouds have long caused large uncertainty in climate\nprojections. These clouds frequently organize into mesoscale (10-500 km)\nstructures, through two processes that couple the clouds to shallow mesoscale\ncirculations: (i) mesoscale moisture aggregation, and (ii) cold pools, driven\nlocally from rain-evaporation. Since global climate models do not capture these\nmesoscale processes, while the degree of mesoscale organization is observed to\ncorrelate to shortwave cooling, it has been suggested that mesoscale processes\nmodulate the cloud response to global warming. Here, we show that introducing\nmesoscale dynamics can indeed substantially alter top-of-the-atmosphere\nradiative budget, if the balance between the two circulations is upset. By\nhomogenizing rain-evaporation across the horizontal domain, we suppress the\ncold-pool-driven circulations in a large ensemble of large-domain, large-eddy\nsimulations. We find that cold pools reduce mesoscale ascent, thereby arresting\na runaway self-aggregation of moisture into very moist regions. This reduces\nthe net rainfall of the cumulus fields, moistens the boundary layer and thus\nreduces the emission of clear-sky longwave radiation to space, giving an\nensemble-averaged warming of 1.88 W/m2. Our results highlight that the proper\ninterplay between mesoscale processes is critical for capturing radiative\nbudgets-especially in kilometer-scale climate models that only partially\nresolve aggregation and cold pools.",
    "pdf_url": "http://arxiv.org/pdf/2506.01750v1",
    "published": "2025-06-02T14:58:12+00:00",
    "categories": [
      "physics.ao-ph"
    ],
    "primary_category": "physics.ao-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.03200v1",
    "title": "Novel Experimental Platform to realize One-dimensional Quantum Fluids",
    "authors": [
      "Stephanie McNamara",
      "Prabin Parajuli",
      "Sutirtha Paul",
      "Garfield Warren",
      "Adrian Del Maestro",
      "Paul E. Sokol"
    ],
    "abstract": "Templated porous materials, such as MCM-41, due to the uniformity of their\nonedimensional structure and scalability in synthesis, have emerged as an\nattractive medium for studying one-dimensional quantum fluids. However, the\nexperimental challenge of synthesizing these materials with pore radii smaller\nthan 15 Angstroms hinders the realization of a one-dimensional quantum liquid\nof helium within such systems, as the coherence length of helium is shorter\nthan the pore radius. Recently, DelMaestro et. al. have preplated MCM-41 with\nAr resulting in a reduction of the pore size and a softening of the adsorption\npotential allowing them to observe 1D Tomanga-Luttinger liquid like behavior.\nIn this paper we present a novel method to obtain an even more ideal\nenvironment for studying the behavior of 1D 4He. We propose preplating MCM-41\npores with cesium (Cs) metal. The non-wetting nature of helium on a Cs-coated\nsurface, coupled with the large atomic radius of cesium, creates an optimal\nenvironment for confining a quantum liquid of helium in one-dimensional\ngeometry. We present preliminary measurements of adsorption isotherms and Small\nAngle X-ray Scattering studies that 1reveal a reduction in pore radius upon\npreplating MCM-41 with Cs, demonstrating promising prospects for facilitating\nthe realization of one-dimensional quantum fluids in templated porous\nmaterials.",
    "pdf_url": "http://arxiv.org/pdf/2506.03200v1",
    "published": "2025-06-02T14:56:30+00:00",
    "categories": [
      "cond-mat.mtrl-sci",
      "cond-mat.quant-gas"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2506.01749v1",
    "title": "Toward Memristor-like Resonant Sensors: Observation of Pinched Hysteresis within MEMS Resonators",
    "authors": [
      "Erion Uka",
      "Chun Zhao"
    ],
    "abstract": "Memristors, uniquely characterized by their pinched hysteresis loop\nfingerprints, have attracted significant research interest over the past\ndecade, due to their enormous potential for novel computation and artificial\nintelligence applications. Memristors are widely regarded as the fourth\nfundamental electrical component, with voltage and current being their input\nand output signals. In broader terms, similar pinched hysteresis behavior\nshould also exist in other physical systems across domains (e.g., physical\ninput and electrical output), hence linking the real physical world with the\ndigital domain (e.g., in the form of a physical sensor). In this work, we\nreport the first observation of pinched hysteresis behavior in a\nmicro-electro-mechanical systems (MEMS) resonator device, showing that it is\nviable to create resonant MEMS sensors incorporating memristor-like properties,\ni.e., MemReSensor. We envisage that this will lay the foundations for a new way\nof fusing MEMS with artificial intelligence (AI), such as creating\nin-physical-sensor computing, as well as in-sensor AI, e.g., multi-mode\nin-sensor matrix multiplication across domains.",
    "pdf_url": "http://arxiv.org/pdf/2506.01749v1",
    "published": "2025-06-02T14:56:09+00:00",
    "categories": [
      "physics.app-ph"
    ],
    "primary_category": "physics.app-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.01748v1",
    "title": "Thinking in Character: Advancing Role-Playing Agents with Role-Aware Reasoning",
    "authors": [
      "Yihong Tang",
      "Kehai Chen",
      "Muyun Yang",
      "Zhengyu Niu",
      "Jing Li",
      "Tiejun Zhao",
      "Min Zhang"
    ],
    "abstract": "The advancement of Large Language Models (LLMs) has spurred significant\ninterest in Role-Playing Agents (RPAs) for applications such as emotional\ncompanionship and virtual interaction. However, recent RPAs are often built on\nexplicit dialogue data, lacking deep, human-like internal thought processes,\nresulting in superficial knowledge and style expression. While Large Reasoning\nModels (LRMs) can be employed to simulate character thought, their direct\napplication is hindered by attention diversion (i.e., RPAs forget their role)\nand style drift (i.e., overly formal and rigid reasoning rather than\ncharacter-consistent reasoning). To address these challenges, this paper\nintroduces a novel Role-Aware Reasoning (RAR) method, which consists of two\nimportant stages: Role Identity Activation (RIA) and Reasoning Style\nOptimization (RSO). RIA explicitly guides the model with character profiles\nduring reasoning to counteract attention diversion, and then RSO aligns\nreasoning style with the character and scene via LRM distillation to mitigate\nstyle drift. Extensive experiments demonstrate that the proposed RAR\nsignificantly enhances the performance of RPAs by effectively addressing\nattention diversion and style drift.",
    "pdf_url": "http://arxiv.org/pdf/2506.01748v1",
    "published": "2025-06-02T14:55:04+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.01747v1",
    "title": "Practical Short-Length Coding Schemes for Binary Distributed Hypothesis Testing",
    "authors": [
      "Ismaila Salihou Adamou",
      "Elsa Dupraz",
      "Reza Asvadi",
      "Tad Matsumoto"
    ],
    "abstract": "This paper addresses the design of practical shortlength coding schemes for\nDistributed Hypothesis Testing (DHT). While most prior work on DHT has focused\non informationtheoretic analyses, deriving bounds on Type-II error exponents\nvia achievability schemes based on quantization and quantizebinning, the\npractical implementation of DHT coding schemes has remained largely unexplored.\nMoreover, existing practical coding solutions for quantization and\nquantize-binning approaches were developed for source reconstruction tasks\nconsidering very long code length, and they are not directly applicable to DHT.\nIn this context, this paper introduces efficient shortlength implementations of\nquantization and quantize-binning schemes for DHT, constructed from short\nbinary linear block codes. Numerical results show the efficiency of the\nproposed coding schemes compared to uncoded cases and to existing schemes\ninitially developed for data reconstruction. In addition to practical code\ndesign, the paper derives exact analytical expressions for the Type-I and\nType-II error probabilities associated with each proposed scheme. The provided\nanalytical expressions are shown to predict accurately the practical\nperformance measured from Monte-Carlo simulations of the proposed schemes.\nThese theoretical results are novel and offer a useful framework for optimizing\nand comparing practical DHT schemes across a wide range of source and code\nparameters.",
    "pdf_url": "http://arxiv.org/pdf/2506.01747v1",
    "published": "2025-06-02T14:53:56+00:00",
    "categories": [
      "cs.IT",
      "eess.SP",
      "math.IT"
    ],
    "primary_category": "cs.IT"
  },
  {
    "id": "http://arxiv.org/abs/2506.01746v1",
    "title": "Optimal Bregman quantization : existence and uniqueness of optimal quantizers revisited",
    "authors": [
      "Guillaume Boutoille",
      "Gilles Pagès"
    ],
    "abstract": "In this paper we revisit the exsistence theorem for $L^r$-optimal\nquantization, $r\\ge 2$, with respect to a Bregman divergence: we establish the\nexistence of optimal quantizaers under lighter assumptions onthe strictly\nconvex function which generates the divergence, espcially in the quadratic case\n($r=2$). We then prove a uniqueness theorem ``\\`a la Trushkin'' in one\ndimension for strongly unimodal distributions and divergences gerated by\nstrictly convex functions whiose thire dervative is either stictly\n$\\log$-convex or $\\log$-concave.",
    "pdf_url": "http://arxiv.org/pdf/2506.01746v1",
    "published": "2025-06-02T14:53:48+00:00",
    "categories": [
      "math.PR"
    ],
    "primary_category": "math.PR"
  },
  {
    "id": "http://arxiv.org/abs/2506.01745v1",
    "title": "Power density spectra morphologies of seismically unresolved red-giant asteroseismic binaries",
    "authors": [
      "Jeong Yun Choi",
      "Francisca Espinoza-Rojas",
      "Quentin Coppée",
      "Saskia Hekker"
    ],
    "abstract": "Asteroseismic binaries are two oscillating stars detected in a single light\ncurve. These systems provide robust constraints on stellar models from the\ncombination of dynamical and asteroseismical stellar parameters. Predictions\nsuggested that approximately 200 asteroseismic binaries may exist among the\nKepler long-cadence data, and the majority of them consist of two red-clump\nstars. However, detecting these systems is challenging when the binary\ncomponents exhibit oscillations at similar frequencies that are\nindistinguishable. In this study, we predict the morphologies of power density\nspectra (PDS) of seismically unresolved red-giant asteroseismic binaries to\nprovide examples that can be used to identify among observed stars. We created\n5,000 artificial asteroseismic binary (AAB) systems by combining the KASOC\nlight curves of red giants with oscillations at similar frequency ranges. To\nquantify the complexity of the oscillation patterns, we used the maximum\nsignal-to-noise ratio of the background-normalized PDS and Shannon entropy.\nAdditionally, we identified the radial and quadrupole mode pairs for the\nindividual binary components and determined their impact on the PDS\nmorphologies of AABs. Our results reveal that the majority of AABs consist of\nthe two red-clump stars. The PDS of AABs generally exhibits increased entropy\nand decreased oscillation power compared to individual components. We focused\non the AABs whose stellar components have similar brightness and classified\nthem into four distinct morphologies: single star-like PDS, aligned, partially\naligned, and misaligned. Most AABs with detectable oscillations from both\ncomponents show complex oscillation patterns. Therefore, unresolved\nasteroseismic binaries with low oscillation power and complex oscillation\npatterns as characterized by high entropy offer a potential explanation to\nunderstand the observed stars with complex PDS.",
    "pdf_url": "http://arxiv.org/pdf/2506.01745v1",
    "published": "2025-06-02T14:52:23+00:00",
    "categories": [
      "astro-ph.SR"
    ],
    "primary_category": "astro-ph.SR"
  },
  {
    "id": "http://arxiv.org/abs/2506.01744v1",
    "title": "Enabling Seamless Transitions from Experimental to Production HPC for Interactive Workflows",
    "authors": [
      "Brian D. Etz",
      "David M. Rogers",
      "Michael J. Brim",
      "Ketan Maheshwari",
      "Kellen Leland",
      "Tyler J. Skluzacek",
      "Jack Lange",
      "Daniel Pelfrey",
      "Jordan Webb",
      "Patrick Widener",
      "Ryan Adamson",
      "Christopher Zimmer",
      "Veronica G. Melesse Vergara",
      "Mallikarjun Shankar",
      "Sarp Oral",
      "Rafael Ferreira da Silva"
    ],
    "abstract": "The evolving landscape of scientific computing requires seamless transitions\nfrom experimental to production HPC environments for interactive workflows.\nThis paper presents a structured transition pathway developed at OLCF that\nbridges the gap between development testbeds and production systems. We address\nboth technological and policy challenges, introducing frameworks for data\nstreaming architectures, secure service interfaces, and adaptive resource\nscheduling for time-sensitive workloads and improved HPC interactivity. Our\napproach transforms traditional batch-oriented HPC into a more dynamic\necosystem capable of supporting modern scientific workflows that require near\nreal-time data analysis, experimental steering, and cross-facility integration.",
    "pdf_url": "http://arxiv.org/pdf/2506.01744v1",
    "published": "2025-06-02T14:50:31+00:00",
    "categories": [
      "cs.DC"
    ],
    "primary_category": "cs.DC"
  },
  {
    "id": "http://arxiv.org/abs/2506.01743v1",
    "title": "A Survey of Synchronization Technologies for Low-power Backscatter Communication",
    "authors": [
      "Wenyuan Jiang",
      "Shuo Guo"
    ],
    "abstract": "Synchronization is a fundamental enabler for low-power backscatter\ncommunication systems, where passive or semi-passive tags modulate ambient RF\nsignals for ultra-low-power data transfer. In this survey, we review recent\nadvances in synchronization techniques across Bluetooth Low Energy (BLE),\nLong-Term Evolution (LTE), and WiFi-based backscatter platforms. We categorize\nexisting methods by their synchronization granularity, accuracy, compatibility,\nand power cost. We then compare representative systems including PassiveBLE,\nBitalign, LScatter, SyncLTE, LiTEfoot, SyncScatter, and BiScatter, highlighting\ndesign trade-offs and performance metrics. Furthermore, we delve into the\ntrade-offs between high throughput and low power synchronization, examining key\napproaches and challenges such as the balance between throughput,\nsynchronization accuracy, and power consumption in various backscatter systems.\nFinally, we discuss open challenges and outline future directions toward\nscalable, secure, and ultra-low-power backscatter synchronization.",
    "pdf_url": "http://arxiv.org/pdf/2506.01743v1",
    "published": "2025-06-02T14:50:19+00:00",
    "categories": [
      "cs.DC"
    ],
    "primary_category": "cs.DC"
  },
  {
    "id": "http://arxiv.org/abs/2506.01742v2",
    "title": "Smooth Logic Constraints in Nonlinear Optimization and Optimal Control Problems",
    "authors": [
      "J. Wehbeh",
      "E. C. Kerrigan"
    ],
    "abstract": "In some optimal control problems, complex relationships between states and\ninputs cannot be easily represented using continuous constraints, necessitating\nthe use of discrete logic instead. This paper presents a method for\nincorporating such logic constraints directly within continuous optimization\nframeworks, eliminating the need for binary variables or specialized solvers.\nOur approach reformulates arbitrary logic constraints under minimal assumptions\nas max-min constraints, which are then smoothed by introducing auxiliary\nvariables into the optimization problem. When these reformulated constraints\nare satisfied, they guarantee that the original logical conditions hold,\nensuring correctness in the optimization process. We demonstrate the\neffectiveness of this method on two planar quadrotor control tasks with complex\nlogic constraints. Compared to existing techniques for encoding logic in\ncontinuous optimization, our approach achieves faster computational performance\nand improved convergence to feasible solutions.",
    "pdf_url": "http://arxiv.org/pdf/2506.01742v2",
    "published": "2025-06-02T14:50:17+00:00",
    "categories": [
      "eess.SY",
      "cs.SY",
      "49N35 (Primary) 90C11, 49M29 (Secondary)"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2506.01741v1",
    "title": "Automated Manifold Learning for Reduced Order Modeling",
    "authors": [
      "Imran Nasim",
      "Melanie Weber"
    ],
    "abstract": "The problem of identifying geometric structure in data is a cornerstone of\n(unsupervised) learning. As a result, Geometric Representation Learning has\nbeen widely applied across scientific and engineering domains. In this work, we\ninvestigate the use of Geometric Representation Learning for the data-driven\ndiscovery of system dynamics from spatial-temporal data. We propose to encode\nsimilarity structure in such data in a spatial-temporal proximity graph, to\nwhich we apply a range of classical and deep learning-based manifold learning\napproaches to learn reduced order dynamics. We observe that while manifold\nlearning is generally capable of recovering reduced order dynamics, the quality\nof the learned representations varies substantially across different algorithms\nand hyperparameter choices. This is indicative of high sensitivity to the\ninherent geometric assumptions of the respective approaches and suggests a need\nfor careful hyperparameter tuning, which can be expensive in practise. To\novercome these challenges, we propose a framework for Automated Manifold\nLearning, which selects a manifold learning approach and corresponding\nhyperparameter choices based on representative subsamples of the input graph.\nWe demonstrate that the proposed framework leads to performance gains both in\nscalability and in the learned representations' accuracy in capturing local and\nglobal geometric features of the underlying system dynamics.",
    "pdf_url": "http://arxiv.org/pdf/2506.01741v1",
    "published": "2025-06-02T14:49:55+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.01740v1",
    "title": "Moduli of truncated shtukas and displays",
    "authors": [
      "Eva Viehmann",
      "Torsten Wedhorn",
      "Appendix by Christopher Lang"
    ],
    "abstract": "We study moduli spaces of truncated local shtukas and truncated displays and\ndescribe them as concrete quotient stacks. To do this, we develop a general\nformalism of frames that can be applied in both cases and is also used to study\nprismatic displays and prismatic F-gauges.",
    "pdf_url": "http://arxiv.org/pdf/2506.01740v1",
    "published": "2025-06-02T14:48:46+00:00",
    "categories": [
      "math.AG",
      "math.NT",
      "math.RT",
      "Primary: 14D23, Secondary: 14D20, 14D24, 14L15, 14L30, 14G35, 11G18"
    ],
    "primary_category": "math.AG"
  },
  {
    "id": "http://arxiv.org/abs/2506.01739v1",
    "title": "On the quadratic 8-edge case of the Brown-Erdős-Sós problem",
    "authors": [
      "Oleg Pikhurko",
      "Shumin Sun"
    ],
    "abstract": "Let $f^{(r)}(n;s,k)$ be the maximum number of edges in an $n$-vertex\n$r$-uniform hypergraph containing no $k$ edges on at most $s$ vertices. Brown,\nErd\\H{o}s and S\\'os conjectured in 1973 that the limit $\\lim_{n\\rightarrow\n\\infty}n^{-2}f^{(3)}(n;k+2,k)$ exists for all $k$. Recently, Delcourt and\nPostle settled the conjecture and their approach was generalised by Shangguan\nto every uniformity $r\\ge 4$: the limit $\\lim_{n\\rightarrow\n\\infty}n^{-2}f^{(r)}(n;rk-2k+2,k)$ exists for all $r\\ge 3$ and $k\\ge 2$.\n  The value of the limit is currently known for $k\\in \\{2,3,4,5,6,7\\}$ due to\nvarious results authored by Glock, Joos, Kim, K\\\"{u}hn, Lichev, Pikhurko,\nR\\\"odl and Sun. In this paper we look at the case $k=8$, determining the value\nof the limit for each $r\\ge 4$ and presenting a lower bound for $k=3$ that we\nconjecture to be sharp.",
    "pdf_url": "http://arxiv.org/pdf/2506.01739v1",
    "published": "2025-06-02T14:48:23+00:00",
    "categories": [
      "math.CO"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2506.01738v1",
    "title": "STORM: Benchmarking Visual Rating of MLLMs with a Comprehensive Ordinal Regression Dataset",
    "authors": [
      "Jinhong Wang",
      "Shuo Tong",
      "Jian liu",
      "Dongqi Tang",
      "Jintai Chen",
      "Haochao Ying",
      "Hongxia Xu",
      "Danny Chen",
      "Jian Wu"
    ],
    "abstract": "Visual rating is an essential capability of artificial intelligence (AI) for\nmulti-dimensional quantification of visual content, primarily applied in\nordinal regression (OR) tasks such as image quality assessment, facial age\nestimation, and medical image grading. However, current multi-modal large\nlanguage models (MLLMs) under-perform in such visual rating ability while also\nsuffering the lack of relevant datasets and benchmarks. In this work, we\ncollect and present STORM, a data collection and benchmark for Stimulating\nTrustworthy Ordinal Regression Ability of MLLMs for universal visual rating.\nSTORM encompasses 14 ordinal regression datasets across five common visual\nrating domains, comprising 655K image-level pairs and the corresponding\ncarefully curated VQAs. Importantly, we also propose a coarse-to-fine\nprocessing pipeline that dynamically considers label candidates and provides\ninterpretable thoughts, providing MLLMs with a general and trustworthy ordinal\nthinking paradigm. This benchmark aims to evaluate the all-in-one and zero-shot\nperformance of MLLMs in scenarios requiring understanding of the essential\ncommon ordinal relationships of rating labels. Extensive experiments\ndemonstrate the effectiveness of our framework and shed light on better\nfine-tuning strategies. The STORM dataset, benchmark, and pre-trained models\nare available on the following webpage to support further research in this\narea. Datasets and codes are released on the project page:\nhttps://storm-bench.github.io/.",
    "pdf_url": "http://arxiv.org/pdf/2506.01738v1",
    "published": "2025-06-02T14:48:15+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.01737v1",
    "title": "The Promise of Spiking Neural Networks for Ubiquitous Computing: A Survey and New Perspectives",
    "authors": [
      "Hemanth Sabbella",
      "Archit Mukherjee",
      "Thivya Kandappu",
      "Sounak Dey",
      "Arpan Pal",
      "Archan Misra",
      "Dong Ma"
    ],
    "abstract": "Spiking neural networks (SNNs) have emerged as a class of bio -inspired\nnetworks that leverage sparse, event-driven signaling to achieve low-power\ncomputation while inherently modeling temporal dynamics. Such characteristics\nalign closely with the demands of ubiquitous computing systems, which often\noperate on resource-constrained devices while continuously monitoring and\nprocessing time-series sensor data. Despite their unique and promising\nfeatures, SNNs have received limited attention and remain underexplored (or at\nleast, under-adopted) within the ubiquitous computing community. To address\nthis gap, this paper first introduces the core components of SNNs, both in\nterms of models and training mechanisms. It then presents a systematic survey\nof 76 SNN-based studies focused on time-series data analysis, categorizing them\ninto six key application domains. For each domain, we summarize relevant works\nand subsequent advancements, distill core insights, and highlight key takeaways\nfor researchers and practitioners. To facilitate hands-on experimentation, we\nalso provide a comprehensive review of current software frameworks and\nneuromorphic hardware platforms, detailing their capabilities and\nspecifications, and then offering tailored recommendations for selecting\ndevelopment tools based on specific application needs. Finally, we identify\nprevailing challenges within each application domain and propose future\nresearch directions that need be explored in ubiquitous community. Our survey\nhighlights the transformative potential of SNNs in enabling energy-efficient\nubiquitous sensing across diverse application domains, while also serving as an\nessential introduction for researchers looking to enter this emerging field.",
    "pdf_url": "http://arxiv.org/pdf/2506.01737v1",
    "published": "2025-06-02T14:47:48+00:00",
    "categories": [
      "cs.NE",
      "eess.SP",
      "I.2"
    ],
    "primary_category": "cs.NE"
  },
  {
    "id": "http://arxiv.org/abs/2506.01736v1",
    "title": "The bad and rough rotation is Poissonian",
    "authors": [
      "Manuel Hauke"
    ],
    "abstract": "Motivated by the Berry-Tabor Conjecture and the seminal work of\nRudnick-Sarnak, the fine-scale properties of sequences $(a_n\\alpha)_{n \\in\n\\mathbb{N}} \\mod 1$ with $(a_n)_{n \\in \\mathbb{N}} \\subseteq \\mathbb{N} $ and\n$\\alpha$ irrational have been extensively studied in the last decades. In this\narticle, we prove that for $(a_n)_{n \\in \\mathbb{N}}$ arising from the set of\nrough numbers with explicit roughness parameters and any badly approximable\n$\\alpha$, $(a_n\\alpha)_{n \\in \\mathbb{N}} \\mod 1$ has Poissonian correlations\nof all orders, and consequently, Poissonian gaps. This is the first known\nexplicit sequence $(a_n\\alpha)_{n \\in \\mathbb{N}} \\mod 1$ with these\nproperties. Further, we show that this result is false for Lebesgue almost\nevery $\\alpha$, thereby disproving a conjecture of Larcher and Stockinger\n[Math. Proc. Camb. Phil. Soc. 2020]. The method of proof makes use of an\nequidistribution result mod $d$ in diophantine Bohr sets which might be of\nindependent interest.",
    "pdf_url": "http://arxiv.org/pdf/2506.01736v1",
    "published": "2025-06-02T14:46:01+00:00",
    "categories": [
      "math.NT",
      "11J71 11N25 11N80 11K45 11K60 11J83"
    ],
    "primary_category": "math.NT"
  },
  {
    "id": "http://arxiv.org/abs/2506.01735v2",
    "title": "Consecutive collision orbits in the restricted three-body problem above the first critical energy value",
    "authors": [
      "Jungsoo Kang",
      "Kevin Ruck"
    ],
    "abstract": "In this paper, we study the planar circular restricted three-body problem for\nenergy levels slightly above the first critical value. We first observe that\nthe energy hypersurfaces in the Birkhoff regularization corresponding to these\nenergy levels are of contact type. Then, using a version of Rabinowitz Floer\nhomology, we establish the existence of either a periodic symmetric collision\norbit or infinitely many symmetric consecutive collision orbits. Furthermore,\nby an analytic continuation argument, for generic mass ratios and energy\nlevels, we prove that there is no periodic symmetric collision orbit with odd\nnumber of collisions. This in turn implies the existence of at least two\nsymmetric consecutive collision orbits.",
    "pdf_url": "http://arxiv.org/pdf/2506.01735v2",
    "published": "2025-06-02T14:45:20+00:00",
    "categories": [
      "math.SG",
      "math.DS"
    ],
    "primary_category": "math.SG"
  },
  {
    "id": "http://arxiv.org/abs/2506.01734v1",
    "title": "Benford's Curse: Tracing Digit Bias to Numerical Hallucination in LLMs",
    "authors": [
      "Jiandong Shao",
      "Yao Lu",
      "Jianfei Yang"
    ],
    "abstract": "Large Language Models (LLMs) exhibit impressive performance on complex\nreasoning tasks, yet they frequently fail on basic numerical problems,\nproducing incorrect outputs. Inspired by Benford's Law -- a statistical pattern\nwhere lower digits occur more frequently as leading digits -- we hypothesize\nthat the long-tailed digit distributions in web-collected corpora may be\nlearned by LLMs during pretraining, leading to biased numerical generation. To\ninvestigate the hypothesis, we first examine whether digits frequencies in\npretraining corpus (OLMo2) follows Benford's law. We then construct an\nevaluation benchmark with uniformly distributed ground-truth digits across\nseven numerical reasoning tasks. Our evaluation results demonstrate that\nleading open-source LLMs show a consistent pattern of digit bias that resembles\nBenford's law. Through logit-lens tracing and neuron-level dissection, we\nidentify that this bias arises predominantly from a small subset of highly\ndigit-selective feed-forward network (FFN) neurons in the deeper layers.\nFinally, we demonstrate that pruning these neurons mitigates imbalanced\novergeneration and partially corrects erroneous outputs, providing causal\nevidence that fine-grained pretraining digit bias can propagate into model\nbehavior. Our findings reveal a fundamental connection between corpus-level\nstatistics and symbolic failure modes in LLMs, offering a new lens for\ndiagnosing and mitigating hallucinations in numerical tasks.",
    "pdf_url": "http://arxiv.org/pdf/2506.01734v1",
    "published": "2025-06-02T14:44:30+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.01733v2",
    "title": "Observation of the Crab Nebula with the Single-Mirror Small-Size Telescope stereoscopic system at low altitude",
    "authors": [
      "C. Alispach",
      "A. Araudo",
      "M. Balbo",
      "V. Beshley",
      "J. Blažek",
      "J. Borkowski",
      "S. Boula",
      "T. Bulik",
      "F. Cadoux",
      "S. Casanova",
      "A. Christov",
      "J. Chudoba",
      "L. Chytka",
      "P. Čechvala",
      "P. Dědic",
      "D. della Volpe",
      "Y. Favre",
      "M. Garczarczyk",
      "L. Gibaud",
      "T. Gieras",
      "E. Głowacki",
      "P. Hamal",
      "M. Heller",
      "M. Hrabovský",
      "P. Janeček",
      "M. Jelínek",
      "V. Jílek",
      "J. Juryšek",
      "V. Karas",
      "B. Lacave",
      "E. Lyard",
      "E. Mach",
      "D. Mandát",
      "W. Marek",
      "S. Michal",
      "J. Michałowski",
      "M. Miroń",
      "R. Moderski",
      "T. Montaruli",
      "A. Muraczewski",
      "S. R. Muthyala",
      "A. L. Müller",
      "A. Nagai",
      "K. Nalewajski",
      "D. Neise",
      "J. Niemiec",
      "M. Nikołajuk",
      "V. Novotný",
      "M. Ostrowski",
      "M. Palatka",
      "M. Pech",
      "M. Prouza",
      "P. Schovanek",
      "V. Sliusar",
      "Ł. Stawarz",
      "R. Sternberger",
      "M. Stodulska",
      "J. Świerblewski",
      "P. Świerk",
      "J. Štrobl",
      "T. Tavernier",
      "P. Trávníček",
      "I. Troyano Pujadas",
      "J. Vícha",
      "R. Walter",
      "K. Ziętara"
    ],
    "abstract": "The Single-Mirror Small-Size Telescope (SST-1M) stereoscopic system is\ncomposed of two Imaging Atmospheric Cherenkov Telescopes (IACTs) designed for\noptimal performance for gamma-ray astronomy in the multi-TeV energy range. It\nfeatures a 4-meter-diameter tessellated mirror dish and an innovative\nSiPM-based camera. Its optical system features a 4-m diameter spherical mirror\ndish based on the Davies-Cotton design, maintaining a good image quality over a\nlarge FoV while minimizing optical aberrations. In 2022, two SST-1M telescopes\nwere installed at the Ond\\v{r}ejov Observatory, Czech Republic, at an altitude\nof 510 meters above sea level, and have been collecting data for commissioning\nand astronomical observations since then. We present the first SST-1M\nobservations of the Crab Nebula, conducted between September 2023 and March\n2024 in both mono and stereoscopic modes. During this observation period, 46\nhours for the SST-1M-1 and 52 hours for the SST-1M-2 were collected for which\n33 hours are in stereoscopic mode. We use the Crab Nebula observation to\nvalidate the expected performance of the instrument, as evaluated by Monte\nCarlo simulations carefully tuned to account for instrumental and atmospheric\neffects. We determined that the energy threshold at the analysis level for the\nzenith angles below $30^\\circ$ is 1 TeV for mono mode and 1.3 TeV for stereo\nmode. The energy and angular resolutions are approximately 20% and $0.18^\\circ$\nfor mono mode and 10% and $0.10^\\circ$ for stereo mode, respectively. We\npresent the off-axis performance of the instrument and a detailed study of\nsystematic uncertainties. The results of a full simulation of the telescope and\nits camera is compared to the data for the first time, allowing a deep\nunderstanding of the SST-1M array performance.",
    "pdf_url": "http://arxiv.org/pdf/2506.01733v2",
    "published": "2025-06-02T14:44:02+00:00",
    "categories": [
      "astro-ph.IM",
      "astro-ph.HE"
    ],
    "primary_category": "astro-ph.IM"
  },
  {
    "id": "http://arxiv.org/abs/2506.01732v1",
    "title": "Common Corpus: The Largest Collection of Ethical Data for LLM Pre-Training",
    "authors": [
      "Pierre-Carl Langlais",
      "Carlos Rosas Hinostroza",
      "Mattia Nee",
      "Catherine Arnett",
      "Pavel Chizhov",
      "Eliot Krzystof Jones",
      "Irène Girard",
      "David Mach",
      "Anastasia Stasenko",
      "Ivan P. Yamshchikov"
    ],
    "abstract": "Large Language Models (LLMs) are pre-trained on large amounts of data from\ndifferent sources and domains. These data most often contain trillions of\ntokens with large portions of copyrighted or proprietary content, which hinders\nthe usage of such models under AI legislation. This raises the need for truly\nopen pre-training data that is compliant with the data security regulations. In\nthis paper, we introduce Common Corpus, the largest open dataset for language\nmodel pre-training. The data assembled in Common Corpus are either\nuncopyrighted or under permissible licenses and amount to about two trillion\ntokens. The dataset contains a wide variety of languages, ranging from the main\nEuropean languages to low-resource ones rarely present in pre-training\ndatasets; in addition, it includes a large portion of code data. The diversity\nof data sources in terms of covered domains and time periods opens up the paths\nfor both research and entrepreneurial needs in diverse areas of knowledge. In\nthis technical report, we present the detailed provenance of data assembling\nand the details of dataset filtering and curation. Being already used by such\nindustry leaders as Anthropic and multiple LLM training projects, we believe\nthat Common Corpus will become a critical infrastructure for open science\nresearch in LLMs.",
    "pdf_url": "http://arxiv.org/pdf/2506.01732v1",
    "published": "2025-06-02T14:43:15+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.01731v1",
    "title": "Benchmarking Neural Speech Codec Intelligibility with SITool",
    "authors": [
      "Anna Leschanowsky",
      "Kishor Kayyar Lakshminarayana",
      "Anjana Rajasekhar",
      "Lyonel Behringer",
      "Ibrahim Kilinc",
      "Guillaume Fuchs",
      "Emanuël A. P. Habets"
    ],
    "abstract": "Speech intelligibility assessment is essential for evaluating neural speech\ncodecs, yet most evaluation efforts focus on overall quality rather than\nintelligibility. Only a few publicly available tools exist for conducting\nstandardized intelligibility tests, like the Diagnostic Rhyme Test (DRT) and\nModified Rhyme Test (MRT). We introduce the Speech Intelligibility Toolkit for\nSubjective Evaluation (SITool), a Flask-based web application for conducting\nDRT and MRT in laboratory and crowdsourcing settings. We use SITool to\nbenchmark 13 neural and traditional speech codecs, analyzing phoneme-level\ndegradations and comparing subjective DRT results with objective\nintelligibility metrics. Our findings show that, while neural speech codecs can\noutperform traditional ones in subjective intelligibility, only STOI and ESTOI\n- not WER - significantly correlate with subjective results, although they\nstruggle to capture gender and wordlist-specific variations observed in\nsubjective evaluations.",
    "pdf_url": "http://arxiv.org/pdf/2506.01731v1",
    "published": "2025-06-02T14:42:50+00:00",
    "categories": [
      "eess.AS"
    ],
    "primary_category": "eess.AS"
  },
  {
    "id": "http://arxiv.org/abs/2506.01730v1",
    "title": "Electro-optic sampling of the electric-field operator for ultrabroadband pulses of Gaussian quantum light",
    "authors": [
      "Geehyun Yang",
      "Sandeep Sharma",
      "Andrey S. Moskalenko"
    ],
    "abstract": "Quantum light pulses (QLPs) can be described by spatio-temporal modes, each\nof which is associated with a quantum state. In the mid-infrared spectral\nrange, electro-optic sampling (EOS) provides a means to characterize quantum\nfluctuations in the electric field of such light pulses. Here, we present a\nprotocol based on the two-port EOS technique that enables the complete\ncharacterization of multimode Gaussian quantum light, demonstrating robustness\nto both the shot noise and cascading effects. We validate this approach\ntheoretically by reconstructing a multimode squeezed state of light generated\nin a thin nonlinear crystal driven by a single-cycle pulse. Our findings\nestablish the two-port EOS technique as a versatile tool for characterizing\nultrafast multimode quantum light, thereby broadening the reach of quantum\nstate tomography. Potential applications include the characterization of\ncomplex quantum structures, such as correlations and entanglement in light and\nmatter. Further, extensions to study multimode non-Gaussian QLPs can be\nenvisaged.",
    "pdf_url": "http://arxiv.org/pdf/2506.01730v1",
    "published": "2025-06-02T14:41:44+00:00",
    "categories": [
      "quant-ph",
      "physics.optics"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.01729v2",
    "title": "Update-Aware Robust Optimal Model Predictive Control for Nonlinear Systems",
    "authors": [
      "J. Wehbeh",
      "E. C. Kerrigan"
    ],
    "abstract": "Robust optimal or min-max model predictive control (MPC) approaches aim to\nguarantee constraint satisfaction over a known, bounded uncertainty set while\nminimizing a worst-case performance bound. Traditionally, these methods compute\na trajectory that meets the desired properties over a fixed prediction horizon,\napply a portion of the resulting input, and then re-solve the MPC problem using\nnewly obtained measurements at the next time step. However, this approach fails\nto account for the fact that the control trajectory will be updated in the\nfuture, potentially leading to conservative designs. In this paper, we present\na novel update-aware robust optimal MPC algorithm for decreasing horizon\nproblems on nonlinear systems that explicitly accounts for future control\ntrajectory updates. This additional insight allows our method to provably\nexpand the feasible solution set and guarantee improved worst-case performance\nbounds compared to existing techniques. Our approach formulates the trajectory\ngeneration problem as a sequence of nested existence-constrained semi-infinite\nprograms (SIPs), which can be efficiently solved using local reduction\ntechniques. To demonstrate its effectiveness, we evaluate our approach on a\nplanar quadrotor problem, where it clearly outperforms an equivalent method\nthat does not account for future updates at the cost of increased computation\ntime.",
    "pdf_url": "http://arxiv.org/pdf/2506.01729v2",
    "published": "2025-06-02T14:40:53+00:00",
    "categories": [
      "eess.SY",
      "cs.SY",
      "math.OC",
      "49N35 (Primary) 93B52, 93D09, 49L20 (Secondary)"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2506.01728v1",
    "title": "Principled data augmentation for learning to solve quadratic programming problems",
    "authors": [
      "Chendi Qian",
      "Christopher Morris"
    ],
    "abstract": "Linear and quadratic optimization are crucial in numerous real-world\napplications, from training machine learning models to integer-linear\noptimization. Recently, learning-to-optimize methods (L2O) for linear (LPs) or\nquadratic programs (QPs) using message-passing graph neural networks (MPNNs)\nhave gained traction, promising lightweight, data-driven proxies for solving\nsuch optimization problems. For example, they replace the costly computation of\nstrong branching scores in branch-and-bound solvers, requiring solving many\nsuch optimization problems. However, robust L2O MPNNs remain challenging in\ndata-scarce settings, especially when addressing complex optimization problems\nsuch as QPs. This work introduces a principled approach to data augmentation\ntailored for QPs via MPNNs. Our method leverages theoretically justified data\naugmentation techniques to generate diverse yet optimality-preserving\ninstances. Furthermore, we integrate these augmentations into a self-supervised\nlearning framework based on contrastive learning, thereby pretraining MPNNs for\nenhanced performance on L2O tasks. Extensive experiments demonstrate that our\napproach improves generalization in supervised scenarios and facilitates\neffective transfer learning to related optimization problems.",
    "pdf_url": "http://arxiv.org/pdf/2506.01728v1",
    "published": "2025-06-02T14:40:18+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.01727v1",
    "title": "Reaching extreme fields in laser-electron beam collisions with XUV laser light",
    "authors": [
      "Brandon K. Russell",
      "Christopher P. Ridgers",
      "Stepan S. Bulanov",
      "Kyle G. Miller",
      "Christopher Arran",
      "Thomas G. Blackburn",
      "Sergei V. Bulanov",
      "Gabriele M. Grittani",
      "John P. Palastro",
      "Qian Qian",
      "Alexander G. R. Thomas"
    ],
    "abstract": "Plasma-based particle accelerators promise to extend the revolutionary work\nperformed with conventional particle accelerators to studies with smaller\nfootprints, lower costs, and higher energies. Here, we propose a new approach\nto access an unexplored regime of strong-field quantum electrodynamics by\nplasma wakefield acceleration of both charged particles and photons. Instead of\nusing increasingly powerful accelerators and lasers, we show that photon\nacceleration of optical pulses into the extreme ultraviolet allows multi-GeV\nelectrons to reach quantum nonlinearity parameters $\\chi_e \\gg 10$ with a high\nprobability due to the reduced radiative losses. A significant fraction of\nphotons produced in high-$\\chi_e$ regions will propagate to detectors without\ngenerating pairs because of the reduction in the quantum rates. The photon\nspectra obtained may be used to characterize the predicted breakdown of\nstrong-field quantum electrodynamics theory as it enters the fully\nnon-perturbative regime.",
    "pdf_url": "http://arxiv.org/pdf/2506.01727v1",
    "published": "2025-06-02T14:37:10+00:00",
    "categories": [
      "physics.plasm-ph",
      "physics.optics"
    ],
    "primary_category": "physics.plasm-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.01726v1",
    "title": "Solving Euclidean Problems by Isotropic Initialization",
    "authors": [
      "Khusrav Yorov",
      "Bolun Wang",
      "Mikhail Skopenkov",
      "Helmut Pottmann",
      "Caigui Jiang"
    ],
    "abstract": "Many problems in Euclidean geometry, arising in computational design and\nfabrication, amount to a system of constraints, which is challenging to solve.\nWe suggest a new general approach to the solution, which is to start with\nanalogous problems in isotropic geometry. Isotropic geometry can be viewed as a\nstructure-preserving simplification of Euclidean geometry. The solutions found\nin the isotropic case give insight and can initialize optimization algorithms\nto solve the original Euclidean problems. We illustrate this general approach\nwith three examples: quad-mesh mechanisms, composite asymptotic-geodesic\ngridshells, and asymptotic gridshells with constant node angle.",
    "pdf_url": "http://arxiv.org/pdf/2506.01726v1",
    "published": "2025-06-02T14:35:51+00:00",
    "categories": [
      "cs.CG",
      "math.DG",
      "math.MG",
      "53A10, 53A40, 53A70",
      "G.2"
    ],
    "primary_category": "cs.CG"
  },
  {
    "id": "http://arxiv.org/abs/2506.01725v1",
    "title": "VideoCap-R1: Enhancing MLLMs for Video Captioning via Structured Thinking",
    "authors": [
      "Desen Meng",
      "Rui Huang",
      "Zhilin Dai",
      "Xinhao Li",
      "Yifan Xu",
      "Jun Zhang",
      "Zhenpeng Huang",
      "Meng Zhang",
      "Lingshu Zhang",
      "Yi Liu",
      "Limin Wang"
    ],
    "abstract": "While recent advances in reinforcement learning have significantly enhanced\nreasoning capabilities in large language models (LLMs), these techniques remain\nunderexplored in multi-modal LLMs for video captioning. This paper presents the\nfirst systematic investigation of GRPO-based RL post-training for video MLLMs,\nwith the goal of enhancing video MLLMs' capability of describing actions in\nvideos. Specifically, we develop the VideoCap-R1, which is prompted to first\nperform structured thinking that analyzes video subjects with their attributes\nand actions before generating complete captions, supported by two specialized\nreward mechanisms: a LLM-free think scorer evaluating the structured thinking\nquality and a LLM-assisted caption scorer assessing the output quality. The RL\ntraining framework effectively establishes the connection between structured\nreasoning and comprehensive description generation, enabling the model to\nproduce captions with more accurate actions. Our experiments demonstrate that\nVideoCap-R1 achieves substantial improvements over the Qwen2VL-7B baseline\nusing limited samples (1.5k) across multiple video caption benchmarks (DREAM1K:\n+4.4 event F1, VDC: +4.2 Acc, CAREBENCH: +3.1 action F1, +6.9 object F1) while\nconsistently outperforming the SFT-trained counterparts, confirming GRPO's\nsuperiority in enhancing MLLMs' captioning capabilities.",
    "pdf_url": "http://arxiv.org/pdf/2506.01725v1",
    "published": "2025-06-02T14:30:09+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.01724v1",
    "title": "Active Learning via Vision-Language Model Adaptation with Open Data",
    "authors": [
      "Tong Wang",
      "Jiaqi Wang",
      "Shu Kong"
    ],
    "abstract": "Pretrained on web-scale open data, VLMs offer powerful capabilities for\nsolving downstream tasks after being adapted to task-specific labeled data.\nYet, data labeling can be expensive and may demand domain expertise. Active\nLearning (AL) aims to reduce this expense by strategically selecting the most\ninformative data for labeling and model training. Recent AL methods have\nexplored VLMs but have not leveraged publicly available open data, such as\nVLM's pretraining data. In this work, we leverage such data by retrieving\ntask-relevant examples to augment the task-specific examples. As expected,\nincorporating them significantly improves AL. Given that our method exploits\nopen-source VLM and open data, we refer to it as Active Learning with Open\nResources (ALOR). Additionally, most VLM-based AL methods use prompt tuning\n(PT) for model adaptation, likely due to its ability to directly utilize\npretrained parameters and the assumption that doing so reduces the risk of\noverfitting to limited labeled data. We rigorously compare popular adaptation\napproaches, including linear probing (LP), finetuning (FT), and contrastive\ntuning (CT). We reveal two key findings: (1) All adaptation approaches benefit\nfrom incorporating retrieved data, and (2) CT resoundingly outperforms other\napproaches across AL methods. Further analysis of retrieved data reveals a\nnaturally imbalanced distribution of task-relevant classes, exposing inherent\nbiases within the VLM. This motivates our novel Tail First Sampling (TFS)\nstrategy for AL, an embarrassingly simple yet effective method that prioritizes\nsampling data from underrepresented classes to label. Extensive experiments\ndemonstrate that our final method, contrastively finetuning VLM on both\nretrieved and TFS-selected labeled data, significantly outperforms existing\nmethods.",
    "pdf_url": "http://arxiv.org/pdf/2506.01724v1",
    "published": "2025-06-02T14:30:04+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.01723v3",
    "title": "Tug-of-war between idiom's figurative and literal meanings in LLMs",
    "authors": [
      "Soyoung Oh",
      "Xinting Huang",
      "Mathis Pink",
      "Michael Hahn",
      "Vera Demberg"
    ],
    "abstract": "Idioms present a unique challenge for language models due to their\nnon-compositional figurative meanings, which often strongly diverge from the\nidiom's literal interpretation. This duality requires a model to learn\nrepresenting and deciding between the two meanings to interpret an idiom in a\nfigurative sense, or literally. In this paper, we employ tools from mechanistic\ninterpretability to trace how a large pretrained causal transformer\n(LLama3.2-1B-base) deals with this ambiguity. We localize three steps of idiom\nprocessing: First, the idiom's figurative meaning is retrieved in early\nattention and MLP sublayers. We identify specific attention heads which boost\nthe figurative meaning of the idiom while suppressing the idiom's literal\ninterpretation. The model subsequently represents the figurative representation\nthrough an intermediate path. Meanwhile, a parallel bypass route forwards\nliteral interpretation, ensuring that a both reading remain available. Overall,\nour findings provide a mechanistic evidence for idiom comprehension in an\nautoregressive transformer.",
    "pdf_url": "http://arxiv.org/pdf/2506.01723v3",
    "published": "2025-06-02T14:29:46+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.01722v1",
    "title": "When Lower-Order Terms Dominate: Adaptive Expert Algorithms for Heavy-Tailed Losses",
    "authors": [
      "Antoine Moulin",
      "Emmanuel Esposito",
      "Dirk van der Hoeven"
    ],
    "abstract": "We consider the problem setting of prediction with expert advice with\npossibly heavy-tailed losses, i.e.\\ the only assumption on the losses is an\nupper bound on their second moments, denoted by $\\theta$. We develop adaptive\nalgorithms that do not require any prior knowledge about the range or the\nsecond moment of the losses. Existing adaptive algorithms have what is\ntypically considered a lower-order term in their regret guarantees. We show\nthat this lower-order term, which is often the maximum of the losses, can\nactually dominate the regret bound in our setting. Specifically, we show that\neven with small constant $\\theta$, this lower-order term can scale as\n$\\sqrt{KT}$, where $K$ is the number of experts and $T$ is the time horizon. We\npropose adaptive algorithms with improved regret bounds that avoid the\ndependence on such a lower-order term and guarantee $\\mathcal{O}(\\sqrt{\\theta\nT\\log(K)})$ regret in the worst case, and $\\mathcal{O}(\\theta\n\\log(KT)/\\Delta_{\\min})$ regret when the losses are sampled i.i.d.\\ from some\nfixed distribution, where $\\Delta_{\\min}$ is the difference between the mean\nlosses of the second best expert and the best expert. Additionally, when the\nloss function is the squared loss, our algorithm also guarantees improved\nregret bounds over prior results.",
    "pdf_url": "http://arxiv.org/pdf/2506.01722v1",
    "published": "2025-06-02T14:29:05+00:00",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.08034v1",
    "title": "Exploring Noncommutative Polynomial Equation Methods for Discrete-Time Quaternionic Control",
    "authors": [
      "Michael Sebek"
    ],
    "abstract": "We present new polynomial-based methods for discrete-time quaternionic\nsystems, highlighting how noncommutative multiplication modifies classical\ncontrol approaches. Defining quaternionic polynomials via a backward-shift\noperator, we examine left and right fraction representations of transfer\nfunctions, showing that right zeros correspond to similarity classes of\nquaternionic matrix right eigenvalues. We then propose a feedback design\nprocedure that generalizes pole placement to quaternions - a first approach\nusing a genuine quaternionic polynomial equation.",
    "pdf_url": "http://arxiv.org/pdf/2506.08034v1",
    "published": "2025-06-02T14:28:20+00:00",
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2506.01721v2",
    "title": "Macroscopic entanglement of three magnon modes in three cavities via optical parametric amplifier",
    "authors": [
      "Ying Zhou",
      "Guo-Qiang Zhang"
    ],
    "abstract": "We propose a scheme to generate bipartite and tripartite entanglements of\nthree magnon modes in a three-cavity system using a nonlinear optical\nparametric amplifier (OPA). The three magnon modes in three YIG spheres are\nrespectively placed inside three cavities near the maximum magnetic fields of\nthe cavities and coupled to cavity modes via linear magnetic dipole\ninteraction. Additionally, linear coupling interaction exists between two\ncavities. Using experimentally feasible parameters, we demonstrate that OPA can\nprepare the three magnon modes in a steady-state entangled state, bipartite and\ntripartite entanglements increase with the nonlinear interaction strength of\nOPA. An alternative approach to enhance quantum entanglement involves\nmultiplexed OPA inputs. By employing individual OPA for each cavity, we observe\na significant improvement in entanglement generation. All the entanglements are\nrobust against bath temperature.",
    "pdf_url": "http://arxiv.org/pdf/2506.01721v2",
    "published": "2025-06-02T14:28:17+00:00",
    "categories": [
      "quant-ph",
      "J.2.9"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.01720v1",
    "title": "Simultaneous Six-way Observations from the Navy Precision Optical Interferometer",
    "authors": [
      "Ellyn K. Baines",
      "Solvay Blomquist",
      "James H. Clark III",
      "Jim Gorney",
      "Erin Maier",
      "Jason Sanborn",
      "Henrique R. Schmitt",
      "Jordan M. Stone",
      "Gerard T. van Belle",
      "Kaspar von Braun"
    ],
    "abstract": "We measured the angular diameters of six stars using the 6-element observing\nmode of the Navy Precision Optical Interferometer (NPOI) for the first time\nsince the early 2000s. Four of the diameters ranged from 1.2 mas to 1.9 mas,\nwhile the two others were much smaller at approximately 0.5 mas to 0.7 mas,\nwhich are the two smallest angular diameters measured to date with the NPOI.\nThere is a larger spread in the measurements than data obtained with 3- or 4-\nor 5-element modes, which can be attributed in part to the flux imbalance due\nto the combination of more than 2 siderostats in a single spectrograph, and\nalso to cross talk between multiple baselines related to non-linearities in the\nfast delay line dither strokes. We plan to address this in the future by using\nthe VISION beam combiner.",
    "pdf_url": "http://arxiv.org/pdf/2506.01720v1",
    "published": "2025-06-02T14:28:04+00:00",
    "categories": [
      "astro-ph.SR",
      "astro-ph.IM"
    ],
    "primary_category": "astro-ph.SR"
  },
  {
    "id": "http://arxiv.org/abs/2506.01719v2",
    "title": "Modal Verification Patterns for Systems",
    "authors": [
      "Ismail Kuru",
      "Colin S. Gordon"
    ],
    "abstract": "Although they differ in the functionality they offer, low-level systems\nexhibit certain patterns of design and utilization of computing resources. In\nthis paper, we argue the position that modalities, in the sense of modal logic,\nshould be a go-to approach when specifying and verifying low-level systems\ncode. We explain how the concept of a resource context helps guide the design\nof new modalities for verification of systems code, and we justify our\nperspective by discussing prior systems that have used modalities for systems\nverification successfully, arguing that they fit into the verification design\npattern we articulate, and explaining how this approach might apply to other\nsystems verification challenges.",
    "pdf_url": "http://arxiv.org/pdf/2506.01719v2",
    "published": "2025-06-02T14:27:05+00:00",
    "categories": [
      "cs.LO",
      "D.2.1; D.2.4; D.3.1; E.1"
    ],
    "primary_category": "cs.LO"
  },
  {
    "id": "http://arxiv.org/abs/2506.01718v1",
    "title": "Signature Maximum Mean Discrepancy Two-Sample Statistical Tests",
    "authors": [
      "Andrew Alden",
      "Blanka Horvath",
      "Zacharia Issa"
    ],
    "abstract": "Maximum Mean Discrepancy (MMD) is a widely used concept in machine learning\nresearch which has gained popularity in recent years as a highly effective tool\nfor comparing (finite-dimensional) distributions. Since it is designed as a\nkernel-based method, the MMD can be extended to path space valued distributions\nusing the signature kernel. The resulting signature MMD (sig-MMD) can be used\nto define a metric between distributions on path space. Similarly to the\noriginal use case of the MMD as a test statistic within a two-sample testing\nframework, the sig-MMD can be applied to determine if two sets of paths are\ndrawn from the same stochastic process. This work is dedicated to understanding\nthe possibilities and challenges associated with applying the sig-MMD as a\nstatistical tool in practice. We introduce and explain the sig-MMD, and provide\neasily accessible and verifiable examples for its practical use. We present\nexamples that can lead to Type 2 errors in the hypothesis test, falsely\nindicating that samples have been drawn from the same underlying process (which\ngenerally occurs in a limited data setting). We then present techniques to\nmitigate the occurrence of this type of error.",
    "pdf_url": "http://arxiv.org/pdf/2506.01718v1",
    "published": "2025-06-02T14:26:58+00:00",
    "categories": [
      "stat.ML",
      "cs.LG",
      "math.DS"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2506.01717v1",
    "title": "On combinatorial aspects of fat Delta",
    "authors": [
      "Stiéphen Pradal"
    ],
    "abstract": "The category fat Delta, introduced by J. Kock, is a modification of the\nsimplex category where the degeneracies behave weakly. The objective of this\nnote is to provide tools for working with fat Delta. In particular, we identify\nthree types of morphisms: degenerated, standard and vertical faces, and\nestablish six relations between these classes. We then show that fat Delta is\ngenerated by these morphisms and relations.",
    "pdf_url": "http://arxiv.org/pdf/2506.01717v1",
    "published": "2025-06-02T14:24:50+00:00",
    "categories": [
      "math.CT",
      "18A32 18B99"
    ],
    "primary_category": "math.CT"
  },
  {
    "id": "http://arxiv.org/abs/2506.01716v1",
    "title": "Self-Challenging Language Model Agents",
    "authors": [
      "Yifei Zhou",
      "Sergey Levine",
      "Jason Weston",
      "Xian Li",
      "Sainbayar Sukhbaatar"
    ],
    "abstract": "Large language models are quickly becoming the foundation for intelligent\nagents that are capable of using tools. However, training such agents is\nchallenging because it requires human creation and annotation of a diverse set\nof tasks, tools, and evaluation criteria. In this paper, we propose the\nSelf-Challenging framework for training an agent on high-quality tasks that are\ngenerated by itself. The agent first plays the role of challenger and generates\na task after interacting with the given tools. The tasks take the form of a\nnovel general class of problems termed Code-as-Task, which are defined by an\ninstruction, a verification function and solution and failure cases which serve\nas tests, allowing to filter only for high-quality tasks. The agent then takes\nan executor role and trains on those tasks with reinforcement learning using\nthe evaluation feedback as a reward. Evaluation on two existing multi-turn\ntool-use agent benchmarks, M3ToolEval and TauBench, shows the Self-Challenging\nframework achieves over a two-fold improvement in Llama-3.1-8B-Instruct,\ndespite using only self-generated training data.",
    "pdf_url": "http://arxiv.org/pdf/2506.01716v1",
    "published": "2025-06-02T14:23:33+00:00",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2506.01715v1",
    "title": "Optimization Strategies for Variational Quantum Algorithms in Noisy Landscapes",
    "authors": [
      "Vojtěch Novák",
      "Ivan Zelinka",
      "Václav Snášel"
    ],
    "abstract": "Variational Quantum Algorithms (VQAs) are a promising tool in the NISQ era,\nleveraging quantum computing across diverse fields. However, their performance\nis hindered by optimization challenges like local minima, barren plateaus, and\nnoise from current quantum hardware. Variational Quantum Eigensolver (VQE), a\nkey subset of VQAs, approximates molecular ground-state energies by minimizing\na Hamiltonian, enabling quantum chemistry applications. Beyond this, VQE\ncontributes to condensed matter physics by exploring quantum phase transitions\nand exotic states, and to quantum machine learning by optimizing parameterized\ncircuits for classifiers and generative models. This study systematically\nevaluates over 50 meta-heuristic optimization algorithms including\nevolution-based, swarm-based, and music-inspired methods-on their ability to\nnavigate VQE's multimodal and noisy landscapes. Using a multi-phase sieve-like\napproach, we identify the most capable optimizers and compare their performance\non a 1D Ising model (3-9 qubits). Further testing on the Hubbard model (up to\n192 parameters) reveals insights into convergence rates, effectiveness, and\nresilience under noise, offering valuable guidance for advancing optimization\nin noisy quantum environments.",
    "pdf_url": "http://arxiv.org/pdf/2506.01715v1",
    "published": "2025-06-02T14:22:30+00:00",
    "categories": [
      "quant-ph",
      "cs.NE",
      "65Kxx",
      "G.1.6"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.01714v2",
    "title": "The optimization of crop response to climatic stress through modulation of plant stress response mechanisms. Opportunities for biostimulants and plant hormones to meet climate challenges",
    "authors": [
      "Jing Li",
      "Giulia Forghieri",
      "Danny Geelen",
      "Patrick du Jardin",
      "Patrick H. Brown"
    ],
    "abstract": "Climate change is a major threat to crop potential and is characterized by\nboth long-term shifts in temperature and precipitation patterns as well as\nincreased occurrence of extreme weather events, these extreme weather events\nare the most immediate and intractable threat to agriculture. Crop resilience\nin the face of stress depends upon the speed and effectiveness with which\nplants and cropping systems sense and respond to that stress. A variety of\nagronomic practices including breeding, exogenous inputs (nutrients, water,\nbiostimulants and others) and shifts in cultivation practice have been used to\ninfluence plant stress response to achieve the goal of increased plant and\ncropping system resilience. Traditional breeding is a powerful tool that has\nresulted in stable and long-term cultivar improvements but is often too slow\nand complex to meet the diverse, complex and unpredictable challenges of\nclimate induced stresses. Increased inputs (water, nutrients, pesticides etc.)\nand management strategies (cropping system choice, soil management etc.) can\nalleviate stress but are often constrained by cost and availability of inputs.\nExogenous biostimulants, microbials and plant hormones have shown great promise\nas mechanisms to optimize natural plant resilience resulting in immediate but\nnon-permanent improvements in plant responses to climate induced stresses. The\nfailure to modernize regulatory frameworks for the use of biostimulants in\nagriculture will constrain the development of safe effective tools and deprive\ngrowers of means to respond to the vagaries of climate change. Here we discuss\nthe scientific rationale for eliminating the regulatory barriers that constrain\nthe potential for biostimulants or products that modulate plant regulatory\nnetworks to address climate change challenges and propose a framework for\nenabling legislation to strengthen cropping system resilience.",
    "pdf_url": "http://arxiv.org/pdf/2506.01714v2",
    "published": "2025-06-02T14:22:14+00:00",
    "categories": [
      "q-bio.BM",
      "q-bio.GN",
      "q-bio.MN"
    ],
    "primary_category": "q-bio.BM"
  },
  {
    "id": "http://arxiv.org/abs/2506.01713v2",
    "title": "SRPO: Enhancing Multimodal LLM Reasoning via Reflection-Aware Reinforcement Learning",
    "authors": [
      "Zhongwei Wan",
      "Zhihao Dou",
      "Che Liu",
      "Yu Zhang",
      "Dongfei Cui",
      "Qinjian Zhao",
      "Hui Shen",
      "Jing Xiong",
      "Yi Xin",
      "Yifan Jiang",
      "Chaofan Tao",
      "Yangfan He",
      "Mi Zhang",
      "Shen Yan"
    ],
    "abstract": "Multimodal large language models (MLLMs) have shown promising capabilities in\nreasoning tasks, yet still struggle with complex problems requiring explicit\nself-reflection and self-correction, especially compared to their unimodal\ntext-based counterparts. Existing reflection methods are simplistic and\nstruggle to generate meaningful and instructive feedback, as the reasoning\nability and knowledge limits of pre-trained models are largely fixed during\ninitial training. To overcome these challenges, we propose Multimodal\nSelf-Reflection enhanced reasoning with Group Relative Policy Optimization\n(SRPO), a two-stage reflection-aware reinforcement learning (RL) framework\nexplicitly designed to enhance multimodal LLM reasoning. In the first stage, we\nconstruct a high-quality, reflection-focused dataset under the guidance of an\nadvanced MLLM, which generates reflections based on initial responses to help\nthe policy model learn both reasoning and self-reflection. In the second stage,\nwe introduce a novel reward mechanism within the GRPO framework that encourages\nconcise and cognitively meaningful reflection while avoiding redundancy.\nExtensive experiments across multiple multimodal reasoning benchmarks,\nincluding MathVista, MathVision, MathVerse, and MMMU-Pro, using Qwen-2.5-VL-7B\nand Qwen-2.5-VL-32B demonstrate that SRPO significantly outperforms\nstate-of-the-art models, achieving notable improvements in both reasoning\naccuracy and reflection quality.",
    "pdf_url": "http://arxiv.org/pdf/2506.01713v2",
    "published": "2025-06-02T14:21:44+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.01712v1",
    "title": "A Vertical Approach to Designing and Managing Sustainable Heterogeneous Edge Data Centers",
    "authors": [
      "Aikaterini Maria Panteleaki",
      "Varatheepan Paramanayakam",
      "Vasileios Pentsos",
      "Andreas Karatzas",
      "Spyros Tragoudas",
      "Iraklis Anagnostopoulos"
    ],
    "abstract": "The increasing demand for Artificial Intelligence (AI) computing poses\nsignificant environmental challenges, with both operational and embodied carbon\nemissions becoming major contributors. This paper presents a carbon-aware\nholistic methodology for designing and managing sustainable Edge Data Centers\n(EDCs), based on three design principles that challenge the state-of-the-art\noptimization paradigms. Our approach employs vertical integration across the\narchitecture, system, and runtime layers, balances operational and embodied\ncarbon emissions while considering EDC performance as a co-optimization\nobjective, rather than a constraint. At the architecture level, we propose\ncarbon-aware and approximate accelerator designs to reduce embodied carbon. At\nthe system level, we enhance resource utilization and adapt to real-time carbon\nintensity variations to minimize operational emissions. Finally, at the runtime\nlevel, we develop dynamic scheduling frameworks that adjust execution, based on\nenergy constraints and carbon intensity.",
    "pdf_url": "http://arxiv.org/pdf/2506.01712v1",
    "published": "2025-06-02T14:21:25+00:00",
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2506.01711v1",
    "title": "Coalgebraic proof translations for non-wellfounded proofs",
    "authors": [
      "Borja Sierra Miranda",
      "Thomas Studer",
      "Lukas Zenger"
    ],
    "abstract": "Non-wellfounded proof theory results from allowing proofs of infinite height\nin proof theory. To guarantee that there is no vicious infinite reasoning, it\nis usual to add a constraint to the possible infinite paths appearing in a\nproof. Among these conditions, one of the simplest is enforcing that any\ninfinite path goes through the premise of a rule infinitely often. Systems of\nthis kind appear for modal logics with conversely well-founded frame conditions\nlike GL or Grz.\n  In this paper, we provide a uniform method to define proof translations for\nsuch systems, guaranteeing that the condition on infinite paths is preserved.\nIn addition, as particular instance of our method, we establish cut-elimination\nfor a non-wellfounded system of the logic Grz. Our proof relies only on the\ncategorical definition of corecursion via coalgebras, while an earlier proof by\nSavateev and Shamkanov uses ultrametric spaces and a corresponding fixed point\ntheorem.",
    "pdf_url": "http://arxiv.org/pdf/2506.01711v1",
    "published": "2025-06-02T14:19:03+00:00",
    "categories": [
      "math.LO"
    ],
    "primary_category": "math.LO"
  },
  {
    "id": "http://arxiv.org/abs/2506.01710v1",
    "title": "Reasoning-Table: Exploring Reinforcement Learning for Table Reasoning",
    "authors": [
      "Fangyu Lei",
      "Jinxiang Meng",
      "Yiming Huang",
      "Tinghong Chen",
      "Yun Zhang",
      "Shizhu He",
      "Jun Zhao",
      "Kang Liu"
    ],
    "abstract": "Table reasoning, encompassing tasks such as table question answering, fact\nverification, and text-to-SQL, requires precise understanding of structured\ntabular data, coupled with numerical computation and code manipulation for\neffective inference. Supervised fine-tuning (SFT) approaches have achieved\nnotable success but often struggle with generalization and robustness due to\nbiases inherent in imitative learning. We introduce Reasoning-Table, the first\napplication of reinforcement learning (RL) to table reasoning, achieving\nstate-of-the-art performance. Through rigorous data preprocessing, reward\ndesign, and tailored training strategies, our method leverages simple\nrule-based outcome rewards to outperform SFT across multiple benchmarks.\nUnified training across diverse tasks enables Reasoning-Table to emerge as a\nrobust table reasoning large language model, surpassing larger proprietary\nmodels like Claude-3.7-Sonnet by 4.0% on table reasoning benchmarks. The\napproach also achieves excellent performance on text-to-SQL tasks, reaching\n68.3% performance on the BIRD dev dataset with a 7B model. Further experiments\ndemonstrate that Reasoning-Table enhances the model's generalization\ncapabilities and robustness.",
    "pdf_url": "http://arxiv.org/pdf/2506.01710v1",
    "published": "2025-06-02T14:18:09+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.01709v1",
    "title": "Fairness Dynamics During Training",
    "authors": [
      "Krishna Patel",
      "Nivedha Sivakumar",
      "Barry-John Theobald",
      "Luca Zappella",
      "Nicholas Apostoloff"
    ],
    "abstract": "We investigate fairness dynamics during Large Language Model (LLM) training\nto enable the diagnoses of biases and mitigations through training\ninterventions like early stopping; we find that biases can emerge suddenly and\ndo not always follow common performance metrics. We introduce two new metrics\nto evaluate fairness dynamics holistically during model pre-training: Average\nRank and Jensen-Shannon Divergence by Parts. These metrics provide insights\ninto the Pythia models' progression of biases in gender prediction of\noccupations on the WinoBias dataset. By monitoring these dynamics, we find that\n(1) Pythia-6.9b is biased towards men; it becomes more performant and confident\npredicting \"male\" than \"female\" during training, (2) via early-stopping,\nPythia-6.9b can exchange 1.7% accuracy on LAMBADA for a 92.5% increase in\nfairness, and (3) larger models can exhibit more bias; Pythia-6.9b makes more\nassumptions about gender than Pythia-160m, even when a subject's gender is not\nspecified.",
    "pdf_url": "http://arxiv.org/pdf/2506.01709v1",
    "published": "2025-06-02T14:15:37+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.01708v2",
    "title": "Quantum Machine Learning for Predicting Anastomotic Leak: A Clinical Study",
    "authors": [
      "Vojtěch Novák",
      "Ivan Zelinka",
      "Lenka Přibylová",
      "Lubomír Martínek",
      "Vladimír Benčurik"
    ],
    "abstract": "Anastomotic leak (AL) is a life-threatening complication following colorectal\nsurgery, and its accurate prediction remains a significant clinical challenge.\nThis study explores the potential of Quantum Neural Networks (QNNs) for AL\nprediction, presenting a rigorous benchmark against hyperparameter-tuned\nclassical models including logistic regression, multilayer perceptrons, and\nboosting algorithms. Using a clinical dataset of 200 patients and four key\npredictors identified through statistical analysis, we evaluated QNNs with\nZZFeatureMap encoding and EfficientSU2 and RealAmplitudes ans\\\"atze simulated\nunder realistic hardware noise models. Our framework emphasizes robustness,\nwith performance metrics averaged over 10 independent optimization runs using\nmultiple algorithms. The EfficientSU2-BFGS combination achieved the highest\nmean AUC of $0.7966 \\pm 0.0237$, while RealAmplitudes with CMA-ES excelled in\nAverage Precision ($0.5041 \\pm 0.1214$), critical for imbalanced medical\ndatasets. We establish a direct link between optimizer convergence and model\nefficacy, where effective variational parameter optimization translates to\nimproved classification metrics. Interpretability analysis suggests QNNs may\ncapture complex, non-linear feature relationships not evident in classical\nlinear models. This work highlights QNNs' potential as screening tools while\nunderscoring the need for model selection based on specific clinical goals,\npending validation on larger datasets.",
    "pdf_url": "http://arxiv.org/pdf/2506.01708v2",
    "published": "2025-06-02T14:13:10+00:00",
    "categories": [
      "quant-ph",
      "68T05",
      "I.2.6"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.01707v1",
    "title": "On some modifications of the Niemytzki plane",
    "authors": [
      "Wojciech Bielas"
    ],
    "abstract": "We present a criterion that compares modifications of the Niemytzki plane. It\nfollows that if usual tangent discs of the Niemytzki plane are replaced by\ntriangles with bounded angles, then the resulting space is not homeomorphic to\nthe former.",
    "pdf_url": "http://arxiv.org/pdf/2506.01707v1",
    "published": "2025-06-02T14:11:32+00:00",
    "categories": [
      "math.GN",
      "Primary 54C30, 54G20, Secondary 54D70, 26A24"
    ],
    "primary_category": "math.GN"
  },
  {
    "id": "http://arxiv.org/abs/2506.01706v1",
    "title": "Jacob's ladders, E. C. Titchmarsh's hypothesis (1934) and new $ζ$-equivalents of the Fermat-Wiles theorem or connections between Fermat's rationals and the Gram's sequence",
    "authors": [
      "Jan Moser"
    ],
    "abstract": "In connection of our proof (1980) of the Titchmarsh's hypothesis (1934), we\nhave obtained two asymptotic formulae (1991). In this paper we obtain three new\n$\\zeta$-equivalents of the Fermat-Wiles theorem based on the mentioned\nasymptotic formulae.",
    "pdf_url": "http://arxiv.org/pdf/2506.01706v1",
    "published": "2025-06-02T14:11:27+00:00",
    "categories": [
      "math.NT"
    ],
    "primary_category": "math.NT"
  },
  {
    "id": "http://arxiv.org/abs/2506.01705v2",
    "title": "SPOT-Trip: Dual-Preference Driven Out-of-Town Trip Recommendation",
    "authors": [
      "Yinghui Liu",
      "Hao Miao",
      "Guojiang Shen",
      "Yan Zhao",
      "Xiangjie Kong",
      "Ivan Lee"
    ],
    "abstract": "Out-of-town trip recommendation aims to generate a sequence of Points of\nInterest (POIs) for users traveling from their hometowns to previously\nunvisited regions based on personalized itineraries, e.g., origin, destination,\nand trip duration. Modeling the complex user preferences--which often exhibit a\ntwo-fold nature of static and dynamic interests--is critical for effective\nrecommendations. However, the sparsity of out-of-town check-in data presents\nsignificant challenges in capturing such user preferences. Meanwhile, existing\nmethods often conflate the static and dynamic preferences, resulting in\nsuboptimal performance. In this paper, we for the first time systematically\nstudy the problem of out-of-town trip recommendation. A novel framework\nSPOT-Trip is proposed to explicitly learns the dual static-dynamic user\npreferences. Specifically, to handle scarce data, we construct a POI attribute\nknowledge graph to enrich the semantic modeling of users' hometown and\nout-of-town check-ins, enabling the static preference modeling through\nattribute relation-aware aggregation. Then, we employ neural ordinary\ndifferential equations (ODEs) to capture the continuous evolution of latent\ndynamic user preferences and innovatively combine a temporal point process to\ndescribe the instantaneous probability of each preference behavior. Further, a\nstatic-dynamic fusion module is proposed to merge the learned static and\ndynamic user preferences. Extensive experiments on real data offer insight into\nthe effectiveness of the proposed solutions, showing that SPOT-Trip achieves\nperformance improvement by up to 17.01%.",
    "pdf_url": "http://arxiv.org/pdf/2506.01705v2",
    "published": "2025-06-02T14:11:21+00:00",
    "categories": [
      "cs.IR"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2506.01704v1",
    "title": "Generate, Not Recommend: Personalized Multimodal Content Generation",
    "authors": [
      "Jiongnan Liu",
      "Zhicheng Dou",
      "Ning Hu",
      "Chenyan Xiong"
    ],
    "abstract": "To address the challenge of information overload from massive web contents,\nrecommender systems are widely applied to retrieve and present personalized\nresults for users. However, recommendation tasks are inherently constrained to\nfiltering existing items and lack the ability to generate novel concepts,\nlimiting their capacity to fully satisfy user demands and preferences. In this\npaper, we propose a new paradigm that goes beyond content filtering and\nselecting: directly generating personalized items in a multimodal form, such as\nimages, tailored to individual users. To accomplish this, we leverage\nany-to-any Large Multimodal Models (LMMs) and train them in both supervised\nfine-tuning and online reinforcement learning strategy to equip them with the\nability to yield tailored next items for users. Experiments on two benchmark\ndatasets and user study confirm the efficacy of the proposed method. Notably,\nthe generated images not only align well with users' historical preferences but\nalso exhibit relevance to their potential future interests.",
    "pdf_url": "http://arxiv.org/pdf/2506.01704v1",
    "published": "2025-06-02T14:10:08+00:00",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2506.01703v1",
    "title": "Understanding synchronization between quantum self-sustained oscillators through coherence generation",
    "authors": [
      "Mohit Kumar",
      "Bijay Kumar Agarwalla"
    ],
    "abstract": "Understanding the origin of phase synchronization between quantum\nself-sustained oscillators has garnered significant interest in recent years.\nIn this work, we study phase synchronization in three settings: between two\ncontinuous-variable oscillators, between two arbitrary quantum spins, and\nwithin a hybrid setup involving a spin and an oscillator. We derive a simple\nand general condition on the elements of the joint density matrix that must be\nsatisfied for them to contribute to the relative phase distribution. In\nparticular, we identify the subset of coherence elements in the joint density\nmatrix that serve as key resources for enabling quantum phase synchronization.\nOur theory is validated against the previously proposed interaction models\nknown to induce synchronization between the self-sustained oscillators.\nMoreover, our approach offers valuable insights into the relationship between\nphase synchronization and various information-theoretic measures.",
    "pdf_url": "http://arxiv.org/pdf/2506.01703v1",
    "published": "2025-06-02T14:08:20+00:00",
    "categories": [
      "quant-ph",
      "cond-mat.mes-hall"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.01702v1",
    "title": "mdok of KInIT: Robustly Fine-tuned LLM for Binary and Multiclass AI-Generated Text Detection",
    "authors": [
      "Dominik Macko"
    ],
    "abstract": "The large language models (LLMs) are able to generate high-quality texts in\nmultiple languages. Such texts are often not recognizable by humans as\ngenerated, and therefore present a potential of LLMs for misuse (e.g.,\nplagiarism, spams, disinformation spreading). An automated detection is able to\nassist humans to indicate the machine-generated texts; however, its robustness\nto out-of-distribution data is still challenging. This notebook describes our\nmdok approach in robust detection, based on fine-tuning smaller LLMs for text\nclassification. It is applied to both subtasks of Voight-Kampff Generative AI\nDetection 2025, providing remarkable performance in binary detection as well as\nin multiclass (1st rank) classification of various cases of human-AI\ncollaboration.",
    "pdf_url": "http://arxiv.org/pdf/2506.01702v1",
    "published": "2025-06-02T14:07:32+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.08033v3",
    "title": "Feasibility Study of CNNs and MLPs for Radiation Heat Transfer in 2-D Furnaces with Spectrally Participative Gases",
    "authors": [
      "Axel TahmasebiMoradi",
      "Vincent Ren",
      "Benjamin Le-Creurer",
      "Chetra Mang",
      "Mouadh Yagoubi"
    ],
    "abstract": "Aiming to reduce the computational cost of numerical simulations, a\nconvolutional neural network (CNN) and a multi-layer perceptron (MLP) are\nintroduced to build a surrogate model to approximate radiative heat transfer\nsolutions in a 2-D walled domain with participative gases. The originality of\nthis work lays in the adaptation of the inputs of the problem (gas and wall\nproperties) in order to fit with the CNN architecture, more commonly used for\nimage processing. Two precision datasets have been created with the classical\nsolver, ICARUS2D, that uses the discrete transfer radiation method with the\nstatistical narrow bands model. The performance of the CNN architecture is\ncompared to a more classical MLP architecture in terms of speed and accuracy.\nThanks to Optuna, all results are obtained using the optimized hyper parameters\nnetworks. The results show a significant speedup with industrially acceptable\nrelative errors compared to the classical solver for both architectures.\nAdditionally, the CNN outperforms the MLP in terms of precision and is more\nrobust and stable to changes in hyper-parameters. A performance analysis on the\ndataset size of the samples have also been carried out to gain a deeper\nunderstanding of the model behavior.",
    "pdf_url": "http://arxiv.org/pdf/2506.08033v3",
    "published": "2025-06-02T14:06:44+00:00",
    "categories": [
      "eess.SY",
      "cs.LG",
      "cs.SY"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2506.01701v2",
    "title": "Data Pruning by Information Maximization",
    "authors": [
      "Haoru Tan",
      "Sitong Wu",
      "Wei Huang",
      "Shizhen Zhao",
      "Xiaojuan Qi"
    ],
    "abstract": "In this paper, we present InfoMax, a novel data pruning method, also known as\ncoreset selection, designed to maximize the information content of selected\nsamples while minimizing redundancy. By doing so, InfoMax enhances the overall\ninformativeness of the coreset. The information of individual samples is\nmeasured by importance scores, which capture their influence or difficulty in\nmodel learning. To quantify redundancy, we use pairwise sample similarities,\nbased on the premise that similar samples contribute similarly to the learning\nprocess. We formalize the coreset selection problem as a discrete quadratic\nprogramming (DQP) task, with the objective of maximizing the total information\ncontent, represented as the sum of individual sample contributions minus the\nredundancies introduced by similar samples within the coreset. To ensure\npractical scalability, we introduce an efficient gradient-based solver,\ncomplemented by sparsification techniques applied to the similarity matrix and\ndataset partitioning strategies. This enables InfoMax to seamlessly scale to\ndatasets with millions of samples. Extensive experiments demonstrate the\nsuperior performance of InfoMax in various data pruning tasks, including image\nclassification, vision-language pre-training, and instruction tuning for large\nlanguage models. Code is available at https://github.com/hrtan/InfoMax.",
    "pdf_url": "http://arxiv.org/pdf/2506.01701v2",
    "published": "2025-06-02T14:06:42+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.01700v1",
    "title": "Combining Different Existing Methods for Describing Steganography Hiding Methods",
    "authors": [
      "Steffen Wendzel",
      "Christian Krätzer",
      "Jana Dittmann",
      "Luca Caviglione",
      "Aleksandra Mileva",
      "Tobias Schmidbauer",
      "Claus Vielhauer",
      "Sebastian Zander"
    ],
    "abstract": "The proliferation of digital carriers that can be exploited to conceal\narbitrary data has greatly increased the number of techniques for implementing\nnetwork steganography. As a result, the literature overlaps greatly in terms of\nconcepts and terminology. Moreover, from a cybersecurity viewpoint, the same\nhiding mechanism may be perceived differently, making harder the development of\na unique defensive strategy or the definition of practices to mitigate risks\narising from the use of steganography. To mitigate these drawbacks, several\nresearchers introduced approaches that aid in the unified description of\nsteganography methods and network covert channels.\n  Understanding and combining all descriptive methods for steganography\ntechniques is a challenging but important task. For instance, researchers might\nwant to explain how malware applies a certain steganography technique or\ncategorize a novel hiding approach. Consequently, this paper aims to provide an\nintroduction to the concept of descriptive methods for steganography. The paper\nis organized in the form of a tutorial, with the main goal of explaining how\nexisting descriptions and taxonomy objects can be combined to achieve a\ndetailed categorization and description of hiding methods. To show how this can\neffectively help the research community, the paper also contains various\nreal-world examples.",
    "pdf_url": "http://arxiv.org/pdf/2506.01700v1",
    "published": "2025-06-02T14:02:54+00:00",
    "categories": [
      "cs.CR",
      "cs.NI"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2506.01699v1",
    "title": "Motivic action conjecture for Doi-Naganuma lifts",
    "authors": [
      "Aleksander Horawa",
      "Yingkun Li"
    ],
    "abstract": "We prove the motivic action conjecture for the base change to real quadratic\nfields of weight one newforms with odd, squarefree level and solvable\nprojective image.",
    "pdf_url": "http://arxiv.org/pdf/2506.01699v1",
    "published": "2025-06-02T14:02:26+00:00",
    "categories": [
      "math.NT"
    ],
    "primary_category": "math.NT"
  },
  {
    "id": "http://arxiv.org/abs/2506.01698v1",
    "title": "When LLMs Team Up: The Emergence of Collaborative Affective Computing",
    "authors": [
      "Wenna Lai",
      "Haoran Xie",
      "Guandong Xu",
      "Qing Li",
      "S. Joe Qin"
    ],
    "abstract": "Affective Computing (AC) is essential in bridging the gap between human\nemotional experiences and machine understanding. Traditionally, AC tasks in\nnatural language processing (NLP) have been approached through pipeline\narchitectures, which often suffer from structure rigidity that leads to\ninefficiencies and limited adaptability. The advent of Large Language Models\n(LLMs) has revolutionized this field by offering a unified approach to\naffective understanding and generation tasks, enhancing the potential for\ndynamic, real-time interactions. However, LLMs face cognitive limitations in\naffective reasoning, such as misinterpreting cultural nuances or contextual\nemotions, and hallucination problems in decision-making. To address these\nchallenges, recent research advocates for LLM-based collaboration systems that\nemphasize interactions among specialized models and LLMs, mimicking human-like\naffective intelligence through the synergy of emotional and rational thinking\nthat aligns with Dual Process Theory in psychology. This survey aims to provide\na comprehensive overview of LLM-based collaboration systems in AC, exploring\nfrom structured collaborations to autonomous collaborations. Specifically, it\nincludes: (1) A systematic review of existing methods, focusing on\ncollaboration strategies, mechanisms, key functions, and applications; (2)\nExperimental comparisons of collaboration strategies across representative\ntasks in affective understanding and generation; (3) An analysis highlighting\nthe potential of these systems to enhance robustness and adaptability in\ncomplex affective reasoning; (4) A discussion of key challenges and future\nresearch directions to further advance the field. This work is the first to\nsystematically explore collaborative intelligence with LLMs in AC, paving the\nway for more powerful applications that approach human-like social\nintelligence.",
    "pdf_url": "http://arxiv.org/pdf/2506.01698v1",
    "published": "2025-06-02T14:00:54+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.02089v3",
    "title": "SALAD: Systematic Assessment of Machine Unlearning on LLM-Aided Hardware Design",
    "authors": [
      "Zeng Wang",
      "Minghao Shao",
      "Rupesh Karn",
      "Likhitha Mankali",
      "Jitendra Bhandari",
      "Ramesh Karri",
      "Ozgur Sinanoglu",
      "Muhammad Shafique",
      "Johann Knechtel"
    ],
    "abstract": "Large Language Models (LLMs) offer transformative capabilities for hardware\ndesign automation, particularly in Verilog code generation. However, they also\npose significant data security challenges, including Verilog evaluation data\ncontamination, intellectual property (IP) design leakage, and the risk of\nmalicious Verilog generation. We introduce SALAD, a comprehensive assessment\nthat leverages machine unlearning to mitigate these threats. Our approach\nenables the selective removal of contaminated benchmarks, sensitive IP and\ndesign artifacts, or malicious code patterns from pre-trained LLMs, all without\nrequiring full retraining. Through detailed case studies, we demonstrate how\nmachine unlearning techniques effectively reduce data security risks in\nLLM-aided hardware design.",
    "pdf_url": "http://arxiv.org/pdf/2506.02089v3",
    "published": "2025-06-02T13:59:08+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.01697v1",
    "title": "Strain-Induced Modulation of Spin Splitting and Persistent Spin Textures in Low-Symmetry 2D Hybrid Perovskites: A case study of RP phase",
    "authors": [
      "Shantanu Pathak",
      "Saswata Bhattacharya"
    ],
    "abstract": "We report the observation of a persistent spin texture (PST) in pseudo-2D\nhybrid perovskite, characterized by significant spin splitting strength on the\norder of \\(3 \\, \\text{eV} \\cdot \\text{\\AA}\\). Using first-principles density\nfunctional theory (DFT) calculations, complemented by a \\(\\mathbf{k} \\cdot\n\\mathbf{p}\\) model analysis, we validate the presence of PST and its robustness\nunder various conditions. The material's non-centrosymmetric nature and strong\nspin-orbit coupling ensure uniform spin orientation in momentum space, enabling\nlong spin lifetimes and promising spintronic applications. Furthermore, we\ndemonstrate the tunability of the spin splitting via the application of\nexternal strain and stress, offering a versatile approach to control spin\nconfigurations. Our results highlight the potential of this perovskite system\nfor next-generation spintronic devices, where external perturbations can be\nused to precisely modulate electronic properties.",
    "pdf_url": "http://arxiv.org/pdf/2506.01697v1",
    "published": "2025-06-02T13:58:53+00:00",
    "categories": [
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2506.01696v2",
    "title": "Missing Data in Signal Processing and Machine Learning: Models, Methods and Modern Approaches",
    "authors": [
      "Alexandre Hippert-Ferrer",
      "Aude Sportisse",
      "Amirhossein Javaheri",
      "Mohammed Nabil El Korso",
      "Daniel P. Palomar"
    ],
    "abstract": "This tutorial aims to provide signal processing (SP) and machine learning\n(ML) practitioners with vital tools, in an accessible way, to answer the\nquestion: How to deal with missing data? There are many strategies to handle\nincomplete signals. In this paper, we propose to group these strategies based\non three common tasks: i) missing-data imputation, ii) estimation with missing\nvalues and iii) prediction with missing values. We focus on methodological and\nexperimental results through specific case studies on real-world applications.\nPromising and future research directions, including a better integration of\ninformative missingness, are also discussed. We hope that the proposed\nconceptual framework and the presentation of recent missing-data problems\nrelated will encourage researchers of the SP and ML communities to develop\noriginal methods and to efficiently deal with new applications involving\nmissing data.",
    "pdf_url": "http://arxiv.org/pdf/2506.01696v2",
    "published": "2025-06-02T13:58:36+00:00",
    "categories": [
      "eess.SP",
      "stat.ML"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2506.01695v1",
    "title": "Spillovers and Effect Attenuation in Firearm Policy Research in the United States",
    "authors": [
      "Lee Kennedy-Shaffer",
      "Alan Hamilton Kennedy"
    ],
    "abstract": "In the United States, firearm-related deaths and injuries are a major public\nhealth issue. Because of limited federal action, state policies are\nparticularly important, and their evaluation informs the actions of other\npolicymakers. The movement of firearms across state and local borders, however,\ncan undermine the effectiveness of these policies and have statistical\nconsequences for their empirical evaluation. This movement causes spillover and\nbypass effects of policies, wherein interventions affect nearby control states\nand the lack of intervention in nearby states reduces the effectiveness in the\nintervention states. While some causal inference methods exist to account for\nspillover effects and reduce bias, these do not necessarily align well with the\ndata available for firearm research or with the most policy-relevant estimands.\nIntegrated data infrastructure and new methods are necessary for a better\nunderstanding of the effects these policies would have if widely adopted. In\nthe meantime, appropriately understanding and interpreting effect estimates\nfrom quasi-experimental analyses is crucial for ensuring that effective\npolicies are not dismissed due to these statistical challenges.",
    "pdf_url": "http://arxiv.org/pdf/2506.01695v1",
    "published": "2025-06-02T13:57:19+00:00",
    "categories": [
      "stat.AP",
      "econ.EM",
      "62P25"
    ],
    "primary_category": "stat.AP"
  },
  {
    "id": "http://arxiv.org/abs/2506.01694v1",
    "title": "Two-stage Distributionally Robust Optimization for Cross-dock Door Design",
    "authors": [
      "Laureano F. Escudero",
      "M. Araceli Garín",
      "Aitziber Unzueta"
    ],
    "abstract": "The cross-dock door design problem consists of deciding the strip and stack\ndoors and nominal capacity of an entity under uncertainty. Inbound commodity\nflow from origin nodes is assigned to the strip doors, it is consolidated in\nthe entity, and the outbound flow is assigned to the stack ones for being\ndelivered to destination nodes, at a minimum cost. The problem combines three\nhighly computational difficulties, namely, NP-hard combinatorics, uncertainty\nin the main parameters and their probability distribution. Distributionally\nrobust optimization is considered to deal with these uncertainties. Its related\ntwo-stage mixed binary quadratic model is presented for cross-dock\nproblem-solving; the first stage decisions are related to the design of the\nentity; the second stage ones are related to the assignment of the commodity\nflow to the doors in a finite set of scenarios for the ambiguity set members.\nThe goal is to minimize the highest total cost in the ambiguity set, subject to\nthe constraint system for each of those members and the stochastic dominance\nrisk averse functional. As far as we know, the challenging problem that results\nhas not been addressed before, although its application field is a very broad\none. Given the problem-solving difficulty, a scenario cluster decomposition and\na min-max based matheuristic are proposed for obtaining lower and upper bounds,\nrespectively. A computational study validates the proposal; it overperformances\nthe straightforward use of the state-of-the-art solvers Cplex and Gurobi.",
    "pdf_url": "http://arxiv.org/pdf/2506.01694v1",
    "published": "2025-06-02T13:57:17+00:00",
    "categories": [
      "math.OC"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2506.03199v2",
    "title": "Quantum Cognition Machine Learning for Forecasting Chromosomal Instability",
    "authors": [
      "Giuseppe Di Caro",
      "Vahagn Kirakosyan",
      "Alexander G. Abanov",
      "Jerome R. Busemeyer",
      "Luca Candelori",
      "Nadine Hartmann",
      "Ernest T. Lam",
      "Kharen Musaelian",
      "Ryan Samson",
      "Harold Steinacker",
      "Dario Villani",
      "Martin T. Wells",
      "Richard J. Wenstrup",
      "Mengjia Xu"
    ],
    "abstract": "The accurate prediction of chromosomal instability from the morphology of\ncirculating tumor cells (CTCs) enables real-time detection of CTCs with high\nmetastatic potential in the context of liquid biopsy diagnostics. However, it\npresents a significant challenge due to the high dimensionality and complexity\nof single-cell digital pathology data. Here, we introduce the application of\nQuantum Cognition Machine Learning (QCML), a quantum-inspired computational\nframework, to estimate morphology-predicted chromosomal instability in CTCs\nfrom patients with metastatic breast cancer. QCML leverages quantum mechanical\nprinciples to represent data as state vectors in a Hilbert space, enabling\ncontext-aware feature modeling, dimensionality reduction, and enhanced\ngeneralization without requiring curated feature selection. QCML outperforms\nconventional machine learning methods when tested on out of sample verification\nCTCs, achieving higher accuracy in identifying predicted large-scale state\ntransitions (pLST) status from CTC-derived morphology features. These\npreliminary findings support the application of QCML as a novel machine\nlearning tool with superior performance in high-dimensional, low-sample-size\nbiomedical contexts. QCML enables the simulation of cognition-like learning for\nthe identification of biologically meaningful prediction of chromosomal\ninstability from CTC morphology, offering a novel tool for CTC classification\nin liquid biopsy.",
    "pdf_url": "http://arxiv.org/pdf/2506.03199v2",
    "published": "2025-06-02T13:55:33+00:00",
    "categories": [
      "q-bio.QM",
      "cs.LG",
      "quant-ph"
    ],
    "primary_category": "q-bio.QM"
  },
  {
    "id": "http://arxiv.org/abs/2506.01693v1",
    "title": "Analytical self-force on scalar particle in eccentric orbits around a Schwarzschild black hole",
    "authors": [
      "Salvatore Capozziello",
      "Nicola Menadeo",
      "Davide Usseglio"
    ],
    "abstract": "In this work, we analytically investigate the effects of scalar self-force\nexerted by a massless scalar field on a particle in a slightly eccentric orbit\naround a Schwarzschild black hole. By solving the Klein-Gordon equation in the\ncurved spacetime background, using a combination of post-Newtonian (PN)\nexpansion, and small-eccentricity approximation, we derive explicit expressions\nfor the self-force components at the particle location, as well as for the\nassociated energy and angular momentum fluxes. Our results are valid up to\nsixth post-Newtonian (6PN) order and fourth order in eccentricity ($e^4$). We\ncompare asymptotic fluxes with those obtained in arXiv:2401.06844 for\nscalar-tensor (ST) theories. Once that the relation between the two approaches\nhas been established, we found perfect agreement by fixing the asymptotic value\nof the scalar field in ST theory $\\phi_0 = 1$.",
    "pdf_url": "http://arxiv.org/pdf/2506.01693v1",
    "published": "2025-06-02T13:53:04+00:00",
    "categories": [
      "gr-qc",
      "hep-th"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2506.01692v1",
    "title": "A Descriptive and Normative Theory of Human Beliefs in RLHF",
    "authors": [
      "Sylee Dandekar",
      "Shripad Deshmukh",
      "Frank Chiu",
      "W. Bradley Knox",
      "Scott Niekum"
    ],
    "abstract": "Human preferences in RLHF are typically modeled as a function of the human's\nreward function or corresponding optimal state-action values. In this work, we\npropose that human beliefs about the capabilities of the agent being trained\nalso play a key role in preference generation. We examine two questions related\nto this hypothesis, one descriptive and one normative, respectively: Do human\nlabelers' beliefs about agent capabilities affect the preferences that they\nprovide? And what is the ideal set of beliefs about an agent -- and resulting\npreferences -- for humans to have? We propose a new preference model that\nincorporates human beliefs and provide a normative theory that bounds the error\non the final learned policy based on the \\textit{mismatch} between the human's\nbeliefs and an idealized set of beliefs. We then confirm via a human study that\nbeliefs about agent capabilities do, in fact, significantly affect preferences\nand can be influenced through simple interventions. Additionally, we\nempirically show through synthetic experiments that it is often suboptimal for\nhuman preference labelers to assume agent optimality. Collectively, these\nresults theoretically and empirically demonstrate how reducing the mismatch\nbetween human beliefs and agent capabilities can lead to more performant RLHF\nand point toward new best practices for RLHF practitioners.",
    "pdf_url": "http://arxiv.org/pdf/2506.01692v1",
    "published": "2025-06-02T13:52:55+00:00",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2506.01691v2",
    "title": "SteerPose: Simultaneous Extrinsic Camera Calibration and Matching from Articulation",
    "authors": [
      "Sang-Eun Lee",
      "Ko Nishino",
      "Shohei Nobuhara"
    ],
    "abstract": "Can freely moving humans or animals themselves serve as calibration targets\nfor multi-camera systems while simultaneously estimating their correspondences\nacross views? We humans can solve this problem by mentally rotating the\nobserved 2D poses and aligning them with those in the target views. Inspired by\nthis cognitive ability, we propose SteerPose, a neural network that performs\nthis rotation of 2D poses into another view. By integrating differentiable\nmatching, SteerPose simultaneously performs extrinsic camera calibration and\ncorrespondence search within a single unified framework. We also introduce a\nnovel geometric consistency loss that explicitly ensures that the estimated\nrotation and correspondences result in a valid translation estimation.\nExperimental results on diverse in-the-wild datasets of humans and animals\nvalidate the effectiveness and robustness of the proposed method. Furthermore,\nwe demonstrate that our method can reconstruct the 3D poses of novel animals in\nmulti-camera setups by leveraging off-the-shelf 2D pose estimators and our\nclass-agnostic model.",
    "pdf_url": "http://arxiv.org/pdf/2506.01691v2",
    "published": "2025-06-02T13:52:35+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.01690v1",
    "title": "Ping-pong dynamics of hyperbolic-like actions with non-simple points",
    "authors": [
      "KyeongRo Kim",
      "Michele Triestino"
    ],
    "abstract": "A hyperbolic-like group is a subgroup of $\\operatorname{Homeo}_+(S^1)$ such\nthat every non-trivial element has exactly two fixed points, one attracting and\none repelling. We investigate the ping-pong dynamics of hyperbolic-like groups,\ninspired by a conjecture of Bonatti. We show the existence of a proper\nping-pong partition for any pair of non-cyclic point stabilizers. More\nprecisely, our results explicitly provide such a ping-pong partition.",
    "pdf_url": "http://arxiv.org/pdf/2506.01690v1",
    "published": "2025-06-02T13:52:23+00:00",
    "categories": [
      "math.GT",
      "math.DS",
      "math.GR",
      "Primary: 57M60, Secondary: 37C85, 37B05"
    ],
    "primary_category": "math.GT"
  },
  {
    "id": "http://arxiv.org/abs/2506.01689v1",
    "title": "Respond Beyond Language: A Benchmark for Video Generation in Response to Realistic User Intents",
    "authors": [
      "Shuting Wang",
      "Yunqi Liu",
      "Zixin Yang",
      "Ning Hu",
      "Zhicheng Dou",
      "Chenyan Xiong"
    ],
    "abstract": "Querying generative AI models, e.g., large language models (LLMs), has become\na prevalent method for information acquisition. However, existing query-answer\ndatasets primarily focus on textual responses, making it challenging to address\ncomplex user queries that require visual demonstrations or explanations for\nbetter understanding. To bridge this gap, we construct a benchmark,\nRealVideoQuest, designed to evaluate the abilities of text-to-video (T2V)\nmodels in answering real-world, visually grounded queries. It identifies 7.5K\nreal user queries with video response intents from Chatbot-Arena and builds\n4.5K high-quality query-video pairs through a multistage video retrieval and\nrefinement process. We further develop a multi-angle evaluation system to\nassess the quality of generated video answers. Experiments indicate that\ncurrent T2V models struggle with effectively addressing real user queries,\npointing to key challenges and future research opportunities in multimodal AI.",
    "pdf_url": "http://arxiv.org/pdf/2506.01689v1",
    "published": "2025-06-02T13:52:21+00:00",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2506.01688v1",
    "title": "Hilbert Eisenstein series as Doi-Naganuma lift",
    "authors": [
      "Yingkun Li",
      "Mingkuan Zhang"
    ],
    "abstract": "In this paper, we show that incoherent Hilbert Eisenstein series for a real\nquadratic fields can be expressed as the Doi-Naganums lift of an incoherent\nEisenstein series over $\\mathbb{Q}$. As an application, we show when $N$ is odd\nand square-free, the values at Heegner points of Borcherds product on\n$X_0(N)^2$ with effective divisors are not integral units when the\ndiscriminants are sufficiently large. This generalizes a result of the first\nauthor to higher levels. In the process, we explicitly describe the\nRankin-Selberg type L-function that appeared in the work of Bruinier-Kudla-Yang\nwhen the quadratic space has signature (2, 2), and give a new construction of\nfundamental invariant vectors appearing in Weil representations of finite\nquadratic modules.",
    "pdf_url": "http://arxiv.org/pdf/2506.01688v1",
    "published": "2025-06-02T13:52:06+00:00",
    "categories": [
      "math.NT"
    ],
    "primary_category": "math.NT"
  },
  {
    "id": "http://arxiv.org/abs/2506.01687v2",
    "title": "StochasTok: Improving Fine-Grained Subword Understanding in LLMs",
    "authors": [
      "Anya Sims",
      "Thom Foster",
      "Klara Kaleb",
      "Tuan-Duy H. Nguyen",
      "Joseph Lee",
      "Jakob N. Foerster",
      "Yee Whye Teh",
      "Cong Lu"
    ],
    "abstract": "Subword-level understanding is integral to numerous tasks, including\nunderstanding multi-digit numbers, spelling mistakes, abbreviations, rhyming,\nand wordplay. Despite this, current large language models (LLMs) still often\nstruggle with seemingly simple subword-level tasks like How many 'r's in\n'strawberry'?. A key factor behind these failures is tokenization which\nobscures the fine-grained structure of words. Current alternatives, such as\ncharacter-level and dropout tokenization methods, significantly increase\ncomputational costs and provide inconsistent improvements. In this paper we\nrevisit tokenization and introduce StochasTok, a simple, efficient stochastic\ntokenization scheme that randomly splits tokens during training, allowing LLMs\nto 'see' their internal structure. Our experiments show that pretraining with\nStochasTok substantially improves LLMs' downstream performance across multiple\nsubword-level language games, including character counting, substring\nidentification, and math tasks. Furthermore, StochasTok's simplicity allows\nseamless integration at any stage of the training pipeline; and we demonstrate\nthat post-training with StochasTok can instill improved subword understanding\ninto existing pretrained models, thus avoiding costly pretraining from scratch.\nThese dramatic improvements achieved with a minimal change suggest StochasTok\nholds exciting potential when applied to larger, more capable models. Code\nopen-sourced at: https://github.com/anyasims/stochastok.",
    "pdf_url": "http://arxiv.org/pdf/2506.01687v2",
    "published": "2025-06-02T13:51:11+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.01686v2",
    "title": "A Graph Neural Network for the Era of Large Atomistic Models",
    "authors": [
      "Duo Zhang",
      "Anyang Peng",
      "Chun Cai",
      "Wentao Li",
      "Yuanchang Zhou",
      "Jinzhe Zeng",
      "Mingyu Guo",
      "Chengqian Zhang",
      "Bowen Li",
      "Hong Jiang",
      "Tong Zhu",
      "Weile Jia",
      "Linfeng Zhang",
      "Han Wang"
    ],
    "abstract": "Foundation models, or large atomistic models (LAMs), aim to universally\nrepresent the ground-state potential energy surface (PES) of atomistic systems\nas defined by density functional theory (DFT). The scaling law is pivotal in\nthe development of large models, suggesting that their generalizability in\ndownstream tasks consistently improves with increased model size, expanded\ntraining datasets, and larger computational budgets. In this study, we present\nDPA3, a multi-layer graph neural network founded on line graph series (LiGS),\ndesigned explicitly for the era of LAMs. We demonstrate that the generalization\nerror of the DPA3 model adheres to the scaling law. The scalability in the\nnumber of model parameters is attained by stacking additional layers within\nDPA3. Additionally, the model employs a dataset encoding mechanism that\ndecouples the scaling of training data size from the model size within its\nmulti-task training framework. When trained as problem-oriented potential\nenergy models, the DPA3 model exhibits superior accuracy in the majority of\nbenchmark cases, encompassing systems with diverse features, including\nmolecules, bulk materials, surface and cluster catalysts, two-dimensional\nmaterials, and battery materials. When trained as a LAM on the OpenLAM-v1\ndataset, the DPA-3.1-3M model exhibits state-of-the-art performance in the\nLAMBench benchmark suite for LAMs, demonstrating lowest overall zero-shot\ngeneralization error across 17 downstream tasks from a broad spectrum of\nresearch domains. This performance suggests superior accuracy as an\nout-of-the-box potential model, requiring minimal fine-tuning data for\ndownstream scientific applications.",
    "pdf_url": "http://arxiv.org/pdf/2506.01686v2",
    "published": "2025-06-02T13:50:22+00:00",
    "categories": [
      "physics.comp-ph"
    ],
    "primary_category": "physics.comp-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.01685v1",
    "title": "Geometry Meets Incentives: Sample-Efficient Incentivized Exploration with Linear Contexts",
    "authors": [
      "Benjamin Schiffer",
      "Mark Sellke"
    ],
    "abstract": "In the incentivized exploration model, a principal aims to explore and learn\nover time by interacting with a sequence of self-interested agents. It has been\nrecently understood that the main challenge in designing incentive-compatible\nalgorithms for this problem is to gather a moderate amount of initial data,\nafter which one can obtain near-optimal regret via posterior sampling. With\nhigh-dimensional contexts, however, this \\emph{initial exploration} phase\nrequires exponential sample complexity in some cases, which prevents efficient\nlearning unless initial data can be acquired exogenously. We show that these\nbarriers to exploration disappear under mild geometric conditions on the set of\navailable actions, in which case incentive-compatibility does not preclude\nregret-optimality. Namely, we consider the linear bandit model with actions in\nthe Euclidean unit ball, and give an incentive-compatible exploration algorithm\nwith sample complexity that scales polynomially with the dimension and other\nparameters.",
    "pdf_url": "http://arxiv.org/pdf/2506.01685v1",
    "published": "2025-06-02T13:50:00+00:00",
    "categories": [
      "cs.GT",
      "cs.LG"
    ],
    "primary_category": "cs.GT"
  },
  {
    "id": "http://arxiv.org/abs/2506.01684v2",
    "title": "On the original Ulam's problem and its quantization",
    "authors": [
      "Changguang Dong",
      "Jing Zhou"
    ],
    "abstract": "In this paper we show that under general resonance the classical piecewise\nlinear Fermi-Ulam accelerator behaves substantially different from its\nquantization in the sense that the classical accelerator exhibits typical\nrecurrence and non-escaping while the quantum version enjoys quadratic energy\ngrowth in general. We also describe a procedure to locate the escaping orbits,\nthough exceptionally rare in the infinite-volume phase space, for the classical\naccelerators, which in particular include Ulam's very original proposal and the\nlinearly escaping orbits therein in the existing literature, and hence provide\na complete (modulo a null set) answer to Ulam's original question. For the\nquantum accelerators, we reveal under resonance the direct and explicit\nconnection between the energy growth and the shape of the quasi-energy spectra.",
    "pdf_url": "http://arxiv.org/pdf/2506.01684v2",
    "published": "2025-06-02T13:49:54+00:00",
    "categories": [
      "math.DS",
      "math-ph",
      "math.MP",
      "quant-ph",
      "37N05, 81Q50 (Primary), 35Q41, 37E10 (Secondary)"
    ],
    "primary_category": "math.DS"
  },
  {
    "id": "http://arxiv.org/abs/2506.01683v1",
    "title": "Reasoning-Based Approach with Chain-of-Thought for Alzheimer's Detection Using Speech and Large Language Models",
    "authors": [
      "Chanwoo Park",
      "Anna Seo Gyeong Choi",
      "Sunghye Cho",
      "Chanwoo Kim"
    ],
    "abstract": "Societies worldwide are rapidly entering a super-aged era, making elderly\nhealth a pressing concern. The aging population is increasing the burden on\nnational economies and households. Dementia cases are rising significantly with\nthis demographic shift. Recent research using voice-based models and large\nlanguage models (LLM) offers new possibilities for dementia diagnosis and\ntreatment. Our Chain-of-Thought (CoT) reasoning method combines speech and\nlanguage models. The process starts with automatic speech recognition to\nconvert speech to text. We add a linear layer to an LLM for Alzheimer's disease\n(AD) and non-AD classification, using supervised fine-tuning (SFT) with CoT\nreasoning and cues. This approach showed an 16.7% relative performance\nimprovement compared to methods without CoT prompt reasoning. To the best of\nour knowledge, our proposed method achieved state-of-the-art performance in CoT\napproaches.",
    "pdf_url": "http://arxiv.org/pdf/2506.01683v1",
    "published": "2025-06-02T13:49:48+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2506.01682v1",
    "title": "Detection of Molecular Hydrogen in a Proton Trap",
    "authors": [
      "J. Caylor",
      "R. Biswas",
      "B. Crawford",
      "M. S. Dewey",
      "N. Fomin",
      "G. L. Greene",
      "S. F. Hoogerheide",
      "J. Hungria-Negron",
      "H. P. Mumm",
      "J. S. Nico",
      "F. E. Wietfeldt",
      "D. O. Valete",
      "J. Zuchegno"
    ],
    "abstract": "One method of determining the free neutron lifetime involves the absolute\ncounting of neutrons and trapped decay protons. In such experiments, a cold\nneutron beam traverses a segmented proton trap inside a superconducting\nsolenoid while the neutron flux is continuously monitored. Protons that are\nborn within the fiducial volume of the trap are confined radially by the\nmagnetic field and axially by the electrostatic potential supplied by trap\nelectrodes. They are periodically released and counted, and the ratio of the\nabsolute number of neutrons to protons is proportional to the neutron lifetime.\nSystematic error can be introduced if protons in the trap are lost, gained, or\nmisidentified. The influence of molecular hydrogen interactions is of\nparticular interest because of its ubiquitous presence in ultrahigh vacuum\nsystems. To understand how it could affect the neutron lifetime, measurements\nwere performed on the production and detection of molecular hydrogen in an\napparatus used to measure the neutron lifetime. We demonstrate that charge\nexchange with molecular hydrogen can occur with trapped protons, and we\ndetermine the efficiency with which the molecular hydrogen ions in the trap are\ndetected. Finally, we comment on the potential impact on a neutron lifetime\nexperiment using this beam technique. We find that the result of the beam\nneutron lifetime performed at NIST is unlikely to have been significantly\naffected by charge exchange with molecular hydrogen.",
    "pdf_url": "http://arxiv.org/pdf/2506.01682v1",
    "published": "2025-06-02T13:49:15+00:00",
    "categories": [
      "nucl-ex"
    ],
    "primary_category": "nucl-ex"
  },
  {
    "id": "http://arxiv.org/abs/2506.01681v1",
    "title": "Lipschitz-Free Mirror Descent Methods for Non-Smooth Optimization Problems",
    "authors": [
      "Bowen Yuan",
      "Mohammad S. Alkousa"
    ],
    "abstract": "The part of the analysis of the convergence rate of the mirror descent method\nthat is connected with the adaptive time-varying step size rules due to Alkousa\net al. (MOTOR 2024, pp. 3-18) is corrected. Moreover, a Lipschitz-free mirror\ndescent method that achieves weak ergodic convergence is presented,\ngeneralizing the convergence results of the mirror descent method in the\nabsence of the Lipschitz assumption.",
    "pdf_url": "http://arxiv.org/pdf/2506.01681v1",
    "published": "2025-06-02T13:49:02+00:00",
    "categories": [
      "math.OC"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2506.01680v1",
    "title": "Visualizing strongly focused 3D light fields in an atomic vapor",
    "authors": [
      "Sphinx Svensson",
      "Clare R. Higgins",
      "Danielle Pizzey",
      "Ifan G. Hughes",
      "Sonja Franke-Arnold"
    ],
    "abstract": "Structured light, when strongly focused, generates highly confined vectorial\nelectromagnetic field distributions which may feature a polarization component\nalong the optical axis. Manipulating and detecting such 3D light fields is\nchallenging, as conventional optical elements and detectors do not interact\nwith the axial polarization component. Vector light can, however, be mapped\nonto atomic polarizations, making electric dipole transitions an ideal\ncandidate to sense such 3D light configurations. Working in the hyperfine\nPaschen-Back regime, where the electric dipole transitions are spectrally\nresolved, we demonstrate direct evidence of the axial polarization component of\nstrongly focused radial light. We investigate the influence of various input\npolarization states, including radial, azimuthal, and higher-order optical\nvortices, on atomic absorption profiles. Our results confirm a clear mapping\nbetween the 3D vector light and the atomic transition strength. This work\nprovides new insights into vectorial light-matter interaction, and opens\navenues for novel quantum sensing applications.",
    "pdf_url": "http://arxiv.org/pdf/2506.01680v1",
    "published": "2025-06-02T13:48:23+00:00",
    "categories": [
      "physics.atom-ph"
    ],
    "primary_category": "physics.atom-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.01679v3",
    "title": "Neutrino pair annihilation driven jets from black-hole torus systems",
    "authors": [
      "Kyohei Kawaguchi",
      "Sho Fujibayashi",
      "Masaru Shibata"
    ],
    "abstract": "We perform axisymmetric general relativistic radiation-viscous hydrodynamics\nsimulations of black hole (BH)-torus systems with full Boltzmann Monte-Carlo\nneutrino transport to investigate the role of neutrino-antineutrino pair\nannihilation in launching relativistic outflows. Our models span a wide range\nof BH spins, torus masses, and viscosity parameters. We find that the pair\nannihilation leads to the formation of relativistic fireballs in most cases,\nexcept for those with low black-hole spin and high viscosity. The\nisotropic-equivalent energies of these outflows reach $\\lesssim 10^{51}\\,{\\rm\nerg}$ with durations $\\lesssim 0.2\\,{\\rm s}$. While this is insufficient to\nexplain the brightest short gamma-ray bursts (sGRBs), our results suggest that\nthe pair annihilation may account for some low-luminosity sGRBs and GRB\nprecursors. We also provide updated scaling relations for the pair annihilation\nenergy deposition rate as a function of accretion rate, and discuss the\nsensitivity of outflow properties to numerical resolution and floor density.",
    "pdf_url": "http://arxiv.org/pdf/2506.01679v3",
    "published": "2025-06-02T13:48:13+00:00",
    "categories": [
      "astro-ph.HE",
      "gr-qc"
    ],
    "primary_category": "astro-ph.HE"
  },
  {
    "id": "http://arxiv.org/abs/2506.01678v1",
    "title": "Overcoming Data Scarcity in Scanning Tunnelling Microscopy Image Segmentation",
    "authors": [
      "Nikola L. Kolev",
      "Max Trouton",
      "Filippo Federici Canova",
      "Geoff Thornton",
      "David Z. Gao",
      "Neil J. Curson",
      "Taylor J. Z. Stock"
    ],
    "abstract": "Scanning tunnelling microscopy (STM) is a powerful technique for imaging\nsurfaces with atomic resolution, providing insight into physical and chemical\nprocesses at the level of single atoms and molecules. A regular task of STM\nimage analysis is the identification and labelling of features of interest\nagainst a uniform background. Performing this manually is a labour-intensive\ntask, requiring significant human effort. To reduce this burden, we propose an\nautomated approach to the segmentation of STM images that uses both few-shot\nlearning and unsupervised learning. Our technique offers greater flexibility\ncompared to previous supervised methods; it removes the requirement for large\nmanually annotated datasets and is thus easier to adapt to an unseen surface\nwhile still maintaining a high accuracy. We demonstrate the effectiveness of\nour approach by using it to recognise atomic features on three distinct\nsurfaces: Si(001), Ge(001), and TiO$_2$(110), including adsorbed AsH$_3$\nmolecules on the silicon and germanium surfaces. Our model exhibits strong\ngeneralisation capabilities, and following initial training, can be adapted to\nunseen surfaces with as few as one additional labelled data point. This work is\na significant step towards efficient and material-agnostic, automatic\nsegmentation of STM images.",
    "pdf_url": "http://arxiv.org/pdf/2506.01678v1",
    "published": "2025-06-02T13:47:37+00:00",
    "categories": [
      "cond-mat.mtrl-sci",
      "cs.AI"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2506.01677v2",
    "title": "Compact embeddings of Bessel Potential Spaces",
    "authors": [
      "José C. Bellido",
      "Javier Cueto",
      "Guillermo García-Sáez"
    ],
    "abstract": "Bessel potential spaces have gained renewed interest due to their robust\nstructural properties and applications in fractional partial differential\nequations (PDEs). These spaces, derived through complex interpolation between\nLebesgue and Sobolev spaces, are closely related to the Riesz fractional\ngradient. Recent studies have demonstrated continuous and compact embeddings of\nBessel potential spaces into Lebesgue spaces. This paper extends these findings\nby addressing the compactness of continuous embeddings from the perspective of\nabstract interpolation theory. We present three distinct proofs, leveraging\ncompactness results, translation estimates, and the relationship between\nGagliardo and Bessel spaces. Our results provide a deeper understanding of the\nfunctional analytic properties of Bessel potential spaces and their\napplications in fractional PDEs.",
    "pdf_url": "http://arxiv.org/pdf/2506.01677v2",
    "published": "2025-06-02T13:47:00+00:00",
    "categories": [
      "math.FA",
      "math.AP"
    ],
    "primary_category": "math.FA"
  },
  {
    "id": "http://arxiv.org/abs/2506.01676v1",
    "title": "K12Vista: Exploring the Boundaries of MLLMs in K-12 Education",
    "authors": [
      "Chong Li",
      "Chenglin Zhu",
      "Tao Zhang",
      "Mingan Lin",
      "Zenan Zhou",
      "Jian Xie"
    ],
    "abstract": "Multimodal large language models have demonstrated remarkable reasoning\ncapabilities in various visual tasks. However, their abilities in K12 scenarios\nare still systematically underexplored. Previous studies suffer from various\nlimitations including narrow subject coverage, insufficient data scale, lack of\ndiversity in question types, and naive answer-centric evaluation method,\nresulting in insufficient exploration of model capabilities. To address these\ngaps, we propose K12Vista, the most comprehensive multimodal benchmark for\nChinese K12 subject knowledge understanding and reasoning to date, featuring\n33,000 questions across five core subjects from primary to high school and\nthree question types. Moreover, beyond the final outcome, we are also concerned\nwith the correctness of MLLMs' reasoning processes. For this purpose, we\nmeticulously compiles errors from MLLMs' reasoning processes and leverage an\nautomated data pipeline to construct K12-PEM-800K, the largest process\nevaluation dataset offering detailed step-by-step judgement annotations for\nMLLMs' reasoning. Subsequently, we developed K12-PEM, an advanced process\nevaluation model that integrates an overall assessment of both the reasoning\nprocess and answer correctness. Moreover, we also introduce K12-PEBench, the\nfirst high-quality, human-annotated benchmark specifically designed for\nevaluating abilities of reasoning process evaluation.Extensive experiments\nreveal that current MLLMs exhibit significant flaws when reasoning within\nK12Vista, providing critical insights for the development of more capable\nMLLMs.We open our resources at https://github.com/lichongod/K12Vista.",
    "pdf_url": "http://arxiv.org/pdf/2506.01676v1",
    "published": "2025-06-02T13:46:38+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2506.14799v2",
    "title": "Analyzing Character Representation in Media Content using Multimodal Foundation Model: Effectiveness and Trust",
    "authors": [
      "Evdoxia Taka",
      "Debadyuti Bhattacharya",
      "Joanne Garde-Hansen",
      "Sanjay Sharma",
      "Tanaya Guha"
    ],
    "abstract": "Recent advances in AI has made automated analysis of complex media content at\nscale possible while generating actionable insights regarding character\nrepresentation along such dimensions as gender and age. Past works focused on\nquantifying representation from audio/video/text using AI models, but without\nhaving the audience in the loop. We ask, even if character distribution along\ndemographic dimensions are available, how useful are those to the general\npublic? Do they actually trust the numbers generated by AI models? Our work\naddresses these open questions by proposing a new AI-based character\nrepresentation tool and performing a thorough user study. Our tool has two\ncomponents: (i) An analytics extraction model based on the Contrastive Language\nImage Pretraining (CLIP) foundation model that analyzes visual screen data to\nquantify character representation across age and gender; (ii) A visualization\ncomponent effectively designed for presenting the analytics to lay audience.\nThe user study seeks empirical evidence on the usefulness and trustworthiness\nof the AI-generated results for carefully chosen movies presented in the form\nof our visualizations. We found that participants were able to understand the\nanalytics in our visualizations, and deemed the tool `overall useful'.\nParticipants also indicated a need for more detailed visualizations to include\nmore demographic categories and contextual information of the characters.\nParticipants' trust in AI-based gender and age models is seen to be moderate to\nlow, although they were not against the use of AI in this context. Our tool\nincluding code, benchmarking, and the user study data can be found at\nhttps://github.com/debadyuti0510/Character-Representation-Media.",
    "pdf_url": "http://arxiv.org/pdf/2506.14799v2",
    "published": "2025-06-02T13:46:28+00:00",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2506.02088v1",
    "title": "Enhancing Speech Emotion Recognition with Graph-Based Multimodal Fusion and Prosodic Features for the Speech Emotion Recognition in Naturalistic Conditions Challenge at Interspeech 2025",
    "authors": [
      "Alef Iury Siqueira Ferreira",
      "Lucas Rafael Gris",
      "Alexandre Ferro Filho",
      "Lucas Ólives",
      "Daniel Ribeiro",
      "Luiz Fernando",
      "Fernanda Lustosa",
      "Rodrigo Tanaka",
      "Frederico Santos de Oliveira",
      "Arlindo Galvão Filho"
    ],
    "abstract": "Training SER models in natural, spontaneous speech is especially challenging\ndue to the subtle expression of emotions and the unpredictable nature of\nreal-world audio. In this paper, we present a robust system for the INTERSPEECH\n2025 Speech Emotion Recognition in Naturalistic Conditions Challenge, focusing\non categorical emotion recognition. Our method combines state-of-the-art audio\nmodels with text features enriched by prosodic and spectral cues. In\nparticular, we investigate the effectiveness of Fundamental Frequency (F0)\nquantization and the use of a pretrained audio tagging model. We also employ an\nensemble model to improve robustness. On the official test set, our system\nachieved a Macro F1-score of 39.79% (42.20% on validation). Our results\nunderscore the potential of these methods, and analysis of fusion techniques\nconfirmed the effectiveness of Graph Attention Networks. Our source code is\npublicly available.",
    "pdf_url": "http://arxiv.org/pdf/2506.02088v1",
    "published": "2025-06-02T13:46:02+00:00",
    "categories": [
      "cs.SD",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.SD"
  },
  {
    "id": "http://arxiv.org/abs/2506.01675v1",
    "title": "Cross-Lingual Transfer of Cultural Knowledge: An Asymmetric Phenomenon",
    "authors": [
      "Chen Zhang",
      "Zhiyuan Liao",
      "Yansong Feng"
    ],
    "abstract": "Despite substantial research efforts evaluating how well large language\nmodels~(LLMs) handle global cultural diversity, the mechanisms behind their\ncultural knowledge acquisition, particularly in multilingual settings, remain\nunclear. We study this question by investigating how cultural knowledge\ntransfers across languages during language adaptation of LLMs. We introduce an\ninterpretable framework for studying this transfer, ensuring training data\ntransparency and controlling transfer effects. Through a study of four\nnon-Anglophonic cultures, we observe bidirectional cultural transfer between\nEnglish and other high-resource languages, while low-resource languages\nprimarily transfer knowledge to English with limited reverse flow. To explain\nthis asymmetric phenomenon, we propose a frequency-based hypothesis: cultural\nknowledge appearing more frequently in the pretraining data transfers more\neasily, which is supported by empirical analysis of the training corpora.",
    "pdf_url": "http://arxiv.org/pdf/2506.01675v1",
    "published": "2025-06-02T13:45:09+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.01674v1",
    "title": "MotionSight: Boosting Fine-Grained Motion Understanding in Multimodal LLMs",
    "authors": [
      "Yipeng Du",
      "Tiehan Fan",
      "Kepan Nan",
      "Rui Xie",
      "Penghao Zhou",
      "Xiang Li",
      "Jian Yang",
      "Zhenheng Yang",
      "Ying Tai"
    ],
    "abstract": "Despite advancements in Multimodal Large Language Models (MLLMs), their\nproficiency in fine-grained video motion understanding remains critically\nlimited. They often lack inter-frame differencing and tend to average or ignore\nsubtle visual cues. Furthermore, while visual prompting has shown potential in\nstatic images, its application to video's temporal complexities, particularly\nfor fine-grained motion understanding, remains largely unexplored. We\ninvestigate whether inherent capability can be unlocked and boost MLLMs' motion\nperception and enable distinct visual signatures tailored to decouple object\nand camera motion cues. In this study, we introduce MotionSight, a novel\nzero-shot method pioneering object-centric visual spotlight and motion blur as\nvisual prompts to effectively improve fine-grained motion understanding without\ntraining. To convert this into valuable data assets, we curated MotionVid-QA,\nthe first large-scale dataset for fine-grained video motion understanding, with\nhierarchical annotations including SFT and preference data, {\\Theta}(40K) video\nclips and {\\Theta}(87K) QAs. Experiments show MotionSight achieves\nstate-of-the-art open-source performance and competitiveness with commercial\nmodels. In particular, for fine-grained motion understanding we present a novel\nzero-shot technique and a large-scale, high-quality dataset. All the code and\nannotations will be publicly available.",
    "pdf_url": "http://arxiv.org/pdf/2506.01674v1",
    "published": "2025-06-02T13:44:56+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.01673v1",
    "title": "GRAM: Generative Recommendation via Semantic-aware Multi-granular Late Fusion",
    "authors": [
      "Sunkyung Lee",
      "Minjin Choi",
      "Eunseong Choi",
      "Hye-young Kim",
      "Jongwuk Lee"
    ],
    "abstract": "Generative recommendation is an emerging paradigm that leverages the\nextensive knowledge of large language models by formulating recommendations\ninto a text-to-text generation task. However, existing studies face two key\nlimitations in (i) incorporating implicit item relationships and (ii) utilizing\nrich yet lengthy item information. To address these challenges, we propose a\nGenerative Recommender via semantic-Aware Multi-granular late fusion (GRAM),\nintroducing two synergistic innovations. First, we design semantic-to-lexical\ntranslation to encode implicit hierarchical and collaborative item\nrelationships into the vocabulary space of LLMs. Second, we present\nmulti-granular late fusion to integrate rich semantics efficiently with minimal\ninformation loss. It employs separate encoders for multi-granular prompts,\ndelaying the fusion until the decoding stage. Experiments on four benchmark\ndatasets show that GRAM outperforms eight state-of-the-art generative\nrecommendation models, achieving significant improvements of 11.5-16.0% in\nRecall@5 and 5.3-13.6% in NDCG@5. The source code is available at\nhttps://github.com/skleee/GRAM.",
    "pdf_url": "http://arxiv.org/pdf/2506.01673v1",
    "published": "2025-06-02T13:42:46+00:00",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2506.01672v1",
    "title": "Minimal Impact ControlNet: Advancing Multi-ControlNet Integration",
    "authors": [
      "Shikun Sun",
      "Min Zhou",
      "Zixuan Wang",
      "Xubin Li",
      "Tiezheng Ge",
      "Zijie Ye",
      "Xiaoyu Qin",
      "Junliang Xing",
      "Bo Zheng",
      "Jia Jia"
    ],
    "abstract": "With the advancement of diffusion models, there is a growing demand for\nhigh-quality, controllable image generation, particularly through methods that\nutilize one or multiple control signals based on ControlNet. However, in\ncurrent ControlNet training, each control is designed to influence all areas of\nan image, which can lead to conflicts when different control signals are\nexpected to manage different parts of the image in practical applications. This\nissue is especially pronounced with edge-type control conditions, where regions\nlacking boundary information often represent low-frequency signals, referred to\nas silent control signals. When combining multiple ControlNets, these silent\ncontrol signals can suppress the generation of textures in related areas,\nresulting in suboptimal outcomes. To address this problem, we propose Minimal\nImpact ControlNet. Our approach mitigates conflicts through three key\nstrategies: constructing a balanced dataset, combining and injecting feature\nsignals in a balanced manner, and addressing the asymmetry in the score\nfunction's Jacobian matrix induced by ControlNet. These improvements enhance\nthe compatibility of control signals, allowing for freer and more harmonious\ngeneration in areas with silent control signals.",
    "pdf_url": "http://arxiv.org/pdf/2506.01672v1",
    "published": "2025-06-02T13:41:43+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.01671v1",
    "title": "AIMSCheck: Leveraging LLMs for AI-Assisted Review of Modern Slavery Statements Across Jurisdictions",
    "authors": [
      "Adriana Eufrosina Bora",
      "Akshatha Arodi",
      "Duoyi Zhang",
      "Jordan Bannister",
      "Mirko Bronzi",
      "Arsene Fansi Tchango",
      "Md Abul Bashar",
      "Richi Nayak",
      "Kerrie Mengersen"
    ],
    "abstract": "Modern Slavery Acts mandate that corporations disclose their efforts to\ncombat modern slavery, aiming to enhance transparency and strengthen practices\nfor its eradication. However, verifying these statements remains challenging\ndue to their complex, diversified language and the sheer number of statements\nthat must be reviewed. The development of NLP tools to assist in this task is\nalso difficult due to a scarcity of annotated data. Furthermore, as modern\nslavery transparency legislation has been introduced in several countries, the\ngeneralizability of such tools across legal jurisdictions must be studied. To\naddress these challenges, we work with domain experts to make two key\ncontributions. First, we present AIMS.uk and AIMS.ca, newly annotated datasets\nfrom the UK and Canada to enable cross-jurisdictional evaluation. Second, we\nintroduce AIMSCheck, an end-to-end framework for compliance validation.\nAIMSCheck decomposes the compliance assessment task into three levels,\nenhancing interpretability and practical applicability. Our experiments show\nthat models trained on an Australian dataset generalize well across UK and\nCanadian jurisdictions, demonstrating the potential for broader application in\ncompliance monitoring. We release the benchmark datasets and AIMSCheck to the\npublic to advance AI-adoption in compliance assessment and drive further\nresearch in this field.",
    "pdf_url": "http://arxiv.org/pdf/2506.01671v1",
    "published": "2025-06-02T13:40:59+00:00",
    "categories": [
      "cs.CY",
      "cs.CL"
    ],
    "primary_category": "cs.CY"
  },
  {
    "id": "http://arxiv.org/abs/2506.01670v1",
    "title": "Multicontinuum splitting schemes for multiscale wave problems",
    "authors": [
      "Mohsen Alshahrani",
      "Buzheng Shan"
    ],
    "abstract": "In this work, we propose multicontinuum splitting schemes for the wave\nequation with a high-contrast coefficient, extending our previous research on\nmultiscale flow problems. The proposed approach consists of two main parts:\ndecomposing the solution space into distinct components, and designing tailored\ntime discretization schemes to enhance computational efficiency. To achieve the\ndecomposition, we employ a multicontinuum homogenization method to introduce\nphysically meaningful macroscopic variables and to separate fast and slow\ndynamics, effectively isolating contrast effects in high-contrast cases. This\ndecomposition enables the design of schemes where the fast-dynamics\n(contrast-dependent) component is treated implicitly, while the slow-dynamics\n(contrast-independent) component is handled explicitly. The idea of discrete\nenergy conservation is applied to derive the stability conditions, which are\ncontrast-independent with appropriately chosen continua. We further discuss\nstrategies for optimizing the space decomposition. These include a Rayleigh\nquotient problem involving tensors, and an alternative generalized eigenvalue\ndecomposition to reduce computational effort. Finally, various numerical\nexamples are presented to validate the accuracy and stability of our proposed\nmethod.",
    "pdf_url": "http://arxiv.org/pdf/2506.01670v1",
    "published": "2025-06-02T13:40:46+00:00",
    "categories": [
      "math.NA",
      "cs.NA"
    ],
    "primary_category": "math.NA"
  },
  {
    "id": "http://arxiv.org/abs/2506.01669v1",
    "title": "A 0.51-Approximation of Maximum Matching in Sublinear $n^{1.5}$ Time",
    "authors": [
      "Sepideh Mahabadi",
      "Mohammad Roghani",
      "Jakub Tarnawski"
    ],
    "abstract": "We study the problem of estimating the size of a maximum matching in\nsublinear time. The problem has been studied extensively in the literature and\nvarious algorithms and lower bounds are known for it. Our result is a\n$0.5109$-approximation algorithm with a running time of $\\tilde{O}(n\\sqrt{n})$.\n  All previous algorithms either provide only a marginal improvement (e.g.,\n$2^{-280}$) over the $0.5$-approximation that arises from estimating a\n\\emph{maximal} matching, or have a running time that is nearly $n^2$. Our\napproach is also arguably much simpler than other algorithms beating\n$0.5$-approximation.",
    "pdf_url": "http://arxiv.org/pdf/2506.01669v1",
    "published": "2025-06-02T13:38:55+00:00",
    "categories": [
      "cs.DS"
    ],
    "primary_category": "cs.DS"
  },
  {
    "id": "http://arxiv.org/abs/2506.01668v1",
    "title": "Small Stickers, Big Meanings: A Multilingual Sticker Semantic Understanding Dataset with a Gamified Approach",
    "authors": [
      "Heng Er Metilda Chee",
      "Jiayin Wang",
      "Zhiqiang Guo",
      "Weizhi Ma",
      "Min Zhang"
    ],
    "abstract": "Stickers, though small, are a highly condensed form of visual expression,\nubiquitous across messaging platforms and embraced by diverse cultures,\ngenders, and age groups. Despite their popularity, sticker retrieval remains an\nunderexplored task due to the significant human effort and subjectivity\ninvolved in constructing high-quality sticker query datasets. Although large\nlanguage models (LLMs) excel at general NLP tasks, they falter when confronted\nwith the nuanced, intangible, and highly specific nature of sticker query\ngeneration.\n  To address this challenge, we propose a threefold solution. First, we\nintroduce Sticktionary, a gamified annotation framework designed to gather\ndiverse, high-quality, and contextually resonant sticker queries. Second, we\npresent StickerQueries, a multilingual sticker query dataset containing 1,115\nEnglish and 615 Chinese queries, annotated by over 60 contributors across 60+\nhours. Lastly, Through extensive quantitative and qualitative evaluation, we\ndemonstrate that our approach significantly enhances query generation quality,\nretrieval accuracy, and semantic understanding in the sticker domain. To\nsupport future research, we publicly release our multilingual dataset along\nwith two fine-tuned query generation models.",
    "pdf_url": "http://arxiv.org/pdf/2506.01668v1",
    "published": "2025-06-02T13:38:45+00:00",
    "categories": [
      "cs.MM",
      "cs.IR"
    ],
    "primary_category": "cs.MM"
  },
  {
    "id": "http://arxiv.org/abs/2506.01667v1",
    "title": "EarthMind: Towards Multi-Granular and Multi-Sensor Earth Observation with Large Multimodal Models",
    "authors": [
      "Yan Shu",
      "Bin Ren",
      "Zhitong Xiong",
      "Danda Pani Paudel",
      "Luc Van Gool",
      "Begum Demir",
      "Nicu Sebe",
      "Paolo Rota"
    ],
    "abstract": "Large Multimodal Models (LMMs) have demonstrated strong performance in\nvarious vision-language tasks. However, they often struggle to comprehensively\nunderstand Earth Observation (EO) data, which is critical for monitoring the\nenvironment and the effects of human activity on it. In this work, we present\nEarthMind, a novel vision-language framework for multi-granular and\nmulti-sensor EO data understanding. EarthMind features two core components: (1)\nSpatial Attention Prompting (SAP), which reallocates attention within the LLM\nto enhance pixel-level understanding; and (2) Cross-modal Fusion, which aligns\nheterogeneous modalities into a shared space and adaptively reweighs tokens\nbased on their information density for effective fusion. To facilitate\nmulti-sensor fusion evaluation, we propose EarthMind-Bench, a comprehensive\nbenchmark with over 2,000 human-annotated multi-sensor image-question pairs,\ncovering a wide range of perception and reasoning tasks. Extensive experiments\ndemonstrate the effectiveness of EarthMind. It achieves state-of-the-art\nperformance on EarthMind-Bench, surpassing GPT-4o despite being only 4B in\nscale. Moreover, EarthMind outperforms existing methods on multiple public EO\nbenchmarks, showcasing its potential to handle both multi-granular and\nmulti-sensor challenges in a unified framework.",
    "pdf_url": "http://arxiv.org/pdf/2506.01667v1",
    "published": "2025-06-02T13:36:05+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.01666v1",
    "title": "Synthesis of discrete-continuous quantum circuits with multimodal diffusion models",
    "authors": [
      "Florian Fürrutter",
      "Zohim Chandani",
      "Ikko Hamamura",
      "Hans J. Briegel",
      "Gorka Muñoz-Gil"
    ],
    "abstract": "Efficiently compiling quantum operations remains a major bottleneck in\nscaling quantum computing. Today's state-of-the-art methods achieve low\ncompilation error by combining search algorithms with gradient-based parameter\noptimization, but they incur long runtimes and require multiple calls to\nquantum hardware or expensive classical simulations, making their scaling\nprohibitive. Recently, machine-learning models have emerged as an alternative,\nthough they are currently restricted to discrete gate sets. Here, we introduce\na multimodal denoising diffusion model that simultaneously generates a\ncircuit's structure and its continuous parameters for compiling a target\nunitary. It leverages two independent diffusion processes, one for discrete\ngate selection and one for parameter prediction. We benchmark the model over\ndifferent experiments, analyzing the method's accuracy across varying qubit\ncounts, circuit depths, and proportions of parameterized gates. Finally, by\nexploiting its rapid circuit generation, we create large datasets of circuits\nfor particular operations and use these to extract valuable heuristics that can\nhelp us discover new insights into quantum circuit synthesis.",
    "pdf_url": "http://arxiv.org/pdf/2506.01666v1",
    "published": "2025-06-02T13:35:33+00:00",
    "categories": [
      "quant-ph",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.01665v2",
    "title": "Leveraging Analytic Gradients in Provably Safe Reinforcement Learning",
    "authors": [
      "Tim Walter",
      "Hannah Markgraf",
      "Jonathan Külz",
      "Matthias Althoff"
    ],
    "abstract": "The deployment of autonomous robots in safety-critical applications requires\nsafety guarantees. Provably safe reinforcement learning is an active field of\nresearch that aims to provide such guarantees using safeguards. These\nsafeguards should be integrated during training to reduce the sim-to-real gap.\nWhile there are several approaches for safeguarding sampling-based\nreinforcement learning, analytic gradient-based reinforcement learning often\nachieves superior performance from fewer environment interactions. However,\nthere is no safeguarding approach for this learning paradigm yet. Our work\naddresses this gap by developing the first effective safeguard for analytic\ngradient-based reinforcement learning. We analyse existing, differentiable\nsafeguards, adapt them through modified mappings and gradient formulations, and\nintegrate them with a state-of-the-art learning algorithm and a differentiable\nsimulation. Using numerical experiments on three control tasks, we evaluate how\ndifferent safeguards affect learning. The results demonstrate safeguarded\ntraining without compromising performance.",
    "pdf_url": "http://arxiv.org/pdf/2506.01665v2",
    "published": "2025-06-02T13:35:03+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.01664v1",
    "title": "On Symbol Elimination and Uniform Interpolation in Theory Extensions",
    "authors": [
      "Viorica Sofronie-Stokkermans"
    ],
    "abstract": "We define a notion of general uniform interpolant, generalizing the notions\nof cover and of uniform interpolant and identify situations in which symbol\nelimination can be used for computing general uniform interpolants. We\ninvestigate the limitations of the method we propose, and identify theory\nextensions for which the computation of general uniform interpolants can be\nreduced to symbol elimination followed by the computation of uniform\nquantifier-free interpolants in extensions with uninterpreted function symbols\nof theories allowing uniform quantifier-free interpolation.",
    "pdf_url": "http://arxiv.org/pdf/2506.01664v1",
    "published": "2025-06-02T13:32:56+00:00",
    "categories": [
      "cs.LO"
    ],
    "primary_category": "cs.LO"
  },
  {
    "id": "http://arxiv.org/abs/2506.01663v2",
    "title": "Zoom-Refine: Boosting High-Resolution Multimodal Understanding via Localized Zoom and Self-Refinement",
    "authors": [
      "Xuan Yu",
      "Dayan Guan",
      "Yanfeng Gu"
    ],
    "abstract": "Multimodal Large Language Models (MLLM) often struggle to interpret\nhigh-resolution images accurately, where fine-grained details are crucial for\ncomplex visual understanding. We introduce Zoom-Refine, a novel training-free\nmethod that enhances MLLM capabilities to address this issue. Zoom-Refine\noperates through a synergistic process of \\textit{Localized Zoom} and\n\\textit{Self-Refinement}. In the \\textit{Localized Zoom} step, Zoom-Refine\nleverages the MLLM to provide a preliminary response to an input query and\nidentifies the most task-relevant image region by predicting its bounding box\ncoordinates. During the \\textit{Self-Refinement} step, Zoom-Refine then\nintegrates fine-grained details from the high-resolution crop (identified by\n\\textit{Localized Zoom}) with its initial reasoning to re-evaluate and refine\nits preliminary response. Our method harnesses the MLLM's inherent capabilities\nfor spatial localization, contextual reasoning and comparative analysis without\nrequiring additional training or external experts. Comprehensive experiments\ndemonstrate the efficacy of Zoom-Refine on two challenging high-resolution\nmultimodal benchmarks. Code is available at\n\\href{https://github.com/xavier-yu114/Zoom-Refine}{\\color{magenta}github.com/xavier-yu114/Zoom-Refine}",
    "pdf_url": "http://arxiv.org/pdf/2506.01663v2",
    "published": "2025-06-02T13:32:35+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.01662v1",
    "title": "Explainable AI Systems Must Be Contestable: Here's How to Make It Happen",
    "authors": [
      "Catarina Moreira",
      "Anna Palatkina",
      "Dacia Braca",
      "Dylan M. Walsh",
      "Peter J. Leihn",
      "Fang Chen",
      "Nina C. Hubig"
    ],
    "abstract": "As AI regulations around the world intensify their focus on system safety,\ncontestability has become a mandatory, yet ill-defined, safeguard. In XAI,\n\"contestability\" remains an empty promise: no formal definition exists, no\nalgorithm guarantees it, and practitioners lack concrete guidance to satisfy\nregulatory requirements. Grounded in a systematic literature review, this paper\npresents the first rigorous formal definition of contestability in explainable\nAI, directly aligned with stakeholder requirements and regulatory mandates. We\nintroduce a modular framework of by-design and post-hoc mechanisms spanning\nhuman-centered interfaces, technical architectures, legal processes, and\norganizational workflows. To operationalize our framework, we propose the\nContestability Assessment Scale, a composite metric built on more than twenty\nquantitative criteria. Through multiple case studies across diverse application\ndomains, we reveal where state-of-the-art systems fall short and show how our\nframework drives targeted improvements. By converting contestability from\nregulatory theory into a practical framework, our work equips practitioners\nwith the tools to embed genuine recourse and accountability into AI systems.",
    "pdf_url": "http://arxiv.org/pdf/2506.01662v1",
    "published": "2025-06-02T13:32:05+00:00",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CY"
  },
  {
    "id": "http://arxiv.org/abs/2506.01661v1",
    "title": "Efficient fiber coupling of telecom single-photons from circular Bragg gratings",
    "authors": [
      "Nam Tran",
      "Pavel Ruchka",
      "Sara Jakovljevic",
      "Benjamin Breiholz",
      "Peter Gierß",
      "Ponraj Vijayan",
      "Carlos Eduardo Jimenez",
      "Alois Herkommer",
      "Michael Jetter",
      "Simone Luca Portalupi",
      "Harald Giessen",
      "Peter Michler"
    ],
    "abstract": "Deterministic sources of quantum light are becoming increasingly relevant in\nthe development of quantum communication, particularly in deployed fiber\nnetworks. Therefore, efficient fiber-coupled sources at telecom wavelength are\nhighly sought after. With this goal in mind, we systematically investigate the\nfiber coupling performance of quantum dots in optical resonators under three\nexperimental configurations. We quantify coupling efficiency and sensitivity to\nspatial displacement for single-mode fibers with 3D printed optics on their\ntip, and benchmark their behavior over a commercial cleaved-cut fiber and a\nstandard optical setup. The reduction of the required optical elements when\noperating with a lensed or a bare fiber allows for an increased end-to-end\nefficiency by a factor of up to 3.0 +/- 0.2 over a standard setup. For the\nperspective of realizing a mechanically stable fiber-coupled source, we\nprecisely quantify the spatial tolerance to fiber-cavity misalignment,\nobserving less than 50 % count rate drop for several micrometers displacement.\nThese results will play a key role in the future development of fiber-coupled\nsources of quantum light.",
    "pdf_url": "http://arxiv.org/pdf/2506.01661v1",
    "published": "2025-06-02T13:31:27+00:00",
    "categories": [
      "quant-ph",
      "physics.optics"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.01660v1",
    "title": "An improved lower bound for the logarithmic energy on $\\mathbb S^2$",
    "authors": [
      "Jordi Marzo"
    ],
    "abstract": "In this short note, we employ well-known results to improve the lower bound\nfor the constant associated with the linear term in the asymptotic expansion of\nthe minimal logarithmic energy on the sphere.",
    "pdf_url": "http://arxiv.org/pdf/2506.01660v1",
    "published": "2025-06-02T13:31:07+00:00",
    "categories": [
      "math.CA"
    ],
    "primary_category": "math.CA"
  },
  {
    "id": "http://arxiv.org/abs/2506.01659v1",
    "title": "Engram Memory Encoding and Retrieval: A Neurocomputational Perspective",
    "authors": [
      "Daniel Szelogowski"
    ],
    "abstract": "Despite substantial research into the biological basis of memory, the precise\nmechanisms by which experiences are encoded, stored, and retrieved in the brain\nremain incompletely understood. A growing body of evidence supports the engram\ntheory, which posits that sparse populations of neurons undergo lasting\nphysical and biochemical changes to support long-term memory. Yet, a\ncomprehensive computational framework that integrates biological findings with\nmechanistic models remains elusive. This work synthesizes insights from\ncellular neuroscience and computational modeling to address key challenges in\nengram research: how engram neurons are identified and manipulated; how\nsynaptic plasticity mechanisms contribute to stable memory traces; and how\nsparsity promotes efficient, interference-resistant representations. Relevant\ncomputational approaches -- such as sparse regularization, engram gating, and\nbiologically inspired architectures like Sparse Distributed Memory and spiking\nneural networks -- are also examined. Together, these findings suggest that\nmemory efficiency, capacity, and stability emerge from the interaction of\nplasticity and sparsity constraints. By integrating neurobiological and\ncomputational perspectives, this paper provides a comprehensive theoretical\nfoundation for engram research and proposes a roadmap for future inquiry into\nthe mechanisms underlying memory, with implications for the diagnosis and\ntreatment of memory-related disorders.",
    "pdf_url": "http://arxiv.org/pdf/2506.01659v1",
    "published": "2025-06-02T13:30:39+00:00",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.IR",
      "cs.LG",
      "q-bio.NC",
      "I.2.0; I.2.4; I.2.6; I.2.m; E.1; E.2; E.4; H.3; J.3; J.4"
    ],
    "primary_category": "cs.NE"
  },
  {
    "id": "http://arxiv.org/abs/2506.01658v1",
    "title": "An Efficient and Interpretable Autoregressive Model for High-Dimensional Tensor-Valued Time Series",
    "authors": [
      "Yuxi Cai",
      "Lan Li",
      "Yize Wang",
      "Guodong Li"
    ],
    "abstract": "In autoregressive modeling for tensor-valued time series, Tucker\ndecomposition, when applied to the coefficient tensor, provides a clear\ninterpretation of supervised factor modeling but loses its efficiency rapidly\nwith increasing tensor order. Conversely, canonical polyadic (CP) decomposition\nmaintains efficiency but lacks a precise statistical interpretation. To attain\nboth interpretability and powerful dimension reduction, this paper proposes a\nnovel approach under the supervised factor modeling paradigm, which first uses\nCP decomposition to extract response and covariate features separately and then\nregresses response features on covariate ones. This leads to a new CP-based\nlow-rank structure for the coefficient tensor. Furthermore, to address\nheterogeneous signals or potential model misspecifications arising from\nstringent low-rank assumptions, a low-rank plus sparse model is introduced by\nincorporating an additional sparse coefficient tensor. Nonasymptotic properties\nare established for the ordinary least squares estimators, and an alternating\nleast squares algorithm is introduced for optimization. Theoretical properties\nof the proposed methodology are validated by simulation studies, and its\nenhanced prediction performance and interpretability are demonstrated by the El\nNi$\\tilde{\\text{n}}$o-Southern Oscillation example.",
    "pdf_url": "http://arxiv.org/pdf/2506.01658v1",
    "published": "2025-06-02T13:28:08+00:00",
    "categories": [
      "stat.ME"
    ],
    "primary_category": "stat.ME"
  },
  {
    "id": "http://arxiv.org/abs/2506.01657v3",
    "title": "State Similarity in Modular Superconducting Quantum Processors with Classical Communications",
    "authors": [
      "Bujiao Wu",
      "Changrong Xie",
      "Peng Mi",
      "Zhiyi Wu",
      "Zechen Guo",
      "Peisheng Huang",
      "Wenhui Huang",
      "Xuandong Sun",
      "Jiawei Zhang",
      "Libo Zhang",
      "Jiawei Qiu",
      "Xiayu Linpeng",
      "Ziyu Tao",
      "Ji Chu",
      "Ji Jiang",
      "Song Liu",
      "Jingjing Niu",
      "Yuxuan Zhou",
      "Yuxuan Du",
      "Wenhui Ren",
      "Youpeng Zhong",
      "Tongliang Liu",
      "Dapeng Yu"
    ],
    "abstract": "As quantum devices continue to scale, distributed quantum computing emerges\nas a promising strategy for executing large-scale tasks across modular quantum\nprocessors. A central challenge in this paradigm is verifying the correctness\nof computational outcomes when subcircuits are executed independently following\ncircuit cutting. Here we propose a cross-platform fidelity estimation algorithm\ntailored for modular architectures. Our method achieves substantial reductions\nin sample complexity compared to previous approaches designed for\nsingle-processor systems. We experimentally implement the protocol on modular\nsuperconducting quantum processors with up to 6 qubits to verify the similarity\nof two 11-qubit GHZ states. Beyond verification, we show that our algorithm\nenables a federated quantum kernel method that preserves data privacy. As a\nproof of concept, we apply it to a 5-qubit quantum phase learning task using\nsix 3-qubit modules, successfully extracting phase information with just eight\ntraining samples. These results establish a practical path for scalable\nverification and trustworthy quantum machine learning of modular quantum\nprocessors.",
    "pdf_url": "http://arxiv.org/pdf/2506.01657v3",
    "published": "2025-06-02T13:27:38+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.01656v2",
    "title": "Mixture of Experts Provably Detect and Learn the Latent Cluster Structure in Gradient-Based Learning",
    "authors": [
      "Ryotaro Kawata",
      "Kohsei Matsutani",
      "Yuri Kinoshita",
      "Naoki Nishikawa",
      "Taiji Suzuki"
    ],
    "abstract": "Mixture of Experts (MoE), an ensemble of specialized models equipped with a\nrouter that dynamically distributes each input to appropriate experts, has\nachieved successful results in the field of machine learning. However,\ntheoretical understanding of this architecture is falling behind due to its\ninherent complexity. In this paper, we theoretically study the sample and\nruntime complexity of MoE following the stochastic gradient descent (SGD) when\nlearning a regression task with an underlying cluster structure of single index\nmodels. On the one hand, we prove that a vanilla neural network fails in\ndetecting such a latent organization as it can only process the problem as a\nwhole. This is intrinsically related to the concept of information exponent\nwhich is low for each cluster, but increases when we consider the entire task.\nOn the other hand, we show that a MoE succeeds in dividing this problem into\neasier subproblems by leveraging the ability of each expert to weakly recover\nthe simpler function corresponding to an individual cluster. To the best of our\nknowledge, this work is among the first to explore the benefits of the MoE\nframework by examining its SGD dynamics in the context of nonlinear regression.",
    "pdf_url": "http://arxiv.org/pdf/2506.01656v2",
    "published": "2025-06-02T13:26:44+00:00",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.01655v1",
    "title": "Self-Supervised Speech Quality Assessment (S3QA): Leveraging Speech Foundation Models for a Scalable Speech Quality Metric",
    "authors": [
      "Mattson Ogg",
      "Caitlyn Bishop",
      "Han Yi",
      "Sarah Robinson"
    ],
    "abstract": "Methods for automatically assessing speech quality are critical for many\nhuman language technologies. Behavioral ratings provided by human raters (e.g.,\nmean opinion scores; MOS) are considered the gold standard, but they are\nsusceptible to variability between individual raters, cannot easily be\ngeneralized across corpora, and are labor-intensive to collect, thus limiting\nthe acoustic challenges they can quantify. Here, we present a new, scalable\nmethod for automatically assessing speech quality: the self-supervised speech\nquality assessment (S3QA) model. First, we processed high quality utterances\nfrom multiple speech corpora, using a wide range of acoustic manipulations\nintended to emulate common sources of quality degradation in the real-world:\nfrequency filtering, reverberation, background noise, and digital compression.\nSecond, we leveraged an existing, pre-trained speech foundation model, WavLM,\nto computationally derive a self-supervised training target for the level of\nsignal degradation by calculating the cosine distances between the clean and\ndegraded versions of each utterance in the embedding space. Next, we trained a\ntransformer-based model to predict the cosine distance, or degradation index,\ngiven only the degraded versions of these utterances. Finally, the trained\nmodel was evaluated on unseen test corpora of synthetic mixtures, NISQA, and\nVOiCES. We show that the S3QA model trained on this task performs well and is\naligned with both behavioral ratings (MOS), speech technology performance\n(automatic speech recognition) and other important features of the held-out\ndata (e.g., microphone distances). This approach provides an automated,\nscalable method for assessing speech quality across a wide range of acoustic\nchallenges, and could easily be adapted to other use cases where acoustic\nsimulations are available.",
    "pdf_url": "http://arxiv.org/pdf/2506.01655v1",
    "published": "2025-06-02T13:26:07+00:00",
    "categories": [
      "eess.AS",
      "cs.SD"
    ],
    "primary_category": "eess.AS"
  },
  {
    "id": "http://arxiv.org/abs/2506.01654v1",
    "title": "Cholesky decomposition and well-posedness of Cauchy problem for Fokker-Planck equations with unbounded coefficients",
    "authors": [
      "Haesung Lee"
    ],
    "abstract": "This paper explores the well-posedness of the Cauchy problem for the\nFokker-Planck equation associated with the partial differential operator $L$\nwith low regularity condition. To address uniqueness, we apply a recently\ndeveloped superposition principle for unbounded coefficients, which reduces the\nuniqueness problem for the Fokker-Planck equation to the uniqueness of\nsolutions to the martingale problem. Using the Cholesky decomposition\nalgorithm, a standard tool in numerical linear algebra, we construct a lower\ntriangular matrix of functions $\\sigma$ with suitable regularity such that $A =\n\\sigma \\sigma^T$. This formulation allows us to connect the uniqueness of\nsolutions to the martingale problem with the uniqueness of weak solutions to\nIt\\^{o}-SDEs. For existence, we rely on established results concerning\nsub-Markovian semigroups, which enable us to confirm the existence of solutions\nto the Fokker-Planck equation under general growth conditions expressed as\ninequalities. Additionally, by imposing further growth conditions on the\ncoefficients, also expressed as inequalities, we establish the ergodicity of\nthe solutions. This work demonstrates the interplay between stochastic analysis\nand numerical linear algebra in addressing problems related to partial\ndifferential equations.",
    "pdf_url": "http://arxiv.org/pdf/2506.01654v1",
    "published": "2025-06-02T13:25:53+00:00",
    "categories": [
      "math.PR",
      "math.AP"
    ],
    "primary_category": "math.PR"
  },
  {
    "id": "http://arxiv.org/abs/2506.01653v1",
    "title": "Anomalous non-thermal fixed point in a quasi-two-dimensional dipolar Bose gas",
    "authors": [
      "Niklas Rasch",
      "Lauriane Chomaz",
      "Thomas Gasenzer"
    ],
    "abstract": "The emergence of distinctly sub-diffusive scaling in the vicinity of an\nanomalous non-thermal fixed point is discussed in a quasi-two-dimensional\ndipolar Bose gas in the superfluid phase, carrying ensembles of vortices and\nantivortices with zero net angular momentum. The observed scaling behavior\nreflects coarsening dynamics driven by the mutual annihilation of vortices and\nantivortices, with the mean inter-defect distance growing algebraically over\ntime as $\\ell_\\text{v}(t)\\sim t^{\\,\\beta}$. A sub-diffusive ($\\beta<1/2$)\nexponent $\\beta\\approx0.2$ is extracted for various parameter regimes, initial\nconditions, and dipolar configurations from both scaling occupation-number\nspectra and the evolution of inter-defect distances as well as the\ncorresponding total vortex densities. As vortex-antivortex annihilation\nprogresses, excitations of the background condensate increase. This gives rise\nto a transition in the scaling behavior at late times, toward a non-thermal\nfixed point governed by diffusion-type scaling with $\\beta\\approx1/2$ as\nexpected for the mutual annihilation of well-separated vortex-antivortex\ndipoles. While the temporal scaling with $\\beta$ does not depend significantly\non the strength and anisotropy of the dipolar interactions and thus underlines\nthe universality of the anomalous as well as diffusion-type non-thermal fixed\npoints, we find distinctly different vortex patterns resulting in the dipolar\ncase. While in the superfluid with contact interactions only, same-sign\nvortices tend to cluster and form large-scale eddies, in the dipolar and tilted\ncases, roton excitations appear to prevent such motion, giving rather rise to a\nmaximisation of distances between vortices of either sign.",
    "pdf_url": "http://arxiv.org/pdf/2506.01653v1",
    "published": "2025-06-02T13:25:38+00:00",
    "categories": [
      "cond-mat.quant-gas",
      "hep-ph"
    ],
    "primary_category": "cond-mat.quant-gas"
  },
  {
    "id": "http://arxiv.org/abs/2506.01652v2",
    "title": "Solutions with large number of peaks for a slightly supercritical nonlinear equation in dimension three",
    "authors": [
      "Yixing Pu"
    ],
    "abstract": "We investigate the existence of solutions to the semilinear equation with a\nslightly supercritical exponent in dimension three,\n  \\begin{align*}\n  -\\Delta u=K(x) u^{5+\\mu},\\quad u>0 ~\\text{in}~ \\mathbf{B}, \\quad u=0\n~\\text{on}~ \\partial \\mathbf{B},\n  \\end{align*}\n  where $\\mu >0$, $\\mathbf{B}$ is the unit ball in $\\mathbb{R}^3$, $K(x)$ is a\nnonnegative radial function under suitable condition on $K$. We prove the\nexistence of positive multi-peak solutions for $\\mu>0$ small enough. All peaks\nof our solutions approach the boundary $\\partial\\mathbf{B}$ as $\\mu\\rightarrow\n0$. Moreover, the number of peaks varies with the parameter $\\mu$ as $\\mu$ goes\nto $0^+$.\n  Note that the case $n\\geq 4$ was considered by Liu and Peng\n\\cite{LiuPeng2016}.",
    "pdf_url": "http://arxiv.org/pdf/2506.01652v2",
    "published": "2025-06-02T13:25:36+00:00",
    "categories": [
      "math.AP"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2506.01651v1",
    "title": "Non-archimedean periods for log Calabi-Yau surfaces",
    "authors": [
      "Soham Karwa",
      "Jonathan Lai"
    ],
    "abstract": "We prove the first instance of a conjecture by Kontsevich-Soibelman that the\nnon-archimedean period map recovers the analytic periods in the case of log\nCalabi-Yau surfaces. In particular, we show that the K-affine structure, a\nnatural enhancement of the singular integral affine structure on the essential\nskeleton, determines the isomorphism type of the log Calabi-Yau surface.",
    "pdf_url": "http://arxiv.org/pdf/2506.01651v1",
    "published": "2025-06-02T13:24:03+00:00",
    "categories": [
      "math.AG",
      "14J26, 14J10, 14G22, 14T90, 14C30"
    ],
    "primary_category": "math.AG"
  },
  {
    "id": "http://arxiv.org/abs/2506.01650v1",
    "title": "Pricing the Right to Renege in Search Markets: Evidence from Trucking",
    "authors": [
      "Richard Faltings"
    ],
    "abstract": "In many markets, advance interim contracts include an explicit right to\nrenege, granting one party the option to switch to more efficient matches that\nemerge later in the search process. This paper studies the formation and\nwelfare implications of such interim contracts, leveraging novel data from a\nbrokerage firm in the trucking industry. The broker allocates advance shipment\ncontracts to carriers through a dynamic auction mechanism and penalizes\ncancellations through a reputational mechanism. I develop a theoretical model\nlinking the carrier's bidding problem to the firm's cancellation penalties\nthrough a dynamic job-search problem and structurally estimate the model from\nrich data on bids and cancellations. In counterfactual simulations, I show that\nthe firm is incentivized to lower cancellation penalties as the option value of\nthe right to renege is priced into carrier bids. The results rationalize the\nlarge degree of contractual flexibility observed in the trucking industry as an\nefficient market outcome rather than one constrained by limited enforcement.",
    "pdf_url": "http://arxiv.org/pdf/2506.01650v1",
    "published": "2025-06-02T13:21:31+00:00",
    "categories": [
      "econ.GN",
      "q-fin.EC"
    ],
    "primary_category": "econ.GN"
  },
  {
    "id": "http://arxiv.org/abs/2506.01649v1",
    "title": "A Grammatical Calculus for the Ramanujan Polynomials",
    "authors": [
      "William Y. C. Chen",
      "Amy M. Fu",
      "Elena L. Wang"
    ],
    "abstract": "As remarked by Berndt, no combinatorial perspective seems to be\n  alluded in the original definition\n  of the Ramanujan polynomials. On a different scene,\n  a recursive algorithm to generate rooted\n  trees has been devised independently by\n  Shor and Dumont-Ramamonjisoa.\n  Zeng\n  discovered the connection between\n  the Ramanujan polynomials\n  and the enumeration of rooted\n  trees by number of improper edges. We present a proper labeling scheme for\n  rooted trees by employing an extra label.\n  Harnessed by this grammar, we develop a calculus heavily\n  depending on the constant properties for\n  the Ramanujan polynomials. From the\n  grammatical formulation, we recover\n  the defining equation\n  of Ramanujan on an implicit function. So the\n  two themes of Ramanujan converge to one combinatorial structure. Moreover, we\nprovide a grammatical treatment of a bijection\n  behind the recursion independently due to\n  Shor and Berndt-Evans-Wilson.",
    "pdf_url": "http://arxiv.org/pdf/2506.01649v1",
    "published": "2025-06-02T13:21:25+00:00",
    "categories": [
      "math.CO",
      "05A05, 05A15"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2506.01648v1",
    "title": "Loop current order on the kagome lattice",
    "authors": [
      "Jun Zhan",
      "Hendrik Hohmann",
      "Matteo Dürrnagel",
      "Ruiqing Fu",
      "Sen Zhou",
      "Ziqiang Wang",
      "Ronny Thomale",
      "Xianxin Wu",
      "Jiangping Hu"
    ],
    "abstract": "Recent discoveries in kagome materials have unveiled their capacity to harbor\nexotic quantum states, including intriguing charge density wave (CDW) and\nsuperconductivity. Notably, accumulating experimental evidence suggests\ntime-reversal symmetry (TRS) breaking within the CDW, hinting at the\nlong-pursued loop current order (LCO). Despite extensive research efforts,\nachieving its model realization and understanding the mechanism through\nunbiased many-body simulations have remained both elusive and challenging.In\nthis work, we develop a microscopic model for LCO on the spinless kagome\nlattice with non-local interactions, utilizing unbiased functional\nrenormalization group calculations to explore ordering tendencies across all\ntwo-particle scattering channels. At the van Hove filling, we identify\nsublattice interference to suppress onsite CDW order, leaving LCO, charge bond\nand nematic CDW state as the main competitors. Remarkably, a $2\\times2$ LCO\nemerges as the many-body ground state over a significant parameter space with\nstrong second nearest-neighbor repulsion, stemming from the unique interplay\nbetween sublattice characters and lattice geometry. The resulting electronic\nmodel with LCO bears similarities to the Haldane model and culminates in a\nquantum anomalous Hall state. We also discuss potential experimental\nimplications for kagome metals.",
    "pdf_url": "http://arxiv.org/pdf/2506.01648v1",
    "published": "2025-06-02T13:20:46+00:00",
    "categories": [
      "cond-mat.str-el",
      "cond-mat.supr-con"
    ],
    "primary_category": "cond-mat.str-el"
  },
  {
    "id": "http://arxiv.org/abs/2506.01647v1",
    "title": "Higher order spectral shift of Euclidean Callias operators",
    "authors": [
      "Oliver Fürst"
    ],
    "abstract": "We consider Dirac-Schr\\\"odinger operators over odd-dimensional Euclidean\nspace. The conditions for the potential are based on those of C. Callias in his\nfamous paper on the corresponding index problem. However, we treat the case\nwhere the potential can take values in unbounded operators of a separable\nHilbert space, and crucially, we also do not assume that the potential needs to\nbe invertible outside a compact region. Hence, the Dirac-Schr\\\"odinger operator\nis not necessarily Fredholm. In the setup we discuss, it however still admits a\nrelated trace formula in terms of the underlying potential.\n  In this paper we express the trace formula for these Callias-type operators\nin terms of higher order spectral shift functions, leading to a functional\nequation which generalizes a known functional equation found first by A.\nPushnitski.\n  To the knowledge of the author, this paper presents the first\nmulti-dimensional non-Fredholm extension of the Callias index theorem involving\nhigher order spectral shift functions. More precisely, we also show that under\na Lebesgue point condition on the higher order spectral shift function\nassociated to the potential, the Callias-type operator admits a regularized\nindex, even in non-Fredholm settings. This corresponds to a known Witten index\nresult in the one-dimensional case shown by A. Carey et al.\n  The regularized index that we introduce is a minor extension of the classical\nWitten index, and we present an index formula, which generalizes the classical\nCallias index theorem. As an example, we treat the case of $(d+1)$-massless\nDirac-Schr\\\"odinger operators, for which we calculate the associated higher\norder spectral shift functions.",
    "pdf_url": "http://arxiv.org/pdf/2506.01647v1",
    "published": "2025-06-02T13:19:19+00:00",
    "categories": [
      "math.SP",
      "math.FA",
      "47A56, 47B10, 47A53, 47A55, 35P25, 81Q10"
    ],
    "primary_category": "math.SP"
  },
  {
    "id": "http://arxiv.org/abs/2506.01646v1",
    "title": "ESGenius: Benchmarking LLMs on Environmental, Social, and Governance (ESG) and Sustainability Knowledge",
    "authors": [
      "Chaoyue He",
      "Xin Zhou",
      "Yi Wu",
      "Xinjia Yu",
      "Yan Zhang",
      "Lei Zhang",
      "Di Wang",
      "Shengfei Lyu",
      "Hong Xu",
      "Xiaoqiao Wang",
      "Wei Liu",
      "Chunyan Miao"
    ],
    "abstract": "We introduce ESGenius, a comprehensive benchmark for evaluating and enhancing\nthe proficiency of Large Language Models (LLMs) in Environmental, Social and\nGovernance (ESG) and sustainability-focused question answering. ESGenius\ncomprises two key components: (i) ESGenius-QA, a collection of 1 136\nmultiple-choice questions generated by LLMs and rigorously validated by domain\nexperts, covering a broad range of ESG pillars and sustainability topics. Each\nquestion is systematically linked to its corresponding source text, enabling\ntransparent evaluation and supporting retrieval-augmented generation (RAG)\nmethods; and (ii) ESGenius-Corpus, a meticulously curated repository of 231\nfoundational frameworks, standards, reports and recommendation documents from\nseven authoritative sources. Moreover, to fully assess the capabilities and\nadaptation potential of the model, we implement a rigorous two-stage evaluation\nprotocol -- Zero-Shot and RAG. Extensive experiments across 50 LLMs (ranging\nfrom 0.5 B to 671 B parameters) demonstrate that state-of-the-art models\nachieve only moderate performance in zero-shot settings, with accuracies\ntypically around 55--70\\%, highlighting ESGenius's challenging nature for LLMs\nin interdisciplinary contexts. However, models employing RAG show significant\nperformance improvements, particularly for smaller models. For example,\n\"DeepSeek-R1-Distill-Qwen-14B\" improves from 63.82\\% (zero-shot) to 80.46\\%\nwith RAG. These results underscore the necessity of grounding responses in\nauthoritative sources for enhanced ESG understanding. To the best of our\nknowledge, ESGenius is the first benchmark curated for LLMs and the relevant\nenhancement technologies that focuses on ESG and sustainability topics.",
    "pdf_url": "http://arxiv.org/pdf/2506.01646v1",
    "published": "2025-06-02T13:19:09+00:00",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "I.2.7; H.3.3"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.01645v1",
    "title": "The Price of Being Partial: Complexity of Partial Generalized Dominating Set on Bounded-Treewidth Graphs",
    "authors": [
      "Jakob Greilhuber",
      "Dániel Marx"
    ],
    "abstract": "The $(\\sigma, \\rho)$-domination framework introduced by Telle [Nord. J.\nComput.'94] captures many classical graph problems. For fixed sets $\\sigma,\n\\rho$ of non-negative integers, a $(\\sigma,\\rho)$-set of a graph $G$ is a set\n$S$ such that for every $v\\in V(G)$, we have (1) if $v \\in S$, then $|N(v) \\cap\nS| \\in \\sigma$, and (2) if $v \\not\\in S$, then $|N(v) \\cap S| \\in \\rho$. We\ninitiate the study of a natural partial variant of the problem, in which the\nconstraints given by $\\sigma, \\rho$ need not be fulfilled for all vertices, but\nwe want to maximize the number of vertices that are happy in the sense that\nthey satisfy (1) or (2) above. Given a graph $G$ and integers $k$ and $\\ell$,\nthe task of $(\\sigma,\\rho)$-MinParDomSet is to decide whether there is a set $S\n\\subseteq V(G)$ of size at most $k$ such that at most $\\ell$ vertices of the\ngraph are not happy under $S$.\n  We consider the problem on graphs of bounded treewidth for nonempty finite or\nsimple cofinite sets $\\sigma$ and $\\rho$, and give matching upper and lower\nbounds for every such fixed $\\sigma$ and $\\rho$ (under the Primal Pathwidth\nStrong Exponential Time Hypothesis). Let $s_\\sigma^\\textsf{p} = \\max \\sigma +\n1$ when $\\sigma$ is finite, and $\\min \\sigma$ when $\\sigma$ is simple cofinite;\ndefine $s_\\rho^{\\textsf{p}}$ similarly for $\\rho$. We show that the problem\n$(\\sigma,\\rho)$-MinParDomSet (1) can be solved in time $(s_\\sigma^\\textsf{p} +\ns_\\rho^{\\textsf{p}} + 2)^{tw} \\cdot |G|^{O(1)}$, when a tree decomposition of\nwidth $tw$ is provided together with the input, and (2) for any\n$\\varepsilon>0$, no algorithm can exist that solves the problem in time\n$(s_\\sigma^\\textsf{p} + s_\\rho^{\\textsf{p}} + 2 - \\varepsilon)^{pw} \\cdot\n|G|^{O(1)}$, even when a path decomposition of width $pw$ is provided together\nwith the input.",
    "pdf_url": "http://arxiv.org/pdf/2506.01645v1",
    "published": "2025-06-02T13:17:45+00:00",
    "categories": [
      "cs.DS",
      "cs.CC"
    ],
    "primary_category": "cs.DS"
  },
  {
    "id": "http://arxiv.org/abs/2506.01644v2",
    "title": "A Budgeted Multi-Level Monte Carlo Method for Full Field Estimates of Multi-PDE Problems",
    "authors": [
      "Niklas Baumgarten",
      "Robert Kutri",
      "Robert Scheichl"
    ],
    "abstract": "We present a high-performance budgeted multi-level Monte Carlo method for\nestimates on the entire spatial domain of multi-PDE problems with random input\ndata. The method is designed to operate optimally within memory and CPU-time\nconstraints and eliminates the need for a priori knowledge of the problem's\nregularity and the algorithm's potential memory demand. To achieve this, we\nbuild on the budgeted multi-level Monte Carlo framework and enhance it with a\nsparse multi-index update algorithm operating on a dynamically assembled\nparallel data structure to enable estimates of the full field solution. We\ndemonstrate numerically and provide mathematical proof that this update\nalgorithm allows computing the full spatial domain estimates at the same\nCPU-time cost as a single quantity of interest, and that the maximum memory\nusage is similar to the memory demands of the deterministic formulation of the\nproblem despite solving the stochastic formulation in parallel. We apply the\nmethod to a sequence of interlinked PDE problems, ranging from a stochastic\npartial differential equation for sampling random fields that serve as the\ndiffusion coefficient in an elliptic subsurface flow problem, to a hyperbolic\nPDE describing mass transport in the resulting flux field.",
    "pdf_url": "http://arxiv.org/pdf/2506.01644v2",
    "published": "2025-06-02T13:17:23+00:00",
    "categories": [
      "math.NA",
      "cs.NA"
    ],
    "primary_category": "math.NA"
  },
  {
    "id": "http://arxiv.org/abs/2506.01643v1",
    "title": "A Low Power Monolithic Active Pixel Sensor Prototype for the STCF Inner Tracker",
    "authors": [
      "Dongwei Xuan",
      "Ruiyang Zhang",
      "Jiajun Qin",
      "Hao Han",
      "Xinyu Bin",
      "Zihan Xu",
      "Lei Zhao",
      "Jianbei Liu",
      "Liang Zhang",
      "Anqing Wang",
      "Aodong Song",
      "Xiangming Sun",
      "Le Xiao",
      "Lailin Xu"
    ],
    "abstract": "The Super Tau-Charm Facility (STCF) is a proposed $e^+e^-$ collider with a\npeak luminosity 100 times higher than that of the present tau-charm factory.\nThe inner tracker (ITK) of STCF should feature a low material budget and high\nreadout speed. Under these requirements, the monolithic active pixel sensor\n(MAPS) is considered as a promising candidate for the ITK. To minimize the\npower consumption of MAPS (for low material budget), larger-size sensors are\nproposed to reduce the scale of the readout circuitry while preserving the\nrequired position resolution. Multiple sensors with varying dimensions and\nstructures were designed and integrated in several prototype chips for\nperformance comparison, fabricated in a 180~nm CIS process. The in-pixel\nreadout circuit can also provide time of arrival (ToA) and time-over-threshold\n(ToT) of the hit signal, with a least significant bit (LSB) of 50 ns. The\nperipheral readout circuit performs operations including timestamp correction,\ndata aggregation, caching, framing, 8b/10b encoding, and serialization.\nAccording to simulation, the power consumption for a full-scale chip is about\n55.7 mW/cm2. Preliminary measurements have been conducted on the prototype\nchips.",
    "pdf_url": "http://arxiv.org/pdf/2506.01643v1",
    "published": "2025-06-02T13:16:14+00:00",
    "categories": [
      "physics.ins-det",
      "hep-ex"
    ],
    "primary_category": "physics.ins-det"
  },
  {
    "id": "http://arxiv.org/abs/2506.01642v2",
    "title": "Catching Stray Balls: Football, fandom, and the impact on digital discourse",
    "authors": [
      "Mark J. Hill"
    ],
    "abstract": "This paper examines how emotional responses to football matches influence\nonline discourse across digital spaces on Reddit. By analysing millions of\nposts from dozens of subreddits, it demonstrates that real-world events trigger\nsentiment shifts that move across communities. It shows that negative sentiment\ncorrelates with problematic language; match outcomes directly influence\nsentiment and posting habits; sentiment can transfer to unrelated communities;\nand offers insights into the content of this shifting discourse. These findings\nreveal how digital spaces function not as isolated environments, but as\ninterconnected emotional ecosystems vulnerable to cross-domain contagion\ntriggered by real-world events, contributing to our understanding of the\npropagation of online toxicity. While football is used as a case-study to\ncomputationally measure affective causes and movements, these patterns have\nimplications for understanding online communities broadly.",
    "pdf_url": "http://arxiv.org/pdf/2506.01642v2",
    "published": "2025-06-02T13:16:06+00:00",
    "categories": [
      "cs.SI",
      "cs.CY"
    ],
    "primary_category": "cs.SI"
  },
  {
    "id": "http://arxiv.org/abs/2506.01641v1",
    "title": "Interpretable reinforcement learning for heat pump control through asymmetric differentiable decision trees",
    "authors": [
      "Toon Van Puyvelde",
      "Mehran Zareh",
      "Chris Develder"
    ],
    "abstract": "In recent years, deep reinforcement learning (DRL) algorithms have gained\ntraction in home energy management systems. However, their adoption by energy\nmanagement companies remains limited due to the black-box nature of DRL, which\nfails to provide transparent decision-making feedback. To address this,\nexplainable reinforcement learning (XRL) techniques have emerged, aiming to\nmake DRL decisions more transparent. Among these, soft differential decision\ntree (DDT) distillation provides a promising approach due to the clear decision\nrules they are based on, which can be efficiently computed. However, achieving\nhigh performance often requires deep, and completely full, trees, which reduces\ninterpretability. To overcome this, we propose a novel asymmetric soft DDT\nconstruction method. Unlike traditional soft DDTs, our approach adaptively\nconstructs trees by expanding nodes only when necessary. This improves the\nefficient use of decision nodes, which require a predetermined depth to\nconstruct full symmetric trees, enhancing both interpretability and\nperformance. We demonstrate the potential of asymmetric DDTs to provide\ntransparent, efficient, and high-performing decision-making in home energy\nmanagement systems.",
    "pdf_url": "http://arxiv.org/pdf/2506.01641v1",
    "published": "2025-06-02T13:16:00+00:00",
    "categories": [
      "eess.SY",
      "cs.LG",
      "cs.SY"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2506.01640v1",
    "title": "On Murmurations and Trace Formulas",
    "authors": [
      "David Lowry-Duda"
    ],
    "abstract": "In recent work with Bober, Booker, Lee, Seymour-Howell, and Zubrilina, we\nproved murmuration behavior for Maass forms in the eigenvalue aspect and for\nmodular forms in the weight aspect. Both used an approach based on the Selberg\ntrace formula. But different trace formulas, including those due to Kuznetsov\nor Petersson, offer different variations. We examine murmurations from the\nperspective of different trace formulas and outline several families of\n$L$-functions where one can likely prove additional murmuration behavior.",
    "pdf_url": "http://arxiv.org/pdf/2506.01640v1",
    "published": "2025-06-02T13:15:45+00:00",
    "categories": [
      "math.NT"
    ],
    "primary_category": "math.NT"
  },
  {
    "id": "http://arxiv.org/abs/2506.01639v1",
    "title": "Bidirectional Soft Actor-Critic: Leveraging Forward and Reverse KL Divergence for Efficient Reinforcement Learning",
    "authors": [
      "Yixian Zhang",
      "Huaze Tang",
      "Changxu Wei",
      "Wenbo Ding"
    ],
    "abstract": "The Soft Actor-Critic (SAC) algorithm, a state-of-the-art method in maximum\nentropy reinforcement learning, traditionally relies on minimizing reverse\nKullback-Leibler (KL) divergence for policy updates. However, this approach\nleads to an intractable optimal projection policy, necessitating gradient-based\napproximations that can suffer from instability and poor sample efficiency.\nThis paper investigates the alternative use of forward KL divergence within\nSAC. We demonstrate that for Gaussian policies, forward KL divergence yields an\nexplicit optimal projection policy -- corresponding to the mean and variance of\nthe target Boltzmann distribution's action marginals. Building on the distinct\nadvantages of both KL directions, we propose Bidirectional SAC, an algorithm\nthat first initializes the policy using the explicit forward KL projection and\nthen refines it by optimizing the reverse KL divergence. Comprehensive\nexperiments on continuous control benchmarks show that Bidirectional SAC\nsignificantly outperforms standard SAC and other baselines, achieving up to a\n$30\\%$ increase in episodic rewards, alongside enhanced sample efficiency.",
    "pdf_url": "http://arxiv.org/pdf/2506.01639v1",
    "published": "2025-06-02T13:15:30+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.01638v1",
    "title": "Finite groups with the minimal generating set exchange property",
    "authors": [
      "Andrea Lucchini",
      "Patricia Medina Capilla"
    ],
    "abstract": "Let $d(G)$ be the smallest cardinality of a generating set of a finite group\n$G.$ We give a complete classification of the finite groups with the property\nthat, whenever $ \\langle x_1, \\dots, x_{d(G)} \\rangle = \\langle y_1, \\dots,\ny_{d(G)} \\rangle = G$, for any $1 \\leq i \\leq d(G)$ there exists $1 \\leq j \\leq\nd(G)$ such that $\\langle x_1, \\dots, x_{i-1}, y_j, x_{i+1}, \\dots, x_{d(G)}\n\\rangle = G.$ We also prove that for every finite group $G$ and every maximal\nsubgroup $M$ of $G$, there exists a generating set for $G$ of minimal size in\nwhich at least $d(G)-2$ elements belong to $M$. We conjecture that the stronger\nstatement holds, that there exists a generating set of size $d(G)$ in which\nonly one element does not belong to $M$, and we prove this conjecture for some\nsuitable choices of $M$.",
    "pdf_url": "http://arxiv.org/pdf/2506.01638v1",
    "published": "2025-06-02T13:15:15+00:00",
    "categories": [
      "math.GR"
    ],
    "primary_category": "math.GR"
  },
  {
    "id": "http://arxiv.org/abs/2506.01637v1",
    "title": "Local Ambiguity Shaping for Doppler-Resilient Sequences Under Spectral and PAPR Constraints",
    "authors": [
      "Shi He",
      "Lingsheng Meng",
      "Yao Ge",
      "Yong Liang Guan",
      "David González G.",
      "Zilong Liu"
    ],
    "abstract": "This paper focuses on designing Doppler-resilient sequences with low local\nAmbiguity Function (AF) sidelobes, subject to certain spectral and\nPeak-to-Average Power Ratio (PAPR) constraints. To achieve this, we propose two\ndistinctoptimization algorithms: (i) an Alternating Minimization (AM) algorithm\nfor superior Weighted Peak Sidelobe Level (WPSL) minimization, and (ii) a\nlow-complexity Augmented Lagrangian-assisted Majorization Minimization (ALaMM)\nalgorithm with effective WPSL suppression. The proposed schemes hold great\npotential for sequence design in future 6G and integrated sensing and\ncommunication applications, supporting robust sensing under spectral\ncoexistence constraints in high-mobility scenarios.",
    "pdf_url": "http://arxiv.org/pdf/2506.01637v1",
    "published": "2025-06-02T13:14:55+00:00",
    "categories": [
      "eess.SP"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2506.01636v1",
    "title": "Visual Explanation via Similar Feature Activation for Metric Learning",
    "authors": [
      "Yi Liao",
      "Ugochukwu Ejike Akpudo",
      "Jue Zhang",
      "Yongsheng Gao",
      "Jun Zhou",
      "Wenyi Zeng",
      "Weichuan Zhang"
    ],
    "abstract": "Visual explanation maps enhance the trustworthiness of decisions made by deep\nlearning models and offer valuable guidance for developing new algorithms in\nimage recognition tasks. Class activation maps (CAM) and their variants (e.g.,\nGrad-CAM and Relevance-CAM) have been extensively employed to explore the\ninterpretability of softmax-based convolutional neural networks, which require\na fully connected layer as the classifier for decision-making. However, these\nmethods cannot be directly applied to metric learning models, as such models\nlack a fully connected layer functioning as a classifier. To address this\nlimitation, we propose a novel visual explanation method termed Similar Feature\nActivation Map (SFAM). This method introduces the channel-wise contribution\nimportance score (CIS) to measure feature importance, derived from the\nsimilarity measurement between two image embeddings. The explanation map is\nconstructed by linearly combining the proposed importance weights with the\nfeature map from a CNN model. Quantitative and qualitative experiments show\nthat SFAM provides highly promising interpretable visual explanations for CNN\nmodels using Euclidean distance or cosine similarity as the similarity metric.",
    "pdf_url": "http://arxiv.org/pdf/2506.01636v1",
    "published": "2025-06-02T13:14:37+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.01635v3",
    "title": "Riemannian Time Warping: Multiple Sequence Alignment in Curved Spaces",
    "authors": [
      "Julian Richter",
      "Christopher A. Erdös",
      "Christian Scheurer",
      "Jochen J. Steil",
      "Niels Dehio"
    ],
    "abstract": "Temporal alignment of multiple signals through time warping is crucial in\nmany fields, such as classification within speech recognition or robot motion\nlearning. Almost all related works are limited to data in Euclidean space.\nAlthough an attempt was made in 2011 to adapt this concept to unit quaternions,\na general extension to Riemannian manifolds remains absent. Given its\nimportance for numerous applications in robotics and beyond, we introduce\nRiemannian Time Warping (RTW). This novel approach efficiently aligns multiple\nsignals by considering the geometric structure of the Riemannian manifold in\nwhich the data is embedded. Extensive experiments on synthetic and real-world\ndata, including tests with an LBR iiwa robot, demonstrate that RTW consistently\noutperforms state-of-the-art baselines in both averaging and classification\ntasks.",
    "pdf_url": "http://arxiv.org/pdf/2506.01635v3",
    "published": "2025-06-02T13:12:02+00:00",
    "categories": [
      "cs.RO",
      "cs.LG"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2506.01634v1",
    "title": "Phase transition for Minesweeper",
    "authors": [
      "Baptiste Louf"
    ],
    "abstract": "We prove a coarse phase transition for the game of Minesweeper: above a\ncertain critical mine density, the game becomes unsolvable with high\nprobability, whereas below the critical mine density it can be solved with a\nlinear time algorithm.",
    "pdf_url": "http://arxiv.org/pdf/2506.01634v1",
    "published": "2025-06-02T13:12:00+00:00",
    "categories": [
      "math.PR",
      "math-ph",
      "math.CO",
      "math.MP",
      "60C05"
    ],
    "primary_category": "math.PR"
  },
  {
    "id": "http://arxiv.org/abs/2506.01633v2",
    "title": "Broken inversion symmetry in the charge density wave phase in EuAl$_4$",
    "authors": [
      "Surya Rohith Kotla",
      "Leila Noohinejad",
      "Preeti Pokhriyal",
      "Martin Tolkiehn",
      "Harshit Agarwal",
      "Sitaram Ramakrishnan",
      "Sander van Smaalen"
    ],
    "abstract": "EuAl$_4$ exhibits a complex phase diagram, including the development of a\ncharge density wave (CDW) below $T_{CDW} = 145$ K. Below $T_{N}=15.4$ K, a\nseries of antiferromagnetically (AFM) ordered phases appear, while non-trivial\ntopological phases, like skyrmion lattices, are stabilized under an applied\nmagnetic field. The symmetries of the variously ordered phases are a major\nissue concerning the understanding of the stabilization of the ordered phases\nas well as concerning the interplay between the various types of order.\nEuAl$_4$ at room temperature has tetragonal symmetry with space group $I4/mmm$.\nThe CDW phase has an incommensurately modulated crystal structure described by\nthe modulation wave vector $\\mathbf{q} \\approx 0.17\\mathbf{c}^{*}$. On the\nbasis of various experiments, including elastic and inelastic x-ray scattering,\nand second-harmonic generation, it has been proposed that the symmetry of the\nCDW phase of EuAl$_4$ could be centrosymmetric orthorhombic,\nnon-centrosymmetric orthorhombic or non-centrosymmetric tetragonal. Here, we\nreport temperature-dependent, single-crystal x-ray diffraction experiments that\nshow that the CDW is a transverse CDW with phason disorder, and with\nnon-centrosymmetric symmetry according to the orthorhombic superspace group\n$F222(0\\,0\\,\\sigma)00s$.Essential for this finding is the availability of a\nsufficient number of second-order ($2\\mathbf{q}$) satellite reflections in the\nx-ray diffraction data set. The broken inversion symmetry implies that\nskyrmions might form due to Dzyaloshinskii-Moriya (DM) interactions, instead of\na more exotic mechanism as it is required for centrosymmetric structures.",
    "pdf_url": "http://arxiv.org/pdf/2506.01633v2",
    "published": "2025-06-02T13:11:45+00:00",
    "categories": [
      "cond-mat.str-el",
      "cond-mat.other"
    ],
    "primary_category": "cond-mat.str-el"
  },
  {
    "id": "http://arxiv.org/abs/2506.01632v2",
    "title": "Probing the Turbulent Corona and Heliosphere Using Radio Spectral Imaging Observation during the Solar Conjunction of Crab Nebula",
    "authors": [
      "Peijin Zhang",
      "Surajit Mondal",
      "Bin Chen",
      "Sijie Yu",
      "Dale Gary",
      "Marin M. Anderson",
      "Judd D. Bowman",
      "Ruby Byrne",
      "Morgan Catha",
      "Xingyao Chen",
      "Sherry Chhabra",
      "Larry D'Addario",
      "Ivey Davis",
      "Jayce Dowell",
      "Katherine Elder",
      "Greg Hellbourg",
      "Jack Hickish",
      "Rick Hobbs",
      "David Hodge",
      "Mark Hodges",
      "Yuping Huang",
      "Andrea Isella",
      "Daniel C. Jacobs",
      "Ghislain Kemby",
      "John T. Klinefelter",
      "Matthew Kolopanis",
      "Nikita Kosogorov",
      "James Lamb",
      "Casey J. Law",
      "Nivedita Mahesh",
      "Brian O'Donnell",
      "Kathryn Plant",
      "Corey Posner",
      "Travis Powell",
      "Vinand Prayag",
      "Andres Rizo",
      "Andrew Romero-Wolf",
      "Jun Shi",
      "Greg Taylor",
      "Jordan Trim",
      "Mike Virgin",
      "Akshatha Vydula",
      "Sandy Weinreb",
      "David Woody"
    ],
    "abstract": "Measuring plasma parameters in the upper solar corona and inner heliosphere\nis challenging because of the region's weakly emissive nature and\ninaccessibility for most in situ observations. Radio imaging of broadened and\ndistorted background astronomical radio sources during solar conjunction can\nprovide unique constraints for the coronal material along the line of sight. In\nthis study, we present radio spectral imaging observations of the Crab Nebula\n(Tau A) from June 9 to June 22, 2024 when it was near the Sun with a projected\nheliocentric distance of 5 to 27 solar radii, using the Owens Valley Radio\nObservatory's Long Wavelength Array (OVRO-LWA) at multiple frequencies in the\n30--80 MHz range. The imaging data reveal frequency-dependent broadening and\ndistortion effects caused by anisotropic wave propagation through the turbulent\nsolar corona at different distances. We analyze the brightness, size, and\nanisotropy of the broadened images. Our results provide detailed observations\nshowing that the eccentricity of the unresolved source increases as the line of\nsight approaches the Sun, suggesting a higher anisotropic ratio of the plasma\nturbulence closer to the Sun. In addition, the major axis of the elongated\nsource is consistently oriented in the direction perpendicular to the radial\ndirection, suggesting that the turbulence-induced scattering effect is more\npronounced in the direction transverse to the coronal magnetic field. Lastly,\nwhen the source undergoes large-scale refraction as the line of sight passes\nthrough a streamer, the apparent source exhibits substructures at lower\nfrequencies. This study demonstrates that observations of celestial radio\nsources with lines of sight near the Sun provide a promising method for\nmeasuring turbulence parameters in the inner heliosphere.",
    "pdf_url": "http://arxiv.org/pdf/2506.01632v2",
    "published": "2025-06-02T13:10:47+00:00",
    "categories": [
      "astro-ph.SR"
    ],
    "primary_category": "astro-ph.SR"
  },
  {
    "id": "http://arxiv.org/abs/2506.06351v1",
    "title": "Deep learning methods for modeling infrasound transmission loss in the middle atmosphere",
    "authors": [
      "Alexis Le Pichon",
      "Alice Janela Cameijo",
      "Samir Aknine",
      "Youcef Sklab",
      "Souhila Arib",
      "Quentin Brissaud",
      "Sven Peter Naesholm"
    ],
    "abstract": "Accurate modeling of infrasound transmission losses (TLs) is essential to\nassess the performance of the global International Monitoring System infrasound\nnetwork. Among existing propagation modeling tools, parabolic equation (PE)\nmethod enables TLs to be finely modeled, but its computational cost does not\nallow exploration of a large parameter space for operational monitoring\napplications. To reduce computation times, Brissaud et al. 2023 explored the\npotential of convolutional neural networks trained on a large set of regionally\nsimulated wavefields (< 1000 km from the source) to predict TLs with negligible\ncomputation times compared to PE simulations. However, this method struggles in\nunfavorable initial wind conditions, especially at high frequencies, and causal\nissues with winds at large distances from the source affecting ground TLs close\nto the source. In this study, we have developed an optimized convolutional\nnetwork designed to minimize prediction errors while predicting TLs from\nglobally simulated combined temperature and wind fields spanning over\npropagation ranges of 4000 km. Our approach enhances the previously proposed\none by implementing key optimizations that improve the overall architecture\nperformance. The implemented model predicts TLs with an average error of 8.6 dB\nin the whole frequency band (0.1-3.2 Hz) and explored realistic atmospheric\nscenarios.",
    "pdf_url": "http://arxiv.org/pdf/2506.06351v1",
    "published": "2025-06-02T13:10:29+00:00",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2506.01631v2",
    "title": "Gradient-Based Model Fingerprinting for LLM Similarity Detection and Family Classification",
    "authors": [
      "Zehao Wu",
      "Yanjie Zhao",
      "Haoyu Wang"
    ],
    "abstract": "As Large Language Models (LLMs) become integral software components in modern\napplications, unauthorized model derivations through fine-tuning, merging, and\nredistribution have emerged as critical software engineering challenges. Unlike\ntraditional software where clone detection and license compliance are\nwell-established, the LLM ecosystem lacks effective mechanisms to detect model\nlineage and enforce licensing agreements. This gap is particularly problematic\nwhen open-source model creators, such as Meta's LLaMA, require derivative works\nto maintain naming conventions for attribution, yet no technical means exist to\nverify compliance.\n  To fill this gap, treating LLMs as software artifacts requiring provenance\ntracking, we present TensorGuard, a gradient-based fingerprinting framework for\nLLM similarity detection and family classification. Our approach extracts\nmodel-intrinsic behavioral signatures by analyzing gradient responses to random\ninput perturbations across tensor layers, operating independently of training\ndata, watermarks, or specific model formats. TensorGuard supports the\nwidely-adopted safetensors format and constructs high-dimensional fingerprints\nthrough statistical analysis of gradient features. These fingerprints enable\ntwo complementary capabilities: direct pairwise similarity assessment between\narbitrary models through distance computation, and systematic family\nclassification of unknown models via the K-Means clustering algorithm with\ndomain-informed centroid initialization using known base models. Experimental\nevaluation on 58 models comprising 8 base models and 50 derivatives across five\nmodel families (Llama, Qwen, Gemma, Phi, Mistral) demonstrates 94%\nclassification accuracy under our centroid-initialized K-Means clustering.",
    "pdf_url": "http://arxiv.org/pdf/2506.01631v2",
    "published": "2025-06-02T13:08:01+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.01630v2",
    "title": "Six-dimensional $\\mathcal{N}=(2,0)$ Conformal Superspace",
    "authors": [
      "Christian Kennedy",
      "Gabriele Tartaglino-Mazzucchelli"
    ],
    "abstract": "We develop a new off-shell formulation for six-dimensional conformal\nsupergravity obtained by gauging the 6D $\\mathcal{N}=(2,0)$ superconformal\nalgebra in superspace. We provide the complete gauged algebra, which proves to\nbe considerably constrained compared to other conformal superspaces constructed\nin the past. This formulation is employed to obtain the unique 6D\n$\\mathcal{N}=(2,0)$ Bach tensor superfield, which describes the multiplet of\nequations of motions for conformal supergravity, by using a general ansatz\nfixed by truncation to 6D $\\mathcal{N}=(1,0)$ results. We also translate some\nresults into components for precise matching against the literature.",
    "pdf_url": "http://arxiv.org/pdf/2506.01630v2",
    "published": "2025-06-02T13:07:41+00:00",
    "categories": [
      "hep-th",
      "math-ph",
      "math.MP"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2506.01629v1",
    "title": "Cross-Lingual Generalization and Compression: From Language-Specific to Shared Neurons",
    "authors": [
      "Frederick Riemenschneider",
      "Anette Frank"
    ],
    "abstract": "Multilingual language models (MLLMs) have demonstrated remarkable abilities\nto transfer knowledge across languages, despite being trained without explicit\ncross-lingual supervision. We analyze the parameter spaces of three MLLMs to\nstudy how their representations evolve during pre-training, observing patterns\nconsistent with compression: models initially form language-specific\nrepresentations, which gradually converge into cross-lingual abstractions as\ntraining progresses. Through probing experiments, we observe a clear transition\nfrom uniform language identification capabilities across layers to more\nspecialized layer functions. For deeper analysis, we focus on neurons that\nencode distinct semantic concepts. By tracing their development during\npre-training, we show how they gradually align across languages. Notably, we\nidentify specific neurons that emerge as increasingly reliable predictors for\nthe same concepts across languages.",
    "pdf_url": "http://arxiv.org/pdf/2506.01629v1",
    "published": "2025-06-02T13:06:30+00:00",
    "categories": [
      "cs.CL",
      "I.2.4; I.2.7"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.01628v1",
    "title": "A Hierarchical Bin Packing Framework with Dual Manipulators via Heuristic Search and Deep Reinforcement Learning",
    "authors": [
      "Beomjoon Lee",
      "Changjoo Nam"
    ],
    "abstract": "We address the bin packing problem (BPP), which aims to maximize bin\nutilization when packing a variety of items. The offline problem, where the\ncomplete information about the item set and their sizes is known in advance, is\nproven to be NP-hard. The semi-online and online variants are even more\nchallenging, as full information about incoming items is unavailable. While\nexisting methods have tackled both 2D and 3D BPPs, the 2D BPP remains\nunderexplored in terms of fully maximizing utilization. We propose a\nhierarchical approach for solving the 2D online and semi-online BPP by\ncombining deep reinforcement learning (RL) with heuristic search. The heuristic\nsearch selects which item to pack or unpack, determines the packing order, and\nchooses the orientation of each item, while the RL agent decides the precise\nposition within the bin. Our method is capable of handling diverse scenarios,\nincluding repacking, varying levels of item information, differing numbers of\naccessible items, and coordination of dual manipulators. Experimental results\ndemonstrate that our approach achieves near-optimal utilization across various\npractical scenarios, largely due to its repacking capability. In addition, the\nalgorithm is evaluated in a physics-based simulation environment, where\nexecution time is measured to assess its real-world performance.",
    "pdf_url": "http://arxiv.org/pdf/2506.01628v1",
    "published": "2025-06-02T13:05:59+00:00",
    "categories": [
      "cs.RO"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2506.01627v1",
    "title": "MVAN: Multi-View Attention Networks for Fake News Detection on Social Media",
    "authors": [
      "Shiwen Ni",
      "Jiawen Li",
      "Hung-Yu Kao"
    ],
    "abstract": "Fake news on social media is a widespread and serious problem in today's\nsociety. Existing fake news detection methods focus on finding clues from Long\ntext content, such as original news articles and user comments. This paper\nsolves the problem of fake news detection in more realistic scenarios. Only\nsource shot-text tweet and its retweet users are provided without user\ncomments. We develop a novel neural network based model,\n\\textbf{M}ulti-\\textbf{V}iew \\textbf{A}ttention \\textbf{N}etworks (MVAN) to\ndetect fake news and provide explanations on social media. The MVAN model\nincludes text semantic attention and propagation structure attention, which\nensures that our model can capture information and clues both of source tweet\ncontent and propagation structure. In addition, the two attention mechanisms in\nthe model can find key clue words in fake news texts and suspicious users in\nthe propagation structure. We conduct experiments on two real-world datasets,\nand the results demonstrate that MVAN can significantly outperform\nstate-of-the-art methods by 2.5\\% in accuracy on average, and produce a\nreasonable explanation.",
    "pdf_url": "http://arxiv.org/pdf/2506.01627v1",
    "published": "2025-06-02T13:05:23+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.01626v3",
    "title": "Safety, Relative Tightness and the Probabilistic Frame Rule",
    "authors": [
      "Janez Ignacij Jereb",
      "Alex Simpson"
    ],
    "abstract": "Probabilistic separation logic offers an approach to reasoning about\nimperative probabilistic programs in which a separating conjunction is used as\na mechanism for expressing independence properties. Crucial to the\neffectiveness of the formalism is the frame rule, which enables modular\nreasoning about independent probabilistic state. We explore a semantic\nformulation of probabilistic separation logic, in which the frame rule has the\nsame simple formulation as in separation logic, without further side\nconditions. This is achieved by building a notion of safety into\nspecifications, using which we establish a crucial property of specifications,\ncalled relative tightness, from which the soundness of the frame rule follows.",
    "pdf_url": "http://arxiv.org/pdf/2506.01626v3",
    "published": "2025-06-02T13:05:00+00:00",
    "categories": [
      "cs.LO",
      "F.3.1; F.3.2"
    ],
    "primary_category": "cs.LO"
  },
  {
    "id": "http://arxiv.org/abs/2506.01625v1",
    "title": "Robust Satisficing Gaussian Process Bandits Under Adversarial Attacks",
    "authors": [
      "Artun Saday",
      "Yaşar Cahit Yıldırım",
      "Cem Tekin"
    ],
    "abstract": "We address the problem of Gaussian Process (GP) optimization in the presence\nof unknown and potentially varying adversarial perturbations. Unlike\ntraditional robust optimization approaches that focus on maximizing performance\nunder worst-case scenarios, we consider a robust satisficing objective, where\nthe goal is to consistently achieve a predefined performance threshold $\\tau$,\neven under adversarial conditions. We propose two novel algorithms based on\ndistinct formulations of robust satisficing, and show that they are instances\nof a general robust satisficing framework. Further, each algorithm offers\ndifferent guarantees depending on the nature of the adversary. Specifically, we\nderive two regret bounds: one that is sublinear over time, assuming certain\nconditions on the adversary and the satisficing threshold $\\tau$, and another\nthat scales with the perturbation magnitude but requires no assumptions on the\nadversary. Through extensive experiments, we demonstrate that our approach\noutperforms the established robust optimization methods in achieving the\nsatisficing objective, particularly when the ambiguity set of the robust\noptimization framework is inaccurately specified.",
    "pdf_url": "http://arxiv.org/pdf/2506.01625v1",
    "published": "2025-06-02T13:04:18+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.01624v1",
    "title": "Social Cooperation in Conversational AI Agents",
    "authors": [
      "Mustafa Mert Çelikok",
      "Saptarashmi Bandyopadhyay",
      "Robert Loftin"
    ],
    "abstract": "The development of AI agents based on large, open-domain language models\n(LLMs) has paved the way for the development of general-purpose AI assistants\nthat can support human in tasks such as writing, coding, graphic design, and\nscientific research. A major challenge with such agents is that, by necessity,\nthey are trained by observing relatively short-term interactions with humans.\nSuch models can fail to generalize to long-term interactions, for example,\ninteractions where a user has repeatedly corrected mistakes on the part of the\nagent. In this work, we argue that these challenges can be overcome by\nexplicitly modeling humans' social intelligence, that is, their ability to\nbuild and maintain long-term relationships with other agents whose behavior\ncannot always be predicted. By mathematically modeling the strategies humans\nuse to communicate and reason about one another over long periods of time, we\nmay be able to derive new game theoretic objectives against which LLMs and\nfuture AI agents may be optimized.",
    "pdf_url": "http://arxiv.org/pdf/2506.01624v1",
    "published": "2025-06-02T13:02:36+00:00",
    "categories": [
      "cs.AI",
      "cs.LG",
      "I.2.6; I.2.7"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2506.01623v3",
    "title": "MAGIK: Mapping to Analogous Goals via Imagination-enabled Knowledge Transfer",
    "authors": [
      "Ajsal Shereef Palattuparambil",
      "Thommen George Karimpanal",
      "Santu Rana"
    ],
    "abstract": "Humans excel at analogical reasoning - applying knowledge from one task to a\nrelated one with minimal relearning. In contrast, reinforcement learning (RL)\nagents typically require extensive retraining even when new tasks share\nstructural similarities with previously learned ones. In this work, we propose\nMAGIK, a novel framework that enables RL agents to transfer knowledge to\nanalogous tasks without interacting with the target environment. Our approach\nleverages an imagination mechanism to map entities in the target task to their\nanalogues in the source domain, allowing the agent to reuse its original\npolicy. Experiments on custom MiniGrid and MuJoCo tasks show that MAGIK\nachieves effective zero-shot transfer using only a small number of\nhuman-labelled examples. We compare our approach to related baselines and\nhighlight how it offers a novel and effective mechanism for knowledge transfer\nvia imagination-based analogy mapping.",
    "pdf_url": "http://arxiv.org/pdf/2506.01623v3",
    "published": "2025-06-02T13:01:14+00:00",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2506.01622v4",
    "title": "General agents contain world models",
    "authors": [
      "Jonathan Richens",
      "David Abel",
      "Alexis Bellot",
      "Tom Everitt"
    ],
    "abstract": "Are world models a necessary ingredient for flexible, goal-directed\nbehaviour, or is model-free learning sufficient? We provide a formal answer to\nthis question, showing that any agent capable of generalizing to multi-step\ngoal-directed tasks must have learned a predictive model of its environment. We\nshow that this model can be extracted from the agent's policy, and that\nincreasing the agents performance or the complexity of the goals it can achieve\nrequires learning increasingly accurate world models. This has a number of\nconsequences: from developing safe and general agents, to bounding agent\ncapabilities in complex environments, and providing new algorithms for\neliciting world models from agents.",
    "pdf_url": "http://arxiv.org/pdf/2506.01622v4",
    "published": "2025-06-02T13:01:13+00:00",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.RO",
      "stat.ML"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2506.02087v1",
    "title": "Optimizing NN reduction in an atom interferometer network for GW detection",
    "authors": [
      "Q. Cojean Palassoé",
      "A. Bertoldi",
      "A. Landragin",
      "B. Canuel"
    ],
    "abstract": "The sensitivity of an atom gradiometer aiming to detect gravitational waves\n(GW) is impacted by fluctuations of Earth's gravity field also called Newtonian\nNoise (NN). Sensor arrays have proved to be a promising technique for NN\nreduction. In our study, we further investigate the benefits of Atom\nInterferometer (AI) networks by improving their geometry and the extraction of\nthe GW signal. We focus on Seismic Newtonian Noise in the frequency band from\n0.1 to 10 Hz. On one hand, we show that using a specific detector geometry, a\nbetter NN rejection can occur optimizing the number of gradiometers in the\nnetwork. On the other hand, we show that carrying out optimization in sub\nfrequency bands - which results in using various detector geometries from a\ncommon network - allows even higher NN rejection while keeping a similar number\nof interferometers.",
    "pdf_url": "http://arxiv.org/pdf/2506.02087v1",
    "published": "2025-06-02T13:00:41+00:00",
    "categories": [
      "gr-qc",
      "physics.atom-ph",
      "physics.ins-det"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2506.01621v1",
    "title": "Domain Lexical Knowledge-based Word Embedding Learning for Text Classification under Small Data",
    "authors": [
      "Zixiao Zhu",
      "Kezhi Mao"
    ],
    "abstract": "Pre-trained language models such as BERT have been proved to be powerful in\nmany natural language processing tasks. But in some text classification\napplications such as emotion recognition and sentiment analysis, BERT may not\nlead to satisfactory performance. This often happens in applications where\nkeywords play critical roles in the prediction of class labels. Our\ninvestigation found that the root cause of the problem is that the\ncontext-based BERT embedding of the keywords may not be discriminative enough\nto produce discriminative text representation for classification. Motivated by\nthis finding, we develop a method to enhance word embeddings using\ndomain-specific lexical knowledge. The knowledge-based embedding enhancement\nmodel projects the BERT embedding into a new space where within-class\nsimilarity and between-class difference are maximized. To implement the\nknowledge-based word embedding enhancement model, we also develop a knowledge\nacquisition algorithm for automatically collecting lexical knowledge from\nonline open sources. Experiment results on three classification tasks,\nincluding sentiment analysis, emotion recognition and question answering, have\nshown the effectiveness of our proposed word embedding enhancing model. The\ncodes and datasets are in https://github.com/MidiyaZhu/KVWEFFER.",
    "pdf_url": "http://arxiv.org/pdf/2506.01621v1",
    "published": "2025-06-02T12:59:41+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.01620v1",
    "title": "Exploring the potential for kinematically colder HI component as a tracer for star-forming gas in nearby galaxies",
    "authors": [
      "Hye-Jin Park",
      "Andrew J. Battisti",
      "Antoine Marchal",
      "Luca Cortese",
      "Emily Wisnioski",
      "Mark Seibert",
      "Shin-Jeong Kim",
      "Naomi McClure-Griffiths",
      "W. J. G. de Blok",
      "Kathryn Grasha",
      "Barry F. Madore",
      "Jeff A. Rich",
      "Rachael L. Beaton"
    ],
    "abstract": "Atomic hydrogen (HI) dominates the mass of the cold interstellar medium,\nundergoing thermal condensation to form molecular gas and fuel star formation.\nKinematically colder HI components, identified via kinematic decomposition of\nHI 21 cm data cubes, serve as a crucial transition phase between diffuse warm\nneutral gas and molecular hydrogen (H$_{2}$). We analyse these colder HI\ncomponents by decomposing HI 21 cm data cubes of seven nearby galaxies -\nSextans A, NGC 6822, WLM, NGC 5068, NGC 7793, NGC 1566, and NGC 5236 - spanning\nmetallicities (0.1 < $Z/Z_{\\odot}$ < 1.0) and physical scales (53-1134 pc).\nUsing a velocity dispersion threshold of 6 km s$^{-1}$, we classify the\nkinematically distinct components into narrow (colder) and broad (warmer).\nCross-correlation analysis between the narrow HI components and H$_{2}$ or star\nformation rate (SFR) surface density at different spatial scales reveals that\ndwarf galaxies exhibit the strongest correlation at ~500-700 pc. The radially\nbinned narrow HI fraction, $f_{\\rm n} = I_{\\rm narrowHI}/I_{\\rm totalHI}$, in\ndwarf galaxies shows no clear trend with metallicity or SFR, while in spirals,\n$f_{\\rm n}$ is lower in inner regions with higher metallicity and SFR. We find\nthat the dataset resolution significantly impacts the results, with higher\nphysical resolution data yielding a higher median $f_{\\rm n}$, $\\langle f_{\\rm\nn} \\rangle$, per galaxy. With this considered, dwarf galaxies consistently\nexhibit a larger $f_{\\rm n}$ than spiral galaxies. These findings highlight the\ncritical role of cold HI in regulating star formation across different galactic\nenvironments and emphasise the need for high-resolution HI observations to\nfurther unravel the connection between atomic-to-molecular gas conversion and\ngalaxy evolution.",
    "pdf_url": "http://arxiv.org/pdf/2506.01620v1",
    "published": "2025-06-02T12:58:40+00:00",
    "categories": [
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2506.01619v3",
    "title": "A projector--rank partition theorem for exact degrees of freedom in experimental design",
    "authors": [
      "Nagananda K G"
    ],
    "abstract": "In many experimental designs\\textemdash split-plots, blocked or nested\nlayouts, fractional factorials, and studies with missing or unequal\nreplication\\textemdash standard ANOVA procedures no longer tell us exactly how\nmany independent pieces of information each effect truly carries. We provide a\ngeneral degrees of freedom $(\\mathrm{df})$ partition theorem that resolves this\nambiguity. For $N$ observations, we show that the total information in the data\n({\\ie}, $N-1$ $\\mathrm{df}$) can be split exactly across experimental effects\nand randomization strata by projecting the data onto each stratum and counting\nthe $\\mathrm{df}$ each effect contributes there. This yields integer\n$\\mathrm{df}$\\textemdash not approximations\\textemdash for any mix of fixed and\nrandom effects, blocking structures, fractionation, or imbalance. This result\nyields closed-form $\\mathrm{df}$ tables for unbalanced split-plot, row-column,\nlattice, and crossed-nested designs. We introduce practical\ndiagnostics\\textemdash the $\\mathrm{df}$-retention ratio $\\rho$, df deficiency\n$\\delta$, and variance-inflation index $\\alpha$\\textemdash that measure exactly\nhow many $\\mathrm{df}$ an effect retains under blocking or fractionation and\nthe resulting loss of precision, thereby extending Box--Hunter's resolution\nidea to multi-stratum and incomplete designs. Classical results emerge as\ncorollaries: Cochran's one-stratum identity; Yates's split-plot $\\mathrm{df}$;\nresolution-$R$ identified when an effect retains no $\\mathrm{df}$. Empirical\nstudies on split-plot and nested designs, a blocked fractional-factorial\ndesign-selection experiment, and timing benchmarks show that our approach\ndelivers calibrated error rates, recovers information to raise power by up to\n60\\% without additional runs, and is orders of magnitude faster than\nbootstrap-based $\\mathrm{df}$ approximations.",
    "pdf_url": "http://arxiv.org/pdf/2506.01619v3",
    "published": "2025-06-02T12:58:25+00:00",
    "categories": [
      "math.ST",
      "stat.TH"
    ],
    "primary_category": "math.ST"
  },
  {
    "id": "http://arxiv.org/abs/2506.01618v1",
    "title": "Unsupervised Rhythm and Voice Conversion to Improve ASR on Dysarthric Speech",
    "authors": [
      "Karl El Hajal",
      "Enno Hermann",
      "Sevada Hovsepyan",
      "Mathew Magimai. -Doss"
    ],
    "abstract": "Automatic speech recognition (ASR) systems struggle with dysarthric speech\ndue to high inter-speaker variability and slow speaking rates. To address this,\nwe explore dysarthric-to-healthy speech conversion for improved ASR\nperformance. Our approach extends the Rhythm and Voice (RnV) conversion\nframework by introducing a syllable-based rhythm modeling method suited for\ndysarthric speech. We assess its impact on ASR by training LF-MMI models and\nfine-tuning Whisper on converted speech. Experiments on the Torgo corpus reveal\nthat LF-MMI achieves significant word error rate reductions, especially for\nmore severe cases of dysarthria, while fine-tuning Whisper on converted data\nhas minimal effect on its performance. These results highlight the potential of\nunsupervised rhythm and voice conversion for dysarthric ASR. Code available at:\nhttps://github.com/idiap/RnV",
    "pdf_url": "http://arxiv.org/pdf/2506.01618v1",
    "published": "2025-06-02T12:57:36+00:00",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.LG",
      "cs.SD"
    ],
    "primary_category": "eess.AS"
  },
  {
    "id": "http://arxiv.org/abs/2506.01617v1",
    "title": "An Open and Collaborative Database of Properties of Materials for High-Temperature Superconducting-Based Devices",
    "authors": [
      "Pablo Cayado",
      "João Rosas",
      "João Murta-Pina",
      "Harold S. Ruiz"
    ],
    "abstract": "The successful integration of high-temperature superconductors (HTS) into\nmodern technologies requires consistent, accessible, and comprehensive material\ndata, a need that is currently unmet due to the fragmented and incomplete\nnature of existing resources. This paper introduces a new collaborative,\nopen-access database specifically designed to address this gap by providing\nstandardized data on HTS materials and crucial auxiliary components for HTS\napplications. The database encompasses extensive data on structural, cryogenic,\nelectrical, magnetic, and superconducting materials, supporting diverse\nrequirements from HTS modelling to magnet design. Developed through\ncollaborative efforts and organized using an ontology-driven data model, this\nplatform is dynamically adaptable, ensuring that it can grow as new materials\nand data emerge. Key features include user-driven contributions, peer-reviewed\ndata validation, and advanced filtering capabilities for efficient data\nretrieval. This innovative database, to the knowledge of the authors, being the\nlargest publicly available for material properties of HTS technologies is\npositioned as a valuable tool for the HTS community, promoting more efficient\nresearch and development processes, accelerating the practical application of\nHTS, and fostering a collaborative approach to knowledge sharing within the\nfield. The database is available at https://sc.hi-scale.grisenergia.pt/app.",
    "pdf_url": "http://arxiv.org/pdf/2506.01617v1",
    "published": "2025-06-02T12:56:51+00:00",
    "categories": [
      "cond-mat.supr-con",
      "physics.app-ph",
      "physics.data-an"
    ],
    "primary_category": "cond-mat.supr-con"
  },
  {
    "id": "http://arxiv.org/abs/2506.01616v1",
    "title": "MLA-Trust: Benchmarking Trustworthiness of Multimodal LLM Agents in GUI Environments",
    "authors": [
      "Xiao Yang",
      "Jiawei Chen",
      "Jun Luo",
      "Zhengwei Fang",
      "Yinpeng Dong",
      "Hang Su",
      "Jun Zhu"
    ],
    "abstract": "The emergence of multimodal LLM-based agents (MLAs) has transformed\ninteraction paradigms by seamlessly integrating vision, language, action and\ndynamic environments, enabling unprecedented autonomous capabilities across GUI\napplications ranging from web automation to mobile systems. However, MLAs\nintroduce critical trustworthiness challenges that extend far beyond\ntraditional language models' limitations, as they can directly modify digital\nstates and trigger irreversible real-world consequences. Existing benchmarks\ninadequately tackle these unique challenges posed by MLAs' actionable outputs,\nlong-horizon uncertainty and multimodal attack vectors. In this paper, we\nintroduce MLA-Trust, the first comprehensive and unified framework that\nevaluates the MLA trustworthiness across four principled dimensions:\ntruthfulness, controllability, safety and privacy. We utilize websites and\nmobile applications as realistic testbeds, designing 34 high-risk interactive\ntasks and curating rich evaluation datasets. Large-scale experiments involving\n13 state-of-the-art agents reveal previously unexplored trustworthiness\nvulnerabilities unique to multimodal interactive scenarios. For instance,\nproprietary and open-source GUI-interacting MLAs pose more severe\ntrustworthiness risks than static MLLMs, particularly in high-stakes domains;\nthe transition from static MLLMs into interactive MLAs considerably compromises\ntrustworthiness, enabling harmful content generation in multi-step interactions\nthat standalone MLLMs would typically prevent; multi-step execution, while\nenhancing the adaptability of MLAs, involves latent nonlinear risk accumulation\nacross successive interactions, circumventing existing safeguards and resulting\nin unpredictable derived risks. Moreover, we present an extensible toolbox to\nfacilitate continuous evaluation of MLA trustworthiness across diverse\ninteractive environments.",
    "pdf_url": "http://arxiv.org/pdf/2506.01616v1",
    "published": "2025-06-02T12:56:27+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2506.01615v2",
    "title": "IndicRAGSuite: Large-Scale Datasets and a Benchmark for Indian Language RAG Systems",
    "authors": [
      "Pasunuti Prasanjith",
      "Prathmesh B More",
      "Anoop Kunchukuttan",
      "Raj Dabre"
    ],
    "abstract": "Retrieval-Augmented Generation (RAG) systems enable language models to access\nrelevant information and generate accurate, well-grounded, and contextually\ninformed responses. However, for Indian languages, the development of\nhigh-quality RAG systems is hindered by the lack of two critical resources: (1)\nevaluation benchmarks for retrieval and generation tasks, and (2) large-scale\ntraining datasets for multilingual retrieval. Most existing benchmarks and\ndatasets are centered around English or high-resource languages, making it\ndifficult to extend RAG capabilities to the diverse linguistic landscape of\nIndia. To address the lack of evaluation benchmarks, we create IndicMSMarco, a\nmultilingual benchmark for evaluating retrieval quality and response generation\nin 13 Indian languages, created via manual translation of 1000 diverse queries\nfrom MS MARCO-dev set. To address the need for training data, we build a\nlarge-scale dataset of (question, answer, relevant passage) tuples derived from\nthe Wikipedias of 19 Indian languages using state-of-the-art LLMs.\nAdditionally, we include translated versions of the original MS MARCO dataset\nto further enrich the training data and ensure alignment with real-world\ninformation-seeking tasks. Resources are available here:\nhttps://huggingface.co/collections/ai4bharat/indicragsuite-683e7273cb2337208c8c0fcb",
    "pdf_url": "http://arxiv.org/pdf/2506.01615v2",
    "published": "2025-06-02T12:55:51+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.01614v1",
    "title": "Contrastive Learning for Efficient Transaction Validation in UTXO-based Blockchains",
    "authors": [
      "Hamid Attar",
      "Luigi Lunardon",
      "Alessio Pagani"
    ],
    "abstract": "This paper introduces a Machine Learning (ML) approach for scalability of\nUTXO-based blockchains, such as Bitcoin. Prior approaches to UTXO set sharding\nstruggle with distributing UTXOs effectively across validators, creating\nsubstantial communication overhead due to child-parent transaction\ndependencies. This overhead, which arises from the need to locate parent UTXOs,\nsignificantly hampers transaction processing speeds. Our solution uses ML to\noptimize not only UTXO set sharding but also the routing of incoming\ntransactions, ensuring that transactions are directed to shards containing\ntheir parent UTXOs. At the heart of our approach is a framework that combines\ncontrastive and unsupervised learning to create an embedding space for\ntransaction outputs. This embedding allows the model to group transaction\noutputs based on spending relationships, making it possible to route\ntransactions efficiently to the correct validation microservices. Trained on\nhistorical transaction data with triplet loss and online semi-hard negative\nmining, the model embeds parent-child spending patterns directly into its\nparameters, thus eliminating the need for costly, real-time parent transaction\nlookups. This significantly reduces cross-shard communication overhead,\nboosting throughput and scalability.",
    "pdf_url": "http://arxiv.org/pdf/2506.01614v1",
    "published": "2025-06-02T12:54:39+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.01613v1",
    "title": "Three approaches to the Howe duality between quantum general linear supergroups",
    "authors": [
      "Li Luo",
      "Xirui Yu",
      "Zhongguo Zhou"
    ],
    "abstract": "The Howe duality between quantum general linear supergroups was firstly\nestablished by Y. Zhang via quantum coordinate superalgebras. In this paper, we\nprovide two other approaches to this Howe duality. One is constructed by\nquantum differential operators, while the other is based on the\nBeilinson-Lusztig-MacPherson realization of $U_q(\\mathfrak{gl}_{m|n})$.\nMoreover, we show that these three approaches are equivalent by giving their\naction formulas explicitly.",
    "pdf_url": "http://arxiv.org/pdf/2506.01613v1",
    "published": "2025-06-02T12:54:37+00:00",
    "categories": [
      "math.QA",
      "math.RT"
    ],
    "primary_category": "math.QA"
  },
  {
    "id": "http://arxiv.org/abs/2506.01612v1",
    "title": "Percolation on random 2-lifts",
    "authors": [
      "Paul Drouvillé"
    ],
    "abstract": "Given a graph $G$, we consider a model for a random cover of $G$ by taking\ntwo parallel copies of $G$ and crossing every pair of parallel edges randomly\nwith probability $q$ independently of each other. The resulting graph $G_q$, is\na random $2$-lift of $G$ that may not be transitive but still probabilistically\nexhibit many properties of transitive graphs. Studying percolation in this\ncontext can help us test the reliability and robustness of our proofs methods\nin percolation theory. Our three main results on this model are the continuity\nof the critical parameter $p_c(G_q)$, for $q\\in(0,1)$, the strict monotonicity\n$p_c(G_q)< p_c(G)$ and the exponential decay of the cluster size in the\nsubcritical regime at $q=1/2$.",
    "pdf_url": "http://arxiv.org/pdf/2506.01612v1",
    "published": "2025-06-02T12:51:17+00:00",
    "categories": [
      "math.PR",
      "math.CO",
      "60K35"
    ],
    "primary_category": "math.PR"
  },
  {
    "id": "http://arxiv.org/abs/2506.01611v1",
    "title": "Lessons Learned from the URGENT 2024 Speech Enhancement Challenge",
    "authors": [
      "Wangyou Zhang",
      "Kohei Saijo",
      "Samuele Cornell",
      "Robin Scheibler",
      "Chenda Li",
      "Zhaoheng Ni",
      "Anurag Kumar",
      "Marvin Sach",
      "Wei Wang",
      "Yihui Fu",
      "Shinji Watanabe",
      "Tim Fingscheidt",
      "Yanmin Qian"
    ],
    "abstract": "The URGENT 2024 Challenge aims to foster speech enhancement (SE) techniques\nwith great universality, robustness, and generalizability, featuring a broader\ntask definition, large-scale multi-domain data, and comprehensive evaluation\nmetrics. Nourished by the challenge outcomes, this paper presents an in-depth\nanalysis of two key, yet understudied, issues in SE system development: data\ncleaning and evaluation metrics. We highlight several overlooked problems in\ntraditional SE pipelines: (1) mismatches between declared and effective audio\nbandwidths, along with label noise even in various \"high-quality\" speech\ncorpora; (2) lack of both effective SE systems to conquer the hardest\nconditions (e.g., speech overlap, strong noise / reverberation) and reliable\nmeasure of speech sample difficulty; (3) importance of combining multifaceted\nmetrics for a comprehensive evaluation correlating well with human judgment. We\nhope that this endeavor can inspire improved SE pipeline designs in the future.",
    "pdf_url": "http://arxiv.org/pdf/2506.01611v1",
    "published": "2025-06-02T12:50:37+00:00",
    "categories": [
      "eess.AS",
      "cs.SD",
      "eess.SP"
    ],
    "primary_category": "eess.AS"
  },
  {
    "id": "http://arxiv.org/abs/2506.01610v1",
    "title": "Bernstein-Markov measures and Toeplitz theory",
    "authors": [
      "Siarhei Finski"
    ],
    "abstract": "We prove that Toeplitz operators associated with a Bernstein-Markov measure\non a compact complex manifold endowed with a big line bundle form an algebra\nunder composition. As an application, we derive a Szeg\\H{o}-type spectral\nequidistribution result for this class of operators. A key component of our\napproach is the off-diagonal asymptotic analysis of the Bergman kernel, also\nknown as the Christoffel-Darboux kernel.",
    "pdf_url": "http://arxiv.org/pdf/2506.01610v1",
    "published": "2025-06-02T12:50:06+00:00",
    "categories": [
      "math.CV",
      "math.AG",
      "math.FA",
      "math.SP",
      "32A25, 32U15, 42C05, 47B35, 15B05"
    ],
    "primary_category": "math.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.01609v1",
    "title": "Network Digital Twin for 6G and Beyond: An End-to-End View Across Multi-Domain Network Ecosystems",
    "authors": [
      "Dinh-Hieu Tran",
      "Nazar Waheed",
      "Yuris Mulya Saputra",
      "Xingqin Lin",
      "Cong T. Nguyen",
      "Tedros Salih Abdu",
      "Van Nhan Vo",
      "Van-Quan Pham",
      "Madyan Alsenwi",
      "Abuzar Babikir Mohammad Adam",
      "Symeon Chatzinotas",
      "Eva Lagaunas",
      "Hung Tran",
      "Tu Ho Dac",
      "Nguyen Van Huynh"
    ],
    "abstract": "With the rapid development of technology, the number of smart mobile users is\nincreasing, accompanied by growing demands from applications such as\nvirtual/augmented reality (VR/XR), remote surgery, autonomous vehicles, and\nreal-time holographic communications, all of which require high transmission\nrates and ultra-low latency in 6G and beyond networks (6G+). This poses\nenormous challenges in efficiently deploying large-scale networks, including\nnetwork design, planning, troubleshooting, optimization, and maintenance,\nwithout affecting the user experience. Network Digital Twin (NDT) has emerged\nas a potential solution, enabling the creation of a virtual model that reflects\nthe actual network, supporting the simulation of various network designs,\napplying diverse operating policies, and reproducing complex fault scenarios\nunder real-world conditions. This motivate us for this study, where we provide\na comprehensive survey of NDT in the context of 6G+, covering areas such as\nradio access networks (RAN), transport networks, 5G core networks and beyond\n(5GCORE+), cloud/edge computing, applications (blockchain, health system,\nmanufacturing, security, and vehicular networks), non-terrestrial networks\n(NTNs), and quantum networks, from both academic and industrial perspectives.\nIn particular, we are the first to provide an in-depth guide and usage of RAN\nand 5GCORE+ for NDT. Then, we provide an extensive review of foundation\ntechnologies such as transport networks, cloud/edge computing, applications,\nNTNs, and quantum networks in NDT. Finally, we discuss the key challenges, open\nissues, and future research directions for NDT in the context of 6G+.",
    "pdf_url": "http://arxiv.org/pdf/2506.01609v1",
    "published": "2025-06-02T12:49:51+00:00",
    "categories": [
      "cs.NI",
      "eess.SP"
    ],
    "primary_category": "cs.NI"
  },
  {
    "id": "http://arxiv.org/abs/2506.01608v2",
    "title": "EPFL-Smart-Kitchen-30: Densely annotated cooking dataset with 3D kinematics to challenge video and language models",
    "authors": [
      "Andy Bonnetto",
      "Haozhe Qi",
      "Franklin Leong",
      "Matea Tashkovska",
      "Mahdi Rad",
      "Solaiman Shokur",
      "Friedhelm Hummel",
      "Silvestro Micera",
      "Marc Pollefeys",
      "Alexander Mathis"
    ],
    "abstract": "Understanding behavior requires datasets that capture humans while carrying\nout complex tasks. The kitchen is an excellent environment for assessing human\nmotor and cognitive function, as many complex actions are naturally exhibited\nin kitchens from chopping to cleaning. Here, we introduce the\nEPFL-Smart-Kitchen-30 dataset, collected in a noninvasive motion capture\nplatform inside a kitchen environment. Nine static RGB-D cameras, inertial\nmeasurement units (IMUs) and one head-mounted HoloLens~2 headset were used to\ncapture 3D hand, body, and eye movements. The EPFL-Smart-Kitchen-30 dataset is\na multi-view action dataset with synchronized exocentric, egocentric, depth,\nIMUs, eye gaze, body and hand kinematics spanning 29.7 hours of 16 subjects\ncooking four different recipes. Action sequences were densely annotated with\n33.78 action segments per minute. Leveraging this multi-modal dataset, we\npropose four benchmarks to advance behavior understanding and modeling through\n1) a vision-language benchmark, 2) a semantic text-to-motion generation\nbenchmark, 3) a multi-modal action recognition benchmark, 4) a pose-based\naction segmentation benchmark. We expect the EPFL-Smart-Kitchen-30 dataset to\npave the way for better methods as well as insights to understand the nature of\necologically-valid human behavior. Code and data are available at\nhttps://github.com/amathislab/EPFL-Smart-Kitchen",
    "pdf_url": "http://arxiv.org/pdf/2506.01608v2",
    "published": "2025-06-02T12:46:44+00:00",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "q-bio.OT"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.02086v1",
    "title": "FSM Modeling For Off-Blockchain Computation",
    "authors": [
      "Christian Gang Liu"
    ],
    "abstract": "Blockchain benefits are due to immutability, replication, and\nstorage-and-execution of smart contracts on the blockchain. However, the\nbenefits come at increased costs due to the blockchain size and execution. We\naddress three fundamental issues that arise in transferring certain parts of a\nsmart contract to be executed off-chain: (i) identifying which parts (patterns)\nof the smart contract should be considered for processing off-chain, (ii) under\nwhich conditions should a smart-contract pattern to be processed off-chain, and\n(iii) how to facilitate interaction between the computation off and on-chain.\nWe use separation of concerns and FSM modeling to model a smart contract and\ngenerate its code. We then (i) use our algorithm to determine which parts\n(patterns) of the smart contract are to be processed off-chain; (ii) consider\nconditions under which to move the pattern off-chain; and (iii) provide model\nfor automatically generating the interface between on and off-chain\ncomputation.",
    "pdf_url": "http://arxiv.org/pdf/2506.02086v1",
    "published": "2025-06-02T12:46:31+00:00",
    "categories": [
      "cs.DC",
      "cs.SE"
    ],
    "primary_category": "cs.DC"
  },
  {
    "id": "http://arxiv.org/abs/2506.01607v2",
    "title": "The free boundary for a superlinear system",
    "authors": [
      "Daniela De Silva",
      "Seongmin Jeon",
      "Henrik Shahgholian"
    ],
    "abstract": "In this paper, we study superlinear systems that give rise to free\nboundaries. Such systems appear for example from the minimization of the energy\nfunctional $$\n\\int_{\\Omega}\\left(|\\nabla\\mathbf{u}|^2+\\frac2p|\\mathbf{u}|^p\\right),\\quad\n0<p<1, $$ but solutions can be also understood in an ad hoc viscosity way.\nFirst, we prove the optimal regularity of minimizers using a variational\napproach. Then, we apply a linearization technique to establish the\n$C^{1,\\alpha}$-regularity of the ``flat'' part of the free boundary via a\nviscosity method. Finally, for minimizing free boundaries, we extend this\nresult to analyticity.",
    "pdf_url": "http://arxiv.org/pdf/2506.01607v2",
    "published": "2025-06-02T12:45:53+00:00",
    "categories": [
      "math.AP",
      "35R35, 35J60"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2506.01606v1",
    "title": "The Boundary Reproduction Number for Determining Boundary Steady State Stability in Chemical Reaction Systems",
    "authors": [
      "Matthew D. Johnston",
      "Florin Avram"
    ],
    "abstract": "We introduce the boundary reproduction number, adapted from the next\ngeneration matrix method, to assess whether an infusion of species will persist\nor become exhausted in a chemical reaction system. Our main contributions are\nas follows: (a) we show how the concept of a siphon, prevalent in Petri nets\nand chemical reaction network theory, identifies sets of species that may\nbecome depleted at steady state, analogous to a disease-free boundary steady\nstate; (b) we develop an approach for incorporating biochemically motivated\nconservation laws, which allows the stability of boundary steady states to be\ndetermined within specific compatibility classes; and (c) we present an\neffective heuristic for decomposing the Jacobian of the system that reduces the\ncomputational complexity required to compute the stability domain of a boundary\nsteady state. The boundary reproduction number approach significantly\nsimplifies existing parameter-dependent methods for determining the stability\nof boundary steady states in chemical reaction systems and has implications for\nthe capacity of critical metabolites and substrates in metabolic pathways to\nbecome exhausted.",
    "pdf_url": "http://arxiv.org/pdf/2506.01606v1",
    "published": "2025-06-02T12:44:47+00:00",
    "categories": [
      "q-bio.MN",
      "math.DS",
      "34D05, 92D30"
    ],
    "primary_category": "q-bio.MN"
  },
  {
    "id": "http://arxiv.org/abs/2506.01605v1",
    "title": "Turnpike property of linear quadratic control problems with unbounded control operators",
    "authors": [
      "Hoai-Minh Nguyen",
      "Emmanuel Trélat"
    ],
    "abstract": "We establish the turnpike property for linear quadratic control problems for\nwhich the control operator is admissible and may be unbounded, under quite\ngeneral and natural assumptions. The turnpike property has been well studied\nfor bounded control operators, based on the theory of differential and\nalgebraic Riccati equations. For unbounded control operators, there are only\nfew results, limited to some special cases of hyperbolic systems in dimension\none or to analytic semigroups. Our analysis is inspired by the pioneering work\nof Porretta and Zuazua \\cite{PZ13}. We start by approximating the admissible\ncontrol operator with a sequence of bounded ones. We then prove the convergence\nof the approximate problems to the initial one in a suitable sense.\nEstablishing this convergence is the core of the paper. It requires to revisit\nin some sense the linear quadratic optimal control theory with admissible\ncontrol operators, in which the roles of energy and adjoint states, and the\nconnection between infinite-horizon and finite-horizon optimal control problems\nwith an appropriate final cost are investigated.",
    "pdf_url": "http://arxiv.org/pdf/2506.01605v1",
    "published": "2025-06-02T12:43:51+00:00",
    "categories": [
      "math.OC",
      "math.AP"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2506.01604v1",
    "title": "Exploring Prompt Patterns in AI-Assisted Code Generation: Towards Faster and More Effective Developer-AI Collaboration",
    "authors": [
      "Sophia DiCuffa",
      "Amanda Zambrana",
      "Priyanshi Yadav",
      "Sashidhar Madiraju",
      "Khushi Suman",
      "Eman Abdullah AlOmar"
    ],
    "abstract": "The growing integration of AI tools in software development, particularly\nLarge Language Models (LLMs) such as ChatGPT, has revolutionized how developers\napproach coding tasks. However, achieving high-quality code often requires\niterative interactions, which can be time-consuming and inefficient. This paper\nexplores the application of structured prompt patterns to minimize the number\nof interactions required for satisfactory AI-assisted code generation. Using\nthe DevGPT dataset, we analyzed seven distinct prompt patterns to evaluate\ntheir effectiveness in reducing back-and-forth communication between developers\nand AI. Our findings highlight patterns such as ''Context and Instruction'' and\n''Recipe'' as particularly effective in achieving high-quality outputs with\nminimal iterations. The study emphasizes the potential for prompt engineering\nto streamline developer-AI collaboration, providing practical insights into\ncrafting prompts that balance precision, efficiency, and clarity.",
    "pdf_url": "http://arxiv.org/pdf/2506.01604v1",
    "published": "2025-06-02T12:43:08+00:00",
    "categories": [
      "cs.SE"
    ],
    "primary_category": "cs.SE"
  },
  {
    "id": "http://arxiv.org/abs/2506.02085v1",
    "title": "Unveiling Audio Deepfake Origins: A Deep Metric learning And Conformer Network Approach With Ensemble Fusion",
    "authors": [
      "Ajinkya Kulkarni",
      "Sandipana Dowerah",
      "Tanel Alumae",
      "Mathew Magimai. -Doss"
    ],
    "abstract": "Audio deepfakes are acquiring an unprecedented level of realism with advanced\nAI. While current research focuses on discerning real speech from spoofed\nspeech, tracing the source system is equally crucial. This work proposes a\nnovel audio source tracing system combining deep metric multi-class N-pair loss\nwith Real Emphasis and Fake Dispersion framework, a Conformer classification\nnetwork, and ensemble score-embedding fusion. The N-pair loss improves\ndiscriminative ability, while Real Emphasis and Fake Dispersion enhance\nrobustness by focusing on differentiating real and fake speech patterns. The\nConformer network captures both global and local dependencies in the audio\nsignal, crucial for source tracing. The proposed ensemble score-embedding\nfusion shows an optimal trade-off between in-domain and out-of-domain source\ntracing scenarios. We evaluate our method using Frechet Distance and standard\nmetrics, demonstrating superior performance in source tracing over the baseline\nsystem.",
    "pdf_url": "http://arxiv.org/pdf/2506.02085v1",
    "published": "2025-06-02T12:42:09+00:00",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.CL",
      "eess.AS"
    ],
    "primary_category": "cs.SD"
  },
  {
    "id": "http://arxiv.org/abs/2506.01603v1",
    "title": "Vietoris--Rips Shadow for Euclidean Graph Reconstruction",
    "authors": [
      "Rafal Komendarczyk",
      "Sushovan Majhi",
      "Atish Mitra"
    ],
    "abstract": "The shadow of an abstract simplicial complex $K$ with vertices in $\\mathbb\nR^N$ is a subset of $\\mathbb R^N$ defined as the union of the convex hulls of\nsimplices of $K$. The Vietoris--Rips complex of a metric space $(S,d)$ at scale\n$\\beta$ is an abstract simplicial complex whose each $k$-simplex corresponds to\n$(k+1)$ points of $S$ within diameter $\\beta$. In case $S\\subset\\mathbb R^2$\nand $d(a,b)=\\|a-b\\|$ standard Euclidean, the natural shadow projection of the\nVietoris--Rips is already proved to be $1$-connected. We extend the result\nbeyond the standard Euclidean distance on $S\\subset\\mathbb R^N$ to a family of\npath-based metrics $d^\\varepsilon_{S}$. From the pairwise Euclidean distances\nof points of $S$, we introduce a family (parametrized by $\\varepsilon$) of\npath-based Vietoris--Rips complexes $R^\\varepsilon_\\beta(S)$ for a scale\n$\\beta>0$. If $S\\subset\\mathbb R^2$ is Hausdorff-close to a planar Euclidean\ngraph $G$, we provide quantitative bounds on scales $\\beta,\\varepsilon$ for the\nshadow projection map of the Vietoris--Rips of $(S,d^\\varepsilon_{S})$ at scale\n$\\beta$ to be $1$-connected. As a novel application, this paper first studies\nthe homotopy-type recovery of $G\\subset\\mathbb R^N$ using the abstract\nVietoris--Rips complex of a Hausdorff-close sample $S$ under the\n$d^\\varepsilon_{S}$ metric. Then, our result on the $1$-connectivity of the\nshadow projection lends itself to providing also a geometrically close\nembedding for the reconstruction. Based on the length of the shortest loop and\nlarge-scale distortion of the embedding of $G$, we quantify the choice of a\nsuitable sample density $\\varepsilon$ and a scale $\\beta$ at which the shadow\nof $R^\\varepsilon_\\beta(S)$ is homotopy-equivalent and Hausdorff-close to $G$.",
    "pdf_url": "http://arxiv.org/pdf/2506.01603v1",
    "published": "2025-06-02T12:41:34+00:00",
    "categories": [
      "math.AT",
      "cs.CG"
    ],
    "primary_category": "math.AT"
  },
  {
    "id": "http://arxiv.org/abs/2506.01602v2",
    "title": "Word Sense Detection Leveraging Maximum Mean Discrepancy",
    "authors": [
      "Kensuke Mitsuzawa"
    ],
    "abstract": "Word sense analysis is an essential analysis work for interpreting the\nlinguistic and social backgrounds. The word sense change detection is a task of\nidentifying and interpreting shifts in word meanings over time. This paper\nproposes MMD-Sense-Analysis, a novel approach that leverages Maximum Mean\nDiscrepancy (MMD) to select semantically meaningful variables and quantify\nchanges across time periods. This method enables both the identification of\nwords undergoing sense shifts and the explanation of their evolution over\nmultiple historical periods. To my knowledge, this is the first application of\nMMD to word sense change detection. Empirical assessment results demonstrate\nthe effectiveness of the proposed approach.",
    "pdf_url": "http://arxiv.org/pdf/2506.01602v2",
    "published": "2025-06-02T12:40:46+00:00",
    "categories": [
      "cs.CL",
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.01601v1",
    "title": "Fuelprop: Fuel property prediction from ATR-FTIR spectroscopic data",
    "authors": [
      "Mohammed Almomtan",
      "Emad Al Ibrahim",
      "Aamir Farooq"
    ],
    "abstract": "Synthetic fuels are crucial for decarbonizing the transportation sector. A\nsignificant challenge lies in the rapid and efficient characterization of these\nfuels. Chemometric methods using ATR-FTIR data offer a potential alternative to\nconventional techniques. This study expands the applicability and performance\nof chemometric models by providing an extensive ATR-FTIR spectral dataset and\nexploring various data enhancement strategies. Data enhancement was achieved by\nsemi-supervised data generation, consistency enforcement through unsupervised\ndata augmentation, and data imputation using synthetic spectra blending and\npseudo-labeling. Models were trained on surrogate fuels and rigorously tested\non real fuels, representing out-of-distribution testing conditions. We believe\nthat this work will enhance the adoption of chemometric models for fuel\ncharacterization.",
    "pdf_url": "http://arxiv.org/pdf/2506.01601v1",
    "published": "2025-06-02T12:36:31+00:00",
    "categories": [
      "physics.chem-ph"
    ],
    "primary_category": "physics.chem-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.01600v1",
    "title": "WoMAP: World Models For Embodied Open-Vocabulary Object Localization",
    "authors": [
      "Tenny Yin",
      "Zhiting Mei",
      "Tao Sun",
      "Lihan Zha",
      "Emily Zhou",
      "Jeremy Bao",
      "Miyu Yamane",
      "Ola Shorinwa",
      "Anirudha Majumdar"
    ],
    "abstract": "Language-instructed active object localization is a critical challenge for\nrobots, requiring efficient exploration of partially observable environments.\nHowever, state-of-the-art approaches either struggle to generalize beyond\ndemonstration datasets (e.g., imitation learning methods) or fail to generate\nphysically grounded actions (e.g., VLMs). To address these limitations, we\nintroduce WoMAP (World Models for Active Perception): a recipe for training\nopen-vocabulary object localization policies that: (i) uses a Gaussian\nSplatting-based real-to-sim-to-real pipeline for scalable data generation\nwithout the need for expert demonstrations, (ii) distills dense rewards signals\nfrom open-vocabulary object detectors, and (iii) leverages a latent world model\nfor dynamics and rewards prediction to ground high-level action proposals at\ninference time. Rigorous simulation and hardware experiments demonstrate\nWoMAP's superior performance in a broad range of zero-shot object localization\ntasks, with more than 9x and 2x higher success rates compared to VLM and\ndiffusion policy baselines, respectively. Further, we show that WoMAP achieves\nstrong generalization and sim-to-real transfer on a TidyBot.",
    "pdf_url": "http://arxiv.org/pdf/2506.01600v1",
    "published": "2025-06-02T12:35:14+00:00",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2506.01599v1",
    "title": "Connecting Neural Models Latent Geometries with Relative Geodesic Representations",
    "authors": [
      "Hanlin Yu",
      "Berfin Inal",
      "Georgios Arvanitidis",
      "Soren Hauberg",
      "Francesco Locatello",
      "Marco Fumero"
    ],
    "abstract": "Neural models learn representations of high-dimensional data on\nlow-dimensional manifolds. Multiple factors, including stochasticities in the\ntraining process, model architectures, and additional inductive biases, may\ninduce different representations, even when learning the same task on the same\ndata. However, it has recently been shown that when a latent structure is\nshared between distinct latent spaces, relative distances between\nrepresentations can be preserved, up to distortions. Building on this idea, we\ndemonstrate that exploiting the differential-geometric structure of latent\nspaces of neural models, it is possible to capture precisely the\ntransformations between representational spaces trained on similar data\ndistributions. Specifically, we assume that distinct neural models parametrize\napproximately the same underlying manifold, and introduce a representation\nbased on the pullback metric that captures the intrinsic structure of the\nlatent space, while scaling efficiently to large models. We validate\nexperimentally our method on model stitching and retrieval tasks, covering\nautoencoders and vision foundation discriminative models, across diverse\narchitectures, datasets, and pretraining schemes.",
    "pdf_url": "http://arxiv.org/pdf/2506.01599v1",
    "published": "2025-06-02T12:34:55+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.01598v1",
    "title": "PMNO: A novel physics guided multi-step neural operator predictor for partial differential equations",
    "authors": [
      "Jin Song",
      "Kenji Kawaguchi",
      "Zhenya Yan"
    ],
    "abstract": "Neural operators, which aim to approximate mappings between\ninfinite-dimensional function spaces, have been widely applied in the\nsimulation and prediction of physical systems. However, the limited\nrepresentational capacity of network architectures, combined with their heavy\nreliance on large-scale data, often hinder effective training and result in\npoor extrapolation performance. In this paper, inspired by traditional\nnumerical methods, we propose a novel physics guided multi-step neural operator\n(PMNO) architecture to address these challenges in long-horizon prediction of\ncomplex physical systems. Distinct from general operator learning methods, the\nPMNO framework replaces the single-step input with multi-step historical data\nin the forward pass and introduces an implicit time-stepping scheme based on\nthe Backward Differentiation Formula (BDF) during backpropagation. This design\nnot only strengthens the model's extrapolation capacity but also facilitates\nmore efficient and stable training with fewer data samples, especially for\nlong-term predictions. Meanwhile, a causal training strategy is employed to\ncircumvent the need for multi-stage training and to ensure efficient end-to-end\noptimization. The neural operator architecture possesses resolution-invariant\nproperties, enabling the trained model to perform fast extrapolation on\narbitrary spatial resolutions. We demonstrate the superior predictive\nperformance of PMNO predictor across a diverse range of physical systems,\nincluding 2D linear system, modeling over irregular domain, complex-valued wave\ndynamics, and reaction-diffusion processes. Depending on the specific problem\nsetting, various neural operator architectures, including FNO, DeepONet, and\ntheir variants, can be seamlessly integrated into the PMNO framework.",
    "pdf_url": "http://arxiv.org/pdf/2506.01598v1",
    "published": "2025-06-02T12:33:50+00:00",
    "categories": [
      "cs.LG",
      "physics.comp-ph"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.01597v1",
    "title": "Policy Newton Algorithm in Reproducing Kernel Hilbert Space",
    "authors": [
      "Yixian Zhang",
      "Huaze Tang",
      "Chao Wang",
      "Wenbo Ding"
    ],
    "abstract": "Reinforcement learning (RL) policies represented in Reproducing Kernel\nHilbert Spaces (RKHS) offer powerful representational capabilities. While\nsecond-order optimization methods like Newton's method demonstrate faster\nconvergence than first-order approaches, current RKHS-based policy optimization\nremains constrained to first-order techniques. This limitation stems primarily\nfrom the intractability of explicitly computing and inverting the\ninfinite-dimensional Hessian operator in RKHS. We introduce Policy Newton in\nRKHS, the first second-order optimization framework specifically designed for\nRL policies represented in RKHS. Our approach circumvents direct computation of\nthe inverse Hessian operator by optimizing a cubic regularized auxiliary\nobjective function. Crucially, we leverage the Representer Theorem to transform\nthis infinite-dimensional optimization into an equivalent, computationally\ntractable finite-dimensional problem whose dimensionality scales with the\ntrajectory data volume. We establish theoretical guarantees proving convergence\nto a local optimum with a local quadratic convergence rate. Empirical\nevaluations on a toy financial asset allocation problem validate these\ntheoretical properties, while experiments on standard RL benchmarks demonstrate\nthat Policy Newton in RKHS achieves superior convergence speed and higher\nepisodic rewards compared to established first-order RKHS approaches and\nparametric second-order methods. Our work bridges a critical gap between\nnon-parametric policy representations and second-order optimization methods in\nreinforcement learning.",
    "pdf_url": "http://arxiv.org/pdf/2506.01597v1",
    "published": "2025-06-02T12:32:52+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.01596v1",
    "title": "Understanding and Improving Laplacian Positional Encodings For Temporal GNNs",
    "authors": [
      "Yaniv Galron",
      "Fabrizio Frasca",
      "Haggai Maron",
      "Eran Treister",
      "Moshe Eliasof"
    ],
    "abstract": "Temporal graph learning has applications in recommendation systems, traffic\nforecasting, and social network analysis. Although multiple architectures have\nbeen introduced, progress in positional encoding for temporal graphs remains\nlimited. Extending static Laplacian eigenvector approaches to temporal graphs\nthrough the supra-Laplacian has shown promise, but also poses key challenges:\nhigh eigendecomposition costs, limited theoretical understanding, and ambiguity\nabout when and how to apply these encodings. In this paper, we address these\nissues by (1) offering a theoretical framework that connects supra-Laplacian\nencodings to per-time-slice encodings, highlighting the benefits of leveraging\nadditional temporal connectivity, (2) introducing novel methods to reduce the\ncomputational overhead, achieving up to 56x faster runtimes while scaling to\ngraphs with 50,000 active nodes, and (3) conducting an extensive experimental\nstudy to identify which models, tasks, and datasets benefit most from these\nencodings. Our findings reveal that while positional encodings can\nsignificantly boost performance in certain scenarios, their effectiveness\nvaries across different models.",
    "pdf_url": "http://arxiv.org/pdf/2506.01596v1",
    "published": "2025-06-02T12:30:58+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.01595v1",
    "title": "A Systematic Mapping Study on Software Architecture for AI-based Mobility Systems",
    "authors": [
      "Amra Ramic",
      "Stefan Kugele"
    ],
    "abstract": "Background: Due to their diversity, complexity, and above all importance,\nsafety-critical and dependable systems must be developed with special\ndiligence. Criticality increases as these systems likely contain artificial\nintelligence (AI) components known for their uncertainty. As software and\nreference architectures form the backbone of any successful system, including\nsafety-critical dependable systems with learning-enabled components, choosing\nthe suitable architecture that guarantees safety despite uncertainties is of\ngreat eminence.\n  Aim: We aim to provide the missing overview of all existing architectures,\ntheir contribution to safety, and their level of maturity in AI-based\nsafety-critical systems.\n  Method: To achieve this aim, we report a systematic mapping study. From a set\nof 1,639 primary studies, we selected 38 relevant studies dealing with safety\nassurance through software architecture in AI-based safety-critical systems.\nThe selected studies were then examined using various criteria to answer the\nresearch questions and identify gaps in this area of research.\n  Results: Our findings showed which architectures have been proposed and to\nwhat extent they have been implemented. Furthermore, we identified gaps in\ndifferent application areas of those systems and explained these gaps with\nvarious arguments.\n  Conclusion: As the AI trend continues to grow, the system complexity will\ninevitably increase, too. To ensure the lasting safety of the systems, we\nprovide an overview of the state of the art, intending to identify best\npractices and research gaps and direct future research more focused.",
    "pdf_url": "http://arxiv.org/pdf/2506.01595v1",
    "published": "2025-06-02T12:29:54+00:00",
    "categories": [
      "cs.SE"
    ],
    "primary_category": "cs.SE"
  },
  {
    "id": "http://arxiv.org/abs/2506.01594v1",
    "title": "Selecting for Less Discriminatory Algorithms: A Relational Search Framework for Navigating Fairness-Accuracy Trade-offs in Practice",
    "authors": [
      "Hana Samad",
      "Michael Akinwumi",
      "Jameel Khan",
      "Christoph Mügge-Durum",
      "Emmanuel O. Ogundimu"
    ],
    "abstract": "As machine learning models are increasingly embedded into society through\nhigh-stakes decision-making, selecting the right algorithm for a given task,\naudience, and sector presents a critical challenge, particularly in the context\nof fairness. Traditional assessments of model fairness have often framed\nfairness as an objective mathematical property, treating model selection as an\noptimization problem under idealized informational conditions. This overlooks\nmodel multiplicity as a consideration--that multiple models can deliver similar\nperformance while exhibiting different fairness characteristics. Legal scholars\nhave engaged this challenge through the concept of Less Discriminatory\nAlgorithms (LDAs), which frames model selection as a civil rights obligation.\nIn real-world deployment, this normative challenge is bounded by constraints on\nfairness experimentation, e.g., regulatory standards, institutional priorities,\nand resource capacity.\n  Against these considerations, the paper revisits Lee and Floridi (2021)'s\nrelational fairness approach using updated 2021 Home Mortgage Disclosure Act\n(HMDA) data, and proposes an expansion of the scope of the LDA search process.\nWe argue that extending the LDA search horizontally, considering fairness\nacross model families themselves, provides a lightweight complement, or\nalternative, to within-model hyperparameter optimization, when operationalizing\nfairness in non-experimental, resource constrained settings. Fairness metrics\nalone offer useful, but insufficient signals to accurately evaluate candidate\nLDAs. Rather, by using a horizontal LDA search approach with the relational\ntrade-off framework, we demonstrate a responsible minimum viable LDA search on\nreal-world lending outcomes. Organizations can modify this approach to\nsystematically compare, evaluate, and select LDAs that optimize fairness and\naccuracy in a sector-based contextualized manner.",
    "pdf_url": "http://arxiv.org/pdf/2506.01594v1",
    "published": "2025-06-02T12:28:51+00:00",
    "categories": [
      "cs.LG",
      "cs.CY",
      "I.2.1; I.2.6; K.4.1; K.5.2"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.01593v1",
    "title": "Nanoelectrospray ionization coupled to a linear charge detection array ion trap spectrometer for single viral particles analysis",
    "authors": [
      "S. Maclot",
      "T. Reinert",
      "L. Duplantier",
      "G. Montagne",
      "C. Clavier",
      "X. Dagany",
      "C. Comby-Zerbino",
      "M. Kerleroux",
      "L. Thiede",
      "R. Pogan",
      "C. Uetrecht",
      "A. N. Kozhinov",
      "K. O. Nagornov",
      "Y. O. Tsybin",
      "D. Papanastasiou",
      "R. Antoine"
    ],
    "abstract": "This work presents the implementation of a new charge detection mass\nspectrometer (CDMS) design that operates in a stand-alone mode, thanks to its\nintegration with nanoelectrospray ionization. More specifically, this\ninnovative CDMS consists of a linear charge detection array ion trap\nspectrometer that combines an eight-tube detector array with conical\nelectrodes. This configuration allows for recording data in both transmission\nmode (linear array) and ion trapping mode (ConeArrayTrap), which enables the\nmeasurement of time-of-flight (related to the mass-to-charge ratio) along with\nthe charge of individual ions. As a result, this design supports\nhigh-throughput metrology of viruses at the single-particle level. The devices\nand geometry of the instrument have been developed based on ion optics\nsimulations. The performance of the current instrument is demonstrated using\nhuman norovirus-like particles (hNoVLP) and Adenovirus Ad(5) (hAdV5).",
    "pdf_url": "http://arxiv.org/pdf/2506.01593v1",
    "published": "2025-06-02T12:28:21+00:00",
    "categories": [
      "physics.ins-det",
      "physics.bio-ph",
      "physics.chem-ph"
    ],
    "primary_category": "physics.ins-det"
  },
  {
    "id": "http://arxiv.org/abs/2506.01592v1",
    "title": "Statement-Tuning Enables Efficient Cross-lingual Generalization in Encoder-only Models",
    "authors": [
      "Ahmed Elshabrawy",
      "Thanh-Nhi Nguyen",
      "Yeeun Kang",
      "Lihan Feng",
      "Annant Jain",
      "Faadil Abdullah Shaikh",
      "Jonibek Mansurov",
      "Mohamed Fazli Mohamed Imam",
      "Jesus-German Ortiz-Barajas",
      "Rendi Chevi",
      "Alham Fikri Aji"
    ],
    "abstract": "Large Language Models (LLMs) excel in zero-shot and few-shot tasks, but\nachieving similar performance with encoder-only models like BERT and RoBERTa\nhas been challenging due to their architecture. However, encoders offer\nadvantages such as lower computational and memory costs. Recent work adapts\nthem for zero-shot generalization using Statement Tuning, which reformulates\ntasks into finite templates. We extend this approach to multilingual NLP,\nexploring whether encoders can achieve zero-shot cross-lingual generalization\nand serve as efficient alternatives to memory-intensive LLMs for low-resource\nlanguages. Our results show that state-of-the-art encoder models generalize\nwell across languages, rivaling multilingual LLMs while being more efficient.\nWe also analyze multilingual Statement Tuning dataset design, efficiency gains,\nand language-specific generalization, contributing to more inclusive and\nresource-efficient NLP models. We release our code and models.",
    "pdf_url": "http://arxiv.org/pdf/2506.01592v1",
    "published": "2025-06-02T12:28:03+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.01591v1",
    "title": "Silence is Golden: Leveraging Adversarial Examples to Nullify Audio Control in LDM-based Talking-Head Generation",
    "authors": [
      "Yuan Gan",
      "Jiaxu Miao",
      "Yunze Wang",
      "Yi Yang"
    ],
    "abstract": "Advances in talking-head animation based on Latent Diffusion Models (LDM)\nenable the creation of highly realistic, synchronized videos. These fabricated\nvideos are indistinguishable from real ones, increasing the risk of potential\nmisuse for scams, political manipulation, and misinformation. Hence, addressing\nthese ethical concerns has become a pressing issue in AI security. Recent\nproactive defense studies focused on countering LDM-based models by adding\nperturbations to portraits. However, these methods are ineffective at\nprotecting reference portraits from advanced image-to-video animation. The\nlimitations are twofold: 1) they fail to prevent images from being manipulated\nby audio signals, and 2) diffusion-based purification techniques can\neffectively eliminate protective perturbations. To address these challenges, we\npropose Silencer, a two-stage method designed to proactively protect the\nprivacy of portraits. First, a nullifying loss is proposed to ignore audio\ncontrol in talking-head generation. Second, we apply anti-purification loss in\nLDM to optimize the inverted latent feature to generate robust perturbations.\nExtensive experiments demonstrate the effectiveness of Silencer in proactively\nprotecting portrait privacy. We hope this work will raise awareness among the\nAI security community regarding critical ethical issues related to talking-head\ngeneration techniques. Code: https://github.com/yuangan/Silencer.",
    "pdf_url": "http://arxiv.org/pdf/2506.01591v1",
    "published": "2025-06-02T12:26:46+00:00",
    "categories": [
      "cs.GR",
      "cs.CR",
      "cs.CV",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.GR"
  },
  {
    "id": "http://arxiv.org/abs/2506.01590v1",
    "title": "Higher-order soft and virtual corrections in $p p \\to γW$ production at the LHC",
    "authors": [
      "Nikolaos Kidonakis",
      "Alberto Tonero"
    ],
    "abstract": "We study higher-order QCD corrections beyond NLO for the associated\nproduction of a photon with a $W$ boson ($\\gamma W^+$ and $\\gamma W^-$\nproduction) at the Large Hadron Collider. We calculate the NNLO\nsoft-plus-virtual QCD corrections as well as the N$^3$LO soft-gluon corrections\nto the total production cross section and the photon transverse-momentum\ndistribution in single-particle-inclusive kinematics. The higher-order\ncorrections provide a significant enhancement to the cross section. This is the\nfirst calculation of the complete soft-gluon corrections at N$^3$LO in\nsingle-particle-inclusive kinematics for a Standard Model process.",
    "pdf_url": "http://arxiv.org/pdf/2506.01590v1",
    "published": "2025-06-02T12:25:31+00:00",
    "categories": [
      "hep-ph"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.01589v1",
    "title": "On the number of edges of restricted matchstick graphs",
    "authors": [
      "Panna Gehér",
      "János Pach",
      "Konrad Swanepoel",
      "Géza Tóth"
    ],
    "abstract": "A graph whose vertices are points in the plane and whose edges are\nnoncrossing straight-line segments of unit length is called a \\emph{matchstick\ngraph}. We prove two somewhat counterintuitive results concerning the maximum\nnumber of edges of such graphs in two different scenarios.\n  First, we show that there is a constant $c>0$ such that every triangle-free\nmatchstick graph on $n$ vertices has at most $2n-c\\sqrt{n}$ edges. This\nstatement is not true for any $c>\\sqrt2.$\n  We also prove that for every $r>0$, there is a constant $\\varepsilon(r)>0$\nwith the property that every matchstick graph on $n$ vertices contained in a\ndisk of radius $r$ has at most $(2-\\varepsilon(r))n$ edges.",
    "pdf_url": "http://arxiv.org/pdf/2506.01589v1",
    "published": "2025-06-02T12:22:32+00:00",
    "categories": [
      "math.CO"
    ],
    "primary_category": "math.CO"
  },
  {
    "id": "http://arxiv.org/abs/2506.01588v3",
    "title": "Learning Perceptually Relevant Temporal Envelope Morphing",
    "authors": [
      "Satvik Dixit",
      "Sungjoon Park",
      "Chris Donahue",
      "Laurie M. Heller"
    ],
    "abstract": "Temporal envelope morphing, the process of interpolating between the\namplitude dynamics of two audio signals, is an emerging problem in generative\naudio systems that lacks sufficient perceptual grounding. Morphing of temporal\nenvelopes in a perceptually intuitive manner should enable new methods for\nsound blending in creative media and for probing perceptual organization in\npsychoacoustics. However, existing audio morphing techniques often fail to\nproduce intermediate temporal envelopes when input sounds have distinct\ntemporal structures; many morphers effectively overlay both temporal\nstructures, leading to perceptually unnatural results. In this paper, we\nintroduce a novel workflow for learning envelope morphing with perceptual\nguidance: we first derive perceptually grounded morphing principles through\nhuman listening studies, then synthesize large-scale datasets encoding these\nprinciples, and finally train machine learning models to create perceptually\nintermediate morphs. Specifically, we present: (1) perceptual principles that\nguide envelope morphing, derived from our listening studies, (2) a supervised\nframework to learn these principles, (3) an autoencoder that learns to compress\ntemporal envelope structures into latent representations, and (4) benchmarks\nfor evaluating audio envelope morphs, using both synthetic and naturalistic\ndata, and show that our approach outperforms existing methods in producing\ntemporally intermediate morphs. All code, models, and checkpoints are available\nat https://github.com/TemporalMorphing/EnvelopeMorphing.",
    "pdf_url": "http://arxiv.org/pdf/2506.01588v3",
    "published": "2025-06-02T12:20:51+00:00",
    "categories": [
      "cs.SD",
      "eess.AS",
      "eess.SP"
    ],
    "primary_category": "cs.SD"
  },
  {
    "id": "http://arxiv.org/abs/2506.01587v1",
    "title": "Unified Large Language Models for Misinformation Detection in Low-Resource Linguistic Settings",
    "authors": [
      "Muhammad Islam",
      "Javed Ali Khan",
      "Mohammed Abaker",
      "Ali Daud",
      "Azeem Irshad"
    ],
    "abstract": "The rapid expansion of social media platforms has significantly increased the\ndissemination of forged content and misinformation, making the detection of\nfake news a critical area of research. Although fact-checking efforts\npredominantly focus on English-language news, there is a noticeable gap in\nresources and strategies to detect news in regional languages, such as Urdu.\nAdvanced Fake News Detection (FND) techniques rely heavily on large, accurately\nlabeled datasets. However, FND in under-resourced languages like Urdu faces\nsubstantial challenges due to the scarcity of extensive corpora and the lack of\nvalidated lexical resources. Current Urdu fake news datasets are often\ndomain-specific and inaccessible to the public. They also lack human\nverification, relying mainly on unverified English-to-Urdu translations, which\ncompromises their reliability in practical applications. This study highlights\nthe necessity of developing reliable, expert-verified, and domain-independent\nUrdu-enhanced FND datasets to improve fake news detection in Urdu and other\nresource-constrained languages. This paper presents the first benchmark large\nFND dataset for Urdu news, which is publicly available for validation and deep\nanalysis. We also evaluate this dataset using multiple state-of-the-art\npre-trained large language models (LLMs), such as XLNet, mBERT, XLM-RoBERTa,\nRoBERTa, DistilBERT, and DeBERTa. Additionally, we propose a unified LLM model\nthat outperforms the others with different embedding and feature extraction\ntechniques. The performance of these models is compared based on accuracy, F1\nscore, precision, recall, and human judgment for vetting the sample results of\nnews.",
    "pdf_url": "http://arxiv.org/pdf/2506.01587v1",
    "published": "2025-06-02T12:19:28+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.01586v1",
    "title": "Multi-Modal Dataset Distillation in the Wild",
    "authors": [
      "Zhuohang Dang",
      "Minnan Luo",
      "Chengyou Jia",
      "Hangwei Qian",
      "Xiaojun Chang",
      "Ivor W. Tsang"
    ],
    "abstract": "Recent multi-modal models have shown remarkable versatility in real-world\napplications. However, their rapid development encounters two critical data\nchallenges. First, the training process requires large-scale datasets, leading\nto substantial storage and computational costs. Second, these data are\ntypically web-crawled with inevitable noise, i.e., partially mismatched pairs,\nseverely degrading model performance. To these ends, we propose Multi-modal\ndataset Distillation in the Wild, i.e., MDW, the first framework to distill\nnoisy multi-modal datasets into compact clean ones for effective and efficient\nmodel training. Specifically, MDW introduces learnable fine-grained\ncorrespondences during distillation and adaptively optimizes distilled data to\nemphasize correspondence-discriminative regions, thereby enhancing distilled\ndata's information density and efficacy. Moreover, to capture robust\ncross-modal correspondence prior knowledge from real data, MDW proposes\ndual-track collaborative learning to avoid the risky data noise, alleviating\ninformation loss with certifiable noise tolerance. Extensive experiments\nvalidate MDW's theoretical and empirical efficacy with remarkable scalability,\nsurpassing prior methods by over 15% across various compression ratios,\nhighlighting its appealing practicality for applications with diverse efficacy\nand resource needs.",
    "pdf_url": "http://arxiv.org/pdf/2506.01586v1",
    "published": "2025-06-02T12:18:20+00:00",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.01585v1",
    "title": "An Effective Sphaleron Awakens",
    "authors": [
      "Xu-Xiang Li",
      "Michael J. Ramsey-Musolf",
      "Tuomas V. I. Tenkanen",
      "Yanda Wu"
    ],
    "abstract": "Using thermal effective field theory, we present a self-consistent\nperturbative formulation of the Higgs phase sphaleron rate after a\nradiatively-induced first-order phase transition. This gauge-invariant\nformulation is based on dimensionally reduced effective field theory (3D EFT)\nat high temperatures and paves a way for including higher order corrections\nwithin the 3D EFT perturbation theory without double counting. Concretely, we\ncompute the Higgs phase sphaleron rate in a semi-classical approximation within\nthe two-loop resummed 3D EFT. We find compact results for the sphaleron rate\nand the baryon washout factor as well as criteria for the baryon number\npreservation by providing a clear connection to the results obtained using a\nsimilar 3D EFT description for the bubble nucleation. We demonstrate these\ncalculations for the real triplet-extended Standard Model, and conclude that\nwhen all two-loop thermal effects for the matching are accounted, no\nsufficiently strong one-step electroweak phase transitions exist within the\nparameter space regime that can be mapped onto the 3D EFT we have considered.",
    "pdf_url": "http://arxiv.org/pdf/2506.01585v1",
    "published": "2025-06-02T12:18:06+00:00",
    "categories": [
      "hep-ph"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.01584v1",
    "title": "VirnyFlow: A Design Space for Responsible Model Development",
    "authors": [
      "Denys Herasymuk",
      "Nazar Protsiv",
      "Julia Stoyanovich"
    ],
    "abstract": "Developing machine learning (ML) models requires a deep understanding of\nreal-world problems, which are inherently multi-objective. In this paper, we\npresent VirnyFlow, the first design space for responsible model development,\ndesigned to assist data scientists in building ML pipelines that are tailored\nto the specific context of their problem. Unlike conventional AutoML\nframeworks, VirnyFlow enables users to define customized optimization criteria,\nperform comprehensive experimentation across pipeline stages, and iteratively\nrefine models in alignment with real-world constraints. Our system integrates\nevaluation protocol definition, multi-objective Bayesian optimization,\ncost-aware multi-armed bandits, query optimization, and distributed parallelism\ninto a unified architecture. We show that VirnyFlow significantly outperforms\nstate-of-the-art AutoML systems in both optimization quality and scalability\nacross five real-world benchmarks, offering a flexible, efficient, and\nresponsible alternative to black-box automation in ML development.",
    "pdf_url": "http://arxiv.org/pdf/2506.01584v1",
    "published": "2025-06-02T12:16:48+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.01583v1",
    "title": "FreqPolicy: Frequency Autoregressive Visuomotor Policy with Continuous Tokens",
    "authors": [
      "Yiming Zhong",
      "Yumeng Liu",
      "Chuyang Xiao",
      "Zemin Yang",
      "Youzhuo Wang",
      "Yufei Zhu",
      "Ye Shi",
      "Yujing Sun",
      "Xinge Zhu",
      "Yuexin Ma"
    ],
    "abstract": "Learning effective visuomotor policies for robotic manipulation is\nchallenging, as it requires generating precise actions while maintaining\ncomputational efficiency. Existing methods remain unsatisfactory due to\ninherent limitations in the essential action representation and the basic\nnetwork architectures. We observe that representing actions in the frequency\ndomain captures the structured nature of motion more effectively: low-frequency\ncomponents reflect global movement patterns, while high-frequency components\nencode fine local details. Additionally, robotic manipulation tasks of varying\ncomplexity demand different levels of modeling precision across these frequency\nbands. Motivated by this, we propose a novel paradigm for visuomotor policy\nlearning that progressively models hierarchical frequency components. To\nfurther enhance precision, we introduce continuous latent representations that\nmaintain smoothness and continuity in the action space. Extensive experiments\nacross diverse 2D and 3D robotic manipulation benchmarks demonstrate that our\napproach outperforms existing methods in both accuracy and efficiency,\nshowcasing the potential of a frequency-domain autoregressive framework with\ncontinuous tokens for generalized robotic manipulation.",
    "pdf_url": "http://arxiv.org/pdf/2506.01583v1",
    "published": "2025-06-02T12:13:51+00:00",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2506.01582v1",
    "title": "Bayes optimal learning of attention-indexed models",
    "authors": [
      "Fabrizio Boncoraglio",
      "Emanuele Troiani",
      "Vittorio Erba",
      "Lenka Zdeborová"
    ],
    "abstract": "We introduce the attention-indexed model (AIM), a theoretical framework for\nanalyzing learning in deep attention layers. Inspired by multi-index models,\nAIM captures how token-level outputs emerge from layered bilinear interactions\nover high-dimensional embeddings. Unlike prior tractable attention models, AIM\nallows full-width key and query matrices, aligning more closely with practical\ntransformers. Using tools from statistical mechanics and random matrix theory,\nwe derive closed-form predictions for Bayes-optimal generalization error and\nidentify sharp phase transitions as a function of sample complexity, model\nwidth, and sequence length. We propose a matching approximate message passing\nalgorithm and show that gradient descent can reach optimal performance. AIM\noffers a solvable playground for understanding learning in modern attention\narchitectures.",
    "pdf_url": "http://arxiv.org/pdf/2506.01582v1",
    "published": "2025-06-02T12:11:26+00:00",
    "categories": [
      "cs.LG",
      "cond-mat.dis-nn",
      "cs.IT",
      "math.IT",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.01581v2",
    "title": "Unfolding the kagome lattice to improve understanding of ARPES in CoSn",
    "authors": [
      "Véronique Brouet",
      "Aaditya Vedant",
      "Francois Bertran",
      "Patrick Le Fèvre",
      "Oleg Rubel"
    ],
    "abstract": "Metallic kagome lattices are attracting significant attention as they provide\na platform to explore the interplay between topology and magnetism.\nAngle-resolved photoemission spectroscopy (ARPES) plays a key role in\nunraveling their electronic structure. However, the analysis is often\nchallenging due to the presence of multiple bands near the Fermi level. Indeed,\neach orbital generates three bands in a kagome lattice due to its three sites\nmotif, which soon becomes complicated if many orbitals are present. To address\nthis complexity, using ARPES matrix elements can be highly beneficial. First,\nband symmetry can be determined through selection rules based on light\npolarization. We emphasize that, in kagome lattices, as in all multi-site\nlattices, symmetry of the Bloch state is not only determined by the orbital\ncharacter but also by the relative phase between the three sublattices.\nAdditionally, interference between the three sublattices leads to a strong\nmodulation of ARPES intensity across neighboring Brillouin zones. We show how\nunfolded band calculations capture these modulations, helping with band\nidentification. We apply these ideas to CoSn, whose simple structure retains\nthe key features of a kagome lattice. Using polarization dependent ARPES in\nseveral Brillouin zones, we isolate the dispersion of each band and discuss\nnovel correlation effects, selectively renormalizing the bands crossing the\nFermi level and shifting the others.",
    "pdf_url": "http://arxiv.org/pdf/2506.01581v2",
    "published": "2025-06-02T12:11:19+00:00",
    "categories": [
      "cond-mat.str-el"
    ],
    "primary_category": "cond-mat.str-el"
  },
  {
    "id": "http://arxiv.org/abs/2506.01580v2",
    "title": "Unlocking the hybrid piezo and pyroelectric nanogenerators performance by SiO2 nanowires confinement in poly(vinylidene fluoride)",
    "authors": [
      "Juan Delgado-Alvarez",
      "Hari Krishna Mishra",
      "Francisco J. Aparicio",
      "Xabier Garcia-Casas",
      "Angel Barranco",
      "Juan R. Sanchez-Valencia",
      "Victor Lopez-Flores",
      "Ana Borras"
    ],
    "abstract": "We report on the development of a novel flexible piezo/pyro-electric\nnanogenerator (PPNG) that combines a uniform film of poly(vinylidene fluoride)\n(PVDF) infiltrated over vertically supported SiO2 nanowires (NWs) to enhance\nboth piezoelectric and pyroelectric energy harvesting capabilities. The\nsynthetic procedure involves a low-temperature multi-step approach, including\nthe soft-template formation of SiO2 NWs on a flexible substrate, followed by\nthe infiltration of a PVDF thin film (TF). The plasma-enabled fabrication of\nSiO2 NWs facilitated vertical alignment and precise control over the surface\nmicrostructure, density, and thickness of the confined nanostructures. These\nstrategic structural systems promote the development of the most favourable\nelectroactive \\b{eta}- and {\\gamma}-phases in the PVDF matrix. Notably, the\nelectrical poling plays a major role in aligning the random dipoles of the PVDF\nmacromolecular chain in a more ordered fashion to nucleate the amplified\nelectroactive phases. As a proof-of-concept, the fabricated PPNG exhibited a\nsignificant improvement in the instantaneous piezoelectric output power density\n(P), ~ 9-fold amplification relative to its bare PVDF TF counterpart.\nAnalogously, the pyroelectric coefficient (p) demonstrated a 4-fold superior\nperformance with referenced PVDF TF based PPNG. Thus, the engineered system of\nSiO2 NWs@PVDF comprising PPNG offers a promising pathway toward multisource\nenergy harvesting capabilities through efficient energy transduction at\nmechanical excitation frequencies of 10-12 Hz and across a temperature\ndifference ({\\Delta}T) of 9 to 22 K.",
    "pdf_url": "http://arxiv.org/pdf/2506.01580v2",
    "published": "2025-06-02T12:09:48+00:00",
    "categories": [
      "cond-mat.mtrl-sci",
      "physics.app-ph",
      "physics.plasm-ph"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2506.01579v1",
    "title": "HOSIG: Full-Body Human-Object-Scene Interaction Generation with Hierarchical Scene Perception",
    "authors": [
      "Wei Yao",
      "Yunlian Sun",
      "Hongwen Zhang",
      "Yebin Liu",
      "Jinhui Tang"
    ],
    "abstract": "Generating high-fidelity full-body human interactions with dynamic objects\nand static scenes remains a critical challenge in computer graphics and\nanimation. Existing methods for human-object interaction often neglect scene\ncontext, leading to implausible penetrations, while human-scene interaction\napproaches struggle to coordinate fine-grained manipulations with long-range\nnavigation. To address these limitations, we propose HOSIG, a novel framework\nfor synthesizing full-body interactions through hierarchical scene perception.\nOur method decouples the task into three key components: 1) a scene-aware grasp\npose generator that ensures collision-free whole-body postures with precise\nhand-object contact by integrating local geometry constraints, 2) a heuristic\nnavigation algorithm that autonomously plans obstacle-avoiding paths in complex\nindoor environments via compressed 2D floor maps and dual-component spatial\nreasoning, and 3) a scene-guided motion diffusion model that generates\ntrajectory-controlled, full-body motions with finger-level accuracy by\nincorporating spatial anchors and dual-space classifier-free guidance.\nExtensive experiments on the TRUMANS dataset demonstrate superior performance\nover state-of-the-art methods. Notably, our framework supports unlimited motion\nlength through autoregressive generation and requires minimal manual\nintervention. This work bridges the critical gap between scene-aware navigation\nand dexterous object manipulation, advancing the frontier of embodied\ninteraction synthesis. Codes will be available after publication. Project page:\nhttp://yw0208.github.io/hosig",
    "pdf_url": "http://arxiv.org/pdf/2506.01579v1",
    "published": "2025-06-02T12:08:08+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.01578v1",
    "title": "Prompt Engineering Large Language Models' Forecasting Capabilities",
    "authors": [
      "Philipp Schoenegger",
      "Cameron R. Jones",
      "Philip E. Tetlock",
      "Barbara Mellers"
    ],
    "abstract": "Large language model performance can be improved in a large number of ways.\nMany such techniques, like fine-tuning or advanced tool usage, are\ntime-intensive and expensive. Although prompt engineering is significantly\ncheaper and often works for simpler tasks, it remains unclear whether prompt\nengineering suffices for more complex domains like forecasting. Here we show\nthat small prompt modifications rarely boost forecasting accuracy beyond a\nminimal baseline. In our first study, we tested 38 prompts across Claude 3.5\nSonnet, Claude 3.5 Haiku, GPT-4o, and Llama 3.1 405B. In our second, we\nintroduced compound prompts and prompts from external sources, also including\nthe reasoning models o1 and o1-mini. Our results show that most prompts lead to\nnegligible gains, although references to base rates yield slight benefits.\nSurprisingly, some strategies showed strong negative effects on accuracy:\nespecially encouraging the model to engage in Bayesian reasoning. These results\nsuggest that, in the context of complex tasks like forecasting, basic prompt\nrefinements alone offer limited gains, implying that more robust or specialized\ntechniques may be required for substantial performance improvements in AI\nforecasting.",
    "pdf_url": "http://arxiv.org/pdf/2506.01578v1",
    "published": "2025-06-02T12:07:11+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.01577v1",
    "title": "Quasi-affine and quasi-quadratic maps of groups with non-abelian targets",
    "authors": [
      "Primoz Moravec"
    ],
    "abstract": "It is shown that the middle quasi-homomorphisms of Fujiwara and Kapovich are\nprecisely constant perturbations of quasi-homomorphisms. Quasi-polynomial maps\nare defined and their constructibility is explored. In particular, it is shown\nthat a large class of quasi-quadratic maps into torsion-free hyperbolic groups\nis rigid with respect to bounded perturbations.",
    "pdf_url": "http://arxiv.org/pdf/2506.01577v1",
    "published": "2025-06-02T12:04:53+00:00",
    "categories": [
      "math.GR"
    ],
    "primary_category": "math.GR"
  },
  {
    "id": "http://arxiv.org/abs/2506.01576v1",
    "title": "All You Need Is Binary Search! A Practical View on Lightweight Database Indexing on GPUs",
    "authors": [
      "Justus Henneberg",
      "Felix Schuhknecht"
    ],
    "abstract": "Performing binary search on a sorted dense array is a widely used baseline\nwhen benchmarking sophisticated index structures: It is simple, fast to build,\nand indexes the dataset with minimal memory footprint. However, the popular\nopinion is that it cannot compete with sophisticated indexes in terms of lookup\nperformance, and hence, should not actually be considered in practice.\n  Interestingly, in our recent works on (even more sophisticated) GPU-resident\nindex structures, we observed the surprisingly good performance of binary\nsearch in a variety of situations. As a consequence, in this work, we analyze\nthe reasons for this and perform three types of optimizations to the standard\nimplementation to push binary search to its limits on GPUs. We show that our\nhighly-optimized version of binary search outperforms the naive variant by up\nto a factor of 2x which makes it a practical alternative to full-fledged\nindexes, such as the state-of-the-art GPU B+-Tree, while consuming considerably\nless space and having a shorter build time. Apart from the optimizations, we\ndiscuss a generalization of binary search in form of K-ary search, which is\nable to consistently outperform the B+-Tree by a factor of 1.5x to 2.7x while\nhaving a negligible space overhead over binary search.",
    "pdf_url": "http://arxiv.org/pdf/2506.01576v1",
    "published": "2025-06-02T12:03:17+00:00",
    "categories": [
      "cs.DB"
    ],
    "primary_category": "cs.DB"
  },
  {
    "id": "http://arxiv.org/abs/2506.01575v1",
    "title": "Pluri-Gaussian rapid updating of geological domains",
    "authors": [
      "Sultan Abulkhair",
      "Peter Dowd",
      "Chaoshui Xu"
    ],
    "abstract": "Over the past decade, the rapid updating of resource knowledge and the\nintegration of real-time sensor information have garnered attention in both\nindustry and academia. However, most studies on rapid resource model updating\nhave focused on continuous variables, such as grade variables and coal quality\nparameters. Geological domain modelling is an essential component of resource\nestimation, which is why it is crucial to extend data assimilation techniques\nto enable the rapid updating of categorical variables. In this paper, a\nmethodology inspired by pluri-Gaussian simulation is proposed for\nnear-real-time updating of geological domains, followed by the updating of\ngrade variables within these domain boundaries. The proposed algorithm consists\nof a Gibbs sampler for converting geological domains into Gaussian random\nfields, an ensemble Kalman filter with multiple data assimilations (EnKF-MDA)\nfor rapid updating, and rotation based iterative Gaussianisation (RBIG) for\nmulti-Gaussian transformation. We demonstrate the algorithm using a synthetic\ncase study with observations sampled from the ground truth, as well as a real\ncase study that uses production drilling samples for joint updating of\ngeological domains and grade variables. Both case studies are based on real\ndata from an iron oxide-copper-gold deposit in South Australia. This approach\nenhances resource knowledge by incorporating both categorical and continuous\nvariables, leading to improved reproduction of domain geometries, closer\nmatches between predictions and observations, and more geologically realistic\nresource models.",
    "pdf_url": "http://arxiv.org/pdf/2506.01575v1",
    "published": "2025-06-02T12:01:37+00:00",
    "categories": [
      "stat.AP",
      "stat.ME"
    ],
    "primary_category": "stat.AP"
  },
  {
    "id": "http://arxiv.org/abs/2506.01574v2",
    "title": "Maximum volume coordinates for Grassmann interpolation: Lagrange, Hermite, and errors",
    "authors": [
      "Rasmus Jensen",
      "Ralf Zimmermann"
    ],
    "abstract": "We present a novel approach to Riemannian interpolation on the Grassmann\nmanifold. Instead of relying on the Riemannian normal coordinates, i.e. the\nRiemannian exponential and logarithm maps, we approach the interpolation\nproblem with an alternative set of local coordinates and corresponding\nparameterizations. A special property of these coordinates is that their\ncalculation does not require any matrix decompositions. This is a numerical\nadvantage over Riemann normal coordinates and many other retractions on the\nGrassmann manifold, especially when derivative data are to be treated. To\nestimate the interpolation error, we examine the conditioning of these mappings\nand state explicit bounds. It turns out that the parameterizations are\nwell-conditioned, but the coordinate mappings are generally not. As a remedy,\nwe introduce maximum-volume coordinates that are based on a search for\nsubblocks of column-orthogonal matrices of large absolute determinant. We show\nthat the order of magnitude of the asymptotic interpolation error on $\\Gr(n,p)$\nis the same as in the Euclidean space. Two numerical experiments are conducted.\nThe first is an academic one, where we interpolate a parametric orthogonal\nprojector $QQ^T$, where the $Q$--factor stems from a parametric compact\nQR--decomposition. The second experiment is in the context of parametric model\nreduction of dynamical systems, where we interpolate reduced subspaces that are\nobtained by proper orthogonal decomposition.",
    "pdf_url": "http://arxiv.org/pdf/2506.01574v2",
    "published": "2025-06-02T11:59:51+00:00",
    "categories": [
      "math.NA",
      "cs.NA",
      "15B10 15B57 65F99 53C30 53C80"
    ],
    "primary_category": "math.NA"
  },
  {
    "id": "http://arxiv.org/abs/2506.01573v1",
    "title": "Analyticity and asymptotic behavior of solutions to the compressible Navier-Stokes-Korteweg equations with the zero sound speed in scaling critical spaces",
    "authors": [
      "Takayuki Kobayashi",
      "Ryosuke Nakasato"
    ],
    "abstract": "We consider the initial-value problem in the $d$-dimensional Euclidean space\n$\\mathbb{R}^d$ $(d \\ge 3)$ for the compressible Navier-Stokes-Korteweg\nequations under the zero sound speed case (namely, $P'(\\rho_*)=0$, where\n$P=P(\\rho)$ stands for the pressure). The system is well-known as the Diffuse\nInterface model describing the motion of a vaper-liquid mixture in a\ncompressible viscous fluid. The purposes of this paper are to obtain the\nglobal-in-time solution around the constant equilibrium states $(\\rho_*,0)$\n$(\\rho_*>0)$ satisfying the estimate on the analyticity as established by\nFoias-Temam (1989), and investigate the $L^p$-$L^1$ type time-decay estimates\nin scaling critical settings based on Fourier-Herz spaces. In addition, we also\nderive the first order asymptotic formula with higher derivatives for solutions\nas the application of the analyticity.",
    "pdf_url": "http://arxiv.org/pdf/2506.01573v1",
    "published": "2025-06-02T11:57:20+00:00",
    "categories": [
      "math.AP"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2506.01572v1",
    "title": "Advanced Nanostructured Topical Therapeutics for Psoriasis: Strategic Synthesis, Multimodal Characterization, and Preliminary Pharmacodynamic Profiling",
    "authors": [
      "Iqra Yousaf",
      "Aqsa Yousaf"
    ],
    "abstract": "Psoriasis is a long-term inflammatory skin disease that remains difficult to\ntreat. In this study, we developed a new topical treatment by combining metal\noxide nanoparticles: cerium oxide (CeO2), zinc oxide (ZnO), and silver (Ag),\nwith natural plant extracts in a gel made from fish collagen and agar. The\nnanoparticles were characterized using UV-Vis spectroscopy, dynamic light\nscattering (DLS), Fourier-transform infrared spectroscopy (FTIR), and scanning\nelectron microscopy (SEM), showing good stability and a uniform particle size\ndistribution (ZnO averaged 66 nm).\n  To enhance therapeutic potential, the gel was enriched with plant-derived\nantioxidants from bitter melon, ginger, and neem. This formulation was tested\non an animal model of psoriasis. The treated group exhibited faster wound\nhealing and reduced inflammation compared to both placebo and untreated groups,\nwith statistically significant results (p < 0.01 to p < 0.001) observed from\nDay 3, becoming more pronounced by Day 14.\n  These results indicate that the combination of nanoparticles with plant-based\ncomponents in a topical gel may provide a promising new approach to psoriasis\ntreatment. Further studies are recommended to evaluate long-term safety and\ntherapeutic effectiveness.",
    "pdf_url": "http://arxiv.org/pdf/2506.01572v1",
    "published": "2025-06-02T11:56:19+00:00",
    "categories": [
      "physics.med-ph",
      "cs.AI",
      "physics.bio-ph",
      "92C50",
      "J.3; I.4.5; J.2"
    ],
    "primary_category": "physics.med-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.01571v1",
    "title": "A Ranking Framework for Network Resource Allocation and Scheduling via Hypergraphs",
    "authors": [
      "Rajpreet Singh",
      "Novak Boškov",
      "Aditya Gudal",
      "Manzoor A. Khan"
    ],
    "abstract": "Resource allocation and scheduling are a common problem in various\ndistributed systems. Although widely studied, the state-of-the-art solutions\neither do not scale or lack the expressive power to capture the most complex\ninstances of the problem. To that end, we present a mathematical framework for\nhypergraph ranking and analysis, unifying graph theory, lattice theory, and\nsemantic analysis. In our fundamental theorem, we prove the existence of\npartial order on entities of hypergraphs, extending traditional hypergraph\nanalysis by introducing semantic operators that capture relationships between\nvertices and hyperedges. Within the boundaries of our framework, we introduce\nan algorithm to rank the node-hyperedge pairs with respect to the captured\nsemantics. The strength of our approach lies in its applicability to complex\nranking problems that can be modeled as hypergraphs, including network resource\nallocation, task scheduling, and table selection in Text-to-SQL. Through\nsimulations, we demonstrate that our framework delivers nearly optimal problem\nsolutions at a superior run time performance.",
    "pdf_url": "http://arxiv.org/pdf/2506.01571v1",
    "published": "2025-06-02T11:55:41+00:00",
    "categories": [
      "cs.DS"
    ],
    "primary_category": "cs.DS"
  },
  {
    "id": "http://arxiv.org/abs/2506.01570v2",
    "title": "Long-time asymptotics of the defocusing mKdV equation with step initial data",
    "authors": [
      "Deng-Shan Wang",
      "Ding Wen"
    ],
    "abstract": "This work investigates the long-time asymptotics of solution to defocusing\nmodified Korteweg-de Vries equation with a class of step initial data. A\nrigorous asymptotic analysis is conducted on the associated Riemann-Hilbert\nproblem by applying Deift-Zhou nonlinear steepest descent method. In this\nprocess, the construction of odd-symmetry g-function is generalized and the\nmethod of genus reduction on the Riemann-theta function is proposed via\nconformal transformation and symmetries. It is revealed that for sufficiently\nlarge time, the solution manifests a tripartite spatiotemporal structure, i.e.,\nin the left plane-wave region, the solution decays to a modulated plane wave\nwith oscillatory correction; in the central dispersive shock wave region, the\nsolution is governed by a modulated elliptic periodic wave; in the right plane\nwave region, the solution converges exponentially to a constant. The results\nfrom the long-time asymptotic analysis have been shown to match remarkably well\nwith that obtained by direct numerical simulations.",
    "pdf_url": "http://arxiv.org/pdf/2506.01570v2",
    "published": "2025-06-02T11:54:12+00:00",
    "categories": [
      "math.AP",
      "math-ph",
      "math.MP"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2506.01569v1",
    "title": "Latent Space Topology Evolution in Multilayer Perceptrons",
    "authors": [
      "Eduardo Paluzo-Hidalgo"
    ],
    "abstract": "This paper introduces a topological framework for interpreting the internal\nrepresentations of Multilayer Perceptrons (MLPs). We construct a simplicial\ntower, a sequence of simplicial complexes connected by simplicial maps, that\ncaptures how data topology evolves across network layers. Our approach enables\nbi-persistence analysis: layer persistence tracks topological features within\neach layer across scales, while MLP persistence reveals how these features\ntransform through the network. We prove stability theorems for our topological\ndescriptors and establish that linear separability in latent spaces is related\nto disconnected components in the nerve complexes. To make our framework\npractical, we develop a combinatorial algorithm for computing MLP persistence\nand introduce trajectory-based visualisations that track data flow through the\nnetwork. Experiments on synthetic and real-world medical data demonstrate our\nmethod's ability to identify redundant layers, reveal critical topological\ntransitions, and provide interpretable insights into how MLPs progressively\norganise data for classification.",
    "pdf_url": "http://arxiv.org/pdf/2506.01569v1",
    "published": "2025-06-02T11:51:53+00:00",
    "categories": [
      "cs.LG",
      "math.AT"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.01568v2",
    "title": "Trajectory First: A Curriculum for Discovering Diverse Policies",
    "authors": [
      "Cornelius V. Braun",
      "Sayantan Auddy",
      "Marc Toussaint"
    ],
    "abstract": "Being able to solve a task in diverse ways makes agents more robust to task\nvariations and less prone to local optima. In this context, constrained\ndiversity optimization has emerged as a powerful reinforcement learning (RL)\nframework to train a diverse set of agents in parallel. However, existing\nconstrained-diversity RL methods often under-explore in complex tasks such as\nrobotic manipulation, leading to a lack in policy diversity. To improve\ndiversity optimization in RL, we therefore propose a curriculum that first\nexplores at the trajectory level before learning step-based policies. In our\nempirical evaluation, we provide novel insights into the shortcoming of\nskill-based diversity optimization, and demonstrate empirically that our\ncurriculum improves the diversity of the learned skills.",
    "pdf_url": "http://arxiv.org/pdf/2506.01568v2",
    "published": "2025-06-02T11:47:51+00:00",
    "categories": [
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.01567v1",
    "title": "Workflow decomposition algorithm for scheduling with quantum annealer-based hybrid solver",
    "authors": [
      "Marcin Kroczek",
      "Justyna Zawalska",
      "Katarzyna Rycerz"
    ],
    "abstract": "We introduce the Series-Parallel Workflow Decomposition (SP\\-WD) heuristic\nalgorithm for the Workflow Scheduling Problem (WSP) decomposition. We\ndemonstrate that the SPWD algorithm facilitates the scheduling of large WSP\ninstances with the hybrid D-Wave Constrained Quadratic Model solver, enabling\nthe scheduling of instances that would otherwise exceed its capacity\nlimitations. We also describe the accompanying execution environment used to\nobtain the results of the experiments with real-life workflow instances\navailable in the WfCommons standardization initiative repository.",
    "pdf_url": "http://arxiv.org/pdf/2506.01567v1",
    "published": "2025-06-02T11:47:43+00:00",
    "categories": [
      "cs.DC"
    ],
    "primary_category": "cs.DC"
  },
  {
    "id": "http://arxiv.org/abs/2506.01566v1",
    "title": "FlexiSAGA: A Flexible Systolic Array GEMM Accelerator for Sparse and Dense Processing",
    "authors": [
      "Mika Markus Müller",
      "Konstantin Lübeck",
      "Alexander Louis-Ferdinand Jung",
      "Jannik Steinmetz",
      "Oliver Bringmann"
    ],
    "abstract": "Artificial Intelligence (AI) algorithms, such as Deep Neural Networks (DNNs),\nhave become an important tool for a wide range of applications, from computer\nvision to natural language processing. However, the computational complexity of\nDNN inference poses a significant challenge, particularly for processing on\nresource-constrained edge devices. One promising approach to address this\nchallenge is the exploitation of sparsity in DNN operator weights.\n  In this work, we present FlexiSAGA, an architecturally configurable and\ndataflow-flexible AI hardware accelerator for the sparse and dense processing\nof general matrix multiplications (GEMMs). FlexiSAGA supports seven different\nsparse and dense dataflows, enabling efficient processing of resource intensive\nDNN operators. Additionally, we propose a DNN pruning method specifically\ntailored towards the FlexiSAGA architecture, allowing for near-optimal\nprocessing of dense and sparse convolution and fully-connected operators,\nfacilitating a DNN/HW co-design flow. Our results show a whole DNN\nsparse-over-dense inference speedup ranging from 1.41 up to 4.28, outperforming\ncommercial and literature-reported accelerator platforms.",
    "pdf_url": "http://arxiv.org/pdf/2506.01566v1",
    "published": "2025-06-02T11:45:37+00:00",
    "categories": [
      "cs.PF",
      "cs.AI",
      "cs.AR",
      "cs.LG"
    ],
    "primary_category": "cs.PF"
  },
  {
    "id": "http://arxiv.org/abs/2506.01565v2",
    "title": "Hanfu-Bench: A Multimodal Benchmark on Cross-Temporal Cultural Understanding and Transcreation",
    "authors": [
      "Li Zhou",
      "Lutong Yu",
      "Dongchu Xie",
      "Shaohuan Cheng",
      "Wenyan Li",
      "Haizhou Li"
    ],
    "abstract": "Culture is a rich and dynamic domain that evolves across both geography and\ntime. However, existing studies on cultural understanding with vision-language\nmodels (VLMs) primarily emphasize geographic diversity, often overlooking the\ncritical temporal dimensions. To bridge this gap, we introduce Hanfu-Bench, a\nnovel, expert-curated multimodal dataset. Hanfu, a traditional garment spanning\nancient Chinese dynasties, serves as a representative cultural heritage that\nreflects the profound temporal aspects of Chinese culture while remaining\nhighly popular in Chinese contemporary society. Hanfu-Bench comprises two core\ntasks: cultural visual understanding and cultural image transcreation.The\nformer task examines temporal-cultural feature recognition based on single- or\nmulti-image inputs through multiple-choice visual question answering, while the\nlatter focuses on transforming traditional attire into modern designs through\ncultural element inheritance and modern context adaptation. Our evaluation\nshows that closed VLMs perform comparably to non-experts on visual cutural\nunderstanding but fall short by 10\\% to human experts, while open VLMs lags\nfurther behind non-experts. For the transcreation task, multi-faceted human\nevaluation indicates that the best-performing model achieves a success rate of\nonly 42\\%. Our benchmark provides an essential testbed, revealing significant\nchallenges in this new direction of temporal cultural understanding and\ncreative adaptation.",
    "pdf_url": "http://arxiv.org/pdf/2506.01565v2",
    "published": "2025-06-02T11:43:46+00:00",
    "categories": [
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.01564v1",
    "title": "Interstellar Polarization Survey. V. Galactic magnetic field tomography in the spiral arms using optical and near-infrared starlight polarization",
    "authors": [
      "Y. Angarita",
      "M. J. F. Versteeg",
      "M. Haverkorn",
      "V. Pelgrims",
      "C. V. Rodrigues",
      "A. M. Magalhães",
      "R. Santos-Lima",
      "Koji S. Kawabata"
    ],
    "abstract": "Interstellar linear polarization occurs when starlight passes through\nelongated dust grains aligned by interstellar magnetic fields. The observed\npolarization can come from different dust structures along the line of sight\n(LOS). By combining polarization measurements with stellar distances, we can\nstudy the plane-of-sky Galactic magnetic field (GMF) between the observer and\nthe star and separate the contributions of clouds with different GMF\nproperties. We used optical and near-infrared (NIR) polarization data from\nthree regions in the Galactic plane ($|b|<1^{\\circ}$ and\n$19.\\!\\!^{\\circ}8<l<25.\\!\\!^{\\circ}5$) to perform a polarization decomposition\nacross the Galactic arms. A comparison between optical and NIR data showed an\noptical-to-NIR polarization ratio of 2 to 3 along the LOS and a consistent\npolarization angle across both wavelengths in all studied regions, within\nmeasurement uncertainties. We applied the Bayesian Inference of Starlight\nPolarization in one dimension and the Gaussian Mixture Model methods to\ndecompose the polarization in the three regions. Optical and NIR observations\ncomplemented each other, consistently identifying nearby ($d\\lesssim143$ pc),\nintermediate ($0.47$ kpc $< d < 1.2$ kpc), and distant ($1.5$ kpc $< d < 2.5$\nkpc) polarizing clouds, in agreement with previous findings in the Local Bubble\nwall, the Local arm, and the Sagittarius arm dust structures. The results from\nboth polarization decomposition methods agree and complement each other.\nPolarization tomography revealed significant LOS variations in the plane-of-sky\nmagnetic field orientation in two of the three regions. The relative alignment\nbetween the magnetic fields traced by starlight polarization and Planck's\npolarized thermal dust emission at 353 GHz reaffirmed these variations.",
    "pdf_url": "http://arxiv.org/pdf/2506.01564v1",
    "published": "2025-06-02T11:42:53+00:00",
    "categories": [
      "astro-ph.GA",
      "astro-ph.SR"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2506.01563v3",
    "title": "Hierarchical Intention-Aware Expressive Motion Generation for Humanoid Robots",
    "authors": [
      "Lingfan Bao",
      "Yan Pan",
      "Tianhu Peng",
      "Dimitrios Kanoulas",
      "Chengxu Zhou"
    ],
    "abstract": "Effective human-robot interaction requires robots to identify human\nintentions and generate expressive, socially appropriate motions in real-time.\nExisting approaches often rely on fixed motion libraries or computationally\nexpensive generative models. We propose a hierarchical framework that combines\nintention-aware reasoning via in-context learning (ICL) with real-time motion\ngeneration using diffusion models. Our system introduces structured prompting\nwith confidence scoring, fallback behaviors, and social context awareness to\nenable intention refinement and adaptive response. Leveraging large-scale\nmotion datasets and efficient latent-space denoising, the framework generates\ndiverse, physically plausible gestures suitable for dynamic humanoid\ninteractions. Experimental validation on a physical platform demonstrates the\nrobustness and social alignment of our method in realistic scenarios.",
    "pdf_url": "http://arxiv.org/pdf/2506.01563v3",
    "published": "2025-06-02T11:42:51+00:00",
    "categories": [
      "cs.RO"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2506.12068v1",
    "title": "Introducing the PIT-plot -- a new tool in the portfolio manager's toolkit",
    "authors": [
      "Stig-Johan Wiklund",
      "Magnus Ytterstad"
    ],
    "abstract": "Project portfolio management is an essential process for organizations aiming\nto optimize the value of their R&D investments. In this article, we introduce a\nnew tool designed to support the prioritization of projects within project\nportfolio management. We label this tool the PIT-plot, an acronym for Project\nImpact Tornado plot, with reference to the similarity to the Tornado plot often\nused for sensitivity analyses. Many traditional practices in portfolio\nmanagement focus on the properties of the projects available to the portfolio.\nWe are with the PIT-plot changing the perspective and focus not on the\nproperties of the projects themselves, but on the impact that the projects may\nhave on the portfolio. This enables the strategic portfolio management to\nidentify and focus on the projects of largest impact to the portfolio, either\nfor the purpose of risk mitigation or for the purpose of value-adding efforts.",
    "pdf_url": "http://arxiv.org/pdf/2506.12068v1",
    "published": "2025-06-02T11:42:36+00:00",
    "categories": [
      "q-fin.PM"
    ],
    "primary_category": "q-fin.PM"
  },
  {
    "id": "http://arxiv.org/abs/2506.04257v2",
    "title": "Deformation Due to Non-planar Fault Movement in Fractional Maxwell Medium",
    "authors": [
      "Pabita Mahato",
      "Seema Sarkar",
      "Subhash Chandra"
    ],
    "abstract": "In earthquake-prone regions, the accumulation of geophysical stress during\nthe aseismic period plays a critical role in determining which faults are more\nlikely to be reactivated in future seismic events. In this model, we consider\nan infinite non-planar fault located in a viscoelastic half-space of a\nfractional Maxwell medium representing the lithosphere-asthenosphere system\ncomprising three interconnected planar sections. The problem is formulated as a\ntwo-dimensional boundary value problem with discontinuities along the fault\nsurface. A numerical solution is obtained using a Laplace transformation,\nfractional derivative, correspondence principle and Green's function technique.\nThe outcomes are demonstrated graphically using appropriate model parameters.\nThe computational findings highlight the significant influence of fault motion\nand geometry in shaping the displacement, stress and strain fields in the\nvicinity of the fault zone. A study has been carried out to investigate how\nnon-planar faults influence displacement and the accumulation of stress and\nstrain. Analysis of these results can provide insights into subsurface\ndeformation and its impact on fault movement, which may contribute to the study\nof earthquake activity.",
    "pdf_url": "http://arxiv.org/pdf/2506.04257v2",
    "published": "2025-06-02T11:38:59+00:00",
    "categories": [
      "physics.geo-ph",
      "74D10, 26A33, 44A10, 33E12"
    ],
    "primary_category": "physics.geo-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.01562v1",
    "title": "Unpacking Softmax: How Temperature Drives Representation Collapse, Compression, and Generalization",
    "authors": [
      "Wojciech Masarczyk",
      "Mateusz Ostaszewski",
      "Tin Sum Cheng",
      "Tomasz Trzciński",
      "Aurelien Lucchi",
      "Razvan Pascanu"
    ],
    "abstract": "The softmax function is a fundamental building block of deep neural networks,\ncommonly used to define output distributions in classification tasks or\nattention weights in transformer architectures. Despite its widespread use and\nproven effectiveness, its influence on learning dynamics and learned\nrepresentations remains poorly understood, limiting our ability to optimize\nmodel behavior. In this paper, we study the pivotal role of the softmax\nfunction in shaping the model's representation. We introduce the concept of\nrank deficit bias - a phenomenon in which softmax-based deep networks find\nsolutions of rank much lower than the number of classes. This bias depends on\nthe softmax function's logits norm, which is implicitly influenced by\nhyperparameters or directly modified by softmax temperature. Furthermore, we\ndemonstrate how to exploit the softmax dynamics to learn compressed\nrepresentations or to enhance their performance on out-of-distribution data. We\nvalidate our findings across diverse architectures and real-world datasets,\nhighlighting the broad applicability of temperature tuning in improving model\nperformance. Our work provides new insights into the mechanisms of softmax,\nenabling better control over representation learning in deep neural networks.",
    "pdf_url": "http://arxiv.org/pdf/2506.01562v1",
    "published": "2025-06-02T11:38:10+00:00",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.01561v2",
    "title": "Physical Observers and Quantum Reconstructions",
    "authors": [
      "Dorian Daimer",
      "Susanne Still"
    ],
    "abstract": "There is a multitude of interpretations of quantum mechanics, but\nfoundational principles are lacking. Relational quantum mechanics views the\nobserver as a physical system, which allows for an unambiguous interpretation\nas all axioms are purely operational, describing how observers acquire\ninformation. The approach, however, is based on the premise that the observer\nretains only predictive information about the observed system. Here, we justify\nthis premise using the following principle: Physically embedded observers\nchoose information processing strategies that provide them with the option to\napproach physical limits to the greatest possible extent. Applied to a lower\nlimit on energy dissipation, the principle leads directly to a compact\npredictive model, thus justifying this core premise of relational quantum\nmechanics.",
    "pdf_url": "http://arxiv.org/pdf/2506.01561v2",
    "published": "2025-06-02T11:37:54+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.01560v1",
    "title": "SPAC: A Python Package for Spatial Single-Cell Analysis of Multiplex Imaging",
    "authors": [
      "Fang Liu",
      "Rui He",
      "Andrei Bombin",
      "Ahmad B. Abdallah",
      "Omar Eldaghar",
      "Tommy R. Sheeley",
      "Sam E. Ying",
      "George Zaki"
    ],
    "abstract": "Multiplexed immunofluorescence microscopy captures detailed measurements of\nspatially resolved, multiple biomarkers simultaneously, revealing tissue\ncomposition and cellular interactions in situ among single cells. The growing\nscale and dimensional complexity of these datasets demand reproducible,\ncomprehensive and user-friendly computational tools. To address this need, we\ndeveloped SPAC (SPAtial single-Cell analysis), a Python-based package and a\ncorresponding shiny application within an integrated, modular SPAC ecosystem\n(Liu et al., 2025) designed specifically for biologists without extensive\ncoding expertise. Following image segmentation and extraction of spatially\nresolved single-cell data, SPAC streamlines downstream phenotyping and spatial\nanalysis, facilitating characterization of cellular heterogeneity and spatial\norganization within tissues. Through scalable performance, specialized spatial\nstatistics, highly customizable visualizations, and seamless workflows from\ndataset to insights, SPAC significantly lowers barriers to sophisticated\nspatial analyses.",
    "pdf_url": "http://arxiv.org/pdf/2506.01560v1",
    "published": "2025-06-02T11:36:32+00:00",
    "categories": [
      "cs.SE",
      "q-bio.GN",
      "62P10",
      "J.3; I.5.4"
    ],
    "primary_category": "cs.SE"
  },
  {
    "id": "http://arxiv.org/abs/2506.01559v1",
    "title": "hqQUBO: A Hybrid-querying Quantum Optimization Model Validated with 16-qubits on an Ion Trap Quantum Computer for Life Science Applications",
    "authors": [
      "Rong Chen",
      "Quan-Xin Mei",
      "Wen-Ding Zhao",
      "Lin Yao",
      "Hao-Xiang Yang",
      "Shun-Yao Zhang",
      "Jiao Chen",
      "Hong-Lin Li"
    ],
    "abstract": "AlphaFold has achieved groundbreaking advancements in protein structure\nprediction, exerting profound influence across biology, medicine, and drug\ndiscovery. However, its reliance on multiple sequence alignment (MSA) is\ninherently time-consuming due to the NP-hard nature of constructing MSAs.\nQuantum computing emerges as a promising alternative, compared to classical\ncomputers, offering the potentials for exponential speedup and improved\naccuracy on such complex optimization challenges. This work bridges the gap\nbetween quantum computing and MSA task efficiently and successfully, where we\ncompared classical and quantum computational scaling as the number of qubits\nincreases, and assessed the role of quantum entanglement in model performance.\nFurthermore, we proposed an innovative hybrid query encoding approach hyQUBO to\navoid redundancy, and thereby the quantum resources significantly reduced to a\nscaling of $\\mathcal{O}(NL)$. Additionally, coupling of VQE and the quenched\nCVaR scheme was utilized to enhance the robustness and convergence. The\nintegration of multiple strategies facilitates the robust deployment of the\nquantum algorithm from idealized simulators (on CPU and GPU) to real-world,\nnoisy quantum devices (HYQ-A37). To the best of our knowledge, our work\nrepresented the largest-scale implementation of digital simulation using up to\n16 qubits on a trapped-ion quantum computer for life science problem, which\nachieved state of the art performance in both simulation and experimental\nresults. Our work paves the way towards large-scale simulations of life science\ntasks on real quantum processors.",
    "pdf_url": "http://arxiv.org/pdf/2506.01559v1",
    "published": "2025-06-02T11:36:30+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.01558v1",
    "title": "SAM2-LOVE: Segment Anything Model 2 in Language-aided Audio-Visual Scenes",
    "authors": [
      "Yuji Wang",
      "Haoran Xu",
      "Yong Liu",
      "Jiaze Li",
      "Yansong Tang"
    ],
    "abstract": "Reference Audio-Visual Segmentation (Ref-AVS) aims to provide a pixel-wise\nscene understanding in Language-aided Audio-Visual Scenes (LAVS). This task\nrequires the model to continuously segment objects referred to by text and\naudio from a video. Previous dual-modality methods always fail due to the lack\nof a third modality and the existing triple-modality method struggles with\nspatio-temporal consistency, leading to the target shift of different frames.\nIn this work, we introduce a novel framework, termed SAM2-LOVE, which\nintegrates textual, audio, and visual representations into a learnable token to\nprompt and align SAM2 for achieving Ref-AVS in the LAVS. Technically, our\napproach includes a multimodal fusion module aimed at improving multimodal\nunderstanding of SAM2, as well as token propagation and accumulation strategies\ndesigned to enhance spatio-temporal consistency without forgetting historical\ninformation. We conducted extensive experiments to demonstrate that SAM2-LOVE\noutperforms the SOTA by 8.5\\% in $\\mathcal{J\\&F}$ on the Ref-AVS benchmark and\nshowcase the simplicity and effectiveness of the components. Our code will be\navailable here.",
    "pdf_url": "http://arxiv.org/pdf/2506.01558v1",
    "published": "2025-06-02T11:36:25+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.01557v1",
    "title": "A general relativistic hydrodynamic simulation code for studying advective, sub-Keplerian accretion flow onto black holes",
    "authors": [
      "Sudip K Garain"
    ],
    "abstract": "In this paper, we describe a general relativistic hydrodynamics simulation\ncode which is developed to simulate advective accretion flow onto black holes.\nWe are particularly interested in the accretion simulations of sub-Keplerian\nmatter in the close vicinity of black holes. Due to the presence of centrifugal\nbarrier, a nearly free-falling sub-Keplerian accretion flow slows down close to\na black hole and can even pass through shocks before accelerating again to the\nblack hole. We design our simulation code using the high resolution shock\ncapturing scheme so that such shock structures can be captured and analyzed for\nrelevance. In this paper, we describe our implementation and validation of the\ncode against a few known analytical and numerical results of sub-Keplerian\nmatter accretion.",
    "pdf_url": "http://arxiv.org/pdf/2506.01557v1",
    "published": "2025-06-02T11:35:26+00:00",
    "categories": [
      "astro-ph.IM",
      "astro-ph.HE"
    ],
    "primary_category": "astro-ph.IM"
  },
  {
    "id": "http://arxiv.org/abs/2506.01556v1",
    "title": "On singular Lagrangian fibrations and applications to symplectic embeddings I",
    "authors": [
      "Santiago Achig-Andrango",
      "Renato Vianna",
      "Alejandro Vicente"
    ],
    "abstract": "In this paper, we construct singular Lagrangian fibrations on some examples\nof disk cotangent bundles in dimensions 4 and 6. As an application, we show how\nthis construction can be used to obtain toric domains in some cases. In\nparticular, we recover results from Ferreira, Ramos, and Vicente on the Gromov\nwidth of the disk cotangent bundle of spheres of revolution, as well as results\nfrom Ramos on the Lagrangian bidisk. We also briefly discuss how this technique\ncan be used to study symplectic embedding problems.",
    "pdf_url": "http://arxiv.org/pdf/2506.01556v1",
    "published": "2025-06-02T11:34:11+00:00",
    "categories": [
      "math.SG"
    ],
    "primary_category": "math.SG"
  },
  {
    "id": "http://arxiv.org/abs/2506.01555v1",
    "title": "The Exact and Approximate Tales of Boost-Breaking Cosmological Correlators",
    "authors": [
      "Zhehan Qin",
      "Sébastien Renaux-Petel",
      "Xi Tong",
      "Denis Werth",
      "Yuhang Zhu"
    ],
    "abstract": "Cosmological correlators offer a remarkable window into the high-energy\nphysics governing Universe's earliest moments, with the tantalising prospect of\ndiscovering new particles. However, extracting new physics from these\nobservables requires both precise theoretical predictions of inflationary\ntheories and accurate, analytical templates suitable for data analysis\nthroughout parameter and kinematic spaces. In this paper, we extend the current\nanalytical results by computing the most general boost-breaking seed correlator\nmediated by the tree-level exchange of a massive spinning particle. We derive\nthe result using two complementary approaches, bootstrapping from boundary\ndifferential equations, and direct spectral integration. Both representations\nare packaged as a single partially resummed series that converges in all\nphysical kinematics. Computing this correlator marks a milestone for carving\nout the space of all boost-breaking correlators, and therefore completes the\ntree-level catalogue. We then introduce a general procedure to obtain accurate\napproximations for cosmological collider signals based on the saddle-point\nmethod. This approach allows for a clear physical intuition of various signals\nhidden in correlators, as the bulk physics is made manifest through the\nlocation of these saddles in the complex time plane, which depend on the\nexternal kinematics. Evaluating the time integrals at these saddles yields\nresults given as elementary functions that remain valid beyond soft limits and\nprovide intuitive control over both the signal shape and amplitude. We\ndemonstrate the power of this method in both de Sitter-invariant and\nboost-breaking scenarios, and uncover novel refined waveform and strength\ndependence for oscillatory signals from massive fields. We provide a complete\ncosmological collider shape template capturing all boost-breaking effects for\nupcoming cosmological surveys.",
    "pdf_url": "http://arxiv.org/pdf/2506.01555v1",
    "published": "2025-06-02T11:33:45+00:00",
    "categories": [
      "hep-th",
      "astro-ph.CO",
      "gr-qc",
      "hep-ph"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2506.01554v1",
    "title": "Searching for charged Higgs bosons via $e^+ e^- \\to H^\\pm W^\\mp S$ at the ILC",
    "authors": [
      "Brahim Ait Ouazghour",
      "Abdesslam Arhrib",
      "Kingman Cheung",
      "Es-said Ghourmin",
      "Mohamed Krab",
      "Larbi Rahili"
    ],
    "abstract": "We investigate the phenomenology of the charged Higgs boson at the\nInternational Linear Collider (ILC) within the framework of the type-X\nTwo-Higgs Doublet Model (2HDM), where a light charged Higgs boson, with a mass\naround 200 GeV or even smaller than top quark mass, is still being consistent\nwith flavor physics data as well as with the colliders experimental data. In\nthe theoretically and experimentally allowed parameter space, the $e^+ e^- \\to\nH^\\pm W^\\mp S$ (with $S = H, A$) production processes can yield signatures with\nevent rates larger than those from $e^+ e^- \\to H^+ H^-$ and offer sensitivity\nto the Higgs mixing parameter $\\sin(\\beta-\\alpha)$. We consider the bosonic\n$H^\\pm \\to W^\\pm S$ decays, where the neutral scalar $S$ further decays into a\npair of tau leptons. We show, through a detector-level Monte Carlo analysis,\nthat the resulting $[\\tau\\tau][\\tau\\tau] WW$ final state could be seen at the\nILC with at least 500 GeV center-of-mass energy and 500 fb$^{-1}$ of\nluminosity.",
    "pdf_url": "http://arxiv.org/pdf/2506.01554v1",
    "published": "2025-06-02T11:33:26+00:00",
    "categories": [
      "hep-ph"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.01553v1",
    "title": "Eta-pairing states in Hubbard models with bond-charge interactions on general graphs",
    "authors": [
      "Ming-Yong Ye"
    ],
    "abstract": "We investigate Hubbard models with bond-charge interactions on general\ngraphs. For a Hamiltonian \\(H\\) of such a model, we provide the condition on\nits parameters under which the \\(\\eta\\)-pairing method can be employed to\nconstruct its exact eigenstates. We arrive at this condition by finding that\nthe requirement for the \\(\\eta\\)-pairing state \\((\\eta^\\dagger)^N |0\\rangle\\)\nto be an eigenstate of \\(H\\) is identical to the requirement for it to be an\neigenstate of a Hubbard-type Hamiltonian \\(H_m\\). When the condition for\n\\((\\eta^\\dagger)^N |0\\rangle\\) to be an eigenstate of the Hubbard-type\nHamiltonian \\(H_m\\) is satisfied, we demonstrate that there are additional\nstates, distinct from \\((\\eta^\\dagger)^N |0\\rangle\\), which are also exact\neigenstates of \\(H_m\\). Our results enhance the understanding of Hubbard models\non general graphs, both with and without bond-charge interactions.",
    "pdf_url": "http://arxiv.org/pdf/2506.01553v1",
    "published": "2025-06-02T11:32:31+00:00",
    "categories": [
      "cond-mat.str-el"
    ],
    "primary_category": "cond-mat.str-el"
  },
  {
    "id": "http://arxiv.org/abs/2506.01552v1",
    "title": "To Each Metric Its Decoding: Post-Hoc Optimal Decision Rules of Probabilistic Hierarchical Classifiers",
    "authors": [
      "Roman Plaud",
      "Alexandre Perez-Lebel",
      "Matthieu Labeau",
      "Antoine Saillenfest",
      "Thomas Bonald"
    ],
    "abstract": "Hierarchical classification offers an approach to incorporate the concept of\nmistake severity by leveraging a structured, labeled hierarchy. However,\ndecoding in such settings frequently relies on heuristic decision rules, which\nmay not align with task-specific evaluation metrics. In this work, we propose a\nframework for the optimal decoding of an output probability distribution with\nrespect to a target metric. We derive optimal decision rules for increasingly\ncomplex prediction settings, providing universal algorithms when candidates are\nlimited to the set of nodes. In the most general case of predicting a subset of\nnodes, we focus on rules dedicated to the hierarchical $hF_{\\beta}$ scores,\ntailored to hierarchical settings. To demonstrate the practical utility of our\napproach, we conduct extensive empirical evaluations, showcasing the\nsuperiority of our proposed optimal strategies, particularly in underdetermined\nscenarios. These results highlight the potential of our methods to enhance the\nperformance and reliability of hierarchical classifiers in real-world\napplications. The code is available at\nhttps://github.com/RomanPlaud/hierarchical_decision_rules",
    "pdf_url": "http://arxiv.org/pdf/2506.01552v1",
    "published": "2025-06-02T11:29:40+00:00",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.01551v2",
    "title": "EvolveNav: Self-Improving Embodied Reasoning for LLM-Based Vision-Language Navigation",
    "authors": [
      "Bingqian Lin",
      "Yunshuang Nie",
      "Khun Loun Zai",
      "Ziming Wei",
      "Mingfei Han",
      "Rongtao Xu",
      "Minzhe Niu",
      "Jianhua Han",
      "Liang Lin",
      "Cewu Lu",
      "Xiaodan Liang"
    ],
    "abstract": "Building Vision-Language Navigation (VLN) agents which can navigate following\nnatural language instructions is a long-standing goal in human-robot\ninteraction applications. Recent studies have revealed the potential of\ntraining open-source Large Language Models (LLMs) to unleash LLMs' reasoning\nability for improving navigation, and simultaneously mitigate the domain gap\nbetween LLMs' training corpus and the VLN task. However, these approaches\nprimarily adopt direct input-output mapping paradigms, causing the mapping\nlearning difficult and the navigational decisions unexplainable.\nChain-of-Thought (CoT) training is a promising way to improve both navigational\ndecision accuracy and interpretability, while the complexity of the navigation\ntask makes the perfect CoT labels unavailable and may lead to overfitting\nthrough pure CoT supervised fine-tuning. In this paper, we propose a novel\nsElf-improving embodied reasoning framework for boosting LLM-based\nvision-language Navigation, dubbed EvolveNav. Our EvolveNav consists of two\nstages: (1) Formalized CoT Supervised Fine-Tuning, where we train the model\nwith formalized CoT labels to both activate the model's navigational reasoning\ncapabilities and increase the reasoning speed; (2) Self-Reflective\nPost-Training, where the model is iteratively trained with its own reasoning\noutputs as self-enriched CoT labels to enhance the supervision diversity. A\nself-reflective auxiliary task is also introduced to encourage learning correct\nreasoning patterns by contrasting with wrong ones. Experimental results on the\npopular VLN benchmarks demonstrate the superiority of EvolveNav over previous\nLLM-based VLN approaches. Code is available at\nhttps://github.com/expectorlin/EvolveNav.",
    "pdf_url": "http://arxiv.org/pdf/2506.01551v2",
    "published": "2025-06-02T11:28:32+00:00",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.01550v1",
    "title": "Alignment Phase Transition in Socially Driven Motion",
    "authors": [
      "Debasish Sarker",
      "Yi Zhang",
      "Lynn K. Perry",
      "Daniel S. Messinger",
      "Chaoming Song"
    ],
    "abstract": "Collective human movement is a hallmark of complex systems, exhibiting\nemergent order across diverse settings, from pedestrian flows to biological\ncollectives. In high-speed scenarios, alignment interactions ensure efficient\nflow and navigation. In contrast, alignment in low-speed, socially engaged\ncontexts emerges not from locomotion goals but from interpersonal interaction.\nUsing high-resolution spatial and orientation data from preschool classrooms,\nwe uncover a sharp, distance-dependent transition in pairwise alignment\npatterns that reflects a spontaneous symmetry breaking between distinct\nbehavioral phases. Below a critical threshold of approximately 0.65\\,m,\nindividuals predominantly align side-by-side; beyond this range, face-to-face\norientations prevail. We show that this transition arises from a\ndistance-dependent competition among three alignment mechanisms:\nparallelization, opposition, and reciprocation, whose interplay generates a\nbifurcation structure in the effective interaction potential. A Fourier-based\ndecomposition of empirical orientation distributions reveals these mechanisms,\nenabling the construction of a minimal pseudo-potential model that captures the\nalignment transition as a non-equilibrium phase transition. Monte Carlo\nsimulations using the inferred interaction terms closely reproduce the\nempirical patterns. These findings establish a quantitative framework for\nsocial alignment in low-speed human motion, extending active matter theory to a\npreviously unexplored regime of socially mediated orientation dynamics, with\nimplications for modeling coordination and control in biological collectives\nand artificial swarms.",
    "pdf_url": "http://arxiv.org/pdf/2506.01550v1",
    "published": "2025-06-02T11:27:39+00:00",
    "categories": [
      "physics.soc-ph",
      "cond-mat.stat-mech",
      "nlin.AO"
    ],
    "primary_category": "physics.soc-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.01549v1",
    "title": "High-precision light curves of geostationary objects: The PHANTOM ECHOES 2 RPO campaign",
    "authors": [
      "Paul Chote",
      "Robert Airey",
      "James McCormac",
      "Don Pollacco",
      "Richard West",
      "Krzysztof Ulaczyk",
      "Martin J. Dyer",
      "Alexander Agathanggelou",
      "William Feline",
      "Simon George",
      "Calum Meredith",
      "Grant Privett"
    ],
    "abstract": "We present results from an extensive optical observation campaign that\nmonitored the Geostationary satellites Intelsat 10-02, Mission Extension\nVehicle 2, Thor 5, Thor 6, Thor 7, and Meteosat 11 over a 14 week period that\ncovered the proximity operations and docking of Mission Extension Vehicle 2\nwith Intelsat 10-02. High-cadence single-color photometric observations are\nsupplemented with targeted multi-color observations, high resolution imaging,\nand passive radio frequency positioning obtained using complementary\nfacilities.\n  The photometric signatures of the six targets are presented in the form of\ntwo-dimensional color maps. A selection of interesting features are\ninvestigated in further detail, including a rapid glinting behavior in Thor 6;\na brightening event from Meteosat 11; using glints to constrain the unresolved\npositions of Intelsat 10-02 and MEV-2; changes in the photometric signature of\nIntelsat 10-02 before and after docking; and signatures of attitude changes and\nmaneuvering in the light curves of MEV-2.\n  A detailed description of the photometric data reduction pipeline is also\npresented, with a focus on details that must be considered when aiming for\nsub-percent photometric precision.",
    "pdf_url": "http://arxiv.org/pdf/2506.01549v1",
    "published": "2025-06-02T11:24:28+00:00",
    "categories": [
      "astro-ph.IM"
    ],
    "primary_category": "astro-ph.IM"
  },
  {
    "id": "http://arxiv.org/abs/2506.01548v1",
    "title": "The Vlasov equation cannot fully account for collisionless shocks",
    "authors": [
      "Antoine Bret"
    ],
    "abstract": "It is argued that the Vlasov equation cannot fully account for collisionless\nshocks since it conserves entropy, while a shock does not. A rigorous\nmathematical theory of collisionless shocks could require working at the\nKlimontovich level.",
    "pdf_url": "http://arxiv.org/pdf/2506.01548v1",
    "published": "2025-06-02T11:24:05+00:00",
    "categories": [
      "physics.plasm-ph",
      "astro-ph.HE",
      "astro-ph.SR"
    ],
    "primary_category": "physics.plasm-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.01547v1",
    "title": "Quadratic Segre indices",
    "authors": [
      "Felipe Espreafico",
      "Stephen McKean",
      "Sabrina Pauli"
    ],
    "abstract": "We prove that the local Euler class of a line on a degree $2n-1$ hypersurface\nin projective $n+1$ space is given by a product of indices of Segre\ninvolutions. Segre involutions and their associated indices were first defined\nby Finashin and Kharlamov over the reals. Our result is valid over any field of\ncharacteristic not 2 and gives an infinite family of problems in enriched\nenumerative geometry with a shared geometric interpretation for the local type.",
    "pdf_url": "http://arxiv.org/pdf/2506.01547v1",
    "published": "2025-06-02T11:21:07+00:00",
    "categories": [
      "math.AG",
      "14N15, 14G27"
    ],
    "primary_category": "math.AG"
  },
  {
    "id": "http://arxiv.org/abs/2506.01546v1",
    "title": "LongDWM: Cross-Granularity Distillation for Building a Long-Term Driving World Model",
    "authors": [
      "Xiaodong Wang",
      "Zhirong Wu",
      "Peixi Peng"
    ],
    "abstract": "Driving world models are used to simulate futures by video generation based\non the condition of the current state and actions. However, current models\noften suffer serious error accumulations when predicting the long-term future,\nwhich limits the practical application. Recent studies utilize the Diffusion\nTransformer (DiT) as the backbone of driving world models to improve learning\nflexibility. However, these models are always trained on short video clips\n(high fps and short duration), and multiple roll-out generations struggle to\nproduce consistent and reasonable long videos due to the training-inference\ngap. To this end, we propose several solutions to build a simple yet effective\nlong-term driving world model. First, we hierarchically decouple world model\nlearning into large motion learning and bidirectional continuous motion\nlearning. Then, considering the continuity of driving scenes, we propose a\nsimple distillation method where fine-grained video flows are self-supervised\nsignals for coarse-grained flows. The distillation is designed to improve the\ncoherence of infinite video generation. The coarse-grained and fine-grained\nmodules are coordinated to generate long-term and temporally coherent videos.\nIn the public benchmark NuScenes, compared with the state-of-the-art front-view\nmodel, our model improves FVD by $27\\%$ and reduces inference time by $85\\%$\nfor the video task of generating 110+ frames. More videos (including 90s\nduration) are available at https://Wang-Xiaodong1899.github.io/longdwm/.",
    "pdf_url": "http://arxiv.org/pdf/2506.01546v1",
    "published": "2025-06-02T11:19:23+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.01545v1",
    "title": "Class Incremental Learning for Algorithm Selection",
    "authors": [
      "Mate Botond Nemeth",
      "Emma Hart",
      "Kevin Sim",
      "Quentin Renau"
    ],
    "abstract": "Algorithm selection is commonly used to predict the best solver from a\nportfolio per per-instance. In many real scenarios, instances arrive in a\nstream: new instances become available over time, while the number of class\nlabels can also grow as new data distributions arrive downstream. As a result,\nthe classification model needs to be periodically updated to reflect additional\nsolvers without catastrophic forgetting of past data. In machine-learning (ML),\nthis is referred to as Class Incremental Learning (CIL). While commonly\naddressed in ML settings, its relevance to algorithm-selection in optimisation\nhas not been previously studied. Using a bin-packing dataset, we benchmark 8\ncontinual learning methods with respect to their ability to withstand\ncatastrophic forgetting. We find that rehearsal-based methods significantly\noutperform other CIL methods. While there is evidence of forgetting, the loss\nis small at around 7%. Hence, these methods appear to be a viable approach to\ncontinual learning in streaming optimisation scenarios.",
    "pdf_url": "http://arxiv.org/pdf/2506.01545v1",
    "published": "2025-06-02T11:18:07+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.01544v1",
    "title": "Temporal Variational Implicit Neural Representations",
    "authors": [
      "Batuhan Koyuncu",
      "Rachael DeVries",
      "Ole Winther",
      "Isabel Valera"
    ],
    "abstract": "We introduce Temporal Variational Implicit Neural Representations (TV-INRs),\na probabilistic framework for modeling irregular multivariate time series that\nenables efficient individualized imputation and forecasting. By integrating\nimplicit neural representations with latent variable models, TV-INRs learn\ndistributions over time-continuous generator functions conditioned on\nsignal-specific covariates. Unlike existing approaches that require extensive\ntraining, fine-tuning or meta-learning, our method achieves accurate\nindividualized predictions through a single forward pass. Our experiments\ndemonstrate that with a single TV-INRs instance, we can accurately solve\ndiverse imputation and forecasting tasks, offering a computationally efficient\nand scalable solution for real-world applications. TV-INRs excel especially in\nlow-data regimes, where it outperforms existing methods by an order of\nmagnitude in mean squared error for imputation task.",
    "pdf_url": "http://arxiv.org/pdf/2506.01544v1",
    "published": "2025-06-02T11:12:30+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.01543v1",
    "title": "Dynamical dark energy in the no-scale Brans-Dicke gravity",
    "authors": [
      "Muzi Hong",
      "Kyohei Mukaida",
      "Tsutomu T. Yanagida"
    ],
    "abstract": "We add a new scalar field in the no-scale Brans-Dicke gravity and require it\nto have a global O(2) symmetry with the original scalar field in the\nBrans-Dicke gravity. This gives us a new massless scalar field in the Einstein\nframe due to the SO(2) symmetry. We then explicitly break the O(2) symmetry to\na $D_4$ symmetry, and this scalar field gains a periodic potential. This scalar\nfield can serve as the quintessence field to explain dark energy. If we further\nadd the $R^2$ term and the non-minimal coupling to the Higgs field, we can\nrealize inflation and reheating, and this leads to a super-Planckian decay\nconstant of the quintessence potential. The super-Planckian decay constant is\nconsistent with the newly released observational data according to a recent\nanalysis.",
    "pdf_url": "http://arxiv.org/pdf/2506.01543v1",
    "published": "2025-06-02T11:11:50+00:00",
    "categories": [
      "hep-ph",
      "astro-ph.CO",
      "gr-qc",
      "hep-th"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.01542v1",
    "title": "Optimal T depth quantum circuits for implementing arbitrary Boolean functions",
    "authors": [
      "Suman Dutta",
      "Anik Basu Bhaumik",
      "Anupam Chattopadhyay",
      "Subhamoy Maitra"
    ],
    "abstract": "In this paper we present a generic construction to obtain an optimal T depth\nquantum circuit for any arbitrary $n$-input $m$-output Boolean function $f:\n\\{0,1\\}^n \\rightarrow \\{0,1\\}^m$ having algebraic degree $k\\leq n$, and it\nachieves an exact Toffoli (and T) depth of $\\lceil \\log_2 k \\rceil$. This is a\nbroader generalization of the recent result establishing the optimal Toffoli\n(and consequently T) depth for multi-controlled Toffoli decompositions (Dutta\net al., Phys. Rev. A, 2025). We achieve this by inspecting the Algebraic Normal\nForm (ANF) of a Boolean function. Obtaining a benchmark for the minimum T depth\nof such circuits are of prime importance for efficient implementation of\nquantum algorithms by enabling greater parallelism, reducing time complexity,\nand minimizing circuit latency, making them suitable for near-term quantum\ndevices with limited coherence times. The implications of our results are\nhighlighted explaining the provable lower bounds on S-box and block cipher\nimplementations, for example AES.",
    "pdf_url": "http://arxiv.org/pdf/2506.01542v1",
    "published": "2025-06-02T11:07:54+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.01541v1",
    "title": "Adaptive Destruction Processes for Diffusion Samplers",
    "authors": [
      "Timofei Gritsaev",
      "Nikita Morozov",
      "Kirill Tamogashev",
      "Daniil Tiapkin",
      "Sergey Samsonov",
      "Alexey Naumov",
      "Dmitry Vetrov",
      "Nikolay Malkin"
    ],
    "abstract": "This paper explores the challenges and benefits of a trainable destruction\nprocess in diffusion samplers -- diffusion-based generative models trained to\nsample an unnormalised density without access to data samples. Contrary to the\nmajority of work that views diffusion samplers as approximations to an\nunderlying continuous-time model, we view diffusion models as discrete-time\npolicies trained to produce samples in very few generation steps. We propose to\ntrade some of the elegance of the underlying theory for flexibility in the\ndefinition of the generative and destruction policies. In particular, we\ndecouple the generation and destruction variances, enabling both transition\nkernels to be learned as unconstrained Gaussian densities. We show that, when\nthe number of steps is limited, training both generation and destruction\nprocesses results in faster convergence and improved sampling quality on\nvarious benchmarks. Through a robust ablation study, we investigate the design\nchoices necessary to facilitate stable training. Finally, we show the\nscalability of our approach through experiments on GAN latent space sampling\nfor conditional image generation.",
    "pdf_url": "http://arxiv.org/pdf/2506.01541v1",
    "published": "2025-06-02T11:07:27+00:00",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.01540v1",
    "title": "A nonparametric statistical method for deconvolving densities in the analysis of proteomic data",
    "authors": [
      "Akin Anarat",
      "Jean Krutmann",
      "Holger Schwender"
    ],
    "abstract": "In medical research, often, genomic or proteomic data are collected, with\nmeasurements frequently subject to uncertainties or errors, making it crucial\nto accurately separate the signals of the genes or proteins, respectively, from\nthe noise. Such a signal separation is also of interest in skin aging research\nin which intrinsic aging driven by genetic factors and extrinsic, i.e.\\\nenvironmentally induced, aging are investigated by considering, e.g., the\nproteome of skin fibroblasts. Since extrinsic influences on skin aging can only\nbe measured alongside intrinsic ones, it is essential to isolate the pure\nextrinsic signal from the combined intrinisic and extrinsic signal. In such\nsituations, deconvolution methods can be employed to estimate the signal's\ndensity function from the data. However, existing nonparametric deconvolution\napproaches often fail when the variance of the mixed distribution is\nsubstantially greater than the variance of the target distribution, which is a\ncommon issue in genomic and proteomic data.\n  We, therefore, propose a new nonparametric deconvolution method called\nN-Power Fourier Deconvolution (NPFD) that addresses this issue by employing the\n$N$-th power of the Fourier transform of transformed densities. This procedure\nutilizes the Fourier transform inversion theorem and exploits properties of\nFourier transforms of density functions to mitigate numerical inaccuracies\nthrough exponentiation, leading to accurate and smooth density estimation. An\nextensive simulation study demonstrates that NPFD effectively handles the\nvariance issues and performs comparably or better than existing deconvolution\nmethods in most scenarios. Moreover, applications to real medical data,\nparticularly to proteomic data from fibroblasts affected by intrinsic and\nextrinsic aging, show how NPFD can be employed to estimate the pure extrinsic\ndensity.",
    "pdf_url": "http://arxiv.org/pdf/2506.01540v1",
    "published": "2025-06-02T11:05:46+00:00",
    "categories": [
      "stat.ME",
      "stat.AP"
    ],
    "primary_category": "stat.ME"
  },
  {
    "id": "http://arxiv.org/abs/2506.01539v1",
    "title": "G4Seg: Generation for Inexact Segmentation Refinement with Diffusion Models",
    "authors": [
      "Tianjiao Zhang",
      "Fei Zhang",
      "Jiangchao Yao",
      "Ya Zhang",
      "Yanfeng Wang"
    ],
    "abstract": "This paper considers the problem of utilizing a large-scale text-to-image\ndiffusion model to tackle the challenging Inexact Segmentation (IS) task.\nUnlike traditional approaches that rely heavily on discriminative-model-based\nparadigms or dense visual representations derived from internal attention\nmechanisms, our method focuses on the intrinsic generative priors in Stable\nDiffusion~(SD). Specifically, we exploit the pattern discrepancies between\noriginal images and mask-conditional generated images to facilitate a\ncoarse-to-fine segmentation refinement by establishing a semantic\ncorrespondence alignment and updating the foreground probability. Comprehensive\nquantitative and qualitative experiments validate the effectiveness and\nsuperiority of our plug-and-play design, underscoring the potential of\nleveraging generation discrepancies to model dense representations and\nencouraging further exploration of generative approaches for solving\ndiscriminative tasks.",
    "pdf_url": "http://arxiv.org/pdf/2506.01539v1",
    "published": "2025-06-02T11:05:28+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.01538v2",
    "title": "LAMARL: LLM-Aided Multi-Agent Reinforcement Learning for Cooperative Policy Generation",
    "authors": [
      "Guobin Zhu",
      "Rui Zhou",
      "Wenkang Ji",
      "Shiyu Zhao"
    ],
    "abstract": "Although Multi-Agent Reinforcement Learning (MARL) is effective for complex\nmulti-robot tasks, it suffers from low sample efficiency and requires iterative\nmanual reward tuning. Large Language Models (LLMs) have shown promise in\nsingle-robot settings, but their application in multi-robot systems remains\nlargely unexplored. This paper introduces a novel LLM-Aided MARL (LAMARL)\napproach, which integrates MARL with LLMs, significantly enhancing sample\nefficiency without requiring manual design. LAMARL consists of two modules: the\nfirst module leverages LLMs to fully automate the generation of prior policy\nand reward functions. The second module is MARL, which uses the generated\nfunctions to guide robot policy training effectively. On a shape assembly\nbenchmark, both simulation and real-world experiments demonstrate the unique\nadvantages of LAMARL. Ablation studies show that the prior policy improves\nsample efficiency by an average of 185.9% and enhances task completion, while\nstructured prompts based on Chain-of-Thought (CoT) and basic APIs improve LLM\noutput success rates by 28.5%-67.5%. Videos and code are available at\nhttps://windylab.github.io/LAMARL/",
    "pdf_url": "http://arxiv.org/pdf/2506.01538v2",
    "published": "2025-06-02T10:59:54+00:00",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2506.02084v1",
    "title": "Temporal Causal-based Simulation for Realistic Time-series Generation",
    "authors": [
      "Nikolaos Gkorgkolis",
      "Nikolaos Kougioulis",
      "MingXue Wang",
      "Bora Caglayan",
      "Andrea Tonon",
      "Dario Simionato",
      "Ioannis Tsamardinos"
    ],
    "abstract": "Causal Discovery plays a pivotal role in revealing relationships among\nobserved variables, particularly in the temporal setup. While the majority of\nCD methods rely on synthetic data for evaluation, and recently for training,\nthese fall short in accurately mirroring real-world scenarios; an effect even\nmore evident in temporal data. Generation techniques depending on simplified\nassumptions on causal structure, effects and time, limit the quality and\ndiversity of the simulated data. In this work, we introduce Temporal\nCausal-based Simulation (TCS), a robust framework for generating realistic\ntime-series data and their associated temporal causal graphs. The approach is\nstructured in three phases: estimating the true lagged causal structure of the\ndata, approximating the functional dependencies between variables and learning\nthe noise distribution of the corresponding causal model, each part of which\ncan be explicitly tailored based on data assumptions and characteristics.\nThrough an extensive evaluation process, we highlight that single detection\nmethods for generated data discrimination prove inadequate, accentuating it as\na multifaceted challenge. For this, we detail a Min-max optimization phase that\ndraws on AutoML techniques. Our contributions include a flexible,\nmodel-agnostic pipeline for generating realistic temporal causal data, a\nthorough evaluation setup which enhances the validity of the generated datasets\nand insights into the challenges posed by realistic data generation. Through\nexperiments involving not only real but also semi-synthetic and purely\nsynthetic datasets, we demonstrate that while sampling realistic causal data\nremains a complex task, our method enriches the domain of generating sensible\ncausal-based temporal data.",
    "pdf_url": "http://arxiv.org/pdf/2506.02084v1",
    "published": "2025-06-02T10:59:48+00:00",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.02083v1",
    "title": "LASPA: Language Agnostic Speaker Disentanglement with Prefix-Tuned Cross-Attention",
    "authors": [
      "Aditya Srinivas Menon",
      "Raj Prakash Gohil",
      "Kumud Tripathi",
      "Pankaj Wasnik"
    ],
    "abstract": "Speaker recognition models face challenges in multi-lingual settings due to\nthe entanglement of linguistic information within speaker embeddings. The\noverlap between vocal traits such as accent, vocal anatomy, and a language's\nphonetic structure complicates separating linguistic and speaker information.\nDisentangling these components can significantly improve speaker recognition\naccuracy. To this end, we propose a novel disentanglement learning strategy\nthat integrates joint learning through prefix-tuned cross-attention. This\napproach is particularly effective when speakers switch between languages.\nExperimental results show the model generalizes across monolingual and\nmulti-lingual settings, including unseen languages. Notably, the proposed model\nimproves the equal error rate across multiple datasets, highlighting its\nability to separate language information from speaker embeddings and enhance\nrecognition in diverse linguistic conditions.",
    "pdf_url": "http://arxiv.org/pdf/2506.02083v1",
    "published": "2025-06-02T10:59:31+00:00",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.LG",
      "cs.MM"
    ],
    "primary_category": "cs.SD"
  },
  {
    "id": "http://arxiv.org/abs/2506.01537v1",
    "title": "Application range of perfect spin hydrodynamics",
    "authors": [
      "Zbigniew Drogosz",
      "Wojciech Florkowski",
      "Valeriya Mykhaylova"
    ],
    "abstract": "The application range of perfect spin hydrodynamics is studied in two cases:\none based on the classical spin description and the other using a quantum spin\ndensity matrix (Wigner function). Different forms of the conditions connecting\nthe components of the spin polarization tensor, particle mass, temperature, and\nhydrodynamic flow are introduced, and their mutual relations are explained. The\nresults obtained are important for practical applications of spin hydrodynamics\nto model heavy-ion collisions.",
    "pdf_url": "http://arxiv.org/pdf/2506.01537v1",
    "published": "2025-06-02T10:55:04+00:00",
    "categories": [
      "hep-ph",
      "nucl-th"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.01536v2",
    "title": "Quantum Agents",
    "authors": [
      "Eldar Sultanow",
      "Madjid Tehrani",
      "Siddhant Dutta",
      "William J Buchanan",
      "Muhammad Shahbaz Khan"
    ],
    "abstract": "This paper explores the intersection of quantum computing and agentic AI by\nexamining how quantum technologies can enhance the capabilities of autonomous\nagents, and, conversely, how agentic AI can support the advancement of quantum\nsystems. We analyze both directions of this synergy and present conceptual and\ntechnical foundations for future quantum-agentic platforms. Our work introduces\na formal definition of quantum agents and outlines potential architectures that\nintegrate quantum computing with agent-based systems. As a proof-of-concept, we\ndevelop and evaluate three quantum agent prototypes that demonstrate the\nfeasibility of our proposed framework. Furthermore, we discuss use cases from\nboth perspectives, including quantum-enhanced decision-making, quantum planning\nand optimization, and AI-driven orchestration of quantum workflows. By bridging\nthese fields, we aim to chart a path toward scalable, intelligent, and adaptive\nquantum-agentic ecosystems.",
    "pdf_url": "http://arxiv.org/pdf/2506.01536v2",
    "published": "2025-06-02T10:54:31+00:00",
    "categories": [
      "quant-ph",
      "2010: Primary 81P68, 68T42, Secondary 68Q12, 68T05"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.01535v1",
    "title": "Dictionaries to the Rescue: Cross-Lingual Vocabulary Transfer for Low-Resource Languages Using Bilingual Dictionaries",
    "authors": [
      "Haruki Sakajo",
      "Yusuke Ide",
      "Justin Vasselli",
      "Yusuke Sakai",
      "Yingtao Tian",
      "Hidetaka Kamigaito",
      "Taro Watanabe"
    ],
    "abstract": "Cross-lingual vocabulary transfer plays a promising role in adapting\npre-trained language models to new languages, including low-resource languages.\nExisting approaches that utilize monolingual or parallel corpora face\nchallenges when applied to languages with limited resources. In this work, we\npropose a simple yet effective vocabulary transfer method that utilizes\nbilingual dictionaries, which are available for many languages, thanks to\ndescriptive linguists. Our proposed method leverages a property of BPE\ntokenizers where removing a subword from the vocabulary causes a fallback to\nshorter subwords. The embeddings of target subwords are estimated iteratively\nby progressively removing them from the tokenizer. The experimental results\nshow that our approach outperforms existing methods for low-resource languages,\ndemonstrating the effectiveness of a dictionary-based approach for\ncross-lingual vocabulary transfer.",
    "pdf_url": "http://arxiv.org/pdf/2506.01535v1",
    "published": "2025-06-02T10:52:52+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.01534v1",
    "title": "Potential absence of observed $π^2$ linear-chain structures in $^{14}$O via $^{10}$C($α,α$) resonant scattering",
    "authors": [
      "J. Bishop",
      "A. Hollands",
      "Tz. Kokolova",
      "G. V. Rogachev",
      "C. Wheldon",
      "E. Aboud",
      "S. Ahn",
      "M. Barbui",
      "N. Curtis",
      "J. Hooker",
      "C. Hunt",
      "H. Jayatissa",
      "E. Koshchiy",
      "S. Pirrie",
      "B. T. Roeder",
      "A. Saastamoinen",
      "S. Upadhyayula"
    ],
    "abstract": "Background: The preference for light nuclear systems to coagulate into\n$\\alpha$-particle clusters has been well-studied. The possibility of a linear\nchain configuration of $\\alpha$-particles would allow for a new way to study\nthis phenomenon. Purpose: A rotational band of states in $^{14}$C has been\nclaimed showing a $\\pi^2$ linear chain structure. The mirror system, $^{14}$O,\nhas been studied here to examine how this linear chain structure is affected by\nreplacing the valence neutrons with protons. Method: A beam of $^{10}$C was\nincident into a chamber filled with He:CO$_2$ gas with the tracks recorded\ninside the TexAT Time Projection Chamber and the recoil $\\alpha$-particles\ndetected by a silicon detector array to measure the\n$^{10}\\mathrm{C}(\\alpha,\\alpha)$ cross section. Results: The experimental cross\nsection was compared with previous studies and fit using R-Matrix theory with\nthe previously-observed $^{14}$O states being transformed to the $^{14}$C using\nmirror symmetry. The measured cross section does not replicate the claimed\nstates, with the predicted cross section exceeding that observed at several\nenergies and angles. Conclusion: A series of possibilities are highlighted with\nthe most likely being that the originally-seen $^{14}$C states did not\nconstitute a $\\pi^2$ rotational band with a potentially incorrect spin\nassignment due to the limitations of the angular correlation method with\nnon-zero spin particles. The work highlights the difficulties in measuring\nbroad resonances corresponding to a linear chain state in a high level density.",
    "pdf_url": "http://arxiv.org/pdf/2506.01534v1",
    "published": "2025-06-02T10:50:11+00:00",
    "categories": [
      "nucl-ex"
    ],
    "primary_category": "nucl-ex"
  },
  {
    "id": "http://arxiv.org/abs/2506.01533v1",
    "title": "A Diffusion-Based Method for Learning the Multi-Outcome Distribution of Medical Treatments",
    "authors": [
      "Yuchen Ma",
      "Jonas Schweisthal",
      "Hengrui Zhang",
      "Stefan Feuerriegel"
    ],
    "abstract": "In medicine, treatments often influence multiple, interdependent outcomes,\nsuch as primary endpoints, complications, adverse events, or other secondary\nendpoints. Hence, to make optimal treatment decisions, clinicians are\ninterested in learning the distribution of multi-dimensional treatment\noutcomes. However, the vast majority of machine learning methods for predicting\ntreatment effects focus on single-outcome settings, despite the fact that\nmedical data often include multiple, interdependent outcomes. To address this\nlimitation, we propose a novel diffusion-based method called DIME to learn the\njoint distribution of multiple outcomes of medical treatments. We addresses\nthree challenges relevant in medical practice: (i)it is tailored to learn the\njoint interventional distribution of multiple medical outcomes, which enables\nreliable decision-making with uncertainty quantification rather than relying\nsolely on point estimates; (ii)it explicitly captures the dependence structure\nbetween outcomes; (iii)it can handle outcomes of mixed type, including binary,\ncategorical, and continuous variables. In DIME, we take into account the\nfundamental problem of causal inference through causal masking. For training,\nour method decomposes the joint distribution into a series of conditional\ndistributions with a customized conditional masking to account for the\ndependence structure across outcomes. For inference, our method\nauto-regressively generates predictions. This allows our method to move beyond\npoint estimates of causal quantities and thus learn the joint interventional\ndistribution. To the best of our knowledge, DIME is the first neural method\ntailored to learn the joint, multi-outcome distribution of medical treatments.\nAcross various experiments, we demonstrate that our method effectively learns\nthe joint distribution and captures shared information among multiple outcomes.",
    "pdf_url": "http://arxiv.org/pdf/2506.01533v1",
    "published": "2025-06-02T10:49:55+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.01532v4",
    "title": "Balancing Beyond Discrete Categories: Continuous Demographic Labels for Fair Face Recognition",
    "authors": [
      "Pedro C. Neto",
      "Naser Damer",
      "Jaime S. Cardoso",
      "Ana F. Sequeira"
    ],
    "abstract": "Bias has been a constant in face recognition models. Over the years,\nresearchers have looked at it from both the model and the data point of view.\nHowever, their approach to mitigation of data bias was limited and lacked\ninsight on the real nature of the problem. Here, in this document, we propose\nto revise our use of ethnicity labels as a continuous variable instead of a\ndiscrete value per identity. We validate our formulation both experimentally\nand theoretically, showcasing that not all identities from one ethnicity\ncontribute equally to the balance of the dataset; thus, having the same number\nof identities per ethnicity does not represent a balanced dataset. We further\nshow that models trained on datasets balanced in the continuous space\nconsistently outperform models trained on data balanced in the discrete space.\nWe trained more than 65 different models, and created more than 20 subsets of\nthe original datasets.",
    "pdf_url": "http://arxiv.org/pdf/2506.01532v4",
    "published": "2025-06-02T10:49:36+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.01531v2",
    "title": "STORM-BORN: A Challenging Mathematical Derivations Dataset Curated via a Human-in-the-Loop Multi-Agent Framework",
    "authors": [
      "Wenhao Liu",
      "Zhenyi Lu",
      "Xinyu Hu",
      "Jierui Zhang",
      "Dailin Li",
      "Jiacheng Cen",
      "Huilin Cao",
      "Haiteng Wang",
      "Yuhan Li",
      "Kun Xie",
      "Dandan Li",
      "Pei Zhang",
      "Chengbo Zhang",
      "Yuxiang Ren",
      "Xiaohong Huang",
      "Yan Ma"
    ],
    "abstract": "High-quality math datasets are crucial for advancing the reasoning abilities\nof large language models (LLMs). However, existing datasets often suffer from\nthree key issues: outdated and insufficient challenging content, neglecting\nhuman-like reasoning, and limited reliability due to single-LLM generation. To\naddress these, we introduce STORM-BORN, an ultra-challenging dataset of\nmathematical derivations sourced from cutting-edge academic papers, which\nincludes dense human-like approximations and heuristic cues. To ensure the\nreliability and quality, we propose a novel human-in-the-loop, multi-agent data\ngeneration framework, integrating reasoning-dense filters, multi-agent\ncollaboration, and human mathematicians' evaluations. We curated a set of 2,000\nsynthetic samples and deliberately selected the 100 most difficult problems.\nEven most advanced models like GPT-o1 solved fewer than 5% of them. Fine-tuning\non STORM-BORN boosts accuracy by 7.84% (LLaMA3-8B) and 9.12% (Qwen2.5-7B). As\nAI approaches mathematician-level reasoning, STORM-BORN provides both a\nhigh-difficulty benchmark and a human-like reasoning training resource. Our\ncode and dataset are publicly available at\nhttps://github.com/lwhere/STORM-BORN.",
    "pdf_url": "http://arxiv.org/pdf/2506.01531v2",
    "published": "2025-06-02T10:48:49+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.02082v1",
    "title": "SALF-MOS: Speaker Agnostic Latent Features Downsampled for MOS Prediction",
    "authors": [
      "Saurabh Agrawal",
      "Raj Gohil",
      "Gopal Kumar Agrawal",
      "Vikram C M",
      "Kushal Verma"
    ],
    "abstract": "Speech quality assessment is a critical process in selecting text-to-speech\nsynthesis (TTS) or voice conversion models. Evaluation of voice synthesis can\nbe done using objective metrics or subjective metrics. Although there are many\nobjective metrics like the Perceptual Evaluation of Speech Quality (PESQ),\nPerceptual Objective Listening Quality Assessment (POLQA) or Short-Time\nObjective Intelligibility (STOI) but none of them is feasible in selecting the\nbest model. On the other hand subjective metric like Mean Opinion Score is\nhighly reliable but it requires a lot of manual efforts and are time-consuming.\nTo counter the issues in MOS Evaluation, we have developed a novel model,\nSpeaker Agnostic Latent Features (SALF)-Mean Opinion Score (MOS) which is a\nsmall-sized, end-to-end, highly generalized and scalable model for predicting\nMOS score on a scale of 5. We use the sequences of convolutions and stack them\nto get the latent features of the audio samples to get the best\nstate-of-the-art results based on mean squared error (MSE), Linear Concordance\nCorrelation coefficient (LCC), Spearman Rank Correlation Coefficient (SRCC) and\nKendall Rank Correlation Coefficient (KTAU).",
    "pdf_url": "http://arxiv.org/pdf/2506.02082v1",
    "published": "2025-06-02T10:45:40+00:00",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.SD"
  },
  {
    "id": "http://arxiv.org/abs/2506.01530v1",
    "title": "Multiple rational normal forms in Lie theory",
    "authors": [
      "Dmitriy Voloshyn"
    ],
    "abstract": "We study the decomposition of a generic element $g \\in G$ of a connected\nreductive complex algebraic group $G$ in the form $g = N(g) B(g) \\bar{u}\nN(g)^{-1}$ where $N: G \\dashrightarrow \\mathcal{N}_-$ and $B : G\n\\dashrightarrow \\mathcal{B}_+$ are rational maps onto a unipotent subgroup\n$\\mathcal{N}_-$ and a Borel subgroup $\\mathcal{B}_+$ opposite to\n$\\mathcal{N}_-$, and $\\bar{u}$ is a representative of a Weyl group element $u$.\nWe introduce a class of rational Weyl group elements that give rise to such\ndecompositions, and study their various properties.",
    "pdf_url": "http://arxiv.org/pdf/2506.01530v1",
    "published": "2025-06-02T10:44:30+00:00",
    "categories": [
      "math.RT",
      "20G07 (Primary) 20F55, 13F60 (Secondary)"
    ],
    "primary_category": "math.RT"
  },
  {
    "id": "http://arxiv.org/abs/2506.01529v1",
    "title": "Learning Abstract World Models with a Group-Structured Latent Space",
    "authors": [
      "Thomas Delliaux",
      "Nguyen-Khanh Vu",
      "Vincent François-Lavet",
      "Elise van der Pol",
      "Emmanuel Rachelson"
    ],
    "abstract": "Learning meaningful abstract models of Markov Decision Processes (MDPs) is\ncrucial for improving generalization from limited data. In this work, we show\nhow geometric priors can be imposed on the low-dimensional representation\nmanifold of a learned transition model. We incorporate known symmetric\nstructures via appropriate choices of the latent space and the associated group\nactions, which encode prior knowledge about invariances in the environment. In\naddition, our framework allows the embedding of additional unstructured\ninformation alongside these symmetries. We show experimentally that this leads\nto better predictions of the latent transition model than fully unstructured\napproaches, as well as better learning on downstream RL tasks, in environments\nwith rotational and translational features, including in first-person views of\n3D environments. Additionally, our experiments show that this leads to simpler\nand more disentangled representations. The full code is available on GitHub to\nensure reproducibility.",
    "pdf_url": "http://arxiv.org/pdf/2506.01529v1",
    "published": "2025-06-02T10:43:18+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.01528v1",
    "title": "Paradoxical decompositions of finite-dimensional non-Archimedean normed spaces",
    "authors": [
      "Kamil Orzechowski"
    ],
    "abstract": "We show that any normed space $(K^n,\\|\\cdot\\|)$, $n\\ge 2$, over a field $K$\nequipped with a nontrivial non-Archimedean valuation admits a paradoxical\ndecomposition using four pieces with respect to the group of its affine\nisometries, provided that the norm $\\|\\cdot\\|$ is equivalent to the maximum\nnorm.\n  It follows that any finite-dimensional normed space $(X,\\|\\cdot\\|)$ with\n$\\dim{X}\\ge 2$ over a complete non-Archimedean nontrivially valued field\n$(K,|\\cdot|)$ is paradoxical using four pieces with respect to the group of its\naffine isometries.",
    "pdf_url": "http://arxiv.org/pdf/2506.01528v1",
    "published": "2025-06-02T10:41:17+00:00",
    "categories": [
      "math.FA",
      "math.GR",
      "Primary 47S10, Secondary 46S10, 12J25, 26E30, 20E05, 20G25, 20H05,\n  22F05 46B04, 05A18"
    ],
    "primary_category": "math.FA"
  },
  {
    "id": "http://arxiv.org/abs/2506.01527v1",
    "title": "Electronic structure reorganization in MPS3 via d-shell-selective alkali metal doping",
    "authors": [
      "Jonah Elias Nitschke",
      "Preeti Bhumla",
      "Till Willershausen",
      "Patrick Merisescu",
      "David Janas",
      "Lasse Sternemann",
      "Michael Gutnikov",
      "Karl Schiller",
      "Valentin Mischke",
      "Michele Capra",
      "Mira Sophie Arndt",
      "Silvana Botti",
      "Mirko Cinchetti"
    ],
    "abstract": "Semiconducting two-dimensional (2D) antiferromagnetic (AFM) transition-metal\nthiophosphates (MPS3) offer promising opportunities for spintronic applications\ndue to their highly tunable electronic properties. While alloying and\nintercalation have been shown to modulate ground states, the role of d-shell\nfilling in governing these transitions remains insufficiently understood. Here,\nwe investigate electron doping effects in MPS3 using angle-resolved\nphotoemission spectroscopy (ARPES), X-ray photoelectron spectroscopy (XPS), and\ndensity functional theory (DFT+U). Lithium and cesium deposition are employed\nto induce doping across different MPS3 compounds. We identify two distinct\ndoping mechanisms: in MnPS3, electrons are primarily donated to the P2S6 ligand\nclusters, with negligible Mn 2p core-level shifts and no major changes in the\nvalence band. In contrast, FePS3, CoPS3, and NiPS3 exhibit clear reductions in\ntransition-metal oxidation states, with a 1.0 eV reduction in spin-orbit\nsplitting for Co upon doping. ARPES on CoPS3 reveals a 400 meV shift of\nCo-derived bands towards higher binding energies and new dispersive states up\nto 1 eV above the valence band maximum, indicating metallic behavior. These\nresults establish a direct correlation between d-shell filling and doping\nresponse, highlighting alkali metal doping as a tunable route to tailor the\nelectronic and magnetic properties of 2D AFM semiconductors for spintronic\napplications.",
    "pdf_url": "http://arxiv.org/pdf/2506.01527v1",
    "published": "2025-06-02T10:40:04+00:00",
    "categories": [
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2506.01526v1",
    "title": "Trigonal Canonically Fibered Surfaces",
    "authors": [
      "Houari Benammar Ammar",
      "Xi Chen",
      "Nathan Grieve"
    ],
    "abstract": "We fix some gaps of a proof of Xiao's conjecture on canonically fibered\nsurfaces of relative genus 5 by the second author. Our argument simplifies the\noriginal proof and gives a much better bound on the geometric genus of the\nsurface. Also we apply the same argument to canonically fibered surfaces of\nrelative genus 3 and 4 to obtain some Noether-type inequalities for these\nsurfaces.",
    "pdf_url": "http://arxiv.org/pdf/2506.01526v1",
    "published": "2025-06-02T10:39:46+00:00",
    "categories": [
      "math.AG",
      "14J29, 14E05, 14H45"
    ],
    "primary_category": "math.AG"
  },
  {
    "id": "http://arxiv.org/abs/2506.01525v1",
    "title": "Effect of Insecurity on Agricultural Output in Benue State, Nigeria",
    "authors": [
      "Victor Ushahemba Ijirshar",
      "Isaiah Iortyom Udaah",
      "Bridget Ngodoo Mile",
      "Joyce Seember Vershima",
      "Abba Adaudu"
    ],
    "abstract": "This study examined the effect of insecurity on agricultural output in Benue\nstate. A descriptive survey design was employed, and 400 respondents were\npurposively selected from insecurity-prone local government areas, namely, Guma\nLGA, Agatu LGA, Gwer LGA, Gwer-West LGA, Katsina-Ala LGA, Logo LGA, Ukum LGA\nand Kwande LGA. The data were collected through the administration of a\nquestionnaire and were analysed using t tests and structural equation modelling\n(SEM). The t-test was used to compare farmers' incomes before and after the\ninsecurity in the study area to assess if the differences were statistically\nsignificant, while Structural Equation Modelling analysed the complex\nrelationships among multiple variables, employing regression and factor\nanalysis to model both direct and indirect effects. The results revealed that\nthe monetary value of crop and livestock output decreased during periods of\ninsecurity. Furthermore, the study showed that insecurity has an adverse effect\non crop and livestock output. This means that a one percent increase in\ninsecurity leads to a 0.211% and 0.311% decrease in crop and livestock output\nrespectively. The study concluded that insecurity reduced agricultural output\nin Benue state. Based on the findings, it was recommended that the government\ndeploy more security personnel, establish community policing initiatives, and\nemploy modern surveillance technologies to deter criminal activities in\ninsecure areas. Additionally, for places experiencing farmer-herder conflict,\nthe government should provide grazing reserves for herdsmen and further\nstrengthen the state law on open grazing prohibition and the establishment of\nranch law.",
    "pdf_url": "http://arxiv.org/pdf/2506.01525v1",
    "published": "2025-06-02T10:38:54+00:00",
    "categories": [
      "econ.GN",
      "q-fin.EC"
    ],
    "primary_category": "econ.GN"
  },
  {
    "id": "http://arxiv.org/abs/2506.01524v1",
    "title": "V-VAE: A Variational Auto Encoding Framework Towards Fine-Grained Control over Human-Like Chat",
    "authors": [
      "Qi Lin",
      "Weikai Xu",
      "Lisi Chen",
      "Bin Dai"
    ],
    "abstract": "With the continued proliferation of Large Language Model (LLM) based\nchatbots, there is a growing demand for generating responses that are not only\nlinguistically fluent but also consistently aligned with persona-specific\ntraits in conversations. However, existing role-play and persona-based chat\napproaches rely heavily on static role descriptions, coarse-grained signal\nspace, and low-quality synthetic data, which fail to capture dynamic\nfine-grained details in human-like chat. Human-like chat requires modeling\nsubtle latent traits, such as emotional tone, situational awareness, and\nevolving personality, which are difficult to predefine and cannot be easily\nlearned from synthetic or distillation-based data. To address these\nlimitations, we propose a Verbal Variational Auto-Encoding (V-VAE) framework,\ncontaining a variational auto-encoding module and fine-grained control space\nwhich dynamically adapts dialogue behaviour based on fine-grained,\ninterpretable latent variables across talking style, interaction patterns, and\npersonal attributes. We also construct a high-quality dataset, HumanChatData,\nand benchmark HumanChatBench to address the scarcity of high-quality data in\nthe human-like domain. Experiments show that LLMs based on V-VAE consistently\noutperform standard baselines on HumanChatBench and DialogBench, which further\ndemonstrates the effectiveness of V-VAE and HumanChatData.",
    "pdf_url": "http://arxiv.org/pdf/2506.01524v1",
    "published": "2025-06-02T10:38:02+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.01523v1",
    "title": "Alignment as Distribution Learning: Your Preference Model is Explicitly a Language Model",
    "authors": [
      "Jihun Yun",
      "Juno Kim",
      "Jongho Park",
      "Junhyuck Kim",
      "Jongha Jon Ryu",
      "Jaewoong Cho",
      "Kwang-Sung Jun"
    ],
    "abstract": "Alignment via reinforcement learning from human feedback (RLHF) has become\nthe dominant paradigm for controlling the quality of outputs from large\nlanguage models (LLMs). However, when viewed as `loss + regularization,' the\nstandard RLHF objective lacks theoretical justification and incentivizes\ndegenerate, deterministic solutions, an issue that variants such as Direct\nPolicy Optimization (DPO) also inherit. In this paper, we rethink alignment by\nframing it as \\emph{distribution learning} from pairwise preference feedback by\nexplicitly modeling how information about the target language model bleeds\nthrough the preference data. This explicit modeling leads us to propose three\nprincipled learning objectives: preference maximum likelihood estimation,\npreference distillation, and reverse KL minimization. We theoretically show\nthat all three approaches enjoy strong non-asymptotic $O(1/n)$ convergence to\nthe target language model, naturally avoiding degeneracy and reward\noverfitting. Finally, we empirically demonstrate that our distribution learning\nframework, especially preference distillation, consistently outperforms or\nmatches the performances of RLHF and DPO across various tasks and models.",
    "pdf_url": "http://arxiv.org/pdf/2506.01523v1",
    "published": "2025-06-02T10:36:31+00:00",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.01522v1",
    "title": "Beyond Diagonal Covariance: Flexible Posterior VAEs via Free-Form Injective Flows",
    "authors": [
      "Peter Sorrenson",
      "Lukas Lührs",
      "Hans Olischläger",
      "Ullrich Köthe"
    ],
    "abstract": "Variational Autoencoders (VAEs) are powerful generative models widely used\nfor learning interpretable latent spaces, quantifying uncertainty, and\ncompressing data for downstream generative tasks. VAEs typically rely on\ndiagonal Gaussian posteriors due to computational constraints. Using arguments\ngrounded in differential geometry, we demonstrate inherent limitations in the\nrepresentational capacity of diagonal covariance VAEs, as illustrated by\nexplicit low-dimensional examples. In response, we show that a regularized\nvariant of the recently introduced Free-form Injective Flow (FIF) can be\ninterpreted as a VAE featuring a highly flexible, implicitly defined posterior.\nCrucially, this regularization yields a posterior equivalent to a full Gaussian\ncovariance distribution, yet maintains computational costs comparable to\nstandard diagonal covariance VAEs. Experiments on image datasets validate our\napproach, demonstrating that incorporating full covariance substantially\nimproves model likelihood.",
    "pdf_url": "http://arxiv.org/pdf/2506.01522v1",
    "published": "2025-06-02T10:36:27+00:00",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.01521v1",
    "title": "Projective and anomalous representations of categories and their linearizations",
    "authors": [
      "Domenico Fiorenza",
      "Chetan Vuppulury"
    ],
    "abstract": "We invesigate the relation between projective and anomalous representations\nof categories, and show how to any anomaly $J\\colon \\mathcal{C}\\to\n2\\mathrm{Vect}$ one can associate an extension $\\mathcal{C}^J$ of $\\mathcal{C}$\nand a subcategory $\\mathcal{C}^J_{\\mathrm{ST}}$ of $\\mathcal{C}^J$ with the\nproperty that: (i) anomalous representations of $\\mathcal{C}$ with anomaly $J$\nare equivalent to $\\mathrm{Vect}$-linear functors $E\\colon \\mathcal{C}^J\\to\n\\mathrm{Vect}$, and (ii) these are in turn equivalent to linear representations\nof $\\mathcal{C}^J_{\\mathrm{ST}}$ where \"$J$ acts as scalars\". This\nconstruction, inspired by and generalizing the technique used to linearize\nanomalous functorial field theories in the physics literature, can be seen as a\nmulti-object version of the classical relation between projective\nrepresentations of a group $G$, with given $2$-cocycle $\\alpha$, and linear\nrepresentations of the central extension $G^\\alpha$ of $G$ associated with\n$\\alpha$.",
    "pdf_url": "http://arxiv.org/pdf/2506.01521v1",
    "published": "2025-06-02T10:35:19+00:00",
    "categories": [
      "math.CT",
      "math-ph",
      "math.MP",
      "math.QA",
      "math.RT",
      "18D25"
    ],
    "primary_category": "math.CT"
  },
  {
    "id": "http://arxiv.org/abs/2506.01520v1",
    "title": "FormFactory: An Interactive Benchmarking Suite for Multimodal Form-Filling Agents",
    "authors": [
      "Bobo Li",
      "Yuheng Wang",
      "Hao Fei",
      "Juncheng Li",
      "Wei Ji",
      "Mong-Li Lee",
      "Wynne Hsu"
    ],
    "abstract": "Online form filling is a common yet labor-intensive task involving extensive\nkeyboard and mouse interactions. Despite the long-standing vision of automating\nthis process with \"one click\", existing tools remain largely rule-based and\nlack generalizable, generative capabilities. Recent advances in Multimodal\nLarge Language Models (MLLMs) have enabled promising agents for GUI-related\ntasks in general-purpose scenarios. However, they struggle with the unique\nchallenges of form filling, such as flexible layouts and the difficulty of\naligning textual instructions with on-screen fields. To bridge this gap, we\nformally define the form-filling task and propose FormFactory, an interactive\nbenchmarking suite comprising a web-based interface, backend evaluation module,\nand carefully constructed dataset. Our benchmark covers diverse real-world\nscenarios, incorporates various field formats, and simulates high-fidelity form\ninteractions. We conduct a comprehensive evaluation of state-of-the-art MLLMs\nand observe that no model surpasses 5% accuracy, underscoring the inherent\ndifficulty of the task. These findings also reveal significant limitations in\ncurrent models' visual layout reasoning and field-value alignment abilities. We\nhope our benchmark can serve as a stepping stone for further research into\nrobust, practical form-filling agents.",
    "pdf_url": "http://arxiv.org/pdf/2506.01520v1",
    "published": "2025-06-02T10:34:57+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.01519v1",
    "title": "Speed-up of Vision Transformer Models by Attention-aware Token Filtering",
    "authors": [
      "Takahiro Naruko",
      "Hiroaki Akutsu"
    ],
    "abstract": "Vision Transformer (ViT) models have made breakthroughs in image embedding\nextraction, which provide state-of-the-art performance in tasks such as\nzero-shot image classification. However, the models suffer from a high\ncomputational burden. In this paper, we propose a novel speed-up method for ViT\nmodels called Attention-aware Token Filtering (ATF). ATF consists of two main\nideas: a novel token filtering module and a filtering strategy. The token\nfiltering module is introduced between a tokenizer and a transformer encoder of\nthe ViT model, without modifying or fine-tuning of the transformer encoder. The\nmodule filters out tokens inputted to the encoder so that it keeps tokens in\nregions of specific object types dynamically and keeps tokens in regions that\nstatically receive high attention in the transformer encoder. This filtering\nstrategy maintains task accuracy while filtering out tokens inputted to the\ntransformer encoder. Evaluation results on retrieval tasks show that ATF\nprovides $2.8\\times$ speed-up to a ViT model, SigLIP, while maintaining the\nretrieval recall rate.",
    "pdf_url": "http://arxiv.org/pdf/2506.01519v1",
    "published": "2025-06-02T10:34:55+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.01518v1",
    "title": "Typical Uniqueness in Ergodic Optimization",
    "authors": [
      "Oliver Jenkinson",
      "Xiaoran Li",
      "Yuexin Liao",
      "Yiwei Zhang"
    ],
    "abstract": "For ergodic optimization on any topological dynamical system, with\nreal-valued potential function $f$ belonging to any separable Banach space $B$\nof continuous functions, we show that the $f$-maximizing measure is typically\nunique, in the strong sense that a countable collection of hypersurfaces\ncontains the exceptional set of those $f\\in B$ with non-unique maximizing\nmeasure. This strengthens previous results asserting that the uniqueness set is\nboth residual and prevalent.",
    "pdf_url": "http://arxiv.org/pdf/2506.01518v1",
    "published": "2025-06-02T10:34:11+00:00",
    "categories": [
      "math.DS"
    ],
    "primary_category": "math.DS"
  },
  {
    "id": "http://arxiv.org/abs/2506.01517v1",
    "title": "Machine-learning-driven modelling of amorphous and polycrystalline BaZrS$_{3}$",
    "authors": [
      "Laura-Bianca Paşca",
      "Yuanbin Liu",
      "Andy S. Anker",
      "Ludmilla Steier",
      "Volker L. Deringer"
    ],
    "abstract": "The chalcogenide perovskite material BaZrS$_{3}$ is of growing interest for\nemerging thin-film photovoltaics. Here we show how machine-learning-driven\nmodelling can be used to describe the material's amorphous precursor as well as\npolycrystalline structures with complex grain boundaries. Using a bespoke\nmachine-learned interatomic potential (MLIP) model for BaZrS$_{3}$, we study\nthe atomic-scale structure of the amorphous phase, quantify grain-boundary\nformation energies, and create realistic-scale polycrystalline structural\nmodels which can be compared to experimental data. Beyond BaZrS$_{3}$, our work\nexemplifies the increasingly central role of MLIPs in materials chemistry and\nmarks a step towards realistic device-scale simulations of materials that are\ngaining momentum in the fields of photovoltaics and photocatalysis.",
    "pdf_url": "http://arxiv.org/pdf/2506.01517v1",
    "published": "2025-06-02T10:33:42+00:00",
    "categories": [
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2506.01516v1",
    "title": "RS Sagittarii: Revealing the component spectra and the mass transfer",
    "authors": [
      "Hicran Bakış",
      "Ömrüm Hilal Yıldız",
      "Volkan Bakış",
      "Gökhan Yücel"
    ],
    "abstract": "We present an analysis of high-resolution (R ~ 48000) spectroscopic and\nphotometric data of RS Sgr, a short-period Algol-type binary system. For the\nfirst time, precise spectroscopic and absolute parameters of the system have\nbeen determined. The primary component is identified as a B3 main-sequence star\nwith an effective temperature of 19000K, while the secondary is classified as\nan A0-type star with a temperature of 9700 K. The secondary appears to have\nrecently evolved off the main sequence and currently fills its Roche lobe,\ntransferring material through the inner Lagrangian point (L1) to the hotter\nprimary component. The H{\\alpha} emission and absorption features observed in\nthe spectra are attributed to a combination of a low-density circumprimary\ndisk, a gas stream originating from the secondary, and a hot spot formed at the\nimpact site on the primary. The combined analysis of spectroscopic and\nphotometric data yields a system distance of approximately 418 pc, which is\nconsistent with the value derived from GAIA DR3 within the uncertainty limits.",
    "pdf_url": "http://arxiv.org/pdf/2506.01516v1",
    "published": "2025-06-02T10:30:05+00:00",
    "categories": [
      "astro-ph.SR"
    ],
    "primary_category": "astro-ph.SR"
  },
  {
    "id": "http://arxiv.org/abs/2506.01515v2",
    "title": "Fully characterized linear magnetoelectric response of 2D monolayers from high-throughput first-principles calculations",
    "authors": [
      "John Mangeri",
      "Thomas Olsen"
    ],
    "abstract": "We screen 4784 stable monolayers from the Computational 2D Materials Database\n(C2DB) and identify 57 ferromagnetic (FM) and 67 antiferromagnetic (AFM)\ncompounds that should exhibit linear magnetoelectric (ME) effects. Using\ndensity functional theory, we compute contributions from the spin and orbital\nangular momentum as well as lattice-mediated and clamped-ion analogs to fully\ncharacterize the linear ME tensor in the static limit. We observe a general\ntrend that AFM ordering gives rise to a larger ME response compared to FM\nordered monolayers. Using a typical van der Waals interlayer distance, we find\nthat AFM $\\mathrm{Mn}_2\\mathrm{SI}_2$ exhibits the strongest component of\nlinear ME response, providing approximately 580 ps/m. This is two orders of\nmagnitude greater than in prototypical $\\mathrm{Cr}_2\\mathrm{O}_3$ but\ncomparable to the largest ME response measured in bulk $\\mathrm{TbPO}_4$\n(280-740 ps/m). We also search for antimagnetoelectricity and find a number of\nFM and AFM compounds with antiferroic tensor entries. By demonstration of\nselect examples and analysis of our full data set, we argue that inclusion of\nall contributions (spin, orbital, lattice-mediated and clamped-ion) is of\ncrucial importance for reliable predictions of the total ME response.",
    "pdf_url": "http://arxiv.org/pdf/2506.01515v2",
    "published": "2025-06-02T10:26:14+00:00",
    "categories": [
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2506.02081v1",
    "title": "RATFM: Retrieval-augmented Time Series Foundation Model for Anomaly Detection",
    "authors": [
      "Chihiro Maru",
      "Shoetsu Sato"
    ],
    "abstract": "Inspired by the success of large language models (LLMs) in natural language\nprocessing, recent research has explored the building of time series foundation\nmodels and applied them to tasks such as forecasting, classification, and\nanomaly detection. However, their performances vary between different domains\nand tasks. In LLM-based approaches, test-time adaptation using example-based\nprompting has become common, owing to the high cost of retraining. In the\ncontext of anomaly detection, which is the focus of this study, providing\nnormal examples from the target domain can also be effective. However, time\nseries foundation models do not naturally acquire the ability to interpret or\nutilize examples or instructions, because the nature of time series data used\nduring training does not encourage such capabilities. To address this\nlimitation, we propose a retrieval augmented time series foundation model\n(RATFM), which enables pretrained time series foundation models to incorporate\nexamples of test-time adaptation. We show that RATFM achieves a performance\ncomparable to that of in-domain fine-tuning while avoiding domain-dependent\nfine-tuning. Experiments on the UCR Anomaly Archive, a multi-domain dataset\nincluding nine domains, confirms the effectiveness of the proposed approach.",
    "pdf_url": "http://arxiv.org/pdf/2506.02081v1",
    "published": "2025-06-02T10:25:35+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.01514v1",
    "title": "Equivalence of Left- and Right-Invariant Extended Kalman Filters on Matrix Lie Groups",
    "authors": [
      "Finn G. Maurer",
      "Erlend A. Basso",
      "Henrik M. Schmidt-Didlaukies",
      "Torleiv H. Bryne"
    ],
    "abstract": "This paper derives the extended Kalman filter (EKF) for continuous-time\nsystems on matrix Lie groups observed through discrete-time measurements. By\nmodeling the system noise on the Lie algebra and adopting a Stratonovich\ninterpretation for the stochastic differential equation (SDE), we ensure that\nsolutions remain on the manifold. The derivation of the filter follows\nclassical EKF principles, naturally integrating a necessary full-order\ncovariance reset post-measurement update. A key contribution is proving that\nthis full-order covariance reset guarantees that the Lie-group-valued state\nestimate is invariant to whether a left- or right-invariant error definition is\nused in the EKF. Monte Carlo simulations of the aided inertial navigation\nproblem validate the invariance property and confirm its absence when employing\nreduced-order covariance resets.",
    "pdf_url": "http://arxiv.org/pdf/2506.01514v1",
    "published": "2025-06-02T10:24:40+00:00",
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2506.01513v1",
    "title": "Stardust: A Scalable and Extensible Simulator for the 3D Continuum",
    "authors": [
      "Thomas Pusztai",
      "Jan Hisberger",
      "Cynthia Marcelino",
      "Stefan Nastic"
    ],
    "abstract": "Low Earth Orbit (LEO) satellite constellations are quickly being recognized\nas an upcoming extension of the Edge-Cloud Continuum into a 3D Continuum.\nLow-latency connectivity around the Earth and increasing computational power\nwith every new satellite generation lead to a vision of workflows being\nseamlessly executed across Edge, Cloud, and space nodes. High launch costs for\nnew satellites and the need to experiment with large constellations mandate the\nuse of simulators for validating new orchestration algorithms. Unfortunately,\nexisting simulators only allow for relatively small constellations to be\nsimulated without scaling to a large number of host machines. In this paper, we\npresent Stardust, a scalable and extensible simulator for the 3D Continuum.\nStardust supports i) simulating mega constellations with 3x the size of the\ncurrently largest LEO mega constellation on a single machine, ii)\nexperimentation with custom network routing protocols through its dynamic\nrouting mechanism, and iii) rapid testing of orchestration algorithms or\nsoftware by integrating them into the simulation as SimPlugins. We evaluate\nStardust in multiple simulations to show that it is more scalable than the\nstate-of-the-art and that it can simulate a mega constellation with up to 20.6k\nsatellites on a single machine.",
    "pdf_url": "http://arxiv.org/pdf/2506.01513v1",
    "published": "2025-06-02T10:20:21+00:00",
    "categories": [
      "cs.DC"
    ],
    "primary_category": "cs.DC"
  },
  {
    "id": "http://arxiv.org/abs/2506.01512v1",
    "title": "Representations of Fact, Fiction and Forecast in Large Language Models: Epistemics and Attitudes",
    "authors": [
      "Meng Li",
      "Michael Vrazitulis",
      "David Schlangen"
    ],
    "abstract": "Rational speakers are supposed to know what they know and what they do not\nknow, and to generate expressions matching the strength of evidence. In\ncontrast, it is still a challenge for current large language models to generate\ncorresponding utterances based on the assessment of facts and confidence in an\nuncertain real-world environment. While it has recently become popular to\nestimate and calibrate confidence of LLMs with verbalized uncertainty, what is\nlacking is a careful examination of the linguistic knowledge of uncertainty\nencoded in the latent space of LLMs. In this paper, we draw on typological\nframeworks of epistemic expressions to evaluate LLMs' knowledge of epistemic\nmodality, using controlled stories. Our experiments show that the performance\nof LLMs in generating epistemic expressions is limited and not robust, and\nhence the expressions of uncertainty generated by LLMs are not always reliable.\nTo build uncertainty-aware LLMs, it is necessary to enrich semantic knowledge\nof epistemic modality in LLMs.",
    "pdf_url": "http://arxiv.org/pdf/2506.01512v1",
    "published": "2025-06-02T10:19:42+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.01511v1",
    "title": "Enhancing Diffusion-based Unrestricted Adversarial Attacks via Adversary Preferences Alignment",
    "authors": [
      "Kaixun Jiang",
      "Zhaoyu Chen",
      "Haijing Guo",
      "Jinglun Li",
      "Jiyuan Fu",
      "Pinxue Guo",
      "Hao Tang",
      "Bo Li",
      "Wenqiang Zhang"
    ],
    "abstract": "Preference alignment in diffusion models has primarily focused on benign\nhuman preferences (e.g., aesthetic). In this paper, we propose a novel\nperspective: framing unrestricted adversarial example generation as a problem\nof aligning with adversary preferences. Unlike benign alignment, adversarial\nalignment involves two inherently conflicting preferences: visual consistency\nand attack effectiveness, which often lead to unstable optimization and reward\nhacking (e.g., reducing visual quality to improve attack success). To address\nthis, we propose APA (Adversary Preferences Alignment), a two-stage framework\nthat decouples conflicting preferences and optimizes each with differentiable\nrewards. In the first stage, APA fine-tunes LoRA to improve visual consistency\nusing rule-based similarity reward. In the second stage, APA updates either the\nimage latent or prompt embedding based on feedback from a substitute\nclassifier, guided by trajectory-level and step-wise rewards. To enhance\nblack-box transferability, we further incorporate a diffusion augmentation\nstrategy. Experiments demonstrate that APA achieves significantly better attack\ntransferability while maintaining high visual consistency, inspiring further\nresearch to approach adversarial attacks from an alignment perspective. Code\nwill be available at https://github.com/deep-kaixun/APA.",
    "pdf_url": "http://arxiv.org/pdf/2506.01511v1",
    "published": "2025-06-02T10:18:09+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.01510v1",
    "title": "LinearVC: Linear transformations of self-supervised features through the lens of voice conversion",
    "authors": [
      "Herman Kamper",
      "Benjamin van Niekerk",
      "Julian Zaïdi",
      "Marc-André Carbonneau"
    ],
    "abstract": "We introduce LinearVC, a simple voice conversion method that sheds light on\nthe structure of self-supervised representations. First, we show that simple\nlinear transformations of self-supervised features effectively convert voices.\nNext, we probe the geometry of the feature space by constraining the set of\nallowed transformations. We find that just rotating the features is sufficient\nfor high-quality voice conversion. This suggests that content information is\nembedded in a low-dimensional subspace which can be linearly transformed to\nproduce a target voice. To validate this hypothesis, we finally propose a\nmethod that explicitly factorizes content and speaker information using\nsingular value decomposition; the resulting linear projection with a rank of\njust 100 gives competitive conversion results. Our work has implications for\nboth practical voice conversion and a broader understanding of self-supervised\nspeech representations. Samples and code: https://www.kamperh.com/linearvc/.",
    "pdf_url": "http://arxiv.org/pdf/2506.01510v1",
    "published": "2025-06-02T10:18:02+00:00",
    "categories": [
      "eess.AS",
      "cs.CL"
    ],
    "primary_category": "eess.AS"
  },
  {
    "id": "http://arxiv.org/abs/2506.01509v1",
    "title": "Two-stage Stochastic Assignment Games",
    "authors": [
      "Laura Sanità",
      "Lucy Verberk"
    ],
    "abstract": "In this paper, we study a two-stage stochastic version of the assignment\ngame, which is a fundamental cooperative game. Given an initial setting, the\nset of players may change in the second stage according to some probability\ndistribution, and the goal is to find core solutions that are minimally\nmodified.\n  When the probability distribution is given explicitly, we observe that the\nproblem is polynomial time solvable, as it can be modeled as an LP. More\ninterestingly, we prove that the underlying polyhedron is integral, and exploit\nthis in two ways.\n  First, integrality of the polyhedron allows us to show that the problem can\nbe well approximated when the distribution is unknown, which is a hard setting.\n  Second, we can establish an intimate connection to the well-studied\nmultistage vertex cover problem. Here, it is known that the problem is NP-hard\neven when there are only 2 stages and the graph in each stage is bipartite. As\na byproduct of our result, we can prove that the problem is polynomial-time\nsolvable if the bipartition is the same in each stage.",
    "pdf_url": "http://arxiv.org/pdf/2506.01509v1",
    "published": "2025-06-02T10:17:26+00:00",
    "categories": [
      "cs.DM"
    ],
    "primary_category": "cs.DM"
  },
  {
    "id": "http://arxiv.org/abs/2506.01508v1",
    "title": "Driving factors of auditory category learning success",
    "authors": [
      "Nan Wang",
      "Gangyi Feng"
    ],
    "abstract": "Our brain learns to update its mental model of the environment by abstracting\nsensory experiences for adaptation and survival. Learning to categorize sounds\nis one essential abstracting process for high-level human cognition, such as\nspeech perception, but it is also challenging due to the variable nature of\nauditory signals and their dynamic contexts. To overcome these learning\nchallenges and enhance learner performance, it is essential to identify the\nimpact of learning-related factors in developing better training protocols.\nHere, we conducted an extensive meta-analysis of auditory category learning\nstudies, including a total of 111 experiments and 4,521 participants, and\nexamined to what extent three hidden factors (i.e., variability, intensity, and\nengagement) derived from 12 experimental variables contributed to learning\nsuccess (i.e., effect sizes). Variables related to intensity and training\nvariability outweigh others in predicting learning effect size. Activation\nlikelihood estimation (ALE) meta-analysis of the neuroimaging studies revealed\ntraining-induced systematic changes in the frontotemporal-parietal networks.\nIncreased brain activities in speech and motor-related auditory-frontotemporal\nregions and decreased activities in cuneus and precuneus areas are associated\nwith increased learning effect sizes. These findings not only enhance our\nunderstanding of the driving forces behind speech and auditory category\nlearning success, along with its neural changes, but also guide researchers and\npractitioners in designing more effective training protocols that consider the\nthree key aspects of learning to facilitate learner success.",
    "pdf_url": "http://arxiv.org/pdf/2506.01508v1",
    "published": "2025-06-02T10:16:52+00:00",
    "categories": [
      "q-bio.NC"
    ],
    "primary_category": "q-bio.NC"
  },
  {
    "id": "http://arxiv.org/abs/2506.01507v1",
    "title": "Interpretation of the binary black hole mass spectrum",
    "authors": [
      "Ilya Mandel"
    ],
    "abstract": "This is a summary of an invited talk given at the Moriond Gravitation meeting\non March 31, 2025. I touch on some of the practical challenges of measuring the\nmass spectrum of merging binary black holes through their gravitational-wave\nsignatures. I then describe my take on the current state of interpreting the\nobserved binary black hole mass spectrum from the perspective of models for the\nformation of these sources. I conclude that meaningful progress must rely on\nthe combination of gravitational-wave observations and a broad range of\nelectromagnetic observations of massive stellar binaries at earlier stages of\ntheir evolution. This is my very personal and necessarily brief take on the\ncurrent state of the field and does not aspire to the balance or completeness\nof a review.",
    "pdf_url": "http://arxiv.org/pdf/2506.01507v1",
    "published": "2025-06-02T10:15:58+00:00",
    "categories": [
      "astro-ph.HE",
      "astro-ph.SR",
      "gr-qc"
    ],
    "primary_category": "astro-ph.HE"
  },
  {
    "id": "http://arxiv.org/abs/2506.01506v1",
    "title": "Deep learning of thermodynamic laws from microscopic dynamics",
    "authors": [
      "Hiroto Kuroyanagi",
      "Tatsuro Yuge"
    ],
    "abstract": "We numerically show that a deep neural network (DNN) can learn macroscopic\nthermodynamic laws purely from microscopic data. Using molecular dynamics\nsimulations, we generate the data of snapshot images of gas particles\nundergoing adiabatic processes. We train a DNN to determine the temporal order\nof input image pairs. We observe that the trained network induces an order\nrelation between states consistent with adiabatic accessibility, satisfying the\naxioms of thermodynamics. Furthermore, the internal representation learned by\nthe DNN act as an entropy. These results suggest that machine learning can\ndiscover emergent physical laws that are valid at scales far larger than those\nof the underlying constituents -- opening a pathway to data-driven discovery of\nmacroscopic physics.",
    "pdf_url": "http://arxiv.org/pdf/2506.01506v1",
    "published": "2025-06-02T10:12:33+00:00",
    "categories": [
      "cond-mat.stat-mech"
    ],
    "primary_category": "cond-mat.stat-mech"
  },
  {
    "id": "http://arxiv.org/abs/2506.01505v1",
    "title": "Biased rate estimates in bump-hunt searches",
    "authors": [
      "William Murray",
      "Matt O'Neill",
      "Finn O'Gara"
    ],
    "abstract": "The cleanest way to discover a new particle is generally the \"bump-hunt\"\nmethodology: looking for a localised excess in a mass (or related)\ndistribution. However, if the mass of the particle being discovered is not\nknown the procedure of quoting the most significant excess seen is \"greedy\",\nand random fluctuations from the background can be merged with the signal. This\nmeans that an observed 3{\\sigma} evidence probably has the rate over-estimated\nby of order 10% and the mass uncertainty underestimated by more like 20%. If\nthe width of the particle being discovered is also unknown, or the experimental\nresolution uncertain, the effect grows larger. In the context of LHC, the\ndata-doubling period is now measured in years. If evidence for a genuine signal\nis obtained at the 3{\\sigma} level, the true signal rate probably corresponds\nto a lower significance. The additional data required to produce a 5{\\sigma}\ndiscovery may be hundreds of inverse femtobarn more than might be naively\nexpected.",
    "pdf_url": "http://arxiv.org/pdf/2506.01505v1",
    "published": "2025-06-02T10:11:50+00:00",
    "categories": [
      "hep-ph"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.01504v1",
    "title": "Probing Cosmic Curvature with Fast Radio Bursts and DESI DR2",
    "authors": [
      "Jéferson A. S. Fortunato",
      "Wiliam S. Hipólito-Ricaldi",
      "Gustavo E. Romero"
    ],
    "abstract": "The spatial curvature of the Universe remains a central question in modern\ncosmology. In this work, we explore the potential of localized Fast Radio\nBursts (FRBs) as a novel tool to constrain the cosmic curvature parameter\n$\\Omega_k$ in a cosmological model-independent way. Using a sample of 80 FRBs\nwith known redshifts and dispersion measures, we reconstruct the Hubble\nparameter $H(z)$ via artificial neural networks, which is then used to obtain\nangular diameter distances $D_A(z)$ through two complementary approaches.\nFirst, we derive the comoving distance $D_C(z)$ and $D_A(z)$ from FRBs without\nassuming a fiducial cosmological model. Then, the $H(z)$ reconstruction is\ncombined with Baryon Acoustic Oscillation (BAO) measurements to infer $D_A(z)$.\nBy comparing the FRB-derived and BAO+FRB-derived $D_A(z)$ values, we extract\nconstraints on $\\Omega_k$ under the Friedmann-Lema\\^itre-Robertson-Walker\nmetric. Our results show consistency with a spatially flat Universe within\n$1\\sigma$ uncertainties, although a mild preference for negative curvature is\nobserved across both covariance-based and Gaussian analyses. This study\nhighlights the growing relevance of FRBs in precision cosmology and\ndemonstrates their synergy with BAO data as a powerful probe of the large-scale\ngeometry of the Universe.",
    "pdf_url": "http://arxiv.org/pdf/2506.01504v1",
    "published": "2025-06-02T10:08:54+00:00",
    "categories": [
      "astro-ph.CO",
      "hep-ph"
    ],
    "primary_category": "astro-ph.CO"
  },
  {
    "id": "http://arxiv.org/abs/2506.01503v1",
    "title": "Analyzing the Importance of Blank for CTC-Based Knowledge Distillation",
    "authors": [
      "Benedikt Hilmes",
      "Nick Rossenbach",
      "Ralf Schlüter"
    ],
    "abstract": "With the rise of large pre-trained foundation models for automatic speech\nrecognition new challenges appear. While the performance of these models is\ngood, runtime and cost of inference increases. One approach to make use of\ntheir strength while retaining efficiency is to distill their knowledge to\nsmaller models during training. In this work, we explore different CTC-based\ndistillation variants, focusing on blank token handling. We show that common\napproaches like blank elimination do not always work off the shelf. We explore\nnew blank selection patterns as a potential sweet spot between standard\nknowledge distillation and blank elimination mechanisms. Through the\nintroduction of a symmetric selection method, we are able to remove the CTC\nloss during knowledge distillation with minimal to no performance degradation.\nWith this, we make the training independent from target labels, potentially\nallowing for distillation on untranscribed audio data.",
    "pdf_url": "http://arxiv.org/pdf/2506.01503v1",
    "published": "2025-06-02T10:08:38+00:00",
    "categories": [
      "cs.LG",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.01502v1",
    "title": "Learning of Population Dynamics: Inverse Optimization Meets JKO Scheme",
    "authors": [
      "Mikhail Persiianov",
      "Jiawei Chen",
      "Petr Mokrov",
      "Alexander Tyurin",
      "Evgeny Burnaev",
      "Alexander Korotin"
    ],
    "abstract": "Learning population dynamics involves recovering the underlying process that\ngoverns particle evolution, given evolutionary snapshots of samples at discrete\ntime points. Recent methods frame this as an energy minimization problem in\nprobability space and leverage the celebrated JKO scheme for efficient time\ndiscretization. In this work, we introduce $\\texttt{iJKOnet}$, an approach that\ncombines the JKO framework with inverse optimization techniques to learn\npopulation dynamics. Our method relies on a conventional $\\textit{end-to-end}$\nadversarial training procedure and does not require restrictive architectural\nchoices, e.g., input-convex neural networks. We establish theoretical\nguarantees for our methodology and demonstrate improved performance over prior\nJKO-based methods.",
    "pdf_url": "http://arxiv.org/pdf/2506.01502v1",
    "published": "2025-06-02T10:08:03+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.01501v1",
    "title": "Refining Yoneda Lemma under Finiteness Constrains and Applications",
    "authors": [
      "Antonio Ceres",
      "Cristina Costoya",
      "Antonio Viruel"
    ],
    "abstract": "Classical Yoneda Lemma asserts that the isomorphism type of an object $a$ in\na category $C$ is determined by the natural type of the set-valued functor\n$Hom_C(a,-)$. Here we show that if finiteness hypothesis are assumed to hold in\n$C$, then the isomorphism type of an object $a$ in $C$ is determined by the\ninteger-valued function $|Hom_C(a,-)|$ on objects in $C$. We present\napplications of this result to the isomorphism problem in Group, Graph, and\nRing Theory.",
    "pdf_url": "http://arxiv.org/pdf/2506.01501v1",
    "published": "2025-06-02T10:07:40+00:00",
    "categories": [
      "math.CT",
      "math.GR",
      "math.RA"
    ],
    "primary_category": "math.CT"
  },
  {
    "id": "http://arxiv.org/abs/2506.01500v1",
    "title": "Thermal dilepton production within conformal viscous Gubser flow",
    "authors": [
      "Lakshmi J. Naik",
      "V. Sreekanth"
    ],
    "abstract": "By employing the Gubser solutions of causal relativistic second-order\nIsrael-Stewart hydrodynamics, we study the thermal dilepton production from\nheavy-ion collisions, considering the transverse expansion of the viscous hot\nQCD medium along with longitudinal boost-invariance. We analyze the evolution\nof the temperature and shear stress profiles of the QCD matter under Gubser\nflow for different values of the associated parameter $q$ (inverse length\nscale). We study the dilepton production using leading order Born rates from\nQGP and hadronic sectors under Gubser geometry. Viscous modified dilepton rate\nis calculated using the first-order Chapman-Enskog (CE) like non-equilibrium\ncorrection of the particle distribution function. Our study indicates that\nlower values of $q$ result in the enhancement of the emitted dilepton spectra.\nWe also determine the effective temperature of the hot QCD medium from the\ninverse slope of transverse mass spectra, for different $q$. We find that the\neffective temperature determined from the dilepton spectra for a smaller system\nto be higher. Further, we compare the strength of CE like and Grad's viscous\ncorrection to the ideal dilepton spectra and find that CE type viscous\ncorrections are well behaved compared to that of Grad's in the presence of\ntransverse flow.",
    "pdf_url": "http://arxiv.org/pdf/2506.01500v1",
    "published": "2025-06-02T10:05:58+00:00",
    "categories": [
      "hep-ph",
      "nucl-th"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.01499v1",
    "title": "A semi-smooth Newton method for magnetic field problems with hysteresis",
    "authors": [
      "Herbert Egger",
      "Felix Engertsberger"
    ],
    "abstract": "Ferromagnetic materials exhibit anisotropy, saturation, and hysteresis. We\nhere study the incorporation of an incremental vector hysteresis model\nrepresenting such complex behavior into nonlinear magnetic field problems both,\nfrom a theoretical and a numerical point of view. We show that the hysteresis\noperators, relating magnetic fields and fluxes at every material point, are\nstrongly monotone and Lipschitz continuous. This allows to ensure\nwell-posedness of the corresponding magnetic field problems and appropriate\nfinite element discretizations thereof. We further show that the hysteresis\noperators are semi-smooth, derive a candidate for their generalized Jacobians,\nand establish global linear and local superlinear convergence of a the\nsemi-smooth Newton method with line search applied to the iterative solution of\nthe discretized nonlinear field problems. The results are proven in detail for\na hysteresis model involving a single pinning force and the scalar potential\nformulation of magnetostatics. The extension to multiple pinning forces and the\nvector potential formulation is possible and briefly outlined. The theoretical\nresults are further illustrated by numerical tests.",
    "pdf_url": "http://arxiv.org/pdf/2506.01499v1",
    "published": "2025-06-02T10:04:59+00:00",
    "categories": [
      "math.NA",
      "cs.NA",
      "65K10, 65N30, 49M15, 65K15 46N10"
    ],
    "primary_category": "math.NA"
  },
  {
    "id": "http://arxiv.org/abs/2506.01498v1",
    "title": "Simulating Complex Crossectional and Longitudinal Data using the simDAG R Package",
    "authors": [
      "Robin Denz",
      "Nina Timmesfeld"
    ],
    "abstract": "Generating artificial data is a crucial step when performing Monte-Carlo\nsimulation studies. Depending on the planned study, complex data generation\nprocesses (DGP) containing multiple, possibly time-varying, variables with\nvarious forms of dependencies and data types may be required. Simulating data\nfrom such DGP may therefore become a difficult and time-consuming endeavor. The\nsimDAG R package offers a standardized approach to generate data from simple\nand complex DGP based on the definition of structural equations in directed\nacyclic graphs using arbitrary functions or regression models. The package\noffers a clear syntax with an enhanced formula interface and directly supports\ngenerating binary, categorical, count and time-to-event data with arbitrary\ndependencies, possibly non-linear relationships and interactions. It\nadditionally includes a framework to conduct discrete-time based simulations\nwhich allows the generation of longitudinal data on a semi-continuous\ntime-scale. This approach may be used to generate time-to-event data with both\nrecurrent or competing events and possibly multiple time-varying covariates,\nwhich may themselves have arbitrary data types. In this article we demonstrate\nthe vast amount of features included in simDAG by replicating the DGP of\nmultiple real Monte-Carlo simulation studies.",
    "pdf_url": "http://arxiv.org/pdf/2506.01498v1",
    "published": "2025-06-02T10:03:38+00:00",
    "categories": [
      "stat.ME",
      "stat.CO"
    ],
    "primary_category": "stat.ME"
  },
  {
    "id": "http://arxiv.org/abs/2506.01497v1",
    "title": "SpiceMixer -- Netlist-Level Circuit Evolution",
    "authors": [
      "Stefan Uhlich",
      "Andrea Bonetti",
      "Arun Venkitaraman",
      "Chia-Yu Hsieh",
      "Mustafa Emre Gürsoy",
      "Ryoga Matsuo",
      "Lorenzo Servadei"
    ],
    "abstract": "This paper introduces SpiceMixer, a genetic algorithm developed to synthesize\nnovel analog circuits by evolving SPICE netlists. Unlike conventional methods,\nSpiceMixer operates directly on netlist lines, enabling compatibility with any\ncomponent or subcircuit type and supporting general-purpose genetic operations.\nBy using a normalized netlist format, the algorithm enhances the effectiveness\nof its genetic operators: crossover, mutation, and pruning. We show that\nSpiceMixer achieves superior performance in synthesizing standard cells\n(inverter, two-input NAND, and latch) and in designing an analog classifier\ncircuit for the Iris dataset, reaching an accuracy of 89% on the test set.\nAcross all evaluated tasks, SpiceMixer consistently outperforms existing\nsynthesis methods.",
    "pdf_url": "http://arxiv.org/pdf/2506.01497v1",
    "published": "2025-06-02T10:00:05+00:00",
    "categories": [
      "cs.NE",
      "cs.AR",
      "cs.LG",
      "B.7.0"
    ],
    "primary_category": "cs.NE"
  },
  {
    "id": "http://arxiv.org/abs/2506.01496v2",
    "title": "Continual Speech Learning with Fused Speech Features",
    "authors": [
      "Guitao Wang",
      "Jinming Zhao",
      "Hao Yang",
      "Guilin Qi",
      "Tongtong Wu",
      "Gholamreza Haffari"
    ],
    "abstract": "Rapid growth in speech data demands adaptive models, as traditional static\nmethods fail to keep pace with dynamic and diverse speech information. We\nintroduce continuous speech learning, a new set-up targeting at bridging the\nadaptation gap in current speech models. We use the encoder-decoder Whisper\nmodel to standardize speech tasks into a generative format. We integrate a\nlearnable gated-fusion layer on the top of the encoder to dynamically select\ntask-specific features for downstream tasks. Our approach improves accuracy\nsignificantly over traditional methods in six speech processing tasks,\ndemonstrating gains in adapting to new speech tasks without full retraining.",
    "pdf_url": "http://arxiv.org/pdf/2506.01496v2",
    "published": "2025-06-02T09:59:35+00:00",
    "categories": [
      "cs.CL",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.01495v4",
    "title": "CVC: A Large-Scale Chinese Value Rule Corpus for Value Alignment of Large Language Models",
    "authors": [
      "Ping Wu",
      "Guobin Shen",
      "Dongcheng Zhao",
      "Yuwei Wang",
      "Yiting Dong",
      "Yu Shi",
      "Enmeng Lu",
      "Feifei Zhao",
      "Yi Zeng"
    ],
    "abstract": "Ensuring that Large Language Models (LLMs) align with mainstream human values\nand ethical norms is crucial for the safe and sustainable development of AI.\nCurrent value evaluation and alignment are constrained by Western cultural bias\nand incomplete domestic frameworks reliant on non-native rules; furthermore,\nthe lack of scalable, rule-driven scenario generation methods makes evaluations\ncostly and inadequate across diverse cultural contexts. To address these\nchallenges, we propose a hierarchical value framework grounded in core Chinese\nvalues, encompassing three main dimensions, 12 core values, and 50 derived\nvalues. Based on this framework, we construct a large-scale Chinese Values\nCorpus (CVC) containing over 250,000 value rules enhanced and expanded through\nhuman annotation. Experimental results show that CVC-guided scenarios\noutperform direct generation ones in value boundaries and content diversity. In\nthe evaluation across six sensitive themes (e.g., surrogacy, suicide), seven\nmainstream LLMs preferred CVC-generated options in over 70.5% of cases, while\nfive Chinese human annotators showed an 87.5% alignment with CVC, confirming\nits universality, cultural relevance, and strong alignment with Chinese values.\nAdditionally, we construct 400,000 rule-based moral dilemma scenarios that\nobjectively capture nuanced distinctions in conflicting value prioritization\nacross 17 LLMs. Our work establishes a culturally-adaptive benchmarking\nframework for comprehensive value evaluation and alignment, representing\nChinese characteristics. All data are available at\nhttps://huggingface.co/datasets/Beijing-AISI/CVC, and the code is available at\nhttps://github.com/Beijing-AISI/CVC.",
    "pdf_url": "http://arxiv.org/pdf/2506.01495v4",
    "published": "2025-06-02T09:56:59+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.01494v1",
    "title": "Turbulent puffs in transitional pulsatile pipe flow at moderate pulsation amplitudes",
    "authors": [
      "Daniel Morón",
      "Marc Avila"
    ],
    "abstract": "We show that, in the transitional regime of pulsatile pipe flow, at\nmoderate-to-high amplitudes 0.5 < A < 1, the first long-lived turbulent\nstructures are localized and take the form of the puffs and slugs observed in\nstatistically steady pipe flow. We perform direct numerical simulations at many\npulsation frequencies, amplitudes and Re, and observe different dynamics of\npuffs and slugs. At certain flow parameters we find, using a causal analysis,\nthat puffs actively make use of linear instabilities in the laminar\nSexl-Womersley profile to survive the pulsation. Using all these lessons\nlearned, we extend a low order model by Barkley et al., Nature (2015), to\nreproduce these dynamics. We find a good agreement between the extended model\nand our numerical results in a broad parametric space of pulsation amplitudes\n0.5 < A < 1, frequencies Wo > 5 and 2100 < Re < 3000. With the help of our\nnumerical results, causal analysis and model, we determine that turbulence\nproduction has two sources at these flow parameters: the mean shear as in\nstatistically steady pipe flow, and the instabilities of the instantaneous\npulsatile mean profile.",
    "pdf_url": "http://arxiv.org/pdf/2506.01494v1",
    "published": "2025-06-02T09:55:09+00:00",
    "categories": [
      "physics.flu-dyn"
    ],
    "primary_category": "physics.flu-dyn"
  },
  {
    "id": "http://arxiv.org/abs/2506.01493v1",
    "title": "Efficiency without Compromise: CLIP-aided Text-to-Image GANs with Increased Diversity",
    "authors": [
      "Yuya Kobayashi",
      "Yuhta Takida",
      "Takashi Shibuya",
      "Yuki Mitsufuji"
    ],
    "abstract": "Recently, Generative Adversarial Networks (GANs) have been successfully\nscaled to billion-scale large text-to-image datasets. However, training such\nmodels entails a high training cost, limiting some applications and research\nusage. To reduce the cost, one promising direction is the incorporation of\npre-trained models. The existing method of utilizing pre-trained models for a\ngenerator significantly reduced the training cost compared with the other\nlarge-scale GANs, but we found the model loses the diversity of generation for\na given prompt by a large margin. To build an efficient and high-fidelity\ntext-to-image GAN without compromise, we propose to use two specialized\ndiscriminators with Slicing Adversarial Networks (SANs) adapted for\ntext-to-image tasks. Our proposed model, called SCAD, shows a notable\nenhancement in diversity for a given prompt with better sample fidelity. We\nalso propose to use a metric called Per-Prompt Diversity (PPD) to evaluate the\ndiversity of text-to-image models quantitatively. SCAD achieved a zero-shot FID\ncompetitive with the latest large-scale GANs at two orders of magnitude less\ntraining cost.",
    "pdf_url": "http://arxiv.org/pdf/2506.01493v1",
    "published": "2025-06-02T09:54:41+00:00",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.01492v1",
    "title": "Challenges in designing research infrastructure software in multi-stakeholder contexts",
    "authors": [
      "Stephan Druskat",
      "Sabine Theis"
    ],
    "abstract": "This study investigates the challenges in designing research infrastructure\nsoftware for automated software publication in multi-stakeholder environments,\nfocusing specifically on the HERMES system. Through two quantitative surveys of\nresearch software engineers (RSEs) and infrastructure facility staff (IFs), it\nexamines technical, organizational, and social requirements across these\nstakeholder groups. The study reveals significant differences in how RSEs and\nIFs prioritize various system features. While RSEs highly value compatibility\nwith existing infrastructure, IFs prioritize user-focused aspects like system\nusability and documentation. The research identifies two main challenges in\ndesigning research infrastructure software: (1) the existence of multiple\nstakeholder groups with differing requirements, and (2) the internal\nheterogeneity within each stakeholder group across dimensions such as technical\nexperience. The study also highlights that only half of RSE respondents\nactively practice software publication, pointing to potential cultural or\ntechnical barriers. Additionally, the research reveals discrepancies in how\nstakeholders view organizational aspects, with IFs consistently rating factors\nlike responsibility structures and quality assurance as more important than\nRSEs do. These findings contribute to a better understanding of the\ncomplexities involved in designing research infrastructure software and\nemphasize the need for systems that can accommodate diverse user groups while\nmaintaining usability across different technical expertise levels.",
    "pdf_url": "http://arxiv.org/pdf/2506.01492v1",
    "published": "2025-06-02T09:50:30+00:00",
    "categories": [
      "cs.SE",
      "cs.HC"
    ],
    "primary_category": "cs.SE"
  },
  {
    "id": "http://arxiv.org/abs/2506.01491v1",
    "title": "Linked skyrmions in shifted magnetic bilayer",
    "authors": [
      "Sumit Ghosh",
      "Hiroshi Katsumoto",
      "Gustav Bihlmayer",
      "Moritz Sallermann",
      "Vladyslav M. Kuchkin",
      "Filipp N. Rybakov",
      "Olle Eriksson",
      "Stefan Blügel",
      "Nikolai S. Kiselev"
    ],
    "abstract": "We present a shifted magnetic bilayer that exhibits various magnetic phases\nand magnetic textures with arbitrarily large topological numbers. The proposed\nsystem is characterised by a mutually orthogonal Dzyaloshinskii-Moriya\ninteraction (DMI) in two different layers which can be induced by suitably\nplacing non-magnetic atom with spin-orbit coupling. At weak interlayer\ncoupling, the ground state resembles a checker-board pattern containing regions\nwith unfavourable magnetic alignment which we call anti-aligned points. At\nfinite interlayer coupling and finite external magnetic field, the bilayer can\ndemonstrate a new class of magnetic solitons where multiple magnetic solitons\ncan be connected by topological point defects which we call linked skyrmion. In\naddition to that the model also demonstrates conventional skyrmion-bags and\n$k\\pi$-skyrmions. Finally, with rigorous first principle calculations, we\npropose a suitable material candidate where these magnetic configurations can\nbe observed.",
    "pdf_url": "http://arxiv.org/pdf/2506.01491v1",
    "published": "2025-06-02T09:50:20+00:00",
    "categories": [
      "cond-mat.mes-hall"
    ],
    "primary_category": "cond-mat.mes-hall"
  },
  {
    "id": "http://arxiv.org/abs/2506.01490v1",
    "title": "Confidence-Aware Self-Distillation for Multimodal Sentiment Analysis with Incomplete Modalities",
    "authors": [
      "Yanxi Luo",
      "Shijin Wang",
      "Zhongxing Xu",
      "Yulong Li",
      "Feilong Tang",
      "Jionglong Su"
    ],
    "abstract": "Multimodal sentiment analysis (MSA) aims to understand human sentiment\nthrough multimodal data. In real-world scenarios, practical factors often lead\nto uncertain modality missingness. Existing methods for handling modality\nmissingness are based on data reconstruction or common subspace projections.\nHowever, these methods neglect the confidence in multimodal combinations and\nimpose constraints on intra-class representation, hindering the capture of\nmodality-specific information and resulting in suboptimal performance. To\naddress these challenges, we propose a Confidence-Aware Self-Distillation\n(CASD) strategy that effectively incorporates multimodal probabilistic\nembeddings via a mixture of Student's $t$-distributions, enhancing its\nrobustness by incorporating confidence and accommodating heavy-tailed\nproperties. This strategy estimates joint distributions with uncertainty scores\nand reduces uncertainty in the student network by consistency distillation.\nFurthermore, we introduce a reparameterization representation module that\nfacilitates CASD in robust multimodal learning by sampling embeddings from the\njoint distribution for the prediction module to calculate the task loss. As a\nresult, the directional constraint from the loss minimization is alleviated by\nthe sampled representation. Experimental results on three benchmark datasets\ndemonstrate that our method achieves state-of-the-art performance.",
    "pdf_url": "http://arxiv.org/pdf/2506.01490v1",
    "published": "2025-06-02T09:48:41+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.01489v1",
    "title": "Multilingual Definition Modeling",
    "authors": [
      "Edison Marrese-Taylor",
      "Erica K. Shimomoto",
      "Alfredo Solano",
      "Enrique Reid"
    ],
    "abstract": "In this paper, we propose the first multilingual study on definition\nmodeling. We use monolingual dictionary data for four new languages (Spanish,\nFrench, Portuguese, and German) and perform an in-depth empirical study to test\nthe performance of pre-trained multilingual language models on definition\nmodeling of monosemic words when finetuned on this data. Furthermore, we use a\nzero-shot approach to test the multilingual capabilities of two popular\nchat-based Large Language Models (LLMs) in the task. Results show that\nmultilingual language models can perform on-pair with English but cannot\nleverage potential cross-lingual synergies, with LLMs generally offering better\nperformance overall. A comprehensive human evaluation of the LLM-generated\ndefinition highlights the zero and few-shot capabilities of these models in\nthis new task, also showing their shortcomings. Finally, we show that\nperformance on our task via BERTScore strongly correlates to the performance on\nmultilingual LLM benchmarks, suggesting that our task offers a viable\ncompute-constrained, stable and natural alternative to these.",
    "pdf_url": "http://arxiv.org/pdf/2506.01489v1",
    "published": "2025-06-02T09:48:37+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.01488v1",
    "title": "Argument-Centric Causal Intervention Method for Mitigating Bias in Cross-Document Event Coreference Resolution",
    "authors": [
      "Long Yao",
      "Wenzhong Yang",
      "Yabo Yin",
      "Fuyuan Wei",
      "Hongzhen Lv",
      "Jiaren Peng",
      "Liejun Wang",
      "Xiaoming Tao"
    ],
    "abstract": "Cross-document Event Coreference Resolution (CD-ECR) is a fundamental task in\nnatural language processing (NLP) that seeks to determine whether event\nmentions across multiple documents refer to the same real-world occurrence.\nHowever, current CD-ECR approaches predominantly rely on trigger features\nwithin input mention pairs, which induce spurious correlations between\nsurface-level lexical features and coreference relationships, impairing the\noverall performance of the models. To address this issue, we propose a novel\ncross-document event coreference resolution method based on Argument-Centric\nCausal Intervention (ACCI). Specifically, we construct a structural causal\ngraph to uncover confounding dependencies between lexical triggers and\ncoreference labels, and introduce backdoor-adjusted interventions to isolate\nthe true causal effect of argument semantics. To further mitigate spurious\ncorrelations, ACCI integrates a counterfactual reasoning module that quantifies\nthe causal influence of trigger word perturbations, and an argument-aware\nenhancement module to promote greater sensitivity to semantically grounded\ninformation. In contrast to prior methods that depend on costly data\naugmentation or heuristic-based filtering, ACCI enables effective debiasing in\na unified end-to-end framework without altering the underlying training\nprocedure. Extensive experiments demonstrate that ACCI achieves CoNLL F1 of\n88.4% on ECB+ and 85.2% on GVC, achieving state-of-the-art performance. The\nimplementation and materials are available at https://github.com/era211/ACCI.",
    "pdf_url": "http://arxiv.org/pdf/2506.01488v1",
    "published": "2025-06-02T09:46:59+00:00",
    "categories": [
      "cs.CL",
      "cs.IR"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.01487v2",
    "title": "FDSG: Forecasting Dynamic Scene Graphs",
    "authors": [
      "Yi Yang",
      "Yuren Cong",
      "Hao Cheng",
      "Bodo Rosenhahn",
      "Michael Ying Yang"
    ],
    "abstract": "Dynamic scene graph generation extends scene graph generation from images to\nvideos by modeling entity relationships and their temporal evolution. However,\nexisting methods either generate scene graphs from observed frames without\nexplicitly modeling temporal dynamics, or predict only relationships while\nassuming static entity labels and locations. These limitations hinder effective\nextrapolation of both entity and relationship dynamics, restricting video scene\nunderstanding. We propose Forecasting Dynamic Scene Graphs (FDSG), a novel\nframework that predicts future entity labels, bounding boxes, and\nrelationships, for unobserved frames, while also generating scene graphs for\nobserved frames. Our scene graph forecast module leverages query decomposition\nand neural stochastic differential equations to model entity and relationship\ndynamics. A temporal aggregation module further refines predictions by\nintegrating forecasted and observed information via cross-attention. To\nbenchmark FDSG, we introduce Scene Graph Forecasting, a new task for full\nfuture scene graph prediction. Experiments on Action Genome show that FDSG\noutperforms state-of-the-art methods on dynamic scene graph generation, scene\ngraph anticipation, and scene graph forecasting. Codes will be released upon\npublication.",
    "pdf_url": "http://arxiv.org/pdf/2506.01487v2",
    "published": "2025-06-02T09:46:22+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.01486v1",
    "title": "Model-agnostic Mitigation Strategies of Data Imbalance for Regression",
    "authors": [
      "Jelke Wibbeke",
      "Sebastian Rohjans",
      "Andreas Rauh"
    ],
    "abstract": "Data imbalance persists as a pervasive challenge in regression tasks,\nintroducing bias in model performance and undermining predictive reliability.\nThis is particularly detrimental in applications aimed at predicting rare\nevents that fall outside the domain of the bulk of the training data. In this\nstudy, we review the current state-of-the-art regarding sampling-based methods\nand cost-sensitive learning. Additionally, we propose novel approaches to\nmitigate model bias. To better asses the importance of data, we introduce the\ndensity-distance and density-ratio relevance functions, which effectively\nintegrate empirical frequency of data with domain-specific preferences,\noffering enhanced interpretability for end-users. Furthermore, we present\nadvanced mitigation techniques (cSMOGN and crbSMOGN), which build upon and\nimprove existing sampling methods. In a comprehensive quantitative evaluation,\nwe benchmark state-of-the-art methods on 10 synthetic and 42 real-world\ndatasets, using neural networks, XGBoosting trees and Random Forest models. Our\nanalysis reveals that while most strategies improve performance on rare\nsamples, they often degrade it on frequent ones. We demonstrate that\nconstructing an ensemble of models -- one trained with imbalance mitigation and\nanother without -- can significantly reduce these negative effects. The key\nfindings underscore the superior performance of our novel crbSMOGN sampling\ntechnique with the density-ratio relevance function for neural networks,\noutperforming state-of-the-art methods.",
    "pdf_url": "http://arxiv.org/pdf/2506.01486v1",
    "published": "2025-06-02T09:46:08+00:00",
    "categories": [
      "cs.LG",
      "62J20 (primary) 68T05 (secondary)",
      "I.2.6"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.01485v1",
    "title": "Unconventional Orbital Magnetism in Graphene-based Fractional Chern Insulators",
    "authors": [
      "Jian Xie",
      "Zaizhe Zhang",
      "Xi Chen",
      "Yves H. Kwan",
      "Zihao Huo",
      "Jonah Herzog-Arbeitman",
      "Liangliang Guo",
      "Kenji Watanabe",
      "Takashi Taniguchi",
      "Kaihui Liu",
      "X. C. Xie",
      "B. Andrei Bernevig",
      "Zhi-Da Song",
      "Xiaobo Lu"
    ],
    "abstract": "Orbital magnetism in graphene originates from correlation-driven spontaneous\nvalley symmetry breaking1-7. It can lead to various anomalous transport\nphenomena such as integer and fractional quantum anomalous Hall effects8-11. In\ngeneral, the in-plane magnetic field B|| primarily couples to the spin degrees\nof freedom in graphene and has long been presumed to have a negligible effect\non orbital magnetism due to the ultra-weak spin-orbit coupling12-18. In this\nwork, we report multiple unconventional orbital magnetic phenomena that are\nhighly sensitive to the B|| field in graphene/hBN superlattices hosting both\ninteger and fractional Chern insulators (FCIs). We observed chirality-switching\nbehaviors of the Chern insulator at moir\\'e filling factor {\\nu} = 1 under a\nfinite B_par, demonstrating that both the C = +-1 states are permissible ground\nstates at zero perpendicular magnetic field B_per. For the FCI at {\\nu} = 2/3,\nwe observed topological phase transitions between two states characterized by\nHall resistivity \\r{ho}xy = +-3h/2e2 under both B_per and B_par fields.\nIn-plane B|| field can effectively suppress the FCI state at zero B_per field\nand enhance the FCI state with the opposite chirality, as resolved in Landau\nfan diagrams. Moreover, we observed rich phase transitions at 1 < {\\nu} < 2,\naccompanied by intervalley coherence and anomalous Hall effects (AHE) that can\nbe triggered by sweeping either B_per or B_par. Our work has unveiled new\nproperties of orbital magnetism, providing a new knob for engineering various\nAHE in graphene.",
    "pdf_url": "http://arxiv.org/pdf/2506.01485v1",
    "published": "2025-06-02T09:45:42+00:00",
    "categories": [
      "cond-mat.mes-hall",
      "cond-mat.str-el"
    ],
    "primary_category": "cond-mat.mes-hall"
  },
  {
    "id": "http://arxiv.org/abs/2506.02080v2",
    "title": "Enhancing GOP in CTC-Based Mispronunciation Detection with Phonological Knowledge",
    "authors": [
      "Aditya Kamlesh Parikh",
      "Cristian Tejedor-Garcia",
      "Catia Cucchiarini",
      "Helmer Strik"
    ],
    "abstract": "Computer-Assisted Pronunciation Training (CAPT) systems employ automatic\nmeasures of pronunciation quality, such as the goodness of pronunciation (GOP)\nmetric. GOP relies on forced alignments, which are prone to labeling and\nsegmentation errors due to acoustic variability. While alignment-free methods\naddress these challenges, they are computationally expensive and scale poorly\nwith phoneme sequence length and inventory size. To enhance efficiency, we\nintroduce a substitution-aware alignment-free GOP that restricts phoneme\nsubstitutions based on phoneme clusters and common learner errors. We evaluated\nour GOP on two L2 English speech datasets, one with child speech, My\nPronunciation Coach (MPC), and SpeechOcean762, which includes child and adult\nspeech. We compared RPS (restricted phoneme substitutions) and UPS\n(unrestricted phoneme substitutions) setups within alignment-free methods,\nwhich outperformed the baseline. We discuss our results and outline avenues for\nfuture research.",
    "pdf_url": "http://arxiv.org/pdf/2506.02080v2",
    "published": "2025-06-02T09:45:29+00:00",
    "categories": [
      "eess.AS",
      "cs.AI"
    ],
    "primary_category": "eess.AS"
  },
  {
    "id": "http://arxiv.org/abs/2506.01484v2",
    "title": "LLM in the Loop: Creating the ParaDeHate Dataset for Hate Speech Detoxification",
    "authors": [
      "Shuzhou Yuan",
      "Ercong Nie",
      "Lukas Kouba",
      "Ashish Yashwanth Kangen",
      "Helmut Schmid",
      "Hinrich Schütze",
      "Michael Färber"
    ],
    "abstract": "Detoxification, the task of rewriting harmful language into non-toxic text,\nhas become increasingly important amid the growing prevalence of toxic content\nonline. However, high-quality parallel datasets for detoxification, especially\nfor hate speech, remain scarce due to the cost and sensitivity of human\nannotation. In this paper, we propose a novel LLM-in-the-loop pipeline\nleveraging GPT-4o-mini for automated detoxification. We first replicate the\nParaDetox pipeline by replacing human annotators with an LLM and show that the\nLLM performs comparably to human annotation. Building on this, we construct\nParaDeHate, a large-scale parallel dataset specifically for hatespeech\ndetoxification. We release ParaDeHate as a benchmark of over 8K hate/non-hate\ntext pairs and evaluate a wide range of baseline methods. Experimental results\nshow that models such as BART, fine-tuned on ParaDeHate, achieve better\nperformance in style accuracy, content preservation, and fluency, demonstrating\nthe effectiveness of LLM-generated detoxification text as a scalable\nalternative to human annotation.",
    "pdf_url": "http://arxiv.org/pdf/2506.01484v2",
    "published": "2025-06-02T09:45:05+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.01483v3",
    "title": "Inter-Speaker Relative Cues for Text-Guided Target Speech Extraction",
    "authors": [
      "Wang Dai",
      "Archontis Politis",
      "Tuomas Virtanen"
    ],
    "abstract": "We propose a novel approach that utilizes inter-speaker relative cues to\ndistinguish target speakers and extract their voices from mixtures. Continuous\ncues (e.g., temporal order, age, pitch level) are grouped by relative\ndifferences, while discrete cues (e.g., language, gender, emotion) retain their\ncategorical distinctions. Compared to fixed speech attribute classification,\ninter-speaker relative cues offer greater flexibility, facilitating much easier\nexpansion of text-guided target speech extraction datasets. Our experiments\nshow that combining all relative cues yields better performance than random\nsubsets, with gender and temporal order being the most robust across languages\nand reverberant conditions. Additional cues, such as pitch level, loudness,\ndistance, speaking duration, language, and pitch range, also demonstrate\nnotable benefits in complex scenarios. Fine-tuning pre-trained WavLM Base+ CNN\nencoders improves overall performance over the Conv1d baseline.",
    "pdf_url": "http://arxiv.org/pdf/2506.01483v3",
    "published": "2025-06-02T09:43:43+00:00",
    "categories": [
      "eess.AS",
      "cs.SD"
    ],
    "primary_category": "eess.AS"
  },
  {
    "id": "http://arxiv.org/abs/2506.01482v1",
    "title": "Automatic Stage Lighting Control: Is it a Rule-Driven Process or Generative Task?",
    "authors": [
      "Zijian Zhao",
      "Dian Jin",
      "Zijing Zhou",
      "Xiaoyu Zhang"
    ],
    "abstract": "Stage lighting plays an essential role in live music performances,\ninfluencing the engaging experience of both musicians and audiences. Given the\nhigh costs associated with hiring or training professional lighting engineers,\nAutomatic Stage Lighting Control (ASLC) has gained increasing attention.\nHowever, most existing approaches only classify music into limited categories\nand map them to predefined light patterns, resulting in formulaic and\nmonotonous outcomes that lack rationality. To address this issue, this paper\npresents an end-to-end solution that directly learns from experienced lighting\nengineers -- Skip-BART. To the best of our knowledge, this is the first work to\nconceptualize ASLC as a generative task rather than merely a classification\nproblem. Our method modifies the BART model to take audio music as input and\nproduce light hue and value (intensity) as output, incorporating a novel skip\nconnection mechanism to enhance the relationship between music and light within\nthe frame grid.We validate our method through both quantitative analysis and an\nhuman evaluation, demonstrating that Skip-BART outperforms conventional\nrule-based methods across all evaluation metrics and shows only a limited gap\ncompared to real lighting engineers.Specifically, our method yields a p-value\nof 0.72 in a statistical comparison based on human evaluations with human\nlighting engineers, suggesting that the proposed approach closely matches human\nlighting engineering performance. To support further research, we have made our\nself-collected dataset, code, and trained model parameters available at\nhttps://github.com/RS2002/Skip-BART .",
    "pdf_url": "http://arxiv.org/pdf/2506.01482v1",
    "published": "2025-06-02T09:42:36+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.MM",
      "eess.AS"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.01481v1",
    "title": "AidAI: Automated Incident Diagnosis for AI Workloads in the Cloud",
    "authors": [
      "Yitao Yang",
      "Yangtao Deng",
      "Yifan Xiong",
      "Baochun Li",
      "Hong Xu",
      "Peng Cheng"
    ],
    "abstract": "AI workloads experience frequent incidents due to intensive hardware\nutilization and extended training times. The current incident management\nworkflow is provider-centric, where customers report incidents and place the\nentire troubleshooting responsibility on the infrastructure provider. However,\nthe inherent knowledge gap between customer and provider significantly impacts\nincident resolution efficiency. In AI infrastructure, incidents may take\nseveral days on average to mitigate, resulting in delays and productivity\nlosses. To address these issues, we present AidAI, a customer-centric system\nthat provides immediate incident diagnosis for customers and streamlines the\ncreation of incident tickets for unresolved issues. The key idea of AidAI is to\nconstruct internal knowledge bases from historical on-call experiences during\nthe offline phase and mimic the reasoning process of human experts to diagnose\nincidents through trial and error in the online phase. Evaluations using\nreal-world incident records in Microsoft show that AidAI achieves an average\nMicro F1 score of 0.854 and Macro F1 score of 0.816 without significant\noverhead.",
    "pdf_url": "http://arxiv.org/pdf/2506.01481v1",
    "published": "2025-06-02T09:41:25+00:00",
    "categories": [
      "cs.SE"
    ],
    "primary_category": "cs.SE"
  },
  {
    "id": "http://arxiv.org/abs/2506.01480v1",
    "title": "Unlocking Aha Moments via Reinforcement Learning: Advancing Collaborative Visual Comprehension and Generation",
    "authors": [
      "Kaihang Pan",
      "Yang Wu",
      "Wendong Bu",
      "Kai Shen",
      "Juncheng Li",
      "Yingting Wang",
      "Yunfei Li",
      "Siliang Tang",
      "Jun Xiao",
      "Fei Wu",
      "Hang Zhao",
      "Yueting Zhuang"
    ],
    "abstract": "Recent endeavors in Multimodal Large Language Models (MLLMs) aim to unify\nvisual comprehension and generation. However, these two capabilities remain\nlargely independent, as if they are two separate functions encapsulated within\nthe same model. Consequently, visual comprehension does not enhance visual\ngeneration, and the reasoning mechanisms of LLMs have not been fully integrated\nto revolutionize image generation. In this paper, we propose to enable the\ncollaborative co-evolution of visual comprehension and generation, advancing\nimage generation into an iterative introspective process. We introduce a\ntwo-stage training approach: supervised fine-tuning teaches the MLLM with the\nfoundational ability to generate genuine CoT for visual generation, while\nreinforcement learning activates its full potential via an\nexploration-exploitation trade-off. Ultimately, we unlock the Aha moment in\nvisual generation, advancing MLLMs from text-to-image tasks to unified image\ngeneration. Extensive experiments demonstrate that our model not only excels in\ntext-to-image generation and image editing, but also functions as a superior\nimage semantic evaluator with enhanced visual comprehension capabilities.\nProject Page: https://janus-pro-r1.github.io.",
    "pdf_url": "http://arxiv.org/pdf/2506.01480v1",
    "published": "2025-06-02T09:39:28+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.01479v2",
    "title": "Exploring the Non-uniqueness of Node Co-occurrence Matrices of Hypergraphs",
    "authors": [
      "Timothy LaRock",
      "Renaud Lambiotte"
    ],
    "abstract": "Hypergraphs extend traditional networks by capturing multi-way or group\ninteractions. Given the complexity of hypergraph data and the wide range of\nmethodology available for pairwise network analysis, hypergraph data is often\nprojected onto a weighted and undirected network. The simplest of these\nprojections, often referred to as a node co-occurrence matrix, is known to be\nnon-unique, as distinct non-isomorphic hypergraphs can produce the same\nweighted adjacency matrix. This non-uniqueness raises important questions about\nthe structural information lost during the projection and how to efficiently\nquantify the complexity of the original hypergraph. Here we develop a search\nalgorithm to identify all hypergraphs corresponding to a given projection,\nanalyze its runtime, and explore its parallelisability. Applying this algorithm\nto projections derived from a random hypergraph model, we characterize\nconditions under which projections are non-unique. Our findings provide a new\nframework and set of computational tools to investigate projections of\nhypergraphs.",
    "pdf_url": "http://arxiv.org/pdf/2506.01479v2",
    "published": "2025-06-02T09:37:43+00:00",
    "categories": [
      "cs.SI",
      "physics.soc-ph"
    ],
    "primary_category": "cs.SI"
  },
  {
    "id": "http://arxiv.org/abs/2506.01478v1",
    "title": "MUDI: A Multimodal Biomedical Dataset for Understanding Pharmacodynamic Drug-Drug Interactions",
    "authors": [
      "Tung-Lam Ngo",
      "Ba-Hoang Tran",
      "Duy-Cat Can",
      "Trung-Hieu Do",
      "Oliver Y. Chén",
      "Hoang-Quynh Le"
    ],
    "abstract": "Understanding the interaction between different drugs (drug-drug interaction\nor DDI) is critical for ensuring patient safety and optimizing therapeutic\noutcomes. Existing DDI datasets primarily focus on textual information,\noverlooking multimodal data that reflect complex drug mechanisms. In this\npaper, we (1) introduce MUDI, a large-scale Multimodal biomedical dataset for\nUnderstanding pharmacodynamic Drug-drug Interactions, and (2) benchmark\nlearning methods to study it. In brief, MUDI provides a comprehensive\nmultimodal representation of drugs by combining pharmacological text, chemical\nformulas, molecular structure graphs, and images across 310,532 annotated drug\npairs labeled as Synergism, Antagonism, or New Effect. Crucially, to\neffectively evaluate machine-learning based generalization, MUDI consists of\nunseen drug pairs in the test set. We evaluate benchmark models using both late\nfusion voting and intermediate fusion strategies. All data, annotations,\nevaluation scripts, and baselines are released under an open research license.",
    "pdf_url": "http://arxiv.org/pdf/2506.01478v1",
    "published": "2025-06-02T09:36:08+00:00",
    "categories": [
      "cs.LG",
      "cs.CL",
      "cs.MM",
      "q-bio.QM"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.01477v2",
    "title": "Long time confinement of multiple concentrated vortices",
    "authors": [
      "David Meyer"
    ],
    "abstract": "We study the stability of multiple almost circular concentrated vortices in a\nfluid evolving according to the two-dimensional Euler equations. We show that,\nfor general configurations, they must remain concentrated on time-scales much\nlonger than previously known as long as they remain separated. We further prove\na new stability estimate for the logarithmic interaction energy as part of the\nproof.",
    "pdf_url": "http://arxiv.org/pdf/2506.01477v2",
    "published": "2025-06-02T09:35:59+00:00",
    "categories": [
      "math.AP"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2506.01476v1",
    "title": "Dependency of quantum time scales on symmetry",
    "authors": [
      "Fei Guo",
      "Dmitrii Usanov",
      "Eduardo B. Guedes",
      "Mauro Fanciulli",
      "Kaishu Kawaguchi",
      "Ryo Mori",
      "Takeshi Kondo",
      "Arnaud Magrez",
      "Michele Puppin",
      "Hugo Dil"
    ],
    "abstract": "Although used extensively in everyday life, time is one of the least\nunderstood quantities in physics, especially on the level of quantum mechanics.\nHere we use an experimental method based on spin- and angle-resolved\nphotoemission spectroscopy from spin-degenerate dispersive states to determine\nthe Eisenbud-Wigner-Smith (EWS) time delay of photoemission. This time scale of\nthe quantum transition is measured for materials with different dimensionality\nand correlation strength. A direct link between the dimensionality, or rather\nthe symmetry of the system, and the attosecond photoionisation time scale is\nfound. The quasi 2-dimensional transition metal dichalcogenides 1T-TiSe$_2$ and\n1T-TiTe$_2$ show time scales around 150 as, whereas in quasi 1-dimensional CuTe\nthe photoionisation takes more than 200 as. This is in stark contrast with the\n26 as found for 3-dimensional pure Cu. These results provide new insights into\nthe role of symmetry in quantum time scales and may provide a route to\nunderstanding the role of time in quantum mechanics.",
    "pdf_url": "http://arxiv.org/pdf/2506.01476v1",
    "published": "2025-06-02T09:35:57+00:00",
    "categories": [
      "cond-mat.mes-hall",
      "quant-ph"
    ],
    "primary_category": "cond-mat.mes-hall"
  },
  {
    "id": "http://arxiv.org/abs/2506.02079v1",
    "title": "Robust Federated Learning against Noisy Clients via Masked Optimization",
    "authors": [
      "Xuefeng Jiang",
      "Tian Wen",
      "Zhiqin Yang",
      "Lvhua Wu",
      "Yufeng Chen",
      "Sheng Sun",
      "Yuwei Wang",
      "Min Liu"
    ],
    "abstract": "In recent years, federated learning (FL) has made significant advance in\nprivacy-sensitive applications. However, it can be hard to ensure that FL\nparticipants provide well-annotated data for training. The corresponding\nannotations from different clients often contain complex label noise at varying\nlevels. This label noise issue has a substantial impact on the performance of\nthe trained models, and clients with greater noise levels can be largely\nattributed for this degradation. To this end, it is necessary to develop an\neffective optimization strategy to alleviate the adverse effects of these noisy\nclients.In this study, we present a two-stage optimization framework,\nMaskedOptim, to address this intricate label noise problem. The first stage is\ndesigned to facilitate the detection of noisy clients with higher label noise\nrates. The second stage focuses on rectifying the labels of the noisy clients'\ndata through an end-to-end label correction mechanism, aiming to mitigate the\nnegative impacts caused by misinformation within datasets. This is achieved by\nlearning the potential ground-truth labels of the noisy clients' datasets via\nbackpropagation. To further enhance the training robustness, we apply the\ngeometric median based model aggregation instead of the commonly-used vanilla\naveraged model aggregation. We implement sixteen related methods and conduct\nevaluations on three image datasets and one text dataset with diverse label\nnoise patterns for a comprehensive comparison. Extensive experimental results\nindicate that our proposed framework shows its robustness in different\nscenarios. Additionally, our label correction framework effectively enhances\nthe data quality of the detected noisy clients' local datasets. % Our codes\nwill be open-sourced to facilitate related research communities. Our codes are\navailable via https://github.com/Sprinter1999/MaskedOptim .",
    "pdf_url": "http://arxiv.org/pdf/2506.02079v1",
    "published": "2025-06-02T09:35:42+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.12067v2",
    "title": "Evaluating Logit-Based GOP Scores for Mispronunciation Detection",
    "authors": [
      "Aditya Kamlesh Parikh",
      "Cristian Tejedor-Garcia",
      "Catia Cucchiarini",
      "Helmer Strik"
    ],
    "abstract": "Pronunciation assessment relies on goodness of pronunciation (GOP) scores,\ntraditionally derived from softmax-based posterior probabilities. However,\nposterior probabilities may suffer from overconfidence and poor phoneme\nseparation, limiting their effectiveness. This study compares logit-based GOP\nscores with probability-based GOP scores for mispronunciation detection. We\nconducted our experiment on two L2 English speech datasets spoken by Dutch and\nMandarin speakers, assessing classification performance and correlation with\nhuman ratings. Logit-based methods outperform probability-based GOP in\nclassification, but their effectiveness depends on dataset characteristics. The\nmaximum logit GOP shows the strongest alignment with human perception, while a\ncombination of different GOP scores balances probability and logit features.\nThe findings suggest that hybrid GOP methods incorporating uncertainty modeling\nand phoneme-specific weighting improve pronunciation assessment.",
    "pdf_url": "http://arxiv.org/pdf/2506.12067v2",
    "published": "2025-06-02T09:35:13+00:00",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.SD"
    ],
    "primary_category": "eess.AS"
  },
  {
    "id": "http://arxiv.org/abs/2506.01475v1",
    "title": "PGPO: Enhancing Agent Reasoning via Pseudocode-style Planning Guided Preference Optimization",
    "authors": [
      "Zouying Cao",
      "Runze Wang",
      "Yifei Yang",
      "Xinbei Ma",
      "Xiaoyong Zhu",
      "Bo Zheng",
      "Hai Zhao"
    ],
    "abstract": "Large Language Model (LLM) agents have demonstrated impressive capabilities\nin handling complex interactive problems. Existing LLM agents mainly generate\nnatural language plans to guide reasoning, which is verbose and inefficient. NL\nplans are also tailored to specific tasks and restrict agents' ability to\ngeneralize across similar tasks. To this end, we explore pseudocode-style plans\n(P-code Plan) to capture the structural logic of reasoning. We find that P-code\nPlan empowers LLM agents with stronger generalization ability and more\nefficiency. Inspired by this finding, we propose a pseudocode-style Planning\nGuided Preference Optimization method called PGPO for effective agent learning.\nWith two planning-oriented rewards, PGPO further enhances LLM agents' ability\nto generate high-quality P-code Plans and subsequent reasoning. Experiments\nshow that PGPO achieves superior performance on representative agent benchmarks\nand outperforms the current leading baselines. Analyses reveal the advantage of\nPGPO in reducing action errors and omissions during reasoning.",
    "pdf_url": "http://arxiv.org/pdf/2506.01475v1",
    "published": "2025-06-02T09:35:07+00:00",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2506.01474v1",
    "title": "Integrating Neural and Symbolic Components in a Model of Pragmatic Question-Answering",
    "authors": [
      "Polina Tsvilodub",
      "Robert D. Hawkins",
      "Michael Franke"
    ],
    "abstract": "Computational models of pragmatic language use have traditionally relied on\nhand-specified sets of utterances and meanings, limiting their applicability to\nreal-world language use. We propose a neuro-symbolic framework that enhances\nprobabilistic cognitive models by integrating LLM-based modules to propose and\nevaluate key components in natural language, eliminating the need for manual\nspecification. Through a classic case study of pragmatic question-answering, we\nsystematically examine various approaches to incorporating neural modules into\nthe cognitive model -- from evaluating utilities and literal semantics to\ngenerating alternative utterances and goals. We find that hybrid models can\nmatch or exceed the performance of traditional probabilistic models in\npredicting human answer patterns. However, the success of the neuro-symbolic\nmodel depends critically on how LLMs are integrated: while they are\nparticularly effective for proposing alternatives and transforming abstract\ngoals into utilities, they face challenges with truth-conditional semantic\nevaluation. This work charts a path toward more flexible and scalable models of\npragmatic language use while illuminating crucial design considerations for\nbalancing neural and symbolic components.",
    "pdf_url": "http://arxiv.org/pdf/2506.01474v1",
    "published": "2025-06-02T09:34:37+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.01473v1",
    "title": "Characterization based Goodness-of-Fit for Generalized Pareto Distribution: A Blend of Stein's Identity and Dynamic Survival Extropy",
    "authors": [
      "Gaurav Kandpal",
      "Nitin Gupta"
    ],
    "abstract": "This paper proposes a goodness of fit test for the generalized Pareto\ndistribution (GPD). Firstly, we provide two characterizations of GPD based on\nStein's identity and dynamic survival extropy. These characterizations are used\nto test GPD separately for the positive and negative shape parameter cases. A\nMonte Carlo simulation is conducted to provide the critical values and power of\nthe proposed test against a good number of alternatives. Our test is simple to\nuse and it has asymptotic normality and relatively high power, which\nstrengthened the purpose of proposing it. Considering the case of right\ncensored data, we provide the procedure to handle censored case too. A few\nreal-life applications are also included.",
    "pdf_url": "http://arxiv.org/pdf/2506.01473v1",
    "published": "2025-06-02T09:33:31+00:00",
    "categories": [
      "stat.ME",
      "math.ST",
      "stat.AP",
      "stat.TH",
      "62G10, 62G20, 62B10, 94A17"
    ],
    "primary_category": "stat.ME"
  },
  {
    "id": "http://arxiv.org/abs/2506.01472v1",
    "title": "Resonant states of structured photonic time crystals",
    "authors": [
      "Adrià Canós Valero",
      "Sergei Gladyshev",
      "David Globosits",
      "Stefan Rotter",
      "Egor A. Muljarov",
      "Thomas Weiss"
    ],
    "abstract": "Photonic time crystals (PTCs) are spatially uniform media with periodic\nmodulation in time, enabling momentum bandgaps and the parametric amplification\nof light. While their potential in optical systems is very promising, practical\nimplementations require temporally modulating nanostructures of finite size,\nfor which the physics is no longer governed by bulk properties but by resonant\nstates, or quasinormal modes. Despite their importance, a quantitative theory\ndescribing the dynamics of these modes has been missing -- a gap we address\nhere by developing a comprehensive resonant state theory for PTCs with\narbitrary geometry. Our framework provides a detailed understanding of the\nresonant behavior of \"structured\" PTCs and uncovers several fundamental\nphenomena. For weak modulations, we find a universal quadratic dependence of\nthe eigenfrequencies on the modulation amplitude. Moreover, each static\nresonant state gives rise to an infinite ladder of new eigenmodes, spaced by\ninteger multiples of the modulation frequency. Crucially, we show that\nparametric amplification in these systems arises from a fundamentally resonant\nprocess, not captured by the momentum bandgap picture of \"bulk\" PTCs. We apply\nour theory to a realistic Bragg microcavity, demonstrating the design of\ntailored parametric resonances. Due to its generality and predictive power, our\napproach lays the foundation for the systematic study and engineering of\nstructured PTCs, advancing the emerging field of space-time optics.",
    "pdf_url": "http://arxiv.org/pdf/2506.01472v1",
    "published": "2025-06-02T09:33:00+00:00",
    "categories": [
      "physics.optics"
    ],
    "primary_category": "physics.optics"
  },
  {
    "id": "http://arxiv.org/abs/2506.02078v1",
    "title": "Evaluating the Effectiveness of Pre-Trained Audio Embeddings for Classification of Parkinson's Disease Speech Data",
    "authors": [
      "Emmy Postma",
      "Cristian Tejedor-Garcia"
    ],
    "abstract": "Speech impairments are prevalent biomarkers for Parkinson's Disease (PD),\nmotivating the development of diagnostic techniques using speech data for\nclinical applications. Although deep acoustic features have shown promise for\nPD classification, their effectiveness often varies due to individual speaker\ndifferences, a factor that has not been thoroughly explored in the existing\nliterature. This study investigates the effectiveness of three pre-trained\naudio embeddings (OpenL3, VGGish and Wav2Vec2.0 models) for PD classification.\nUsing the NeuroVoz dataset, OpenL3 outperforms others in diadochokinesis (DDK)\nand listen and repeat (LR) tasks, capturing critical acoustic features for PD\ndetection. Only Wav2Vec2.0 shows significant gender bias, achieving more\nfavorable results for male speakers, in DDK tasks. The misclassified cases\nreveal challenges with atypical speech patterns, highlighting the need for\nimproved feature extraction and model robustness in PD detection.",
    "pdf_url": "http://arxiv.org/pdf/2506.02078v1",
    "published": "2025-06-02T09:32:54+00:00",
    "categories": [
      "eess.AS",
      "cs.AI"
    ],
    "primary_category": "eess.AS"
  },
  {
    "id": "http://arxiv.org/abs/2506.01471v1",
    "title": "SemiVT-Surge: Semi-Supervised Video Transformer for Surgical Phase Recognition",
    "authors": [
      "Yiping Li",
      "Ronald de Jong",
      "Sahar Nasirihaghighi",
      "Tim Jaspers",
      "Romy van Jaarsveld",
      "Gino Kuiper",
      "Richard van Hillegersberg",
      "Fons van der Sommen",
      "Jelle Ruurda",
      "Marcel Breeuwer",
      "Yasmina Al Khalil"
    ],
    "abstract": "Accurate surgical phase recognition is crucial for computer-assisted\ninterventions and surgical video analysis. Annotating long surgical videos is\nlabor-intensive, driving research toward leveraging unlabeled data for strong\nperformance with minimal annotations. Although self-supervised learning has\ngained popularity by enabling large-scale pretraining followed by fine-tuning\non small labeled subsets, semi-supervised approaches remain largely\nunderexplored in the surgical domain. In this work, we propose a video\ntransformer-based model with a robust pseudo-labeling framework. Our method\nincorporates temporal consistency regularization for unlabeled data and\ncontrastive learning with class prototypes, which leverages both labeled data\nand pseudo-labels to refine the feature space. Through extensive experiments on\nthe private RAMIE (Robot-Assisted Minimally Invasive Esophagectomy) dataset and\nthe public Cholec80 dataset, we demonstrate the effectiveness of our approach.\nBy incorporating unlabeled data, we achieve state-of-the-art performance on\nRAMIE with a 4.9% accuracy increase and obtain comparable results to full\nsupervision while using only 1/4 of the labeled data on Cholec80. Our findings\nestablish a strong benchmark for semi-supervised surgical phase recognition,\npaving the way for future research in this domain.",
    "pdf_url": "http://arxiv.org/pdf/2506.01471v1",
    "published": "2025-06-02T09:32:12+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.01470v1",
    "title": "Persistence of charge ordering instability to Coulomb engineering in the excitonic insulator candidate TiSe$_2$",
    "authors": [
      "Sebastian Buchberger",
      "Yann in 't Veld",
      "Akhil Rajan",
      "Philip A. E. Murgatroyd",
      "Brendan Edwards",
      "Bruno K. Saika",
      "Naina Kushwaha",
      "Maria H. Visscher",
      "Jan Berges",
      "Dina Carbone",
      "Jacek Osiecki",
      "Craig Polley",
      "Tim Wehling",
      "Phil D. C. King"
    ],
    "abstract": "TiSe$_2$ has long been considered one of the best candidate materials to host\nthe elusive excitonic insulator (EI) phase. However, a finite coupling to the\nlattice can generically be expected, while a lack of \"smoking-gun\" signatures\nfor the importance of the electron-hole interaction in driving the phase\ntransition has rendered it challenging to distinguish the EI from the\nconventional charge-density-wave (CDW) phase. Here, we demonstrate a new\napproach, exploiting the susceptibility of excitons to dielectric screening. We\ncombine mechanical exfoliation with molecular-beam epitaxy to fabricate\nultra-clean van der Waals heterostructures of monolayer (ML-)TiSe$_2$/graphite\nand ML-TiSe$_2$/hBN. We observe how the modified substrate screening\nenvironment drives a renormalisation of the quasi-particle band gap of the\nTiSe$_2$ layer, signifying its susceptibility to Coloumb engineering. The\ntemperature-dependent evolution of its electronic structure, however, remains\nunaffected, indicating that excitons are not required to drive the CDW\ntransition in TiSe$_2$.",
    "pdf_url": "http://arxiv.org/pdf/2506.01470v1",
    "published": "2025-06-02T09:32:03+00:00",
    "categories": [
      "cond-mat.mtrl-sci",
      "cond-mat.mes-hall",
      "cond-mat.str-el"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2506.01469v1",
    "title": "A State of the Art on Recent Progress and Emerging Challenges on Energy Transfer Between Vibrating Modes Under an External Mechanical Force With Time-Varying Frequency From 2020 to 2025",
    "authors": [
      "Jose Manoel Balthazar",
      "Jorge Luis Palacios Felix",
      "Mauricio A. Ribeiro",
      "Angelo Marcelo Tusset",
      "Jeferson Jose de Lima",
      "Vinicius Piccirillo",
      "Julijana Simonovic",
      "Nikola D. Nevsic",
      "Marcos Varanis",
      "Clivaldo de Oliveira",
      "Raphaela C. Machado",
      "Gabriella O M Oliveira"
    ],
    "abstract": "In this paper, we discuss an example of current importance with a future\nperspective in engineering, in which excitation sources always have limited\npower, limited inertia, and their frequencies vary according to the\ninstantaneous state of the vibrating system. Practical examples of non-ideal\nsystems are considered. The most common phenomenon for this kind of system is\ndiscussed. The period considered is from 2020 to 2025. The specific properties\nof various models are also discussed. Directions for future investigations are\nprovided. In this paper, the authors revisited some publications based on the\nassumption that the external excitations are produced by non-ideal sources\n(RNIS), that is, with limited power supply. Among these applications, nonlinear\nphenomena such as the Sommerfeld effect and saturation phenomenon were\nobserved, considering fractional damping. Energy harvesters and the\nJacobi-Anger expansion were used in the governing equations of motion. We also\nused the Jacobi-Anger expansion in the case of energy transfer between\nvibrating modes under an external force with time-varying frequency, which\nrepresents one of the future directions of research on non-ideal vibrating\nsystems (RNIS).",
    "pdf_url": "http://arxiv.org/pdf/2506.01469v1",
    "published": "2025-06-02T09:27:58+00:00",
    "categories": [
      "nlin.CD",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "nlin.CD"
  },
  {
    "id": "http://arxiv.org/abs/2506.01468v1",
    "title": "Sheep Facial Pain Assessment Under Weighted Graph Neural Networks",
    "authors": [
      "Alam Noor",
      "Luis Almeida",
      "Mohamed Daoudi",
      "Kai Li",
      "Eduardo Tovar"
    ],
    "abstract": "Accurately recognizing and assessing pain in sheep is key to discern animal\nhealth and mitigating harmful situations. However, such accuracy is limited by\nthe ability to manage automatic monitoring of pain in those animals. Facial\nexpression scoring is a widely used and useful method to evaluate pain in both\nhumans and other living beings. Researchers also analyzed the facial\nexpressions of sheep to assess their health state and concluded that facial\nlandmark detection and pain level prediction are essential. For this purpose,\nwe propose a novel weighted graph neural network (WGNN) model to link sheep's\ndetected facial landmarks and define pain levels. Furthermore, we propose a new\nsheep facial landmarks dataset that adheres to the parameters of the Sheep\nFacial Expression Scale (SPFES). Currently, there is no comprehensive\nperformance benchmark that specifically evaluates the use of graph neural\nnetworks (GNNs) on sheep facial landmark data to detect and measure pain\nlevels. The YOLOv8n detector architecture achieves a mean average precision\n(mAP) of 59.30% with the sheep facial landmarks dataset, among seven other\ndetection models. The WGNN framework has an accuracy of 92.71% for tracking\nmultiple facial parts expressions with the YOLOv8n lightweight on-board device\ndeployment-capable model.",
    "pdf_url": "http://arxiv.org/pdf/2506.01468v1",
    "published": "2025-06-02T09:24:09+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.01467v1",
    "title": "Feature-aware Hypergraph Generation via Next-Scale Prediction",
    "authors": [
      "Dorian Gailhard",
      "Enzo Tartaglione",
      "Lirida Naviner",
      "Jhony H. Giraldo"
    ],
    "abstract": "Hypergraphs generalize traditional graphs by allowing hyperedges to connect\nmultiple nodes, making them well-suited for modeling complex structures with\nhigher-order relationships, such as 3D meshes, molecular systems, and\nelectronic circuits. While topology is central to hypergraph structure, many\nreal-world applications also require node and hyperedge features. Existing\nhypergraph generation methods focus solely on topology, often overlooking\nfeature modeling. In this work, we introduce FAHNES (feature-aware hypergraph\ngeneration via next-scale prediction), a hierarchical approach that jointly\ngenerates hypergraph topology and features. FAHNES builds a multi-scale\nrepresentation through node coarsening, then learns to reconstruct finer levels\nvia localized expansion and refinement, guided by a new node budget mechanism\nthat controls cluster splitting. We evaluate FAHNES on synthetic hypergraphs,\n3D meshes, and molecular datasets. FAHNES achieves competitive results in\nreconstructing topology and features, establishing a foundation for future\nresearch in featured hypergraph generative modeling.",
    "pdf_url": "http://arxiv.org/pdf/2506.01467v1",
    "published": "2025-06-02T09:24:08+00:00",
    "categories": [
      "cs.LG",
      "cs.DM"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.01466v1",
    "title": "Towards Scalable Video Anomaly Retrieval: A Synthetic Video-Text Benchmark",
    "authors": [
      "Shuyu Yang",
      "Yilun Wang",
      "Yaxiong Wang",
      "Li Zhu",
      "Zhedong Zheng"
    ],
    "abstract": "Video anomaly retrieval aims to localize anomalous events in videos using\nnatural language queries to facilitate public safety. However, existing\ndatasets suffer from severe limitations: (1) data scarcity due to the long-tail\nnature of real-world anomalies, and (2) privacy constraints that impede\nlarge-scale collection. To address the aforementioned issues in one go, we\nintroduce SVTA (Synthetic Video-Text Anomaly benchmark), the first large-scale\ndataset for cross-modal anomaly retrieval, leveraging generative models to\novercome data availability challenges. Specifically, we collect and generate\nvideo descriptions via the off-the-shelf LLM (Large Language Model) covering 68\nanomaly categories, e.g., throwing, stealing, and shooting. These descriptions\nencompass common long-tail events. We adopt these texts to guide the video\ngenerative model to produce diverse and high-quality videos. Finally, our SVTA\ninvolves 41,315 videos (1.36M frames) with paired captions, covering 30 normal\nactivities, e.g., standing, walking, and sports, and 68 anomalous events, e.g.,\nfalling, fighting, theft, explosions, and natural disasters. We adopt three\nwidely-used video-text retrieval baselines to comprehensively test our SVTA,\nrevealing SVTA's challenging nature and its effectiveness in evaluating a\nrobust cross-modal retrieval method. SVTA eliminates privacy risks associated\nwith real-world anomaly collection while maintaining realistic scenarios. The\ndataset demo is available at: [https://svta-mm.github.io/SVTA.github.io/].",
    "pdf_url": "http://arxiv.org/pdf/2506.01466v1",
    "published": "2025-06-02T09:23:58+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.01465v1",
    "title": "Amplitude Noise Cancellation of Microwave Tones",
    "authors": [
      "Joe Depellette",
      "Ewa Rej",
      "Matthew Herbst",
      "Richa Cutting",
      "Yulong Liu",
      "Mika A. Sillanpää"
    ],
    "abstract": "Carrier noise in coherent tones limits sensitivity and causes heating in many\nexperimental systems, such as force sensors, time-keeping, and studies of\nmacroscopic quantum phenomena. Much progress has been made to reduce carrier\nnoise using phase noise cancellation techniques, however, in systems where\namplitude noise dominates, these methods are ineffective. Here, we present a\ntechnique to reduce amplitude noise from microwave generators using feedback\ncancellation. The method uses a field-programmable gate array (FPGA) to\nreproduce noise with a tunable gain and time delay, resulting in destructive\ninterference when combined with the original tone. The FPGA additionally allows\nfor tuning of the frequency offset and bandwidth in which the noise is\ncanceled. By employing the cancellation we observe 13 dB of noise power\nreduction at a 2 MHz offset from a 4 GHz microwave tone, lowering the total\nnoise to the phase noise level. To verify its applicability we utilize the\nsetup in a microwave optomechanics experiment to investigate the effect of\ngenerator noise on the sideband cooling of a 0.5 mm silicon nitride membrane\nresonator. We observe that with our technique the rate of externally induced\ncavity heating is reduced by a factor of 3.5 and the minimum oscillator\noccupation is lowered by a factor of 2. This method broadens the field of noise\ncancellation techniques, where amplitude noise is becoming an increasingly\nimportant consideration in microwave systems as phase noise performances\nimprove over time.",
    "pdf_url": "http://arxiv.org/pdf/2506.01465v1",
    "published": "2025-06-02T09:23:36+00:00",
    "categories": [
      "physics.app-ph"
    ],
    "primary_category": "physics.app-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.01464v1",
    "title": "Tunable direct bandgap and optical response in \\ch{Mo_{1-x}W_xS2} monolayer alloys: A first-principles investigation",
    "authors": [
      "Kevin Ndang Amassa",
      "Jean-Pierre Tchapet Njafa",
      "Anne Justine Etindele",
      "Chetty Nithaya",
      "Serge Guy Nana Engo"
    ],
    "abstract": "This study presents a comprehensive first-principles investigation of the\nstructural, electronic and optical properties of monolayer \\ch{Mo_{1-x}W_xS2}\nalloys, systematically exploring the full compositional range ($x=0$ to $1$)\nusing density functional theory (DFT). We establish that these alloys are\nthermodynamically stable and maintain the characteristic 2H crystal structure\nwith minimal structural perturbation upon alloying. A key finding is the\npreservation of a direct bandgap at the $K$-point across all compositions. This\ngap exhibits continuous tunability, increasing near-monotonically from\n\\SI{1.696}{\\electronvolt} (\\ch{MoS2}) to \\SI{1.858}{\\electronvolt} (\\ch{WS2}),\na critical feature for tailoring optoelectronic devices. Electronic structure\nanalysis reveals the systematic evolution of the orbital contributions of\ntransition metal $d$ and sulfur $p$ at the edges of the band with composition.\nConsequently, the optical spectra, evaluated up to \\SI{8}{\\electronvolt}, show\na progressive blueshift in the main features of the interband transition with\nincreasing \\ch{W} content, accompanied by predictable changes in key optical\nconstants. Our comprehensive results validate the monolayer \\ch{Mo_{1-x} W_xS2}\nas an electronically versatile platform that offers fine control over\nelectronic and optical properties via alloying, making these tunable direct-gap\nsemiconductors highly promising for next-generation photodetectors, light\nemitters, and potentially flexible optoelectronic applications exploiting their\n2D nature.",
    "pdf_url": "http://arxiv.org/pdf/2506.01464v1",
    "published": "2025-06-02T09:20:39+00:00",
    "categories": [
      "cond-mat.mtrl-sci",
      "quant-ph"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2506.01463v1",
    "title": "Agentic AI and Multiagentic: Are We Reinventing the Wheel?",
    "authors": [
      "V. Botti"
    ],
    "abstract": "The terms Agentic AI and Multiagentic AI have recently gained popularity in\ndiscussions on generative artificial intelligence, often used to describe\nautonomous software agents and systems composed of such agents. However, the\nuse of these terms confuses these buzzwords with well-established concepts in\nAI literature: intelligent agents and multi-agent systems. This article offers\na critical analysis of this conceptual misuse. We review the theoretical\norigins of \"agentic\" in the social sciences (Bandura, 1986) and philosophical\nnotions of intentionality (Dennett, 1971), and then summarise foundational\nworks on intelligent agents and multi-agent systems by Wooldridge, Jennings and\nothers. We examine classic agent architectures, from simple reactive agents to\nBelief-Desire-Intention (BDI) models, and highlight key properties (autonomy,\nreactivity, proactivity, social capability) that define agency in AI. We then\ndiscuss recent developments in large language models (LLMs) and agent platforms\nbased on LLMs, including the emergence of LLM-powered AI agents and open-source\nmulti-agent orchestration frameworks. We argue that the term AI Agentic is\noften used as a buzzword for what are essentially AI agents, and AI\nMultiagentic for what are multi-agent systems. This confusion overlooks decades\nof research in the field of autonomous agents and multi-agent systems. The\narticle advocates for scientific and technological rigour and the use of\nestablished terminology from the state of the art in AI, incorporating the\nwealth of existing knowledge, including standards for multi-agent system\nplatforms, communication languages and coordination and cooperation algorithms,\nagreement technologies (automated negotiation, argumentation, virtual\norganisations, trust, reputation, etc.), into the new and promising wave of\nLLM-based AI agents, so as not to end up reinventing the wheel.",
    "pdf_url": "http://arxiv.org/pdf/2506.01463v1",
    "published": "2025-06-02T09:19:11+00:00",
    "categories": [
      "cs.MA",
      "cs.AI"
    ],
    "primary_category": "cs.MA"
  },
  {
    "id": "http://arxiv.org/abs/2506.01462v3",
    "title": "First-Spammed, First-Served: MEV Extraction on Fast-Finality Blockchains",
    "authors": [
      "Krzysztof Gogol",
      "Manvir Schneider",
      "Claudio Tessone"
    ],
    "abstract": "This research analyzes the economics of spam-based arbitrage strategies on\nfast-finality blockchains. We begin by theoretically demonstrating that,\nsplitting a profitable MEV opportunity into multiple small transactions is the\noptimal strategy for CEX-DEX arbitrageurs. We then empirically validate these\nfindings on major Ethereum rollups. To uncover the structure of reverted\ntransactions, we construct execution graphs from transaction traces and\nsystematically search them to identify DEX or router interactions and targeted\nliquidity pools. This analysis reveals that 80\\% of reverted transactions are\nswaps with approximately 50\\% targeting USDC-WETH pools on Uniswap v3/v4. These\npatterns intensified following the March 2024 Dencun upgrade, which lowered L2\ngas costs and made spam-based arbitrage economically viable.\nCounterintuitively, we find that these reverted MEV transactions rarely engage\nwith Priority Fee Auctions (PFAs), preferring to submit duplicate transactions\nrather than bid for inclusion. Moreover, reverted transactions cluster at the\nvery top of blocks on fast rollups like Arbitrum and ZKsync, indicating an\nintense latency race and revealing the fragility of fee-based ordering under\nsub-second block times.",
    "pdf_url": "http://arxiv.org/pdf/2506.01462v3",
    "published": "2025-06-02T09:18:53+00:00",
    "categories": [
      "cs.CR"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2506.01461v1",
    "title": "Contact potentials in presence of a regular finite-range interaction using dimensional regularization and the $N/D$ method",
    "authors": [
      "David R. Entem",
      "Juan Nieves",
      "Jose Antonio Oller"
    ],
    "abstract": "We solve the Lippman-Schwinger equation (LSE) with a kernel that includes a\nregular finite-range potential and additional contact terms with derivatives.\nWe employ distorted wave theory and dimensional regularization, as proposed in\nPhysics Letters B 568 (2003) 109. We analyze the spin singlet nucleon-nucleon\n$S-$wave as case of study, with the regular one-pion exchange (OPE) potential\nin this partial wave and up to ${\\cal O}(Q^6)$ (six derivatives) contact\ninteractions. We discuss in detail the renormalization of the LSE, and show\nthat the scattering amplitude solution of the LSE fulfills exact elastic\nunitarity and inherits the left-hand cut of the long-distance OPE amplitude.\nFurthermore, we proof that the LSE amplitude coincides with that obtained from\nthe exact $N/D$ calculation, with the appropriate number and typology of\nsubtractions to reproduce the effective range parameters taken as input to\nrenormalize the LSE amplitude. The generalization to higher number of\nderivatives is straightforward.",
    "pdf_url": "http://arxiv.org/pdf/2506.01461v1",
    "published": "2025-06-02T09:18:04+00:00",
    "categories": [
      "nucl-th",
      "hep-ph"
    ],
    "primary_category": "nucl-th"
  },
  {
    "id": "http://arxiv.org/abs/2506.01460v1",
    "title": "Few-step Adversarial Schrödinger Bridge for Generative Speech Enhancement",
    "authors": [
      "Seungu Han",
      "Sungho Lee",
      "Juheon Lee",
      "Kyogu Lee"
    ],
    "abstract": "Deep generative models have recently been employed for speech enhancement to\ngenerate perceptually valid clean speech on large-scale datasets. Several\ndiffusion models have been proposed, and more recently, a tractable\nSchr\\\"odinger Bridge has been introduced to transport between the clean and\nnoisy speech distributions. However, these models often suffer from an\niterative reverse process and require a large number of sampling steps -- more\nthan 50. Our investigation reveals that the performance of baseline models\nsignificantly degrades when the number of sampling steps is reduced,\nparticularly under low-SNR conditions. We propose integrating Schr\\\"odinger\nBridge with GANs to effectively mitigate this issue, achieving high-quality\noutputs on full-band datasets while substantially reducing the required\nsampling steps. Experimental results demonstrate that our proposed model\noutperforms existing baselines, even with a single inference step, in both\ndenoising and dereverberation tasks.",
    "pdf_url": "http://arxiv.org/pdf/2506.01460v1",
    "published": "2025-06-02T09:17:35+00:00",
    "categories": [
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.SD"
  },
  {
    "id": "http://arxiv.org/abs/2506.01459v2",
    "title": "The effect of measurement uncertainties on the inferred stability of planes of satellite galaxies",
    "authors": [
      "Prem Kumar",
      "Marcel S. Pawlowski",
      "Kosuke Jamie Kanehisa",
      "Pengfei Li",
      "Mariana P. Júlio",
      "Salvatore Taibi"
    ],
    "abstract": "Observations have revealed that the MW, Andromeda, Centaurus A (and\npotentially other galaxies) host spatially thin and kinematically coherent\nplanes of satellites. Such structures are highly improbable within the standard\nLCDM cosmological model, and the dynamical stability of these planes has been a\nsubject of debate for a long time. Accurately determining their stability\nrequires a thorough understanding of orbital parameters such as proper motion,\ndistance, and line-of-sight velocity, in addition to the gravitational\npotential of the host galaxy. However, many of these remain insufficiently\nconstrained, leading to significant uncertainties in any analysis. This\nresearch aims to explore the impact of measurement errors in proper motions and\ndistances of the satellite galaxies and in the adopted host halo mass on the\ninferred stability of satellite planes in Milky-Way-like potentials. Test\nsatellite galaxies orbiting a host galaxy are simulated, mock observed by\nadding various degrees and types of observational errors, and then\nbackward-integrated. Trends and correlations between the initial conditions and\nthe applied uncertainties on the inferred orbital stability of the satellite\nsystems are analyzed. Additionally, the effects of adopting incorrect\npotentials and the impact of different orbital eccentricities are considered.\nUncertainties in proper motions lead to an inferred, ostensible widening of an\nintrinsically stable satellite plane, with its width increasing linearly with\nthe adopted proper motion uncertainties. Even uncertainties on the level of\nGaia systematics strongly affect the plane's inferred past width. Moreover, the\npotential with a low halo mass showed a significant impact on the stability of\nthese planes, while the remaining two host models showed similar effects.\nUncertainties in satellite distance also contribute noticeably to the inferred,\napparent instability.",
    "pdf_url": "http://arxiv.org/pdf/2506.01459v2",
    "published": "2025-06-02T09:17:02+00:00",
    "categories": [
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2506.01458v1",
    "title": "TalTech Systems for the Interspeech 2025 ML-SUPERB 2.0 Challenge",
    "authors": [
      "Tanel Alumäe",
      "Artem Fedorchenko"
    ],
    "abstract": "This paper describes the language identification and multilingual speech\nrecognition system developed at Tallinn University of Technology for the\nInterspeech 2025 ML-SUPERB 2.0 Challenge. A hybrid language identification\nsystem is used, consisting of a pretrained language embedding model and a\nlight-weight speech recognition model with a shared encoder across languages\nand language-specific bigram language models. For speech recognition, three\nmodels are used, where only a single model is applied for each language,\ndepending on the training data availability and performance on held-out data.\nThe model set consists of a finetuned version of SeamlessM4T, MMS-1B-all with\ncustom language adapters and MMS-zeroshot. The system obtained the top overall\nscore in the challenge.",
    "pdf_url": "http://arxiv.org/pdf/2506.01458v1",
    "published": "2025-06-02T09:16:09+00:00",
    "categories": [
      "cs.CL",
      "eess.AS"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.02077v1",
    "title": "Assigning Distinct Roles to Quantized and Low-Rank Matrices Toward Optimal Weight Decomposition",
    "authors": [
      "Yoonjun Cho",
      "Soeun Kim",
      "Dongjae Jeon",
      "Kyelim Lee",
      "Beomsoo Lee",
      "Albert No"
    ],
    "abstract": "Decomposing weight matrices into quantization and low-rank components\n($\\mathbf{W} \\approx \\mathbf{Q} + \\mathbf{L}\\mathbf{R}$) is a widely used\ntechnique for compressing large language models (LLMs). Existing joint\noptimization methods iteratively alternate between quantization and low-rank\napproximation. However, these methods tend to prioritize one component at the\nexpense of the other, resulting in suboptimal decompositions that fail to\nleverage each component's unique strengths. In this work, we introduce\nOutlier-Driven Low-Rank Initialization (ODLRI), which assigns low-rank\ncomponents the specific role of capturing activation-sensitive weights. This\nstructured decomposition mitigates outliers' negative impact on quantization,\nenabling more effective balance between quantization and low-rank\napproximation. Experiments on Llama2 (7B, 13B, 70B), Llama3-8B, and Mistral-7B\ndemonstrate that incorporating ODLRI into the joint optimization framework\nconsistently reduces activation-aware error, minimizes quantization scale, and\nimproves perplexity and zero-shot accuracy in low-bit settings.",
    "pdf_url": "http://arxiv.org/pdf/2506.02077v1",
    "published": "2025-06-02T09:15:13+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.01457v1",
    "title": "On Generalised Danielewski Surfaces over fields of arbitrary characteristic",
    "authors": [
      "Debojyoti Saha"
    ],
    "abstract": "In this paper we study exponential maps ($\\mathbb{G}_a$-actions) on the\nfamily of affine two dimensional surfaces of the form $f(x)y=\\phi(x,z)$ over\narbitrary fields, describe the Makar-Limanov invariant and Derksen invariant of\nthese surfaces, give a complete characterization of isomorphisms between such\nsurfaces and display a subfamily which provides counterexamples to the\ncancellation problem.",
    "pdf_url": "http://arxiv.org/pdf/2506.01457v1",
    "published": "2025-06-02T09:14:33+00:00",
    "categories": [
      "math.AC"
    ],
    "primary_category": "math.AC"
  },
  {
    "id": "http://arxiv.org/abs/2506.01456v1",
    "title": "GenDMR: A dynamic multimodal role-swapping network for identifying risk gene phenotypes",
    "authors": [
      "Lina Qin",
      "Cheng Zhu",
      "Chuqi Zhou",
      "Yukun Huang",
      "Jiayi Zhu",
      "Ping Liang",
      "Jinju Wang",
      "Yixing Huang",
      "Cheng Luo",
      "Dezhong Yao",
      "Ying Tan"
    ],
    "abstract": "Recent studies have shown that integrating multimodal data fusion techniques\nfor imaging and genetic features is beneficial for the etiological analysis and\npredictive diagnosis of Alzheimer's disease (AD). However, there are several\ncritical flaws in current deep learning methods. Firstly, there has been\ninsufficient discussion and exploration regarding the selection and encoding of\ngenetic information. Secondly, due to the significantly superior classification\nvalue of AD imaging features compared to genetic features, many studies in\nmultimodal fusion emphasize the strengths of imaging features, actively\nmitigating the influence of weaker features, thereby diminishing the learning\nof the unique value of genetic features. To address this issue, this study\nproposes the dynamic multimodal role-swapping network (GenDMR). In GenDMR, we\ndevelop a novel approach to encode the spatial organization of single\nnucleotide polymorphisms (SNPs), enhancing the representation of their genomic\ncontext. Additionally, to adaptively quantify the disease risk of SNPs and\nbrain region, we propose a multi-instance attention module to enhance model\ninterpretability. Furthermore, we introduce a dominant modality selection\nmodule and a contrastive self-distillation module, combining them to achieve a\ndynamic teacher-student role exchange mechanism based on dominant and auxiliary\nmodalities for bidirectional co-updating of different modal data. Finally,\nGenDMR achieves state-of-the-art performance on the ADNI public dataset and\nvisualizes attention to different SNPs, focusing on confirming 12 potential\nhigh-risk genes related to AD, including the most classic APOE and recently\nhighlighted significant risk genes. This demonstrates GenDMR's interpretable\nanalytical capability in exploring AD genetic features, providing new insights\nand perspectives for the development of multimodal data fusion techniques.",
    "pdf_url": "http://arxiv.org/pdf/2506.01456v1",
    "published": "2025-06-02T09:12:53+00:00",
    "categories": [
      "q-bio.GN",
      "cs.AI",
      "cs.LG",
      "q-bio.NC"
    ],
    "primary_category": "q-bio.GN"
  },
  {
    "id": "http://arxiv.org/abs/2506.01455v1",
    "title": "Universal Preference-Score-based Pairwise Speech Quality Assessment",
    "authors": [
      "Yu-Fei Shi",
      "Yang Ai",
      "Zhen-Hua Ling"
    ],
    "abstract": "To compare the performance of two speech generation systems, one of the most\neffective approaches is estimating the preference score between their generated\nspeech. This paper proposes a novel universal preference-score-based pairwise\nspeech quality assessment (UPPSQA) model, aimed at predicting the preference\nscore between paired speech samples to determine which one has better quality.\nThe model first predicts the absolute mean opinion score (MOS) for the two\nspeech samples separately, and then aggregates them into a relative preference\nscore using a preference function. To address the scarcity of preference data,\nwe also construct a new pairwise speech dataset based on a MOS dataset for\nexperiments. Experimental results confirm that, whether in training scenarios\nwith different data types and label conditions, or in both in-domain and\nout-of-domain test scenarios, the prediction accuracy of UPP-SQA outperforms\nthat of the baseline models, demonstrating its universality.",
    "pdf_url": "http://arxiv.org/pdf/2506.01455v1",
    "published": "2025-06-02T09:12:50+00:00",
    "categories": [
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.SD"
  },
  {
    "id": "http://arxiv.org/abs/2506.01454v1",
    "title": "DiffuseSlide: Training-Free High Frame Rate Video Generation Diffusion",
    "authors": [
      "Geunmin Hwang",
      "Hyun-kyu Ko",
      "Younghyun Kim",
      "Seungryong Lee",
      "Eunbyung Park"
    ],
    "abstract": "Recent advancements in diffusion models have revolutionized video generation,\nenabling the creation of high-quality, temporally consistent videos. However,\ngenerating high frame-rate (FPS) videos remains a significant challenge due to\nissues such as flickering and degradation in long sequences, particularly in\nfast-motion scenarios. Existing methods often suffer from computational\ninefficiencies and limitations in maintaining video quality over extended\nframes. In this paper, we present a novel, training-free approach for high FPS\nvideo generation using pre-trained diffusion models. Our method, DiffuseSlide,\nintroduces a new pipeline that leverages key frames from low FPS videos and\napplies innovative techniques, including noise re-injection and sliding window\nlatent denoising, to achieve smooth, consistent video outputs without the need\nfor additional fine-tuning. Through extensive experiments, we demonstrate that\nour approach significantly improves video quality, offering enhanced temporal\ncoherence and spatial fidelity. The proposed method is not only computationally\nefficient but also adaptable to various video generation tasks, making it ideal\nfor applications such as virtual reality, video games, and high-quality content\ncreation.",
    "pdf_url": "http://arxiv.org/pdf/2506.01454v1",
    "published": "2025-06-02T09:12:41+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.01453v1",
    "title": "From Initial Data to Boundary Layers: Neural Networks for Nonlinear Hyperbolic Conservation Laws",
    "authors": [
      "Igor Ciril",
      "Khalil Haddaoui",
      "Yohann Tendero"
    ],
    "abstract": "We address the approximation of entropy solutions to initial-boundary value\nproblems for nonlinear strictly hyperbolic conservation laws using neural\nnetworks. A general and systematic framework is introduced for the design of\nefficient and reliable learning algorithms, combining fast convergence during\ntraining with accurate predictions. The methodology is assessed through a\nseries of one-dimensional scalar test cases, highlighting its potential\napplicability to more complex industrial scenarios.",
    "pdf_url": "http://arxiv.org/pdf/2506.01453v1",
    "published": "2025-06-02T09:12:13+00:00",
    "categories": [
      "math.AP",
      "cs.AI"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2506.01452v2",
    "title": "e-GAI: e-value-based Generalized $α$-Investing for Online False Discovery Rate Control",
    "authors": [
      "Yifan Zhang",
      "Zijian Wei",
      "Haojie Ren",
      "Changliang Zou"
    ],
    "abstract": "Online multiple hypothesis testing has attracted a lot of attention in many\napplications, e.g., anomaly status detection and stock market price monitoring.\nThe state-of-the-art generalized $\\alpha$-investing (GAI) algorithms can\ncontrol online false discovery rate (FDR) on p-values only under specific\ndependence structures, a situation that rarely occurs in practice. The e-LOND\nalgorithm (Xu & Ramdas, 2024) utilizes e-values to achieve online FDR control\nunder arbitrary dependence but suffers from a significant loss in power as\ntesting levels are derived from pre-specified descent sequences. To address\nthese limitations, we propose a novel framework on valid e-values named e-GAI.\nThe proposed e-GAI can ensure provable online FDR control under more general\ndependency conditions while improving the power by dynamically allocating the\ntesting levels. These testing levels are updated not only by relying on both\nthe number of previous rejections and the prior costs, but also, differing from\nthe GAI framework, by assigning less $\\alpha$-wealth for each rejection from a\nrisk aversion perspective. Within the e-GAI framework, we introduce two new\nonline FDR procedures, e-LORD and e-SAFFRON, and provide strategies for the\nlong-term performance to address the issue of $\\alpha$-death, a common\nphenomenon within the GAI framework. Furthermore, we demonstrate that e-GAI can\nbe generalized to conditionally super-uniform p-values. Both simulated and real\ndata experiments demonstrate the advantages of both e-LORD and e-SAFFRON in FDR\ncontrol and power.",
    "pdf_url": "http://arxiv.org/pdf/2506.01452v2",
    "published": "2025-06-02T09:08:52+00:00",
    "categories": [
      "stat.ME"
    ],
    "primary_category": "stat.ME"
  },
  {
    "id": "http://arxiv.org/abs/2506.01451v1",
    "title": "Building Entity Association Mining Framework for Knowledge Discovery",
    "authors": [
      "Anshika Rawal",
      "Abhijeet Kumar",
      "Mridul Mishra"
    ],
    "abstract": "Extracting useful signals or pattern to support important business decisions\nfor example analyzing investment product traction and discovering customer\npreference, risk monitoring etc. from unstructured text is a challenging task.\nCapturing interaction of entities or concepts and association mining is a\ncrucial component in text mining, enabling information extraction and reasoning\nover and knowledge discovery from text. Furthermore, it can be used to enrich\nor filter knowledge graphs to guide exploration processes, descriptive\nanalytics and uncover hidden stories in the text. In this paper, we introduce a\ndomain independent pipeline i.e., generalized framework to enable document\nfiltering, entity extraction using various sources (or techniques) as plug-ins\nand association mining to build any text mining business use-case and\nquantitatively define a scoring metric for ranking purpose. The proposed\nframework has three major components a) Document filtering: filtering\ndocuments/text of interest from massive amount of texts b) Configurable entity\nextraction pipeline: include entity extraction techniques i.e., i) DBpedia\nSpotlight, ii) Spacy NER, iii) Custom Entity Matcher, iv) Phrase extraction (or\ndictionary) based c) Association Relationship Mining: To generates\nco-occurrence graph to analyse potential relationships among entities,\nconcepts. Further, co-occurrence count based frequency statistics provide a\nholistic window to observe association trends or buzz rate in specific business\ncontext. The paper demonstrates the usage of framework as fundamental building\nbox in two financial use-cases namely brand product discovery and vendor risk\nmonitoring. We aim that such framework will remove duplicated effort, minimize\nthe development effort, and encourage reusability and rapid prototyping in\nassociation mining business applications for institutions.",
    "pdf_url": "http://arxiv.org/pdf/2506.01451v1",
    "published": "2025-06-02T09:08:38+00:00",
    "categories": [
      "cs.CL",
      "cs.IR",
      "I.2.7"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.01450v1",
    "title": "ShaTS: A Shapley-based Explainability Method for Time Series Artificial Intelligence Models applied to Anomaly Detection in Industrial Internet of Things",
    "authors": [
      "Manuel Franco de la Peña",
      "Ángel Luis Perales Gómez",
      "Lorenzo Fernández Maimó"
    ],
    "abstract": "Industrial Internet of Things environments increasingly rely on advanced\nAnomaly Detection and explanation techniques to rapidly detect and mitigate\ncyberincidents, thereby ensuring operational safety. The sequential nature of\ndata collected from these environments has enabled improvements in Anomaly\nDetection using Machine Learning and Deep Learning models by processing time\nwindows rather than treating the data as tabular. However, conventional\nexplanation methods often neglect this temporal structure, leading to imprecise\nor less actionable explanations. This work presents ShaTS (Shapley values for\nTime Series models), which is a model-agnostic explainable Artificial\nIntelligence method designed to enhance the precision of Shapley value\nexplanations for time series models. ShaTS addresses the shortcomings of\ntraditional approaches by incorporating an a priori feature grouping strategy\nthat preserves temporal dependencies and produces both coherent and actionable\ninsights. Experiments conducted on the SWaT dataset demonstrate that ShaTS\naccurately identifies critical time instants, precisely pinpoints the sensors,\nactuators, and processes affected by anomalies, and outperforms SHAP in terms\nof both explainability and resource efficiency, fulfilling the real-time\nrequirements of industrial environments.",
    "pdf_url": "http://arxiv.org/pdf/2506.01450v1",
    "published": "2025-06-02T09:07:27+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.01449v1",
    "title": "Machine Learning-Guided Discovery of Temperature-Induced Solid-Solid Phase Transitions in Inorganic Materials",
    "authors": [
      "Cibrán López",
      "Joshua Ojih",
      "Ming Hu",
      "Josep Lluis Tamarit",
      "Edgardo Saucedo",
      "Claudio Cazorla"
    ],
    "abstract": "Predicting solid-solid phase transitions remains a long-standing challenge in\nmaterials science. Solid-solid transformations underpin a wide range of\nfunctional properties critical to energy conversion, information storage, and\nthermal management technologies. However, their prediction is computationally\nintensive due to the need to account for finite-temperature effects. Here, we\npresent an uncertainty-aware machine-learning-guided framework for\nhigh-throughput prediction of temperature-induced polymorphic phase transitions\nin inorganic crystals. By combining density functional theory calculations with\ngraph-based neural networks trained to estimate vibrational free energies, we\nscreened a curated dataset of approximately 50,000 inorganic compounds and\nidentified over 2,000 potential solid-solid transitions within the\ntechnologically relevant temperature interval 300-600 K. Among our key\nfindings, we uncover numerous phase transitions exhibiting large entropy\nchanges (> 300 J K$^{-1}$ kg$^{-1}$), many of which occur near room temperature\nhence offering strong potential for solid-state cooling applications. We also\nidentify $21$ compounds that exhibit substantial relative changes in lattice\nthermal conductivity (20-70%) across a phase transition, highlighting them as\npromising thermal switching materials. Validation against experimental\nobservations and first-principles calculations supports the robustness and\npredictive power of our approach. Overall, this work establishes a scalable\nroute to discover functional phase-change materials under realistic thermal\nconditions, and lays the foundation for future high-throughput studies\nleveraging generative models and expanding open-access materials databases.",
    "pdf_url": "http://arxiv.org/pdf/2506.01449v1",
    "published": "2025-06-02T09:07:13+00:00",
    "categories": [
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2506.01448v1",
    "title": "Enhanced coherence and layer-selective charge order in a trilayer cuprate superconductor",
    "authors": [
      "S. Smit",
      "M. Bluschke",
      "P. Moen",
      "N. Heinsdorf",
      "E. Zavatti",
      "G. Bellomia",
      "S. Giuli",
      "S. K. Y. Dufresne",
      "C. T. Suen",
      "V. Zimmermann",
      "C. Au-Yeung",
      "S. Zhdanovich",
      "J. I. Dadap",
      "M. Zonno",
      "S. Gorovikov",
      "H. Lee",
      "C-T. Kuo",
      "J-S. Lee",
      "D. Song",
      "S. Ishida",
      "H. Eisaki",
      "B. Keimer",
      "M. Michiardi",
      "I. S. Elfimov",
      "G. Levy",
      "D. J. Jones",
      "M. Capone",
      "A. Damascelli"
    ],
    "abstract": "Trilayer cuprates hold the record for the highest superconducting critical\ntemperatures ($T_{\\text{c}}$), yet the underlying mechanism remains elusive.\nUsing time- and angle-resolved photoemission spectroscopy (tr-ARPES), we\nuncover a striking interplay between charge order, superconducting gap\nmagnitude, and quasiparticle coherence in\nBi$_2$Sr$_2$Ca$_2$Cu$_3$O$_{10+\\delta}$ (Bi2223). This constitutes ARPES-based\nevidence of charge order on the inner CuO$_2$ plane, as confirmed via resonant\nx-ray scattering (RXS); in addition, the same inner plane hosts a\nsuperconducting gap significantly larger than that of the overdoped outer\nplanes, firmly establishing it as underdoped. Unexpectedly, despite its\nunderdoped nature, the inner plane also exhibits an exceptional degree of\nquasiparticle coherence; suppressing charge-order fluctuations further enhances\nthis, making it comparable to that of the overdoped outer planes at elevated\nelectronic temperatures. These findings, supported by complementary three-layer\nsingle-band Hubbard calculations, reveal a unique interlayer mechanism in which\nboth pairing strength and phase coherence are optimized when interfacing planes\nwith distinct hole concentrations, providing new microscopic insight into the\nrecord $T_{\\text{c}}$ of Bi2223.",
    "pdf_url": "http://arxiv.org/pdf/2506.01448v1",
    "published": "2025-06-02T09:07:12+00:00",
    "categories": [
      "cond-mat.str-el"
    ],
    "primary_category": "cond-mat.str-el"
  },
  {
    "id": "http://arxiv.org/abs/2506.01447v3",
    "title": "Doppler Pulse Amplification",
    "authors": [
      "Klaas De Kinder",
      "Amir Bahrami",
      "Christophe Caloz"
    ],
    "abstract": "The ability to amplify ultrashort pulses has revolutionized modern laser\nscience, driving advances in various fields such as ultrafast optics and\nspectroscopy. A pivotal development in this field is chirped pulse\namplification (CPA), which stretches, amplifies and recompresses ultrashort\noptical pulses using dispersive elements to overcome amplification limits.\nHowever, CPA faces limitations due to gain narrowing, restricting the final\npulse duration. Here, we propose Doppler pulse amplification (DoPA), a novel\napproach for amplifying ultrashort pulses. While DoPA shares similarities with\nCPA in that it also stretches, amplifies and recompresses pulses, it differs in\nhow it achieves this temporal compansion. Unlike CPA, DoPA exploits Doppler\nshifts induced by space-time modulated interfaces through a space-time wedge\nimplementation without chirping. We show that DoPA dynamically shifts the pulse\nspectrum, effectively mitigating the gain narrowing issue of CPA. Additionally,\nwe show that DoPA enables more compact amplification systems via a space-time\nFresnel implementation. This approach may pave the way for more efficient,\nhigh-intensity laser systems and expand the potential for applications in both\nlaboratory research and practical environments.",
    "pdf_url": "http://arxiv.org/pdf/2506.01447v3",
    "published": "2025-06-02T09:05:36+00:00",
    "categories": [
      "physics.optics"
    ],
    "primary_category": "physics.optics"
  },
  {
    "id": "http://arxiv.org/abs/2506.02076v1",
    "title": "A meaningful prediction of functional decline in amyotrophic lateral sclerosis based on multi-event survival analysis",
    "authors": [
      "Christian Marius Lillelund",
      "Sanjay Kalra",
      "Russell Greiner"
    ],
    "abstract": "Amyotrophic lateral sclerosis (ALS) is a degenerative disorder of motor\nneurons that causes progressive paralysis in patients. Current treatment\noptions aim to prolong survival and improve quality of life; however, due to\nthe heterogeneity of the disease, it is often difficult to determine the\noptimal time for potential therapies or medical interventions. In this study,\nwe propose a novel method to predict the time until a patient with ALS\nexperiences significant functional impairment (ALSFRS-R<=2) with respect to\nfive common functions: speaking, swallowing, handwriting, walking and\nbreathing. We formulate this task as a multi-event survival problem and\nvalidate our approach in the PRO-ACT dataset by training five covariate-based\nsurvival models to estimate the probability of an event over a 500-day period\nafter a baseline visit. We then predict five event-specific individual survival\ndistributions (ISDs) for each patient, each providing an interpretable and\nmeaningful estimate of when that event will likely take place in the future.\nThe results show that covariate-based models are superior to the Kaplan-Meier\nestimator at predicting time-to-event outcomes. Additionally, our method\nenables practitioners to make individual counterfactual predictions, where\ncertain features (covariates) can be changed to see their effect on the\npredicted outcome. In this regard, we find that Riluzole has little to no\nimpact on predicted functional decline. However, for patients with bulbar-onset\nALS, our method predicts considerably shorter counterfactual time-to-event\nestimates for tasks related to speech and swallowing compared to limb-onset\nALS. The proposed method can be applied to current clinical examination data to\nassess the risk of functional decline and thus allow more personalized\ntreatment planning.",
    "pdf_url": "http://arxiv.org/pdf/2506.02076v1",
    "published": "2025-06-02T09:04:59+00:00",
    "categories": [
      "q-bio.QM",
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "q-bio.QM"
  },
  {
    "id": "http://arxiv.org/abs/2506.01446v1",
    "title": "Policy as Code, Policy as Type",
    "authors": [
      "Matthew D. Fuchs"
    ],
    "abstract": "Policies are designed to distinguish between correct and incorrect actions;\nthey are types. But badly typed actions may cause not compile errors, but\nfinancial and reputational harm We demonstrate how even the most complex ABAC\npolicies can be expressed as types in dependently typed languages such as Agda\nand Lean, providing a single framework to express, analyze, and implement\npolicies. We then go head-to-head with Rego, the popular and powerful\nopen-source ABAC policy language. We show the superior safety that comes with a\npowerful type system and built-in proof assistant. In passing, we discuss\nvarious access control models, sketch how to integrate in a future when\nattributes are distributed and signed (as discussed at the W3C), and show how\npolicies can be communicated using just the syntax of the language. Our\nexamples are in Agda.",
    "pdf_url": "http://arxiv.org/pdf/2506.01446v1",
    "published": "2025-06-02T09:04:48+00:00",
    "categories": [
      "cs.CR",
      "cs.PL",
      "D.4.6; K.6.5; D.3.2; F.3.1; D.2.4"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2506.01445v1",
    "title": "A Novel Context-Adaptive Fusion of Shadow and Highlight Regions for Efficient Sonar Image Classification",
    "authors": [
      "Kamal Basha S",
      "Anukul Kiran B",
      "Athira Nambiar",
      "Suresh Rajendran"
    ],
    "abstract": "Sonar imaging is fundamental to underwater exploration, with critical\napplications in defense, navigation, and marine research. Shadow regions, in\nparticular, provide essential cues for object detection and classification, yet\nexisting studies primarily focus on highlight-based analysis, leaving\nshadow-based classification underexplored. To bridge this gap, we propose a\nContext-adaptive sonar image classification framework that leverages advanced\nimage processing techniques to extract and integrate discriminative shadow and\nhighlight features. Our framework introduces a novel shadow-specific classifier\nand adaptive shadow segmentation, enabling effective classification based on\nthe dominant region. This approach ensures optimal feature representation,\nimproving robustness against noise and occlusions. In addition, we introduce a\nRegion-aware denoising model that enhances sonar image quality by preserving\ncritical structural details while suppressing noise. This model incorporates an\nexplainability-driven optimization strategy, ensuring that denoising is guided\nby feature importance, thereby improving interpretability and classification\nreliability. Furthermore, we present S3Simulator+, an extended dataset\nincorporating naval mine scenarios with physics-informed noise specifically\ntailored for the underwater sonar domain, fostering the development of robust\nAI models. By combining novel classification strategies with an enhanced\ndataset, our work addresses key challenges in sonar image analysis,\ncontributing\n  to the advancement of autonomous underwater perception.",
    "pdf_url": "http://arxiv.org/pdf/2506.01445v1",
    "published": "2025-06-02T09:01:46+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.01444v2",
    "title": "Variance-Based Defense Against Blended Backdoor Attacks",
    "authors": [
      "Sujeevan Aseervatham",
      "Achraf Kerzazi",
      "Younès Bennani"
    ],
    "abstract": "Backdoor attacks represent a subtle yet effective class of cyberattacks\ntargeting AI models, primarily due to their stealthy nature. The model behaves\nnormally on clean data but exhibits malicious behavior only when the attacker\nembeds a specific trigger into the input. This attack is performed during the\ntraining phase, where the adversary corrupts a small subset of the training\ndata by embedding a pattern and modifying the labels to a chosen target. The\nobjective is to make the model associate the pattern with the target label\nwhile maintaining normal performance on unaltered data. Several defense\nmechanisms have been proposed to sanitize training data-sets. However, these\nmethods often rely on the availability of a clean dataset to compute\nstatistical anomalies, which may not always be feasible in real-world scenarios\nwhere datasets can be unavailable or compromised. To address this limitation,\nwe propose a novel defense method that trains a model on the given dataset,\ndetects poisoned classes, and extracts the critical part of the attack trigger\nbefore identifying the poisoned instances. This approach enhances\nexplainability by explicitly revealing the harmful part of the trigger. The\neffectiveness of our method is demonstrated through experimental evaluations on\nwell-known image datasets and comparative analysis against three\nstate-of-the-art algorithms: SCAn, ABL, and AGPD.",
    "pdf_url": "http://arxiv.org/pdf/2506.01444v2",
    "published": "2025-06-02T09:01:35+00:00",
    "categories": [
      "cs.LG",
      "cs.CV"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.01443v1",
    "title": "MS-RAFT-3D: A Multi-Scale Architecture for Recurrent Image-Based Scene Flow",
    "authors": [
      "Jakob Schmid",
      "Azin Jahedi",
      "Noah Berenguel Senn",
      "Andrés Bruhn"
    ],
    "abstract": "Although multi-scale concepts have recently proven useful for recurrent\nnetwork architectures in the field of optical flow and stereo, they have not\nbeen considered for image-based scene flow so far. Hence, based on a\nsingle-scale recurrent scene flow backbone, we develop a multi-scale approach\nthat generalizes successful hierarchical ideas from optical flow to image-based\nscene flow. By considering suitable concepts for the feature and the context\nencoder, the overall coarse-to-fine framework and the training loss, we succeed\nto design a scene flow approach that outperforms the current state of the art\non KITTI and Spring by 8.7%(3.89 vs. 4.26) and 65.8% (9.13 vs. 26.71),\nrespectively. Our code is available at\nhttps://github.com/cv-stuttgart/MS-RAFT-3D.",
    "pdf_url": "http://arxiv.org/pdf/2506.01443v1",
    "published": "2025-06-02T08:59:05+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.01442v1",
    "title": "Agentic Episodic Control",
    "authors": [
      "Xidong Yang",
      "Wenhao Li",
      "Junjie Sheng",
      "Chuyun Shen",
      "Yun Hua",
      "Xiangfeng Wang"
    ],
    "abstract": "Reinforcement learning (RL) has driven breakthroughs in AI, from game-play to\nscientific discovery and AI alignment. However, its broader applicability\nremains limited by challenges such as low data efficiency and poor\ngeneralizability. Recent advances suggest that large language models, with\ntheir rich world knowledge and reasoning capabilities, could complement RL by\nenabling semantic state modeling and task-agnostic planning. In this work, we\npropose the Agentic Episodic Control (AEC), a novel architecture that\nintegrates RL with LLMs to enhance decision-making. The AEC can leverage a\nlarge language model (LLM) to map the observations into language-grounded\nembeddings, which further can be stored in an episodic memory for rapid\nretrieval of high-value experiences. Simultaneously, a World-Graph working\nmemory module is utilized to capture structured environmental dynamics in order\nto enhance relational reasoning. Furthermore, a lightweight critical state\ndetector dynamically arbitrates between the episodic memory recall and the\nworld-model-guided exploration. On the whole, by combining the trial-and-error\nlearning scheme with LLM-derived semantic priors, the proposed AEC can improve\nboth data efficiency and generalizability in reinforcement learning. In\nexperiments on BabyAI-Text benchmark tasks, AEC demonstrates substantial\nimprovements over existing baselines, especially on complex and generalization\ntasks like FindObj, where it outperforms the best baseline by up to 76%. The\nproposed AEC framework bridges the strengths of numeric reinforcement learning\nand symbolic reasoning, which provides a pathway toward more adaptable and\nsample-efficient agents.",
    "pdf_url": "http://arxiv.org/pdf/2506.01442v1",
    "published": "2025-06-02T08:57:37+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2506.01441v1",
    "title": "Semantic Palette-Guided Color Propagation",
    "authors": [
      "Zi-Yu Zhang",
      "Bing-Feng Seng",
      "Ya-Feng Du",
      "Kang Li",
      "Zhe-Cheng Wang",
      "Zheng-Jun Du"
    ],
    "abstract": "Color propagation aims to extend local color edits to similar regions across\nthe input image. Conventional approaches often rely on low-level visual cues\nsuch as color, texture, or lightness to measure pixel similarity, making it\ndifficult to achieve content-aware color propagation. While some recent\napproaches attempt to introduce semantic information into color editing, but\noften lead to unnatural, global color change in color adjustments. To overcome\nthese limitations, we present a semantic palette-guided approach for color\npropagation. We first extract a semantic palette from an input image. Then, we\nsolve an edited palette by minimizing a well-designed energy function based on\nuser edits. Finally, local edits are accurately propagated to regions that\nshare similar semantics via the solved palette. Our approach enables efficient\nyet accurate pixel-level color editing and ensures that local color changes are\npropagated in a content-aware manner. Extensive experiments demonstrated the\neffectiveness of our method.",
    "pdf_url": "http://arxiv.org/pdf/2506.01441v1",
    "published": "2025-06-02T08:57:34+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.01440v1",
    "title": "Point Jacobi-type preconditioning and parameter tuning for Calderon-preconditioned Burton-Miller method in transmission problems",
    "authors": [
      "Keigo Tomoyasu",
      "Hiroshi Isakari"
    ],
    "abstract": "It was recently demonstrated that the boundary element method based on the\nBurton-Miller formulation (BM-BEM), widely used for solving exterior problems,\ncan be adapted to solve transmission problems efficiently. This approach\nutilises Calderon's identities to improve the spectral properties of the\nunderlying integral operator. Consequently, most eigenvalues of the squared BEM\ncoefficient matrix, i.e. the collocation-discretised version of the operator,\ncluster at a few points in the complex plane. When these clustering points are\nclosely packed, the resulting linear system is well-conditioned and can be\nsolved efficiently using the generalised minimal residual method with only a\nfew iterations. However, when multiple materials with significantly different\nmaterial constants are involved, some eigenvalues become separated,\ndeteriorating the conditioning. To address this, we propose an enhanced\nCalderon-preconditioned BM-BEM with two strategies. First, we apply a\npreconditioning scheme inspired by the point Jacobi method. Second, we tune the\nBurton-Miller parameters to minimise the condition number of the coefficient\nmatrix. Both strategies leverage a newly derived analytical expression for the\neigenvalue clustering points of the relevant operator. Numerical experiments\ndemonstrate that the proposed method, combining both strategies, is\nparticularly effective for solving scattering problems involving composite\npenetrable materials with high contrast in material properties.",
    "pdf_url": "http://arxiv.org/pdf/2506.01440v1",
    "published": "2025-06-02T08:53:52+00:00",
    "categories": [
      "math.NA",
      "cs.NA"
    ],
    "primary_category": "math.NA"
  },
  {
    "id": "http://arxiv.org/abs/2508.00831v2",
    "title": "EngiBench: A Framework for Data-Driven Engineering Design Research",
    "authors": [
      "Florian Felten",
      "Gabriel Apaza",
      "Gerhard Bräunlich",
      "Cashen Diniz",
      "Xuliang Dong",
      "Arthur Drake",
      "Milad Habibi",
      "Nathaniel J. Hoffman",
      "Matthew Keeler",
      "Soheyl Massoudi",
      "Francis G. VanGessel",
      "Mark Fuge"
    ],
    "abstract": "Engineering design optimization seeks to automatically determine the shapes,\ntopologies, or parameters of components that maximize performance under given\nconditions. This process often depends on physics-based simulations, which are\ndifficult to install, computationally expensive, and require domain-specific\nexpertise. To mitigate these challenges, we introduce EngiBench, the first\nopen-source library and datasets spanning diverse domains for data-driven\nengineering design. EngiBench provides a unified API and a curated set of\nbenchmarks -- covering aeronautics, heat conduction, photonics, and more --\nthat enable fair, reproducible comparisons of optimization and machine learning\nalgorithms, such as generative or surrogate models. We also release EngiOpt, a\ncompanion library offering a collection of such algorithms compatible with the\nEngiBench interface. Both libraries are modular, letting users plug in novel\nalgorithms or problems, automate end-to-end experiment workflows, and leverage\nbuilt-in utilities for visualization, dataset generation, feasibility checks,\nand performance analysis. We demonstrate their versatility through experiments\ncomparing state-of-the-art techniques across multiple engineering design\nproblems, an undertaking that was previously prohibitively time-consuming to\nperform. Finally, we show that these problems pose significant challenges for\nstandard machine learning methods due to highly sensitive and constrained\ndesign manifolds.",
    "pdf_url": "http://arxiv.org/pdf/2508.00831v2",
    "published": "2025-06-02T08:53:02+00:00",
    "categories": [
      "cs.CE",
      "cs.LG",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.CE"
  },
  {
    "id": "http://arxiv.org/abs/2506.01439v1",
    "title": "Whale: Large-Scale multilingual ASR model with w2v-BERT and E-Branchformer with large speech data",
    "authors": [
      "Yosuke Kashiwagi",
      "Hayato Futami",
      "Emiru Tsunoo",
      "Satoshi Asakawa"
    ],
    "abstract": "This paper reports on the development of a large-scale speech recognition\nmodel, Whale. Similar to models such as Whisper and OWSM, Whale leverages both\na large model size and a diverse, extensive dataset. Whale's architecture\nintegrates w2v-BERT self-supervised model, an encoder-decoder backbone built on\nE-Branchformer, and a joint CTC-attention decoding strategy. The training\ncorpus comprises varied speech data, of not only public corpora but also\nin-house data, thereby enhancing the model's robustness to different speaking\nstyles and acoustic conditions. Through evaluations on multiple benchmarks,\nWhale achieved comparable performance to existing models. In particular, it\nachieves a word error rate of 2.4% on the Librispeech test-clean set and a\ncharacter error rate of 3.4% on the CSJ eval3 set, outperforming Whisper\nlarge-v3 and OWSM v3.1.",
    "pdf_url": "http://arxiv.org/pdf/2506.01439v1",
    "published": "2025-06-02T08:52:50+00:00",
    "categories": [
      "cs.CL",
      "eess.AS"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.01438v2",
    "title": "Distinguishing Autonomous AI Agents from Collaborative Agentic Systems: A Comprehensive Framework for Understanding Modern Intelligent Architectures",
    "authors": [
      "Prashik Buddhaghosh Bansod"
    ],
    "abstract": "The emergence of large language models has catalyzed two distinct yet\ninterconnected paradigms in artificial intelligence: standalone AI Agents and\ncollaborative Agentic AI ecosystems. This comprehensive study establishes a\ndefinitive framework for distinguishing these architectures through systematic\nanalysis of their operational principles, structural compositions, and\ndeployment methodologies. We characterize AI Agents as specialized,\ntool-enhanced systems leveraging foundation models for targeted automation\nwithin constrained environments. Conversely, Agentic AI represents\nsophisticated multi-entity frameworks where distributed agents exhibit emergent\ncollective intelligence through coordinated interaction protocols. Our\ninvestigation traces the evolutionary trajectory from traditional rule-based\nsystems through generative AI foundations to contemporary agent architectures.\nWe present detailed architectural comparisons examining planning mechanisms,\nmemory systems, coordination protocols, and decision-making processes. The\nstudy categorizes application landscapes, contrasting single-agent\nimplementations in customer service and content management with multi-agent\ndeployments in research automation and complex decision support. We identify\ncritical challenges including reliability issues, coordination complexities,\nand scalability constraints, while proposing innovative solutions through\nenhanced reasoning frameworks, robust memory architectures, and improved\ncoordination mechanisms. This framework provides essential guidance for\npractitioners selecting appropriate agentic approaches and establishes\nfoundational principles for next-generation intelligent system development.",
    "pdf_url": "http://arxiv.org/pdf/2506.01438v2",
    "published": "2025-06-02T08:52:23+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2506.01437v1",
    "title": "Black hole supercolliders",
    "authors": [
      "Andrew Mummery",
      "Joseph Silk"
    ],
    "abstract": "We show that collisions between particles free falling from infinity and a\ndisk of material plunging off the retrograde innermost stable circular orbit of\na near-extremal Kerr black hole is the unique astronomically natural way in\nwhich to create a gravitational particle accelerator with center of mass\nenergies at the $10$'s to $100$'s of teraelectronvolt range, in other words a\nsupercollider.",
    "pdf_url": "http://arxiv.org/pdf/2506.01437v1",
    "published": "2025-06-02T08:51:54+00:00",
    "categories": [
      "gr-qc"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2506.01436v1",
    "title": "Reply to the Comment on \"Shell-Shaped Quantum Droplet in a Three-Component Ultracold Bose Gas\"",
    "authors": [
      "Yinfeng Ma",
      "Xiaoling Cui"
    ],
    "abstract": "In our work (Phys. Rev. Lett. 134, 043402 (2025)), we have proposed to\nrealize a shell-shaped BEC with self-bound character in a three-component\n($1,2,3$) Bose gas, where $(2,3)$ and $(1,2)$ both form quantum droplets and\nmeanwhile are linked as core-shell structure. It was then commented in\n2505.16554 that such structure is unstable against decaying to a ``dimer\"\nconfiguration with lower energy, and moreover, it is ``most likely\" impossible\nto be realized after releasing from the trap. In contrast to these claims, our\nreply shows that the core-shell and dimer states are energetically degenerate\nin the thermodynamic limit, and more importantly, the core-shell structure is\nrobustly stable against external perturbations and can be realized practically\nfollowing the trap-release scheme.",
    "pdf_url": "http://arxiv.org/pdf/2506.01436v1",
    "published": "2025-06-02T08:50:56+00:00",
    "categories": [
      "cond-mat.quant-gas"
    ],
    "primary_category": "cond-mat.quant-gas"
  },
  {
    "id": "http://arxiv.org/abs/2506.01435v1",
    "title": "Redundancy, Isotropy, and Intrinsic Dimensionality of Prompt-based Text Embeddings",
    "authors": [
      "Hayato Tsukagoshi",
      "Ryohei Sasano"
    ],
    "abstract": "Prompt-based text embedding models, which generate task-specific embeddings\nupon receiving tailored prompts, have recently demonstrated remarkable\nperformance. However, their resulting embeddings often have thousands of\ndimensions, leading to high storage costs and increased computational costs of\nembedding-based operations. In this paper, we investigate how post-hoc\ndimensionality reduction applied to the embeddings affects the performance of\nvarious tasks that leverage these embeddings, specifically classification,\nclustering, retrieval, and semantic textual similarity (STS) tasks. Our\nexperiments show that even a naive dimensionality reduction, which keeps only\nthe first 25% of the dimensions of the embeddings, results in a very slight\nperformance degradation, indicating that these embeddings are highly redundant.\nNotably, for classification and clustering, even when embeddings are reduced to\nless than 0.5% of the original dimensionality the performance degradation is\nvery small. To quantitatively analyze this redundancy, we perform an analysis\nbased on the intrinsic dimensionality and isotropy of the embeddings. Our\nanalysis reveals that embeddings for classification and clustering, which are\nconsidered to have very high dimensional redundancy, exhibit lower intrinsic\ndimensionality and less isotropy compared with those for retrieval and STS.",
    "pdf_url": "http://arxiv.org/pdf/2506.01435v1",
    "published": "2025-06-02T08:50:38+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.01434v2",
    "title": "General monotone formula for homogeneous $k$-Hessian equation in the exterior domain and its applications",
    "authors": [
      "Jiabin Yin",
      "Xingjian Zhou"
    ],
    "abstract": "In this paper, we deal with an overdetermined problem for the $k$-Hessian\nequation ($1\\leq k<\\frac n2$) in the exterior domain and prove the\ncorresponding ball characterizations. Since that Weinberger type approach seems\nto fail to solve the problem, we give a new perspective to solve exterior\noverdetermined problem by combining two integral identities and geometric\ninequalities inspired by Brandolini-Nitsch-Salani's results \\cite{BNS}.\nMeanwhile, we establish general monotone formulas to derive geometric\ninequalities related to $k$-admissible solution $u$ in $\\mathbb\nR^n\\setminus\\Omega$, where $\\Omega$ is smooth, $k$-convex and star-shaped\ndomain, which constructed by Ma-Zhang\\cite{MZ} and Xiao\\cite{xiao}.",
    "pdf_url": "http://arxiv.org/pdf/2506.01434v2",
    "published": "2025-06-02T08:50:23+00:00",
    "categories": [
      "math.AP",
      "math.DG"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2506.06350v1",
    "title": "An analysis of capital market through the lens of integral transforms: exploring efficient markets and information asymmetry",
    "authors": [
      "Kiran Sharma",
      "Abhijit Dutta",
      "Rupak Mukherjee"
    ],
    "abstract": "Post Modigliani and Miller (1958), the concept of usage of arbitrage created\na permanent mark on the discourses of financial framework. The arbitrage\nprocess is largely based on information dissemination amongst the stakeholders\noperating in the financial market. The advent of the efficient market\nHypothesis draws close to the M&M hypothesis. Giving importance to the\narbitrage process, which effects the price discovery in the stock market. This\ndivided the market as random and efficient cohort system. The focus was on\nwhich information forms a key factor in deciding the price formation in the\nmarket. However, the conventional techniques of analysis do not permit the\nprice cycles to be interpreted beyond its singular wave-like cyclical movement.\nThe apparent cyclic measurement is not coherent as the technical analysis does\nnot give sustained result. Hence adaption of theories and computation from\nmathematical methods of physics ensures that these cycles are decomposed and\nthe effect of the broken-down cycles is interpreted to understand the overall\neffect of information on price formation and discovery. In order to break the\ncycle this paper uses spectrum analysis to decompose and understand the\nabove-said phenomenon in determining the price behavior in National Stock\nExchange of India (NSE).",
    "pdf_url": "http://arxiv.org/pdf/2506.06350v1",
    "published": "2025-06-02T08:46:36+00:00",
    "categories": [
      "q-fin.ST",
      "math.SP",
      "physics.comp-ph"
    ],
    "primary_category": "q-fin.ST"
  },
  {
    "id": "http://arxiv.org/abs/2506.01433v1",
    "title": "Switchable polarization in non-ferroelectric SrTiO$_3$",
    "authors": [
      "Wahib Aggoune",
      "Matthias Scheffler"
    ],
    "abstract": "Perovskites with tunable and switchable polarization hold immense promise for\nunlocking novel functionalities. Using density-functional theory, we reveal\nthat intrinsic defects can induce, enhance, and control polarization in\nnon-ferroelectric perovskites, with SrTiO$_3$ as our model system. At high\ndefect concentrations, these systems exhibit strong spontaneous polarization -\ncomparable to that of conventional ferroelectrics. Crucially, this polarization\nis switchable, enabled by the inherent symmetry-equivalence of defect sites in\nSrTiO$_3$. Strikingly, polarization switching not only reverses the\npolarization direction and modulates its magnitude but also modifies the\nspatial distribution of localized defect states. This dynamic behavior points\nto unprecedented responses to external stimuli, opening new avenues for\ndefect-engineered materials design.",
    "pdf_url": "http://arxiv.org/pdf/2506.01433v1",
    "published": "2025-06-02T08:45:14+00:00",
    "categories": [
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2506.01432v2",
    "title": "New aspects of quantum topological data analysis: Betti number estimation, and testing and tracking of homology and cohomology classes",
    "authors": [
      "Junseo Lee",
      "Nhat A. Nghiem"
    ],
    "abstract": "The application of quantum computation to topological data analysis (TDA) has\nreceived growing attention. While estimating Betti numbers is a central task in\nTDA, general complexity theoretic limitations restrict the possibility of\nquantum speedups. To address this, we explore quantum algorithms under a more\nstructured input model. We show that access to additional topological\ninformation enables improved quantum algorithms for estimating Betti and\npersistent Betti numbers. Building on this, we introduce a new approach based\non homology tracking, which avoids computing the kernel of combinatorial\nLaplacians used in prior methods. This yields a framework that remains\nefficient even when Betti numbers are small, offering substantial and sometimes\nexponential speedups. Beyond Betti number estimation, we formulate and study\nthe homology property testing problem, and extend our approach to the\ncohomological setting. We present quantum algorithms for testing triviality and\ndistinguishing homology classes, revealing new avenues for quantum advantage in\nTDA.",
    "pdf_url": "http://arxiv.org/pdf/2506.01432v2",
    "published": "2025-06-02T08:43:58+00:00",
    "categories": [
      "quant-ph",
      "cs.CC",
      "cs.CG",
      "cs.DS",
      "math.AT"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.01431v1",
    "title": "Binding energies of small interstellar molecules on neutral and charged amorphous solid water surfaces",
    "authors": [
      "Tobe Vorsselmans",
      "Erik C. Neyts"
    ],
    "abstract": "The interstellar medium (ISM) is all but empty. To date, more than 300\nmolecules have already been discovered. Because of the extremely low\ntemperature, the gas-phase chemistry is dominated by barrierless exothermic\nreactions of radicals and ions. However, several abundant molecules and organic\nmolecules cannot be produced efficiently by gas-phase reactions. To explain the\nexistence of such molecules in the ISM, gas-surface interactions between small\nmolecules and dust particles covered with amorphous solid water (ASW) mantles\nmust be considered. In general, surface processes such as adsorption,\ndiffusion, desorption, and chemical reactions can be linked to the binding\nenergy of molecules to the surface. Hence, a lot of studies have been performed\nto identify the binding energies of interstellar molecules on ASW surfaces.\nCosmic radiation and free electrons may induce a negative charge on the dust\nparticles, and the binding energies may be affected by this charge. In this\nstudy, we calculate the binding energies of CO, CH4, and NH3, on neutral and\ncharged ASW surfaces using DFT calculations. Our results indicate that CO can\ninteract with the surface charge, increasing its binding energy. In contrast,\nthe binding energy of CH4 remains unchanged in the presence of surface charge,\nand that of NH3 typically decreases.",
    "pdf_url": "http://arxiv.org/pdf/2506.01431v1",
    "published": "2025-06-02T08:41:48+00:00",
    "categories": [
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2506.01430v1",
    "title": "DNAEdit: Direct Noise Alignment for Text-Guided Rectified Flow Editing",
    "authors": [
      "Chenxi Xie",
      "Minghan Li",
      "Shuai Li",
      "Yuhui Wu",
      "Qiaosi Yi",
      "Lei Zhang"
    ],
    "abstract": "Leveraging the powerful generation capability of large-scale pretrained\ntext-to-image models, training-free methods have demonstrated impressive image\nediting results. Conventional diffusion-based methods, as well as recent\nrectified flow (RF)-based methods, typically reverse synthesis trajectories by\ngradually adding noise to clean images, during which the noisy latent at the\ncurrent timestep is used to approximate that at the next timesteps, introducing\naccumulated drift and degrading reconstruction accuracy. Considering the fact\nthat in RF the noisy latent is estimated through direct interpolation between\nGaussian noises and clean images at each timestep, we propose Direct Noise\nAlignment (DNA), which directly refines the desired Gaussian noise in the noise\ndomain, significantly reducing the error accumulation in previous methods.\nSpecifically, DNA estimates the velocity field of the interpolated noised\nlatent at each timestep and adjusts the Gaussian noise by computing the\ndifference between the predicted and expected velocity field. We validate the\neffectiveness of DNA and reveal its relationship with existing RF-based\ninversion methods. Additionally, we introduce a Mobile Velocity Guidance (MVG)\nto control the target prompt-guided generation process, balancing image\nbackground preservation and target object editability. DNA and MVG collectively\nconstitute our proposed method, namely DNAEdit. Finally, we introduce\nDNA-Bench, a long-prompt benchmark, to evaluate the performance of advanced\nimage editing models. Experimental results demonstrate that our DNAEdit\nachieves superior performance to state-of-the-art text-guided editing methods.\nCodes and benchmark will be available at \\href{\nhttps://xiechenxi99.github.io/DNAEdit/}{https://xiechenxi99.github.io/DNAEdit/}.",
    "pdf_url": "http://arxiv.org/pdf/2506.01430v1",
    "published": "2025-06-02T08:41:33+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.14798v1",
    "title": "MODS: Multi-source Observations Conditional Diffusion Model for Meteorological State Downscaling",
    "authors": [
      "Siwei Tu",
      "Jingyi Xu",
      "Weidong Yang",
      "Lei Bai",
      "Ben Fei"
    ],
    "abstract": "Accurate acquisition of high-resolution surface meteorological conditions is\ncritical for forecasting and simulating meteorological variables. Directly\napplying spatial interpolation methods to derive meteorological values at\nspecific locations from low-resolution grid fields often yields results that\ndeviate significantly from the actual conditions. Existing downscaling methods\nprimarily rely on the coupling relationship between geostationary satellites\nand ERA5 variables as a condition. However, using brightness temperature data\nfrom geostationary satellites alone fails to comprehensively capture all the\nchanges in meteorological variables in ERA5 maps. To address this limitation,\nwe can use a wider range of satellite data to make more full use of its\ninversion effects on various meteorological variables, thus producing more\nrealistic results across different meteorological variables. To further improve\nthe accuracy of downscaling meteorological variables at any location, we\npropose the Multi-source Observation Down-Scaling Model (MODS). It is a\nconditional diffusion model that fuses data from multiple geostationary\nsatellites GridSat, polar-orbiting satellites (AMSU-A, HIRS, and MHS), and\ntopographic data (GEBCO), as conditions, and is pre-trained on the ERA5\nreanalysis dataset. During training, latent features from diverse conditional\ninputs are extracted separately and fused into ERA5 maps via a multi-source\ncross-attention module. By exploiting the inversion relationships between\nreanalysis data and multi-source atmospheric variables, MODS generates\natmospheric states that align more closely with real-world conditions. During\nsampling, MODS enhances downscaling consistency by incorporating low-resolution\nERA5 maps and station-level meteorological data as guidance. Experimental\nresults demonstrate that MODS achieves higher fidelity when downscaling ERA5\nmaps to a 6.25 km resolution.",
    "pdf_url": "http://arxiv.org/pdf/2506.14798v1",
    "published": "2025-06-02T08:40:16+00:00",
    "categories": [
      "physics.ao-ph",
      "cs.AI"
    ],
    "primary_category": "physics.ao-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.01429v1",
    "title": "Computing Path Signature Varieties in Macaulay2",
    "authors": [
      "Carlos Améndola",
      "Angelo El Saliby",
      "Felix Lotter",
      "Oriol Reig Fité"
    ],
    "abstract": "The signature of a path is a non-commutative power series whose coefficients\nare given by certain iterated integrals over the path coordinates. This series\nalmost uniquely characterizes the path up to translation and\nreparameterization. Taking only fixed degree parts of these series yields\nsignature tensors. We introduce the Macaulay2 package $\\texttt{PathSignatures}$\nto simplify the study of these interesting objects for piecewise polynomial\npaths. It allows for the creation and manipulation of parametrized families of\npaths and provides methods for computing their signature tensors and their\nassociated algebraic varieties.",
    "pdf_url": "http://arxiv.org/pdf/2506.01429v1",
    "published": "2025-06-02T08:40:13+00:00",
    "categories": [
      "math.AG",
      "math.AC",
      "math.PR",
      "60L10, 60L70, 14Q15, 15A69"
    ],
    "primary_category": "math.AG"
  },
  {
    "id": "http://arxiv.org/abs/2506.01428v1",
    "title": "Low-velocity precessing jets can explain observed morphologies in the Twin Radio Galaxy TRG J104454+354055",
    "authors": [
      "Santanu Mondal",
      "Gourab Giri",
      "Ravi Joshi",
      "Paul J. Wiita",
      "Gopal-Krishna",
      "Luis C. Ho"
    ],
    "abstract": "Our understanding of large-scale radio jets in merger systems has been\ndrastically improved in the era of VLA, VLBA/EVN, uGMRT, and MeerKAT. Twin\nRadio Galaxies (TRGs) are the rare interacting galaxy pairs where both\nsupermassive black holes host kiloparsec-scale bipolar radio jets. Only\nrecently was a third TRG discovered and it shows significantly different jet\nmorphologies than the previous two. Due to both the extreme paucity and\ncomplexity of such systems, the launching of their jets as well as their mutual\ninteraction during the propagation through the ambient medium are not well\nunderstood. We have performed 3D hydrodynamic simulations to study the bipolar\njets in the third TRG, J104454+354055. Our study indicates that the precession\nof mutually tilted bipolar jets originating from the two galactic nuclei\nseparated by tens of kiloparsecs and propagating at low velocities can explain\nthe observed morphologies. The simulated jet precession timescales are short\ncompared to the overall dynamical timescale of the jets and could originate\nfrom Lense-Thirring effects in the accretion disks. This approach to\nunderstanding the TRG jet dynamics could also be applied to other TRG systems\nwith similar helical morphologies that may be discovered in the upcoming era of\nthe SKA and its pathfinder surveys.",
    "pdf_url": "http://arxiv.org/pdf/2506.01428v1",
    "published": "2025-06-02T08:35:40+00:00",
    "categories": [
      "astro-ph.HE",
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.HE"
  },
  {
    "id": "http://arxiv.org/abs/2506.01427v1",
    "title": "Forcrat: Automatic I/O API Translation from C to Rust via Origin and Capability Analysis",
    "authors": [
      "Jaemin Hong",
      "Sukyoung Ryu"
    ],
    "abstract": "Translating C to Rust is a promising way to enhance the reliability of legacy\nsystem programs. Although the industry has developed an automatic C-to-Rust\ntranslator, C2Rust, its translation remains unsatisfactory. One major reason is\nthat C2Rust retains C standard library (libc) function calls instead of\nreplacing them with functions from the Rust standard library (Rust std).\nHowever, little work has been done on replacing library functions in\nC2Rust-generated code. In this work, we focus on replacing the I/O API, an\nimportant subset of library functions. This poses challenges due to the\nsemantically different designs of I/O APIs in libc and Rust std. First, the two\nAPIs offer different sets of types that represent the origins (e.g., standard\ninput, files) and capabilities (e.g., read, write) of streams used for I/O.\nSecond, they use different error-checking mechanisms: libc uses internal\nindicators, while Rust std uses return values. To address these challenges, we\npropose two static analysis techniques, origin and capability analysis and\nerror source analysis, and use their results to replace the I/O API. Our\nevaluation shows that the proposed approach is (1) correct, with all 32\nprograms that have test suites passing the tests after transformation, (2)\nefficient, analyzing and transforming 422k LOC in 14 seconds, and (3) widely\napplicable, replacing 82% of I/O API calls.",
    "pdf_url": "http://arxiv.org/pdf/2506.01427v1",
    "published": "2025-06-02T08:34:06+00:00",
    "categories": [
      "cs.SE"
    ],
    "primary_category": "cs.SE"
  },
  {
    "id": "http://arxiv.org/abs/2506.01426v1",
    "title": "Optimal Co-Design of a Hybrid Energy Storage System for Truck Charging",
    "authors": [
      "Juan Pablo Bertucci",
      "Sudarshan Raghuraman",
      "Mauro Salazar",
      "Theo Hofman"
    ],
    "abstract": "The major challenges to battery electric truck adoption are their high cost\nand grid congestion.In this context, stationary energy storage systems can help\nmitigate both issues. Since their design and operation are strongly coupled, to\nmake the best out of them, they should be jointly optimized. This paper\npresents a co-design framework for hybrid energy storage systems where their\ntechnology and sizing are optimized jointly with their operational strategies.\nSpecifically, we consider a microgrid supporting truck chargers that consists\nof utility grid, solar panels, and energy storage systems including batteries,\nsupercapacitors and flywheels. We frame the co-design problem as a\nmixed-integer linear program that can be solved with global optimality\nguarantees. We showcase our framework in a case-study of a distribution center\nin the Netherlands. Our results show that although the battery-only\nconfiguration is already competitive, adding supercapacitors or flywheel\nstorage decrease total cost and increase energy sold back to the grid. Overall,\nthe fully hybrid solution (Battery+Supercapacitors+Flywheel) offers the best\noutcomes, achieving the lowest overall cost (1.96\\% lower compared to\nbattery-only) and reduced grid dependency, but at a higher (2.6\\%) initial\ninvestment.",
    "pdf_url": "http://arxiv.org/pdf/2506.01426v1",
    "published": "2025-06-02T08:31:51+00:00",
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2506.01425v1",
    "title": "CSVAR: Enhancing Visual Privacy in Federated Learning via Adaptive Shuffling Against Overfitting",
    "authors": [
      "Zhuo Chen",
      "Zhenya Ma",
      "Yan Zhang",
      "Donghua Cai",
      "Ye Zhang",
      "Qiushi Li",
      "Yongheng Deng",
      "Ye Guo",
      "Ju Ren",
      "Xuemin",
      "Shen"
    ],
    "abstract": "Although federated learning preserves training data within local privacy\ndomains, the aggregated model parameters may still reveal private\ncharacteristics. This vulnerability stems from clients' limited training data,\nwhich predisposes models to overfitting. Such overfitting enables models to\nmemorize distinctive patterns from training samples, thereby amplifying the\nsuccess probability of privacy attacks like membership inference. To enhance\nvisual privacy protection in FL, we present CSVAR(Channel-Wise Spatial Image\nShuffling with Variance-Guided Adaptive Region Partitioning), a novel image\nshuffling framework to generate obfuscated images for secure data transmission\nand each training epoch, addressing both overfitting-induced privacy leaks and\nraw image transmission risks. CSVAR adopts region-variance as the metric to\nmeasure visual privacy sensitivity across image regions. Guided by this, CSVAR\nadaptively partitions each region into multiple blocks, applying fine-grained\npartitioning to privacy-sensitive regions with high region-variances for\nenhancing visual privacy protection and coarse-grained partitioning to\nprivacy-insensitive regions for balancing model utility. In each region, CSVAR\nthen shuffles between blocks in both the spatial domains and chromatic channels\nto hide visual spatial features and disrupt color distribution. Experimental\nevaluations conducted on diverse real-world datasets demonstrate that CSVAR is\ncapable of generating visually obfuscated images that exhibit high perceptual\nambiguity to human eyes, simultaneously mitigating the effectiveness of\nadversarial data reconstruction attacks and achieving a good trade-off between\nvisual privacy protection and model utility.",
    "pdf_url": "http://arxiv.org/pdf/2506.01425v1",
    "published": "2025-06-02T08:30:12+00:00",
    "categories": [
      "cs.CR"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2506.01424v1",
    "title": "Discretely structured magnetic flux concentrators",
    "authors": [
      "Yujun Shi",
      "Xiaoting Feng"
    ],
    "abstract": "Conventional magnetic flux concentrators (MFCs) are typically designed with\nsolid structures, which may not be optimal for applications requiring\nlightweight design or material efficiency. In this study, we investigate the\nfeasibility of spatially discretized MFCs in guiding and concentrating magnetic\nflux, through finite element simulations. Our results demonstrate that\ndiscretely structured MFCs can achieve performance comparable to that of solid\ncounterparts while significantly reducing material usage. For instance, even\nwith a non-optimized discretized design, discretization along a single\ndimension can reduce material usage by an order of magnitude. Moreover, for\nthree-dimensional structural devices, discretization along two dimensions has\nthe potential to reduce material consumption by two orders of magnitude. This\nmay offer a notable advantage in applications where weight reduction and cost\nefficiency are of primary concern.",
    "pdf_url": "http://arxiv.org/pdf/2506.01424v1",
    "published": "2025-06-02T08:26:50+00:00",
    "categories": [
      "physics.app-ph"
    ],
    "primary_category": "physics.app-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.01423v1",
    "title": "FinRobot: Generative Business Process AI Agents for Enterprise Resource Planning in Finance",
    "authors": [
      "Hongyang Yang",
      "Likun Lin",
      "Yang She",
      "Xinyu Liao",
      "Jiaoyang Wang",
      "Runjia Zhang",
      "Yuquan Mo",
      "Christina Dan Wang"
    ],
    "abstract": "Enterprise Resource Planning (ERP) systems serve as the digital backbone of\nmodern financial institutions, yet they continue to rely on static, rule-based\nworkflows that limit adaptability, scalability, and intelligence. As business\noperations grow more complex and data-rich, conventional ERP platforms struggle\nto integrate structured and unstructured data in real time and to accommodate\ndynamic, cross-functional workflows.\n  In this paper, we present the first AI-native, agent-based framework for ERP\nsystems, introducing a novel architecture of Generative Business Process AI\nAgents (GBPAs) that bring autonomy, reasoning, and dynamic optimization to\nenterprise workflows. The proposed system integrates generative AI with\nbusiness process modeling and multi-agent orchestration, enabling end-to-end\nautomation of complex tasks such as budget planning, financial reporting, and\nwire transfer processing. Unlike traditional workflow engines, GBPAs interpret\nuser intent, synthesize workflows in real time, and coordinate specialized\nsub-agents for modular task execution. We validate the framework through case\nstudies in bank wire transfers and employee reimbursements, two representative\nfinancial workflows with distinct complexity and data modalities. Results show\nthat GBPAs achieve up to 40% reduction in processing time, 94% drop in error\nrate, and improved regulatory compliance by enabling parallelism, risk control\ninsertion, and semantic reasoning. These findings highlight the potential of\nGBPAs to bridge the gap between generative AI capabilities and enterprise-grade\nautomation, laying the groundwork for the next generation of intelligent ERP\nsystems.",
    "pdf_url": "http://arxiv.org/pdf/2506.01423v1",
    "published": "2025-06-02T08:22:28+00:00",
    "categories": [
      "cs.AI",
      "cs.SE",
      "q-fin.GN"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2506.01422v1",
    "title": "Large Bayesian VARs for Binary and Censored Variables",
    "authors": [
      "Joshua C. C. Chan",
      "Michael Pfarrhofer"
    ],
    "abstract": "We extend the standard VAR to jointly model the dynamics of binary, censored\nand continuous variables, and develop an efficient estimation approach that\nscales well to high-dimensional settings. In an out-of-sample forecasting\nexercise, we show that the proposed VARs forecast recessions and short-term\ninterest rates well. We demonstrate the utility of the proposed framework using\na wide rage of empirical applications, including conditional forecasting and a\nstructural analysis that examines the dynamic effects of a financial shock on\nrecession probabilities.",
    "pdf_url": "http://arxiv.org/pdf/2506.01422v1",
    "published": "2025-06-02T08:22:24+00:00",
    "categories": [
      "econ.EM",
      "stat.CO"
    ],
    "primary_category": "econ.EM"
  },
  {
    "id": "http://arxiv.org/abs/2506.01421v1",
    "title": "A Decidable Bundled Fragment of First-Order Modal Logic Without Finite Model Property",
    "authors": [
      "Varad Joshi",
      "Anantha Padmanabha"
    ],
    "abstract": "The satisfiability problem for First-order Modal Logic (\\FOML) is undecidable\neven for simple fragments like having only unary predicates, two variables etc.\nRecently a new way to identify decidable fragments of \\FOML has been introduced\ncalled the \"bundled fragments\", where the quantifiers and modalities are\nrestricted to appear together. Since there are many ways to bundle the\nquantifiers together, some of them lead to (un)decidable fragments. In (Liu\net.al, 2023) the authors prove a `trichotomy', where they show that every\nbundled fragment falls into one of the following three categories: (1) Those\nthat satisfy \"finite model property\" (and hence decidable), (2) Those that are\nundecidable, and (3) Those that do not satisfy \"finite model property\" (whose\ndecidability is left open).\n  In this paper we collapse the trichotomy into a dichotomy over \"increasing\ndomain models\" by proving that the one combination that falls into the last\ncategory is indeed decidable.",
    "pdf_url": "http://arxiv.org/pdf/2506.01421v1",
    "published": "2025-06-02T08:21:53+00:00",
    "categories": [
      "cs.LO"
    ],
    "primary_category": "cs.LO"
  },
  {
    "id": "http://arxiv.org/abs/2506.01420v1",
    "title": "Self-Refining Language Model Anonymizers via Adversarial Distillation",
    "authors": [
      "Kyuyoung Kim",
      "Hyunjun Jeon",
      "Jinwoo Shin"
    ],
    "abstract": "Large language models (LLMs) are increasingly used in sensitive domains,\nwhere their ability to infer personal data from seemingly benign text poses\nemerging privacy risks. While recent LLM-based anonymization methods help\nmitigate such risks, they often rely on proprietary models (e.g., GPT-4),\nraising concerns about cost and the potential exposure of sensitive data to\nuntrusted external systems. To address this, we introduce SElf-refining\nAnonymization with Language model (SEAL), a novel distillation framework for\ntraining small language models (SLMs) to perform effective anonymization\nwithout relying on external costly models at inference time. We leverage\nadversarial interactions between an LLM anonymizer and an inference model to\ncollect trajectories of anonymized texts and inferred attributes, which are\nused to distill anonymization, adversarial inference, and utility evaluation\ncapabilities into SLMs via supervised fine-tuning and preference learning. The\nresulting models learn to both anonymize text and critique their outputs,\nenabling iterative improvement of anonymization quality via self-refinement.\nExperiments on SynthPAI, a dataset of synthetic personal profiles and text\ncomments, demonstrate that SLMs trained with SEAL achieve substantial\nimprovements in anonymization capabilities. Notably, 8B models attain a\nprivacy-utility trade-off comparable to that of the GPT-4 anonymizer and, with\nself-refinement, even surpass it in terms of privacy. These results show the\neffectiveness of our adversarial distillation framework in training SLMs as\nefficient anonymizers. To facilitate further research, we release the full\ndataset used in our experiments.",
    "pdf_url": "http://arxiv.org/pdf/2506.01420v1",
    "published": "2025-06-02T08:21:27+00:00",
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.01419v1",
    "title": "UniversalCEFR: Enabling Open Multilingual Research on Language Proficiency Assessment",
    "authors": [
      "Joseph Marvin Imperial",
      "Abdullah Barayan",
      "Regina Stodden",
      "Rodrigo Wilkens",
      "Ricardo Munoz Sanchez",
      "Lingyun Gao",
      "Melissa Torgbi",
      "Dawn Knight",
      "Gail Forey",
      "Reka R. Jablonkai",
      "Ekaterina Kochmar",
      "Robert Reynolds",
      "Eugenio Ribeiro",
      "Horacio Saggion",
      "Elena Volodina",
      "Sowmya Vajjala",
      "Thomas Francois",
      "Fernando Alva-Manchego",
      "Harish Tayyar Madabushi"
    ],
    "abstract": "We introduce UniversalCEFR, a large-scale multilingual multidimensional\ndataset of texts annotated according to the CEFR (Common European Framework of\nReference) scale in 13 languages. To enable open research in both automated\nreadability and language proficiency assessment, UniversalCEFR comprises\n505,807 CEFR-labeled texts curated from educational and learner-oriented\nresources, standardized into a unified data format to support consistent\nprocessing, analysis, and modeling across tasks and languages. To demonstrate\nits utility, we conduct benchmark experiments using three modelling paradigms:\na) linguistic feature-based classification, b) fine-tuning pre-trained LLMs,\nand c) descriptor-based prompting of instruction-tuned LLMs. Our results\nfurther support using linguistic features and fine-tuning pretrained models in\nmultilingual CEFR level assessment. Overall, UniversalCEFR aims to establish\nbest practices in data distribution in language proficiency research by\nstandardising dataset formats and promoting their accessibility to the global\nresearch community.",
    "pdf_url": "http://arxiv.org/pdf/2506.01419v1",
    "published": "2025-06-02T08:21:16+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.01418v1",
    "title": "SEMNAV: A Semantic Segmentation-Driven Approach to Visual Semantic Navigation",
    "authors": [
      "Rafael Flor-Rodríguez",
      "Carlos Gutiérrez-Álvarez",
      "Francisco Javier Acevedo-Rodríguez",
      "Sergio Lafuente-Arroyo",
      "Roberto J. López-Sastre"
    ],
    "abstract": "Visual Semantic Navigation (VSN) is a fundamental problem in robotics, where\nan agent must navigate toward a target object in an unknown environment, mainly\nusing visual information. Most state-of-the-art VSN models are trained in\nsimulation environments, where rendered scenes of the real world are used, at\nbest. These approaches typically rely on raw RGB data from the virtual scenes,\nwhich limits their ability to generalize to real-world environments due to\ndomain adaptation issues. To tackle this problem, in this work, we propose\nSEMNAV, a novel approach that leverages semantic segmentation as the main\nvisual input representation of the environment to enhance the agent's\nperception and decision-making capabilities. By explicitly incorporating\nhigh-level semantic information, our model learns robust navigation policies\nthat improve generalization across unseen environments, both in simulated and\nreal world settings. We also introduce a newly curated dataset, i.e. the SEMNAV\ndataset, designed for training semantic segmentation-aware navigation models\nlike SEMNAV. Our approach is evaluated extensively in both simulated\nenvironments and with real-world robotic platforms. Experimental results\ndemonstrate that SEMNAV outperforms existing state-of-the-art VSN models,\nachieving higher success rates in the Habitat 2.0 simulation environment, using\nthe HM3D dataset. Furthermore, our real-world experiments highlight the\neffectiveness of semantic segmentation in mitigating the sim-to-real gap,\nmaking our model a promising solution for practical VSN-based robotic\napplications. We release SEMNAV dataset, code and trained models at\nhttps://github.com/gramuah/semnav",
    "pdf_url": "http://arxiv.org/pdf/2506.01418v1",
    "published": "2025-06-02T08:19:41+00:00",
    "categories": [
      "cs.RO",
      "cs.CV"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2506.01417v2",
    "title": "Colloidal nanoparticles in cholesteric liquid crystals: Bulk properties, biaxiality and untwisting",
    "authors": [
      "Prabakaran Rajamanickam",
      "Fatimah Almutari",
      "Apala Majumdar"
    ],
    "abstract": "We study the effects of colloidal nanoparticles (NPs) in cholesteric liquid\ncrystal samples in the dilute limit, in a Landau-de Gennes theoretical\nframework. The effects of the suspended NPs are captured by a homogenized\nenergy, as outlined in [7]. For spatially homogeneous samples, we explicitly\ncompute the critical points and minimizers of the modified Landau-de Gennes\nenergy and show that the presence of NP eliminates the first-order\nisotropic-nematic phase transition, stabilises elusive biaxial phases over some\ntemperature ranges, and that the symmetry of the NP boundary conditions or\nsurface treatments dictates the bulk equilibrium phase at high temperatures. We\nalso numerically demonstrate structural transitions from twisted helical\ndirector profiles to untwisted director profiles, in cholesteric-filled channel\ngeometries, driven by the collective effects of the NPs and increasing\ntemperature. These transitions are reversible upon lowering the temperature in\nsufficiently large domains, where thermal hysteresis can also be observed. This\nbehaviour opens interesting avenues for tuning the optical properties of\nconfined, nano-doped cholesteric systems.",
    "pdf_url": "http://arxiv.org/pdf/2506.01417v2",
    "published": "2025-06-02T08:18:42+00:00",
    "categories": [
      "cond-mat.soft"
    ],
    "primary_category": "cond-mat.soft"
  },
  {
    "id": "http://arxiv.org/abs/2506.01416v1",
    "title": "Solar Surface Magnetic Field Simulation from 2010 to 2024 and Anomalous Southern Poleward Flux Transport in Cycle 24",
    "authors": [
      "Ruihui Wang",
      "Jie Jiang",
      "Yukun Luo"
    ],
    "abstract": "The solar surface magnetic field is fundamental for modeling the coronal\nmagnetic field, studying the solar dynamo, and predicting solar cycle strength.\nWe perform a continuous simulation of the surface magnetic field from 2010 to\n2024, covering solar cycle 24 and the ongoing cycle 25, using the surface flux\ntransport model with assimilated observed active regions (ARs) as the source.\nThe simulation reproduces the evolution of the axial dipole strength, polar\nfield reversal timing, and magnetic butterfly diagram in good agreement with\nSDO/HMI observations. Notably, these results are achieved without incorporating\nradial diffusion or cyclic variations in meridional flow speed, suggesting\ntheir limited impact. Poleward surges of the following polarity typically\ndominate throughout the cycle, but in the southern hemisphere during cycle 24,\nthey are limited to a short period from 2011 to 2016. This anomalous pattern\narises from intermittent AR emergence, with about 46% of total unsigned flux\ncontributed by ARs emerging during Carrington Rotations 2141-2160 (September\n2013 - February 2015). These ARs show a strong active longitude at Carrington\nlongitudes 200-260 degree and a weaker one at 80-100 degree. After 2016,\npoleward migrations of leading-polarity flux become dominant, despite most ARs\nfollowing Joy's and Hale's laws. This reversal is likely due to prolonged\nintervals between AR emergences, which allow leading-polarity flux to\ndistribute across a broad latitude range before cancellation by subsequent ARs.\nThese findings highlight the importance of the temporal interval of AR\nemergence in driving the flux transport pattern.",
    "pdf_url": "http://arxiv.org/pdf/2506.01416v1",
    "published": "2025-06-02T08:15:21+00:00",
    "categories": [
      "astro-ph.SR"
    ],
    "primary_category": "astro-ph.SR"
  },
  {
    "id": "http://arxiv.org/abs/2506.01415v3",
    "title": "Super Macdonald polynomials and BPS state counting on the blow-up",
    "authors": [
      "Hiroaki Kanno",
      "Ryo Ohkawa",
      "Jun'ichi Shiraishi"
    ],
    "abstract": "We explore the relation of the super Macdonald polynomials and the BPS state\ncounting on the blow-up of $\\mathbb{P}^2$, which is mathematically described by\nframed stable perverse coherent sheaves. Fixed points of the torus action on\nthe moduli space of BPS states are labeled by super partitions. From the\nequivariant character of the tangent space at the fixed points we can define\nthe Nekrasov factor for a pair of super partitions, which is used for the\nlocalization computation of the partition function. The Nekrasov factor also\nallows us to compute matrix elements of the action of the quantum toroidal\nalgebra of type $\\mathfrak{gl}_{1|1}$ on the $K$ group of the moduli space. We\nconfirm that these matrix elements are consistent with the Pieri rule of the\nsuper Macdonald polynomials.",
    "pdf_url": "http://arxiv.org/pdf/2506.01415v3",
    "published": "2025-06-02T08:14:28+00:00",
    "categories": [
      "hep-th",
      "math-ph",
      "math.MP",
      "math.QA",
      "math.RT"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2506.01414v1",
    "title": "Self-supervised Latent Space Optimization with Nebula Variational Coding",
    "authors": [
      "Yida Wang",
      "David Joseph Tan",
      "Nassir Navab",
      "Federico Tombari"
    ],
    "abstract": "Deep learning approaches process data in a layer-by-layer way with\nintermediate (or latent) features. We aim at designing a general solution to\noptimize the latent manifolds to improve the performance on classification,\nsegmentation, completion and/or reconstruction through probabilistic models.\nThis paper proposes a variational inference model which leads to a clustered\nembedding. We introduce additional variables in the latent space, called\n\\textbf{nebula anchors}, that guide the latent variables to form clusters\nduring training. To prevent the anchors from clustering among themselves, we\nemploy the variational constraint that enforces the latent features within an\nanchor to form a Gaussian distribution, resulting in a generative model we\nrefer as Nebula Variational Coding (NVC). Since each latent feature can be\nlabeled with the closest anchor, we also propose to apply metric learning in a\nself-supervised way to make the separation between clusters more explicit. As a\nconsequence, the latent variables of our variational coder form clusters which\nadapt to the generated semantic of the training data, \\textit{e.g.} the\ncategorical labels of each sample. We demonstrate experimentally that it can be\nused within different architectures designed to solve different problems\nincluding text sequence, images, 3D point clouds and volumetric data,\nvalidating the advantage of our proposed method.",
    "pdf_url": "http://arxiv.org/pdf/2506.01414v1",
    "published": "2025-06-02T08:13:32+00:00",
    "categories": [
      "cs.LG",
      "cs.IT",
      "math.IT"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.01413v6",
    "title": "Incentivizing Reasoning for Advanced Instruction-Following of Large Language Models",
    "authors": [
      "Yulei Qin",
      "Gang Li",
      "Zongyi Li",
      "Zihan Xu",
      "Yuchen Shi",
      "Zhekai Lin",
      "Xiao Cui",
      "Ke Li",
      "Xing Sun"
    ],
    "abstract": "Existing large language models (LLMs) face challenges of following complex\ninstructions, especially when multiple constraints are present and organized in\nparalleling, chaining, and branching structures. One intuitive solution, namely\nchain-of-thought (CoT), is expected to universally improve capabilities of\nLLMs. However, we find that the vanilla CoT exerts a negative impact on\nperformance due to its superficial reasoning pattern of simply paraphrasing the\ninstructions. It fails to peel back the compositions of constraints for\nidentifying their relationship across hierarchies of types and dimensions. To\nthis end, we propose RAIF, a systematic method to boost LLMs in dealing with\ncomplex instructions via incentivizing reasoning for test-time compute scaling.\nFirst, we stem from the decomposition of complex instructions under existing\ntaxonomies and propose a reproducible data acquisition method. Second, we\nexploit reinforcement learning (RL) with verifiable rule-centric reward signals\nto cultivate reasoning specifically for instruction following. We address the\nshallow, non-essential nature of reasoning under complex instructions via\nsample-wise contrast for superior CoT enforcement. We also exploit behavior\ncloning of experts to facilitate steady distribution shift from fast-thinking\nLLMs to skillful reasoners. Extensive evaluations on seven comprehensive\nbenchmarks confirm the validity of the proposed method, where a 1.5B LLM\nachieves 11.74% gains with performance comparable to a 8B LLM. Evaluation on\nOOD constraints also confirms the generalizability of our RAIF. Codes and data\nare available at https://github.com/yuleiqin/RAIF.\n  Keywords: reinforcement learning with verifiable rewards (RLVR), instruction\nfollowing, complex instructions",
    "pdf_url": "http://arxiv.org/pdf/2506.01413v6",
    "published": "2025-06-02T08:11:44+00:00",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.01412v1",
    "title": "System Calls for Malware Detection and Classification: Methodologies and Applications",
    "authors": [
      "Bishwajit Prasad Gond",
      "Durga Prasad Mohapatra"
    ],
    "abstract": "As malware continues to become more complex and harder to detect, Malware\nAnalysis needs to continue to evolve to stay one step ahead. One promising key\narea approach focuses on using system calls and API Calls, the core\ncommunication between user applications and the operating system and their\nkernels. These calls provide valuable insight into how software or programs\nbehaves, making them an useful tool for spotting suspicious or harmful activity\nof programs and software. This chapter takes a deep down look at how system\ncalls are used in malware detection and classification, covering techniques\nlike static and dynamic analysis, as well as sandboxing. By combining these\nmethods with advanced techniques like machine learning, statistical analysis,\nand anomaly detection, researchers can analyze system call patterns to tell the\ndifference between normal and malicious behavior. The chapter also explores how\nthese techniques are applied across different systems, including Windows,\nLinux, and Android, while also looking at the ways sophisticated malware tries\nto evade detection.",
    "pdf_url": "http://arxiv.org/pdf/2506.01412v1",
    "published": "2025-06-02T08:11:27+00:00",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2506.01411v1",
    "title": "ViTA-PAR: Visual and Textual Attribute Alignment with Attribute Prompting for Pedestrian Attribute Recognition",
    "authors": [
      "Minjeong Park",
      "Hongbeen Park",
      "Jinkyu Kim"
    ],
    "abstract": "The Pedestrian Attribute Recognition (PAR) task aims to identify various\ndetailed attributes of an individual, such as clothing, accessories, and\ngender. To enhance PAR performance, a model must capture features ranging from\ncoarse-grained global attributes (e.g., for identifying gender) to fine-grained\nlocal details (e.g., for recognizing accessories) that may appear in diverse\nregions. Recent research suggests that body part representation can enhance the\nmodel's robustness and accuracy, but these methods are often restricted to\nattribute classes within fixed horizontal regions, leading to degraded\nperformance when attributes appear in varying or unexpected body locations. In\nthis paper, we propose Visual and Textual Attribute Alignment with Attribute\nPrompting for Pedestrian Attribute Recognition, dubbed as ViTA-PAR, to enhance\nattribute recognition through specialized multimodal prompting and\nvision-language alignment. We introduce visual attribute prompts that capture\nglobal-to-local semantics, enabling diverse attribute representations. To\nenrich textual embeddings, we design a learnable prompt template, termed person\nand attribute context prompting, to learn person and attributes context.\nFinally, we align visual and textual attribute features for effective fusion.\nViTA-PAR is validated on four PAR benchmarks, achieving competitive performance\nwith efficient inference. We release our code and model at\nhttps://github.com/mlnjeongpark/ViTA-PAR.",
    "pdf_url": "http://arxiv.org/pdf/2506.01411v1",
    "published": "2025-06-02T08:07:06+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.01410v1",
    "title": "Unwrapping photonic reservoirs: enhanced expressivity via random Fourier encoding over stretched domains",
    "authors": [
      "Gerard McCaul",
      "Girish Tripathy",
      "Giulia Marcucci",
      "Juan Sebastian Totero Gongora"
    ],
    "abstract": "Photonic Reservoir Computing (RC) systems leverage the complex propagation\nand nonlinear interaction of optical waves to perform information processing\ntasks. These systems employ a combination of optical data encoding (in the\nfield amplitude and/or phase), random scattering, and nonlinear detection to\ngenerate nonlinear features that can be processed via a linear readout layer.\nIn this work, we propose a novel scattering-assisted photonic reservoir\nencoding scheme where the input phase is deliberately wrapped multiple times\nbeyond the natural period of the optical waves $[0,2\\pi)$. We demonstrate that,\nrather than hindering nonlinear separability through loss of bijectivity,\nwrapping significantly improves the reservoir's prediction performance across\nregression and classification tasks that are unattainable within the canonical\n$2\\pi$ period. We demonstrate that this counterintuitive effect stems from the\nnonlinear interference between sets of random synthetic frequencies introduced\nby the encoding, which generates a rich feature space spanning both the feature\nand sample dimensions of the data. Our results highlight the potential of\nengineered phase wrapping as a computational resource in RC systems based on\nphase encoding, paving the way for novel approaches to designing and optimizing\nphysical computing platforms based on topological and geometric stretching.",
    "pdf_url": "http://arxiv.org/pdf/2506.01410v1",
    "published": "2025-06-02T08:07:00+00:00",
    "categories": [
      "physics.optics",
      "quant-ph"
    ],
    "primary_category": "physics.optics"
  },
  {
    "id": "http://arxiv.org/abs/2506.01409v1",
    "title": "X-ray mirror figure correction using differential deposition",
    "authors": [
      "Ch. Morawe",
      "S. Labouré",
      "F. Perrin",
      "A. Vivo",
      "R. Barrett"
    ],
    "abstract": "The surface figure of x-ray mirrors can be improved by differential\ndeposition of thin films. To achieve the required corrections, WSi2 layers of\nvariable thickness were deposited through beam-defining apertures of different\nopenings. The substrates were moved in front of the particle source with\nspecific velocity profiles that were calculated with a deconvolution algorithm.\nTwo different DC magnetron sputter systems were used to investigate the\ncorrection process. Height errors were evaluated before and after each\niteration using off-line visible light surface metrology. Four 300 mm long flat\nSi mirrors were used to study the impact of the initial shape errors on the\nperformance of the correction approach. The shape errors were routinely reduced\nby a factor of 20-30 down to levels below 0.5 nm RMS.",
    "pdf_url": "http://arxiv.org/pdf/2506.01409v1",
    "published": "2025-06-02T08:06:12+00:00",
    "categories": [
      "physics.optics",
      "physics.app-ph"
    ],
    "primary_category": "physics.optics"
  },
  {
    "id": "http://arxiv.org/abs/2506.01408v1",
    "title": "Modeling temporal hypergraphs",
    "authors": [
      "Jürgen Lerner",
      "Marian-Gabriel Hâncean",
      "Matjaz Perc"
    ],
    "abstract": "Networks representing social, biological, technological or other systems are\noften characterized by higher-order interaction involving any number of nodes.\nTemporal hypergraphs are given by ordered sequences of hyperedges representing\nsets of nodes interacting at given points in time. In this paper we discuss how\na recently proposed model family for time-stamped hyperedges - relational\nhyperevent models (RHEM) - can be employed to define tailored null\ndistributions for temporal hypergraphs. RHEM can be specified with a given\nvector of temporal hyperedge statistics - functions that quantify the\nstructural position of hyperedges in the history of previous hyperedges - and\nequate expected values of these statistics with their empirically observed\nvalues. This allows, for instance, to analyze the overrepresentation or\nunderrepresentation of temporal hyperedge configurations in a model that\nreproduces the observed distributions of possibly complex sub-configurations,\nincluding but going beyond node degrees. Concrete examples include, but are not\nlimited to, preferential attachment, repetition of subsets of any given size,\ntriadic closure, homophily, and degree assortativity for subsets of any order.",
    "pdf_url": "http://arxiv.org/pdf/2506.01408v1",
    "published": "2025-06-02T08:04:59+00:00",
    "categories": [
      "physics.soc-ph",
      "stat.AP"
    ],
    "primary_category": "physics.soc-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.01407v1",
    "title": "Comparing LLM-generated and human-authored news text using formal syntactic theory",
    "authors": [
      "Olga Zamaraeva",
      "Dan Flickinger",
      "Francis Bond",
      "Carlos Gómez-Rodríguez"
    ],
    "abstract": "This study provides the first comprehensive comparison of New York\nTimes-style text generated by six large language models against real,\nhuman-authored NYT writing. The comparison is based on a formal syntactic\ntheory. We use Head-driven Phrase Structure Grammar (HPSG) to analyze the\ngrammatical structure of the texts. We then investigate and illustrate the\ndifferences in the distributions of HPSG grammar types, revealing systematic\ndistinctions between human and LLM-generated writing. These findings contribute\nto a deeper understanding of the syntactic behavior of LLMs as well as humans,\nwithin the NYT genre.",
    "pdf_url": "http://arxiv.org/pdf/2506.01407v1",
    "published": "2025-06-02T08:04:34+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.01406v1",
    "title": "Speech-to-Speech Translation Pipelines for Conversations in Low-Resource Languages",
    "authors": [
      "Andrei Popescu-Belis",
      "Alexis Allemann",
      "Teo Ferrari",
      "Gopal Krishnamani"
    ],
    "abstract": "The popularity of automatic speech-to-speech translation for human\nconversations is growing, but the quality varies significantly depending on the\nlanguage pair. In a context of community interpreting for low-resource\nlanguages, namely Turkish and Pashto to/from French, we collected fine-tuning\nand testing data, and compared systems using several automatic metrics (BLEU,\nCOMET, and BLASER) and human assessments. The pipelines included automatic\nspeech recognition, machine translation, and speech synthesis, with local\nmodels and cloud-based commercial ones. Some components have been fine-tuned on\nour data. We evaluated over 60 pipelines and determined the best one for each\ndirection. We also found that the ranks of components are generally independent\nof the rest of the pipeline.",
    "pdf_url": "http://arxiv.org/pdf/2506.01406v1",
    "published": "2025-06-02T08:02:44+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.01405v2",
    "title": "SOC-DGL: Social Interaction Behavior Inspired Dual Graph Learning Framework for Drug-Target Interaction Identification",
    "authors": [
      "Xiang Zhao",
      "Ruijie Li",
      "Qiao Ning",
      "Shikai Guo",
      "Hui Li",
      "Qian Ma"
    ],
    "abstract": "The identification of drug-target interactions (DTI) is critical for drug\ndiscovery and repositioning, as it reveals potential therapeutic uses of\nexisting drugs, accelerating development and reducing costs. However, most\nexisting models focus only on direct similarity in homogeneous graphs, failing\nto exploit the rich similarity in heterogeneous graphs. To address this gap,\ninspired by real-world social interaction behaviors, we propose SOC-DGL, which\ncomprises two specialized modules: the Affinity-Driven Graph Learning (ADGL)\nmodule, learning global similarity through an affinity-enhanced drug-target\ngraph, and the Equilibrium-Driven Graph Learning (EDGL) module, capturing\nhigher-order similarity by amplifying the influence of even-hop neighbors using\nan even-polynomial graph filter based on balance theory. This dual approach\nenables SOC-DGL to effectively capture similarity information across multiple\ninteraction scales within affinity and association matrices. To address the\nissue of imbalance in DTI datasets, we propose an adjustable imbalance loss\nfunction that adjusts the weight of negative samples by the parameter.\nExtensive experiments on four benchmark datasets demonstrate that SOC-DGL\nconsistently outperforms existing state-of-the-art methods across both balanced\nand imbalanced scenarios. Moreover, SOC-DGL successfully predicts the top 9\ndrugs known to bind ABL1, and further analyzed the 10th drug, which has not\nbeen experimentally confirmed to interact with ABL1, providing supporting\nevidence for its potential binding.",
    "pdf_url": "http://arxiv.org/pdf/2506.01405v2",
    "published": "2025-06-02T08:00:24+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.02075v1",
    "title": "Stop Chasing the C-index: This Is How We Should Evaluate Our Survival Models",
    "authors": [
      "Christian Marius Lillelund",
      "Shi-ang Qi",
      "Russell Greiner",
      "Christian Fischer Pedersen"
    ],
    "abstract": "We argue that many survival analysis and time-to-event models are incorrectly\nevaluated. First, we survey many examples of evaluation approaches in the\nliterature and find that most rely on concordance (C-index). However, the\nC-index only measures a model's discriminative ability and does not assess\nother important aspects, such as the accuracy of the time-to-event predictions\nor the calibration of the model's probabilistic estimates. Next, we present a\nset of key desiderata for choosing the right evaluation metric and discuss\ntheir pros and cons. These are tailored to the challenges in survival analysis,\nsuch as sensitivity to miscalibration and various censoring assumptions. We\nhypothesize that the current development of survival metrics conforms to a\ndouble-helix ladder, and that model validity and metric validity must stand on\nthe same rung of the assumption ladder. Finally, we discuss the appropriate\nmethods for evaluating a survival model in practice and summarize various\nviewpoints opposing our analysis.",
    "pdf_url": "http://arxiv.org/pdf/2506.02075v1",
    "published": "2025-06-02T07:59:34+00:00",
    "categories": [
      "stat.ME",
      "cs.LG"
    ],
    "primary_category": "stat.ME"
  },
  {
    "id": "http://arxiv.org/abs/2506.01404v1",
    "title": "Quantitative Error Feedback for Quantization Noise Reduction of Filtering over Graphs",
    "authors": [
      "Xue Xian Zheng",
      "Weihang Liu",
      "Xin Lou",
      "Stefan Vlaski",
      "Tareq Al-Naffouri"
    ],
    "abstract": "This paper introduces an innovative error feedback framework designed to\nmitigate quantization noise in distributed graph filtering, where\ncommunications are constrained to quantized messages. It comes from error\nspectrum shaping techniques from state-space digital filters, and therefore\nestablishes connections between quantized filtering processes over different\ndomains. In contrast to existing error compensation methods, our framework\nquantitatively feeds back the quantization noise for exact compensation. We\nexamine the framework under three key scenarios: (i) deterministic graph\nfiltering, (ii) graph filtering over random graphs, and (iii) graph filtering\nwith random node-asynchronous updates. Rigorous theoretical analysis\ndemonstrates that the proposed framework significantly reduces the effect of\nquantization noise, and we provide closed-form solutions for the optimal error\nfeedback coefficients. Moreover, this quantitative error feedback mechanism can\nbe seamlessly integrated into communication-efficient decentralized\noptimization frameworks, enabling lower error floors. Numerical experiments\nvalidate the theoretical results, consistently showing that our method\noutperforms conventional quantization strategies in terms of both accuracy and\nrobustness.",
    "pdf_url": "http://arxiv.org/pdf/2506.01404v1",
    "published": "2025-06-02T07:57:04+00:00",
    "categories": [
      "cs.LG",
      "cs.MA",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.02074v1",
    "title": "Evolution of Wormholes under f(R, T) Theory, the Karmarkar Condition and the Casimir Energy",
    "authors": [
      "Murat Metehan Turkoglu"
    ],
    "abstract": "In this study, both the evolution of wormholes (by examining both the energy\nconditions and using the TOV equations) and the effects of the Karmarkar\ncondition on the solutions obtained under certain specific cases were examined\nin the light of the $f(R,T)$ gravity theory, using two $f(R,T)$ functions\npredicted to describe the accelerated expansion of the universe. In this\ncontext, for the first time in the literature, a generalized shape function was\nobtained using the Karmarkar condition. It was observed that solutions of the\ntype $R-a_{1}^2/R+a_{2}g(T)$ satisfy the energy conditions (with the dominant\nenergy condition being partially satisfied), whereas solutions of the type\n$R+a_{1}^2R^2+a_{2}g(T)$ require the presence of exotic matter. In both cases,\nstable, static, and traversable wormhole solutions were obtained. By applying\nthe Karmarkar condition to the $R+a_{1}^2R^2+a_{2}g(T)$ type solutions, which\nviolate the energy conditions, the relationship between wormhole geometry and\nenergy conditions was investigated. The study examined whether the Karmarkar\ncondition eliminates the need for exotic matter, and it was found that the\nsolutions do not remove the necessity of exotic matter. Additionally, it was\ndemonstrated that a specific value of the parameter, ${\\beta}$, which\ndetermines the radial variation of the shape function, could ensure the\nstability of the wormhole throat with the aid of Casimir energy. In other\nwords, it is considered possible that the geometric evolution of the wormhole\nthroat could trigger the transition from positive energy (baryonic matter) to\nnegative energy (dark matter, dark energy, or other exotic matter) by inducing\nCasimir forces.",
    "pdf_url": "http://arxiv.org/pdf/2506.02074v1",
    "published": "2025-06-02T07:56:10+00:00",
    "categories": [
      "gr-qc",
      "astro-ph.CO"
    ],
    "primary_category": "gr-qc"
  },
  {
    "id": "http://arxiv.org/abs/2506.01403v1",
    "title": "High-Dimensional Regularized Additive Matrix Autoregressive Model",
    "authors": [
      "Debika Ghosh",
      "Samrat Roy",
      "Nilanjana Chakraborty"
    ],
    "abstract": "High-dimensional time series has diverse applications in econometrics and\nfinance. Recent models for capturing temporal dependence have employed a\nbilinear representation for matrix time series, or the Tucker-decomposition\nbased representation in case of tensor time series. A bilinear or\nTucker-decomposition based temporal effect is difficult to interpret on many\noccasions, along with its computational complexity due to the non-convex nature\nof the underlying optimization problem. Moreover, the existing matrix case\nmodels have not sufficiently explored the possibilities of imposing any\nlower-dimensional pattern on the transition matrices. In this work, we propose\na regularized additive matrix autoregressive model with additive interaction of\nrow-wise and column-wise temporal dependence, that offers more\ninterpretability, less computational burden due to its convex nature and\nestimation of the underlying low rank plus sparse pattern of its transition\nmatrices. We address the issue of identifiability of the various components in\nour model and subsequently develop a scalable Alternating Block Minimization\nalgorithm for estimating the parameters. We provide a finite sample error bound\nunder high-dimensional scaling for the model parameters. Finally, the efficacy\nof the proposed model is demonstrated on synthetic and real data.",
    "pdf_url": "http://arxiv.org/pdf/2506.01403v1",
    "published": "2025-06-02T07:54:03+00:00",
    "categories": [
      "stat.ME"
    ],
    "primary_category": "stat.ME"
  },
  {
    "id": "http://arxiv.org/abs/2506.01402v3",
    "title": "Sliding Ferroelectrics Induced Hybrid-Order Topological Phase Transitions",
    "authors": [
      "Ning-Jing Yang",
      "Jian-Min Zhang",
      "Xiao-Ping Li",
      "Zeying Zhang",
      "Zhi-Ming Yu",
      "Zhigao Huang",
      "Yugui Yao"
    ],
    "abstract": "We propose ferroelectric layer sliding as a new approach to realize and\nmanipulate topological quantum states in two-dimensional (2D) bilayer magnetic\nvan der Waals materials. We show that stacking monolayer ferromagnetic\ntopological states into layer-spin-locked bilayer antiferromagnetic structures,\nand introducing sliding ferroelectricity leads to asynchronous topological\nevolution of different layers (spins) owing to existence of polarization\npotentials, thereby giving rise to rich layer-resolved topological phases. As a\nspecific example, by means of a lattice model, we show that a bilayer magnetic\n2D second order topological insulator (SOTI) reveals an unrecognized\nspin-hybrid-order topological insulator after undergoing ferroelectric sliding.\nInterestingly, in such phase, the spin-up (top layer) and spin-down (bottom\nlayer) channels exhibit first-order and second-order topological properties,\nrespectively. Moreover, other topological phases such as SOTI, quantum spin\nHall insulator, quantum anomalous Hall insulator, and trivial insulator can\nalso emerge through changes in the parameters of the system, and the relevant\ntopological indices are also discussed. In terms of materials, based on first\nprinciples calculations, we predict material ScI2 can serve as an ideal\nplatform to realize our proposal. Further, we predict that the anomalous Nernst\neffect of these several topological phases exhibits distinct differences, and\ntherefore can be used as a signal for experimentally probing.",
    "pdf_url": "http://arxiv.org/pdf/2506.01402v3",
    "published": "2025-06-02T07:53:08+00:00",
    "categories": [
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2506.01401v2",
    "title": "Floquet Möbius topological insulators",
    "authors": [
      "Longwen Zhou",
      "Fan Zhang",
      "Jiaxin Pan"
    ],
    "abstract": "M\\\"obius topological insulators have dispersive edge bands with M\\\"obius\ntwists in momentum space, which are protected by the combination of chiral and\n$Z_2$-projective translational symmetries. In this work, we reveal a unique\ntype of M\\\"obius topological insulator, whose edge bands could twist around the\nquasienergy $\\pi$ of a periodically driven system and are thus of Floquet\norigin. By applying time-periodic quenches to an experimentally realized\nM\\\"obius insulator model, we obtain interconnected M\\\"obius edge bands around\nzero and $\\pi$ quasienergies, which can coexist with a gapped or gapless bulk.\nThese M\\\"obius bands are topologically characterized by a pair of generalized\nwinding numbers, which are integer-quantized due to an emergent chiral symmetry\nat a high-symmetry point in momentum space. Numerical investigations of the\nquasienergy and entanglement spectra provide consistent evidence for the\npresence of such M\\\"obius topological phases. A protocol based on the adiabatic\nswitching of edge-band populations is further introduced to dynamically\ncharacterize the topology of Floquet M\\\"obius edge bands. Our findings thus\nextend the scope of M\\\"obius topological phases to nonequilibrium settings and\nunveil a unique class of M\\\"obius-twisted topological edge states without\nstatic counterparts.",
    "pdf_url": "http://arxiv.org/pdf/2506.01401v2",
    "published": "2025-06-02T07:52:13+00:00",
    "categories": [
      "cond-mat.mes-hall",
      "quant-ph"
    ],
    "primary_category": "cond-mat.mes-hall"
  },
  {
    "id": "http://arxiv.org/abs/2506.01400v1",
    "title": "Unified Interference-Aware Water-Filling for QoS-Constrained Communication, Sensing, and JRC",
    "authors": [
      "Ahmed Naeem",
      "Anastassia Gharib",
      "Hüseyin Arslan"
    ],
    "abstract": "Water-filling (WF) algorithms are pivotal in maximizing capacity and spectral\nefficiency in multiple-input and multiple-output (MIMO) systems. However,\ntraditional WF approaches cater solely to communication requirements,\nneglecting the emerging heterogeneity of 6G, including sensing and joint\nradar-communication (JRC). As these diverse demands grow in importance and have\ndifferent Quality of Service (QoS) constraints, traditional WF becomes\ninadequate. Therefore, in this paper, we propose a unified interference-aware\nand QoS-constrained WF algorithm for systems with communication, sensing, and\nJRC. The proposed algorithm enables power allocation for multi-user MIMO\nsystems, effectively addressing interference and balancing the support for\nheterogeneous user requirements.",
    "pdf_url": "http://arxiv.org/pdf/2506.01400v1",
    "published": "2025-06-02T07:51:37+00:00",
    "categories": [
      "eess.SP"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2506.01399v1",
    "title": "Captivity-Escape Games as a Means for Safety in Online Motion Generation",
    "authors": [
      "Christopher Bohn",
      "Manuel Hess",
      "Sören Hohmann"
    ],
    "abstract": "This paper presents a method that addresses the conservatism, computational\neffort, and limited numerical accuracy of existing frameworks and methods that\nensure safety in online model-based motion generation, commonly referred to as\nfast and safe tracking. Computational limitations restrict online motion\nplanning to low-fidelity models. However, planning with low-fidelity models\ncompromises safety, as the dynamic feasibility of resulting reference\ntrajectories is not ensured. This potentially leads to unavoidable tracking\nerrors that may cause safety-critical constraint violations. Existing\nframeworks mitigate this safety risk by augmenting safety-critical constraints\nin motion planning by a safety margin that prevents constraint violations under\nworst-case tracking errors. However, the methods employed in these frameworks\ndetermine the safety margin based on a heuristically selected performance of\nthe planning model, which likely results in overly conservative reference\ntrajectories. Furthermore, these methods are computationally intensive, and the\nstate-of-the-art method is limited in numerical accuracy. We adopt a different\nperspective and address these limitations with a method that mitigates\nconservatism in existing frameworks by adapting the planning model performance\nto a given safety margin. Our method achieves numerical accuracy and requires\nsignificantly less computation time than existing methods by leveraging a\ncaptivity-escape game, which is a specific zero-sum differential game\nformulated in this paper. We demonstrate our method using a numerical example\nand compare it to the state of the art.",
    "pdf_url": "http://arxiv.org/pdf/2506.01399v1",
    "published": "2025-06-02T07:51:00+00:00",
    "categories": [
      "eess.SY",
      "cs.RO",
      "cs.SY"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2506.01398v1",
    "title": "Monte Carlo simulations of relativistic shock breakout from a stellar wind",
    "authors": [
      "Hirotaka Ito",
      "Amir Levinson",
      "Ehud Nakar",
      "Shigehiro Nagataki"
    ],
    "abstract": "We present Monte Carlo simulations of relativistic radiation-mediated shocks\n(RRMS) in the photon-starved regime, incorporating photon escape from the\nupstream region -- characterized by the escape fraction, $f_{esc}$ -- under a\nsteady-state assumption. These simulations, performed for shock Lorentz factors\n$\\Gamma_u = 2$, $6$, and $10$, are applicable to RRMS breakouts occurring in\nshallowly declining density profiles, such as stellar winds. We find that\nvigorous pair production acts as a thermostat, regulating the downstream\ntemperature to $\\sim 100$-$200~{\\rm keV}$, largely independent of $f_{\\rm\nesc}$. A subshock forms and strengthens with increasing $f_{esc}$. The escaping\nspectra consistently peak at $E_p \\approx 300$-$600~{\\rm keV}$ in the shock\nframe and deviate from a Wien distribution, exhibiting low-energy flattening\n($f_\\nu \\propto \\nu^0$) due to free-free emission and high-energy extensions\ncaused by inverse Compton scattering from subshock-heated pairs. While the\nexisting analytical model (Granot et al. 2018) reproduces the velocity\nstructure well at $\\Gamma_u = 2$, it significantly overestimates the shock\nwidth at higher Lorentz factors, particularly for $f_{esc} \\gtrsim$ a few $\\%$.\nBased on this finding, we provide updated predictions for breakout observables\nin wind environments for $\\Gamma_u \\gtrsim 6$. Notably, the duration of the\nrelativistic breakout becomes largely insensitive to the explosion energy and\nejecta mass, typically exceeding analytical predictions by orders of magnitude\nand capable of producing a $\\sim$200 s flash of MeV photons with a radiated\nenergy of $\\sim 7 \\times 10^{49}$ erg for an energetic explosion yielding\n$\\Gamma_{bo} \\sim 6$.",
    "pdf_url": "http://arxiv.org/pdf/2506.01398v1",
    "published": "2025-06-02T07:50:22+00:00",
    "categories": [
      "astro-ph.HE"
    ],
    "primary_category": "astro-ph.HE"
  },
  {
    "id": "http://arxiv.org/abs/2506.02073v1",
    "title": "Flow2Code: Evaluating Large Language Models for Flowchart-based Code Generation Capability",
    "authors": [
      "Mengliang He",
      "Jiayi Zeng",
      "Yankai Jiang",
      "Wei Zhang",
      "Zeming Liu",
      "Xiaoming Shi",
      "Aimin Zhou"
    ],
    "abstract": "While large language models (LLMs) show promise in code generation, existing\nbenchmarks neglect the flowchart-based code generation. To promote further\nresearch on flowchart-based code generation, this work presents Flow2Code, a\nnovel benchmark for flowchart-based code generation evaluation. The evaluation\ndataset spans 15 programming languages and includes 5,622 code segments paired\nwith 16,866 flowcharts of three types: code, UML, and pseudocode. Extensive\nexperiments with 13 multimodal LLMs reveal that current LLMs can not generate\ncode based on flowcharts perfectly. Besides, experiment results show that the\nsupervised fine-tuning technique contributes greatly to the models'\nperformance. We publicly release our code and datasets at\nhttps://github.com/hml-github/Flow2Code.",
    "pdf_url": "http://arxiv.org/pdf/2506.02073v1",
    "published": "2025-06-02T07:48:57+00:00",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE"
  },
  {
    "id": "http://arxiv.org/abs/2506.02072v1",
    "title": "The Electron-Gamma Coincidence Setup DAGOBERT",
    "authors": [
      "B. Hesbacher",
      "G. Steinhilber",
      "J. Isaak",
      "N. Pietralla",
      "J. Birkhan",
      "M. L. Cortés",
      "D. H. Jakubassa-Amundsen",
      "I. Jurosevic",
      "P. von Neumann-Cosel",
      "M. Rech",
      "X. Roca-Maza",
      "D. Schneider"
    ],
    "abstract": "The QCLAM electron spectrometer at the S-DALINAC electron accelerator at\nTechnische Universit\\\"at Darmstadt has been extended by the DAGOBERT\n$\\gamma$-detector array consisting of fast timing and high efficiency\nLaBr$_3$:Ce detectors to perform electron-gamma coincidence measurements. The\nfunctionality of the setup and data acquisition system was demonstrated in a\ncommissioning measurement on $^{12}\\textrm{C}$ observing the $4.44\\,$MeV and\n$15.11\\,$MeV states. A medium-heavy nucleus, $^{96}\\textrm{Ru}$, has been\nstudied for the first time up to excitation energies of $15\\,$MeV using the\n$(e,e'\\gamma)$ reaction. In particular, the angular distribution of the $2_1^+$\nstate and the $\\gamma$-decay branching ratios of the mixed-symmetric $2_3^+$\nstate were observed. DAGOBERT@QCLAM is a new and worldwide unique setup for\nnuclear structure studies of excitation and decay using purely electromagnetic\nprobes, with a significantly improved sensitivity compared to previous\nexperiments.",
    "pdf_url": "http://arxiv.org/pdf/2506.02072v1",
    "published": "2025-06-02T07:46:23+00:00",
    "categories": [
      "physics.ins-det",
      "nucl-ex"
    ],
    "primary_category": "physics.ins-det"
  },
  {
    "id": "http://arxiv.org/abs/2506.01397v1",
    "title": "Geometry on the Gluing Locus of Two Surfaces",
    "authors": [
      "Li Junzhen"
    ],
    "abstract": "In this paper, we deal with the gluing of two surfaces, where the gluing\nlocus is assumed to be a curve. We consider a moving frame along the gluing\nlocus, and define developable surfaces with respect to the frame. Considering\ngeometric properties of these developable surfaces, we study the geometry of\ngluing two surfaces.",
    "pdf_url": "http://arxiv.org/pdf/2506.01397v1",
    "published": "2025-06-02T07:45:00+00:00",
    "categories": [
      "math.DG",
      "53A05, 57R45, 53A10"
    ],
    "primary_category": "math.DG"
  },
  {
    "id": "http://arxiv.org/abs/2506.01396v1",
    "title": "Mitigating Disparate Impact of Differentially Private Learning through Bounded Adaptive Clipping",
    "authors": [
      "Linzh Zhao",
      "Aki Rehn",
      "Mikko A. Heikkilä",
      "Razane Tajeddine",
      "Antti Honkela"
    ],
    "abstract": "Differential privacy (DP) has become an essential framework for\nprivacy-preserving machine learning. Existing DP learning methods, however,\noften have disparate impacts on model predictions, e.g., for minority groups.\nGradient clipping, which is often used in DP learning, can suppress larger\ngradients from challenging samples. We show that this problem is amplified by\nadaptive clipping, which will often shrink the clipping bound to tiny values to\nmatch a well-fitting majority, while significantly reducing the accuracy for\nothers. We propose bounded adaptive clipping, which introduces a tunable lower\nbound to prevent excessive gradient suppression. Our method improves the\naccuracy of the worst-performing class on average over 10 percentage points on\nskewed MNIST and Fashion MNIST compared to the unbounded adaptive clipping, and\nover 5 percentage points over constant clipping.",
    "pdf_url": "http://arxiv.org/pdf/2506.01396v1",
    "published": "2025-06-02T07:44:17+00:00",
    "categories": [
      "cs.LG",
      "cs.CR",
      "stat.ML",
      "I.2.6; K.4.2"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.08032v1",
    "title": "Tram Positioning with Map-Enabled GNSS Data Reconciliation",
    "authors": [
      "Jakub Kašpar",
      "Vít Fanta",
      "Vladimír Havlena"
    ],
    "abstract": "This paper presents an approach to tackle the problem of tram localization\nthrough utilizing a custom processing of Global Navigation Satellite System\n(GNSS) observables and the track map. The method is motivated by suboptimal\nperformance in dense urban environments where the direct line of sight to GNSS\nsatellites is often obscured which leads to multipath propagation of GNSS\nsignals. The presented concept is based upon the iterated extended Kalman\nfilter (IEKF) and has linear complexity (with respect to the number of GNSS\nmeasurements) as opposed to some other techniques mitigating the multipath\nsignal propagation. The technique is demonstrated both on a simulated example\nand real data. The root-mean-squared errors from the simulated ground truth\npositions show that the presented solution is able to improve performance\ncompared to a baseline localization approach. Similar result is achieved for\nthe experiment with real data, while treating orthogonal projections onto the\ntram track as the true position, which is unavailable in the realistic\nscenario. This proof-of-concept shows results which may be further improved\nwith implementation of a bank-of-models method or $\\chi^2$-based rejection of\noutlying GNSS pseudorange measurements.",
    "pdf_url": "http://arxiv.org/pdf/2506.08032v1",
    "published": "2025-06-02T07:44:17+00:00",
    "categories": [
      "eess.SY",
      "cs.SY",
      "eess.SP"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2506.01395v1",
    "title": "NoRe: Augmenting Journaling Experience with Generative AI for Music Creation",
    "authors": [
      "Joonyoung Park",
      "Hyewon Cho",
      "Hyehyun Chu",
      "Yeeun Lee",
      "Hajin Lim"
    ],
    "abstract": "Journaling has long been recognized for fostering emotional awareness and\nself-reflection, and recent advancements in generative AI offer new\nopportunities to create personalized music that can enhance these practices. In\nthis study, we explore how AI-generated music can augment the journaling\nexperience. Through a formative study, we examined journal writers' writing\npatterns, purposes, emotional regulation strategies, and the design\nrequirements for the system that augments journaling experience by\njournal-based AI-generated music. Based on these insights, we developed NoRe, a\nsystem that transforms journal entries into personalized music using generative\nAI. In a seven-day in-the-wild study (N=15), we investigated user engagement\nand perceived emotional effectiveness through system logs, surveys, and\ninterviews. Our findings suggest that journal-based music generation could\nsupport emotional reflection and provide vivid reminiscence of daily\nexperiences. Drawing from these findings, we discuss design implications for\ntailoring music to journal writers' emotional states and preferences.",
    "pdf_url": "http://arxiv.org/pdf/2506.01395v1",
    "published": "2025-06-02T07:43:42+00:00",
    "categories": [
      "cs.HC"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2506.01394v1",
    "title": "NTIRE 2025 the 2nd Restore Any Image Model (RAIM) in the Wild Challenge",
    "authors": [
      "Jie Liang",
      "Radu Timofte",
      "Qiaosi Yi",
      "Zhengqiang Zhang",
      "Shuaizheng Liu",
      "Lingchen Sun",
      "Rongyuan Wu",
      "Xindong Zhang",
      "Hui Zeng",
      "Lei Zhang"
    ],
    "abstract": "In this paper, we present a comprehensive overview of the NTIRE 2025\nchallenge on the 2nd Restore Any Image Model (RAIM) in the Wild. This challenge\nestablished a new benchmark for real-world image restoration, featuring diverse\nscenarios with and without reference ground truth. Participants were tasked\nwith restoring real-captured images suffering from complex and unknown\ndegradations, where both perceptual quality and fidelity were critically\nevaluated. The challenge comprised two tracks: (1) the low-light joint\ndenoising and demosaicing (JDD) task, and (2) the image detail\nenhancement/generation task. Each track included two sub-tasks. The first\nsub-task involved paired data with available ground truth, enabling\nquantitative evaluation. The second sub-task dealt with real-world yet unpaired\nimages, emphasizing restoration efficiency and subjective quality assessed\nthrough a comprehensive user study. In total, the challenge attracted nearly\n300 registrations, with 51 teams submitting more than 600 results. The\ntop-performing methods advanced the state of the art in image restoration and\nreceived unanimous recognition from all 20+ expert judges. The datasets used in\nTrack 1 and Track 2 are available at\nhttps://drive.google.com/drive/folders/1Mgqve-yNcE26IIieI8lMIf-25VvZRs_J and\nhttps://drive.google.com/drive/folders/1UB7nnzLwqDZOwDmD9aT8J0KVg2ag4Qae,\nrespectively. The official challenge pages for Track 1 and Track 2 can be found\nat https://codalab.lisn.upsaclay.fr/competitions/21334#learn_the_details and\nhttps://codalab.lisn.upsaclay.fr/competitions/21623#learn_the_details.",
    "pdf_url": "http://arxiv.org/pdf/2506.01394v1",
    "published": "2025-06-02T07:43:35+00:00",
    "categories": [
      "eess.IV",
      "cs.CV"
    ],
    "primary_category": "eess.IV"
  },
  {
    "id": "http://arxiv.org/abs/2506.01393v2",
    "title": "Improved Regret Bounds for Gaussian Process Upper Confidence Bound in Bayesian Optimization",
    "authors": [
      "Shogo Iwazaki"
    ],
    "abstract": "This paper addresses the Bayesian optimization problem (also referred to as\nthe Bayesian setting of the Gaussian process bandit), where the learner seeks\nto minimize the regret under a function drawn from a known Gaussian process\n(GP). Under a Mat\\'ern kernel with a certain degree of smoothness, we show that\nthe Gaussian process upper confidence bound (GP-UCB) algorithm achieves\n$\\tilde{O}(\\sqrt{T})$ cumulative regret with high probability. Furthermore, our\nanalysis yields $O(\\sqrt{T \\ln^2 T})$ regret under a squared exponential\nkernel. These results fill the gap between the existing regret upper bound for\nGP-UCB and the best-known bound provided by Scarlett (2018). The key idea in\nour proof is to capture the concentration behavior of the input sequence\nrealized by GP-UCB, enabling a more refined analysis of the GP's information\ngain.",
    "pdf_url": "http://arxiv.org/pdf/2506.01393v2",
    "published": "2025-06-02T07:38:58+00:00",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.01392v1",
    "title": "Sparse Imagination for Efficient Visual World Model Planning",
    "authors": [
      "Junha Chun",
      "Youngjoon Jeong",
      "Taesup Kim"
    ],
    "abstract": "World model based planning has significantly improved decision-making in\ncomplex environments by enabling agents to simulate future states and make\ninformed choices. However, ensuring the prediction accuracy of world models\noften demands substantial computational resources, posing a major challenge for\nreal-time applications. This computational burden is particularly restrictive\nin robotics, where resources are severely constrained. To address this\nlimitation, we propose a Sparse Imagination for Efficient Visual World Model\nPlanning, which enhances computational efficiency by reducing the number of\ntokens processed during forward prediction. Our method leverages a sparsely\ntrained vision-based world model based on transformers with randomized grouped\nattention strategy, allowing the model to adaptively adjust the number of\ntokens processed based on the computational resource. By enabling sparse\nimagination (rollout), our approach significantly accelerates planning while\nmaintaining high control fidelity. Experimental results demonstrate that sparse\nimagination preserves task performance while dramatically improving inference\nefficiency, paving the way for the deployment of world models in real-time\ndecision-making scenarios.",
    "pdf_url": "http://arxiv.org/pdf/2506.01392v1",
    "published": "2025-06-02T07:36:14+00:00",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2506.01391v2",
    "title": "AgentCPM-GUI: Building Mobile-Use Agents with Reinforcement Fine-Tuning",
    "authors": [
      "Zhong Zhang",
      "Yaxi Lu",
      "Yikun Fu",
      "Yupeng Huo",
      "Shenzhi Yang",
      "Yesai Wu",
      "Han Si",
      "Xin Cong",
      "Haotian Chen",
      "Yankai Lin",
      "Jie Xie",
      "Wei Zhou",
      "Wang Xu",
      "Yuanheng Zhang",
      "Zhou Su",
      "Zhongwu Zhai",
      "Xiaoming Liu",
      "Yudong Mei",
      "Jianming Xu",
      "Hongyan Tian",
      "Chongyi Wang",
      "Chi Chen",
      "Yuan Yao",
      "Zhiyuan Liu",
      "Maosong Sun"
    ],
    "abstract": "The recent progress of large language model agents has opened new\npossibilities for automating tasks through graphical user interfaces (GUIs),\nespecially in mobile environments where intelligent interaction can greatly\nenhance usability. However, practical deployment of such agents remains\nconstrained by several key challenges. Existing training data is often noisy\nand lack semantic diversity, which hinders the learning of precise grounding\nand planning. Models trained purely by imitation tend to overfit to seen\ninterface patterns and fail to generalize in unfamiliar scenarios. Moreover,\nmost prior work focuses on English interfaces while overlooks the growing\ndiversity of non-English applications such as those in the Chinese mobile\necosystem. In this work, we present AgentCPM-GUI, an 8B-parameter GUI agent\nbuilt for robust and efficient on-device GUI interaction. Our training pipeline\nincludes grounding-aware pre-training to enhance perception, supervised\nfine-tuning on high-quality Chinese and English trajectories to imitate\nhuman-like actions, and reinforcement fine-tuning with GRPO to improve\nreasoning capability. We also introduce a compact action space that reduces\noutput length and supports low-latency execution on mobile devices.\nAgentCPM-GUI achieves state-of-the-art performance on five public benchmarks\nand a new Chinese GUI benchmark called CAGUI, reaching $96.9\\%$ Type-Match and\n$91.3\\%$ Exact-Match. To facilitate reproducibility and further research, we\npublicly release all code, model checkpoint, and evaluation data.",
    "pdf_url": "http://arxiv.org/pdf/2506.01391v2",
    "published": "2025-06-02T07:30:29+00:00",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CV",
      "cs.HC",
      "I.2.8; I.2.7; I.2.10; H.5.2"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2506.01390v1",
    "title": "Dense clumps survive in the vicinity of R136 in 30 Doradus",
    "authors": [
      "M. T. Valdivia-Mena",
      "M. Rubio",
      "V. M. Kalari",
      "H. Saldaño",
      "A. Bolatto",
      "R. Indebetouw",
      "H. Zinnecker",
      "C. Herrera"
    ],
    "abstract": "Context: The young massive cluster R136 at the center of 30 Doradus (30 Dor)\nin the Large Magellanic Cloud (LMC) generates a cavity in the surrounding\nmolecular cloud. However, there is molecular gas between 2 and 10 pc in\nprojection from R136's center. The region, known as the Stapler nebula, hosts\nthe closest known molecular gas clouds to R136. Aims: We investigated the\nproperties of molecular gas in the Stapler nebula to better understand why\nthese clouds survive so close in projection to R136. Methods: We used Atacama\nLarge Millimeter/Sub-millimeter Array 7m observations in Band 7 (345 GHz) of\ncontinuum emission, $^{12}$CO and $^{13}$CO, together with dense gas tracers\nCS, HCO$^+$, and HCN. Our observations resolve the molecular clouds in the\nnebula into individual, parsec-sized clumps. We determined the physical\nproperties of the clumps using both dust and molecular emission, and compared\nthe emission properties observed close to R136 to other clouds in the LMC.\nResults: The densest clumps in our sample, where we observe CS, HCO$^+$, and\nHCN, are concentrated in a northwest-southeast diagonal seen as a dark dust\nlane in HST images. Resolved clumps have masses between $\\sim 200-2500$ \\Msun,\nand the values obtained using the virial theorem are larger than the masses\nobtained through $^{12}$CO and $^{12}$CO luminosity. The velocity dispersion of\nthe clumps is due both to self-gravity and the external pressure of the gas.\nClumps at the center of our map, which have detections of dense gas tracers\n($n_{crit}\\sim10^6$ cm$^{-3}$ and above), are spatially coincident with young\nstellar objects. Conclusions: The clumps' physical and chemical properties are\nconsistent with other clumps in 30 Dor. We suggest that these clumps are the\ndensest regions of a Molecular Cloud carved by the radiation of R136.",
    "pdf_url": "http://arxiv.org/pdf/2506.01390v1",
    "published": "2025-06-02T07:29:20+00:00",
    "categories": [
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2506.01389v1",
    "title": "Neural shape reconstruction from multiple views with static pattern projection",
    "authors": [
      "Ryo Furukawa",
      "Kota Nishihara",
      "Hiroshi Kawasaki"
    ],
    "abstract": "Active-stereo-based 3D shape measurement is crucial for various purposes,\nsuch as industrial inspection, reverse engineering, and medical systems, due to\nits strong ability to accurately acquire the shape of textureless objects.\nActive stereo systems typically consist of a camera and a pattern projector,\ntightly fixed to each other, and precise calibration between a camera and a\nprojector is required, which in turn decreases the usability of the system. If\na camera and a projector can be freely moved during shape scanning process, it\nwill drastically increase the convenience of the usability of the system. To\nrealize it, we propose a technique to recover the shape of the target object by\ncapturing multiple images while both the camera and the projector are in\nmotion, and their relative poses are auto-calibrated by our neural\nsigned-distance-field (NeuralSDF) using novel volumetric differential rendering\ntechnique. In the experiment, the proposed method is evaluated by performing 3D\nreconstruction using both synthetic and real images.",
    "pdf_url": "http://arxiv.org/pdf/2506.01389v1",
    "published": "2025-06-02T07:29:18+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.01388v1",
    "title": "VRD-IU: Lessons from Visually Rich Document Intelligence and Understanding",
    "authors": [
      "Yihao Ding",
      "Soyeon Caren Han",
      "Yan Li",
      "Josiah Poon"
    ],
    "abstract": "Visually Rich Document Understanding (VRDU) has emerged as a critical field\nin document intelligence, enabling automated extraction of key information from\ncomplex documents across domains such as medical, financial, and educational\napplications. However, form-like documents pose unique challenges due to their\ncomplex layouts, multi-stakeholder involvement, and high structural\nvariability. Addressing these issues, the VRD-IU Competition was introduced,\nfocusing on extracting and localizing key information from multi-format forms\nwithin the Form-NLU dataset, which includes digital, printed, and handwritten\ndocuments. This paper presents insights from the competition, which featured\ntwo tracks: Track A, emphasizing entity-based key information retrieval, and\nTrack B, targeting end-to-end key information localization from raw document\nimages. With over 20 participating teams, the competition showcased various\nstate-of-the-art methodologies, including hierarchical decomposition,\ntransformer-based retrieval, multimodal feature fusion, and advanced object\ndetection techniques. The top-performing models set new benchmarks in VRDU,\nproviding valuable insights into document intelligence.",
    "pdf_url": "http://arxiv.org/pdf/2506.01388v1",
    "published": "2025-06-02T07:28:28+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.04256v1",
    "title": "Estimating properties of a homogeneous bounded soil using machine learning models",
    "authors": [
      "Konstantinos Kalimeris",
      "Leonidas Mindrinos",
      "Nikolaos Pallikarakis"
    ],
    "abstract": "This work focuses on estimating soil properties from water moisture\nmeasurements. We consider simulated data generated by solving the\ninitial-boundary value problem governing vertical infiltration in a\nhomogeneous, bounded soil profile, with the usage of the Fokas method. To\naddress the parameter identification problem, which is formulated as a\ntwo-output regression task, we explore various machine learning models. The\nperformance of each model is assessed under different data conditions: full,\nnoisy, and limited. Overall, the prediction of diffusivity $D$ tends to be more\naccurate than that of hydraulic conductivity $K.$ Among the models considered,\nSupport Vector Machines (SVMs) and Neural Networks (NNs) demonstrate the\nhighest robustness, achieving near-perfect accuracy and minimal errors.",
    "pdf_url": "http://arxiv.org/pdf/2506.04256v1",
    "published": "2025-06-02T07:25:03+00:00",
    "categories": [
      "physics.geo-ph",
      "cs.LG"
    ],
    "primary_category": "physics.geo-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.01387v1",
    "title": "Multi Part Deployment of Neural Network",
    "authors": [
      "Paritosh Ranjan",
      "Surajit Majumder",
      "Prodip Roy"
    ],
    "abstract": "The increasing scale of modern neural networks, exemplified by architectures\nfrom IBM (530 billion neurons) and Google (500 billion parameters), presents\nsignificant challenges in terms of computational cost and infrastructure\nrequirements. As deep neural networks continue to grow, traditional training\nparadigms relying on monolithic GPU clusters become increasingly unsustainable.\nThis paper proposes a distributed system architecture that partitions a neural\nnetwork across multiple servers, each responsible for a subset of neurons.\nNeurons are classified as local or remote, with inter-server connections\nmanaged via a metadata-driven lookup mechanism. A Multi-Part Neural Network\nExecution Engine facilitates seamless execution and training across distributed\npartitions by dynamically resolving and invoking remote neurons using stored\nmetadata. All servers share a unified model through a network file system\n(NFS), ensuring consistency during parallel updates. A Neuron Distributor\nmodule enables flexible partitioning strategies based on neuron count,\npercentage, identifiers, or network layers. This architecture enables\ncost-effective, scalable deployment of deep learning models on cloud\ninfrastructure, reducing dependency on high-performance centralized compute\nresources.",
    "pdf_url": "http://arxiv.org/pdf/2506.01387v1",
    "published": "2025-06-02T07:24:29+00:00",
    "categories": [
      "cs.LG",
      "cs.NE"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.01386v2",
    "title": "ThinkEval: Practical Evaluation of Knowledge Leakage in LLM Editing using Thought-based Knowledge Graphs",
    "authors": [
      "Manit Baser",
      "Dinil Mon Divakaran",
      "Mohan Gurusamy"
    ],
    "abstract": "Robust model-editing techniques are essential for deploying large language\nmodels (LLMs) in practical applications, to enable cost-effective ways to deal\nwith challenges such as privacy breaches, bias mitigation and misinformation\nspread. For example, an LLM-based healthcare assistance may need to update\nout-dated or incorrect knowledge to prevent harmful recommendations. However,\nmany editing techniques focus on isolated facts, which critically fail to\nprevent indirect knowledge leakage -- the unintended reconstruction of\nedited-out information through persistent causal links and contextual\nrelationships. To assist users in selecting the right editing technique, we\ndevelop and present ThinkEval, a framework to systematically quantify indirect\nknowledge leakage and ripple effects in model-editing. ThinkEval builds and\nemploys specialized knowledge graphs to analyze the causal structure of facts\nbefore and after editing. To support this approach, we present KnowGIC, a\nbenchmark dataset comprising multi-step reasoning paths that precisely measure\nthese complex knowledge transformation effects. We evaluate five editing\ntechniques: AlphaEdit, RECT, ROME, MEMIT, and PRUNE across multiple LLMs. Our\nresults show that these techniques struggle to balance indirect fact\nsuppression with the preservation of related knowledge, compromising the\ncontextual integrity of a model's knowledge. Our dataset is available at:\nhttps://anonymous.4open.science/r/KnowGIC.",
    "pdf_url": "http://arxiv.org/pdf/2506.01386v2",
    "published": "2025-06-02T07:24:12+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.01385v2",
    "title": "Spending Behavior and Economic Impacts of Urban Digital Consumption Vouchers",
    "authors": [
      "Ming-Huan Liou",
      "Shou-Yung Yin",
      "Hsiang-Wen Mao"
    ],
    "abstract": "This paper evaluates the Taipei Bear Vouchers 2.0 program using verified\nuser-level survey data and a regional input-output model to assess the\neffectiveness of consumption vouchers as a fiscal stimulus tool. We focus on\nthree key behavioral mechanisms: expenditure substitution, induced consumption,\nand the intensity of treatment through varying voucher face values. Our\nfindings show that voucher effectiveness differs by type. Accommodation\nvouchers stimulate the most additional spending due to low expenditure\nsubstitution and high induced consumption effects, while sports vouchers often\nreplace existing consumption. Increases in voucher value further enhance\nmarginal consumption, especially when this change is a part of unexpected\npolicy. Taking these behavioral responses into account, we find that the output\nmultiplier of the program rises significantly, and indirect benefits extend to\nuntargeted sectors through inter-industry linkages. These results highlight the\ncritical role of consumer behavior in shaping policy outcomes and offer\npractical guidance for designing more effective and targeted consumption\nvoucher programs.",
    "pdf_url": "http://arxiv.org/pdf/2506.01385v2",
    "published": "2025-06-02T07:21:51+00:00",
    "categories": [
      "econ.GN",
      "q-fin.EC"
    ],
    "primary_category": "econ.GN"
  },
  {
    "id": "http://arxiv.org/abs/2506.01384v1",
    "title": "Formal Security Analysis of SPV Clients Versus Home-Based Full Nodes in Bitcoin-Derived Systems",
    "authors": [
      "Craig Steven Wright"
    ],
    "abstract": "This paper presents a mathematically rigorous formal analysis of Simplified\nPayment Verification (SPV) clients, as specified in Section 8 of the original\nBitcoin white paper, versus non-mining full nodes operated by home users. It\ndefines security as resistance to divergence from global consensus and models\ntransaction acceptance, enforcement capability, and divergence probability\nunder adversarial conditions. The results demonstrate that SPV clients, despite\nomitting script verification, are cryptographically sufficient under\nhonest-majority assumptions and topologically less vulnerable to attack than\nstructurally passive, non-enforcing full nodes. The paper introduces new axioms\non behavioral divergence and communication topology, proving that home-based\nfull nodes increase systemic entropy without contributing to consensus\nintegrity. Using a series of formally defined lemmas, propositions, and Monte\nCarlo simulation results, it is shown that SPV clients represent the rational\nequilibrium strategy for non-mining participants. This challenges the\nprevailing narrative that home validators enhance network security, providing\nformal and operational justifications for the sufficiency of SPV models.",
    "pdf_url": "http://arxiv.org/pdf/2506.01384v1",
    "published": "2025-06-02T07:20:25+00:00",
    "categories": [
      "cs.CR",
      "cs.DC",
      "cs.GT",
      "cs.IT",
      "math.IT",
      "68M10, 68Q85, 91A40, 94A60",
      "F.1.2; F.2.2; K.6.5"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2506.01383v1",
    "title": "Many-body critical non-Hermitian skin effect",
    "authors": [
      "Yi Qin",
      "Yee Sin Ang",
      "Ching Hua Lee",
      "Linhu Li"
    ],
    "abstract": "Criticality in non-Hermitian systems unveils unique phase transitions and\nscaling behaviors beyond Hermitian paradigms, offering new insights into the\ninterplay between gain/loss, non-reciprocity, and complex energy spectra. In\nthis paper, we uncover a new class of many-body critical non-Hermitian skin\neffect (CSE) originating from the interplay between multiple non-Hermitian\npumping channels and Hubbard interactions. In particular, criticality in the\nreal-to-complex transitions can selectively emerge within the subspace of bound\nstates or scattering states, as well as their interacting admixtures. These\nmechanisms possess no single-particle analog and can be diagnosed through a\nspecially defined correlation function. As more particles are involved,\nhigher-order CSEs naturally arise, with greatly enhanced effective coupling\nstrengths and hence greater experimental accessibility. Our results reveal an\nenriched landscape of non-Hermitian critical phenomena in interacting many-body\nsystems, and pave the way for investigating unconventional non-Hermitian\ncriticality in the context of various interaction-induced particle clustering\nconfigurations.",
    "pdf_url": "http://arxiv.org/pdf/2506.01383v1",
    "published": "2025-06-02T07:20:17+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.01382v1",
    "title": "Enabling Scalable Distributed Beamforming via Networked LEO Satellites Towards 6G",
    "authors": [
      "Yuchen Zhang Seungnyun Kim",
      "Tareq Y. Al-Naffouri"
    ],
    "abstract": "In this paper, we propose scalable distributed beamforming schemes over low\nEarth orbit (LEO) satellite networks that rely solely on statistical channel\nstate information for downlink orthogonal frequency division multiplexing\nsystems. We begin by introducing the system model and presenting a pragmatic\nyet effective analog beamformer and user-scheduling design. We then derive a\nclosed-form lower bound on the ergodic sum rate, based on the hardening bound,\nfor the digital beamformer design. Next, we formulate a per-satellite\npower-constrained sum-rate maximization problem, whose centralized solution,\nobtained via the weighted minimum mean squared error (WMMSE) framework,\nestablishes performance limits and motivates decentralized strategies. We\nsubsequently introduce two decentralized optimization schemes, based on\napproximating the hardening bound and decentralizing the WMMSE framework, for\nrepresentative inter-satellite link topologies. In the Ring scheme, satellites\nupdate beamformers locally and exchange intermediate parameters sequentially.\nIn the Star scheme, edge satellites update beamformers locally and in parallel,\nachieving consensus on intermediate parameters at a central satellite using a\npenalty-dual decomposition framework. Extensive simulations demonstrate that\nour distributed designs achieve near-centralized performance with superior\nscalability, substantially outperforming simple closed-form beamformers and\nsingle-satellite baselines in sum rate. Additionally, the delay-overhead\ntrade-off between the two topologies is revealed.",
    "pdf_url": "http://arxiv.org/pdf/2506.01382v1",
    "published": "2025-06-02T07:18:50+00:00",
    "categories": [
      "eess.SP"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2506.01381v1",
    "title": "AdaRewriter: Unleashing the Power of Prompting-based Conversational Query Reformulation via Test-Time Adaptation",
    "authors": [
      "Yilong Lai",
      "Jialong Wu",
      "Zhenglin Wang",
      "Deyu Zhou"
    ],
    "abstract": "Prompting-based conversational query reformulation has emerged as a powerful\napproach for conversational search, refining ambiguous user queries into\nstandalone search queries. Best-of-N reformulation over the generated\ncandidates via prompting shows impressive potential scaling capability.\nHowever, both the previous tuning methods (training time) and adaptation\napproaches (test time) can not fully unleash their benefits. In this paper, we\npropose AdaRewriter, a novel framework for query reformulation using an\noutcome-supervised reward model via test-time adaptation. By training a\nlightweight reward model with contrastive ranking loss, AdaRewriter selects the\nmost promising reformulation during inference. Notably, it can operate\neffectively in black-box systems, including commercial LLM APIs. Experiments on\nfive conversational search datasets show that AdaRewriter significantly\noutperforms the existing methods across most settings, demonstrating the\npotential of test-time adaptation for conversational query reformulation.",
    "pdf_url": "http://arxiv.org/pdf/2506.01381v1",
    "published": "2025-06-02T07:18:26+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.01380v2",
    "title": "Playing with Transformer at 30+ FPS via Next-Frame Diffusion",
    "authors": [
      "Xinle Cheng",
      "Tianyu He",
      "Jiayi Xu",
      "Junliang Guo",
      "Di He",
      "Jiang Bian"
    ],
    "abstract": "Autoregressive video models offer distinct advantages over bidirectional\ndiffusion models in creating interactive video content and supporting streaming\napplications with arbitrary duration. In this work, we present Next-Frame\nDiffusion (NFD), an autoregressive diffusion transformer that incorporates\nblock-wise causal attention, enabling iterative sampling and efficient\ninference via parallel token generation within each frame. Nonetheless,\nachieving real-time video generation remains a significant challenge for such\nmodels, primarily due to the high computational cost associated with diffusion\nsampling and the hardware inefficiencies inherent to autoregressive generation.\nTo address this, we introduce two innovations: (1) We extend consistency\ndistillation to the video domain and adapt it specifically for video models,\nenabling efficient inference with few sampling steps; (2) To fully leverage\nparallel computation, motivated by the observation that adjacent frames often\nshare the identical action input, we propose speculative sampling. In this\napproach, the model generates next few frames using current action input, and\ndiscard speculatively generated frames if the input action differs. Experiments\non a large-scale action-conditioned video generation benchmark demonstrate that\nNFD beats autoregressive baselines in terms of both visual quality and sampling\nefficiency. We, for the first time, achieves autoregressive video generation at\nover 30 Frames Per Second (FPS) on an A100 GPU using a 310M model.",
    "pdf_url": "http://arxiv.org/pdf/2506.01380v2",
    "published": "2025-06-02T07:16:01+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.01379v1",
    "title": "RadarSplat: Radar Gaussian Splatting for High-Fidelity Data Synthesis and 3D Reconstruction of Autonomous Driving Scenes",
    "authors": [
      "Pou-Chun Kung",
      "Skanda Harisha",
      "Ram Vasudevan",
      "Aline Eid",
      "Katherine A. Skinner"
    ],
    "abstract": "High-Fidelity 3D scene reconstruction plays a crucial role in autonomous\ndriving by enabling novel data generation from existing datasets. This allows\nsimulating safety-critical scenarios and augmenting training datasets without\nincurring further data collection costs. While recent advances in radiance\nfields have demonstrated promising results in 3D reconstruction and sensor data\nsynthesis using cameras and LiDAR, their potential for radar remains largely\nunexplored. Radar is crucial for autonomous driving due to its robustness in\nadverse weather conditions like rain, fog, and snow, where optical sensors\noften struggle. Although the state-of-the-art radar-based neural representation\nshows promise for 3D driving scene reconstruction, it performs poorly in\nscenarios with significant radar noise, including receiver saturation and\nmultipath reflection. Moreover, it is limited to synthesizing preprocessed,\nnoise-excluded radar images, failing to address realistic radar data synthesis.\nTo address these limitations, this paper proposes RadarSplat, which integrates\nGaussian Splatting with novel radar noise modeling to enable realistic radar\ndata synthesis and enhanced 3D reconstruction. Compared to the\nstate-of-the-art, RadarSplat achieves superior radar image synthesis (+3.4 PSNR\n/ 2.6x SSIM) and improved geometric reconstruction (-40% RMSE / 1.5x Accuracy),\ndemonstrating its effectiveness in generating high-fidelity radar data and\nscene reconstruction. A project page is available at\nhttps://umautobots.github.io/radarsplat.",
    "pdf_url": "http://arxiv.org/pdf/2506.01379v1",
    "published": "2025-06-02T07:14:27+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.01378v1",
    "title": "From Turbulence to Tranquility: AI-Driven Low-Altitude Network",
    "authors": [
      "Kürşat Tekbıyık",
      "Amir Hossein Fahim Raouf",
      "İsmail Güvenç",
      "Mingzhe Chen",
      "Güneş Karabulut Kurt",
      "Antoine Lesage-Landry"
    ],
    "abstract": "Low Altitude Economy (LAE) networks own transformative potential in urban\nmobility, emergency response, and aerial logistics. However, these networks\nface significant challenges in spectrum management, interference mitigation,\nand real-time coordination across dynamic and resource-constrained\nenvironments. After addressing these challenges, this study explores three core\nelements for enabling intelligent LAE networks as follows machine\nlearning-based spectrum sensing and coexistence, artificial intelligence\n(AI)-optimized resource allocation and trajectory planning, and testbed-driven\nvalidation and standardization. We highlight how federated and reinforcement\nlearning techniques support decentralized, adaptive decision-making under\nmobility and energy constraints. In addition, we discuss the role of real-world\nplatforms such as AERPAW in bridging the gap between simulation and deployment\nand enabling iterative system refinement under realistic conditions. This study\naims to provide a forward-looking roadmap toward developing efficient and\ninteroperable AI-driven LAE ecosystems.",
    "pdf_url": "http://arxiv.org/pdf/2506.01378v1",
    "published": "2025-06-02T07:12:44+00:00",
    "categories": [
      "eess.SP",
      "cs.LG"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2506.01377v1",
    "title": "Scheduling Techniques of AI Models on Modern Heterogeneous Edge GPU -- A Critical Review",
    "authors": [
      "Ashiyana Abdul Majeed",
      "Mahmoud Meribout"
    ],
    "abstract": "In recent years, the development of specialized edge computing devices has\nsignificantly increased, driven by the growing demand for AI models. These\ndevices, such as the NVIDIA Jetson series, must efficiently handle increased\ndata processing and storage requirements. However, despite these advancements,\nthere remains a lack of frameworks that automate the optimal execution of\noptimal execution of deep neural network (DNN). Therefore, efforts have been\nmade to create schedulers that can manage complex data processing needs while\nensuring the efficient utilization of all available accelerators within these\ndevices, including the CPU, GPU, deep learning accelerator (DLA), programmable\nvision accelerator (PVA), and video image compositor (VIC). Such schedulers\nwould maximize the performance of edge computing systems, crucial in\nresource-constrained environments. This paper aims to comprehensively review\nthe various DNN schedulers implemented on NVIDIA Jetson devices. It examines\ntheir methodologies, performance, and effectiveness in addressing the demands\nof modern AI workloads. By analyzing these schedulers, this review highlights\nthe current state of the research in the field. It identifies future research\nand development areas, further enhancing edge computing devices' capabilities.",
    "pdf_url": "http://arxiv.org/pdf/2506.01377v1",
    "published": "2025-06-02T07:11:10+00:00",
    "categories": [
      "cs.DC",
      "cs.AR"
    ],
    "primary_category": "cs.DC"
  },
  {
    "id": "http://arxiv.org/abs/2506.01376v1",
    "title": "Modeling All-Atom Glycan Structures via Hierarchical Message Passing and Multi-Scale Pre-training",
    "authors": [
      "Minghao Xu",
      "Jiaze Song",
      "Keming Wu",
      "Xiangxin Zhou",
      "Bin Cui",
      "Wentao Zhang"
    ],
    "abstract": "Understanding the various properties of glycans with machine learning has\nshown some preliminary promise. However, previous methods mainly focused on\nmodeling the backbone structure of glycans as graphs of monosaccharides (i.e.,\nsugar units), while they neglected the atomic structures underlying each\nmonosaccharide, which are actually important indicators of glycan properties.\nWe fill this blank by introducing the GlycanAA model for All-Atom-wise Glycan\nmodeling. GlycanAA models a glycan as a heterogeneous graph with monosaccharide\nnodes representing its global backbone structure and atom nodes representing\nits local atomic-level structures. Based on such a graph, GlycanAA performs\nhierarchical message passing to capture from local atomic-level interactions to\nglobal monosaccharide-level interactions. To further enhance model capability,\nwe pre-train GlycanAA on a high-quality unlabeled glycan dataset, deriving the\nPreGlycanAA model. We design a multi-scale mask prediction algorithm to endow\nthe model about different levels of dependencies in a glycan. Extensive\nbenchmark results show the superiority of GlycanAA over existing glycan\nencoders and verify the further improvements achieved by PreGlycanAA. We\nmaintain all resources at https://github.com/kasawa1234/GlycanAA",
    "pdf_url": "http://arxiv.org/pdf/2506.01376v1",
    "published": "2025-06-02T07:08:39+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.01375v2",
    "title": "Generative Next POI Recommendation with Semantic ID",
    "authors": [
      "Dongsheng Wang",
      "Yuxi Huang",
      "Shen Gao",
      "Yifan Wang",
      "Chengrui Huang",
      "Shuo Shang"
    ],
    "abstract": "Point-of-interest (POI) recommendation systems aim to predict the next\ndestinations of user based on their preferences and historical check-ins.\nExisting generative POI recommendation methods usually employ random numeric\nIDs for POIs, limiting the ability to model semantic relationships between\nsimilar locations. In this paper, we propose Generative Next POI Recommendation\nwith Semantic ID (GNPR-SID), an LLM-based POI recommendation model with a novel\nsemantic POI ID (SID) representation method that enhances the semantic\nunderstanding of POI modeling. There are two key components in our GNPR-SID:\n(1) a Semantic ID Construction module that generates semantically rich POI IDs\nbased on semantic and collaborative features, and (2) a Generative POI\nRecommendation module that fine-tunes LLMs to predict the next POI using these\nsemantic IDs. By incorporating user interaction patterns and POI semantic\nfeatures into the semantic ID generation, our method improves the\nrecommendation accuracy and generalization of the model. To construct\nsemantically related SIDs, we propose a POI quantization method based on\nresidual quantized variational autoencoder, which maps POIs into a discrete\nsemantic space. We also propose a diversity loss to ensure that SIDs are\nuniformly distributed across the semantic space. Extensive experiments on three\nbenchmark datasets demonstrate that GNPR-SID substantially outperforms\nstate-of-the-art methods, achieving up to 16% improvement in recommendation\naccuracy.",
    "pdf_url": "http://arxiv.org/pdf/2506.01375v2",
    "published": "2025-06-02T07:04:16+00:00",
    "categories": [
      "cs.IR"
    ],
    "primary_category": "cs.IR"
  },
  {
    "id": "http://arxiv.org/abs/2506.01374v1",
    "title": "Compiler Optimization via LLM Reasoning for Efficient Model Serving",
    "authors": [
      "Sujun Tang",
      "Christopher Priebe",
      "Rohan Mahapatra",
      "Lianhui Qin",
      "Hadi Esmaeilzadeh"
    ],
    "abstract": "While model serving has unlocked unprecedented capabilities, the high cost of\nserving large-scale models continues to be a significant barrier to widespread\naccessibility and rapid innovation. Compiler optimizations have long driven\nsubstantial performance improvements, but existing compilers struggle with\nneural workloads due to the exponentially large and highly interdependent space\nof possible transformations. Although existing stochastic search techniques can\nbe effective, they are often sample-inefficient and fail to leverage the\nstructural context underlying compilation decisions. We set out to investigate\nthe research question of whether reasoning with large language models (LLMs),\nwithout any retraining, can leverage the context-aware decision space of\ncompiler optimization to significantly improve sample efficiency. To that end,\nwe introduce a novel compilation framework (dubbed REASONING COMPILER) that\nformulates optimization as a sequential, context-aware decision process, guided\nby a large language model and structured Monte Carlo tree search (MCTS). The\nLLM acts as a proposal mechanism, suggesting hardware-aware transformations\nthat reflect the current program state and accumulated performance feedback.\nMonte Carlo tree search (MCTS) incorporates the LLM-generated proposals to\nbalance exploration and exploitation, facilitating structured,\ncontext-sensitive traversal of the expansive compiler optimization space. By\nachieving substantial speedups with markedly fewer samples than leading neural\ncompilers, our approach demonstrates the potential of LLM-guided reasoning to\ntransform the landscape of compiler optimization.",
    "pdf_url": "http://arxiv.org/pdf/2506.01374v1",
    "published": "2025-06-02T07:02:46+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.PL"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.01373v1",
    "title": "No Train Yet Gain: Towards Generic Multi-Object Tracking in Sports and Beyond",
    "authors": [
      "Tomasz Stanczyk",
      "Seongro Yoon",
      "Francois Bremond"
    ],
    "abstract": "Multi-object tracking (MOT) is essential for sports analytics, enabling\nperformance evaluation and tactical insights. However, tracking in sports is\nchallenging due to fast movements, occlusions, and camera shifts. Traditional\ntracking-by-detection methods require extensive tuning, while\nsegmentation-based approaches struggle with track processing. We propose\nMcByte, a tracking-by-detection framework that integrates temporally propagated\nsegmentation mask as an association cue to improve robustness without per-video\ntuning. Unlike many existing methods, McByte does not require training, relying\nsolely on pre-trained models and object detectors commonly used in the\ncommunity. Evaluated on SportsMOT, DanceTrack, SoccerNet-tracking 2022 and\nMOT17, McByte demonstrates strong performance across sports and general\npedestrian tracking. Our results highlight the benefits of mask propagation for\na more adaptable and generalizable MOT approach. Code will be made available at\nhttps://github.com/tstanczyk95/McByte.",
    "pdf_url": "http://arxiv.org/pdf/2506.01373v1",
    "published": "2025-06-02T07:00:15+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.01372v2",
    "title": "AI Scientists Fail Without Strong Implementation Capability",
    "authors": [
      "Minjun Zhu",
      "Qiujie Xie",
      "Yixuan Weng",
      "Jian Wu",
      "Zhen Lin",
      "Linyi Yang",
      "Yue Zhang"
    ],
    "abstract": "The emergence of Artificial Intelligence (AI) Scientist represents a paradigm\nshift in scientific discovery, with large language models (LLMs) taking the\nlead as the primary executor in the entire scientific workflow from idea\ngeneration to experiment implementation. Recent AI Scientist studies\ndemonstrate sufficient capabilities for independent scientific discovery, with\nthe generated research reports gaining acceptance at the ICLR 2025 workshop and\nACL 2025, arguing that a human-level AI Scientist, capable of uncovering\nphenomena previously unknown to humans, may be imminent. Despite this\nsubstantial progress, AI Scientist has yet to produce a groundbreaking\nachievement in the domain of computer science on par with automated scientific\ntools. Based on extensive quantitative evidence from existing benchmarks in\ncomplex engineering tasks and a systematic evaluation assess 28 research papers\ngenerated by five advanced AI Scientist systems, we argue that \\textbf{the\nfundamental bottleneck for AI Scientists lies in their capability to execute\nthe requisite verification procedures.} Current AI Scientist systems lack the\nexecution capabilities needed to execute rigorous experiments and produce\nhigh-quality scientific papers. To better illustrate the root cause of this\n\\textbf{implementation gap}, we provide an in-depth discussion on the\nfundamental limitations of AI Scientist. This position paper aims to call for\nthe participants in the community to bridge the implementation gap.",
    "pdf_url": "http://arxiv.org/pdf/2506.01372v2",
    "published": "2025-06-02T06:59:10+00:00",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2506.01371v1",
    "title": "SVQA-R1: Reinforcing Spatial Reasoning in MLLMs via View-Consistent Reward Optimization",
    "authors": [
      "Peiyao Wang",
      "Haibin Ling"
    ],
    "abstract": "Spatial reasoning remains a critical yet underdeveloped capability in\nexisting vision-language models (VLMs), especially for Spatial Visual Question\nAnswering (Spatial VQA) tasks that require understanding relative positions,\ndistances, and object configurations. Inspired by the R1 paradigm introduced in\nDeepSeek-R1, which enhances reasoning in language models through rule-based\nreinforcement learning (RL), we propose SVQA-R1, the first framework to extend\nR1-style training to spatial VQA. In particular, we introduce Spatial-GRPO, a\nnovel group-wise RL strategy that constructs view-consistent rewards by\nperturbing spatial relations between objects, e.g., mirror flipping, thereby\nencouraging the model to develop a consistent and grounded understanding of\nspace. Our model, SVQA-R1, not only achieves dramatically improved accuracy on\nspatial VQA benchmarks but also exhibits interpretable reasoning paths even\nwithout using supervised fine-tuning (SFT) data. Extensive experiments and\nvisualization demonstrate the effectiveness of SVQA-R1 across multiple spatial\nreasoning benchmarks.",
    "pdf_url": "http://arxiv.org/pdf/2506.01371v1",
    "published": "2025-06-02T06:58:43+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.01370v1",
    "title": "PointT2I: LLM-based text-to-image generation via keypoints",
    "authors": [
      "Taekyung Lee",
      "Donggyu Lee",
      "Myungjoo Kang"
    ],
    "abstract": "Text-to-image (T2I) generation model has made significant advancements,\nresulting in high-quality images aligned with an input prompt. However, despite\nT2I generation's ability to generate fine-grained images, it still faces\nchallenges in accurately generating images when the input prompt contains\ncomplex concepts, especially human pose. In this paper, we propose PointT2I, a\nframework that effectively generates images that accurately correspond to the\nhuman pose described in the prompt by using a large language model (LLM).\nPointT2I consists of three components: Keypoint generation, Image generation,\nand Feedback system. The keypoint generation uses an LLM to directly generate\nkeypoints corresponding to a human pose, solely based on the input prompt,\nwithout external references. Subsequently, the image generation produces images\nbased on both the text prompt and the generated keypoints to accurately reflect\nthe target pose. To refine the outputs of the preceding stages, we incorporate\nan LLM-based feedback system that assesses the semantic consistency between the\ngenerated contents and the given prompts. Our framework is the first approach\nto leveraging LLM for keypoints-guided image generation without any\nfine-tuning, producing accurate pose-aligned images based solely on textual\nprompts.",
    "pdf_url": "http://arxiv.org/pdf/2506.01370v1",
    "published": "2025-06-02T06:55:20+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.01369v1",
    "title": "Incentivizing LLMs to Self-Verify Their Answers",
    "authors": [
      "Fuxiang Zhang",
      "Jiacheng Xu",
      "Chaojie Wang",
      "Ce Cui",
      "Yang Liu",
      "Bo An"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated remarkable progress in complex\nreasoning tasks through both post-training and test-time scaling laws. While\nprevalent test-time scaling approaches are often realized by using external\nreward models to guide the model generation process, we find only marginal\ngains can be acquired when scaling a model post-trained on specific reasoning\ntasks. We identify that the limited improvement stems from distribution\ndiscrepancies between the specific post-trained generator and the general\nreward model. To address this, we propose a framework that incentivizes LLMs to\nself-verify their own answers. By unifying answer generation and verification\nwithin a single reinforcement learning (RL) process, we train models that can\neffectively assess the correctness of their own solutions. The trained model\ncan further scale its performance during inference time by verifying its\ngenerations, without the need for external verifiers. We train our\nself-verification models based on Qwen2.5-Math-7B and\nDeepSeek-R1-Distill-Qwen-1.5B, demonstrating its capabilities across varying\nreasoning context lengths. Experiments on multiple mathematical reasoning\nbenchmarks show that our models can not only improve post-training performance\nbut also enable effective test-time scaling. Our code is available at\nhttps://github.com/mansicer/self-verification.",
    "pdf_url": "http://arxiv.org/pdf/2506.01369v1",
    "published": "2025-06-02T06:54:29+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.01368v1",
    "title": "Synthetic Data Augmentation using Pre-trained Diffusion Models for Long-tailed Food Image Classification",
    "authors": [
      "GaYeon Koh",
      "Hyun-Jic Oh",
      "Jeonghyun Noh",
      "Won-Ki Jeong"
    ],
    "abstract": "Deep learning-based food image classification enables precise identification\nof food categories, further facilitating accurate nutritional analysis.\nHowever, real-world food images often show a skewed distribution, with some\nfood types being more prevalent than others. This class imbalance can be\nproblematic, causing models to favor the majority (head) classes with overall\nperformance degradation for the less common (tail) classes. Recently, synthetic\ndata augmentation using diffusion-based generative models has emerged as a\npromising solution to address this issue. By generating high-quality synthetic\nimages, these models can help uniformize the data distribution, potentially\nimproving classification performance. However, existing approaches face\nchallenges: fine-tuning-based methods need a uniformly distributed dataset,\nwhile pre-trained model-based approaches often overlook inter-class separation\nin synthetic data. In this paper, we propose a two-stage synthetic data\naugmentation framework, leveraging pre-trained diffusion models for long-tailed\nfood classification. We generate a reference set conditioned by a positive\nprompt on the generation target and then select a class that shares similar\nfeatures with the generation target as a negative prompt. Subsequently, we\ngenerate a synthetic augmentation set using positive and negative prompt\nconditions by a combined sampling strategy that promotes intra-class diversity\nand inter-class separation. We demonstrate the efficacy of the proposed method\non two long-tailed food benchmark datasets, achieving superior performance\ncompared to previous works in terms of top-1 accuracy.",
    "pdf_url": "http://arxiv.org/pdf/2506.01368v1",
    "published": "2025-06-02T06:51:28+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.01367v1",
    "title": "MMD-Flagger: Leveraging Maximum Mean Discrepancy to Detect Hallucinations",
    "authors": [
      "Kensuke Mitsuzawa",
      "Damien Garreau"
    ],
    "abstract": "Large language models (LLMs) have become pervasive in our everyday life. Yet,\na fundamental obstacle prevents their use in many critical applications: their\npropensity to generate fluent, human-quality content that is not grounded in\nreality. The detection of such hallucinations is thus of the highest\nimportance. In this work, we propose a new method to flag hallucinated content,\nMMD-Flagger. It relies on Maximum Mean Discrepancy (MMD), a non-parametric\ndistance between distributions. On a high-level perspective, MMD-Flagger tracks\nthe MMD between the generated documents and documents generated with various\ntemperature parameters. We show empirically that inspecting the shape of this\ntrajectory is sufficient to detect most hallucinations. This novel method is\nbenchmarked on two machine translation datasets, on which it outperforms\nnatural competitors.",
    "pdf_url": "http://arxiv.org/pdf/2506.01367v1",
    "published": "2025-06-02T06:50:58+00:00",
    "categories": [
      "cs.CL",
      "stat.ML"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.01366v1",
    "title": "CLIP-driven rain perception: Adaptive deraining with pattern-aware network routing and mask-guided cross-attention",
    "authors": [
      "Cong Guan",
      "Osamu Yoshie"
    ],
    "abstract": "Existing deraining models process all rainy images within a single network.\nHowever, different rain patterns have significant variations, which makes it\nchallenging for a single network to handle diverse types of raindrops and\nstreaks. To address this limitation, we propose a novel CLIP-driven rain\nperception network (CLIP-RPN) that leverages CLIP to automatically perceive\nrain patterns by computing visual-language matching scores and adaptively\nrouting to sub-networks to handle different rain patterns, such as varying\nraindrop densities, streak orientations, and rainfall intensity. CLIP-RPN\nestablishes semantic-aware rain pattern recognition through CLIP's cross-modal\nvisual-language alignment capabilities, enabling automatic identification of\nprecipitation characteristics across different rain scenarios. This rain\npattern awareness drives an adaptive subnetwork routing mechanism where\nspecialized processing branches are dynamically activated based on the detected\nrain type, significantly enhancing the model's capacity to handle diverse\nrainfall conditions. Furthermore, within sub-networks of CLIP-RPN, we introduce\na mask-guided cross-attention mechanism (MGCA) that predicts precise rain masks\nat multi-scale to facilitate contextual interactions between rainy regions and\nclean background areas by cross-attention. We also introduces a dynamic loss\nscheduling mechanism (DLS) to adaptively adjust the gradients for the\noptimization process of CLIP-RPN. Compared with the commonly used $l_1$ or\n$l_2$ loss, DLS is more compatible with the inherent dynamics of the network\ntraining process, thus achieving enhanced outcomes. Our method achieves\nstate-of-the-art performance across multiple datasets, particularly excelling\nin complex mixed datasets.",
    "pdf_url": "http://arxiv.org/pdf/2506.01366v1",
    "published": "2025-06-02T06:49:04+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.01365v1",
    "title": "Attention Is Not Always the Answer: Optimizing Voice Activity Detection with Simple Feature Fusion",
    "authors": [
      "Kumud Tripathi",
      "Chowdam Venkata Kumar",
      "Pankaj Wasnik"
    ],
    "abstract": "Voice Activity Detection (VAD) plays a key role in speech processing, often\nutilizing hand-crafted or neural features. This study examines the\neffectiveness of Mel-Frequency Cepstral Coefficients (MFCCs) and pre-trained\nmodel (PTM) features, including wav2vec 2.0, HuBERT, WavLM, UniSpeech, MMS, and\nWhisper. We propose FusionVAD, a unified framework that combines both feature\ntypes using three fusion strategies: concatenation, addition, and\ncross-attention (CA). Experimental results reveal that simple fusion\ntechniques, particularly addition, outperform CA in both accuracy and\nefficiency. Fusion-based models consistently surpass single-feature models,\nhighlighting the complementary nature of MFCCs and PTM features. Notably, our\nbest-performing fusion model exceeds the state-of-the-art Pyannote across\nmultiple datasets, achieving an absolute average improvement of 2.04%. These\nresults confirm that simple feature fusion enhances VAD robustness while\nmaintaining computational efficiency.",
    "pdf_url": "http://arxiv.org/pdf/2506.01365v1",
    "published": "2025-06-02T06:47:42+00:00",
    "categories": [
      "cs.SD",
      "cs.CL",
      "eess.AS"
    ],
    "primary_category": "cs.SD"
  },
  {
    "id": "http://arxiv.org/abs/2506.01364v1",
    "title": "Unraveling Spatio-Temporal Foundation Models via the Pipeline Lens: A Comprehensive Review",
    "authors": [
      "Yuchen Fang",
      "Hao Miao",
      "Yuxuan Liang",
      "Liwei Deng",
      "Yue Cui",
      "Ximu Zeng",
      "Yuyang Xia",
      "Yan Zhao",
      "Torben Bach Pedersen",
      "Christian S. Jensen",
      "Xiaofang Zhou",
      "Kai Zheng"
    ],
    "abstract": "Spatio-temporal deep learning models aims to utilize useful patterns in such\ndata to support tasks like prediction. However, previous deep learning models\ndesigned for specific tasks typically require separate training for each use\ncase, leading to increased computational and storage costs. To address this\nissue, spatio-temporal foundation models have emerged, offering a unified\nframework capable of solving multiple spatio-temporal tasks. These foundation\nmodels achieve remarkable success by learning general knowledge with\nspatio-temporal data or transferring the general capabilities of pre-trained\nlanguage models. While previous surveys have explored spatio-temporal data and\nmethodologies separately, they have ignored a comprehensive examination of how\nfoundation models are designed, selected, pre-trained, and adapted. As a\nresult, the overall pipeline for spatio-temporal foundation models remains\nunclear. To bridge this gap, we innovatively provide an up-to-date review of\nprevious spatio-temporal foundation models from the pipeline perspective. The\npipeline begins with an introduction to different types of spatio-temporal\ndata, followed by details of data preprocessing and embedding techniques. The\npipeline then presents a novel data property taxonomy to divide existing\nmethods according to data sources and dependencies, providing efficient and\neffective model design and selection for researchers. On this basis, we further\nillustrate the training objectives of primitive models, as well as the\nadaptation techniques of transferred models. Overall, our survey provides a\nclear and structured pipeline to understand the connection between core\nelements of spatio-temporal foundation models while guiding researchers to get\nstarted quickly. Additionally, we introduce emerging opportunities such as\nmulti-objective training in the field of spatio-temporal foundation models.",
    "pdf_url": "http://arxiv.org/pdf/2506.01364v1",
    "published": "2025-06-02T06:46:42+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.01363v1",
    "title": "A flexible and interoperable high-performance Lanczos-based solver for generic quantum impurity problems: upgrading EDIpack",
    "authors": [
      "Lorenzo Crippa",
      "Igor Krivenko",
      "Samuele Giuli",
      "Gabriele Bellomia",
      "Alexander Kowalski",
      "Francesco Petocchi",
      "Alberto Scazzola",
      "Markus Wallerberger",
      "Giacomo Mazza",
      "Luca de Medici",
      "Giorgio Sangiovanni",
      "Massimo Capone",
      "Adriano Amaricci"
    ],
    "abstract": "EDIpack is a flexible, high-performance numerical library using Lanczos-based\nexact diagonalization to solve generic quantum impurity problems, such as those\nintroduced in Dynamical Mean-Field Theory to describe extended strongly\ncorrelated materials. The library efficiently solves impurity problems allowing\nfor different broken-symmetry solutions, including superconductivity and\nfeaturing local spin-orbit coupling and/or electron-phonon coupling. The\nmodular architecture of the software not only provides Fortran APIs but also\nincludes bindings to C/C++, interfaces with Python and Julia or with TRIQS and\nW2Dynamics research platforms, thus ensuring unprecedented level of\ninter-operability. The outlook includes further extensions to study quantum\nmaterials and cold atoms quantum simulators, as well as quantum information\napplications.",
    "pdf_url": "http://arxiv.org/pdf/2506.01363v1",
    "published": "2025-06-02T06:45:21+00:00",
    "categories": [
      "cond-mat.str-el",
      "physics.comp-ph"
    ],
    "primary_category": "cond-mat.str-el"
  },
  {
    "id": "http://arxiv.org/abs/2506.01362v1",
    "title": "Generating Diverse Challenging Terrains for Legged Robots Using Quality-Diversity Algorithm",
    "authors": [
      "Arthur Esquerre-Pourtère",
      "Minsoo Kim",
      "Jaeheung Park"
    ],
    "abstract": "While legged robots have achieved significant advancements in recent years,\nensuring the robustness of their controllers on unstructured terrains remains\nchallenging. It requires generating diverse and challenging unstructured\nterrains to test the robot and discover its vulnerabilities. This topic remains\nunderexplored in the literature. This paper presents a Quality-Diversity\nframework to generate diverse and challenging terrains that uncover weaknesses\nin legged robot controllers. Our method, applied to both simulated bipedal and\nquadruped robots, produces an archive of terrains optimized to challenge the\ncontroller in different ways. Quantitative and qualitative analyses show that\nthe generated archive effectively contains terrains that the robots struggled\nto traverse, presenting different failure modes. Interesting results were\nobserved, including failure cases that were not necessarily expected.\nExperiments show that the generated terrains can also be used to improve\nRL-based controllers.",
    "pdf_url": "http://arxiv.org/pdf/2506.01362v1",
    "published": "2025-06-02T06:44:58+00:00",
    "categories": [
      "cs.RO",
      "cs.NE"
    ],
    "primary_category": "cs.RO"
  },
  {
    "id": "http://arxiv.org/abs/2506.02071v1",
    "title": "AI Data Development: A Scorecard for the System Card Framework",
    "authors": [
      "Tadesse K. Bahiru",
      "Haileleol Tibebu",
      "Ioannis A. Kakadiaris"
    ],
    "abstract": "Artificial intelligence has transformed numerous industries, from healthcare\nto finance, enhancing decision-making through automated systems. However, the\nreliability of these systems is mainly dependent on the quality of the\nunderlying datasets, raising ongoing concerns about transparency,\naccountability, and potential biases. This paper introduces a scorecard\ndesigned to evaluate the development of AI datasets, focusing on five key areas\nfrom the system card framework data development life cycle: data dictionary,\ncollection process, composition, motivation, and pre-processing. The method\nfollows a structured approach, using an intake form and scoring criteria to\nassess the quality and completeness of the data set. Applied to four diverse\ndatasets, the methodology reveals strengths and improvement areas. The results\nare compiled using a scoring system that provides tailored recommendations to\nenhance the transparency and integrity of the data set. The scorecard addresses\ntechnical and ethical aspects, offering a holistic evaluation of data\npractices. This approach aims to improve the quality of the data set. It offers\npractical guidance to curators and researchers in developing responsible AI\nsystems, ensuring fairness and accountability in decision support systems.",
    "pdf_url": "http://arxiv.org/pdf/2506.02071v1",
    "published": "2025-06-02T06:35:45+00:00",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CY"
  },
  {
    "id": "http://arxiv.org/abs/2506.01361v1",
    "title": "TimeGraph: Synthetic Benchmark Datasets for Robust Time-Series Causal Discovery",
    "authors": [
      "Muhammad Hasan Ferdous",
      "Emam Hossain",
      "Md Osman Gani"
    ],
    "abstract": "Robust causal discovery in time series datasets depends on reliable benchmark\ndatasets with known ground-truth causal relationships. However, such datasets\nremain scarce, and existing synthetic alternatives often overlook critical\ntemporal properties inherent in real-world data, including nonstationarity\ndriven by trends and seasonality, irregular sampling intervals, and the\npresence of unobserved confounders. To address these challenges, we introduce\nTimeGraph, a comprehensive suite of synthetic time-series benchmark datasets\nthat systematically incorporates both linear and nonlinear dependencies while\nmodeling key temporal characteristics such as trends, seasonal effects, and\nheterogeneous noise patterns. Each dataset is accompanied by a fully specified\ncausal graph featuring varying densities and diverse noise distributions and is\nprovided in two versions: one including unobserved confounders and one without,\nthereby offering extensive coverage of real-world complexity while preserving\nmethodological neutrality. We further demonstrate the utility of TimeGraph\nthrough systematic evaluations of state-of-the-art causal discovery algorithms\nincluding PCMCI+, LPCMCI, and FGES across a diverse array of configurations and\nmetrics. Our experiments reveal significant variations in algorithmic\nperformance under realistic temporal conditions, underscoring the need for\nrobust synthetic benchmarks in the fair and transparent assessment of causal\ndiscovery methods. The complete TimeGraph suite, including dataset generation\nscripts, evaluation metrics, and recommended experimental protocols, is freely\navailable to facilitate reproducible research and foster community-driven\nadvancements in time-series causal discovery.",
    "pdf_url": "http://arxiv.org/pdf/2506.01361v1",
    "published": "2025-06-02T06:34:11+00:00",
    "categories": [
      "cs.LG",
      "cs.IR",
      "stat.ML",
      "62H12, 62P10, 68T05",
      "I.2.6; I.5.1; G.3"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.01360v1",
    "title": "RDB2G-Bench: A Comprehensive Benchmark for Automatic Graph Modeling of Relational Databases",
    "authors": [
      "Dongwon Choi",
      "Sunwoo Kim",
      "Juyeon Kim",
      "Kyungho Kim",
      "Geon Lee",
      "Shinhwan Kang",
      "Myunghwan Kim",
      "Kijung Shin"
    ],
    "abstract": "Relational databases (RDBs) are composed of interconnected tables, where\nrelationships between them are defined through foreign keys. Recent research on\napplying machine learning to RDBs has explored graph-based representations of\nRDBs, where rows of tables are modeled as nodes, and foreign key relationships\nare modeled as edges. RDB-to-graph modeling helps capture cross-table\ndependencies, ultimately leading to enhanced performance across diverse tasks.\nHowever, there are numerous ways to model RDBs as graphs, and performance\nvaries significantly depending on the chosen graph model. In our analysis,\napplying a common heuristic rule for graph modeling leads to up to a 10% drop\nin performance compared to the best-performing graph model, which remains\nnon-trivial to identify. To foster research on intelligent RDB-to-graph\nmodeling, we introduce RDB2G-Bench, the first benchmark framework for\nevaluating such methods. We construct extensive datasets covering 5 real-world\nRDBs and 12 predictive tasks, resulting in around 50k graph-performance pairs\nfor efficient and reproducible evaluations. Thanks to our precomputed datasets,\nwe were able to benchmark 9 automatic RDB-to-graph modeling methods on the 12\ntasks over 600x faster than on-the-fly evaluation, which requires repeated\nmodel training. Our analysis of the datasets and benchmark results reveals key\nstructural patterns affecting graph model effectiveness, along with practical\nimplications for effective graph modeling.",
    "pdf_url": "http://arxiv.org/pdf/2506.01360v1",
    "published": "2025-06-02T06:34:10+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.01359v1",
    "title": "The random $k$-SAT Gibbs uniqueness threshold revisited",
    "authors": [
      "Arnab Chatterjee",
      "Amin Coja-Oghlan",
      "Catherine Greenhill",
      "Vincent Pfenninger",
      "Maurice Rolvien",
      "Pavel Zakharov",
      "Kostas Zampetakis"
    ],
    "abstract": "We prove that for any $k\\geq3$ for clause/variable ratios up to the Gibbs\nuniqueness threshold of the corresponding Galton-Watson tree, the number of\nsatisfying assignments of random $k$-SAT formulas is given by the `replica\nsymmetric solution' predicted by physics methods [Monasson, Zecchina: Phys.\nRev. Lett. (1996)]. Furthermore, while the Gibbs uniqueness threshold is still\nnot known precisely for any $k\\geq3$, we derive new lower bounds on this\nthreshold that improve over prior work [Montanari and Shah: SODA (2007)].The\nimprovement is significant particularly for small $k$.",
    "pdf_url": "http://arxiv.org/pdf/2506.01359v1",
    "published": "2025-06-02T06:32:12+00:00",
    "categories": [
      "cs.DM",
      "math.CO",
      "math.PR",
      "68Q87, 60C05, 68R07"
    ],
    "primary_category": "cs.DM"
  },
  {
    "id": "http://arxiv.org/abs/2506.01358v4",
    "title": "Prediction of the Conditional Probability Densities of Time Interval Extrema with Application to Risk-Sensitive Scheduling",
    "authors": [
      "Buyi Yu",
      "Wenyuan Tang"
    ],
    "abstract": "Planning and scheduling activities in the electrical power system, such as\nthe commitment of reserve generation, often involve the statistical\ncharacterization of peak demand. Due to the stationarity assumption of\nclassical extreme value analysis (EVA), existing approaches in the industry\napply EVA on simulated annual peaks created by weather-dependent surrogate\nmodels using Monte-Carlo simulations on a per-scenario basis. In day-ahead\nscheduling, the daily peak demand changes upon various factors besides\ntemperature, Monte-Carlo experiments become intractable, and state-of-the-art\ngeneralized additive model for location, scale and shape (GAMLSS)-based\nnonstationary EVA is often impractical due to convergence issues on\nhigh-dimensional covariates. This article explores uncharted territories and\nproposes a novel nonstationary EVA estimator that predicts the probable peaks\nof high-resolution time intervals and their corresponding conditional\nprobability densities based on calendar information and weather conditions\nwhere historical peaks are observed. Compared to GAMLSS, our method\nautomatically discovers and robustly models complex relationships between the\ncovariate and the peak demand density. We present a case study on the\ndetermination of day-ahead scheduling capacity and demonstrate that compared to\nthe industry approach, our approach results in a 38% reduction in the yearly\ntotal committed capacity while maintaining the given risk requirement.",
    "pdf_url": "http://arxiv.org/pdf/2506.01358v4",
    "published": "2025-06-02T06:27:15+00:00",
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2506.01357v1",
    "title": "KokoroChat: A Japanese Psychological Counseling Dialogue Dataset Collected via Role-Playing by Trained Counselors",
    "authors": [
      "Zhiyang Qi",
      "Takumasa Kaneko",
      "Keiko Takamizo",
      "Mariko Ukiyo",
      "Michimasa Inaba"
    ],
    "abstract": "Generating psychological counseling responses with language models relies\nheavily on high-quality datasets. Crowdsourced data collection methods require\nstrict worker training, and data from real-world counseling environments may\nraise privacy and ethical concerns. While recent studies have explored using\nlarge language models (LLMs) to augment psychological counseling dialogue\ndatasets, the resulting data often suffers from limited diversity and\nauthenticity. To address these limitations, this study adopts a role-playing\napproach where trained counselors simulate counselor-client interactions,\nensuring high-quality dialogues while mitigating privacy risks. Using this\nmethod, we construct KokoroChat, a Japanese psychological counseling dialogue\ndataset comprising 6,589 long-form dialogues, each accompanied by comprehensive\nclient feedback. Experimental results demonstrate that fine-tuning open-source\nLLMs with KokoroChat improves both the quality of generated counseling\nresponses and the automatic evaluation of counseling dialogues. The KokoroChat\ndataset is available at https://github.com/UEC-InabaLab/KokoroChat.",
    "pdf_url": "http://arxiv.org/pdf/2506.01357v1",
    "published": "2025-06-02T06:20:53+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.01356v1",
    "title": "Two-Stage Learning of Stabilizing Neural Controllers via Zubov Sampling and Iterative Domain Expansion",
    "authors": [
      "Haoyu Li",
      "Xiangru Zhong",
      "Bin Hu",
      "Huan Zhang"
    ],
    "abstract": "Learning-based neural network (NN) control policies have shown impressive\nempirical performance. However, obtaining stability guarantees and estimations\nof the region of attraction of these learned neural controllers is challenging\ndue to the lack of stable and scalable training and verification algorithms.\nAlthough previous works in this area have achieved great success, much\nconservatism remains in their framework. In this work, we propose a novel\ntwo-stage training framework to jointly synthesize the controller and Lyapunov\nfunction for continuous-time systems. By leveraging a Zubov-inspired region of\nattraction characterization to directly estimate stability boundaries, we\npropose a novel training data sampling strategy and a domain updating mechanism\nthat significantly reduces the conservatism in training. Moreover, unlike\nexisting works on continuous-time systems that rely on an SMT solver to\nformally verify the Lyapunov condition, we extend state-of-the-art neural\nnetwork verifier $\\alpha,\\!\\beta$-CROWN with the capability of performing\nautomatic bound propagation through the Jacobian of dynamical systems and a\nnovel verification scheme that avoids expensive bisection. To demonstrate the\neffectiveness of our approach, we conduct numerical experiments by synthesizing\nand verifying controllers on several challenging nonlinear systems across\nmultiple dimensions. We show that our training can yield region of attractions\nwith volume $5 - 1.5\\cdot 10^{5}$ times larger compared to the baselines, and\nour verification on continuous systems can be up to $40-10000$ times faster\ncompared to the traditional SMT solver dReal. Our code is available at\nhttps://github.com/Verified-Intelligence/Two-Stage_Neural_Controller_Training.",
    "pdf_url": "http://arxiv.org/pdf/2506.01356v1",
    "published": "2025-06-02T06:20:09+00:00",
    "categories": [
      "cs.LG",
      "cs.RO",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.01355v1",
    "title": "Rydberg Atomic Quantum MIMO Receivers for The Multi-User Uplink",
    "authors": [
      "Tierui Gong",
      "Chau Yuen",
      "Chong Meng Samson See",
      "Mérouane Debbah",
      "Lajos Hanzo"
    ],
    "abstract": "Rydberg atomic quantum receivers (RAQRs) have emerged as a promising solution\nfor evolving wireless receivers from the classical to the quantum domain. To\nfurther unleash their great potential in wireless communications, we propose a\nflexible architecture for Rydberg atomic quantum multiple-input multiple-output\n(RAQ-MIMO) receivers in the multi-user uplink. Then the corresponding signal\nmodel of the RAQ-MIMO system is constructed by paving the way from quantum\nphysics to classical wireless communications. Explicitly, we outline the\nassociated operating principles and transmission flow. We also validate the\nlinearity of our model and its feasible region. Based on our model, we derive\nclosed-form asymptotic formulas for the ergodic achievable rate (EAR) of both\nthe maximum-ratio combining (MRC) and zero-forcing (ZF) receivers operating in\nuncorrelated fading channels (UFC) and the correlated fading channels (CFC),\nrespectively. Furthermore, we theoretically characterize the EAR difference\nboth between the UFC and CFC scenarios, as well as MRC and ZF schemes. More\nparticularly, we quantify the superiority of RAQ-MIMO receivers over the\nclassical massive MIMO (M-MIMO) receivers, specifying an increase of $\\log_{2}\n\\Pi$ of the EAR per user, $\\Pi$-fold reduction of the users' transmit power,\nand $\\sqrt[\\nu]{\\Pi}$-fold increase of the transmission distance, respectively,\nwhere $\\Pi = \\text{ReceiverGainRatio} / \\text{ReceiverNoisePowerRatio}$ of the\nsingle-sensor receivers and $\\nu$ is the path-loss exponent. Our simulation\nresults reveal that, compared to classical M-MIMO receivers, our RAQ-MIMO\nscheme can either realize $\\sim 12$ bits/s/Hz/user ($\\sim 8$ bits/s/Hz/user)\nhigher EAR, or $\\sim 10000$-fold ($\\sim 500$-fold) lower transmit power, or\nalternatively, $\\sim 100$-fold ($\\sim 21$-fold) longer distance in free-space\ntransmissions, in the standard quantum limit (photon shot limit).",
    "pdf_url": "http://arxiv.org/pdf/2506.01355v1",
    "published": "2025-06-02T06:16:54+00:00",
    "categories": [
      "eess.SP",
      "cs.IT",
      "math.IT",
      "quant-ph"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2506.01354v1",
    "title": "Menelaus' and Ceva's theorems for translation triangles in Thurston geometries",
    "authors": [
      "Jenő Szirmai"
    ],
    "abstract": "After having investigated and defined the ``surface of a translation-like\ntriangle\" in each non-constant curvature Thurston geometry \\cite{Cs-Sz25}, we\ngeneralize the famous Menelaus' and Ceva's theorems for translation triangles\nin the mentioned spaces.\n  The described method makes it possible to transfer further classical\nEuclidean theorems and notions to Thurston geometries with non-constant\ncurvature. In our work we will use the projective models of Thurston geometries\ndescribed by E. Moln\\'ar in \\cite{M97}.",
    "pdf_url": "http://arxiv.org/pdf/2506.01354v1",
    "published": "2025-06-02T06:15:46+00:00",
    "categories": [
      "math.GT",
      "math.MG",
      "53A20, 53A35, 52C35, 53B20"
    ],
    "primary_category": "math.GT"
  },
  {
    "id": "http://arxiv.org/abs/2506.01353v1",
    "title": "EgoBrain: Synergizing Minds and Eyes For Human Action Understanding",
    "authors": [
      "Nie Lin",
      "Yansen Wang",
      "Dongqi Han",
      "Weibang Jiang",
      "Jingyuan Li",
      "Ryosuke Furuta",
      "Yoichi Sato",
      "Dongsheng Li"
    ],
    "abstract": "The integration of brain-computer interfaces (BCIs), in particular\nelectroencephalography (EEG), with artificial intelligence (AI) has shown\ntremendous promise in decoding human cognition and behavior from neural\nsignals. In particular, the rise of multimodal AI models have brought new\npossibilities that have never been imagined before. Here, we present EgoBrain\n--the world's first large-scale, temporally aligned multimodal dataset that\nsynchronizes egocentric vision and EEG of human brain over extended periods of\ntime, establishing a new paradigm for human-centered behavior analysis. This\ndataset comprises 61 hours of synchronized 32-channel EEG recordings and\nfirst-person video from 40 participants engaged in 29 categories of daily\nactivities. We then developed a muiltimodal learning framework to fuse EEG and\nvision for action understanding, validated across both cross-subject and\ncross-environment challenges, achieving an action recognition accuracy of\n66.70%. EgoBrain paves the way for a unified framework for brain-computer\ninterface with multiple modalities. All data, tools, and acquisition protocols\nare openly shared to foster open science in cognitive computing.",
    "pdf_url": "http://arxiv.org/pdf/2506.01353v1",
    "published": "2025-06-02T06:14:02+00:00",
    "categories": [
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2506.01352v1",
    "title": "TAH-QUANT: Effective Activation Quantization in Pipeline Parallelism over Slow Network",
    "authors": [
      "Guangxin He",
      "Yuan Cao",
      "Yutong He",
      "Tianyi Bai",
      "Kun Yuan",
      "Binhang Yuan"
    ],
    "abstract": "Decentralized training of large language models offers the opportunity to\npool computational resources across geographically distributed participants but\nfaces significant network communication bottlenecks, particularly in\npipeline-parallel settings. While pipeline parallelism partitions model layers\nacross devices to handle large-scale models, it necessitates frequent\ncommunication of intermediate activations, creating challenges when network\nbandwidth is limited. Existing activation compression methods, such as AQ-SGD,\nmitigate quantization-induced errors through error compensation but impose\nprohibitive memory overhead by requiring storage of previous activations. To\naddress these issues, we introduce TAH-Quant (Tile-wise Adaptive Hadamard\nQuantization), a novel activation quantization framework designed specifically\nfor pipeline parallelism. Our approach integrates fine-grained tile-wise\nquantization for precise control, entropy-guided token-level adaptive bit\nallocation for optimal bit usage, and a Hadamard-based transform with pivot\nelement swapping to effectively suppress quantization outliers. We further\nprovide a theoretical analysis, proving that pipeline parallel training\nequipped with TAH-Quant maintains a convergence rate of\n$\\mathcal{O}(1/\\sqrt{T})$, matching that of vanilla stochastic gradient\ndescent. Extensive experiments on diverse LLM tasks demonstrate that TAH-Quant\nachieves aggressive activation quantization (3-4 bits) ratio, which provides up\nto 4.3$\\times$ end-to-end speedup without compromising training convergence,\nmatches state-of-the-art methods, incurs no extra memory overhead, and\ngeneralizes well across different training scenarios.",
    "pdf_url": "http://arxiv.org/pdf/2506.01352v1",
    "published": "2025-06-02T06:13:41+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.01351v4",
    "title": "Thermalization and irreversibility of an isolated quantum system II",
    "authors": [
      "Xue-Yi Guo"
    ],
    "abstract": "The irreversible entropy increase described by the second law of\nthermodynamics is fundamentally tied to thermalization and the emergence of\nequilibrium. In the first part of our work (Ref: arXiv.2503.04152), we\nconstructed an isolated gas system model and numerically demonstrated\nirreversible growth of entanglement entropy caused by erasure of spread\nnon-equilibrium state information. Here, we mathematically prove that for a\ntypical macroscopic system in a non-equilibrium state $|\\phi_0\\rangle$, the\nquantum state $|\\phi'_0\\rangle = \\hat{O}(t)|\\phi_0\\rangle$ will inevitably\nevolve toward equilibrium. Our work demonstrates that the second law of\nthermodynamics, and consequently the ergodic hypothesis in statistical physics,\ncan be understood and proven from a quantum information perspective. From this\nperspective, the second law can be stated as: In typical macroscopic physical\nsystems, the spreading and erasure of non-equilibrium information is\ninevitable.",
    "pdf_url": "http://arxiv.org/pdf/2506.01351v4",
    "published": "2025-06-02T06:13:25+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.01350v1",
    "title": "Variational Adaptive Noise and Dropout towards Stable Recurrent Neural Networks",
    "authors": [
      "Taisuke Kobayashi",
      "Shingo Murata"
    ],
    "abstract": "This paper proposes a novel stable learning theory for recurrent neural\nnetworks (RNNs), so-called variational adaptive noise and dropout (VAND). As\nstabilizing factors for RNNs, noise and dropout on the internal state of RNNs\nhave been separately confirmed in previous studies. We reinterpret the\noptimization problem of RNNs as variational inference, showing that noise and\ndropout can be derived simultaneously by transforming the explicit\nregularization term arising in the optimization problem into implicit\nregularization. Their scale and ratio can also be adjusted appropriately to\noptimize the main objective of RNNs, respectively. In an imitation learning\nscenario with a mobile manipulator, only VAND is able to imitate sequential and\nperiodic behaviors as instructed. https://youtu.be/UOho3Xr6A2w",
    "pdf_url": "http://arxiv.org/pdf/2506.01350v1",
    "published": "2025-06-02T06:13:22+00:00",
    "categories": [
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.01349v1",
    "title": "Target Driven Adaptive Loss For Infrared Small Target Detection",
    "authors": [
      "Yuho Shoji",
      "Takahiro Toizumi",
      "Atsushi Ito"
    ],
    "abstract": "We propose a target driven adaptive (TDA) loss to enhance the performance of\ninfrared small target detection (IRSTD). Prior works have used loss functions,\nsuch as binary cross-entropy loss and IoU loss, to train segmentation models\nfor IRSTD. Minimizing these loss functions guides models to extract pixel-level\nfeatures or global image context. However, they have two issues: improving\ndetection performance for local regions around the targets and enhancing\nrobustness to small scale and low local contrast. To address these issues, the\nproposed TDA loss introduces a patch-based mechanism, and an adaptive\nadjustment strategy to scale and local contrast. The proposed TDA loss leads\nthe model to focus on local regions around the targets and pay particular\nattention to targets with smaller scales and lower local contrast. We evaluate\nthe proposed method on three datasets for IRSTD. The results demonstrate that\nthe proposed TDA loss achieves better detection performance than existing\nlosses on these datasets.",
    "pdf_url": "http://arxiv.org/pdf/2506.01349v1",
    "published": "2025-06-02T06:11:29+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.01348v2",
    "title": "Distributionally Robust Learning in Survival Analysis",
    "authors": [
      "Yeping Jin",
      "Lauren Wise",
      "Ioannis Ch. Paschalidis"
    ],
    "abstract": "We introduce an innovative approach that incorporates a Distributionally\nRobust Learning (DRL) approach into Cox regression to enhance the robustness\nand accuracy of survival predictions. By formulating a DRL framework with a\nWasserstein distance-based ambiguity set, we develop a variant Cox model that\nis less sensitive to assumptions about the underlying data distribution and\nmore resilient to model misspecification and data perturbations. By leveraging\nWasserstein duality, we reformulate the original min-max DRL problem into a\ntractable regularized empirical risk minimization problem, which can be\ncomputed by exponential conic programming. We provide guarantees on the finite\nsample behavior of our DRL-Cox model. Moreover, through extensive simulations\nand real world case studies, we demonstrate that our regression model achieves\nsuperior performance in terms of prediction accuracy and robustness compared\nwith traditional methods.",
    "pdf_url": "http://arxiv.org/pdf/2506.01348v2",
    "published": "2025-06-02T06:11:22+00:00",
    "categories": [
      "cs.LG",
      "math.OC",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.01347v1",
    "title": "The Surprising Effectiveness of Negative Reinforcement in LLM Reasoning",
    "authors": [
      "Xinyu Zhu",
      "Mengzhou Xia",
      "Zhepei Wei",
      "Wei-Lin Chen",
      "Danqi Chen",
      "Yu Meng"
    ],
    "abstract": "Reinforcement learning with verifiable rewards (RLVR) is a promising approach\nfor training language models (LMs) on reasoning tasks that elicit emergent long\nchains of thought (CoTs). Unlike supervised learning, it updates the model\nusing both correct and incorrect samples via policy gradients. To better\nunderstand its mechanism, we decompose the learning signal into reinforcing\ncorrect responses and penalizing incorrect ones, referred to as Positive and\nNegative Sample Reinforcement (PSR and NSR), respectively. We train\nQwen2.5-Math-7B and Qwen3-4B on a mathematical reasoning dataset and uncover a\nsurprising result: training with only negative samples -- without reinforcing\ncorrect responses -- can be highly effective: it consistently improves\nperformance over the base model across the entire Pass@$k$ spectrum ($k$ up to\n$256$), often matching or surpassing PPO and GRPO. In contrast, reinforcing\nonly correct responses improves Pass@$1$ but degrades performance at higher\n$k$, due to reduced diversity. These inference-scaling trends highlight that\nsolely penalizing incorrect responses may contribute more to performance than\npreviously recognized. Through gradient analysis, we show that NSR works by\nsuppressing incorrect generations and redistributing probability mass toward\nother plausible candidates, guided by the model's prior beliefs. It refines the\nmodel's existing knowledge rather than introducing entirely new behaviors.\nBuilding on this insight, we propose a simple variant of the RL objective that\nupweights NSR, and show that it consistently improves overall Pass@$k$\nperformance on MATH, AIME 2025, and AMC23. Our code is available at\nhttps://github.com/TianHongZXY/RLVR-Decomposed.",
    "pdf_url": "http://arxiv.org/pdf/2506.01347v1",
    "published": "2025-06-02T06:10:54+00:00",
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.01346v1",
    "title": "Rethinking Image Histogram Matching for Image Classification",
    "authors": [
      "Rikuto Otsuka",
      "Yuho Shoji",
      "Yuka Ogino",
      "Takahiro Toizumi",
      "Atsushi Ito"
    ],
    "abstract": "This paper rethinks image histogram matching (HM) and proposes a\ndifferentiable and parametric HM preprocessing for a downstream classifier.\nConvolutional neural networks have demonstrated remarkable achievements in\nclassification tasks. However, they often exhibit degraded performance on\nlow-contrast images captured under adverse weather conditions. To maintain\nclassifier performance under low-contrast images, histogram equalization (HE)\nis commonly used. HE is a special case of HM using a uniform distribution as a\ntarget pixel value distribution. In this paper, we focus on the shape of the\ntarget pixel value distribution. Compared to a uniform distribution, a single,\nwell-designed distribution could have potential to improve the performance of\nthe downstream classifier across various adverse weather conditions. Based on\nthis hypothesis, we propose a differentiable and parametric HM that optimizes\nthe target distribution using the loss function of the downstream classifier.\nThis method addresses pixel value imbalances by transforming input images with\narbitrary distributions into a target distribution optimized for the\nclassifier. Our HM is trained on only normal weather images using the\nclassifier. Experimental results show that a classifier trained with our\nproposed HM outperforms conventional preprocessing methods under adverse\nweather conditions.",
    "pdf_url": "http://arxiv.org/pdf/2506.01346v1",
    "published": "2025-06-02T06:09:12+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.01345v1",
    "title": "Quasi-canonical lifting of projective varieties in positive characteristic",
    "authors": [
      "Ryo Ishizuka",
      "Kazuma Shimomoto"
    ],
    "abstract": "The main aim of this article is to give new classes of smooth projective\nvarieties over characteristic $p>0$ that admit flat liftings over the Witt\nvectors together with additional data (logarithmic structure and the Frobenius\nmorphism) by showing a descending property of such Frobenius liftability. We\nestablish a refined form of the classical result due to Mehta-Srinivas on the\nexistence of canonical liftings. For this purpose, we also establish a result\non the algebraization of certain $p$-adic formal schemes.",
    "pdf_url": "http://arxiv.org/pdf/2506.01345v1",
    "published": "2025-06-02T06:09:09+00:00",
    "categories": [
      "math.AG",
      "math.AC"
    ],
    "primary_category": "math.AG"
  },
  {
    "id": "http://arxiv.org/abs/2506.01344v1",
    "title": "Follow the Flow: Fine-grained Flowchart Attribution with Neurosymbolic Agents",
    "authors": [
      "Manan Suri",
      "Puneet Mathur",
      "Nedim Lipka",
      "Franck Dernoncourt",
      "Ryan A. Rossi",
      "Vivek Gupta",
      "Dinesh Manocha"
    ],
    "abstract": "Flowcharts are a critical tool for visualizing decision-making processes.\nHowever, their non-linear structure and complex visual-textual relationships\nmake it challenging to interpret them using LLMs, as vision-language models\nfrequently hallucinate nonexistent connections and decision paths when\nanalyzing these diagrams. This leads to compromised reliability for automated\nflowchart processing in critical domains such as logistics, health, and\nengineering. We introduce the task of Fine-grained Flowchart Attribution, which\ntraces specific components grounding a flowchart referring LLM response.\nFlowchart Attribution ensures the verifiability of LLM predictions and improves\nexplainability by linking generated responses to the flowchart's structure. We\npropose FlowPathAgent, a neurosymbolic agent that performs fine-grained post\nhoc attribution through graph-based reasoning. It first segments the flowchart,\nthen converts it into a structured symbolic graph, and then employs an agentic\napproach to dynamically interact with the graph, to generate attribution paths.\nAdditionally, we present FlowExplainBench, a novel benchmark for evaluating\nflowchart attributions across diverse styles, domains, and question types.\nExperimental results show that FlowPathAgent mitigates visual hallucinations in\nLLM answers over flowchart QA, outperforming strong baselines by 10-14% on our\nproposed FlowExplainBench dataset.",
    "pdf_url": "http://arxiv.org/pdf/2506.01344v1",
    "published": "2025-06-02T06:02:41+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.01343v2",
    "title": "Polynomial Expectation Property for Max-Polymatrix Games",
    "authors": [
      "Howard Dai"
    ],
    "abstract": "We address an open problem on the computability of correlated equilibria in a\nvariant of polymatrix where each player's utility is the maximum of their edge\npayoffs. We demonstrate that this max-variant game has the polynomial\nexpectation property, and the results of \\cite{papadimitriou2008computing} can\nthus be applied. We propose ideas for extending these findings to other\nvariants of polymatrix games, as well as briefly address the broader question\nof necessity for the polynomial expectation property when computing correlated\nequilibria.",
    "pdf_url": "http://arxiv.org/pdf/2506.01343v2",
    "published": "2025-06-02T05:59:21+00:00",
    "categories": [
      "cs.GT"
    ],
    "primary_category": "cs.GT"
  },
  {
    "id": "http://arxiv.org/abs/2506.01342v1",
    "title": "An Accurate and Efficient Vulnerability Propagation Analysis Framework",
    "authors": [
      "Bonan Ruan",
      "Zhiwei Lin",
      "Jiahao Liu",
      "Chuqi Zhang",
      "Kaihang Ji",
      "Zhenkai Liang"
    ],
    "abstract": "Identifying the impact scope and scale is critical for software supply chain\nvulnerability assessment. However, existing studies face substantial\nlimitations. First, prior studies either work at coarse package-level\ngranularity, producing many false positives, or fail to accomplish\nwhole-ecosystem vulnerability propagation analysis. Second, although\nvulnerability assessment indicators like CVSS characterize individual\nvulnerabilities, no metric exists to specifically quantify the dynamic impact\nof vulnerability propagation across software supply chains. To address these\nlimitations and enable accurate and comprehensive vulnerability impact\nassessment, we propose a novel approach: (i) a hierarchical worklist-based\nalgorithm for whole-ecosystem and call-graph-level vulnerability propagation\nanalysis and (ii) the Vulnerability Propagation Scoring System (VPSS), a\ndynamic metric to quantify the scope and evolution of vulnerability impacts in\nsoftware supply chains. We implement a prototype of our approach in the Java\nMaven ecosystem and evaluate it on 100 real-world vulnerabilities. Experimental\nresults demonstrate that our approach enables effective ecosystem-wide\nvulnerability propagation analysis, and provides a practical, quantitative\nmeasure of vulnerability impact through VPSS.",
    "pdf_url": "http://arxiv.org/pdf/2506.01342v1",
    "published": "2025-06-02T05:55:45+00:00",
    "categories": [
      "cs.SE",
      "cs.CR"
    ],
    "primary_category": "cs.SE"
  },
  {
    "id": "http://arxiv.org/abs/2506.01341v1",
    "title": "TurnBench-MS: A Benchmark for Evaluating Multi-Turn, Multi-Step Reasoning in Large Language Models",
    "authors": [
      "Yiran Zhang",
      "Mo Wang",
      "Xiaoyang Li",
      "Kaixuan Ren",
      "Chencheng Zhu",
      "Usman Naseem"
    ],
    "abstract": "Despite impressive advances in large language models (LLMs), existing\nbenchmarks often focus on single-turn or single-step tasks, failing to capture\nthe kind of iterative reasoning required in real-world settings. To address\nthis limitation, we introduce TurnBench, a novel benchmark that evaluates\nmulti-turn, multi-step reasoning through an interactive code-breaking task\ninspired by a \"Turing Machine Board Game.\" In each episode, a model must\nuncover hidden logical or arithmetic rules by making sequential guesses,\nreceiving structured feedback, and integrating clues across multiple rounds.\nThis dynamic setup requires models to reason over time, adapt based on past\ninformation, and maintain consistency across steps-capabilities underexplored\nin current benchmarks. TurnBench includes two modes: Classic, which tests\nstandard reasoning, and Nightmare, which introduces increased complexity and\nrequires robust inferential chains. To support fine-grained analysis, we\nprovide ground-truth annotations for intermediate reasoning steps. Our\nevaluation of state-of-the-art LLMs reveals significant gaps: the best model\nachieves 81.5% accuracy in Classic mode, but performance drops to 17.8% in\nNightmare mode. In contrast, human participants achieve 100% in both,\nunderscoring the challenge TurnBench poses to current models. By incorporating\nfeedback loops and hiding task rules, TurnBench reduces contamination risks and\nprovides a rigorous testbed for diagnosing and advancing multi-step, multi-turn\nreasoning in LLMs.",
    "pdf_url": "http://arxiv.org/pdf/2506.01341v1",
    "published": "2025-06-02T05:47:50+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.01340v1",
    "title": "The Landscape of Arabic Large Language Models (ALLMs): A New Era for Arabic Language Technology",
    "authors": [
      "Shahad Al-Khalifa",
      "Nadir Durrani",
      "Hend Al-Khalifa",
      "Firoj Alam"
    ],
    "abstract": "The emergence of ChatGPT marked a transformative milestone for Artificial\nIntelligence (AI), showcasing the remarkable potential of Large Language Models\n(LLMs) to generate human-like text. This wave of innovation has revolutionized\nhow we interact with technology, seamlessly integrating LLMs into everyday\ntasks such as vacation planning, email drafting, and content creation. While\nEnglish-speaking users have significantly benefited from these advancements,\nthe Arabic world faces distinct challenges in developing Arabic-specific LLMs.\nArabic, one of the languages spoken most widely around the world, serves more\nthan 422 million native speakers in 27 countries and is deeply rooted in a rich\nlinguistic and cultural heritage. Developing Arabic LLMs (ALLMs) presents an\nunparalleled opportunity to bridge technological gaps and empower communities.\nThe journey of ALLMs has been both fascinating and complex, evolving from\nrudimentary text processing systems to sophisticated AI-driven models. This\narticle explores the trajectory of ALLMs, from their inception to the present\nday, highlighting the efforts to evaluate these models through benchmarks and\npublic leaderboards. We also discuss the challenges and opportunities that\nALLMs present for the Arab world.",
    "pdf_url": "http://arxiv.org/pdf/2506.01340v1",
    "published": "2025-06-02T05:45:19+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.08031v1",
    "title": "Stochastic Krasnosel skii-Mann Iterations in Banach Spaces with Bregman Distances",
    "authors": [
      "Saeed Hashemi Sababe",
      "Ehsan Lotfali Ghasab"
    ],
    "abstract": "We propose a generalization of the stochastic Krasnoselskil-Mann $(SKM)$\nalgorithm to reflexive Banach spaces endowed with Bregman distances. Under\nstandard martingale-difference noise assumptions in the dual space and mild\nconditions on the distance-generating function, we establish almost-sure\nconvergence to a fixed point and derive non-asymptotic residual bounds that\ndepend on the uniform convexity modulus of the generating function. Extensions\nto adaptive Bregman geometries and robust noise models are also discussed.\nNumerical experiments on entropy-regularized reinforcement learning and\nmirror-descent illustrate the theoretical findings.",
    "pdf_url": "http://arxiv.org/pdf/2506.08031v1",
    "published": "2025-06-02T05:44:44+00:00",
    "categories": [
      "math.OC"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2506.10017v3",
    "title": "Design of A* based heuristic algorithm for efficient interdiction in multi-Layer networks",
    "authors": [
      "Sukanya Samanta"
    ],
    "abstract": "Intercepting a criminal using limited police resources presents a significant\nchallenge in dynamic crime environments, where the criminal's location\ncontinuously changes over time. The complexity is further heightened by the\nvastness of the transportation network. To tackle this problem, we propose a\nlayered graph representation, in which each time step is associated with a\nduplicate of the transportation network. For any given set of attacker\nstrategies, a near-optimal defender strategy is computed using the A-Star\nheuristic algorithm applied to the layered graph. The defender's goal is to\nmaximize the probability of successful interdiction. We evaluate the\nperformance of the proposed method by comparing it with a Mixed-Integer Linear\nProgramming (MILP) approach used for the defender. The comparison considers\nboth computational efficiency and solution quality. The results demonstrate\nthat our approach effectively addresses the complexity of the problem and\ndelivers high-quality solutions within a short computation time.",
    "pdf_url": "http://arxiv.org/pdf/2506.10017v3",
    "published": "2025-06-02T05:41:02+00:00",
    "categories": [
      "cs.SI",
      "cs.MA",
      "math.OC"
    ],
    "primary_category": "cs.SI"
  },
  {
    "id": "http://arxiv.org/abs/2506.01339v1",
    "title": "Invariance Makes LLM Unlearning Resilient Even to Unanticipated Downstream Fine-Tuning",
    "authors": [
      "Changsheng Wang",
      "Yihua Zhang",
      "Jinghan Jia",
      "Parikshit Ram",
      "Dennis Wei",
      "Yuguang Yao",
      "Soumyadeep Pal",
      "Nathalie Baracaldo",
      "Sijia Liu"
    ],
    "abstract": "Machine unlearning offers a promising solution to privacy and safety concerns\nin large language models (LLMs) by selectively removing targeted knowledge\nwhile preserving utility. However, current methods are highly sensitive to\ndownstream fine-tuning, which can quickly recover forgotten information-even\nfrom unrelated tasks. To address this, we introduce invariance into unlearning\nfor the first time, inspired by invariant risk minimization (IRM). Building on\nthis principle, we propose invariant LLM unlearning (ILU), a\nregularization-based framework that enhances robustness. Notably, ILU\ngeneralizes well to diverse fine-tuning tasks, even when trained using a single\ndataset. A task vector analysis is also provided to further elucidate the\nrationale behind ILU's effectiveness. Extensive experiments on the WMDP and\nMUSE benchmark, reveal that ILU significantly outperforms state-of-the-art\nunlearning methods, including negative preference optimization (NPO) and\nrepresentation misdirection for unlearning (RMU). Notably, ILU achieves\nsuperior unlearning robustness across diverse downstream fine-tuning scenarios\n(e.g., math, paraphrase detection, and sentiment analysis) while preserving the\nfine-tuning performance.",
    "pdf_url": "http://arxiv.org/pdf/2506.01339v1",
    "published": "2025-06-02T05:38:43+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.01338v1",
    "title": "A 2-Stage Model for Vehicle Class and Orientation Detection with Photo-Realistic Image Generation",
    "authors": [
      "Youngmin Kim",
      "Donghwa Kang",
      "Hyeongboo Baek"
    ],
    "abstract": "We aim to detect the class and orientation of a vehicle by training a model\nwith synthetic data. However, the distribution of the classes in the training\ndata is imbalanced, and the model trained on the synthetic image is difficult\nto predict in real-world images. We propose a two-stage detection model with\nphoto-realistic image generation to tackle this issue. Our model mainly takes\nfour steps to detect the class and orientation of the vehicle. (1) It builds a\ntable containing the image, class, and location information of objects in the\nimage, (2) transforms the synthetic images into real-world images style, and\nmerges them into the meta table. (3) Classify vehicle class and orientation\nusing images from the meta-table. (4) Finally, the vehicle class and\norientation are detected by combining the pre-extracted location information\nand the predicted classes. We achieved 4th place in IEEE BigData Challenge 2022\nVehicle class and Orientation Detection (VOD) with our approach.",
    "pdf_url": "http://arxiv.org/pdf/2506.01338v1",
    "published": "2025-06-02T05:38:10+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.03349v1",
    "title": "Effectiveness of Stacks in the Stacked Hilbert-Huang Transform",
    "authors": [
      "Lupin Chun-Che Lin",
      "Chin-Ping Hu",
      "Chien-Chang Yen",
      "Kuo-Chuan Pan",
      "C. Y. Hui",
      "Kwan-Lok Li",
      "Yu-Chiung Lin",
      "Yi-Sheng Huang",
      "Albert K. H. Kong"
    ],
    "abstract": "The Hilbert-Huang transform (HHT) consists of empirical mode decomposition\n(EMD), which is a template-free method that represents the combination of\ndifferent intrinsic modes on a time-frequency map (i.e., the Hilbert spectrum).\nThe application of HHT involves introducing trials by imposing white noise on\nthe signal and then calculating the ensemble mean process of the corresponding\nEMD to demonstrate its significance on the Hilbert spectrum. In this study, we\ndevelop a stacked Hilbert-Huang Transform (sHHT) method that generates the\nHilbert spectrum for each trial and compiles all results to enhance the\nstrength of the real instantaneous frequency of the main signal on the\ntime-frequency map. This new approach is more sensitive to detecting/tracing\nthe nonlinear and transient features of a signal embedded in astronomical\ndatabases than the conventional HHT, particularly when the signal experiences\ndramatic frequency changes in a short time. We analytically investigate the\nconsistency of HHT and sHHT and perform numerical simulations to examine the\ndispersion of the instantaneous frequency obtained through sHHT and compare its\nadvantages and effectiveness with those of conventional HHT. To confirm the\nfeasibility of the sHHT, we demonstrate its application in verifying the signal\nof superorbital modulation in X-ray and binary black hole mergers in\ngravitational waves.",
    "pdf_url": "http://arxiv.org/pdf/2506.03349v1",
    "published": "2025-06-02T05:32:59+00:00",
    "categories": [
      "astro-ph.IM"
    ],
    "primary_category": "astro-ph.IM"
  },
  {
    "id": "http://arxiv.org/abs/2506.01337v1",
    "title": "NoiseAR: AutoRegressing Initial Noise Prior for Diffusion Models",
    "authors": [
      "Zeming Li",
      "Xiangyue Liu",
      "Xiangyu Zhang",
      "Ping Tan",
      "Heung-Yeung Shum"
    ],
    "abstract": "Diffusion models have emerged as powerful generative frameworks, creating\ndata samples by progressively denoising an initial random state. Traditionally,\nthis initial state is sampled from a simple, fixed distribution like isotropic\nGaussian, inherently lacking structure and a direct mechanism for external\ncontrol. While recent efforts have explored ways to introduce controllability\ninto the diffusion process, particularly at the initialization stage, they\noften rely on deterministic or heuristic approaches. These methods can be\nsuboptimal, lack expressiveness, and are difficult to scale or integrate into\nmore sophisticated optimization frameworks. In this paper, we introduce\nNoiseAR, a novel method for AutoRegressive Initial Noise Prior for Diffusion\nModels. Instead of a static, unstructured source, NoiseAR learns to generate a\ndynamic and controllable prior distribution for the initial noise. We formulate\nthe generation of the initial noise prior's parameters as an autoregressive\nprobabilistic modeling task over spatial patches or tokens. This approach\nenables NoiseAR to capture complex spatial dependencies and introduce learned\nstructure into the initial state. Crucially, NoiseAR is designed to be\nconditional, allowing text prompts to directly influence the learned prior,\nthereby achieving fine-grained control over the diffusion initialization. Our\nexperiments demonstrate that NoiseAR can generate initial noise priors that\nlead to improved sample quality and enhanced consistency with conditional\ninputs, offering a powerful, learned alternative to traditional random\ninitialization. A key advantage of NoiseAR is its probabilistic formulation,\nwhich naturally supports seamless integration into probabilistic frameworks\nlike Markov Decision Processes and Reinforcement Learning. Our code will be\navailable at https://github.com/HKUST-SAIL/NoiseAR/",
    "pdf_url": "http://arxiv.org/pdf/2506.01337v1",
    "published": "2025-06-02T05:32:35+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.12066v1",
    "title": "Focusing on Students, not Machines: Grounded Question Generation and Automated Answer Grading",
    "authors": [
      "Gérôme Meyer",
      "Philip Breuer"
    ],
    "abstract": "Digital technologies are increasingly used in education to reduce the\nworkload of teachers and students. However, creating open-ended study or\nexamination questions and grading their answers is still a tedious task. This\nthesis presents the foundation for a system that generates questions grounded\nin class materials and automatically grades student answers. It introduces a\nsophisticated method for chunking documents with a visual layout, specifically\ntargeting PDF documents. This method enhances the accuracy of downstream tasks,\nincluding Retrieval Augmented Generation (RAG). Our thesis demonstrates that\nhigh-quality questions and reference answers can be generated from study\nmaterial. Further, it introduces a new benchmark for automated grading of short\nanswers to facilitate comparison of automated grading systems. An evaluation of\nvarious grading systems is conducted and indicates that Large Language Models\n(LLMs) can generalise to the task of automated grading of short answers from\ntheir pre-training tasks. As with other tasks, increasing the parameter size of\nthe LLMs leads to greater performance. Currently, available systems still need\nhuman oversight, especially in examination scenarios.",
    "pdf_url": "http://arxiv.org/pdf/2506.12066v1",
    "published": "2025-06-02T05:32:23+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.01336v1",
    "title": "Anomaly of conserved and nonconserved axial charges in Hamiltonian lattice gauge theory",
    "authors": [
      "Yoshimasa Hidaka",
      "Arata Yamamoto"
    ],
    "abstract": "We investigate the axial anomaly in Hamiltonian lattice gauge theory. The\ndefinition of axial charge operators is ambiguous, especially between conserved\nand nonconserved axial charges. While these charges appear to differ only by a\nhigher-order term in lattice spacing, they do not coincide in the continuum\nlimit. We demonstrate, through analytical and numerical calculations, that the\nconserved axial charge correctly reproduces the axial anomaly relation in\ncontinuous spacetime. Our finding would provide valuable insights for future\nstudies on quantum computing for lattice gauge theory.",
    "pdf_url": "http://arxiv.org/pdf/2506.01336v1",
    "published": "2025-06-02T05:27:31+00:00",
    "categories": [
      "hep-lat",
      "hep-th",
      "quant-ph"
    ],
    "primary_category": "hep-lat"
  },
  {
    "id": "http://arxiv.org/abs/2506.01335v1",
    "title": "Neural-network-assisted Monte Carlo sampling trained by Quantum Approximate Optimization Algorithm",
    "authors": [
      "Yuichiro Nakano",
      "Ken N. Okada",
      "Keisuke Fujii"
    ],
    "abstract": "Sampling problems are widely regarded as the task for which quantum computers\ncan most readily provide a quantum advantage. Leveraging this feature, the\nquantum-enhanced Markov chain Monte Carlo [Layden, D. et al., Nature 619,\n282-287 (2023)] has been proposed recently, where sampling from a quantum\ncomputer is used as a proposal distribution and convergence to a target\ndistribution is accelerated. However, guaranteeing convergence to the target\ndistribution typically forces one to impose restrictive symmetry constraints on\nthe quantum circuit, which makes it hard to design good proposal distributions\nand prevents making full use of the advantage of a quantum computer. We explore\na hybrid quantum-classical MCMC framework that combines a quantum circuit with\na generative neural sampler (GNS). The GNS is trained on quantum samples and\nacts as a classical surrogate to efficiently emulate quantum outputs, thereby\nlifting circuit constraints. We apply this method to Boltzmann sampling of spin\nglasses using proposals trained with a QAOA circuit. This approach outperforms\nconventional methods, showing a $\\sim$100$\\times$ improvement in spectral gap\nover uniform proposals. Notably, it maintains similar acceleration even without\nparameter optimization. These results establish the method as a viable\nsampling-based quantum algorithm for NISQ devices and highlight its potential\nfor solving practical problems with quantum computation.",
    "pdf_url": "http://arxiv.org/pdf/2506.01335v1",
    "published": "2025-06-02T05:26:26+00:00",
    "categories": [
      "quant-ph",
      "cond-mat.dis-nn"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.01334v1",
    "title": "Enhancing Interpretable Image Classification Through LLM Agents and Conditional Concept Bottleneck Models",
    "authors": [
      "Yiwen Jiang",
      "Deval Mehta",
      "Wei Feng",
      "Zongyuan Ge"
    ],
    "abstract": "Concept Bottleneck Models (CBMs) decompose image classification into a\nprocess governed by interpretable, human-readable concepts. Recent advances in\nCBMs have used Large Language Models (LLMs) to generate candidate concepts.\nHowever, a critical question remains: What is the optimal number of concepts to\nuse? Current concept banks suffer from redundancy or insufficient coverage. To\naddress this issue, we introduce a dynamic, agent-based approach that adjusts\nthe concept bank in response to environmental feedback, optimizing the number\nof concepts for sufficiency yet concise coverage. Moreover, we propose\nConditional Concept Bottleneck Models (CoCoBMs) to overcome the limitations in\ntraditional CBMs' concept scoring mechanisms. It enhances the accuracy of\nassessing each concept's contribution to classification tasks and feature an\neditable matrix that allows LLMs to correct concept scores that conflict with\ntheir internal knowledge. Our evaluations across 6 datasets show that our\nmethod not only improves classification accuracy by 6% but also enhances\ninterpretability assessments by 30%.",
    "pdf_url": "http://arxiv.org/pdf/2506.01334v1",
    "published": "2025-06-02T05:25:52+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.01333v1",
    "title": "ETDI: Mitigating Tool Squatting and Rug Pull Attacks in Model Context Protocol (MCP) by using OAuth-Enhanced Tool Definitions and Policy-Based Access Control",
    "authors": [
      "Manish Bhatt",
      "Vineeth Sai Narajala",
      "Idan Habler"
    ],
    "abstract": "The Model Context Protocol (MCP) plays a crucial role in extending the\ncapabilities of Large Language Models (LLMs) by enabling integration with\nexternal tools and data sources. However, the standard MCP specification\npresents significant security vulnerabilities, notably Tool Poisoning and Rug\nPull attacks. This paper introduces the Enhanced Tool Definition Interface\n(ETDI), a security extension designed to fortify MCP. ETDI incorporates\ncryptographic identity verification, immutable versioned tool definitions, and\nexplicit permission management, often leveraging OAuth 2.0. We further propose\nextending MCP with fine-grained, policy-based access control, where tool\ncapabilities are dynamically evaluated against explicit policies using a\ndedicated policy engine, considering runtime context beyond static OAuth\nscopes. This layered approach aims to establish a more secure, trustworthy, and\ncontrollable ecosystem for AI applications interacting with LLMs and external\ntools.",
    "pdf_url": "http://arxiv.org/pdf/2506.01333v1",
    "published": "2025-06-02T05:22:38+00:00",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.ET"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2506.01332v1",
    "title": "An Empirical Study of Group Conformity in Multi-Agent Systems",
    "authors": [
      "Min Choi",
      "Keonwoo Kim",
      "Sungwon Chae",
      "Sangyeob Baek"
    ],
    "abstract": "Recent advances in Large Language Models (LLMs) have enabled multi-agent\nsystems that simulate real-world interactions with near-human reasoning. While\nprevious studies have extensively examined biases related to protected\nattributes such as race, the emergence and propagation of biases on socially\ncontentious issues in multi-agent LLM interactions remain underexplored. This\nstudy explores how LLM agents shape public opinion through debates on five\ncontentious topics. By simulating over 2,500 debates, we analyze how initially\nneutral agents, assigned a centrist disposition, adopt specific stances over\ntime. Statistical analyses reveal significant group conformity mirroring human\nbehavior; LLM agents tend to align with numerically dominant groups or more\nintelligent agents, exerting a greater influence. These findings underscore the\ncrucial role of agent intelligence in shaping discourse and highlight the risks\nof bias amplification in online interactions. Our results emphasize the need\nfor policy measures that promote diversity and transparency in LLM-generated\ndiscussions to mitigate the risks of bias propagation within anonymous online\nenvironments.",
    "pdf_url": "http://arxiv.org/pdf/2506.01332v1",
    "published": "2025-06-02T05:22:29+00:00",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.MA"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2506.01331v1",
    "title": "Ultra-High-Resolution Image Synthesis: Data, Method and Evaluation",
    "authors": [
      "Jinjin Zhang",
      "Qiuyu Huang",
      "Junjie Liu",
      "Xiefan Guo",
      "Di Huang"
    ],
    "abstract": "Ultra-high-resolution image synthesis holds significant potential, yet\nremains an underexplored challenge due to the absence of standardized\nbenchmarks and computational constraints. In this paper, we establish\nAesthetic-4K, a meticulously curated dataset containing dedicated training and\nevaluation subsets specifically designed for comprehensive research on\nultra-high-resolution image synthesis. This dataset consists of high-quality 4K\nimages accompanied by descriptive captions generated by GPT-4o. Furthermore, we\npropose Diffusion-4K, an innovative framework for the direct generation of\nultra-high-resolution images. Our approach incorporates the Scale Consistent\nVariational Auto-Encoder (SC-VAE) and Wavelet-based Latent Fine-tuning (WLF),\nwhich are designed for efficient visual token compression and the capture of\nintricate details in ultra-high-resolution images, thereby facilitating direct\ntraining with photorealistic 4K data. This method is applicable to various\nlatent diffusion models and demonstrates its efficacy in synthesizing highly\ndetailed 4K images. Additionally, we propose novel metrics, namely the GLCM\nScore and Compression Ratio, to assess the texture richness and fine details in\nlocal patches, in conjunction with holistic measures such as FID, Aesthetics,\nand CLIPScore, enabling a thorough and multifaceted evaluation of\nultra-high-resolution image synthesis. Consequently, Diffusion-4K achieves\nimpressive performance in ultra-high-resolution image synthesis, particularly\nwhen powered by state-of-the-art large-scale diffusion models (eg, Flux-12B).\nThe source code is publicly available at\nhttps://github.com/zhang0jhon/diffusion-4k.",
    "pdf_url": "http://arxiv.org/pdf/2506.01331v1",
    "published": "2025-06-02T05:19:40+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.01330v1",
    "title": "Superconducting properties of ultrapure niobium",
    "authors": [
      "N. E. Alekseevskiy",
      "V. I. Nizhankovskiy",
      "K. -H. Bertel"
    ],
    "abstract": "The results of determination of critical magnetic fields, magnetization\ncurves and critical currents of niobium samples of different purity are\npresented. It is shown that ultrapure niobium near Tc is a superconductor of\nthe first type and becomes a superconductor of the second type with decreasing\ntemperature due to the temperature dependence of the Ginzburg-Landau\nparameters. The dependence of the hysteresis of the magnetization curves of\nmassive samples on the surface state is investigated. A comparison of the\nsuperconducting parameters with the parameters of the electron spectrum of\nniobium is carried out. The dependence of the critical current of niobium wires\non the longitudinal magnetic field agrees with the assumption of a force-free\ncurrent distribution.",
    "pdf_url": "http://arxiv.org/pdf/2506.01330v1",
    "published": "2025-06-02T05:19:16+00:00",
    "categories": [
      "cond-mat.supr-con",
      "cond-mat.mtrl-sci"
    ],
    "primary_category": "cond-mat.supr-con"
  },
  {
    "id": "http://arxiv.org/abs/2506.01329v1",
    "title": "Evaluating Large Language Models in Crisis Detection: A Real-World Benchmark from Psychological Support Hotlines",
    "authors": [
      "Guifeng Deng",
      "Shuyin Rao",
      "Tianyu Lin",
      "Anlu Dai",
      "Pan Wang",
      "Junyi Xie",
      "Haidong Song",
      "Ke Zhao",
      "Dongwu Xu",
      "Zhengdong Cheng",
      "Tao Li",
      "Haiteng Jiang"
    ],
    "abstract": "Psychological support hotlines are critical for crisis intervention but face\nsignificant challenges due to rising demand. Large language models (LLMs) could\nsupport crisis assessments, yet their capabilities in emotionally sensitive\ncontexts remain unclear. We introduce PsyCrisisBench, a benchmark of 540\nannotated transcripts from the Hangzhou Psychological Assistance Hotline,\nassessing four tasks: mood status recognition, suicidal ideation detection,\nsuicide plan identification, and risk assessment. We evaluated 64 LLMs across\n15 families (e.g., GPT, Claude, Gemini, Llama, Qwen, DeepSeek) using zero-shot,\nfew-shot, and fine-tuning paradigms. Performance was measured by F1-score, with\nstatistical comparisons via Welch's t-tests. LLMs performed strongly on\nsuicidal ideation detection (F1=0.880), suicide plan identification (F1=0.779),\nand risk assessment (F1=0.907), improved with few-shot and fine-tuning. Mood\nstatus recognition was more challenging (max F1=0.709), likely due to lost\nvocal cues and ambiguity. A fine-tuned 1.5B-parameter model (Qwen2.5-1.5B)\nsurpassed larger models on mood and suicidal ideation. Open-source models like\nQwQ-32B performed comparably to closed-source on most tasks (p>0.3), though\nclosed models retained an edge in mood detection (p=0.007). Performance scaled\nwith size up to a point; quantization (AWQ) reduced GPU memory by 70% with\nminimal F1 degradation. LLMs show substantial promise in structured\npsychological crisis assessments, especially with fine-tuning. Mood recognition\nremains limited due to contextual complexity. The narrowing gap between open-\nand closed-source models, combined with efficient quantization, suggests\nfeasible integration. PsyCrisisBench offers a robust evaluation framework to\nguide model development and ethical deployment in mental health.",
    "pdf_url": "http://arxiv.org/pdf/2506.01329v1",
    "published": "2025-06-02T05:18:24+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.01328v1",
    "title": "Universal Coacting Hopf algebra of a Finite dimensional Lie-Yamaguti algebra",
    "authors": [
      "Saikat Goswami",
      "Satyendra Kumar Mishra",
      "Goutam Mukherjee"
    ],
    "abstract": "M. E. Sweedler first constructed a universal Hopf algebra of an algebra. It\nis known that the dual notions to the existing ones play a dominant role in\nHopf algebra theory. Yu. I. Manin and D. Tambara introduced the dual notion of\nSweedler's construction in separate works. In this paper, we construct a\nuniversal algebra for a finite-dimensional Lie-Yamaguti algebra. We demonstrate\nthat this universal algebra possesses a bialgebra structure, leading to a\nuniversal coacting Hopf algebra for a finite-dimensional Lie-Yamaguti algebra.\nAdditionally, we develop a representation-theoretic version of our results. As\nan application, we characterize the automorphism group and classify all abelian\ngroup gradings of a finite-dimensional Lie-Yamaguti algebra.",
    "pdf_url": "http://arxiv.org/pdf/2506.01328v1",
    "published": "2025-06-02T05:18:07+00:00",
    "categories": [
      "math.RA",
      "16D90, 16T05, 16T10, 17A30, 17A36, 17A60"
    ],
    "primary_category": "math.RA"
  },
  {
    "id": "http://arxiv.org/abs/2506.06349v2",
    "title": "Heart Rate Classification in ECG Signals Using Machine Learning and Deep Learning",
    "authors": [
      "Thien Nhan Vo"
    ],
    "abstract": "This study addresses the classification of heartbeats from ECG signals\nthrough two distinct approaches: traditional machine learning utilizing\nhand-crafted features and deep learning via transformed images of ECG beats.\nThe dataset underwent preprocessing steps, including downsampling, filtering,\nand normalization, to ensure consistency and relevance for subsequent analysis.\nIn the first approach, features such as heart rate variability (HRV), mean,\nvariance, and RR intervals were extracted to train various classifiers,\nincluding SVM, Random Forest, AdaBoost, LSTM, Bi-directional LSTM, and\nLightGBM. The second approach involved transforming ECG signals into images\nusing Gramian Angular Field (GAF), Markov Transition Field (MTF), and\nRecurrence Plots (RP), with these images subsequently classified using CNN\narchitectures like VGG and Inception.\n  Experimental results demonstrate that the LightGBM model achieved the highest\nperformance, with an accuracy of 99% and an F1 score of 0.94, outperforming the\nimage-based CNN approach (F1 score of 0.85). Models such as SVM and AdaBoost\nyielded significantly lower scores, indicating limited suitability for this\ntask. The findings underscore the superior ability of hand-crafted features to\ncapture temporal and morphological variations in ECG signals compared to\nimage-based representations of individual beats. Future investigations may\nbenefit from incorporating multi-lead ECG signals and temporal dependencies\nacross successive beats to enhance classification accuracy further.",
    "pdf_url": "http://arxiv.org/pdf/2506.06349v2",
    "published": "2025-06-02T05:16:16+00:00",
    "categories": [
      "eess.SP",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2506.01327v1",
    "title": "STSA: Federated Class-Incremental Learning via Spatial-Temporal Statistics Aggregation",
    "authors": [
      "Zenghao Guan",
      "Guojun Zhu",
      "Yucan Zhou",
      "Wu Liu",
      "Weiping Wang",
      "Jiebo Luo",
      "Xiaoyan Gu"
    ],
    "abstract": "Federated Class-Incremental Learning (FCIL) enables Class-Incremental\nLearning (CIL) from distributed data. Existing FCIL methods typically integrate\nold knowledge preservation into local client training. However, these methods\ncannot avoid spatial-temporal client drift caused by data heterogeneity and\noften incur significant computational and communication overhead, limiting\npractical deployment. To address these challenges simultaneously, we propose a\nnovel approach, Spatial-Temporal Statistics Aggregation (STSA), which provides\na unified framework to aggregate feature statistics both spatially (across\nclients) and temporally (across stages). The aggregated feature statistics are\nunaffected by data heterogeneity and can be used to update the classifier in\nclosed form at each stage. Additionally, we introduce STSA-E, a\ncommunication-efficient variant with theoretical guarantees, achieving similar\nperformance to STSA-E with much lower communication overhead. Extensive\nexperiments on three widely used FCIL datasets, with varying degrees of data\nheterogeneity, show that our method outperforms state-of-the-art FCIL methods\nin terms of performance, flexibility, and both communication and computation\nefficiency.",
    "pdf_url": "http://arxiv.org/pdf/2506.01327v1",
    "published": "2025-06-02T05:14:57+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.06495v1",
    "title": "Optimizing Optimizations: Case Study on Detecting Specific Types of Mathematical Optimization Constraints with E-Graphs in JijModeling",
    "authors": [
      "Hiromi Ishii",
      "Taro Shimizu",
      "Toshiki Teramura"
    ],
    "abstract": "In solving mathematical optimization problems efficiently, it is crucial to\nmake use of information about specific types of constraints, such as the\none-hot or Special-Ordered Set (SOS) constraints. In many cases, exploiting\nsuch information gives asymptotically better execution time. JijModeling, an\nindustrial-strength mathematical optimization modeller, achieves this by\nseparating the symbolic representation of an optimization problem from the\ninput data. In this paper, we will report a real-world case study on a\nconstraint detection mechanism modulo the algebraic congruence using e-graphs,\nand describe heuristic criteria for designing rewriting systems. We give\nbenchmarking result that shows the performance impact of the constraint\ndetection mechanism.\n  We also introduce egg_recursive, a utility library for writing egg-terms as\nrecursive abstract syntax trees, reducing the burden of writing and maintaining\ncomplex terms in S-expressions.",
    "pdf_url": "http://arxiv.org/pdf/2506.06495v1",
    "published": "2025-06-02T05:11:49+00:00",
    "categories": [
      "cs.PL",
      "cs.MS",
      "math.OC"
    ],
    "primary_category": "cs.PL"
  },
  {
    "id": "http://arxiv.org/abs/2506.01326v2",
    "title": "ORMind: A Cognitive-Inspired End-to-End Reasoning Framework for Operations Research",
    "authors": [
      "Zhiyuan Wang",
      "Bokui Chen",
      "Yinya Huang",
      "Qingxing Cao",
      "Ming He",
      "Jianping Fan",
      "Xiaodan Liang"
    ],
    "abstract": "Operations research (OR) is widely deployed to solve critical decision-making\nproblems with complex objectives and constraints, impacting manufacturing,\nlogistics, finance, and healthcare outcomes. While Large Language Models (LLMs)\nhave shown promising results in various domains, their practical application in\nindustry-relevant operations research (OR) problems presents significant\nchallenges and opportunities. Preliminary industrial applications of LLMs for\noperations research face two critical deployment challenges: 1) Self-correction\nfocuses on code syntax rather than mathematical accuracy, causing costly\nerrors; 2) Complex expert selection creates unpredictable workflows that reduce\ntransparency and increase maintenance costs, making them impractical for\ntime-sensitive business applications. To address these business limitations, we\nintroduce ORMind, a cognitive-inspired framework that enhances optimization\nthrough counterfactual reasoning. Our approach emulates human cognition,\nimplementing an end-to-end workflow that systematically transforms requirements\ninto mathematical models and executable solver code. It is currently being\ntested internally in Lenovo's AI Assistant, with plans to enhance optimization\ncapabilities for both business and consumer customers. Experiments demonstrate\nthat ORMind outperforms existing methods, achieving a 9.5\\% improvement on the\nNL4Opt dataset and a 14.6\\% improvement on the ComplexOR dataset.",
    "pdf_url": "http://arxiv.org/pdf/2506.01326v2",
    "published": "2025-06-02T05:11:21+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2506.01325v2",
    "title": "Understanding the Identity-Transformation Approach in OIDC-Compatible Privacy-Preserving SSO Services",
    "authors": [
      "Jingqiang Lin",
      "Baitao Zhang",
      "Wei Wang",
      "Quanwei Cai",
      "Jiwu Jing",
      "Huiyang He"
    ],
    "abstract": "OpenID Connect (OIDC) enables a user with commercial-off-the-shelf browsers\nto log into multiple websites, called relying parties (RPs), by her username\nand credential set up in another trusted web system, called the identity\nprovider (IdP). Identity transformations are proposed in UppreSSO to provide\nOIDC-compatible SSO services, preventing both IdP-based login tracing and\nRP-based identity linkage. While security and privacy of SSO services in\nUppreSSO have been proved, several essential issues of this\nidentity-transformation approach are not well studied. In this paper, we\ncomprehensively investigate the approach as below. Firstly, several suggestions\nfor the efficient integration of identity transformations in OIDC-compatible\nSSO are explained. Then, we uncover the relationship between\nidentity-transformations in SSO and oblivious pseudo-random functions (OPRFs),\nand present two variations of the properties required for SSO security as well\nas the privacy requirements, to analyze existing OPRF protocols. Finally, new\nidentity transformations different from those designed in UppreSSO, are\nconstructed based on OPRFs, satisfying different variations of SSO security\nrequirements. To the best of our knowledge, this is the first time to uncover\nthe relationship between identity transformations in OIDC-compatible\nprivacy-preserving SSO services and OPRFs, and prove the SSO-related properties\n(i.e., key-identifier freeness, RP designation and user identification) of OPRF\nprotocols, in addition to the basic properties of correctness, obliviousness\nand pseudo-randomness.",
    "pdf_url": "http://arxiv.org/pdf/2506.01325v2",
    "published": "2025-06-02T05:11:01+00:00",
    "categories": [
      "cs.CR"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2506.01324v2",
    "title": "Near-Optimal Clustering in Mixture of Markov Chains",
    "authors": [
      "Junghyun Lee",
      "Yassir Jedra",
      "Alexandre Proutière",
      "Se-Young Yun"
    ],
    "abstract": "We study the problem of clustering $T$ trajectories of length $H$, each\ngenerated by one of $K$ unknown ergodic Markov chains over a finite state space\nof size $S$. The goal is to accurately group trajectories according to their\nunderlying generative model. We begin by deriving an instance-dependent,\nhigh-probability lower bound on the clustering error rate, governed by the\nweighted KL divergence between the transition kernels of the chains. We then\npresent a novel two-stage clustering algorithm. In Stage~I, we apply spectral\nclustering using a new injective Euclidean embedding for ergodic Markov chains\n-- a contribution of independent interest that enables sharp concentration\nresults. Stage~II refines the initial clusters via a single step of\nlikelihood-based reassignment. Our method achieves a near-optimal clustering\nerror with high probability, under the conditions $H =\n\\tilde{\\Omega}(\\gamma_{\\mathrm{ps}}^{-1} (S^2 \\vee \\pi_{\\min}^{-1}))$ and $TH =\n\\tilde{\\Omega}(\\gamma_{\\mathrm{ps}}^{-1} S^2 )$, where $\\pi_{\\min}$ is the\nminimum stationary probability of a state across the $K$ chains and\n$\\gamma_{\\mathrm{ps}}$ is the minimum pseudo-spectral gap. These requirements\nprovide significant improvements, if not at least comparable, to the\nstate-of-the-art guarantee (Kausik et al., 2023), and moreover, our algorithm\noffers a key practical advantage: unlike existing approach, it requires no\nprior knowledge of model-specific quantities (e.g., separation between kernels\nor visitation probabilities). We conclude by discussing the inherent gap\nbetween our upper and lower bounds, providing insights into the unique\nstructure of this clustering problem.",
    "pdf_url": "http://arxiv.org/pdf/2506.01324v2",
    "published": "2025-06-02T05:10:40+00:00",
    "categories": [
      "stat.ML",
      "cs.IT",
      "cs.LG",
      "math.IT",
      "math.PR"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2506.01323v3",
    "title": "Computing Diverse and Nice Triangulations",
    "authors": [
      "Waldo Gálvez",
      "Mayank Goswami",
      "Arturo Merino",
      "GiBeom Park",
      "Meng-Tsung Tsai"
    ],
    "abstract": "We initiate the study of computing diverse triangulations to a given polygon.\nGiven a simple $n$-gon $P$, an integer $ k \\geq 2 $, a quality measure $\\sigma$\non the set of triangulations of $P$ and a factor $ \\alpha \\geq 1 $, we\nformulate the Diverse and Nice Triangulations (DNT) problem that asks to\ncompute $k$ \\emph{distinct} triangulations $T_1,\\dots,T_k$ of $P$ such that a)\ntheir diversity, $\\sum_{i < j} d(T_i,T_j) $, is as large as possible \\emph{and}\nb) they are nice, i.e., $\\sigma(T_i) \\leq \\alpha \\sigma^* $ for all $1\\leq i\n\\leq k$. Here, $d$ denotes the symmetric difference of edge sets of two\ntriangulations, and $\\sigma^*$ denotes the best quality of triangulations of\n$P$, e.g., the minimum Euclidean length.\n  As our main result, we provide a $\\mathrm{poly}(n,k)$-time approximation\nalgorithm for the DNT problem that returns a collection of $k$ distinct\ntriangulations whose diversity is at least $1 - \\Theta(1/k)$ of the optimal,\nand each triangulation satisfies the quality constraint. This is accomplished\nby studying \\emph{bi-criteria triangulations} (BCT), which are triangulations\nthat simultaneously optimize two criteria, a topic of independent interest. We\ncomplement our approximation algorithms by showing that the DNT problem and the\nBCT problem are NP-hard.\n  Finally, for the version where diversity is defined as $\\min_{i < j}\nd(T_i,T_j) $, we show a reduction from the problem of computing optimal Hamming\ncodes, and provide an $n^{O(k)}$-time $\\tfrac12$-approximation algorithm. This\nimproves over the naive ${C_{n-2} \\choose k} \\approx 2^{O(nk)}$ time bound for\nenumerating all $k$-tuples among the triangulations of a simple $n$-gon, where\n$C_n$ denotes the $n$-th Catalan number.",
    "pdf_url": "http://arxiv.org/pdf/2506.01323v3",
    "published": "2025-06-02T05:10:16+00:00",
    "categories": [
      "cs.CG",
      "cs.DS"
    ],
    "primary_category": "cs.CG"
  },
  {
    "id": "http://arxiv.org/abs/2506.02070v2",
    "title": "An Introduction to Flow Matching and Diffusion Models",
    "authors": [
      "Peter Holderrieth",
      "Ezra Erives"
    ],
    "abstract": "Diffusion and flow-based models have become the state of the art for\ngenerative AI across a wide range of data modalities, including images, videos,\nshapes, molecules, music, and more. This tutorial provides a self-contained\nintroduction to diffusion and flow-based generative models from first\nprinciples. We systematically develop the necessary mathematical background in\nordinary and stochastic differential equations and derive the core algorithms\nof flow matching and denoising diffusion models. We then provide a step-by-step\nguide to building image and video generators, including training methods,\nguidance, and architectural design. This tutorial is ideal for machine learning\nresearchers who want to develop a principled understanding of the theory and\npractice of generative AI.",
    "pdf_url": "http://arxiv.org/pdf/2506.02070v2",
    "published": "2025-06-02T05:07:25+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.01322v1",
    "title": "Zero-Shot Text-to-Speech for Vietnamese",
    "authors": [
      "Thi Vu",
      "Linh The Nguyen",
      "Dat Quoc Nguyen"
    ],
    "abstract": "This paper introduces PhoAudiobook, a newly curated dataset comprising 941\nhours of high-quality audio for Vietnamese text-to-speech. Using PhoAudiobook,\nwe conduct experiments on three leading zero-shot TTS models: VALL-E,\nVoiceCraft, and XTTS-V2. Our findings demonstrate that PhoAudiobook\nconsistently enhances model performance across various metrics. Moreover,\nVALL-E and VoiceCraft exhibit superior performance in synthesizing short\nsentences, highlighting their robustness in handling diverse linguistic\ncontexts. We publicly release PhoAudiobook to facilitate further research and\ndevelopment in Vietnamese text-to-speech.",
    "pdf_url": "http://arxiv.org/pdf/2506.01322v1",
    "published": "2025-06-02T05:07:06+00:00",
    "categories": [
      "cs.CL",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.01321v1",
    "title": "Twisted associative algebras associated to vertex algebras",
    "authors": [
      "Shun Xu"
    ],
    "abstract": "Let $V$ be a vertex algebra and $g$ an automorphism of $V$ of order $T$. We\nconstruct a sequence of associative algebras $\\tilde{A}_{g,n}(V )$ for any\n$n\\in(1/T)\\mathbb{N}$, which are not depend on the conformal structure of $V$.\nWe show that for a vertex operator algebra, $g$-rationality, $g$-regularity,\nand twisted fusion rules are independent of the choice of the conformal vector.",
    "pdf_url": "http://arxiv.org/pdf/2506.01321v1",
    "published": "2025-06-02T05:03:12+00:00",
    "categories": [
      "math.QA"
    ],
    "primary_category": "math.QA"
  },
  {
    "id": "http://arxiv.org/abs/2506.01320v2",
    "title": "Psi-Sampler: Initial Particle Sampling for SMC-Based Inference-Time Reward Alignment in Score Models",
    "authors": [
      "Taehoon Yoon",
      "Yunhong Min",
      "Kyeongmin Yeo",
      "Minhyuk Sung"
    ],
    "abstract": "We introduce $\\Psi$-Sampler, an SMC-based framework incorporating pCNL-based\ninitial particle sampling for effective inference-time reward alignment with a\nscore-based generative model. Inference-time reward alignment with score-based\ngenerative models has recently gained significant traction, following a broader\nparadigm shift from pre-training to post-training optimization. At the core of\nthis trend is the application of Sequential Monte Carlo (SMC) to the denoising\nprocess. However, existing methods typically initialize particles from the\nGaussian prior, which inadequately captures reward-relevant regions and results\nin reduced sampling efficiency. We demonstrate that initializing from the\nreward-aware posterior significantly improves alignment performance. To enable\nposterior sampling in high-dimensional latent spaces, we introduce the\npreconditioned Crank-Nicolson Langevin (pCNL) algorithm, which combines\ndimension-robust proposals with gradient-informed dynamics. This approach\nenables efficient and scalable posterior sampling and consistently improves\nperformance across various reward alignment tasks, including layout-to-image\ngeneration, quantity-aware generation, and aesthetic-preference generation, as\ndemonstrated in our experiments. Project Webpage:\nhttps://psi-sampler.github.io/",
    "pdf_url": "http://arxiv.org/pdf/2506.01320v2",
    "published": "2025-06-02T05:02:33+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.01319v1",
    "title": "Learning Sparsity for Effective and Efficient Music Performance Question Answering",
    "authors": [
      "Xingjian Diao",
      "Tianzhen Yang",
      "Chunhui Zhang",
      "Weiyi Wu",
      "Ming Cheng",
      "Jiang Gui"
    ],
    "abstract": "Music performances, characterized by dense and continuous audio as well as\nseamless audio-visual integration, present unique challenges for multimodal\nscene understanding and reasoning. Recent Music Performance Audio-Visual\nQuestion Answering (Music AVQA) datasets have been proposed to reflect these\nchallenges, highlighting the continued need for more effective integration of\naudio-visual representations in complex question answering. However, existing\nMusic AVQA methods often rely on dense and unoptimized representations, leading\nto inefficiencies in the isolation of key information, the reduction of\nredundancy, and the prioritization of critical samples. To address these\nchallenges, we introduce Sparsify, a sparse learning framework specifically\ndesigned for Music AVQA. It integrates three sparsification strategies into an\nend-to-end pipeline and achieves state-of-the-art performance on the Music AVQA\ndatasets. In addition, it reduces training time by 28.32% compared to its fully\ntrained dense counterpart while maintaining accuracy, demonstrating clear\nefficiency gains. To further improve data efficiency, we propose a key-subset\nselection algorithm that selects and uses approximately 25% of MUSIC-AVQA v2.0\ntraining data and retains 70-80% of full-data performance across models.",
    "pdf_url": "http://arxiv.org/pdf/2506.01319v1",
    "published": "2025-06-02T05:02:03+00:00",
    "categories": [
      "cs.SD",
      "cs.CV",
      "cs.MM",
      "eess.AS"
    ],
    "primary_category": "cs.SD"
  },
  {
    "id": "http://arxiv.org/abs/2506.01318v2",
    "title": "Unlearning's Blind Spots: Over-Unlearning and Prototypical Relearning Attack",
    "authors": [
      "SeungBum Ha",
      "Saerom Park",
      "Sung Whan Yoon"
    ],
    "abstract": "Machine unlearning (MU) aims to expunge a designated forget set from a\ntrained model without costly retraining, yet the existing techniques overlook\ntwo critical blind spots: \"over-unlearning\" that deteriorates retained data\nnear the forget set, and post-hoc \"relearning\" attacks that aim to resurrect\nthe forgotten knowledge. We first derive the over-unlearning metric\nOU@{\\epsilon}, which represents the collateral damage to the nearby region of\nthe forget set, where the over-unlearning mainly appears. Next, we expose an\nunforeseen relearning threat on MU, i.e., the Prototypical Relearning Attack,\nwhich exploits the per-class prototype of the forget class with just a few\nsamples, and easily restores the pre-unlearning performance. To counter both\nblind spots, we introduce Spotter, a plug-and-play objective that combines (i)\na masked knowledge-distillation penalty on the nearby region of forget set to\nsuppress OU@{\\epsilon}, and (ii) an intra-class dispersion loss that scatters\nforget-class embeddings, neutralizing prototypical relearning attacks. On\nCIFAR-10, as one of validations, Spotter reduces OU@{\\epsilon}by below the\n0.05X of the baseline, drives forget accuracy to 0%, preserves accuracy of the\nretain set within 1% of difference with the original, and denies the\nprototype-attack by keeping the forget set accuracy within <1%, without\naccessing retained data. It confirms that Spotter is a practical remedy of the\nunlearning's blind spots.",
    "pdf_url": "http://arxiv.org/pdf/2506.01318v2",
    "published": "2025-06-02T05:01:30+00:00",
    "categories": [
      "cs.LG",
      "cs.AI",
      "I.2.6"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.01317v1",
    "title": "T-SHIRT: Token-Selective Hierarchical Data Selection for Instruction Tuning",
    "authors": [
      "Yanjun Fu",
      "Faisal Hamman",
      "Sanghamitra Dutta"
    ],
    "abstract": "Instruction tuning is essential for Large Language Models (LLMs) to\neffectively follow user instructions. To improve training efficiency and reduce\ndata redundancy, recent works use LLM-based scoring functions, e.g.,\nInstruction-Following Difficulty (IFD), to select high-quality\ninstruction-tuning data with scores above a threshold. While these data\nselection methods often lead to models that can match or even exceed the\nperformance of models trained on the full datasets, we identify two key\nlimitations: (i) they assess quality at the sample level, ignoring token-level\ninformativeness; and (ii) they overlook the robustness of the scoring method,\noften selecting a sample due to superficial lexical features instead of its\ntrue quality. In this work, we propose Token-Selective HIeRarchical Data\nSelection for Instruction Tuning (T-SHIRT), a novel data selection framework\nthat introduces a new scoring method to include only informative tokens in\nquality evaluation and also promotes robust and reliable samples whose\nneighbors also show high quality with less local inconsistencies. We\ndemonstrate that models instruction-tuned on a curated dataset (only 5% of the\noriginal size) using T-SHIRT can outperform those trained on the entire\nlarge-scale dataset by up to 5.48 points on average across eight benchmarks.\nAcross various LLMs and training set scales, our method consistently surpasses\nexisting state-of-the-art data selection techniques, while also remaining both\ncost-effective and highly efficient. For instance, by using GPT-2 for score\ncomputation, we are able to process a dataset of 52k samples using 40 minutes\non a single GPU.",
    "pdf_url": "http://arxiv.org/pdf/2506.01317v1",
    "published": "2025-06-02T04:59:17+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.01316v1",
    "title": "Non-conformality of large deviations of moving average of the random walk in strongly mixing environment",
    "authors": [
      "Jiaming Chen"
    ],
    "abstract": "The quenched and annealed large deviations of the random walk in random\nenvironment are shown to conform on any compact set whenever the level of\ndisorder is sufficiently low. In this work, we show that these two large\ndeviations always disagree at some interior point of the natural domain of the\nrandom walk in strongly mixing environment, regardless of the level of\ndisorder.",
    "pdf_url": "http://arxiv.org/pdf/2506.01316v1",
    "published": "2025-06-02T04:58:04+00:00",
    "categories": [
      "math.PR"
    ],
    "primary_category": "math.PR"
  },
  {
    "id": "http://arxiv.org/abs/2506.01315v1",
    "title": "Regular genus of $\\mathbb{S}^2 \\times \\mathbb{S}^1 \\times \\mathbb{S}^1$, $4$-torus, and small covers over $Δ^2 \\times Δ^2$",
    "authors": [
      "Anshu Agarwal",
      "Biplab Basak"
    ],
    "abstract": "A crystallization of a PL manifold is an edge-colored graph encoding a\ncontracted triangulation of the manifold. The concept of regular genus\ngeneralizes the notions of surface genus and Heegaard genus for 3-manifolds to\nhigher-dimensional closed PL manifolds. The regular genus of a PL manifold is a\nPL invariant. Determining the regular genus of a closed PL $n$-manifold remains\na fundamental challenge in combinatorial topology. In this article, we first\nresolve a conjecture by proving that the regular genus of $\\mathbb{S}^2 \\times\n\\mathbb{S}^1 \\times \\mathbb{S}^1$ is 6. Additionally, we determine that the\nregular genus of $\\mathbb{S}^1 \\times \\mathbb{S}^1 \\times \\mathbb{S}^1 \\times\n\\mathbb{S}^1$ is 16. We also present some observations related to the regular\ngenus of the $n$-dimensional torus and conjecture that the regular genus of\n$\\mathbb{S}^1 \\times \\mathbb{S}^1 \\times \\cdots \\times \\mathbb{S}^1$ ($n$\ntimes) is $1+\\frac{(n+1)! \\ (n-3)}{8}$, for $n\\ge 5$. Then, we investigate the\nregular genus of small covers. Small covers are closed $n$-manifolds admitting\na locally standard $\\mathbb{Z}_2^n$-action with orbit space homeomorphic to a\nsimple convex polytope $P^n$. For the polytope $P = \\Delta^2 \\times \\Delta^2$,\nwe classify all the small covers up to Davis-Januszkiewicz (D-J) equivalence\nand show that there are exactly seven such covers. Among these, one is\n$\\mathbb{RP}^2 \\times \\mathbb{RP}^2$, while the others are\n$\\mathbb{RP}^2$-bundles over $\\mathbb{RP}^2$. Remarkably, each of these seven\nsmall covers has the regular genus 8. Results in this article provide explicit\nregular genus values for several important 4-manifolds, offering new insights\nand tools for future work in combinatorial topology.",
    "pdf_url": "http://arxiv.org/pdf/2506.01315v1",
    "published": "2025-06-02T04:55:54+00:00",
    "categories": [
      "math.GT",
      "math.CO",
      "57Q15"
    ],
    "primary_category": "math.GT"
  },
  {
    "id": "http://arxiv.org/abs/2506.01314v2",
    "title": "Emergent symmetry in a two-Higgs-doublet model from quantum information and nonstabiliserness",
    "authors": [
      "Giorgio Busoni",
      "John Gargalionis",
      "Ewan N. V. Wallace",
      "Martin J. White"
    ],
    "abstract": "Studies of scattering processes in scalar models with two Higgs doublets have\nrecently hinted at a connection between the absence of flavour-space\nentanglement in $\\Phi^+\\Phi^0$ scattering and an emergent $\\mathrm{SO}(8)$\nsymmetry in the scalar potential. We extend the analysis to all scattering\nchannels with two particles in the external states by treating the process as a\nfour-qubit system in the weak isospin and flavour subspaces of the $2$-particle\nstate. We work with a generic quantum information-theoretic principle encoded\nby the commutativity of the initial state density matrix with the transition\nmatrix (at leading order in perturbation theory). This yields a special case of\nthe entanglement minimisation conditions previously derived in the literature,\nand we interpret the principle in terms of the conservation of\nnon-stabiliserness (or magic). Working at leading order in the quartic\ncouplings, we find a consistent set of conditions that implies an\n$\\mathrm{SO}(8)$ symmetry on the quartic part of the potential for scattering\nan arbitrary initial state, but a smaller $\\mathrm{SU}(2)_R$ symmetry when the\ninitial state is chosen to have definite isospin. This follows by accounting\nfor Bose symmetry in the initial state, which introduces entanglement between\nthe isospin and flavour subspaces.",
    "pdf_url": "http://arxiv.org/pdf/2506.01314v2",
    "published": "2025-06-02T04:53:35+00:00",
    "categories": [
      "hep-ph",
      "hep-th",
      "quant-ph"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.01313v1",
    "title": "Surjectivity and flatness over DVR's (after Moret-Bailly)",
    "authors": [
      "Benedictus Margaux"
    ],
    "abstract": "We study morphisms of schemes $f : X \\to S$ which are locally of finite type.\nWe present conditions under which there exists a morphism $g : S'\\to X$ of\n$S$--schemes such that $f \\circ g $ is the canonical morphism $S'\\to S$.\nFurthermore, we exhibit situations in which $f$ is flat surjective. Our results\nare mostly concerned with $S$ being the spectrum of a DVR.",
    "pdf_url": "http://arxiv.org/pdf/2506.01313v1",
    "published": "2025-06-02T04:53:34+00:00",
    "categories": [
      "math.AG",
      "14B25, 14E22"
    ],
    "primary_category": "math.AG"
  },
  {
    "id": "http://arxiv.org/abs/2506.01312v1",
    "title": "Growing Through Experience: Scaling Episodic Grounding in Language Models",
    "authors": [
      "Chunhui Zhang",
      "Sirui",
      "Wang",
      "Zhongyu Ouyang",
      "Xiangchi Yuan",
      "Soroush Vosoughi"
    ],
    "abstract": "Language models (LMs) require robust episodic grounding-the capacity to learn\nfrom and apply past experiences-to excel at physical planning tasks. Current\nepisodic grounding approaches struggle with scalability and integration,\nlimiting their effectiveness, especially for medium-sized LMs (7B parameters).\nWhile larger LMs (70-405B parameters) possess superior hierarchical\nrepresentations and extensive pre-trained knowledge, they encounter a\nfundamental scale paradox: despite their advanced abstraction capabilities,\nthey lack efficient mechanisms to leverage experience streams. We propose a\nscalable weak-to-strong episodic learning framework that effectively transfers\nepisodic behaviors from smaller to larger LMs. This framework integrates Monte\nCarlo tree search for structured experience collection with a novel\ndistillation method, preserving the inherent LM capabilities while embedding\nepisodic memory. Experiments demonstrate our method surpasses state-of-the-art\nproprietary LMs by 3.45% across diverse planning and question-answering tasks.\nLayer-wise probing further indicates significant improvements in task\nalignment, especially within deeper LM layers, highlighting stable\ngeneralization even for previously unseen scenarios with increased planning\ncomplexity-conditions where baseline methods degrade markedly.",
    "pdf_url": "http://arxiv.org/pdf/2506.01312v1",
    "published": "2025-06-02T04:52:19+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.01311v1",
    "title": "Energy Considerations for Large Pretrained Neural Networks",
    "authors": [
      "Leo Mei",
      "Mark Stamp"
    ],
    "abstract": "Increasingly complex neural network architectures have achieved phenomenal\nperformance. However, these complex models require massive computational\nresources that consume substantial amounts of electricity, which highlights the\npotential environmental impact of such models. Previous studies have\ndemonstrated that substantial redundancies exist in large pre-trained models.\nHowever, previous work has primarily focused on compressing models while\nretaining comparable model performance, and the direct impact on electricity\nconsumption appears to have received relatively little attention. By\nquantifying the energy usage associated with both uncompressed and compressed\nmodels, we investigate compression as a means of reducing electricity\nconsumption. We consider nine different pre-trained models, ranging in size\nfrom 8M parameters to 138M parameters. To establish a baseline, we first train\neach model without compression and record the electricity usage and time\nrequired during training, along with other relevant statistics. We then apply\nthree compression techniques: Steganographic capacity reduction, pruning, and\nlow-rank factorization. In each of the resulting cases, we again measure the\nelectricity usage, training time, model accuracy, and so on. We find that\npruning and low-rank factorization offer no significant improvements with\nrespect to energy usage or other related statistics, while steganographic\ncapacity reduction provides major benefits in almost every case. We discuss the\nsignificance of these findings.",
    "pdf_url": "http://arxiv.org/pdf/2506.01311v1",
    "published": "2025-06-02T04:39:24+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.01310v1",
    "title": "Rigid affine cones over singular del Pezzo surfaces",
    "authors": [
      "In-Kyun Kim",
      "Jaehyun Kim",
      "Joonyeong Won"
    ],
    "abstract": "We completely determine the existence of anticanonical polar cylinders in\nquasi-smooth log del Pezzo surfaces of index one.",
    "pdf_url": "http://arxiv.org/pdf/2506.01310v1",
    "published": "2025-06-02T04:37:43+00:00",
    "categories": [
      "math.AG"
    ],
    "primary_category": "math.AG"
  },
  {
    "id": "http://arxiv.org/abs/2506.01309v1",
    "title": "A continuum mechanics approach for the deformation of non-Euclidean origami generated by piecewise constant nematic director fields",
    "authors": [
      "Linjuan Wang",
      "Fan Feng"
    ],
    "abstract": "We merge classical origami concepts with active actuation by designing\norigami patterns whose panels undergo prescribed metric changes. These metric\nchanges render the system non-Euclidean, inducing non-zero Gaussian curvature\nat the vertices after actuation. Such patterns can be realized by programming\npiecewise constant director fields in liquid crystal elastomer (LCE) sheets. In\nthis work, we address the geometric design of both compatible reference\ndirector patterns and their corresponding actuated configurations. On the\nreference configuration, we systematically construct director patterns that\nsatisfy metric compatibility across interfaces. On the actuated configuration,\nwe develop a continuum mechanics framework to analyze the kinematics of\nnon-Euclidean origami. In particular, we fully characterize the deformation\nspaces of three-fold and four-fold vertices and establish analytical\nrelationships between their deformations and the director patterns. Building on\nthese kinematic insights, we propose two rational designs of large director\npatterns: one based on a quadrilateral tiling with alternating positive and\nnegative actuated Gaussian curvature, and another combining three-fold and\nfour-fold vertices governed by a folding angle theorem. Remarkably, both\ndesigns achieve compatibility in both the reference and actuated states. We\nanticipate that our geometric framework will facilitate the design of\nnon-Euclidean/active origami structures and broaden their application in active\nmetamaterials, soft actuators, and robotic systems.",
    "pdf_url": "http://arxiv.org/pdf/2506.01309v1",
    "published": "2025-06-02T04:37:00+00:00",
    "categories": [
      "cond-mat.soft"
    ],
    "primary_category": "cond-mat.soft"
  },
  {
    "id": "http://arxiv.org/abs/2506.01308v1",
    "title": "A Platform for Investigating Public Health Content with Efficient Concern Classification",
    "authors": [
      "Christopher Li",
      "Rickard Stureborg",
      "Bhuwan Dhingra",
      "Jun Yang"
    ],
    "abstract": "A recent rise in online content expressing concerns with public health\ninitiatives has contributed to already stalled uptake of preemptive measures\nglobally. Future public health efforts must attempt to understand such content,\nwhat concerns it may raise among readers, and how to effectively respond to it.\nTo this end, we present ConcernScope, a platform that uses a teacher-student\nframework for knowledge transfer between large language models and light-weight\nclassifiers to quickly and effectively identify the health concerns raised in a\ntext corpus. The platform allows uploading massive files directly,\nautomatically scraping specific URLs, and direct text editing. ConcernScope is\nbuilt on top of a taxonomy of public health concerns. Intended for public\nhealth officials, we demonstrate several applications of this platform: guided\ndata exploration to find useful examples of common concerns found in online\ncommunity datasets, identification of trends in concerns through an example\ntime series analysis of 186,000 samples, and finding trends in topic frequency\nbefore and after significant events.",
    "pdf_url": "http://arxiv.org/pdf/2506.01308v1",
    "published": "2025-06-02T04:36:13+00:00",
    "categories": [
      "cs.CL",
      "cs.IR",
      "cs.LG"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.01307v1",
    "title": "Align is not Enough: Multimodal Universal Jailbreak Attack against Multimodal Large Language Models",
    "authors": [
      "Youze Wang",
      "Wenbo Hu",
      "Yinpeng Dong",
      "Jing Liu",
      "Hanwang Zhang",
      "Richang Hong"
    ],
    "abstract": "Large Language Models (LLMs) have evolved into Multimodal Large Language\nModels (MLLMs), significantly enhancing their capabilities by integrating\nvisual information and other types, thus aligning more closely with the nature\nof human intelligence, which processes a variety of data forms beyond just\ntext. Despite advancements, the undesirable generation of these models remains\na critical concern, particularly due to vulnerabilities exposed by text-based\njailbreak attacks, which have represented a significant threat by challenging\nexisting safety protocols. Motivated by the unique security risks posed by the\nintegration of new and old modalities for MLLMs, we propose a unified\nmultimodal universal jailbreak attack framework that leverages iterative\nimage-text interactions and transfer-based strategy to generate a universal\nadversarial suffix and image. Our work not only highlights the interaction of\nimage-text modalities can be used as a critical vulnerability but also\nvalidates that multimodal universal jailbreak attacks can bring higher-quality\nundesirable generations across different MLLMs. We evaluate the undesirable\ncontext generation of MLLMs like LLaVA, Yi-VL, MiniGPT4, MiniGPT-v2, and\nInstructBLIP, and reveal significant multimodal safety alignment issues,\nhighlighting the inadequacy of current safety mechanisms against sophisticated\nmultimodal attacks. This study underscores the urgent need for robust safety\nmeasures in MLLMs, advocating for a comprehensive review and enhancement of\nsecurity protocols to mitigate potential risks associated with multimodal\ncapabilities.",
    "pdf_url": "http://arxiv.org/pdf/2506.01307v1",
    "published": "2025-06-02T04:33:56+00:00",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2506.01306v3",
    "title": "Asymptotic of Coulomb gas integral, Temperley-Lieb type algebras and pure partition functions",
    "authors": [
      "Jiaxin Zhang"
    ],
    "abstract": "In this supplementary note, we study the asymptotic behavior of several types\nof Coulomb gas integrals and construct the pure partition functions for\nmultiple radial $\\mathrm{SLE}(\\kappa)$ and general multiple chordal\n$\\mathrm{SLE}(\\kappa)$ systems.\n  For both radial and chordal cases, we prove the linear independence of the\nground state solutions $J_{\\alpha}^{(m,n)}(\\boldsymbol{x})$ to the null vector\nequations for irrational values of $\\kappa \\in (0,8)$.\n  In particular, we show that the ground state solutions $J^{(m,n)}_\\alpha \\in\nB_{m,n}$, indexed by link patterns $\\alpha$ with $m$ screening charges, are\nlinearly independent when $\\kappa$ is irrational. This is achieved by\nconstructing, for each link pattern $\\beta$, a dual functional $l_\\beta \\in\nB^{*}_{m,n}$ such that the meander matrix of the corresponding Temperley-Lieb\ntype algebra is given by $M_{\\alpha\\beta} = l_{\\beta}(J^{(m,n)}_\\alpha)$. The\ndeterminant of this matrix admits an explicit expression and is nonzero for\nirrational $\\kappa$, establishing the desired linear independence.\n  As a consequence, we construct the pure partition functions\n$Z_{\\alpha}(\\boldsymbol{x})$ of the multiple $\\mathrm{SLE}(\\kappa)$ systems for\neach link pattern $\\alpha$ by multiplying the inverse of the meander matrix.\n  This method can also be extended to the asymptotic analysis of the excited\nstate solutions $K_{\\alpha}$ in both radial and chordal cases.",
    "pdf_url": "http://arxiv.org/pdf/2506.01306v3",
    "published": "2025-06-02T04:33:12+00:00",
    "categories": [
      "math.PR",
      "math-ph",
      "math.MP"
    ],
    "primary_category": "math.PR"
  },
  {
    "id": "http://arxiv.org/abs/2506.01305v2",
    "title": "VM14K: First Vietnamese Medical Benchmark",
    "authors": [
      "Thong Nguyen",
      "Duc Nguyen",
      "Minh Dang",
      "Thai Dao",
      "Long Nguyen",
      "Quan H. Nguyen",
      "Dat Nguyen",
      "Kien Tran",
      "Minh Tran"
    ],
    "abstract": "Medical benchmarks are indispensable for evaluating the capabilities of\nlanguage models in healthcare for non-English-speaking communities,therefore\nhelp ensuring the quality of real-life applications. However, not every\ncommunity has sufficient resources and standardized methods to effectively\nbuild and design such benchmark, and available non-English medical data is\nnormally fragmented and difficult to verify. We developed an approach to tackle\nthis problem and applied it to create the first Vietnamese medical question\nbenchmark, featuring 14,000 multiple-choice questions across 34 medical\nspecialties. Our benchmark was constructed using various verifiable sources,\nincluding carefully curated medical exams and clinical records, and eventually\nannotated by medical experts. The benchmark includes four difficulty levels,\nranging from foundational biological knowledge commonly found in textbooks to\ntypical clinical case studies that require advanced reasoning. This design\nenables assessment of both the breadth and depth of language models' medical\nunderstanding in the target language thanks to its extensive coverage and\nin-depth subject-specific expertise. We release the benchmark in three parts: a\nsample public set (4k questions), a full public set (10k questions), and a\nprivate set (2k questions) used for leaderboard evaluation. Each set contains\nall medical subfields and difficulty levels. Our approach is scalable to other\nlanguages, and we open-source our data construction pipeline to support the\ndevelopment of future multilingual benchmarks in the medical domain.",
    "pdf_url": "http://arxiv.org/pdf/2506.01305v2",
    "published": "2025-06-02T04:32:15+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.01304v1",
    "title": "SAM-I2V: Upgrading SAM to Support Promptable Video Segmentation with Less than 0.2% Training Cost",
    "authors": [
      "Haiyang Mei",
      "Pengyu Zhang",
      "Mike Zheng Shou"
    ],
    "abstract": "Foundation models like the Segment Anything Model (SAM) have significantly\nadvanced promptable image segmentation in computer vision. However, extending\nthese capabilities to videos presents substantial challenges, particularly in\nensuring precise and temporally consistent mask propagation in dynamic scenes.\nSAM 2 attempts to address this by training a model on massive image and video\ndata from scratch to learn complex spatiotemporal associations, resulting in\nhuge training costs that hinder research and practical deployment. In this\npaper, we introduce SAM-I2V, an effective image-to-video upgradation method for\ncultivating a promptable video segmentation (PVS) model. Our approach\nstrategically upgrades the pre-trained SAM to support PVS, significantly\nreducing training complexity and resource requirements. To achieve this, we\nintroduce three key innovations: (i) an image-to-video feature extraction\nupgrader built upon SAM's static image encoder to enable spatiotemporal video\nperception, (ii) a memory filtering strategy that selects the most relevant\npast frames for more effective utilization of historical information, and (iii)\na memory-as-prompt mechanism leveraging object memory to ensure temporally\nconsistent mask propagation in dynamic scenes. Comprehensive experiments\ndemonstrate that our method achieves over 90% of SAM 2's performance while\nusing only 0.2% of its training cost. Our work presents a resource-efficient\npathway to PVS, lowering barriers for further research in PVS model design and\nenabling broader applications and advancements in the field. Code and model are\navailable at: https://github.com/showlab/SAM-I2V.",
    "pdf_url": "http://arxiv.org/pdf/2506.01304v1",
    "published": "2025-06-02T04:30:14+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.01303v2",
    "title": "Latent Structured Hopfield Network for Semantic Association and Retrieval",
    "authors": [
      "Chong Li",
      "Xiangyang Xue",
      "Jianfeng Feng",
      "Taiping Zeng"
    ],
    "abstract": "Episodic memory enables humans to recall past experiences by associating\nsemantic elements such as objects, locations, and time into coherent event\nrepresentations. While large pretrained models have shown remarkable progress\nin modeling semantic memory, the mechanisms for forming associative structures\nthat support episodic memory remain underexplored. Inspired by hippocampal CA3\ndynamics and its role in associative memory, we propose the Latent Structured\nHopfield Network (LSHN), a biologically inspired framework that integrates\ncontinuous Hopfield attractor dynamics into an autoencoder architecture. LSHN\nmimics the cortical-hippocampal pathway: a semantic encoder extracts compact\nlatent representations, a latent Hopfield network performs associative\nrefinement through attractor convergence, and a decoder reconstructs perceptual\ninput. Unlike traditional Hopfield networks, our model is trained end-to-end\nwith gradient descent, achieving scalable and robust memory retrieval.\nExperiments on MNIST, CIFAR-10, and a simulated episodic memory task\ndemonstrate superior performance in recalling corrupted inputs under occlusion\nand noise, outperforming existing associative memory models. Our work provides\na computational perspective on how semantic elements can be dynamically bound\ninto episodic memory traces through biologically grounded attractor mechanisms.\nCode: https://github.com/fudan-birlab/LSHN.",
    "pdf_url": "http://arxiv.org/pdf/2506.01303v2",
    "published": "2025-06-02T04:24:36+00:00",
    "categories": [
      "cs.LG",
      "q-bio.NC"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.01302v1",
    "title": "Recent Developments in GNNs for Drug Discovery",
    "authors": [
      "Zhengyu Fang",
      "Xiaoge Zhang",
      "Anyin Zhao",
      "Xiao Li",
      "Huiyuan Chen",
      "Jing Li"
    ],
    "abstract": "In this paper, we review recent developments and the role of Graph Neural\nNetworks (GNNs) in computational drug discovery, including molecule generation,\nmolecular property prediction, and drug-drug interaction prediction. By\nsummarizing the most recent developments in this area, we underscore the\ncapabilities of GNNs to comprehend intricate molecular patterns, while\nexploring both their current and prospective applications. We initiate our\ndiscussion by examining various molecular representations, followed by detailed\ndiscussions and categorization of existing GNN models based on their input\ntypes and downstream application tasks. We also collect a list of commonly used\nbenchmark datasets for a variety of applications. We conclude the paper with\nbrief discussions and summarize common trends in this important research area.",
    "pdf_url": "http://arxiv.org/pdf/2506.01302v1",
    "published": "2025-06-02T04:24:05+00:00",
    "categories": [
      "cs.LG",
      "q-bio.QM"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.01301v1",
    "title": "Overcoming Multi-step Complexity in Multimodal Theory-of-Mind Reasoning: A Scalable Bayesian Planner",
    "authors": [
      "Chunhui Zhang",
      "Zhongyu Ouyang",
      "Kwonjoon Lee",
      "Nakul Agarwal",
      "Sean Dae Houlihan",
      "Soroush Vosoughi",
      "Shao-Yuan Lo"
    ],
    "abstract": "Theory-of-Mind (ToM) enables humans to infer mental states-such as beliefs,\ndesires, and intentions-forming the foundation of social cognition. However,\nexisting computational ToM methods rely on structured workflows with\nToM-specific priors or deep model fine-tuning, which struggle with scalability\nin multimodal environments and fail to generalize as task complexity increases.\nTo address these limitations, we propose a scalable Bayesian ToM planner that\ndecomposes ToM reasoning into stepwise Bayesian updates. Our framework\nintroduces weak-to-strong control, allowing smaller language models (LMs) to\nspecialize in ToM-specific likelihood estimation and transfer their reasoning\nbehaviors to larger LMs (7B to 405B) for integration with social and world\nknowledge. This synergistic approach aligns large-model inference of human\nmental states with Bayesian principles. Extensive experiments show that our\nmethod achieves a 4.6% accuracy improvement over state-of-the-art techniques on\nmultimodal ToM benchmarks, including challenging unseen scenarios, thereby\nestablishing a new standard for modeling human mental states in complex\nenvironments.",
    "pdf_url": "http://arxiv.org/pdf/2506.01301v1",
    "published": "2025-06-02T04:23:45+00:00",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2506.01300v1",
    "title": "ReAgent-V: A Reward-Driven Multi-Agent Framework for Video Understanding",
    "authors": [
      "Yiyang Zhou",
      "Yangfan He",
      "Yaofeng Su",
      "Siwei Han",
      "Joel Jang",
      "Gedas Bertasius",
      "Mohit Bansal",
      "Huaxiu Yao"
    ],
    "abstract": "Video understanding is fundamental to tasks such as action recognition, video\nreasoning, and robotic control. Early video understanding methods based on\nlarge vision-language models (LVLMs) typically adopt a single-pass reasoning\nparadigm without dynamic feedback, limiting the model's capacity to\nself-correct and adapt in complex scenarios. Recent efforts have attempted to\naddress this limitation by incorporating reward models and reinforcement\nlearning to enhance reasoning, or by employing tool-agent frameworks. However,\nthese approaches face several challenges, including high annotation costs,\nreward signals that fail to capture real-time reasoning states, and low\ninference efficiency. To overcome these issues, we propose ReAgent-V, a novel\nagentic video understanding framework that integrates efficient frame selection\nwith real-time reward generation during inference. These reward signals not\nonly guide iterative answer refinement through a multi-perspective reflection\nmechanism-adjusting predictions from conservative, neutral, and aggressive\nviewpoints-but also enable automatic filtering of high-quality data for\nsupervised fine-tuning (SFT), direct preference optimization (DPO), and group\nrelative policy optimization (GRPO). ReAgent-V is lightweight, modular, and\nextensible, supporting flexible tool integration tailored to diverse tasks.\nExtensive experiments on 12 datasets across three core applications-video\nunderstanding, video reasoning enhancement, and vision-language-action model\nalignment-demonstrate significant gains in generalization and reasoning, with\nimprovements of up to 6.9%, 2.1%, and 9.8%, respectively, highlighting the\neffectiveness and versatility of the proposed framework.",
    "pdf_url": "http://arxiv.org/pdf/2506.01300v1",
    "published": "2025-06-02T04:23:21+00:00",
    "categories": [
      "cs.CV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.01299v1",
    "title": "Scalable In-Context Q-Learning",
    "authors": [
      "Jinmei Liu",
      "Fuhong Liu",
      "Jianye Hao",
      "Bo Wang",
      "Huaxiong Li",
      "Chunlin Chen",
      "Zhi Wang"
    ],
    "abstract": "Recent advancements in language models have demonstrated remarkable\nin-context learning abilities, prompting the exploration of in-context\nreinforcement learning (ICRL) to extend the promise to decision domains. Due to\ninvolving more complex dynamics and temporal correlations, existing ICRL\napproaches may face challenges in learning from suboptimal trajectories and\nachieving precise in-context inference. In the paper, we propose\n\\textbf{S}calable \\textbf{I}n-\\textbf{C}ontext \\textbf{Q}-\\textbf{L}earning\n(\\textbf{SICQL}), an innovative framework that harnesses dynamic programming\nand world modeling to steer ICRL toward efficient reward maximization and task\ngeneralization, while retaining the scalability and stability of supervised\npretraining. We design a prompt-based multi-head transformer architecture that\nsimultaneously predicts optimal policies and in-context value functions using\nseparate heads. We pretrain a generalized world model to capture task-relevant\ninformation, enabling the construction of a compact prompt that facilitates\nfast and precise in-context inference. During training, we perform iterative\npolicy improvement by fitting a state value function to an upper-expectile of\nthe Q-function, and distill the in-context value functions into policy\nextraction using advantage-weighted regression. Extensive experiments across a\nrange of discrete and continuous environments show consistent performance gains\nover various types of baselines, especially when learning from suboptimal data.\nOur code is available at https://github.com/NJU-RL/SICQL",
    "pdf_url": "http://arxiv.org/pdf/2506.01299v1",
    "published": "2025-06-02T04:21:56+00:00",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2506.01298v2",
    "title": "Visualization of Co-3d high- and low-spin states in an Ising spin chain magnet",
    "authors": [
      "Kamini Gautam",
      "Shunsuke Kitou",
      "Yuiga Nakamura",
      "Arvind Kumar Yogi",
      "Dinesh Kumar Shukla",
      "Taka-hisa Arima"
    ],
    "abstract": "Properties of trivalent cobalt oxide compounds are largely influenced by the\nspin state of the six 3d electrons at each Co site. High-spin Co3+ ions, where\norbital angular momentum is only partially quenched, often exhibit significant\nanisotropy, providing playgrounds for Ising spin systems. However, real-space\nobservations of their orbital states have remained limited. Here, we determine\nthe Co-3d spin and orbital states in an Ising spin chain magnet Ca3Co2O6, where\nhigh- and low-spin states alternate along the chain. Synchrotron x-ray\ndiffraction and valence electron density (VED) analysis, utilizing the core\ndifferential Fourier synthesis (CDFS) method, reveal distinct anisotropic VED\ndistributions around the two inequivalent Co sites. The VED distribution around\nthe octahedral Co site corresponds to a low-spin state, while the\ntrigonal-prismatic Co site exhibits anisotropic VED that cannot be explained by\nthe crystal electric field (CEF) alone. This anisotropy is quantitatively\ncaptured by a model incorporating CEF, spin-orbit coupling, and on-site 3d-4p\norbital hybridization, consistent with a high-spin state exhibiting Ising\nmagnetism.",
    "pdf_url": "http://arxiv.org/pdf/2506.01298v2",
    "published": "2025-06-02T04:20:35+00:00",
    "categories": [
      "cond-mat.str-el"
    ],
    "primary_category": "cond-mat.str-el"
  },
  {
    "id": "http://arxiv.org/abs/2506.01297v3",
    "title": "MobCLIP: Learning General-purpose Geospatial Representation at Scale",
    "authors": [
      "Ya Wen",
      "Jixuan Cai",
      "Qiyao Ma",
      "Linyan Li",
      "Xinhua Chen",
      "Chris Webster",
      "Yulun Zhou"
    ],
    "abstract": "Representation learning of geospatial locations remains a core challenge in\nachieving general geospatial intelligence. Current embedding methods often lack\nversatility, limiting their utility across diverse tasks in both human and\nnatural domains. We present MobCLIP, the first nationwide general-purpose\nlocation encoder, integrating an unprecedented diversity of data modalities\nthrough effective and scalable multimodal fusion. Adopting a novel CLIP-based\narchitecture, our framework aligns 100M+ POIs, nationwide remote sensing\nimagery, and structured demographic statistics with a billion-edge mobility\ngraph. By tokenizing spatial locations into grid cells inspired by Vision\nTransformers, we establish a unified representation space bridging mobility\npatterns and multimodal features. To rigorously evaluate the general-purpose\neffectiveness of MobCLIP, we construct a benchmark dataset composed of 11\ndownstream prediction tasks across social, economic, and natural domains.\nExperiments show that MobCLIP, with four input modalities and a compact\n128-dimensional representation space, achieves significantly superior\ngeneral-purpose predictive performances than state-of-the-art models by an\naverage of 35%. Thanks to the effective integration of human-centric\nmodalities, the performance gain is particularly profound in human-centric\ntasks, such as energy consumption (+260%), offline retail consumption amount\n(+98%), and crime cases (+95%) predictions. Echoing LLM scaling laws, we\nfurther demonstrate the scaling behavior in geospatial representation learning.\nWe open-source code and pretrained models at:\nhttps://github.com/ylzhouchris/MobCLIP.",
    "pdf_url": "http://arxiv.org/pdf/2506.01297v3",
    "published": "2025-06-02T04:14:03+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2506.01296v1",
    "title": "Long-Distance Device-Independent Conference Key Agreement",
    "authors": [
      "Makoto Ishihara",
      "Anders J. E. Bjerrum",
      "Wojciech Roga",
      "Jonatan B. Brask",
      "Ulrik L. Andersen",
      "Masahiro Takeoka"
    ],
    "abstract": "Device-independent quantum key distribution (DI-QKD) enables two remote\nparties to share an information-theoretically secure key without any\nassumptions on the inner workings of the devices used. Device-independent\nconference key agreement (DI-CKA) is multipartite DI-QKD where more than two\nparties share a common secure key. The performance of DI-CKA, however, is\nstrictly limited because of its susceptibility to losses due e.g. to imperfect\ndetection efficiency and channel transmission. Here, we propose a DI-CKA\nprotocol which reduces this limitation by using a heralding scheme to\ndistribute multipartite entanglement. We analyze key rates of our protocol for\ntwo different measurement scenarios and we show that our protocol outperforms a\nprevious DI-CKA protocol even with an experimentally feasible measurement.",
    "pdf_url": "http://arxiv.org/pdf/2506.01296v1",
    "published": "2025-06-02T04:11:30+00:00",
    "categories": [
      "quant-ph"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.01295v1",
    "title": "Adsorbate phase transitions on nanoclusters from nested sampling",
    "authors": [
      "Thanawitch Chatbipho",
      "Ray Yang",
      "Robert B. Wexler",
      "Livia B. Pártay"
    ],
    "abstract": "Nested sampling was employed to investigate adsorption equilibria on the\ntruncated-octahedral Lennard-Jones nanocluster LJ$_{38}$ while systematically\nvarying adsorbate-surface well depth and Lennard-Jones size parameters.\nEvaluation of the canonical partition function over a wide temperature range\nidentifies two successive phase transitions: (i) condensation of the gas phase\nonto the cluster surface at higher temperatures, and (ii) lateral rearrangement\nof the adsorbed layer at lower temperatures. For identical interactions, the\ncondensate first populates both three- and four-fold hollow sites; when\nadsorbate-adsorbate interactions are weakened, preference shifts to the\nfour-coordinated (100) sites. Size mismatch governs low-temperature behavior:\nsmaller adsorbates aggregate to increase mutual contacts, whereas larger ones\ndistribute more evenly to maximize coordination with the cluster. These\nfindings highlight key trends in facet competition and lattice mismatch, and\nshowcase nested sampling as an automated, unbiased tool for exploring surface\nconfigurational space and guiding investigations of more complex, realistic\ninterfaces.",
    "pdf_url": "http://arxiv.org/pdf/2506.01295v1",
    "published": "2025-06-02T04:10:00+00:00",
    "categories": [
      "cond-mat.mtrl-sci",
      "cond-mat.stat-mech",
      "physics.chem-ph",
      "physics.comp-ph"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2506.01294v2",
    "title": "Equation of State and First Principles Prediction of the Vibrational Matrix Shift of Solid Parahydrogen",
    "authors": [
      "Alexander Ibrahim",
      "Lecheng Wang",
      "Tom Halverson",
      "Robert J Le Roy",
      "Pierre-Nicholas Roy"
    ],
    "abstract": "We generate the equation of state (EOS) of solid parahydrogen using a\npath-integral Monte Carlo (PIMC) simulation based on a highly accurate\nfirst-principles adiabatic hindered rotor (AHR) potential energy curve for the\nparahydrogen dimer. The EOS curves for the fcc and hcp structures of solid\nparahydrogen near the equilibrium density show that the hcp structure is the\nmore stable of the two, in agreement with experiment. To accurately reproduce\nthe structural and energy properties of solid parahydrogen, we eliminated by\nextrapolation the systematic errors associated with the choice of simulation\nparameters used in the PIMC calculation. We also investigate the temperature\ndependence of the EOS curves, and the invariance of the equilibrium density\nwith temperature is satisfyingly reproduced. The pressure as a function of\ndensity, and the compressibility as a function of pressure, are both calculated\nusing the obtained EOS and are compared with previous simulation results and\nexperiments. We also report the first ever a priori prediction of a vibrational\nmatrix shift from first-principles two-body potential functions, and its result\nfor the equilibrium state agrees well with experiment.",
    "pdf_url": "http://arxiv.org/pdf/2506.01294v2",
    "published": "2025-06-02T04:02:51+00:00",
    "categories": [
      "physics.chem-ph"
    ],
    "primary_category": "physics.chem-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.02069v1",
    "title": "A label-switching algorithm for fast core-periphery identification",
    "authors": [
      "Eric Yanchenko",
      "Srijan Sengupta"
    ],
    "abstract": "Core-periphery (CP) structure is frequently observed in networks where the\nnodes form two distinct groups: a small, densely interconnected core and a\nsparse periphery. Borgatti and Everett (2000) proposed one of the most popular\nmethods to identify and quantify CP structure by comparing the observed network\nwith an ``ideal'' CP structure. While this metric has been widely used, an\nimproved algorithm is still needed. In this work, we detail a greedy,\nlabel-switching algorithm to identify CP structure that is both fast and\naccurate. By leveraging a mathematical reformulation of the CP metric, our\nproposed heuristic offers an order-of-magnitude improvement on the number of\noperations compared to a naive implementation. We prove that the algorithm\nconverges to a local minimum while consistently yielding solutions within 90\\%\nof the global optimum on small toy networks. On synthetic networks, our\nalgorithm exhibits superior classification accuracies and run-times compared to\na popular competing method, and the analysis of real-world networks shows that\nthe proposed method can be nearly 400 times faster than the competition.",
    "pdf_url": "http://arxiv.org/pdf/2506.02069v1",
    "published": "2025-06-02T04:02:12+00:00",
    "categories": [
      "stat.CO"
    ],
    "primary_category": "stat.CO"
  },
  {
    "id": "http://arxiv.org/abs/2506.01293v1",
    "title": "Abstractive Visual Understanding of Multi-modal Structured Knowledge: A New Perspective for MLLM Evaluation",
    "authors": [
      "Yichi Zhang",
      "Zhuo Chen",
      "Lingbing Guo",
      "Yajing Xu",
      "Min Zhang",
      "Wen Zhang",
      "Huajun Chen"
    ],
    "abstract": "Multi-modal large language models (MLLMs) incorporate heterogeneous\nmodalities into LLMs, enabling a comprehensive understanding of diverse\nscenarios and objects. Despite the proliferation of evaluation benchmarks and\nleaderboards for MLLMs, they predominantly overlook the critical capacity of\nMLLMs to comprehend world knowledge with structured abstractions that appear in\nvisual form. To address this gap, we propose a novel evaluation paradigm and\ndevise M3STR, an innovative benchmark grounded in the Multi-Modal Map for\nSTRuctured understanding. This benchmark leverages multi-modal knowledge graphs\nto synthesize images encapsulating subgraph architectures enriched with\nmulti-modal entities. M3STR necessitates that MLLMs not only recognize the\nmulti-modal entities within the visual inputs but also decipher intricate\nrelational topologies among them. We delineate the benchmark's statistical\nprofiles and automated construction pipeline, accompanied by an extensive\nempirical analysis of 26 state-of-the-art MLLMs. Our findings reveal persistent\ndeficiencies in processing abstractive visual information with structured\nknowledge, thereby charting a pivotal trajectory for advancing MLLMs' holistic\nreasoning capacities. Our code and data are released at\nhttps://github.com/zjukg/M3STR",
    "pdf_url": "http://arxiv.org/pdf/2506.01293v1",
    "published": "2025-06-02T04:00:35+00:00",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.01292v2",
    "title": "Time inversion symmetry in the Dirac and Schrödinger-Pauli theories",
    "authors": [
      "R. Winkler",
      "U. Zülicke"
    ],
    "abstract": "The Schr\\\"odinger-Pauli theory is generally believed to give a faithful\nrepresentation of the nonrelativistic and weakly relativistic limit of the\nDirac theory. However, the Schr\\\"odinger-Pauli theory is fundamentally\nincomplete in its account of broken time inversion symmetry, e.g., in\nmagnetically ordered systems. In the Dirac theory of the electron, magnetic\norder breaks time inversion symmetry even in the nonrelativistic limit, whereas\ntime inversion symmetry is effectively preserved in the Schr\\\"odinger-Pauli\ntheory in the absence of spin-orbit coupling. In the Dirac theory, the Berry\ncurvature $1/(2m^2c^2)$ is thus an intrinsic property of nonrelativistic\nelectrons similar to the well-known spin magnetic moment $e\\hbar/(2m)$, while\nthis result is missed by the nonrelativistic or weakly relativistic\nSchr\\\"odinger-Pauli equation. In ferromagnetically ordered systems, the\nintrinsic Berry curvature yields a contribution to the anomalous Hall\nconductivity independent of spin-orbit coupling.",
    "pdf_url": "http://arxiv.org/pdf/2506.01292v2",
    "published": "2025-06-02T03:56:47+00:00",
    "categories": [
      "cond-mat.mtrl-sci",
      "quant-ph"
    ],
    "primary_category": "cond-mat.mtrl-sci"
  },
  {
    "id": "http://arxiv.org/abs/2506.01291v2",
    "title": "The Hasse principle for homogeneous polynomials with random coefficients over thin sets II",
    "authors": [
      "Daniel Flores",
      "Kiseok Yeon"
    ],
    "abstract": "Let $d$ and $n$ be natural numbers. Let $\\nu_{d,n}: \\mathbb{R}^n\\rightarrow\n\\mathbb{R}^{N}$ denote the Veronese embedding with\n$N=N_{n,d}:=\\binom{n+d-1}{d}$, defined by listing all the monomials of degree\n$d$ in $n$ variables using the lexicographical ordering. Let $\\langle\n\\boldsymbol{a}, \\nu_{d,n}(\\boldsymbol{x})\\rangle\\in \\mathbb{Z}[\\boldsymbol{x}]$\nbe a homogeneous polynomial in $n$ variables of degree $d$ with integer\ncoefficients $\\boldsymbol{a}$, where $\\langle\\cdot,\\cdot\\rangle$ denotes the\ninner product. For a non-singular form $P\\in \\mathbb{Z}[\\boldsymbol{x}]$ of\ndegree $k\\ (\\leq d)$ in $N$ variables, consider a set of integer vectors\n$\\boldsymbol{a}\\in \\mathbb{Z}^N$, defined by\n$$\\mathfrak{A}(A;P)=\\{\\boldsymbol{a}\\in \\mathbb{Z}^N:\\ P(\\boldsymbol{a})=0,\\\n\\|\\boldsymbol{a}\\|_{\\infty}\\leq A\\}.$$ By handling a new lattice problem via\nthe geometry of numbers, we confirm that whenever $n> 24d$ and $d\\geq 17,$ the\nproportion of integer coefficients $\\boldsymbol{a}\\in \\mathfrak{A}(A;P)$, whose\nassociated equation $f_{\\boldsymbol{a}}(\\boldsymbol{x})=0$ satisfies the Hasse\nprinciple, converges to $1$ as $A\\rightarrow\\infty$. This improves on the\nrecent work of the second author.",
    "pdf_url": "http://arxiv.org/pdf/2506.01291v2",
    "published": "2025-06-02T03:56:37+00:00",
    "categories": [
      "math.NT",
      "math.AG"
    ],
    "primary_category": "math.NT"
  },
  {
    "id": "http://arxiv.org/abs/2506.01290v1",
    "title": "TSRating: Rating Quality of Diverse Time Series Data by Meta-learning from LLM Judgment",
    "authors": [
      "Shunyu Wu",
      "Dan Li",
      "Haozheng Ye",
      "Zhuomin Chen",
      "Jiahui Zhou",
      "Jian Lou",
      "Zibin Zheng",
      "See-Kiong Ng"
    ],
    "abstract": "High-quality time series (TS) data are essential for ensuring TS model\nperformance, rendering research on rating TS data quality indispensable.\nExisting methods have shown promising rating accuracy within individual\ndomains, primarily by extending data quality rating techniques such as\ninfluence functions and Shapley values to account for temporal characteristics.\nHowever, they neglect the fact that real-world TS data can span vastly\ndifferent domains and exhibit distinct properties, hampering the accurate and\nefficient rating of diverse TS data. In this paper, we propose TSRating, a\nnovel and unified framework for rating the quality of time series data crawled\nfrom diverse domains. TSRating is built on the assumption that LLMs inherit\nample knowledge, acquired during their extensive pretraining, enabling them to\ncomprehend and discern quality differences in diverse TS data. We verify this\nassumption by devising a series of prompts to elicit quality comparisons from\nLLMs for pairs of TS samples. We then fit a dedicated rating model, termed\nTSRater, to convert the LLMs' judgments into efficient quality predictions via\nTSRater's inference on future TS samples. To ensure cross-domain adaptability,\nwe develop a meta-learning scheme to train TSRater on quality comparisons\ncollected from nine distinct domains. To improve training efficiency, we employ\nsignSGD for inner-loop updates, thus circumventing the demanding computation of\nhypergradients. Extensive experimental results on eleven benchmark datasets\nacross three time series tasks, each using both conventional TS models and TS\nfoundation models, demonstrate that TSRating outperforms baselines in terms of\nestimation accuracy, efficiency, and domain adaptability.",
    "pdf_url": "http://arxiv.org/pdf/2506.01290v1",
    "published": "2025-06-02T03:52:55+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.01289v1",
    "title": "Suzaku Observation of Merging Clusters Abell 222 and Abell 223",
    "authors": [
      "Yanling Chen",
      "Wei Cui",
      "Aurora Simionescu",
      "Rui Huang",
      "Dan Hu"
    ],
    "abstract": "Previous X-ray and optical studies of the galaxy cluster pair Abell 222/223\nsuggested the possible presence of a filamentary structure connecting the two\nclusters, a result that appears to be supported by subsequent weak-lensing\nanalyses. This filament has been reported to host a primordial warm-hot\nintergalactic medium (WHIM), which existed prior to being heated by the\ninteractions of the clusters. In this study, we made an attempt to examine the\nreported emission feature with data from an archival Suzaku observation, taking\nadvantage of its low detector background. Because the emission is expected to\nbe very weak, we first carefully examined all potential sources of\n\"contamination\", and then modelled the residual emission. Due to large\nuncertainties, unfortunately, our results can neither confirm the presence of\nthe reported emission feature nor rule it out. We discuss the sources of\nuncertainties.",
    "pdf_url": "http://arxiv.org/pdf/2506.01289v1",
    "published": "2025-06-02T03:52:02+00:00",
    "categories": [
      "astro-ph.CO"
    ],
    "primary_category": "astro-ph.CO"
  },
  {
    "id": "http://arxiv.org/abs/2506.01288v1",
    "title": "WishGI: Lightweight Static Global Illumination Baking via Spherical Harmonics Fitting",
    "authors": [
      "Junke Zhu",
      "Zehan Wu",
      "Qixing Zhang",
      "Cheng Liao",
      "Zhangjin Huang"
    ],
    "abstract": "Global illumination combines direct and indirect lighting to create realistic\nlighting effects, bringing virtual scenes closer to reality. Static global\nillumination is a crucial component of virtual scene rendering, leveraging\nprecomputation and baking techniques to significantly reduce runtime\ncomputational costs. Unfortunately, many existing works prioritize visual\nquality by relying on extensive texture storage and massive pixel-level texture\nsampling, leading to large performance overhead. In this paper, we introduce an\nillumination reconstruction method that effectively reduces sampling in\nfragment shader and avoids additional render passes, making it well-suited for\nlow-end platforms. To achieve high-quality global illumination with reduced\nmemory usage, we adopt a spherical harmonics fitting approach for baking\neffective illumination information and propose an inverse probe distribution\nmethod that generates unique probe associations for each mesh. This\nassociation, which can be generated offline in the local space, ensures\nconsistent lighting quality across all instances of the same mesh. As a\nconsequence, our method delivers highly competitive lighting effects while\nusing only approximately 5% of the memory required by mainstream industry\ntechniques.",
    "pdf_url": "http://arxiv.org/pdf/2506.01288v1",
    "published": "2025-06-02T03:50:45+00:00",
    "categories": [
      "cs.GR"
    ],
    "primary_category": "cs.GR"
  },
  {
    "id": "http://arxiv.org/abs/2506.01287v1",
    "title": "How Problematic are Suspenseful Interactions?",
    "authors": [
      "Alarith Uhde"
    ],
    "abstract": "Current \"social acceptability\" guidelines for interactive technologies advise\nagainst certain, seemingly problematic forms of interaction. Specifically,\n\"suspenseful\" interactions, characterized by visible manipulations and\ninvisible effects, are generally considered be problematic. However, the\nempirical grounding for this claim is surprisingly weak. To test its validity,\nthis paper presents a controlled replication study (n = 281) of the\n\"suspensefulness effect\". Although it could be statistically replicated with\ntwo out of three social acceptability measures, effect sizes were small (r =<\n.2), and all compared forms of interaction, including the suspenseful one, had\nhigh absolute social acceptability scores. Thus, despite the slight negative\neffect, suspenseful interactions seem less problematic in the overall scheme of\nthings. We discuss alternative approaches to improve the social acceptability\nof interactive technology, and recommend to more closely engage with their\nspecific social situatedness.",
    "pdf_url": "http://arxiv.org/pdf/2506.01287v1",
    "published": "2025-06-02T03:47:22+00:00",
    "categories": [
      "cs.HC"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2506.01286v1",
    "title": "New insights into the cavitation erosion by bubble collapse at moderate stand-off distances",
    "authors": [
      "Zhesheng Zhao",
      "Shuai Li",
      "Chengwang Xiong",
      "Pu Cui",
      "Shiping Wang",
      "A-Man Zhang"
    ],
    "abstract": "Non-spherical bubble collapses near solid boundaries, generating water hammer\npressures and shock waves, were recognized as key mechanisms for cavitation\nerosion. However, there is no agreement on local erosion patterns, and\ncavitation erosion damage lacks quantitative analysis. In our experiments, five\ndistinct local erosion patterns were identified on aluminum sample surfaces,\nresulting from the collapse of laser-induced cavitation bubbles at moderate\nstand-off distances of $0.4\\le\\gamma\\le2.2$, namely Bipolar, Monopolar,\nAnnular, Solar-Halo, and Central. Among them, the Bipolar and Monopolar\npatterns exhibit the most severe cavitation erosion when the toroidal bubbles\nundergo asymmetrical collapse along the circumferential direction during the\nsecond cycle. Shadowgraphy visualization revealed that asymmetrical collapse\ncaused shockwave focusing through head-on collision and oblique superposition\nof wavefronts. This led to the variations in toroidal bubble radii and the\npositions of maximum erosion depth not matching at certain stand-off distances.\nBoth initial plasma asymmetry and bubble-wall stand-off distance were critical\nin determining circumferential asymmetrical collapse behaviors. At large\ninitial aspect ratios, the elliptical jet tips form during the contraction\nprocess, resulting in the toroidal bubble collapsing from regions with smaller\ncurvature radii, ultimately converging to the colliding point along the\ncircumferential direction. Our three-dimensional simulations using OpenFOAM\nsuccessfully reproduce the key features of circumferentially asymmetrical\nbubble collapse. This study provides new insights into the non-spherical\nnear-wall bubble collapse dynamics and provides a foundation for developing\npredictive models for cavitation erosion.",
    "pdf_url": "http://arxiv.org/pdf/2506.01286v1",
    "published": "2025-06-02T03:47:18+00:00",
    "categories": [
      "physics.flu-dyn"
    ],
    "primary_category": "physics.flu-dyn"
  },
  {
    "id": "http://arxiv.org/abs/2506.01285v1",
    "title": "A Reliable Vertical Federated Learning Framework for Traffic State Estimation with Data Selection and Incentive Mechanisms",
    "authors": [
      "Zijun Zhan",
      "Yaxian Dong",
      "Daniel Mawunyo Doe",
      "Yuqing Hu",
      "Shuai Li",
      "Shaohua Cao",
      "Zhu Han"
    ],
    "abstract": "Vertical Federated Learning (VFL)-based Traffic State Estimation (TSE) offers\na promising approach for integrating vertically distributed traffic data from\nmunicipal authorities (MA) and mobility providers (MP) while safeguarding\nprivacy. However, given the variations in MPs' data collection capabilities and\nthe potential for MPs to underperform in data provision, we propose a reliable\nVFL-based TSE framework that ensures model reliability during training and\noperation. The proposed framework comprises two components: data provider\nselection and incentive mechanism design. Data provider selection is conducted\nin three stages to identify the most qualified MPs for VFL model training with\nthe MA. First, the MA partitions the transportation network into road segments.\nThen, a mutual information (MI) model is trained for each segment to capture\nthe relationship between data and labels. Finally, using a sampling strategy\nand the MI model, the MA assesses each MP's competence in data provision and\nselects the most qualified MP for each segment. For the incentive mechanism\ndesign, given the MA can leverage the MI mode to inspect the data quality of\nMP, we formulate the interaction between MA and MP as a supervision game model.\nUpon this, we devise a penalty-based incentive mechanism to inhibit the lazy\nprobability of MP, thereby guaranteeing the utility of MA. Numerical simulation\non real-world datasets showcased that our proposed framework augments the\ntraffic flow and density prediction accuracy by 11.23\\% and 23.15\\% and\nelevates the utility of MA by 130$\\sim$400\\$ compared to the benchmark.",
    "pdf_url": "http://arxiv.org/pdf/2506.01285v1",
    "published": "2025-06-02T03:42:46+00:00",
    "categories": [
      "cs.GT"
    ],
    "primary_category": "cs.GT"
  },
  {
    "id": "http://arxiv.org/abs/2506.01284v1",
    "title": "Fast SSVEP Detection Using a Calibration-Free EEG Decoding Framework",
    "authors": [
      "Chenlong Wang",
      "Jiaao Li",
      "Shuailei Zhang",
      "Wenbo Ding",
      "Xinlei Chen"
    ],
    "abstract": "Steady-State Visual Evoked Potential is a brain response to visual stimuli\nflickering at constant frequencies. It is commonly used in brain-computer\ninterfaces for direct brain-device communication due to their simplicity,\nminimal training data, and high information transfer rate. Traditional methods\nsuffer from poor performance due to reliance on prior knowledge, while deep\nlearning achieves higher accuracy but requires substantial high-quality\ntraining data for precise signal decoding. In this paper, we propose a\ncalibration-free EEG signal decoding framework for fast SSVEP detection. Our\nframework integrates Inter-Trial Remixing & Context-Aware Distribution\nAlignment data augmentation for EEG signals and employs a compact architecture\nof small fully connected layers, effectively addressing the challenge of\nlimited EEG data availability. Additionally, we propose an Adaptive Spectrum\nDenoise Module that operates in the frequency domain based on global features,\nrequiring only linear complexity to reduce noise in EEG data and improve data\nquality. For calibration-free classification experiments on short EEG signals\nfrom three public datasets, our framework demonstrates statistically\nsignificant accuracy advantages(p<0.05) over existing methods in the majority\nof cases, while requiring at least 52.7% fewer parameters and 29.9% less\ninference time. By eliminating the need for user-specific calibration, this\nadvancement significantly enhances the usability of BCI systems, accelerating\ntheir commercialization and widespread adoption in real-world applications.",
    "pdf_url": "http://arxiv.org/pdf/2506.01284v1",
    "published": "2025-06-02T03:41:15+00:00",
    "categories": [
      "cs.HC"
    ],
    "primary_category": "cs.HC"
  },
  {
    "id": "http://arxiv.org/abs/2506.01283v1",
    "title": "Getting to the Bottom of Serverless Billing",
    "authors": [
      "Changyuan Lin",
      "Gigi",
      "Ma",
      "Mohammad Shahrad"
    ],
    "abstract": "Public cloud serverless platforms have attracted a large user base due to\ntheir high scalability, plug-and-play deployment model, and pay-per-use\nbilling. However, compared to virtual machines and container hosting services,\nmodern serverless offerings typically impose higher per-unit time and resource\ncharges. Additionally, billing practices such as wall-clock allocation-based\nbilling, invocation fees, and usage rounding up can further increase costs.\n  This work, for the first time, holistically demystifies these costs by\nconducting an in-depth, top-down characterization and analysis from user-facing\nbilling models, through request serving architectures, and down to operating\nsystem scheduling on major public serverless platforms. We quantify, for the\nfirst time, how current billing practices inflate billable resources up to\n5.49x beyond actual consumption. Also, our analysis reveals previously\nunreported cost drivers, such as operational patterns of serving architectures\nthat create overheads, details of resource allocation during keep-alive\nperiods, and OS scheduling granularity effects that directly impact both\nperformance and billing. By tracing the sources of costs from billing models\ndown to OS scheduling, we uncover the rationale behind today's expensive\nserverless billing model and practices and provide insights for designing\nperformant and cost-effective serverless systems.",
    "pdf_url": "http://arxiv.org/pdf/2506.01283v1",
    "published": "2025-06-02T03:40:24+00:00",
    "categories": [
      "cs.DC",
      "cs.OS",
      "cs.PF"
    ],
    "primary_category": "cs.DC"
  },
  {
    "id": "http://arxiv.org/abs/2506.01282v1",
    "title": "Shape Shifting Light Dark Matter Solitons",
    "authors": [
      "Dor Ben-Amotz"
    ],
    "abstract": "Dark matter consisting of a Bose-Einstein-Condensate (BEC) of ultra-light\nparticles is predicted to have a soliton shape that shifts with the dark matter\nmass fraction in galaxies with a centrally localized stellar mass (such as a\nblack hole). In the self-gravitating dark matter limit, the predicted cored\nsoliton shape is consistent with previous numerical predictions and analytical\napproximations. As the dark matter mass fraction decreases, the soliton is\npredicted to become increasingly cusp shaped, asymptotically approaching an\nexponential density distribution (isomorphic with a Hydrogen 1s state), with a\ncentral slope comparable to that predicted by cold dark matter simulations. The\nsoliton shapes are obtained by solving the associated Schr\\\"{o}dinger-Poisson\nequation with the ground state wavefunction represented as a sum of Gaussians\nwith numerically optimized amplitudes and widths. The results are used to\nexpress the soliton size, total mass and density directly in terms of the\ncorresponding velocity dispersion, by invoking an approximation relating tracer\nstar rotational velocity and dispersion that is validated by experimental\nobservations. Applications of the predictions, as well as challenges associated\nwith critically testing dark matter models, are illustrated using comparisons\nwith dwarf spheroidal (dSph) and ultrafaint dwarf (UFD) galaxy observations.\nImplications include speculations regarding the possible role of dark matter\nevaporation in galactic evolution, as well as a light-dark-matter hypothesis\nthat dark matter solitons may be photon condensates, if photons have a non-zero\nrest mass consistent with the upper bounds established by a wide range of\noptical and electrodynamic measurements.",
    "pdf_url": "http://arxiv.org/pdf/2506.01282v1",
    "published": "2025-06-02T03:36:20+00:00",
    "categories": [
      "astro-ph.GA"
    ],
    "primary_category": "astro-ph.GA"
  },
  {
    "id": "http://arxiv.org/abs/2506.01281v1",
    "title": "On the Hardness of Approximating Distributions with Probabilistic Circuits",
    "authors": [
      "John Leland",
      "YooJung Choi"
    ],
    "abstract": "A fundamental challenge in probabilistic modeling is balancing expressivity\nand tractable inference. Probabilistic circuits (PCs) aim to directly address\nthis tradeoff by imposing structural constraints that guarantee efficient\ninference of certain queries while maintaining expressivity. Since inference\ncomplexity on PCs depends on circuit size, understanding the size bounds across\ncircuit families is key to characterizing the tradeoff between tractability and\nexpressive efficiency. However, expressive efficiency is often studied through\nexact representations, where exactly encoding distributions while enforcing\nvarious structural properties often incurs exponential size blow-ups. Thus, we\npose the following question: can we avoid such size blow-ups by allowing some\nsmall approximation error? We first show that approximating an arbitrary\ndistribution with bounded $f$-divergence is $\\mathsf{NP}$-hard for any model\nthat can tractably compute marginals. We then prove an exponential size gap for\napproximation between the class of decomposable PCs and additionally\ndeterministic PCs.",
    "pdf_url": "http://arxiv.org/pdf/2506.01281v1",
    "published": "2025-06-02T03:35:07+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2506.01280v1",
    "title": "Fourier Frames on Salem Measures",
    "authors": [
      "Longhui Li",
      "Bochen Liu"
    ],
    "abstract": "For every $0<s\\leq 1$ we construct $s$-dimensional Salem measures in the unit\ninterval that do not admit any Fourier frame. Our examples are generic for each\n$s$, including all existing types of Salem measures in the literature: random\nCantor sets (convolutions, non-convolutions), random images, and deterministic\nconstructions on Diophantine approximations. They even appear almost surely as\nBrownian images. We also develop different approaches to prove the nonexistence\nof Fourier frames on different constructions. Both the criteria and ideas\nbehind the constructions are expected to work in higher dimensions.\n  On the other hand, we observe that a weighted arc in the plane can be a\n$1$-dimensional Salem measure with orthonormal basis of exponentials. This\nleaves whether there exist Salem measures in the real line with Fourier frames\nor even orthonormal basis of exponentials a subtle problem.",
    "pdf_url": "http://arxiv.org/pdf/2506.01280v1",
    "published": "2025-06-02T03:25:32+00:00",
    "categories": [
      "math.CA",
      "math.FA"
    ],
    "primary_category": "math.CA"
  },
  {
    "id": "http://arxiv.org/abs/2506.01279v2",
    "title": "$W$-entropy formulas and Langevin deformation on the $L^q$-Wasserstein space over Riemannian manifolds",
    "authors": [
      "Rong Lei",
      "Xiang-Dong Li",
      "Yu-Zhao Wang"
    ],
    "abstract": "We first prove the $W$-entropy formula and rigidity theorem for the geodesic\nflow on the $L^q$-Wasserstein space over a complete Riemannian manifold with\nbounded geometry condition. Then we introduce the Langevin deformation on the\n$L^q$-Wasserstein space over a complete Riemannian manifold, which interpolates\nbetween the $p$-Laplacian heat equation and the geodesic flow on the\n$L^q$-Wasserstein space, where ${1\\over p}+{1\\over q}=1$, $1< p, q<\\infty$. The\nlocal existence, uniqueness and regularity of the Langevin deformation on the\n$L^q$-Wasserstein space over the Euclidean space and a compact Riemannian\nmanifold are proved for $q\\in [2, \\infty)$. We further prove the\n$W$-entropy-information formula and the rigidity theorem for the Langevin\ndeformation on the $L^q$-Wasserstein space over an $n$-dimensional complete\nRiemannian manifold with non-negative Ricci curvature, where $q\\in (1,\\infty)$.",
    "pdf_url": "http://arxiv.org/pdf/2506.01279v2",
    "published": "2025-06-02T03:21:36+00:00",
    "categories": [
      "math.PR",
      "Primary 58J35, 58J65, Secondary 35K92, 60H30"
    ],
    "primary_category": "math.PR"
  },
  {
    "id": "http://arxiv.org/abs/2506.01278v1",
    "title": "Abelian dualities and line defect indices for 3d gauge theories",
    "authors": [
      "Hirotaka Hayashi",
      "Tomoki Nosaka",
      "Tadashi Okazaki"
    ],
    "abstract": "We find matching pairs of the line defect indices for 3d supersymmetric\nAbelian gauge theories as strong evidence of dualities of the BPS line\noperators. They lead to novel duality maps of the BPS line operators for\n$\\mathcal{N}\\ge 4$ supersymmetric circular and linear quiver gauge theories\nwhich can be realized as brane configurations in Type IIB string theory,\nincluding SQED, ADHM and ABJM theories.",
    "pdf_url": "http://arxiv.org/pdf/2506.01278v1",
    "published": "2025-06-02T03:20:37+00:00",
    "categories": [
      "hep-th"
    ],
    "primary_category": "hep-th"
  },
  {
    "id": "http://arxiv.org/abs/2506.08030v2",
    "title": "MOSS: Multi-Objective Optimization for Stable Rule Sets",
    "authors": [
      "Brian Liu",
      "Rahul Mazumder"
    ],
    "abstract": "We present MOSS, a multi-objective optimization framework for constructing\nstable sets of decision rules. MOSS incorporates three important criteria for\ninterpretability: sparsity, accuracy, and stability, into a single\nmulti-objective optimization framework. Importantly, MOSS allows a practitioner\nto rapidly evaluate the trade-off between accuracy and stability in sparse rule\nsets in order to select an appropriate model. We develop a specialized cutting\nplane algorithm in our framework to rapidly compute the Pareto frontier between\nthese two objectives, and our algorithm scales to problem instances beyond the\ncapabilities of commercial optimization solvers. Our experiments show that MOSS\noutperforms state-of-the-art rule ensembles in terms of both predictive\nperformance and stability.",
    "pdf_url": "http://arxiv.org/pdf/2506.08030v2",
    "published": "2025-06-02T03:20:12+00:00",
    "categories": [
      "math.OC",
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "math.OC"
  },
  {
    "id": "http://arxiv.org/abs/2506.01277v1",
    "title": "GeoLocSFT: Efficient Visual Geolocation via Supervised Fine-Tuning of Multimodal Foundation Models",
    "authors": [
      "Qiang Yi",
      "Lianlei Shan"
    ],
    "abstract": "Accurately determining the geographic location where a single image was\ntaken, visual geolocation, remains a formidable challenge due to the planet's\nvastness and the deceptive similarity among distant locations. We introduce\nGeoLocSFT, a framework that demonstrates how targeted supervised fine-tuning\n(SFT) of a large multimodal foundation model (Gemma 3) using a small,\nhigh-quality dataset can yield highly competitive geolocation performance.\nGeoLocSFT is trained with only 2700 carefully selected image-GPS pairs from our\ngeographically diverse MR600k dataset. Despite this limited data, our\nSFT-centric approach substantially improves over baseline models and achieves\nrobust results on standard benchmarks such as Im2GPS-3k and YFCC-4k, as well as\non our newly proposed and challenging MR40k benchmark, aimed specifically at\nsparsely populated regions. Further, we explore multi-candidate inference and\naggregation strategies but find that the core gains are already realized at the\nSFT stage. Our findings highlight the power of high-quality supervision and\nefficient SFT for planet-scale image geolocation, especially when compared to\nprior methods that require massive databases or complex pipelines. To foster\nfurther research, we publicly release the MR40k benchmark dataset.",
    "pdf_url": "http://arxiv.org/pdf/2506.01277v1",
    "published": "2025-06-02T03:16:19+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2506.01276v1",
    "title": "Schema as Parameterized Tools for Universal Information Extraction",
    "authors": [
      "Sheng Liang",
      "Yongyue Zhang",
      "Yaxiong Wu",
      "Ruiming Tang",
      "Yong Liu"
    ],
    "abstract": "Universal information extraction (UIE) primarily employs an extractive\ngeneration approach with large language models (LLMs), typically outputting\nstructured information based on predefined schemas such as JSON or tables. UIE\nsuffers from a lack of adaptability when selecting between predefined schemas\nand on-the-fly schema generation within the in-context learning paradigm,\nespecially when there are numerous schemas to choose from. In this paper, we\npropose a unified adaptive text-to-structure generation framework, called\nSchema as Parameterized Tools (SPT), which reimagines the tool-calling\ncapability of LLMs by treating predefined schemas as parameterized tools for\ntool selection and parameter filling. Specifically, our SPT method can be\napplied to unify closed, open, and on-demand IE tasks by adopting Schema\nRetrieval by fetching the relevant schemas from a predefined pool, Schema\nFilling by extracting information and filling slots as with tool parameters, or\nSchema Generation by synthesizing new schemas with uncovered cases. Experiments\nshow that the SPT method can handle four distinct IE tasks adaptively,\ndelivering robust schema retrieval and selection performance. SPT also achieves\ncomparable extraction performance to LoRA baselines and current leading UIE\nsystems with significantly fewer trainable parameters.",
    "pdf_url": "http://arxiv.org/pdf/2506.01276v1",
    "published": "2025-06-02T03:12:44+00:00",
    "categories": [
      "cs.CL",
      "I.2.7"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.01275v1",
    "title": "Contra4: Evaluating Contrastive Cross-Modal Reasoning in Audio, Video, Image, and 3D",
    "authors": [
      "Artemis Panagopoulou",
      "Le Xue",
      "Honglu Zhou",
      "silvio savarese",
      "Ran Xu",
      "Caiming Xiong",
      "Chris Callison-Burch",
      "Mark Yatskar",
      "Juan Carlos Niebles"
    ],
    "abstract": "Real-world decision-making often begins with identifying which modality\ncontains the most relevant information for a given query. While recent\nmultimodal models have made impressive progress in processing diverse inputs,\nit remains unclear whether they can reason contrastively across multiple\nmodalities to select the one that best satisfies a natural language prompt. We\nargue this capability is foundational, especially in retrieval-augmented and\ndecision-time contexts, where systems must evaluate multiple signals and\nidentify which one conveys the relevant information. To evaluate this skill, we\nintroduce Contra4, a dataset for contrastive cross-modal reasoning across four\nmodalities: image, audio, video, and 3D. Each example presents a natural\nlanguage question alongside multiple candidate modality instances, and the\nmodel must select the one that semantically aligns with the prompt. Contra4\ncombines human-annotated captions with a mixture-of-models\nround-trip-consistency filter to ensure high-quality supervision, resulting in\n174k training examples and a manually verified test set of 2.3k samples. While\ntask-specific fine-tuning improves performance by 56% relative to baseline,\nstate-of-the-art models still achieve only 56% accuracy overall and 42% in\nfour-modality settings, underscoring a significant limitation in current\nmultimodal models.",
    "pdf_url": "http://arxiv.org/pdf/2506.01275v1",
    "published": "2025-06-02T03:12:13+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2506.01274v1",
    "title": "ReFoCUS: Reinforcement-guided Frame Optimization for Contextual Understanding",
    "authors": [
      "Hosu Lee",
      "Junho Kim",
      "Hyunjun Kim",
      "Yong Man Ro"
    ],
    "abstract": "Recent progress in Large Multi-modal Models (LMMs) has enabled effective\nvision-language reasoning, yet the ability to understand video content remains\nconstrained by suboptimal frame selection strategies. Existing approaches often\nrely on static heuristics or external retrieval modules to feed frame\ninformation into video-LLMs, which may fail to provide the query-relevant\ninformation. In this work, we introduce ReFoCUS (Reinforcement-guided Frame\nOptimization for Contextual UnderStanding), a novel frame-level policy\noptimization framework that shifts the optimization target from textual\nresponses to visual input selection. ReFoCUS learns a frame selection policy\nvia reinforcement learning, using reward signals derived from a reference LMM\nto reflect the model's intrinsic preferences for frames that best support\ntemporally grounded responses. To efficiently explore the large combinatorial\nframe space, we employ an autoregressive, conditional selection architecture\nthat ensures temporal coherence while reducing complexity. Our approach does\nnot require explicit supervision at the frame-level and consistently improves\nreasoning performance across multiple video QA benchmarks, highlighting the\nbenefits of aligning frame selection with model-internal utility.",
    "pdf_url": "http://arxiv.org/pdf/2506.01274v1",
    "published": "2025-06-02T03:08:07+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.01273v1",
    "title": "RAISE: Reasoning Agent for Interactive SQL Exploration",
    "authors": [
      "Fernando Granado",
      "Roberto Lotufo",
      "Jayr Pereira"
    ],
    "abstract": "Recent advances in large language models (LLMs) have propelled research in\nnatural language interfaces to databases. However, most state-of-the-art\ntext-to-SQL systems still depend on complex, multi-stage pipelines. This work\nproposes a novel agentic framework that unifies schema linking, query\ngeneration, and iterative refinement within a single, end-to-end component. By\nleveraging the intrinsic reasoning abilities of LLMs, our method emulates how\nhumans answer questions when working with unfamiliar databases: understanding\nthe data by formulating hypotheses, running dynamic queries to validate them,\nreasoning over the results, and revising outputs based on observed results.\nCrucially, our approach introduces a new strategy for scaling test-time\ncomputation in text-to-SQL: we scale the depth of interactive database\nexploration and reflection. This shift enables the model to allocate\ncomputation dynamically to better understand the data, especially useful in\nambiguous and underspecified scenarios. Our experiments show that it improved\nthe Execution Accuracy (EX) from 44.8% to 56.5% on the challenging BIRD dataset\nusing DeepSeek-R1-Distill-Llama-70B. Furthermore, when equipped with steps to\nadd more diversity to the answers, our agent achieves a Best-of-N accuracy of\n81.8% with 8 rounds of candidate generation, rivaling the 82.79% achieved by\nthe top-ranked published solution, while reducing engineering complexity. These\nfindings position our unified framework as a promising alternative for building\nnatural language interfaces to databases.",
    "pdf_url": "http://arxiv.org/pdf/2506.01273v1",
    "published": "2025-06-02T03:07:08+00:00",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2507.07107v1",
    "title": "Machine Learning Enhanced Multi-Factor Quantitative Trading: A Cross-Sectional Portfolio Optimization Approach with Bias Correction",
    "authors": [
      "Yimin Du"
    ],
    "abstract": "This paper presents a comprehensive machine learning framework for\nquantitative trading that achieves superior risk-adjusted returns through\nsystematic factor engineering, real-time computation optimization, and\ncross-sectional portfolio construction. Our approach integrates multi-factor\nalpha discovery with bias correction techniques, leveraging PyTorch-accelerated\nfactor computation and advanced portfolio optimization. The system processes\n500-1000 factors derived from open-source alpha101 extensions and proprietary\nmarket microstructure signals. Key innovations include tensor-based factor\ncomputation acceleration, geometric Brownian motion data augmentation, and\ncross-sectional neutralization strategies. Empirical validation on Chinese\nA-share markets (2010-2024) demonstrates annualized returns of $20\\%$ with\nSharpe ratios exceeding 2.0, significantly outperforming traditional\napproaches. Our analysis reveals the critical importance of bias correction in\nfactor construction and the substantial impact of cross-sectional portfolio\noptimization on strategy performance. Code and experimental implementations are\navailable at: https://github.com/initial-d/ml-quant-trading",
    "pdf_url": "http://arxiv.org/pdf/2507.07107v1",
    "published": "2025-06-02T03:04:19+00:00",
    "categories": [
      "q-fin.PM",
      "cs.CE"
    ],
    "primary_category": "q-fin.PM"
  },
  {
    "id": "http://arxiv.org/abs/2506.01272v3",
    "title": "Hadrons in group expansion",
    "authors": [
      "Hua-Xing Chen"
    ],
    "abstract": "Various approximate symmetries exist in nature. For example, the flavor\n$SU(4)$ symmetry involving the $up/down/strange/charm$ quarks is severely\nbroken, the flavor $SU(3)$ symmetry involving the $up/down/strange$ quarks is\nmoderately broken, and the isospin $SU(2)$ symmetry involving the $up/down$\nquarks is slightly broken. These broken symmetries are primarily governed by\nthe strong interaction, making them an ideal platform for investigating the\ngeneral behavior of approximate symmetries. To explore the application of the\nflavor $SU(4)$ group to ground-state baryons, we systematically calculate the\ntransition matrices associated with various flavor $SU(4)$ representations as\nwell as the matrices that describe their connections. These matrices are then\nemployed to analyze the mass spectrum of ground-state baryons. Our results\nindicate that these states can be described as mixtures of various flavor\nrepresentations, such as $\\Sigma_c/\\Xi_c^\\prime/\\Omega_c \\sim \\mathbf{20_M}\n\\oplus \\mathbf{20_S}\\oplus \\mathbf{\\bar{4}_A}~[SU(4)]$, $\\Xi_c/\\Xi_c^\\prime\n\\sim \\mathbf{\\bar 3_A} \\oplus \\mathbf{6_S}~[SU(3)]$, $\\Lambda^0/\\Sigma^0 \\sim\n\\mathbf{1_A} \\oplus \\mathbf{3_S}~[SU(2)]$, where the subscripts $\\mathbf{S}$,\n$\\mathbf{A}$, and $\\mathbf{M}$ denote the symmetric, antisymmetric, and mixed\nflavor wave functions, respectively. Our results also indicate that the flavor\nsymmetries, as they break, necessitate the mixing of these flavor\nrepresentations according to specific rules. For example, the approximate\n$SU(3)$ flavor decuplet, with one of its flavor components slightly differing\nfrom the other two, deviates from the exact $SU(3)$ flavor decuplet, and this\ndeviation is characterized by the exact $SU(3)$ flavor octet.",
    "pdf_url": "http://arxiv.org/pdf/2506.01272v3",
    "published": "2025-06-02T03:00:39+00:00",
    "categories": [
      "hep-ph",
      "hep-th",
      "math-ph",
      "math.MP"
    ],
    "primary_category": "hep-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.01271v1",
    "title": "Transport Theory and Correlation Measurements: Coming to Terms on Emission Sources",
    "authors": [
      "Pierre Nzabahimana",
      "Pawel Danielewicz",
      "Giuseppe Verde"
    ],
    "abstract": "Two-particle correlations play a pivotal role in understanding the space-time\ncharacteristics of particle emission in Heavy-ion collisions. These\ncharacteristics are typically represented by a relative emission source and can\nbe obtained using transport model simulations such as the Boltzmann-\nUehling-Uhlenbeck (BUU) transport model. In this paper, we utilize the BUU\ntransport model to simulate the p-p source. Subsequently, we integrate this\nsource and the p-p kernel within the KP formula to calculate the correlations.\nBy comparing the correlations obtained from the BUU simulation with those\nobtained using imaging methods, such as the deblurring method, we aim to gain a\ndeeper understanding of the impact of fast and slow emissions on the measured\ncorrelations. Specifically, this comparison is used as a tool to determine a\nfunction (tail) that represents the relative distribution of the particle pair\nfrom secondary decay emissions. Thus, we correct the BUU source function by\nincorporating a tail to account for the contribution of secondary decay\nemissions, which cannot be accurately captured by BUU simulations. Resulting\nsource function reproduces the features in the measured correlations. To\nillustrate our approach, we examine p-p correlations measured in Ar + Sc\nreactions at E/A = 80 MeV, considering both momentum-independent and\nmomentum-dependent nuclear equations of state (EOS).",
    "pdf_url": "http://arxiv.org/pdf/2506.01271v1",
    "published": "2025-06-02T02:52:17+00:00",
    "categories": [
      "nucl-th"
    ],
    "primary_category": "nucl-th"
  },
  {
    "id": "http://arxiv.org/abs/2506.01270v1",
    "title": "Online Audio-Visual Autoregressive Speaker Extraction",
    "authors": [
      "Zexu Pan",
      "Wupeng Wang",
      "Shengkui Zhao",
      "Chong Zhang",
      "Kun Zhou",
      "Yukun Ma",
      "Bin Ma"
    ],
    "abstract": "This paper proposes a novel online audio-visual speaker extraction model. In\nthe streaming regime, most studies optimize the audio network only, leaving the\nvisual frontend less explored. We first propose a lightweight visual frontend\nbased on depth-wise separable convolution. Then, we propose a lightweight\nautoregressive acoustic encoder to serve as the second cue, to actively explore\nthe information in the separated speech signal from past steps. Scenario-wise,\nfor the first time, we study how the algorithm performs when there is a change\nin focus of attention, i.e., the target speaker. Experimental results on LRS3\ndatasets show that our visual frontend performs comparably to the previous\nstate-of-the-art on both SkiM and ConvTasNet audio backbones with only 0.1\nmillion network parameters and 2.1 MACs per second of processing. The\nautoregressive acoustic encoder provides an additional 0.9 dB gain in terms of\nSI-SNRi, and its momentum is robust against the change in attention.",
    "pdf_url": "http://arxiv.org/pdf/2506.01270v1",
    "published": "2025-06-02T02:47:53+00:00",
    "categories": [
      "eess.AS",
      "cs.SD"
    ],
    "primary_category": "eess.AS"
  },
  {
    "id": "http://arxiv.org/abs/2506.01269v2",
    "title": "Region-of-Interest-Guided Deep Joint Source-Channel Coding for Image Transmission",
    "authors": [
      "Hansung Choi",
      "Daewon Seo"
    ],
    "abstract": "Deep joint source-channel coding (deepJSCC) methods have shown promising\nimprovements in communication performance over wireless networks. However,\nexisting approaches primarily focus on enhancing overall image reconstruction\nquality, which may not fully align with user experiences, often driven by the\nquality of regions of interest (ROI). Motivated by this, we propose ROI-guided\njoint source-channel coding (ROI-JSCC), a novel deepJSCC framework that\nprioritizes high-quality transmission of ROI. The ROI-JSCC consists of four key\ncomponents: (1) Image ROI embedding, (2) ROI-guided split processing, (3)\nROI-based loss function design, and (4) ROI-adaptive bandwidth allocation.\nTogether, these components allow ROI-JSCC to selectively enhance the ROI\nreconstruction quality at varying ROI positions while maintaining overall image\nquality with minimal computational overhead. Experimental results under diverse\ncommunication environments demonstrate that ROI-JSCC significantly improves ROI\nreconstruction quality while maintaining competitive average image quality\ncompared to recent state-of-the-art methods.",
    "pdf_url": "http://arxiv.org/pdf/2506.01269v2",
    "published": "2025-06-02T02:42:50+00:00",
    "categories": [
      "cs.IT",
      "math.IT"
    ],
    "primary_category": "cs.IT"
  },
  {
    "id": "http://arxiv.org/abs/2506.01268v1",
    "title": "CleanS2S: Single-file Framework for Proactive Speech-to-Speech Interaction",
    "authors": [
      "Yudong Lu",
      "Yazhe Niu",
      "Shuai Hu",
      "Haolin Wang"
    ],
    "abstract": "CleanS2S is a framework for human-like speech-to-speech interaction that\nadvances conversational AI through single-file implementation and proactive\ndialogue capabilities. Our system integrates automatic speech recognition,\nlarge language models, and text-to-speech synthesis into a unified pipeline\nwith real-time interruption handling, achieving low transition latency through\nfull-duplex websocket connections and non-blocking I/O. Beyond conventional\nchatbot paradigms, we pioneer a proactive interaction mechanism, which combines\nmemory systems with Subjective Action Judgement module, enabling five\nhuman-like response strategies: interruption, refusal, deflection, silence, and\nstandard response. The memory module dynamically aggregates historical, and\ncontextual data to inform interaction decisions. This approach breaks the rigid\nturn-based convention by allowing system-initiated dialog control and\ncontext-aware response selection. And we propose Action Judgement SFT that\nassesses input streams for responses strategies. The framework's single-file\nimplementation with atomic configurations offers researchers unprecedented\ntransparency and extensibility for interaction agents. The code of CleanS2S is\nreleased at \\https://github.com/opendilab/CleanS2S.",
    "pdf_url": "http://arxiv.org/pdf/2506.01268v1",
    "published": "2025-06-02T02:40:46+00:00",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI"
  },
  {
    "id": "http://arxiv.org/abs/2506.01267v1",
    "title": "Adversarial learning for nonparametric regression: Minimax rate and adaptive estimation",
    "authors": [
      "Jingfu Peng",
      "Yuhong Yang"
    ],
    "abstract": "Despite tremendous advancements of machine learning models and algorithms in\nvarious application domains, they are known to be vulnerable to subtle, natural\nor intentionally crafted perturbations in future input data, known as\nadversarial attacks. While numerous adversarial learning methods have been\nproposed, fundamental questions about their statistical optimality in robust\nloss remain largely unanswered. In particular, the minimax rate of convergence\nand the construction of rate-optimal estimators under future $X$-attacks are\nyet to be worked out.\n  In this paper, we address this issue in the context of nonparametric\nregression, under suitable assumptions on the smoothness of the regression\nfunction and the geometric structure of the input perturbation set. We first\nestablish the minimax rate of convergence under adversarial $L_q$-risks with $1\n\\leq q \\leq \\infty$ and propose a piecewise local polynomial estimator that\nachieves the minimax optimality. The established minimax rate elucidates how\nthe smoothness level and perturbation magnitude affect the fundamental limit of\nadversarial learning under future $X$-attacks. Furthermore, we construct a\ndata-driven adaptive estimator that is shown to achieve, within a logarithmic\nfactor, the optimal rate across a broad scale of nonparametric and adversarial\nclasses.",
    "pdf_url": "http://arxiv.org/pdf/2506.01267v1",
    "published": "2025-06-02T02:38:47+00:00",
    "categories": [
      "stat.ML",
      "cs.LG",
      "math.ST",
      "stat.ME",
      "stat.TH"
    ],
    "primary_category": "stat.ML"
  },
  {
    "id": "http://arxiv.org/abs/2506.01266v1",
    "title": "Detoxification of Large Language Models through Output-layer Fusion with a Calibration Model",
    "authors": [
      "Yuanhe Tian",
      "Mingjie Deng",
      "Guoqing Jin",
      "Yan Song"
    ],
    "abstract": "Existing approaches for Large language model (LLM) detoxification generally\nrely on training on large-scale non-toxic or human-annotated preference data,\ndesigning prompts to instruct the LLM to generate safe content, or modifying\nthe model parameters to remove toxic information, which are computationally\nexpensive, lack robustness, and often compromise LLMs' fluency and contextual\nunderstanding. In this paper, we propose a simple yet effective approach for\nLLM detoxification, which leverages a compact, pre-trained calibration model\nthat guides the detoxification process of a target LLM via a lightweight\nintervention in its generation pipeline. By learning a detoxified embedding\nspace from non-toxic data, the calibration model effectively steers the LLM\naway from generating harmful content. This approach only requires a one-time\ntraining of the calibration model that is able to be seamlessly applied to\nmultiple LLMs without compromising fluency or contextual understanding.\nExperiment results on the benchmark dataset demonstrate that our approach\nreduces toxicity while maintaining reasonable content expression.",
    "pdf_url": "http://arxiv.org/pdf/2506.01266v1",
    "published": "2025-06-02T02:36:32+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.01265v1",
    "title": "Beyond In-Context Learning: Aligning Long-form Generation of Large Language Models via Task-Inherent Attribute Guidelines",
    "authors": [
      "Do Xuan Long",
      "Duong Ngoc Yen",
      "Do Xuan Trong",
      "Luu Anh Tuan",
      "Kenji Kawaguchi",
      "Shafiq Joty",
      "Min-Yen Kan",
      "Nancy F. Chen"
    ],
    "abstract": "In-context learning (ICL) is an important yet not fully understood ability of\npre-trained large language models (LLMs). It can greatly enhance task\nperformance using a few examples, termed demonstrations, without fine-tuning.\nAlthough effective in question answering, ICL often underperforms in long-form\ngeneration tasks such as summarization. Under appropriately realistic\nassumptions, we empirically and theoretically show that ICL demonstrations\nalone are insufficient to teach LLMs the task language and format distributions\nfor generation. We argue for explicit exposure to the task distributions and\nhypothesize that defining them by prompting enhances model performance. To this\nend, we present LongGuide, which efficiently generates two parallel streams of\nguidelines capturing task language and format properties: (i) Metric Guidelines\n(MGs) that instruct models to optimize self-evaluated metrics; and (ii) Output\nConstraint Guidelines (OCGs) that constrain generation at both token and\nsentence levels. LongGuide automatically selects the best combination of\nguidelines, improving both strong open- and closed-source LLMs by over 5% in\nboth zero- and few-shot settings. We show that LongGuide is generalizable,\nlearnable by weak models to enhance strong ones, and integrates synergistically\nwith automatic prompt optimizers.",
    "pdf_url": "http://arxiv.org/pdf/2506.01265v1",
    "published": "2025-06-02T02:35:24+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.01264v2",
    "title": "Image-based measurements of Tafel slopes in aqueous MV/4-HO-TEMPO Flow Batteries",
    "authors": [
      "Stéphane Chevalier",
      "Yui Sasaki",
      "Tsuyoshi Minami"
    ],
    "abstract": "A total organic aqueous redox flow battery (RFB) employing methyl viologen\n(MV) electrolyte and 4-hydroxy-2,2,6,6-tetramethylpiperidine-1-oxyl\n(4-HO-TEMPO) is tested and characterized under microfluidic conditions. The\nabsence of physical membrane and the quasi-two-dimensional energy transfers\noccurring in this RFB design enables the first direct measurement of Tafel\nkinetics, charge transfer, and charge transport resistances for both anolyte\nand catholyte reactants during the RFB operations. The methodology reported in\nthis work combines spectroelectrochemical imaging and analytical modeling of\nthe periodic mass and charge transfer equations. The Tafel kinetics and charge\ntransfers resistances are measured through several RFB geometries and operating\nconditions without the need of reference electrode nor absorptivity coefficient\ncalibration, which simplifies the experimental setup, eases the measurements\nand suppresses the uncertainty related to the electrolyte potential value. Data\nprovided in this work (concentration fields, kinetics properties,\nelectrochemical impedances) quantify the charge transfer in these systems and\ncan serve as reference values for further advanced RFB numerical simulations\nand design optimization.",
    "pdf_url": "http://arxiv.org/pdf/2506.01264v2",
    "published": "2025-06-02T02:32:10+00:00",
    "categories": [
      "physics.chem-ph"
    ],
    "primary_category": "physics.chem-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.08029v1",
    "title": "Inverse Design in Distributed Circuits Using Single-Step Reinforcement Learning",
    "authors": [
      "Jiayu Li",
      "Masood Mortazavi",
      "Ning Yan",
      "Yihong Ma",
      "Reza Zafarani"
    ],
    "abstract": "The goal of inverse design in distributed circuits is to generate\nnear-optimal designs that meet a desirable transfer function specification.\nExisting design exploration methods use some combination of strategies\ninvolving artificial grids, differentiable evaluation procedures, and specific\ntemplate topologies. However, real-world design practices often require\nnon-differentiable evaluation procedures, varying topologies, and\nnear-continuous placement spaces. In this paper, we propose DCIDA, a design\nexploration framework that learns a near-optimal design sampling policy for a\ntarget transfer function. DCIDA decides all design factors in a compound\nsingle-step action by sampling from a set of jointly-trained conditional\ndistributions generated by the policy. Utilizing an injective interdependent\n``map\", DCIDA transforms raw sampled design ``actions\" into uniquely equivalent\nphysical representations, enabling the framework to learn the conditional\ndependencies among joint ``raw'' design decisions. Our experiments demonstrate\nDCIDA's Transformer-based policy network achieves significant reductions in\ndesign error compared to state-of-the-art approaches, with significantly better\nfit in cases involving more complex transfer functions.",
    "pdf_url": "http://arxiv.org/pdf/2506.08029v1",
    "published": "2025-06-02T02:31:52+00:00",
    "categories": [
      "eess.SY",
      "cs.AI",
      "cs.LG",
      "cs.SY"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2506.01263v1",
    "title": "WCTC-Biasing: Retraining-free Contextual Biasing ASR with Wildcard CTC-based Keyword Spotting and Inter-layer Biasing",
    "authors": [
      "Yu Nakagome",
      "Michael Hentschel"
    ],
    "abstract": "Despite recent advances in end-to-end speech recognition methods, the output\ntends to be biased to the training data's vocabulary, resulting in inaccurate\nrecognition of proper nouns and other unknown terms. To address this issue, we\npropose a method to improve recognition accuracy of such rare words in\nCTC-based models without additional training or text-to-speech systems.\nSpecifically, keyword spotting is performed using acoustic features of\nintermediate layers during inference, and a bias is applied to the subsequent\nlayers of the acoustic model for detected keywords. For keyword detection, we\nadopt a wildcard CTC that is both fast and tolerant of ambiguous matches,\nallowing flexible handling of words that are difficult to match strictly. Since\nthis method does not require retraining of existing models, it can be easily\napplied to even large-scale models. In experiments on Japanese speech\nrecognition, the proposed method achieved a 29% improvement in the F1 score for\nunknown words.",
    "pdf_url": "http://arxiv.org/pdf/2506.01263v1",
    "published": "2025-06-02T02:30:26+00:00",
    "categories": [
      "cs.CL",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.01262v1",
    "title": "Exploring the Potential of LLMs as Personalized Assistants: Dataset, Evaluation, and Analysis",
    "authors": [
      "Jisoo Mok",
      "Ik-hwan Kim",
      "Sangkwon Park",
      "Sungroh Yoon"
    ],
    "abstract": "Personalized AI assistants, a hallmark of the human-like capabilities of\nLarge Language Models (LLMs), are a challenging application that intertwines\nmultiple problems in LLM research. Despite the growing interest in the\ndevelopment of personalized assistants, the lack of an open-source\nconversational dataset tailored for personalization remains a significant\nobstacle for researchers in the field. To address this research gap, we\nintroduce HiCUPID, a new benchmark to probe and unleash the potential of LLMs\nto deliver personalized responses. Alongside a conversational dataset, HiCUPID\nprovides a Llama-3.2-based automated evaluation model whose assessment closely\nmirrors human preferences. We release our dataset, evaluation model, and code\nat https://github.com/12kimih/HiCUPID.",
    "pdf_url": "http://arxiv.org/pdf/2506.01262v1",
    "published": "2025-06-02T02:25:46+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.01261v1",
    "title": "The Actor-Critic Update Order Matters for PPO in Federated Reinforcement Learning",
    "authors": [
      "Zhijie Xie",
      "Shenghui Song"
    ],
    "abstract": "In the context of Federated Reinforcement Learning (FRL), applying Proximal\nPolicy Optimization (PPO) faces challenges related to the update order of its\nactor and critic due to the aggregation step occurring between successive\niterations. In particular, when local actors are updated based on local critic\nestimations, the algorithm becomes vulnerable to data heterogeneity. As a\nresult, the conventional update order in PPO (critic first, then actor) may\ncause heterogeneous gradient directions among clients, hindering convergence to\na globally optimal policy. To address this issue, we propose FedRAC, which\nreverses the update order (actor first, then critic) to eliminate the\ndivergence of critics from different clients. Theoretical analysis shows that\nthe convergence bound of FedRAC is immune to data heterogeneity under mild\nconditions, i.e., bounded level of heterogeneity and accurate policy\nevaluation. Empirical results indicate that the proposed algorithm obtains\nhigher cumulative rewards and converges more rapidly in five experiments,\nincluding three classical RL environments and a highly heterogeneous autonomous\ndriving scenario using the SUMO traffic simulator.",
    "pdf_url": "http://arxiv.org/pdf/2506.01261v1",
    "published": "2025-06-02T02:20:22+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.01260v1",
    "title": "Protocol Models: Scaling Decentralized Training with Communication-Efficient Model Parallelism",
    "authors": [
      "Sameera Ramasinghe",
      "Thalaiyasingam Ajanthan",
      "Gil Avraham",
      "Yan Zuo",
      "Alexander Long"
    ],
    "abstract": "Scaling models has led to significant advancements in deep learning, but\ntraining these models in decentralized settings remains challenging due to\ncommunication bottlenecks. While existing compression techniques are effective\nin data-parallel, they do not extend to model parallelism. Unlike data-parallel\ntraining, where weight gradients are exchanged, model-parallel requires\ncompressing activations and activation gradients as they propagate through\nlayers, accumulating compression errors. We propose a novel compression\nalgorithm that compresses both forward and backward passes, enabling up to 99%\ncompression with no convergence degradation with negligible memory/compute\noverhead. By leveraging a recursive structure in transformer networks, we\npredefine a low-dimensional subspace to confine the activations and gradients,\nallowing full reconstruction in subsequent layers. Our method achieves up to\n100x improvement in communication efficiency and enables training\nbillion-parameter-scale models over low-end GPUs connected via consumer-grade\ninternet speeds as low as 80Mbps, matching the convergence of centralized\ndatacenter systems with 100Gbps connections with model parallel.",
    "pdf_url": "http://arxiv.org/pdf/2506.01260v1",
    "published": "2025-06-02T02:19:22+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.01259v1",
    "title": "2D material exciton-polariton transport on 2D photonic crystals",
    "authors": [
      "Xin Xie",
      "Qiuyang Li",
      "Chenxi Liu",
      "Yuze Liu",
      "Chulwon Lee",
      "Kai Sun",
      "Hui Deng"
    ],
    "abstract": "Transport of elementary excitations is a fundamental property of 2D\nsemiconductors, important for wide-ranging emergent phenomena and device\napplications. While exciton transport reported in 2D materials barely exceeds\n1-2 $\\mu$m, coherent coupling of excitons with photons to form polaritons\nallows not only greatly enhanced transport length, but also the potential to\nleverage photonic mode engineering for novel transport properties. However,\nconventional vertical cavity or waveguide polaritons are difficult to tune or\nintegrate into photonic circuits. Here, we report the transport of\ntransition-metal dichalcogenide polaritons in slab 2D photonic crystals that\nare highly versatile for tuning, mode-engineering and integration. We show an\norder-of-magnitude enhancement of the transport length compared to that of bare\nexcitons. We further show the dependence of transport on the polariton\ndispersion and population dynamics, which we control by varying the photonic\ncrystal design and pumping intensity. Stimulated relaxation observed in the\nsystem suggests the potential for forming superfluid polaritons with\nfrictionless transport. These results demonstrate the 2D photonic crystal\npolariton system as a versatile platform to enhance and manipulate energy\ntransport for novel photonic technologies.",
    "pdf_url": "http://arxiv.org/pdf/2506.01259v1",
    "published": "2025-06-02T02:19:01+00:00",
    "categories": [
      "physics.optics",
      "cond-mat.mes-hall"
    ],
    "primary_category": "physics.optics"
  },
  {
    "id": "http://arxiv.org/abs/2506.01258v2",
    "title": "Neural Networks for Parameter Estimation of the Discretely Observed Hawkes Process",
    "authors": [
      "Jason J. Lambe",
      "Feng Chen",
      "Tom Stindl",
      "Tsz-Kit Jeffrey Kwan"
    ],
    "abstract": "When the sample path of a Hawkes process is observed discretely, such that\nonly the total event counts in disjoint time intervals are known, the\nlikelihood function becomes intractable. To overcome the challenge of\nlikelihood-based inference in this setting, we propose to use a likelihood-free\napproach to parameter estimation, where simulated data is used to train a fully\nconnected neural network (NN) to estimate the parameters of the Hawkes process\nfrom a summary statistic of the count data. A naive imputation estimate of the\nparameters forms the basis of our summary statistic, which is fast to generate\nand requires minimal expert knowledge to design. The resulting NN estimator is\ncomparable to the best extant approximate likelihood estimators in terms of\nmean-squared error but requires significantly less computational time. We also\npropose to use a bootstrap procedure for bias correction and variance\nestimation. The proposed estimation procedure is applied to weekly count data\nfor two infectious diseases, with a time-varying background rate used to\ncapture seasonal fluctuations in infection risk.",
    "pdf_url": "http://arxiv.org/pdf/2506.01258v2",
    "published": "2025-06-02T02:17:11+00:00",
    "categories": [
      "stat.ME"
    ],
    "primary_category": "stat.ME"
  },
  {
    "id": "http://arxiv.org/abs/2506.01257v1",
    "title": "DeepSeek in Healthcare: A Survey of Capabilities, Risks, and Clinical Applications of Open-Source Large Language Models",
    "authors": [
      "Jiancheng Ye",
      "Sophie Bronstein",
      "Jiarui Hai",
      "Malak Abu Hashish"
    ],
    "abstract": "DeepSeek-R1 is a cutting-edge open-source large language model (LLM)\ndeveloped by DeepSeek, showcasing advanced reasoning capabilities through a\nhybrid architecture that integrates mixture of experts (MoE), chain of thought\n(CoT) reasoning, and reinforcement learning. Released under the permissive MIT\nlicense, DeepSeek-R1 offers a transparent and cost-effective alternative to\nproprietary models like GPT-4o and Claude-3 Opus; it excels in structured\nproblem-solving domains such as mathematics, healthcare diagnostics, code\ngeneration, and pharmaceutical research. The model demonstrates competitive\nperformance on benchmarks like the United States Medical Licensing Examination\n(USMLE) and American Invitational Mathematics Examination (AIME), with strong\nresults in pediatric and ophthalmologic clinical decision support tasks. Its\narchitecture enables efficient inference while preserving reasoning depth,\nmaking it suitable for deployment in resource-constrained settings. However,\nDeepSeek-R1 also exhibits increased vulnerability to bias, misinformation,\nadversarial manipulation, and safety failures - especially in multilingual and\nethically sensitive contexts. This survey highlights the model's strengths,\nincluding interpretability, scalability, and adaptability, alongside its\nlimitations in general language fluency and safety alignment. Future research\npriorities include improving bias mitigation, natural language comprehension,\ndomain-specific validation, and regulatory compliance. Overall, DeepSeek-R1\nrepresents a major advance in open, scalable AI, underscoring the need for\ncollaborative governance to ensure responsible and equitable deployment.",
    "pdf_url": "http://arxiv.org/pdf/2506.01257v1",
    "published": "2025-06-02T02:17:04+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.02068v1",
    "title": "Enhancing Interpretability of Quantum-Assisted Blockchain Clustering via AI Agent-Based Qualitative Analysis",
    "authors": [
      "Yun-Cheng Tsai",
      "Yen-Ku Liu",
      "Samuel Yen-Chi Chen"
    ],
    "abstract": "Blockchain transaction data is inherently high dimensional, noisy, and\nentangled, posing substantial challenges for traditional clustering algorithms.\nWhile quantum enhanced clustering models have demonstrated promising\nperformance gains, their interpretability remains limited, restricting their\napplication in sensitive domains such as financial fraud detection and\nblockchain governance. To address this gap, we propose a two stage analysis\nframework that synergistically combines quantitative clustering evaluation with\nAI Agent assisted qualitative interpretation. In the first stage, we employ\nclassical clustering methods and evaluation metrics including the Silhouette\nScore, Davies Bouldin Index, and Calinski Harabasz Index to determine the\noptimal cluster count and baseline partition quality. In the second stage, we\nintegrate an AI Agent to generate human readable, semantic explanations of\nclustering results, identifying intra cluster characteristics and inter cluster\nrelationships. Our experiments reveal that while fully trained Quantum Neural\nNetworks (QNN) outperform random Quantum Features (QF) in quantitative metrics,\nthe AI Agent further uncovers nuanced differences between these methods,\nnotably exposing the singleton cluster phenomenon in QNN driven models. The\nconsolidated insights from both stages consistently endorse the three cluster\nconfiguration, demonstrating the practical value of our hybrid approach. This\nwork advances the interpretability frontier in quantum assisted blockchain\nanalytics and lays the groundwork for future autonomous AI orchestrated\nclustering frameworks.",
    "pdf_url": "http://arxiv.org/pdf/2506.02068v1",
    "published": "2025-06-02T02:15:48+00:00",
    "categories": [
      "quant-ph",
      "cs.LG"
    ],
    "primary_category": "quant-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.01256v1",
    "title": "Confidence intervals for forced alignment boundaries using model ensembles",
    "authors": [
      "Matthew C. Kelley"
    ],
    "abstract": "Forced alignment is a common tool to align audio with orthographic and\nphonetic transcriptions. Most forced alignment tools provide only a single\nestimate of a boundary. The present project introduces a method of deriving\nconfidence intervals for these boundaries using a neural network ensemble\ntechnique. Ten different segment classifier neural networks were previously\ntrained, and the alignment process is repeated with each model. The alignment\nensemble is then used to place the boundary at the median of the boundaries in\nthe ensemble, and 97.85% confidence intervals are constructed using order\nstatistics. On the Buckeye and TIMIT corpora, the ensemble boundaries show a\nslight improvement over using just a single model. The confidence intervals are\nincorporated into Praat TextGrids using a point tier, and they are also output\nas a table for researchers to analyze separately as diagnostics or to\nincorporate uncertainty into their analyses.",
    "pdf_url": "http://arxiv.org/pdf/2506.01256v1",
    "published": "2025-06-02T02:12:28+00:00",
    "categories": [
      "eess.AS",
      "cs.CL",
      "cs.LG",
      "cs.SD"
    ],
    "primary_category": "eess.AS"
  },
  {
    "id": "http://arxiv.org/abs/2506.01255v1",
    "title": "Dynamic Control of Nonlinear Emission by Exciton-Photon Coupling in WS2 Metasurfaces",
    "authors": [
      "Mudassar Nauman",
      "Domenico de Ceglia",
      "Jingshi Yan",
      "Lujun Huang",
      "Mohsen Rahmani",
      "Costantino De Angelis",
      "Andrey E. Miroshnichenko",
      "Yuerui Lu",
      "Dragomir Neshev"
    ],
    "abstract": "Transition metal dichalcogenides (TMDCs) have demonstrated significant\npotential as versatile quantum materials for light absorption and emission.\nTheir unique properties are primarily governed by exciton-photon interactions,\nwhich can be substantially enhanced through coupling with resonant photonic\nstructures. For example, nonlinear light emission, such as second harmonic\ngeneration (SHG) is doubly enhanced when the incident wave is resonant\nsimultaneously with the excitonic and photonic resonance. However, the\nexcitonic absorption of incident waves can significantly dump the SHG emission.\nHere, we propose and demonstrate a tunable enhancement of SHG by leveraging\nvirtual coupling effects between quasi-bound states in the continuum (qBIC)\noptical resonances and tunable excitons in arrays of high-index WS2 crescent\nmetaatoms. These crescent metaatoms excites a pure magnetic type qBIC\nresonance, enabling dynamic control and enhancement of nonlinear optical\nprocesses in visible spectrum. Our findings demonstrate that an array of WS2\ncrescent metaatoms, exhibiting qBIC resonance at half the exciton energy,\nenhances SHG efficiency by more than 98-fold compared to monolayer WS2 (1L-WS2)\nand four orders of magnitude relative to unpatterned WS2 film. This substantial\nSHG enhancement is tunable as a function of temperature and polarization angle\nof incident light, allowing us to obtain control of the virtual coupling and\nSHG efficiency in the visible spectrum (600-650 nm). Our work opens new avenues\ntoward next-generation reconfigurable meta-optics devices.",
    "pdf_url": "http://arxiv.org/pdf/2506.01255v1",
    "published": "2025-06-02T02:12:01+00:00",
    "categories": [
      "physics.optics",
      "physics.app-ph"
    ],
    "primary_category": "physics.optics"
  },
  {
    "id": "http://arxiv.org/abs/2506.01254v1",
    "title": "Memory-Efficient FastText: A Comprehensive Approach Using Double-Array Trie Structures and Mark-Compact Memory Management",
    "authors": [
      "Yimin Du"
    ],
    "abstract": "FastText has established itself as a fundamental algorithm for learning word\nrepresentations, demonstrating exceptional capability in handling\nout-of-vocabulary words through character-level n-gram embeddings. However, its\nhash-based bucketing mechanism introduces critical limitations for large-scale\nindustrial deployment: hash collisions cause semantic drift, and memory\nrequirements become prohibitively expensive when dealing with real-world\nvocabularies containing millions of terms. This paper presents a comprehensive\nmemory optimization framework that fundamentally reimagines FastText's memory\nmanagement through the integration of double-array trie (DA-trie) structures\nand mark-compact garbage collection principles. Our approach leverages the\nlinguistic insight that n-grams sharing common prefixes or suffixes exhibit\nhighly correlated embeddings due to co-occurrence patterns in natural language.\nBy systematically identifying and merging semantically similar embeddings based\non structural relationships, we achieve compression ratios of 4:1 to 10:1 while\nmaintaining near-perfect embedding quality. The algorithm consists of four\nsophisticated phases: prefix trie construction with embedding mapping,\nprefix-based similarity compression, suffix-based similarity compression, and\nmark-compact memory reorganization. Comprehensive experiments on a 30-million\nChinese vocabulary dataset demonstrate memory reduction from over 100GB to\napproximately 30GB with negligible performance degradation. Our industrial\ndeployment results show significant cost reduction, faster loading times, and\nimproved model reliability through the elimination of hash collision artifacts.\nCode and experimental implementations are available at:\nhttps://github.com/initial-d/me_fasttext",
    "pdf_url": "http://arxiv.org/pdf/2506.01254v1",
    "published": "2025-06-02T02:11:22+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.01253v1",
    "title": "CoRE: Condition-based Reasoning for Identifying Outcome Variance in Complex Events",
    "authors": [
      "Sai Vallurupalli",
      "Francis Ferraro"
    ],
    "abstract": "Knowing which latent conditions lead to a particular outcome is useful for\ncritically examining claims made about complex event outcomes. Identifying\nimplied conditions and examining their influence on an outcome is challenging.\nWe handle this by combining and augmenting annotations from two existing\ndatasets consisting of goals and states, and explore the influence of\nconditions through our research questions and Condition-based Reasoning tasks.\nWe examine open and closed LLMs of varying sizes and intent-alignment on our\nreasoning tasks and find that conditions are useful when not all context is\navailable. Models differ widely in their ability to generate and identify\noutcome-variant conditions which affects their performance on outcome\nvalidation when conditions are used to replace missing context. Larger models\nlike GPT-4o, are more cautious in such less constrained situations.",
    "pdf_url": "http://arxiv.org/pdf/2506.01253v1",
    "published": "2025-06-02T02:09:20+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.01252v1",
    "title": "MTCMB: A Multi-Task Benchmark Framework for Evaluating LLMs on Knowledge, Reasoning, and Safety in Traditional Chinese Medicine",
    "authors": [
      "Shufeng Kong",
      "Xingru Yang",
      "Yuanyuan Wei",
      "Zijie Wang",
      "Hao Tang",
      "Jiuqi Qin",
      "Shuting Lan",
      "Yingheng Wang",
      "Junwen Bai",
      "Zhuangbin Chen",
      "Zibin Zheng",
      "Caihua Liu",
      "Hao Liang"
    ],
    "abstract": "Traditional Chinese Medicine (TCM) is a holistic medical system with\nmillennia of accumulated clinical experience, playing a vital role in global\nhealthcare-particularly across East Asia. However, the implicit reasoning,\ndiverse textual forms, and lack of standardization in TCM pose major challenges\nfor computational modeling and evaluation. Large Language Models (LLMs) have\ndemonstrated remarkable potential in processing natural language across diverse\ndomains, including general medicine. Yet, their systematic evaluation in the\nTCM domain remains underdeveloped. Existing benchmarks either focus narrowly on\nfactual question answering or lack domain-specific tasks and clinical realism.\nTo fill this gap, we introduce MTCMB-a Multi-Task Benchmark for Evaluating LLMs\non TCM Knowledge, Reasoning, and Safety. Developed in collaboration with\ncertified TCM experts, MTCMB comprises 12 sub-datasets spanning five major\ncategories: knowledge QA, language understanding, diagnostic reasoning,\nprescription generation, and safety evaluation. The benchmark integrates\nreal-world case records, national licensing exams, and classical texts,\nproviding an authentic and comprehensive testbed for TCM-capable models.\nPreliminary results indicate that current LLMs perform well on foundational\nknowledge but fall short in clinical reasoning, prescription planning, and\nsafety compliance. These findings highlight the urgent need for domain-aligned\nbenchmarks like MTCMB to guide the development of more competent and\ntrustworthy medical AI systems. All datasets, code, and evaluation tools are\npublicly available at: https://github.com/Wayyuanyuan/MTCMB.",
    "pdf_url": "http://arxiv.org/pdf/2506.01252v1",
    "published": "2025-06-02T02:01:40+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.01251v1",
    "title": "A generalized sphere theorem and its applications",
    "authors": [
      "Jing Mao"
    ],
    "abstract": "In this paper, we successfully set up a generalized sphere theorem for\ncompact Riemannian manifolds with radial Ricci curvature bounded.",
    "pdf_url": "http://arxiv.org/pdf/2506.01251v1",
    "published": "2025-06-02T01:59:27+00:00",
    "categories": [
      "math.DG",
      "35P15, 58C40"
    ],
    "primary_category": "math.DG"
  },
  {
    "id": "http://arxiv.org/abs/2506.01250v1",
    "title": "Neural Variance-aware Dueling Bandits with Deep Representation and Shallow Exploration",
    "authors": [
      "Youngmin Oh",
      "Jinje Park",
      "Taejin Paik",
      "Jaemin Park"
    ],
    "abstract": "In this paper, we address the contextual dueling bandit problem by proposing\nvariance-aware algorithms that leverage neural networks to approximate\nnonlinear utility functions. Our approach employs a \\textit{variance-aware\nexploration strategy}, which adaptively accounts for uncertainty in pairwise\ncomparisons while relying only on the gradients with respect to the learnable\nparameters of the last layer. This design effectively balances the\nexploration--exploitation tradeoff under both the Upper Confidence Bound (UCB)\nand Thompson Sampling (TS) frameworks. As a result, under standard assumptions,\nwe establish theoretical guarantees showing that our algorithms achieve\nsublinear cumulative average regret of order $\\bigol\\lt(d \\sqrt{\\sum_{t=1}^T\n\\sigma_t^2} + \\sqrt{dT}\\rt),$ for sufficiently wide neural networks, where $ d\n$ is the contextual dimension, $ \\sigma_t^2 $ the variance of comparisons at\nround $ t $, and $ T $ the total number of rounds. We also empirically validate\nthat our approach offers reasonable computational efficiency and achieves\nsublinear regret on both synthetic tasks with nonlinear utilities and\nreal-world tasks, outperforming existing methods.",
    "pdf_url": "http://arxiv.org/pdf/2506.01250v1",
    "published": "2025-06-02T01:58:48+00:00",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.01249v1",
    "title": "SysLLMatic: Large Language Models are Software System Optimizers",
    "authors": [
      "Huiyun Peng",
      "Arjun Gupte",
      "Ryan Hasler",
      "Nicholas John Eliopoulos",
      "Chien-Chou Ho",
      "Rishi Mantri",
      "Leo Deng",
      "Konstantin Läufer",
      "George K. Thiruvathukal",
      "James C. Davis"
    ],
    "abstract": "Automatic software system optimization can improve software speed, reduce\noperating costs, and save energy. Traditional approaches to optimization rely\non manual tuning and compiler heuristics, limiting their ability to generalize\nacross diverse codebases and system contexts. Recent methods using Large\nLanguage Models (LLMs) offer automation to address these limitations, but often\nfail to scale to the complexity of real-world software systems and\napplications. We present SysLLMatic, a system that integrates LLMs with\nprofiling-guided feedback and system performance insights to automatically\noptimize software code. We evaluate it on three benchmark suites: HumanEval_CPP\n(competitive programming in C++), SciMark2 (scientific kernels in Java), and\nDaCapoBench (large-scale software systems in Java). Results show that\nSysLLMatic can improve system performance, including latency, throughput,\nenergy efficiency, memory usage, and CPU utilization. It consistently\noutperforms state-of-the-art LLM baselines on microbenchmarks. On large-scale\napplication codes, it surpasses traditional compiler optimizations, achieving\naverage relative improvements of 1.85x in latency and 2.24x in throughput. Our\nfindings demonstrate that LLMs, guided by principled systems thinking and\nappropriate performance diagnostics, can serve as viable software system\noptimizers. We further identify limitations of our approach and the challenges\ninvolved in handling complex applications. This work provides a foundation for\ngenerating optimized code across various languages, benchmarks, and program\nsizes in a principled manner.",
    "pdf_url": "http://arxiv.org/pdf/2506.01249v1",
    "published": "2025-06-02T01:57:21+00:00",
    "categories": [
      "cs.SE",
      "cs.PF"
    ],
    "primary_category": "cs.SE"
  },
  {
    "id": "http://arxiv.org/abs/2506.11070v1",
    "title": "Targeted control of fast prototyping through domain-specific interface",
    "authors": [
      "Yu-Zhe Shi",
      "Mingchen Liu",
      "Hanlu Ma",
      "Qiao Xu",
      "Huamin Qu",
      "Kun He",
      "Lecheng Ruan",
      "Qining Wang"
    ],
    "abstract": "Industrial designers have long sought a natural and intuitive way to achieve\nthe targeted control of prototype models -- using simple natural language\ninstructions to configure and adjust the models seamlessly according to their\nintentions, without relying on complex modeling commands. While Large Language\nModels have shown promise in this area, their potential for controlling\nprototype models through language remains partially underutilized. This\nlimitation stems from gaps between designers' languages and modeling languages,\nincluding mismatch in abstraction levels, fluctuation in semantic precision,\nand divergence in lexical scopes. To bridge these gaps, we propose an interface\narchitecture that serves as a medium between the two languages. Grounded in\ndesign principles derived from a systematic investigation of fast prototyping\npractices, we devise the interface's operational mechanism and develop an\nalgorithm for its automated domain specification. Both machine-based\nevaluations and human studies on fast prototyping across various product design\ndomains demonstrate the interface's potential to function as an auxiliary\nmodule for Large Language Models, enabling precise and effective targeted\ncontrol of prototype models.",
    "pdf_url": "http://arxiv.org/pdf/2506.11070v1",
    "published": "2025-06-02T01:56:31+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.01248v1",
    "title": "Conjugacy in a family of free-by-cyclic groups",
    "authors": [
      "Martin R. Bridson",
      "Timothy R. Riley",
      "Andrew W. Sale"
    ],
    "abstract": "We analyse the geometry and complexity of the conjugacy problem in a family\nof free-by-cyclic groups $H_m=F_m\\rtimes\\mathbb{Z}$ where the defining\nfree-group automorphism is positive and polynomially growing. We prove that the\nconjugator length function of $H_m$ is linear, and describe polynomial-time\nsolutions to the conjugacy problem and conjugacy search problem in $H_m$.",
    "pdf_url": "http://arxiv.org/pdf/2506.01248v1",
    "published": "2025-06-02T01:52:52+00:00",
    "categories": [
      "math.GR",
      "20F65, 20F10"
    ],
    "primary_category": "math.GR"
  },
  {
    "id": "http://arxiv.org/abs/2506.01247v1",
    "title": "Visual Sparse Steering: Improving Zero-shot Image Classification with Sparsity Guided Steering Vectors",
    "authors": [
      "Gerasimos Chatzoudis",
      "Zhuowei Li",
      "Gemma E. Moran",
      "Hao Wang",
      "Dimitris N. Metaxas"
    ],
    "abstract": "Steering vision foundation models at inference time without retraining or\naccess to large labeled datasets is a desirable yet challenging objective,\nparticularly in dynamic or resource-constrained settings. In this paper, we\nintroduce Visual Sparse Steering (VS2), a lightweight, test-time method that\nguides vision models using steering vectors derived from sparse features\nlearned by top-$k$ Sparse Autoencoders without requiring contrastive data.\nSpecifically, VS2 surpasses zero-shot CLIP by 4.12% on CIFAR-100, 1.08% on\nCUB-200, and 1.84% on Tiny-ImageNet. We further propose VS2++, a\nretrieval-augmented variant that selectively amplifies relevant sparse features\nusing pseudo-labeled neighbors at inference time. With oracle positive/negative\nsets, VS2++ achieves absolute top-1 gains over CLIP zero-shot of up to 21.44%\non CIFAR-100, 7.08% on CUB-200, and 20.47% on Tiny-ImageNet. Interestingly, VS2\nand VS2++ raise per-class accuracy by up to 25% and 38%, respectively, showing\nthat sparse steering benefits specific classes by disambiguating visually or\ntaxonomically proximate categories rather than providing a uniform boost.\nFinally, to better align the sparse features learned through the SAE\nreconstruction task with those relevant for downstream performance, we propose\nPrototype-Aligned Sparse Steering (PASS). By incorporating a\nprototype-alignment loss during SAE training, using labels only during training\nwhile remaining fully test-time unsupervised, PASS consistently, though\nmodestly, outperforms VS2, achieving a 6.12% gain over VS2 only on CIFAR-100\nwith ViT-B/32.",
    "pdf_url": "http://arxiv.org/pdf/2506.01247v1",
    "published": "2025-06-02T01:51:20+00:00",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.01246v1",
    "title": "Inverse scattering for the nonlinear magnetic Schrodinger equation",
    "authors": [
      "Lei Wei",
      "Hua Huang"
    ],
    "abstract": "In this paper, we focus on the inverse scattering problem for the nonlinear\nSchrodinger equation with magnetic potentials. Specifically, we investigate\nwhether the scattering operator associated with the nonlinear Schrodinger\nequation can uniquely determine the magnetic potential. Our main goal is to\nestablish the uniqueness result for the magnetic potential based on the\nscattering data obtained from the scattering operator.",
    "pdf_url": "http://arxiv.org/pdf/2506.01246v1",
    "published": "2025-06-02T01:47:17+00:00",
    "categories": [
      "math.AP",
      "81U40, 35Q60, 35Q55"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2506.01245v2",
    "title": "Comprehensive Vulnerability Analysis is Necessary for Trustworthy LLM-MAS",
    "authors": [
      "Pengfei He",
      "Yue Xing",
      "Shen Dong",
      "Juanhui Li",
      "Zhenwei Dai",
      "Xianfeng Tang",
      "Hui Liu",
      "Han Xu",
      "Zhen Xiang",
      "Charu C. Aggarwal",
      "Hui Liu"
    ],
    "abstract": "This paper argues that a comprehensive vulnerability analysis is essential\nfor building trustworthy Large Language Model-based Multi-Agent Systems\n(LLM-MAS). These systems, which consist of multiple LLM-powered agents working\ncollaboratively, are increasingly deployed in high-stakes applications but face\nnovel security threats due to their complex structures. While single-agent\nvulnerabilities are well-studied, LLM-MAS introduces unique attack surfaces\nthrough inter-agent communication, trust relationships, and tool integration\nthat remain significantly underexplored. We present a systematic framework for\nvulnerability analysis of LLM-MAS that unifies diverse research. For each type\nof vulnerability, we define formal threat models grounded in practical attacker\ncapabilities and illustrate them using real-world LLM-MAS applications. This\nformulation enables rigorous quantification of vulnerability across different\narchitectures and provides a foundation for designing meaningful evaluation\nbenchmarks. Our analysis reveals that LLM-MAS faces elevated risk due to\ncompositional effects -- vulnerabilities in individual components can cascade\nthrough agent communication, creating threat models not present in single-agent\nsystems. We conclude by identifying critical open challenges: (1) developing\nbenchmarks specifically tailored to LLM-MAS vulnerability assessment, (2)\nconsidering new potential attacks specific to multi-agent architectures, and\n(3) implementing trust management systems that can enforce security in LLM-MAS.\nThis research provides essential groundwork for future efforts to enhance\nLLM-MAS trustworthiness as these systems continue their expansion into critical\napplications.",
    "pdf_url": "http://arxiv.org/pdf/2506.01245v2",
    "published": "2025-06-02T01:46:15+00:00",
    "categories": [
      "cs.CR"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2506.01244v2",
    "title": "Exact operator inference with minimal data",
    "authors": [
      "Henrik Rosenberger",
      "Benjamin Sanderse",
      "Giovanni Stabile"
    ],
    "abstract": "This work introduces a novel method to generate snapshot data for operator\ninference that guarantees the exact reconstruction of intrusive\nprojection-based reduced-order models (ROMs). To ensure exact reconstruction,\nthe operator inference least squares matrix must have full rank, without\nregularization. Existing works have achieved this full rank using heuristic\nstrategies to generate snapshot data and a-posteriori checks on full rank, but\nwithout a guarantee of success. Our novel snapshot data generation method\nprovides this guarantee thanks to two key ingredients: first we identify ROM\nstates that induce full rank, then we generate snapshots corresponding to\nexactly these states by simulating multiple trajectories for only a single time\nstep. This way, the number of required snapshots is minimal and orders of\nmagnitude lower than typically reported with existing methods. The method\navoids non-Markovian terms and does not require re-projection. Since the number\nof snapshots is minimal, the least squares problem simplifies to a linear\nsystem that is numerically more stable. In addition, because the inferred\noperators are exact, properties of the intrusive ROM operators such as symmetry\nor skew-symmetry are preserved. Numerical results for differential equations\ninvolving 2nd, 3rd and 8th order polynomials demonstrate that the novel\nsnapshot data generation method leads to exact reconstruction of the intrusive\nreduced order models.",
    "pdf_url": "http://arxiv.org/pdf/2506.01244v2",
    "published": "2025-06-02T01:44:33+00:00",
    "categories": [
      "math.NA",
      "cs.NA",
      "65Y99, 65F22, 35R30, 65D05"
    ],
    "primary_category": "math.NA"
  },
  {
    "id": "http://arxiv.org/abs/2506.03198v1",
    "title": "FLEX: A Large-Scale Multi-Modal Multi-Action Dataset for Fitness Action Quality Assessment",
    "authors": [
      "Hao Yin",
      "Lijun Gu",
      "Paritosh Parmar",
      "Lin Xu",
      "Tianxiao Guo",
      "Weiwei Fu",
      "Yang Zhang",
      "Tianyou Zheng"
    ],
    "abstract": "With the increasing awareness of health and the growing desire for aesthetic\nphysique, fitness has become a prevailing trend. However, the potential risks\nassociated with fitness training, especially with weight-loaded fitness\nactions, cannot be overlooked. Action Quality Assessment (AQA), a technology\nthat quantifies the quality of human action and provides feedback, holds the\npotential to assist fitness enthusiasts of varying skill levels in achieving\nbetter training outcomes. Nevertheless, current AQA methodologies and datasets\nare limited to single-view competitive sports scenarios and RGB modality and\nlack professional assessment and guidance of fitness actions. To address this\ngap, we propose the FLEX dataset, the first multi-modal, multi-action,\nlarge-scale dataset that incorporates surface electromyography (sEMG) signals\ninto AQA. FLEX utilizes high-precision MoCap to collect 20 different\nweight-loaded actions performed by 38 subjects across 3 different skill levels\nfor 10 repetitions each, containing 5 different views of the RGB video, 3D\npose, sEMG, and physiological information. Additionally, FLEX incorporates\nknowledge graphs into AQA, constructing annotation rules in the form of penalty\nfunctions that map weight-loaded actions, action keysteps, error types, and\nfeedback. We conducted various baseline methodologies on FLEX, demonstrating\nthat multimodal data, multiview data, and fine-grained annotations\nsignificantly enhance model performance. FLEX not only advances AQA\nmethodologies and datasets towards multi-modal and multi-action scenarios but\nalso fosters the integration of artificial intelligence within the fitness\ndomain. Dataset and code are available at\nhttps://haoyin116.github.io/FLEX_Dataset.",
    "pdf_url": "http://arxiv.org/pdf/2506.03198v1",
    "published": "2025-06-02T01:44:02+00:00",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.01243v1",
    "title": "Energy-Efficient Integrated Communication and Computation via Non-Terrestrial Networks with Uncertainty Awareness",
    "authors": [
      "Xiao Tang",
      "Yudan Jiang",
      "Ruonan Zhang",
      "Qinghe Du",
      "Jinxin Liu",
      "Naijin Liu"
    ],
    "abstract": "Non-terrestrial network (NTN)-based integrated communication and computation\nempowers various emerging applications with global coverage. Yet this vision is\nseverely challenged by the energy issue given the limited energy supply of NTN\nnodes and the energy-consuming nature of communication and computation. In this\npaper, we investigate the energy-efficient integrated communication and\ncomputation for the ground node data through a NTN, incorporating an unmanned\naerial vehicle (UAV) and a satellite. We jointly consider ground data\noffloading to the UAV, edge processing on the UAV, and the forwarding of\nresults from UAV to satellite, where we particularly address the uncertainties\nof the UAV-satellite links due to the large distance and high dynamics therein.\nAccordingly, we propose to minimize the weighted energy consumption due to data\noffloading, UAV computation, UAV transmission, and UAV propulsion, in the\npresence of angular uncertainties under Gaussian distribution within the\nUAV-satellite channels. The formulated problem with probabilistic constraints\ndue to uncertainties is converted into a deterministic form by exploiting the\nBernstein-type inequality, which is then solved using a block coordinate\ndescent framework with algorithm design. Simulation results are provided to\ndemonstrate the performance superiority of our proposal in terms of energy\nsustainability, along with the robustness against uncertain non-terrestrial\nenvironments.",
    "pdf_url": "http://arxiv.org/pdf/2506.01243v1",
    "published": "2025-06-02T01:43:18+00:00",
    "categories": [
      "eess.SP"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2506.01242v1",
    "title": "General search techniques without common knowledge for imperfect-information games, and application to superhuman Fog of War chess",
    "authors": [
      "Brian Hu Zhang",
      "Tuomas Sandholm"
    ],
    "abstract": "Since the advent of AI, games have served as progress benchmarks. Meanwhile,\nimperfect-information variants of chess have existed for over a century,\npresent extreme challenges, and have been the focus of significant AI research.\nBeyond calculation needed in regular chess, they require reasoning about\ninformation gathering, the opponent's knowledge, signaling, etc. The most\npopular variant, Fog of War (FoW) chess (aka. dark chess) is a recognized\nchallenge problem in AI after superhuman performance was reached in no-limit\nTexas hold'em poker. We present Obscuro, the first superhuman AI for FoW chess.\nIt introduces advances to search in imperfect-information games, enabling\nstrong, scalable reasoning. Experiments against the prior state-of-the-art AI\nand human players -- including the world's best -- show that Obscuro is\nsignificantly stronger. FoW chess is the largest (by amount of imperfect\ninformation) turn-based game in which superhuman performance has been achieved\nand the largest game in which imperfect-information search has been\nsuccessfully applied.",
    "pdf_url": "http://arxiv.org/pdf/2506.01242v1",
    "published": "2025-06-02T01:41:27+00:00",
    "categories": [
      "cs.GT",
      "cs.AI"
    ],
    "primary_category": "cs.GT"
  },
  {
    "id": "http://arxiv.org/abs/2506.01241v2",
    "title": "ExpertLongBench: Benchmarking Language Models on Expert-Level Long-Form Generation Tasks with Structured Checklists",
    "authors": [
      "Jie Ruan",
      "Inderjeet Nair",
      "Shuyang Cao",
      "Amy Liu",
      "Sheza Munir",
      "Micah Pollens-Dempsey",
      "Tiffany Chiang",
      "Lucy Kates",
      "Nicholas David",
      "Sihan Chen",
      "Ruxin Yang",
      "Yuqian Yang",
      "Jasmine Gump",
      "Tessa Bialek",
      "Vivek Sankaran",
      "Margo Schlanger",
      "Lu Wang"
    ],
    "abstract": "This paper introduces ExpertLongBench, an expert-level benchmark containing\n11 tasks from 9 domains that reflect realistic expert workflows and\napplications. Beyond question answering, the application-driven tasks in\nExpertLongBench demand long-form outputs that can exceed 5,000 tokens and\nstrict adherence to domain-specific requirements. Notably, each task in\nExpertLongBench includes a rubric, designed or validated by domain experts, to\nspecify task requirements and guide output evaluation. Furthermore, we propose\nCLEAR, an evaluation framework that supports accurate evaluation of long-form\nmodel outputs in our benchmark. To achieve fine-grained, expert-aligned\nevaluation, CLEAR derives checklists from both model outputs and references by\nextracting information corresponding to items in the task-specific rubric.\nChecklist items for model outputs are then compared with corresponding items\nfor reference outputs to assess their correctness, enabling grounded\nevaluation. We benchmark 11 large language models (LLMs) and analyze components\nin CLEAR, showing that (1) existing LLMs, with the top performer achieving only\na 26.8% F1 score, require significant improvement for expert-level tasks; (2)\nmodels can generate content corresponding to the required aspects, though often\nnot accurately; and (3) accurate checklist extraction and comparison in CLEAR\ncan be achieved by open-weight models for more scalable and low-cost usage.",
    "pdf_url": "http://arxiv.org/pdf/2506.01241v2",
    "published": "2025-06-02T01:39:02+00:00",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.01240v1",
    "title": "Polariton Chern Bands in 2D Photonic Crystals Beyond Dirac Cones",
    "authors": [
      "Xin Xie",
      "Kai Sun",
      "Hui Deng"
    ],
    "abstract": "Polaritons, formed by strong light-matter interactions, open new avenues for\nstudying topological phases, where the spatial and time symmetries can be\ncontrolled via the light and matter components, respectively. However, most\nresearch on topological polaritons has been confined to hexagonal photonic\nlattices featuring Dirac cones at large wavenumbers. This restricts key\ntopological properties and device performance, including sub-meV gap sizes that\nhinder further experimental investigations and future applications of polariton\nChern insulator systems. In this study, we move beyond the traditional Dirac\ncone framework and introduce two alternative band structures in photonic\ncrystals (PhCs) as promising platforms for realizing polariton Chern bands:\nbands with symmetry-protected bound states in the continuum (BICs) and bands\nwith symmetry-protected degeneracies at the $\\Gamma$ points. These band\nstructures are prevalent in various PhC lattices and have features crucial for\nexperimental studies. We show examples of higher Chern number bands, more\nuniform Berry curvature distributions, and an experimentally feasible system\ncapable of achieving a large topological gap. Our findings show the broad\napplicability of polariton Chern bands in 2D PhCs, provide design principles\nfor enhancing the functionality and performance of topological photonic\ndevices, opening up exciting possibilities for better understanding and using\ntopological physics.",
    "pdf_url": "http://arxiv.org/pdf/2506.01240v1",
    "published": "2025-06-02T01:34:31+00:00",
    "categories": [
      "physics.optics",
      "cond-mat.mes-hall"
    ],
    "primary_category": "physics.optics"
  },
  {
    "id": "http://arxiv.org/abs/2506.11069v1",
    "title": "Regularized Federated Learning for Privacy-Preserving Dysarthric and Elderly Speech Recognition",
    "authors": [
      "Tao Zhong",
      "Mengzhe Geng",
      "Shujie Hu",
      "Guinan Li",
      "Xunying Liu"
    ],
    "abstract": "Accurate recognition of dysarthric and elderly speech remains challenging to\ndate. While privacy concerns have driven a shift from centralized approaches to\nfederated learning (FL) to ensure data confidentiality, this further\nexacerbates the challenges of data scarcity, imbalanced data distribution and\nspeaker heterogeneity. To this end, this paper conducts a systematic\ninvestigation of regularized FL techniques for privacy-preserving dysarthric\nand elderly speech recognition, addressing different levels of the FL process\nby 1) parameter-based, 2) embedding-based and 3) novel loss-based\nregularization. Experiments on the benchmark UASpeech dysarthric and\nDementiaBank Pitt elderly speech corpora suggest that regularized FL systems\nconsistently outperform the baseline FedAvg system by statistically significant\nWER reductions of up to 0.55\\% absolute (2.13\\% relative). Further increasing\ncommunication frequency to one exchange per batch approaches centralized\ntraining performance.",
    "pdf_url": "http://arxiv.org/pdf/2506.11069v1",
    "published": "2025-06-02T01:34:20+00:00",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.CL",
      "cs.SD"
    ],
    "primary_category": "eess.AS"
  },
  {
    "id": "http://arxiv.org/abs/2506.02067v1",
    "title": "Computational complexity of spin-glass three-dimensional (3D) Ising model",
    "authors": [
      "Zhidong Zhang"
    ],
    "abstract": "In this work, the computational complexity of a spin-glass three-dimensional\n(3D) Ising model (for the lattice size N = lmn, where l, m, n are the numbers\nof lattice points along three crystallographic directions) is studied. We prove\nthat an absolute minimum core (AMC) model consisting of a spin-glass 2D Ising\nmodel interacting with its nearest neighboring plane, has its computational\ncomplexity O(2^mn). Any algorithms to make the model smaller (or simpler) than\nthe AMC model will cut the basic element of the spin-glass 3D Ising model and\nlost many important information of the original model. Therefore, the\ncomputational complexity of the spin-glass 3D Ising model cannot be reduced to\nbe less than O(2^mn) by any algorithms, which is in subexponential time,\nsuperpolynomial.",
    "pdf_url": "http://arxiv.org/pdf/2506.02067v1",
    "published": "2025-06-02T01:31:45+00:00",
    "categories": [
      "physics.gen-ph"
    ],
    "primary_category": "physics.gen-ph"
  },
  {
    "id": "http://arxiv.org/abs/2506.01239v1",
    "title": "Linear Diophantine equations and conjugator length in 2-step nilpotent groups",
    "authors": [
      "Martin R. Bridson",
      "Timothy R. Riley"
    ],
    "abstract": "We establish upper bounds on the lengths of minimal conjugators in 2-step\nnilpotent groups. These bounds exploit the existence of small integral\nsolutions to systems of linear Diophantine equations. We prove that in some\ncases these bounds are sharp. This enables us to construct a family of finitely\ngenerated 2-step nilpotent groups $(G_m)_{m\\in\\mathbb{N}}$ such that the\nconjugator length function of $G_m$ grows like a polynomial of degree $m+1$.",
    "pdf_url": "http://arxiv.org/pdf/2506.01239v1",
    "published": "2025-06-02T01:31:35+00:00",
    "categories": [
      "math.GR",
      "20F65, 20F10, 20F18"
    ],
    "primary_category": "math.GR"
  },
  {
    "id": "http://arxiv.org/abs/2506.01238v1",
    "title": "Testing the Young FRB Progenitor Hypothesis: A Crossmatch of Catalog-1 CHIME Bursts with Historic Local Universe Supernovae",
    "authors": [
      "Wanqing Liu",
      "Mohit Bhardwaj",
      "Ben Margalit"
    ],
    "abstract": "Fast radio bursts (FRBs) are among the most energetic and enigmatic\ntransients in the radio sky, with mounting evidence suggesting newborn, highly\nmagnetized neutron stars formed in core-collapse supernovae (CCSNe) as their\nsources. A definitive spatial association between an FRB and a historic CCSN\nwould confirm this link and tightly constrain young neutron star source models.\nHere we report on the first systematic cross-matching of 886 spectroscopically\nclassified CCSNe in the local Universe (z $\\leq$ 0.043) against 241 CHIME/FRB\nCatalog 1 events, applying rigorous spatial, dispersion measure (DM), and\nscattering time (${\\tau}$) criteria. We identify four positional overlaps, all\nconsistent with chance alignment; however, one pair, FRB 20190412B-SN 2009gi,\nalso satisfies independent host-DM and ${\\tau}$ constraints, making it a\npromising candidate for targeted follow-up. Next, we search for compact\n(persistent or transient) radio emission at all matched supernova sites using\nmulti-epoch VLASS data and detect none. Treating every CCSN sight line as a\nnon-detection, we derive Poisson upper limits on the FRB burst rate at these\nlocations, which lie well below the rates observed for the most active\nrepeaters unless their activity is heavily suppressed by beaming,\nintermittency, or residual free-free absorption. We then develop a\ngalaxy-integrated FRB-rate model that incorporates an intrinsic spectral index,\nsecular magnetar-activity decay, and frequency-dependent free-free opacity.\nApplying this formalism to existing FRB data shows that reproducing the\nobserved CHIME/CRAFT all-sky rate ratio requires a steep decline in magnetar\nburst rates with age. Finally, our work underscores the necessity of\nsub-arcsecond localizations and multiwavelength follow-up to definitively test\nthe young neutron star source hypothesis.",
    "pdf_url": "http://arxiv.org/pdf/2506.01238v1",
    "published": "2025-06-02T01:29:50+00:00",
    "categories": [
      "astro-ph.HE"
    ],
    "primary_category": "astro-ph.HE"
  },
  {
    "id": "http://arxiv.org/abs/2506.01237v1",
    "title": "Polishing Every Facet of the GEM: Testing Linguistic Competence of LLMs and Humans in Korean",
    "authors": [
      "SungHo Kim",
      "Nayeon Kim",
      "Taehee Jeon",
      "SangKeun Lee"
    ],
    "abstract": "We introduce the $\\underline{Ko}rean \\underline{G}rammar\n\\underline{E}valuation Bench\\underline{M}ark (KoGEM)$, designed to assess the\nlinguistic competence of LLMs and humans in Korean. KoGEM consists of 1.5k\nmultiple-choice QA pairs covering five main categories and 16 subcategories.\nThe zero-shot evaluation of 27 LLMs of various sizes and types reveals that\nwhile LLMs perform remarkably well on straightforward tasks requiring primarily\ndefinitional knowledge, they struggle with tasks that demand the integration of\nreal-world experiential knowledge, such as phonological rules and\npronunciation. Furthermore, our in-depth analysis suggests that incorporating\nsuch experiential knowledge could enhance the linguistic competence of LLMs.\nWith KoGEM, we not only highlight the limitations of current LLMs in linguistic\ncompetence but also uncover hidden facets of LLMs in linguistic competence,\npaving the way for enhancing comprehensive language understanding. Our code and\ndataset are available at: https://github.com/SungHo3268/KoGEM.",
    "pdf_url": "http://arxiv.org/pdf/2506.01237v1",
    "published": "2025-06-02T01:27:46+00:00",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL"
  },
  {
    "id": "http://arxiv.org/abs/2506.01236v1",
    "title": "Construction of DNA codes using $θ$-skew cyclic codes over $\\mathbb{F}_4 + v \\mathbb{F}_4$",
    "authors": [
      "Joël Kabore",
      "Mohammed Elhassani Charkani"
    ],
    "abstract": "In this paper, we investigate $\\theta$-skew cyclic codes over the ring $R=\n\\mathbb{F}_4 + v \\mathbb{F}_4$, where $v^2=v$ and $\\theta$ is a non-trivial\nautomorphism over $\\mathbb{F}_4 + v \\mathbb{F}_4$. This allows us to describe\nDNA code over this ring by characterizing $\\theta$-skew cyclic reversible DNA\ncodes and $\\theta$-skew cyclic reversible complement DNA codes. We also explore\nthe Gray images of $\\theta$-skew cyclic codes.",
    "pdf_url": "http://arxiv.org/pdf/2506.01236v1",
    "published": "2025-06-02T01:23:43+00:00",
    "categories": [
      "cs.IT",
      "math.IT",
      "94B05, 94B60, 11T71"
    ],
    "primary_category": "cs.IT"
  },
  {
    "id": "http://arxiv.org/abs/2506.01235v1",
    "title": "The lengths of conjugators in the model filiform groups",
    "authors": [
      "Martin R. Bridson",
      "Timothy R. Riley"
    ],
    "abstract": "The conjugator length function of a finitely generated group $\\Gamma$ gives\nthe optimal upper bound on the length of a shortest conjugator for any pair of\nconjugate elements in the ball of radius $n$ in the Cayley graph of $\\Gamma$.\nWe prove that polynomials of arbitrary degree arise as conjugator length\nfunctions of finitely presented groups. To establish this, we analyse the\ngeometry of conjugation in the discrete model filiform groups $\\Gamma_d =\n\\mathbb{Z}^d\\rtimes_\\phi\\mathbb{Z}$ where is $\\phi$ is the automorphism of\n$\\mathbb{Z}^d$ that fixes the last element of a basis $a_1,\\dots,a_d$ and sends\n$a_i$ to $a_ia_{i+1}$ for $i<d$. The conjugator length function of $\\Gamma_d$\nis polynomial of degree $d$.",
    "pdf_url": "http://arxiv.org/pdf/2506.01235v1",
    "published": "2025-06-02T01:22:16+00:00",
    "categories": [
      "math.GR",
      "20F65, 20F10, 20F18"
    ],
    "primary_category": "math.GR"
  },
  {
    "id": "http://arxiv.org/abs/2506.01234v2",
    "title": "Fourier-Modulated Implicit Neural Representation for Multispectral Satellite Image Compression",
    "authors": [
      "Woojin Cho",
      "Steve Andreas Immanuel",
      "Junhyuk Heo",
      "Darongsae Kwon"
    ],
    "abstract": "Multispectral satellite images play a vital role in agriculture, fisheries,\nand environmental monitoring. However, their high dimensionality, large data\nvolumes, and diverse spatial resolutions across multiple channels pose\nsignificant challenges for data compression and analysis. This paper presents\nImpliSat, a unified framework specifically designed to address these challenges\nthrough efficient compression and reconstruction of multispectral satellite\ndata. ImpliSat leverages Implicit Neural Representations (INR) to model\nsatellite images as continuous functions over coordinate space, capturing fine\nspatial details across varying spatial resolutions. Furthermore, we introduce a\nFourier modulation algorithm that dynamically adjusts to the spectral and\nspatial characteristics of each band, ensuring optimal compression while\npreserving critical image details.",
    "pdf_url": "http://arxiv.org/pdf/2506.01234v2",
    "published": "2025-06-02T01:16:36+00:00",
    "categories": [
      "cs.CV",
      "cs.AI",
      "eess.IV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.01233v1",
    "title": "Hyperspherical Analysis of Dimer-Dimer Scattering in One-Dimensional Systems",
    "authors": [
      "Jia Wang",
      "Hui Hu",
      "Xia-Ji Liu"
    ],
    "abstract": "We present a comprehensive analysis of four-body scattering in\none-dimensional (1D) quantum systems using the adiabatic hyperspherical\nrepresentation (AHR). Focusing on dimer-dimer collisions between two species of\nfermions interacting via the sinh-cosh potential, we implement the slow\nvariable discretization (SVD) method to overcome numerical challenges posed by\nsharp avoided crossings in the potential curves. Our numerical approach is\nbenchmarked against exact analytical results available in integrable regimes,\ndemonstrating excellent agreement. We further explore non-integrable regimes\nwhere no analytical solutions exist, revealing novel features such as resonant\nenhancement of the scattering length associated with tetramer formation. These\nresults highlight the power and flexibility of the AHR+SVD framework for\naccurate few-body scattering calculations in low-dimensional quantum systems,\nand establish a foundation for future investigations of universal few-body\nphysics in ultracold gases.",
    "pdf_url": "http://arxiv.org/pdf/2506.01233v1",
    "published": "2025-06-02T01:11:30+00:00",
    "categories": [
      "cond-mat.quant-gas",
      "physics.atom-ph",
      "quant-ph"
    ],
    "primary_category": "cond-mat.quant-gas"
  },
  {
    "id": "http://arxiv.org/abs/2506.01232v1",
    "title": "Retrieval-Augmented Generation of Ontologies from Relational Databases",
    "authors": [
      "Mojtaba Nayyeri",
      "Athish A Yogi",
      "Nadeen Fathallah",
      "Ratan Bahadur Thapa",
      "Hans-Michael Tautenhahn",
      "Anton Schnurpel",
      "Steffen Staab"
    ],
    "abstract": "Transforming relational databases into knowledge graphs with enriched\nontologies enhances semantic interoperability and unlocks advanced graph-based\nlearning and reasoning over data. However, previous approaches either demand\nsignificant manual effort to derive an ontology from a database schema or\nproduce only a basic ontology. We present RIGOR, Retrieval-augmented Iterative\nGeneration of RDB Ontologies, an LLM-driven approach that turns relational\nschemas into rich OWL ontologies with minimal human effort. RIGOR combines\nthree sources via RAG, the database schema and its documentation, a repository\nof domain ontologies, and a growing core ontology, to prompt a generative LLM\nfor producing successive, provenance-tagged delta ontology fragments. Each\nfragment is refined by a judge-LLM before being merged into the core ontology,\nand the process iterates table-by-table following foreign key constraints until\ncoverage is complete. Applied to real-world databases, our approach outputs\nontologies that score highly on standard quality dimensions such as accuracy,\ncompleteness, conciseness, adaptability, clarity, and consistency, while\nsubstantially reducing manual effort.",
    "pdf_url": "http://arxiv.org/pdf/2506.01232v1",
    "published": "2025-06-02T01:10:05+00:00",
    "categories": [
      "cs.DB",
      "cs.AI"
    ],
    "primary_category": "cs.DB"
  },
  {
    "id": "http://arxiv.org/abs/2506.01231v2",
    "title": "Towards Efficient Few-shot Graph Neural Architecture Search via Partitioning Gradient Contribution",
    "authors": [
      "Wenhao Song",
      "Xuan Wu",
      "Bo Yang",
      "You Zhou",
      "Yubin Xiao",
      "Yanchun Liang",
      "Hongwei Ge",
      "Heow Pueh Lee",
      "Chunguo Wu"
    ],
    "abstract": "To address the weight coupling problem, certain studies introduced few-shot\nNeural Architecture Search (NAS) methods, which partition the supernet into\nmultiple sub-supernets. However, these methods often suffer from computational\ninefficiency and tend to provide suboptimal partitioning schemes. To address\nthis problem more effectively, we analyze the weight coupling problem from a\nnovel perspective, which primarily stems from distinct modules in succeeding\nlayers imposing conflicting gradient directions on the preceding layer modules.\nBased on this perspective, we propose the Gradient Contribution (GC) method\nthat efficiently computes the cosine similarity of gradient directions among\nmodules by decomposing the Vector-Jacobian Product during supernet\nbackpropagation. Subsequently, the modules with conflicting gradient directions\nare allocated to distinct sub-supernets while similar ones are grouped\ntogether. To assess the advantages of GC and address the limitations of\nexisting Graph Neural Architecture Search methods, which are limited to\nsearching a single type of Graph Neural Networks (Message Passing Neural\nNetworks (MPNNs) or Graph Transformers (GTs)), we propose the Unified Graph\nNeural Architecture Search (UGAS) framework, which explores optimal\ncombinations of MPNNs and GTs. The experimental results demonstrate that GC\nachieves state-of-the-art (SOTA) performance in supernet partitioning quality\nand time efficiency. In addition, the architectures searched by UGAS+GC\noutperform both the manually designed GNNs and those obtained by existing NAS\nmethods. Finally, ablation studies further demonstrate the effectiveness of all\nproposed methods.",
    "pdf_url": "http://arxiv.org/pdf/2506.01231v2",
    "published": "2025-06-02T01:03:12+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.01230v1",
    "title": "Stress-Testing ML Pipelines with Adversarial Data Corruption",
    "authors": [
      "Jiongli Zhu",
      "Geyang Xu",
      "Felipe Lorenzi",
      "Boris Glavic",
      "Babak Salimi"
    ],
    "abstract": "Structured data-quality issues, such as missing values correlated with\ndemographics, culturally biased labels, or systemic selection biases, routinely\ndegrade the reliability of machine-learning pipelines. Regulators now\nincreasingly demand evidence that high-stakes systems can withstand these\nrealistic, interdependent errors, yet current robustness evaluations typically\nuse random or overly simplistic corruptions, leaving worst-case scenarios\nunexplored. We introduce SAVAGE, a causally inspired framework that (i)\nformally models realistic data-quality issues through dependency graphs and\nflexible corruption templates, and (ii) systematically discovers corruption\npatterns that maximally degrade a target performance metric. SAVAGE employs a\nbi-level optimization approach to efficiently identify vulnerable data\nsubpopulations and fine-tune corruption severity, treating the full ML\npipeline, including preprocessing and potentially non-differentiable models, as\na black box. Extensive experiments across multiple datasets and ML tasks (data\ncleaning, fairness-aware learning, uncertainty quantification) demonstrate that\neven a small fraction (around 5 %) of structured corruptions identified by\nSAVAGE severely impacts model performance, far exceeding random or manually\ncrafted errors, and invalidating core assumptions of existing techniques. Thus,\nSAVAGE provides a practical tool for rigorous pipeline stress-testing, a\nbenchmark for evaluating robustness methods, and actionable guidance for\ndesigning more resilient data workflows.",
    "pdf_url": "http://arxiv.org/pdf/2506.01230v1",
    "published": "2025-06-02T00:41:24+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.01229v1",
    "title": "Structured Pruning and Quantization for Learned Image Compression",
    "authors": [
      "Md Adnan Faisal Hossain",
      "Fengqing Zhu"
    ],
    "abstract": "The high computational costs associated with large deep learning models\nsignificantly hinder their practical deployment. Model pruning has been widely\nexplored in deep learning literature to reduce their computational burden, but\nits application has been largely limited to computer vision tasks such as image\nclassification and object detection. In this work, we propose a structured\npruning method targeted for Learned Image Compression (LIC) models that aims to\nreduce the computational costs associated with image compression while\nmaintaining the rate-distortion performance. We employ a Neural Architecture\nSearch (NAS) method based on the rate-distortion loss for computing the pruning\nratio for each layer of the network. We compare our pruned model with the\nuncompressed LIC Model with same network architecture and show that it can\nachieve model size reduction without any BD-Rate performance drop. We further\nshow that our pruning method can be integrated with model quantization to\nachieve further model compression while maintaining similar BD-Rate\nperformance. We have made the source code available at\ngitlab.com/viper-purdue/lic-pruning.",
    "pdf_url": "http://arxiv.org/pdf/2506.01229v1",
    "published": "2025-06-02T00:40:53+00:00",
    "categories": [
      "eess.IV"
    ],
    "primary_category": "eess.IV"
  },
  {
    "id": "http://arxiv.org/abs/2506.01228v3",
    "title": "Reweighted Spectral Partitioning Works: Bounds for Special Graph Classes",
    "authors": [
      "Jack Spalding-Jamieson"
    ],
    "abstract": "Spectral partitioning is a method that can be used to compute small sparse\ncuts or small edge-separators in a wide variety of graph classes, by computing\nthe second-smallest eigenvalue (and eigenvector) of the Laplacian matrix. Upper\nbounds on this eigenvalue for certain graph classes imply that the method\nobtains small edge-separators for these classes, usually with a sub-optimal\ndependence on the maximum degree. In this work, we show that a related method,\ncalled reweighted spectral partitioning, guarantees near-optimal sparse\nvertex-cuts and vertex-separators in a wide variety of graph classes. In many\ncases, this involves little-to-no necessary dependence on maximum degree.\n  We also obtain a new proof of the planar separator theorem, a strengthened\neigenvalue bound for bounded-genus graphs, and a refined form of the recent\nCheeger-style inequality for vertex expansion via a specialized\ndimension-reduction step.",
    "pdf_url": "http://arxiv.org/pdf/2506.01228v3",
    "published": "2025-06-02T00:40:30+00:00",
    "categories": [
      "cs.DS",
      "cs.CG",
      "cs.DM"
    ],
    "primary_category": "cs.DS"
  },
  {
    "id": "http://arxiv.org/abs/2506.01227v1",
    "title": "SPEAR: Security Posture Evaluation using AI Planner-Reasoning on Attack-Connectivity Hypergraphs",
    "authors": [
      "Rakesh Podder",
      "Turgay Caglar",
      "Shadaab Kawnain Bashir",
      "Sarath Sreedharan",
      "Indrajit Ray",
      "Indrakshi Ray"
    ],
    "abstract": "Graph-based frameworks are often used in network hardening to help a cyber\ndefender understand how a network can be attacked and how the best defenses can\nbe deployed. However, incorporating network connectivity parameters in the\nattack graph, reasoning about the attack graph when we do not have access to\ncomplete information, providing system administrator suggestions in an\nunderstandable format, and allowing them to do what-if analysis on various\nscenarios and attacker motives is still missing. We fill this gap by presenting\nSPEAR, a formal framework with tool support for security posture evaluation and\nanalysis that keeps human-in-the-loop. SPEAR uses the causal formalism of AI\nplanning to model vulnerabilities and configurations in a networked system. It\nautomatically converts network configurations and vulnerability descriptions\ninto planning models expressed in the Planning Domain Definition Language\n(PDDL). SPEAR identifies a set of diverse security hardening strategies that\ncan be presented in a manner understandable to the domain expert. These allow\nthe administrator to explore the network hardening solution space in a\nsystematic fashion and help evaluate the impact and compare the different\nsolutions.",
    "pdf_url": "http://arxiv.org/pdf/2506.01227v1",
    "published": "2025-06-02T00:38:47+00:00",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2506.06348v1",
    "title": "Multi-Platform Methane Plume Detection via Model and Domain Adaptation",
    "authors": [
      "Vassiliki Mancoridis",
      "Brian Bue",
      "Jake H. Lee",
      "Andrew K. Thorpe",
      "Daniel Cusworth",
      "Alana Ayasse",
      "Philip G. Brodrick",
      "Riley Duren"
    ],
    "abstract": "Prioritizing methane for near-term climate action is crucial due to its\nsignificant impact on global warming. Previous work used columnwise matched\nfilter products from the airborne AVIRIS-NG imaging spectrometer to detect\nmethane plume sources; convolutional neural networks (CNNs) discerned\nanthropogenic methane plumes from false positive enhancements. However, as an\nincreasing number of remote sensing platforms are used for methane plume\ndetection, there is a growing need to address cross-platform alignment. In this\nwork, we describe model- and data-driven machine learning approaches that\nleverage airborne observations to improve spaceborne methane plume detection,\nreconciling the distributional shifts inherent with performing the same task\nacross platforms. We develop a spaceborne methane plume classifier using data\nfrom the EMIT imaging spectroscopy mission. We refine classifiers trained on\nairborne imagery from AVIRIS-NG campaigns using transfer learning,\noutperforming the standalone spaceborne model. Finally, we use CycleGAN, an\nunsupervised image-to-image translation technique, to align the data\ndistributions between airborne and spaceborne contexts. Translating spaceborne\nEMIT data to the airborne AVIRIS-NG domain using CycleGAN and applying airborne\nclassifiers directly yields the best plume detection results. This methodology\nis useful not only for data simulation, but also for direct data alignment.\nThough demonstrated on the task of methane plume detection, our work more\nbroadly demonstrates a data-driven approach to align related products obtained\nfrom distinct remote sensing instruments.",
    "pdf_url": "http://arxiv.org/pdf/2506.06348v1",
    "published": "2025-06-02T00:38:41+00:00",
    "categories": [
      "eess.SP",
      "cs.LG"
    ],
    "primary_category": "eess.SP"
  },
  {
    "id": "http://arxiv.org/abs/2506.01226v2",
    "title": "React to Surprises: Stable-by-Design Neural Feedback Control and the Youla-REN",
    "authors": [
      "Nicholas H. Barbara",
      "Ruigang Wang",
      "Alexandre Megretski",
      "Ian R. Manchester"
    ],
    "abstract": "We study parameterizations of stabilizing nonlinear policies for\nlearning-based control. We propose a structure based on a nonlinear version of\nthe Youla-Kucera parameterization combined with robust neural networks such as\nthe recurrent equilibrium network (REN). The resulting parameterizations are\nunconstrained, and hence can be searched over with first-order optimization\nmethods, while always ensuring closed-loop stability by construction. We study\nthe combination of (a) nonlinear dynamics, (b) partial observation, and (c)\nincremental closed-loop stability requirements (contraction and Lipschitzness).\nWe find that with any two of these three difficulties, a contracting and\nLipschitz Youla parameter always leads to contracting and Lipschitz closed\nloops. However, if all three hold, then incremental stability can be lost with\nexogenous disturbances. Instead, a weaker condition is maintained, which we\ncall d-tube contraction and Lipschitzness. We further obtain converse results\nshowing that the proposed parameterization covers all contracting and Lipschitz\nclosed loops for certain classes of nonlinear systems. Numerical experiments\nillustrate the utility of our parameterization when learning controllers with\nbuilt-in stability certificates for: (i) \"economic\" rewards without stabilizing\neffects; (ii) short training horizons; and (iii) uncertain systems.",
    "pdf_url": "http://arxiv.org/pdf/2506.01226v2",
    "published": "2025-06-02T00:36:24+00:00",
    "categories": [
      "eess.SY",
      "cs.LG",
      "cs.SY"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2506.01225v1",
    "title": "Self-Refining Training for Amortized Density Functional Theory",
    "authors": [
      "Majdi Hassan",
      "Cristian Gabellini",
      "Hatem Helal",
      "Dominique Beaini",
      "Kirill Neklyudov"
    ],
    "abstract": "Density Functional Theory (DFT) allows for predicting all the chemical and\nphysical properties of molecular systems from first principles by finding an\napproximate solution to the many-body Schr\\\"odinger equation. However, the cost\nof these predictions becomes infeasible when increasing the scale of the energy\nevaluations, e.g., when calculating the ground-state energy for simulating\nmolecular dynamics. Recent works have demonstrated that, for substantially\nlarge datasets of molecular conformations, Deep Learning-based models can\npredict the outputs of the classical DFT solvers by amortizing the\ncorresponding optimization problems. In this paper, we propose a novel method\nthat reduces the dependency of amortized DFT solvers on large pre-collected\ndatasets by introducing a self-refining training strategy. Namely, we propose\nan efficient method that simultaneously trains a deep-learning model to predict\nthe DFT outputs and samples molecular conformations that are used as training\ndata for the model. We derive our method as a minimization of the variational\nupper bound on the KL-divergence measuring the discrepancy between the\ngenerated samples and the target Boltzmann distribution defined by the ground\nstate energy. To demonstrate the utility of the proposed scheme, we perform an\nextensive empirical study comparing it with the models trained on the\npre-collected datasets. Finally, we open-source our implementation of the\nproposed algorithm, optimized with asynchronous training and sampling stages,\nwhich enables simultaneous sampling and training. Code is available at\nhttps://github.com/majhas/self-refining-dft.",
    "pdf_url": "http://arxiv.org/pdf/2506.01225v1",
    "published": "2025-06-02T00:32:32+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG"
  },
  {
    "id": "http://arxiv.org/abs/2506.01224v2",
    "title": "Dirty and Clean-Label attack detection using GAN discriminators",
    "authors": [
      "John W. Smutny"
    ],
    "abstract": "Gathering enough images to train a deep computer vision model is a constant\nchallenge. Unfortunately, collecting images from unknown sources can leave your\nmodel s behavior at risk of being manipulated by a dirty-label or clean-label\nattack unless the images are properly inspected. Manually inspecting each\nimage-label pair is impractical and common poison-detection methods that\ninvolve re-training your model can be time consuming. This research uses GAN\ndiscriminators to protect a single class against mislabeled and different\nlevels of modified images. The effect of said perturbation on a basic\nconvolutional neural network classifier is also included for reference. The\nresults suggest that after training on a single class, GAN discriminator s\nconfidence scores can provide a threshold to identify mislabeled images and\nidentify 100% of the tested poison starting at a perturbation epsilon magnitude\nof 0.20, after decision threshold calibration using in-class samples.\nDevelopers can use this report as a basis to train their own discriminators to\nprotect high valued classes in their CV models.",
    "pdf_url": "http://arxiv.org/pdf/2506.01224v2",
    "published": "2025-06-02T00:32:07+00:00",
    "categories": [
      "cs.CV",
      "eess.IV"
    ],
    "primary_category": "cs.CV"
  },
  {
    "id": "http://arxiv.org/abs/2506.08028v1",
    "title": "Sensor Fusion for Track Geometry Monitoring: Integrating On-Board Data and Degradation Models via Kalman Filtering",
    "authors": [
      "Huy Truong-Ba",
      "Jacky Chin",
      "Michael E. Cholette",
      "Pietro Borghesani"
    ],
    "abstract": "Track geometry monitoring is essential for maintaining the safety and\nefficiency of railway operations. While Track Recording Cars (TRCs) provide\naccurate measurements of track geometry indicators, their limited availability\nand high operational costs restrict frequent monitoring across large rail\nnetworks. Recent advancements in on-board sensor systems installed on\nin-service trains offer a cost-effective alternative by enabling\nhigh-frequency, albeit less accurate, data collection. This study proposes a\nmethod to enhance the reliability of track geometry predictions by integrating\nlow-accuracy sensor signals with degradation models through a Kalman filter\nframework. An experimental campaign using a low-cost sensor system mounted on a\nTRC evaluates the proposed approach. The results demonstrate that incorporating\nfrequent sensor data significantly reduces prediction uncertainty, even when\nthe data is noisy. The study also investigates how the frequency of data\nrecording influences the size of the credible prediction interval, providing\nguidance on the optimal deployment of on-board sensors for effective track\nmonitoring and maintenance planning.",
    "pdf_url": "http://arxiv.org/pdf/2506.08028v1",
    "published": "2025-06-02T00:31:53+00:00",
    "categories": [
      "eess.SY",
      "cs.SY",
      "stat.AP"
    ],
    "primary_category": "eess.SY"
  },
  {
    "id": "http://arxiv.org/abs/2506.01223v1",
    "title": "Poiseuille flow of hyperbolic Ericksen-Leslie system in dimension two",
    "authors": [
      "Geng Chen",
      "Tao Huang",
      "Xiang Xu",
      "Qingtian Zhang"
    ],
    "abstract": "In this paper, we study the Poiseuille laminar flow in a tube for the full\nEricksen-Leslie system. It is a parabolic-hyperbolic coupled system which may\ndevelop singularity in finite time. We will prove the global existence of\nenergy weak solution, and the partial regularity of solution to system. We\nfirst construct global weak finite energy solutions by the Ginzburg- Landau\napproximation and the fixed-point arguments. Then we obtain the enhanced\nregularity of solution. Different from the solution in one space dimension, the\nfinite energy solution of Poiseuille laminar flow in a tube may still form a\ndiscontinuity at the origin. We show that at the first possible blowup time,\nthere are blowup sequences which converge to a non-constant time-independent\n(axisymmetric) harmonic map.",
    "pdf_url": "http://arxiv.org/pdf/2506.01223v1",
    "published": "2025-06-02T00:27:51+00:00",
    "categories": [
      "math.AP"
    ],
    "primary_category": "math.AP"
  },
  {
    "id": "http://arxiv.org/abs/2506.01222v2",
    "title": "Learning collective variables that preserve transition rates",
    "authors": [
      "Shashank Sule",
      "Arnav Mehta",
      "Maria K. Cameron"
    ],
    "abstract": "Collective variables (CVs) play a crucial role in capturing rare events in\nhigh-dimensional systems, motivating the continual search for principled\napproaches to their design. In this work, we revisit the framework of\nquantitative coarse graining and identify the orthogonality condition from\nLegoll and Lelievre (2010) as a key criterion for constructing CVs that\naccurately preserve the statistical properties of the original process. We\nestablish that satisfaction of the orthogonality condition enables error\nestimates for both relative entropy and pathwise distance to scale\nproportionally with the degree of scale separation. Building on this\nfoundation, we introduce a general numerical method for designing neural\nnetwork-based CVs that integrates tools from manifold learning with\ngroup-invariant featurization. To demonstrate the efficacy of our approach, we\nconstruct CVs for butane and achieve a CV that reproduces the anti-gauche\ntransition rate with less than ten percent relative error. Additionally, we\nprovide empirical evidence challenging the necessity of uniform positive\ndefiniteness in diffusion tensors for transition rate reproduction and\nhighlight the critical role of light atoms in CV design for molecular dynamics.",
    "pdf_url": "http://arxiv.org/pdf/2506.01222v2",
    "published": "2025-06-02T00:18:16+00:00",
    "categories": [
      "math.NA",
      "cs.NA",
      "physics.chem-ph",
      "stat.ML",
      "70-08, 60G25, 58-08, 68T07"
    ],
    "primary_category": "math.NA"
  },
  {
    "id": "http://arxiv.org/abs/2506.01221v1",
    "title": "Flexible Mixed Precision Quantization for Learned Image Compression",
    "authors": [
      "Md Adnan Faisal Hossain",
      "Zhihao Duan",
      "Fengqing Zhu"
    ],
    "abstract": "Despite its improvements in coding performance compared to traditional\ncodecs, Learned Image Compression (LIC) suffers from large computational costs\nfor storage and deployment. Model quantization offers an effective solution to\nreduce the computational complexity of LIC models. However, most existing works\nperform fixed-precision quantization which suffers from sub-optimal utilization\nof resources due to the varying sensitivity to quantization of different layers\nof a neural network. In this paper, we propose a Flexible Mixed Precision\nQuantization (FMPQ) method that assigns different bit-widths to different\nlayers of the quantized network using the fractional change in rate-distortion\nloss as the bit-assignment criterion. We also introduce an adaptive search\nalgorithm which reduces the time-complexity of searching for the desired\ndistribution of quantization bit-widths given a fixed model size. Evaluation of\nour method shows improved BD-Rate performance under similar model size\nconstraints compared to other works on quantization of LIC models. We have made\nthe source code available at gitlab.com/viper-purdue/fmpq.",
    "pdf_url": "http://arxiv.org/pdf/2506.01221v1",
    "published": "2025-06-02T00:12:50+00:00",
    "categories": [
      "eess.IV",
      "cs.LG"
    ],
    "primary_category": "eess.IV"
  },
  {
    "id": "http://arxiv.org/abs/2506.01220v3",
    "title": "Vulnerability Management Chaining: An Integrated Framework for Efficient Cybersecurity Risk Prioritization",
    "authors": [
      "Naoyuki Shimizu",
      "Masaki Hashimoto"
    ],
    "abstract": "As the number of Common Vulnerabilities and Exposures (CVE) continues to grow\nexponentially, security teams face increasingly difficult decisions about\nprioritization. Current approaches using Common Vulnerability Scoring System\n(CVSS) scores produce overwhelming volumes of high-priority vulnerabilities,\nwhile Exploit Prediction Scoring System (EPSS) and Known Exploited\nVulnerabilities (KEV) catalog offer valuable but incomplete perspectives on\nactual exploitation risk. We present Vulnerability Management Chaining, a\ndecision tree framework that systematically integrates these three approaches\nto achieve efficient vulnerability prioritization. Our framework employs a\ntwo-stage evaluation process: first applying threat-based filtering using KEV\nmembership or EPSS threshold $\\geq$ 0.088), then applying vulnerability\nseverity assessment using CVSS scores $\\geq$ 7.0) to enable informed\ndeprioritization. Experimental validation using 28,377 real-world\nvulnerabilities and vendor-reported exploitation data demonstrates 18-fold\nefficiency improvements while maintaining 85.6\\% coverage. Organizations can\nreduce urgent remediation workload by approximately 95\\%. The integration\nidentifies 48 additional exploited vulnerabilities that neither KEV nor EPSS\ncaptures individually. Our framework uses exclusively open-source data,\nenabling immediate adoption regardless of organizational resources.",
    "pdf_url": "http://arxiv.org/pdf/2506.01220v3",
    "published": "2025-06-02T00:06:54+00:00",
    "categories": [
      "cs.CR"
    ],
    "primary_category": "cs.CR"
  },
  {
    "id": "http://arxiv.org/abs/2506.01219v1",
    "title": "Reluctant Interaction Inference after Additive Modeling",
    "authors": [
      "Yiling Huang",
      "Snigdha Panigrahi",
      "Guo Yu",
      "Jacob Bien"
    ],
    "abstract": "Additive models enjoy the flexibility of nonlinear models while still being\nreadily understandable to humans. By contrast, other nonlinear models, which\ninvolve interactions between features, are not only harder to fit but also\nsubstantially more complicated to explain. Guided by the principle of\nparsimony, a data analyst therefore may naturally be reluctant to move beyond\nan additive model unless it is truly warranted.\n  To put this principle of interaction reluctance into practice, we formulate\nthe problem as a hypothesis test with a fitted sparse additive model (SPAM)\nserving as the null. Because our hypotheses on interaction effects are formed\nafter fitting a SPAM to the data, we adopt a selective inference approach to\nconstruct p-values that properly account for this data adaptivity. Our approach\nmakes use of external randomization to obtain the distribution of test\nstatistics conditional on the SPAM fit, allowing us to derive valid p-values,\ncorrected for the over-optimism introduced by the data-adaptive process prior\nto the test. Through experiments on simulated and real data, we illustrate\nthat--even with small amounts of external randomization--this rigorous modeling\napproach enjoys considerable advantages over naive methods and data splitting.",
    "pdf_url": "http://arxiv.org/pdf/2506.01219v1",
    "published": "2025-06-02T00:01:23+00:00",
    "categories": [
      "stat.ME"
    ],
    "primary_category": "stat.ME"
  }
]