name: Daily arXiv Scrape

on:
  schedule:
    - cron: '0 12 * * *'  # Run daily at 12 PM UTC (8 AM EST)
  workflow_dispatch:  # Allow manual triggers

jobs:
  scrape:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Debug directory structure
        run: |
          echo "Current directory: $(pwd)"
          echo "Directory contents:"
          ls -la
          echo "Looking for Python files:"
          find . -name "*.py" -type f | head -20

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Install dependencies
        run: |
          pip install arxiv

      - name: Find and run scraper
        run: |
          # Try to find the scraper.py file
          SCRAPER_PATH=$(find . -name "scraper.py" -type f | head -1)
          if [ -z "$SCRAPER_PATH" ]; then
            echo "Error: scraper.py not found!"
            find . -name "*.py" -type f
            exit 1
          fi
          echo "Found scraper at: $SCRAPER_PATH"
          SCRAPER_DIR=$(dirname "$SCRAPER_PATH")
          cd "$SCRAPER_DIR"
          python scraper.py

      - name: Commit and push changes
        run: |
          git config user.name "GitHub Actions"
          git config user.email "actions@users.noreply.github.com"
          git add data/
          git commit -m "Add daily arXiv data for $(date +'%Y-%m-%d')" || echo "No changes to commit"
          git push
