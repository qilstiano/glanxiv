name: Daily arXiv Scrape

on:
  schedule:
    - cron: '0 12 * * *'  # Run daily at 12 PM UTC (8 AM EST)
  workflow_dispatch:  # Allow manual triggers

jobs:
  scrape:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Debug directory structure
        run: |
          echo "Current directory: $(pwd)"
          echo "Directory contents:"
          ls -la
          echo "Looking for Python files:"
          find . -name "*.py" -type f | head -20

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Install dependencies
        run: |
          pip install arxiv

      - name: Find and run scraper
        run: |
          # Try to find and run the scraper
          if [ -f "scraper.py" ]; then
            python scraper.py
          elif [ -f "glanxiv/scraper.py" ]; then
            cd glanxiv
            python scraper.py
          elif [ -f "glanxiv/glanxiv/scraping/scraper.py" ]; then
            cd glanxiv/glanxiv/scraping
            python scraper.py
          else
            echo "Could not find scraper.py in any expected location!"
            find . -name "*.py" -type f
            exit 1
          fi

          - name: Commit and push changes
            run: |
              git config user.name "GitHub Actions"
              git config user.email "actions@users.noreply.github.com"
              # Add the correct data directory path
              git add public/data/
              git commit -m "Add daily arXiv data for $(date +'%Y-%m-%d')" || echo "No changes to commit"
              git push

